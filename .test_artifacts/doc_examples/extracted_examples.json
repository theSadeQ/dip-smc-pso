[
  {
    "id": "benchmarks_methodology_1_e5cb3878",
    "file": "docs\\benchmarks_methodology.md",
    "index": 1,
    "code": "# Base seed for reproducibility\nbase_seed = 1234\n\n# Each trial gets independent seed\ntrial_seeds = rng.integers(0, 2**32-1, size=n_trials)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e5cb3878"
  },
  {
    "id": "benchmarks_methodology_2_0e94388f",
    "file": "docs\\benchmarks_methodology.md",
    "index": 2,
    "code": "# Configurable noise standard deviation\nnoise_std = 0.001  # 1mm position noise\nx_noisy = x_true + N(0, noise_std)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e94388f"
  },
  {
    "id": "benchmarks_methodology_3_4a2fbd05",
    "file": "docs\\benchmarks_methodology.md",
    "index": 3,
    "code": "# Example: \u00b15 degree initial angle variation\n\u03b81_init = np.random.uniform(-\u03c0/36, \u03c0/36)\n\u03b82_init = np.random.uniform(-\u03c0/36, \u03c0/36)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a2fbd05"
  },
  {
    "id": "benchmarks_methodology_4_bd8ec234",
    "file": "docs\\benchmarks_methodology.md",
    "index": 4,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials\nfrom src.controllers.factory import create_controller_factory\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller factory\nfactory = create_controller_factory('classical_smc', config.controllers.classical_smc)\n\n# Run benchmark\nmetrics_per_trial, ci_results = run_trials(\n    controller_factory=factory,\n    cfg=config,\n    n_trials=30,\n    seed=1234\n)\n\n# Display results with confidence intervals\nfor metric, (mean, ci_width) in ci_results.items():\n    print(f\"{metric}: {mean:.4f} \u00b1 {ci_width:.4f}\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd8ec234"
  },
  {
    "id": "benchmarks_methodology_5_7f5a4ff1",
    "file": "docs\\benchmarks_methodology.md",
    "index": 5,
    "code": "# Test with physics uncertainty and sensor noise\nmetrics_robust, ci_robust = run_trials(\n    controller_factory=factory,\n    cfg=config,\n    n_trials=50,              # More trials for robustness testing\n    randomise_physics=True,   # Enable parameter variations\n    noise_std=0.001          # Add sensor noise\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7f5a4ff1"
  },
  {
    "id": "benchmarks_methodology_6_aef92a84",
    "file": "docs\\benchmarks_methodology.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ncontrollers = ['classical_smc', 'sta_smc', 'adaptive_smc']\nresults = {}\n\nfor ctrl_name in controllers:\n    factory = create_controller_factory(ctrl_name, getattr(config.controllers, ctrl_name))\n    _, ci_results = run_trials(factory, config, n_trials=30)\n    results[ctrl_name] = ci_results\n\n# Compare ISE performance\nfor ctrl, metrics in results.items():\n    ise_mean, ise_ci = metrics['ise']\n    print(f\"{ctrl}: ISE = {ise_mean:.3f} \u00b1 {ise_ci:.3f}\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aef92a84"
  },
  {
    "id": "benchmarks_methodology_7_afb18db8",
    "file": "docs\\benchmarks_methodology.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nbenchmark_metadata = {\n    'timestamp': datetime.now().isoformat(),\n    'config_hash': hashlib.md5(config_content).hexdigest(),\n    'random_seed': 1234,\n    'n_trials': 30,\n    'environment': {\n        'python_version': sys.version,\n        'numpy_version': np.__version__,\n        'platform': platform.platform()\n    }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "afb18db8"
  },
  {
    "id": "benchmarks_methodology_8_7cf32c05",
    "file": "docs\\benchmarks_methodology.md",
    "index": 8,
    "code": "uncertainty_levels = [0.0, 0.05, 0.10, 0.15, 0.20]\nsensitivity_results = {}\n\nfor uncertainty in uncertainty_levels:\n    # Update config with uncertainty level\n    config.physics_uncertainty.cart_mass = uncertainty\n\n    # Run benchmark\n    _, ci_results = run_trials(factory, config, n_trials=30)\n    sensitivity_results[uncertainty] = ci_results['ise'][0]  # Mean ISE",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7cf32c05"
  },
  {
    "id": "benchmarks_methodology_9_6638de37",
    "file": "docs\\benchmarks_methodology.md",
    "index": 9,
    "code": "from scipy import stats\n\n# Compare two controllers\nctrl1_ise = [trial['ise'] for trial in metrics_ctrl1]\nctrl2_ise = [trial['ise'] for trial in metrics_ctrl2]\n\n# Welch's t-test (unequal variances)\nt_stat, p_value = stats.ttest_ind(ctrl1_ise, ctrl2_ise, equal_var=False)\n\n# Significant difference if p < 0.05\nif p_value < 0.05:\n    print(f\"Controllers significantly different (p={p_value:.4f})\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6638de37"
  },
  {
    "id": "CLAUDE_1_c9e1fcc9",
    "file": "docs\\CLAUDE.md",
    "index": 1,
    "code": "from pathlib import Path\nimport sys\nsys.path.insert(0, str(Path.cwd() / \".dev_tools\"))\n\nfrom session_manager import has_recent_session, get_session_summary, load_session\n\nif has_recent_session():\n    print(get_session_summary())\n    state = load_session()\n    # Resume work based on state['context'] and state['next_actions']",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9e1fcc9"
  },
  {
    "id": "CLAUDE_2_8bcea043",
    "file": "docs\\CLAUDE.md",
    "index": 2,
    "code": "from session_manager import add_completed_todo\n   add_completed_todo(\"Create PowerShell backup script\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8bcea043"
  },
  {
    "id": "CLAUDE_3_a17cca45",
    "file": "docs\\CLAUDE.md",
    "index": 3,
    "code": "from session_manager import add_decision\n   add_decision(\"Task Scheduler frequency: 1 minute\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a17cca45"
  },
  {
    "id": "CLAUDE_4_07bee1fa",
    "file": "docs\\CLAUDE.md",
    "index": 4,
    "code": "from session_manager import update_session_context\n   update_session_context(\n       current_task=\"Implementing feature X\",\n       phase=\"testing\",\n       last_commit=\"abc1234\"\n   )",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07bee1fa"
  },
  {
    "id": "CLAUDE_5_e5b4ae6f",
    "file": "docs\\CLAUDE.md",
    "index": 5,
    "code": "from session_manager import add_next_action\n   add_next_action(\"Register Task Scheduler job\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e5b4ae6f"
  },
  {
    "id": "CLAUDE_6_8b4d952f",
    "file": "docs\\CLAUDE.md",
    "index": 6,
    "code": "from session_manager import mark_token_limit_approaching, finalize_session\n   mark_token_limit_approaching()\n   finalize_session(\"Completed automated backup system implementation\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b4d952f"
  },
  {
    "id": "CLAUDE_7_47620691",
    "file": "docs\\CLAUDE.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Check for continuable session\nhas_recent_session(threshold_hours=24) -> bool\n\n# Load session state\nload_session() -> Optional[Dict]\n\n# Get human-readable summary\nget_session_summary() -> str\n\n# Update session context\nupdate_session_context(**kwargs) -> bool\n\n# Track progress\nadd_completed_todo(todo: str) -> bool\nadd_decision(decision: str) -> bool\nadd_next_action(action: str) -> bool\n\n# Prepare for handoff\nmark_token_limit_approaching() -> bool\nfinalize_session(summary: str) -> bool",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47620691"
  },
  {
    "id": "CLAUDE_8_c060a50e",
    "file": "docs\\CLAUDE.md",
    "index": 8,
    "code": "# Claude automatically throughout session:\nupdate_session_context(current_task=\"Implementing backup system\", phase=\"testing\")\nadd_completed_todo(\"Create PowerShell script\")\nadd_completed_todo(\"Write documentation\")\nadd_next_action(\"User needs to register Task Scheduler\")\n\n# As token limit approaches:\nmark_token_limit_approaching()\nfinalize_session(\"Backup system implementation complete\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c060a50e"
  },
  {
    "id": "CLAUDE_9_3bf75e25",
    "file": "docs\\CLAUDE.md",
    "index": 9,
    "code": "from src.core.vector_sim import run_batch_simulation\nresults = run_batch_simulation(controller, dynamics, initial_conditions, sim_params)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3bf75e25"
  },
  {
    "id": "CLAUDE_10_79e56a7c",
    "file": "docs\\CLAUDE.md",
    "index": 10,
    "code": "from src.config import load_config\nconfig = load_config(\"config.yaml\", allow_unknown=False)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79e56a7c"
  },
  {
    "id": "CLAUDE_11_55f876be",
    "file": "docs\\CLAUDE.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/optimization/monitor_and_validate.py pattern:\n# 1. Monitor PSO logs for completion\n# 2. Auto-trigger validation when done\n# 3. Update config if validation passes\n# 4. Provide clear next steps",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55f876be"
  },
  {
    "id": "CLAUDE_12_73fa010f",
    "file": "docs\\CLAUDE.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/optimization/validate_and_summarize.py pattern:\n# 1. Load optimized gains from JSON\n# 2. Re-simulate with exact PSO metrics\n# 3. Compare against acceptance criteria\n# 4. Generate comprehensive summary JSON",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "73fa010f"
  },
  {
    "id": "CLAUDE_13_a9b08055",
    "file": "docs\\CLAUDE.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# ClassicalSMC implementation\nif dynamics_model is not None:\n    self._dynamics_ref = weakref.ref(dynamics_model)\nelse:\n    self._dynamics_ref = lambda: None\n\n@property\ndef dyn(self):\n    \"\"\"Access dynamics model via weakref.\"\"\"\n    if self._dynamics_ref is not None:\n        return self._dynamics_ref()\n    return None",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9b08055"
  },
  {
    "id": "CLAUDE_14_70808e7e",
    "file": "docs\\CLAUDE.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.smc import ClassicalSMC\n\ncontroller = ClassicalSMC(gains=[...], max_force=100, boundary_layer=0.01)\n# ... use controller ...\ncontroller.cleanup()  # Explicit cleanup\ndel controller",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70808e7e"
  },
  {
    "id": "CLAUDE_15_0fbfb9a1",
    "file": "docs\\CLAUDE.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# Automatic cleanup when controller goes out of scope\ndef run_simulation():\n    controller = ClassicalSMC(...)\n    return simulate(controller, duration=5.0)\n# Controller automatically cleaned up via __del__",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fbfb9a1"
  },
  {
    "id": "CLAUDE_16_44ac8b31",
    "file": "docs\\CLAUDE.md",
    "index": 16,
    "code": "import psutil\nimport os\n\nclass MemoryMonitor:\n    def __init__(self, threshold_mb=500):\n        self.threshold_mb = threshold_mb\n        self.process = psutil.Process(os.getpid())\n\n    def check(self):\n        memory_mb = self.process.memory_info().rss / 1024 / 1024\n        if memory_mb > self.threshold_mb:\n            return f\"Alert: {memory_mb:.1f}MB > {self.threshold_mb}MB\"\n        return None\n\nmonitor = MemoryMonitor(threshold_mb=500)\nif alert := monitor.check():\n    history = controller.initialize_history()  # Clear buffers",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "44ac8b31"
  },
  {
    "id": "CLAUDE_17_ab1ada5a",
    "file": "docs\\CLAUDE.md",
    "index": 17,
    "code": "controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100, boundary_layer=0.01)\nresult = simulate(controller)\n# Automatic cleanup",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab1ada5a"
  },
  {
    "id": "CLAUDE_18_e5747190",
    "file": "docs\\CLAUDE.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ncontroller = HybridAdaptiveSTASMC(gains=[...], dt=0.01, max_force=100, ...)\nhistory = controller.initialize_history()\n\nwhile running:\n    control, state_vars, history = controller.compute_control(state, state_vars, history)\n\n    # Hourly cleanup\n    if time.time() - last_cleanup > 3600:\n        history = controller.initialize_history()\n        gc.collect()",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e5747190"
  },
  {
    "id": "CLAUDE_19_fe388afc",
    "file": "docs\\CLAUDE.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nfor i in range(10000):\n    controller = AdaptiveSMC(gains=candidates[i], ...)\n    fitness[i] = evaluate(controller)\n\n    if i % 100 == 99:\n        controller.cleanup()\n        del controller\n        gc.collect()",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe388afc"
  },
  {
    "id": "CLAUDE_20_76e732cf",
    "file": "docs\\CLAUDE.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.factory import create_controller\ncontroller = create_controller(\n  'classical_smc',\n  config=controller_config,\n  gains=[10.0, 5.0, 8.0, 3.0, 15.0, 2.0]\n)\ncontrol_output = controller.compute_control(state, last_control, history)\n# Optimization (PSO)\nfrom src.optimizer.pso_optimizer import PSOTuner\n# ... initialize bounds, tuner, and run pso.optimize(...)\n# Monitoring\nfrom src.utils.monitoring.latency import LatencyMonitor\nmonitor = LatencyMonitor(dt=0.01)\nstart = monitor.start()\n# ... loop ...\nmissed = monitor.end(start)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e732cf"
  },
  {
    "id": "configuration_integration_documentation_1_724394b7",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 1,
    "code": "def demonstrate_configuration_priority():\n    \"\"\"Demonstrate configuration priority resolution.\"\"\"\n\n    from src.config import load_config\n    from src.controllers.factory import create_controller\n\n    # Load YAML configuration\n    config = load_config(\"config.yaml\")  # Contains gains: [10, 8, 5, 3, 20, 2]\n\n    # Priority 1: Explicit parameters override everything\n    controller = create_controller(\n        'classical_smc',\n        config=config,\n        gains=[25, 20, 15, 10, 40, 6]  # These gains will be used (Priority 1)\n    )\n    print(f\"Priority 1 - Explicit gains: {controller.gains}\")\n\n    # Priority 2: Configuration object when no explicit parameters\n    controller = create_controller(\n        'classical_smc',\n        config=config  # Uses gains from config.yaml (Priority 2)\n    )\n    print(f\"Priority 2 - Config gains: {controller.gains}\")\n\n    # Priority 3: Registry defaults when no config provided\n    controller = create_controller('classical_smc')  # Uses registry defaults (Priority 3)\n    print(f\"Priority 3 - Default gains: {controller.gains}\")\n\ndemonstrate_configuration_priority()",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "724394b7"
  },
  {
    "id": "configuration_integration_documentation_2_3c28cae2",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 2,
    "code": "# Highest priority - always used when provided\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20, 15, 12, 8, 35, 5],    # Explicit gains\n    max_force=150.0,                  # Explicit max_force\n    boundary_layer=0.02               # Explicit boundary_layer\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c28cae2"
  },
  {
    "id": "configuration_integration_documentation_3_f8c55e2d",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Second priority - extracted from configuration objects\nclass CustomConfig:\n    def __init__(self):\n        self.controllers = {\n            'classical_smc': {\n                'gains': [18, 12, 10, 6, 30, 4],\n                'max_force': 120.0,\n                'boundary_layer': 0.015\n            }\n        }\n\nconfig = CustomConfig()\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8c55e2d"
  },
  {
    "id": "configuration_integration_documentation_4_0fc4d7c2",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Fourth priority - built-in defaults\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        # ... other defaults\n    }\n}",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fc4d7c2"
  },
  {
    "id": "configuration_integration_documentation_5_2d98e7d7",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nfrom pydantic import BaseModel, Field, validator\nfrom typing import List, Dict, Optional, Literal\n\nclass PhysicsConfig(BaseModel):\n    \"\"\"Physics parameters for the double-inverted pendulum.\"\"\"\n\n    m1: float = Field(..., gt=0, description=\"Upper pendulum mass [kg]\")\n    m2: float = Field(..., gt=0, description=\"Lower pendulum mass [kg]\")\n    M: float = Field(..., gt=0, description=\"Cart mass [kg]\")\n    l1: float = Field(..., gt=0, description=\"Upper pendulum length [m]\")\n    l2: float = Field(..., gt=0, description=\"Lower pendulum length [m]\")\n    b1: float = Field(..., ge=0, description=\"Upper pendulum friction\")\n    b2: float = Field(..., ge=0, description=\"Lower pendulum friction\")\n    I1: float = Field(..., gt=0, description=\"Upper pendulum inertia [kg\u22c5m\u00b2]\")\n    I2: float = Field(..., gt=0, description=\"Lower pendulum inertia [kg\u22c5m\u00b2]\")\n\nclass SimulationConfig(BaseModel):\n    \"\"\"Simulation parameters.\"\"\"\n\n    duration: float = Field(..., gt=0, description=\"Simulation time [s]\")\n    dt: float = Field(..., gt=0, le=0.01, description=\"Integration timestep [s]\")\n    initial_state: List[float] = Field(..., min_items=6, max_items=6)\n    use_full_dynamics: bool = Field(False, description=\"Use full nonlinear dynamics\")\n\n    @validator('initial_state')\n    def validate_initial_state(cls, v):\n        \"\"\"Validate initial state vector.\"\"\"\n        if len(v) != 6:\n            raise ValueError(\"Initial state must have 6 components\")\n\n        # Check angle limits (\u00b1\u03c0)\n        if abs(v[0]) > 3.14159 or abs(v[1]) > 3.14159:\n            raise ValueError(\"Initial angles must be within \u00b1\u03c0 radians\")\n\n        return v\n\nclass ClassicalSMCConfig(BaseModel):\n    \"\"\"Classical SMC controller configuration.\"\"\"\n\n    gains: List[float] = Field(..., min_items=6, max_items=6)\n    max_force: float = Field(..., gt=0)\n    boundary_layer: float = Field(..., gt=0)\n    dt: float = Field(..., gt=0)\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = \"tanh\"\n    regularization: float = Field(1e-10, gt=0)\n\n    @validator('gains')\n    def validate_gains(cls, v):\n        \"\"\"Validate SMC gains for stability.\"\"\"\n        if not all(g > 0 for g in v):\n            raise ValueError(\"All SMC gains must be positive\")\n\n        k1, k2, lam1, lam2, K, kd = v\n\n        # Stability constraints\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Surface coefficients \u03bb1, \u03bb2 must be positive\")\n\n        if K <= 0:\n            raise ValueError(\"Switching gain K must be positive\")\n\n        # Practical constraints\n        if K > 200:\n            raise ValueError(\"Switching gain K too large (>200), may cause excessive chattering\")\n\n        return v\n\nclass ConfigSchema(BaseModel):\n    \"\"\"Complete configuration schema.\"\"\"\n\n    global_seed: Optional[int] = Field(None, ge=0)\n    physics: PhysicsConfig\n    simulation: SimulationConfig\n    controllers: Dict[str, Dict] = Field(default_factory=dict)\n    pso: Optional[Dict] = Field(default_factory=dict)\n    cost_function: Optional[Dict] = Field(default_factory=dict)\n    hil: Optional[Dict] = Field(default_factory=dict)\n    logging: Optional[Dict] = Field(default_factory=dict)\n    monitoring: Optional[Dict] = Field(default_factory=dict)",
    "lines": 82,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d98e7d7"
  },
  {
    "id": "configuration_integration_documentation_6_1a9b5cb3",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 6,
    "code": "from dataclasses import dataclass, field\nfrom typing import List, Optional, Literal\nimport numpy as np\n\n@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    \"\"\"Type-safe configuration for Classical SMC controller.\"\"\"\n\n    # Required parameters\n    gains: List[float] = field()                           # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    max_force: float = field()                             # Control saturation limit [N]\n    boundary_layer: float = field()                        # Chattering reduction thickness\n\n    # Optional parameters with defaults\n    dt: float = field(default=0.01)                       # Control timestep [s]\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = field(default=\"tanh\")\n    regularization: float = field(default=1e-10)          # Matrix regularization\n    boundary_layer_slope: float = field(default=0.0)      # Adaptive boundary layer\n    controllability_threshold: Optional[float] = field(default=None)\n\n    # Optional dynamics model\n    dynamics_model: Optional[object] = field(default=None, compare=False)\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after creation.\"\"\"\n        self._validate_gains()\n        self._validate_control_parameters()\n        self._validate_stability_requirements()\n\n    def _validate_gains(self):\n        \"\"\"Validate gain array for classical SMC.\"\"\"\n        if len(self.gains) != 6:\n            raise ValueError(\"Classical SMC requires exactly 6 gains: [k1, k2, \u03bb1, \u03bb2, K, kd]\")\n\n        if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in self.gains):\n            raise ValueError(\"All gains must be finite numbers\")\n\n        if not all(g > 0 for g in self.gains):\n            raise ValueError(\"All gains must be positive for stability\")\n\n        k1, k2, lam1, lam2, K, kd = self.gains\n\n        # Control theory constraints\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Surface coefficients \u03bb1, \u03bb2 must be positive (Hurwitz stability)\")\n\n        if K <= 0:\n            raise ValueError(\"Switching gain K must be positive (reaching condition)\")\n\n        # Practical constraints\n        if K > 200:\n            raise ValueError(\"Switching gain K > 200 may cause excessive chattering\")\n\n        if lam1/k1 > 50 or lam2/k2 > 50:\n            raise ValueError(\"Surface coefficient ratios too large (\u03bb/k > 50)\")\n\n    def _validate_control_parameters(self):\n        \"\"\"Validate control-specific parameters.\"\"\"\n        if self.max_force <= 0:\n            raise ValueError(\"max_force must be positive\")\n\n        if self.boundary_layer <= 0:\n            raise ValueError(\"boundary_layer must be positive\")\n\n        if self.dt <= 0:\n            raise ValueError(\"dt must be positive\")\n\n        if self.regularization <= 0:\n            raise ValueError(\"regularization must be positive\")\n\n    def _validate_stability_requirements(self):\n        \"\"\"Validate control theory stability requirements.\"\"\"\n        k1, k2, lam1, lam2, K, kd = self.gains\n\n        # Lyapunov stability condition: surface must be stable\n        # For s = \u03bb1*e1 + \u03bb2*e2 + \u01171 + \u01172, we need \u03bb1, \u03bb2 > 0\n\n        # Reaching condition: K must overcome uncertainties\n        # Conservative estimate: K > max(k1, k2) for robustness\n        min_K = max(k1, k2)\n        if K < min_K:\n            print(f\"Warning: K={K} < max(k1,k2)={min_K}, may not satisfy reaching condition\")\n\n        # Chattering bound: K should not be excessively large\n        if K > 10 * min_K:\n            print(f\"Warning: K={K} >> max(k1,k2)={min_K}, expect significant chattering\")",
    "lines": 86,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a9b5cb3"
  },
  {
    "id": "configuration_integration_documentation_7_30fe8206",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass AdaptiveSMCConfig:\n    \"\"\"Type-safe configuration for Adaptive SMC controller.\"\"\"\n\n    # Required parameters\n    gains: List[float] = field()                           # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    max_force: float = field()                             # Control saturation limit\n    dt: float = field()                                    # Control timestep\n\n    # Adaptive parameters\n    leak_rate: float = field(default=0.01)                 # \u03c3-modification leak rate\n    dead_zone: float = field(default=0.05)                 # Adaptation dead zone\n    adapt_rate_limit: float = field(default=10.0)          # Maximum adaptation rate\n    K_min: float = field(default=0.1)                      # Minimum adaptive gain\n    K_max: float = field(default=100.0)                    # Maximum adaptive gain\n    K_init: float = field(default=10.0)                    # Initial adaptive gain\n    alpha: float = field(default=0.5)                      # Adaptation smoothing\n    boundary_layer: float = field(default=0.01)            # Chattering reduction\n    smooth_switch: bool = field(default=True)              # Smooth switching\n\n    # Optional dynamics model\n    dynamics_model: Optional[object] = field(default=None, compare=False)\n\n    def __post_init__(self):\n        \"\"\"Validate adaptive SMC configuration.\"\"\"\n        self._validate_gains()\n        self._validate_adaptive_parameters()\n        self._validate_adaptation_stability()\n\n    def _validate_gains(self):\n        \"\"\"Validate gain array for adaptive SMC.\"\"\"\n        if len(self.gains) != 5:\n            raise ValueError(\"Adaptive SMC requires exactly 5 gains: [k1, k2, \u03bb1, \u03bb2, \u03b3]\")\n\n        if not all(g > 0 for g in self.gains):\n            raise ValueError(\"All gains must be positive\")\n\n        k1, k2, lam1, lam2, gamma = self.gains\n\n        # Adaptation rate constraints\n        if gamma <= 0:\n            raise ValueError(\"Adaptation rate \u03b3 must be positive\")\n\n        if gamma > 50:\n            raise ValueError(\"Adaptation rate \u03b3 > 50 may cause instability\")\n\n        # Surface stability\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Surface coefficients must be positive\")\n\n    def _validate_adaptive_parameters(self):\n        \"\"\"Validate adaptation-specific parameters.\"\"\"\n        if not 0 < self.leak_rate < 1:\n            raise ValueError(\"leak_rate must be in (0, 1)\")\n\n        if self.dead_zone <= 0:\n            raise ValueError(\"dead_zone must be positive\")\n\n        if self.adapt_rate_limit <= 0:\n            raise ValueError(\"adapt_rate_limit must be positive\")\n\n        if not 0 < self.K_min < self.K_max:\n            raise ValueError(\"Must have 0 < K_min < K_max\")\n\n        if not self.K_min <= self.K_init <= self.K_max:\n            raise ValueError(\"K_init must be in [K_min, K_max]\")\n\n    def _validate_adaptation_stability(self):\n        \"\"\"Validate adaptation stability requirements.\"\"\"\n        k1, k2, lam1, lam2, gamma = self.gains\n\n        # Ensure adaptation is not too aggressive relative to surface dynamics\n        surface_time_constant = min(1/lam1, 1/lam2)\n        adaptation_time_constant = 1/gamma\n\n        if adaptation_time_constant < 0.1 * surface_time_constant:\n            print(f\"Warning: Fast adaptation (\u03c4_adapt={adaptation_time_constant:.3f}) \"\n                  f\"relative to surface dynamics (\u03c4_surface={surface_time_constant:.3f})\")",
    "lines": 81,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30fe8206"
  },
  {
    "id": "configuration_integration_documentation_8_9a872008",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SuperTwistingSMCConfig:\n    \"\"\"Type-safe configuration for Super-Twisting SMC controller.\"\"\"\n\n    # Required parameters\n    gains: List[float] = field()                           # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    max_force: float = field()                             # Control saturation limit\n    dt: float = field()                                    # Control timestep\n\n    # Super-twisting specific parameters\n    power_exponent: float = field(default=0.5)             # Fractional power (0 < \u03b1 < 1)\n    regularization: float = field(default=1e-6)            # Singularity avoidance\n    boundary_layer: float = field(default=0.01)            # Chattering reduction\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = field(default=\"tanh\")\n    damping_gain: float = field(default=0.0)               # Additional damping\n\n    # Optional dynamics model\n    dynamics_model: Optional[object] = field(default=None, compare=False)\n\n    def __post_init__(self):\n        \"\"\"Validate super-twisting configuration.\"\"\"\n        self._validate_gains()\n        self._validate_twisting_parameters()\n        self._validate_convergence_conditions()\n\n    def _validate_gains(self):\n        \"\"\"Validate gain array for super-twisting SMC.\"\"\"\n        if len(self.gains) != 6:\n            raise ValueError(\"Super-twisting SMC requires 6 gains: [K1, K2, k1, k2, \u03bb1, \u03bb2]\")\n\n        if not all(g > 0 for g in self.gains):\n            raise ValueError(\"All gains must be positive\")\n\n        K1, K2, k1, k2, lam1, lam2 = self.gains\n\n        # Super-twisting stability conditions\n        if K1 <= 0 or K2 <= 0:\n            raise ValueError(\"Algorithmic gains K1, K2 must be positive\")\n\n        # Surface gains\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Surface coefficients must be positive\")\n\n    def _validate_twisting_parameters(self):\n        \"\"\"Validate super-twisting specific parameters.\"\"\"\n        if not 0 < self.power_exponent < 1:\n            raise ValueError(\"Power exponent must be in (0, 1) for finite-time convergence\")\n\n        if self.regularization <= 0:\n            raise ValueError(\"Regularization must be positive\")\n\n        if self.boundary_layer <= 0:\n            raise ValueError(\"Boundary layer must be positive\")\n\n        if self.damping_gain < 0:\n            raise ValueError(\"Damping gain must be non-negative\")\n\n    def _validate_convergence_conditions(self):\n        \"\"\"Validate finite-time convergence conditions.\"\"\"\n        K1, K2, k1, k2, lam1, lam2 = self.gains\n\n        # Super-twisting convergence requires specific gain relationships\n        # Sufficient condition: K1 > \u221a(2)*uncertainty_bound\n        # and K2 > uncertainty_bound for some uncertainty bound\n\n        # Check gain ratios for practical convergence\n        if K2 > 2 * K1:\n            print(f\"Warning: K2={K2} > 2*K1={2*K1}, may cause oscillations\")\n\n        if K1 < max(k1, k2):\n            print(f\"Warning: K1={K1} < max(k1,k2), may not achieve finite-time convergence\")",
    "lines": 74,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a872008"
  },
  {
    "id": "configuration_integration_documentation_9_fd37db0a",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef _resolve_controller_gains(\n    gains: Optional[Union[List[float], np.ndarray]],\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> List[float]:\n    \"\"\"Resolve controller gains from multiple sources with priority.\"\"\"\n\n    # Priority 1: Explicit gains parameter\n    if gains is not None:\n        if isinstance(gains, np.ndarray):\n            gains = gains.tolist()\n        return gains\n\n    # Priority 2: Configuration object extraction\n    if config is not None:\n        extracted_gains = _extract_gains_from_config(config, controller_type)\n        if extracted_gains is not None:\n            return extracted_gains\n\n    # Priority 3: Registry defaults\n    return controller_info['default_gains']\n\ndef _extract_gains_from_config(config: Any, controller_type: str) -> Optional[List[float]]:\n    \"\"\"Extract gains from configuration object using multiple patterns.\"\"\"\n\n    extraction_patterns = [\n        # Pattern 1: config.controllers.controller_type.gains\n        lambda: getattr(getattr(config.controllers, controller_type, None), 'gains', None),\n\n        # Pattern 2: config.controllers[controller_type]['gains']\n        lambda: config.controllers[controller_type]['gains'] if isinstance(config.controllers, dict) else None,\n\n        # Pattern 3: config.controller_defaults.controller_type.gains\n        lambda: getattr(getattr(config.controller_defaults, controller_type, None), 'gains', None),\n\n        # Pattern 4: config.controller_defaults[controller_type]['gains']\n        lambda: config.controller_defaults[controller_type]['gains'] if isinstance(config.controller_defaults, dict) else None,\n    ]\n\n    for pattern in extraction_patterns:\n        try:\n            gains = pattern()\n            if gains is not None and isinstance(gains, (list, tuple)) and len(gains) > 0:\n                return list(gains)\n        except (AttributeError, KeyError, TypeError):\n            continue\n\n    return None",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd37db0a"
  },
  {
    "id": "configuration_integration_documentation_10_9873dc11",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 10,
    "code": "from pydantic import BaseModel\nfrom typing import Dict, Any\n\nclass ControllerConfig(BaseModel):\n    gains: List[float]\n    max_force: float\n    boundary_layer: float\n    dt: float\n\nclass ProjectConfig(BaseModel):\n    controllers: Dict[str, ControllerConfig]\n    physics: Dict[str, float]\n    simulation: Dict[str, Any]\n\n# Usage\nconfig_data = {\n    'controllers': {\n        'classical_smc': {\n            'gains': [20, 15, 12, 8, 35, 5],\n            'max_force': 150.0,\n            'boundary_layer': 0.02,\n            'dt': 0.001\n        }\n    },\n    'physics': {'m1': 0.5, 'm2': 0.5, 'M': 2.0},\n    'simulation': {'duration': 5.0, 'dt': 0.001}\n}\n\nconfig = ProjectConfig(**config_data)\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9873dc11"
  },
  {
    "id": "configuration_integration_documentation_11_ef157b8c",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Nested dictionary configuration\nconfig = {\n    'controllers': {\n        'classical_smc': {\n            'gains': [18, 12, 10, 6, 30, 4],\n            'max_force': 120.0,\n            'boundary_layer': 0.015,\n            'dt': 0.001\n        },\n        'adaptive_smc': {\n            'gains': [22, 16, 12, 8, 3.5],\n            'max_force': 140.0,\n            'dt': 0.001,\n            'leak_rate': 0.015\n        }\n    }\n}\n\n# Use with factory\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef157b8c"
  },
  {
    "id": "configuration_integration_documentation_12_cedd5799",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass AttributeConfig:\n    \"\"\"Configuration using attributes.\"\"\"\n\n    def __init__(self):\n        # Create controller configurations as attributes\n        self.classical_smc = type('Config', (), {\n            'gains': [25, 20, 15, 10, 40, 6],\n            'max_force': 160.0,\n            'boundary_layer': 0.025,\n            'dt': 0.001\n        })()\n\n        self.adaptive_smc = type('Config', (), {\n            'gains': [30, 22, 18, 12, 5.0],\n            'max_force': 160.0,\n            'dt': 0.001,\n            'leak_rate': 0.02\n        })()\n\n# Initialize controllers namespace\nconfig = type('Config', (), {})()\nconfig.controllers = AttributeConfig()\n\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cedd5799"
  },
  {
    "id": "configuration_integration_documentation_13_ed29aa0b",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 13,
    "code": "class DynamicConfigurationManager:\n    \"\"\"Manage dynamic configuration updates.\"\"\"\n\n    def __init__(self, config_file=\"config.yaml\"):\n        self.config_file = config_file\n        self.config = self._load_config()\n        self.controller_cache = {}\n        self.observers = []\n\n    def _load_config(self):\n        \"\"\"Load configuration from file.\"\"\"\n        from src.config import load_config\n        return load_config(self.config_file)\n\n    def update_controller_config(self, controller_type: str, **updates):\n        \"\"\"Update controller configuration dynamically.\"\"\"\n\n        # Update configuration\n        if controller_type not in self.config.controllers:\n            self.config.controllers[controller_type] = {}\n\n        for key, value in updates.items():\n            self.config.controllers[controller_type][key] = value\n\n        # Invalidate cached controllers\n        if controller_type in self.controller_cache:\n            del self.controller_cache[controller_type]\n\n        # Notify observers\n        self._notify_observers(controller_type, updates)\n\n    def get_controller(self, controller_type: str):\n        \"\"\"Get controller with current configuration.\"\"\"\n\n        if controller_type not in self.controller_cache:\n            # Create controller with current config\n            controller = create_controller(controller_type, config=self.config)\n            self.controller_cache[controller_type] = controller\n\n        return self.controller_cache[controller_type]\n\n    def register_observer(self, callback):\n        \"\"\"Register configuration change observer.\"\"\"\n        self.observers.append(callback)\n\n    def _notify_observers(self, controller_type: str, updates: Dict[str, Any]):\n        \"\"\"Notify observers of configuration changes.\"\"\"\n        for observer in self.observers:\n            try:\n                observer(controller_type, updates)\n            except Exception as e:\n                print(f\"Observer notification failed: {e}\")\n\n    def save_config(self):\n        \"\"\"Save current configuration to file.\"\"\"\n        import yaml\n\n        # Convert config to dictionary\n        config_dict = self.config.model_dump() if hasattr(self.config, 'model_dump') else vars(self.config)\n\n        with open(self.config_file, 'w') as f:\n            yaml.dump(config_dict, f, default_flow_style=False)\n\n# Usage\nconfig_manager = DynamicConfigurationManager()\n\n# Update configuration\nconfig_manager.update_controller_config(\n    'classical_smc',\n    gains=[22, 16, 14, 9, 38, 5.5],\n    max_force=160.0\n)\n\n# Get updated controller\ncontroller = config_manager.get_controller('classical_smc')\n\n# Register change observer\ndef config_change_handler(controller_type, updates):\n    print(f\"Configuration updated for {controller_type}: {updates}\")\n\nconfig_manager.register_observer(config_change_handler)",
    "lines": 81,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed29aa0b"
  },
  {
    "id": "configuration_integration_documentation_14_bc41e7a8",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationValidator:\n    \"\"\"Comprehensive configuration validation system.\"\"\"\n\n    def __init__(self):\n        self.validation_rules = self._initialize_validation_rules()\n        self.validation_errors = []\n        self.validation_warnings = []\n\n    def _initialize_validation_rules(self):\n        \"\"\"Initialize controller-specific validation rules.\"\"\"\n        return {\n            'classical_smc': self._validate_classical_smc,\n            'adaptive_smc': self._validate_adaptive_smc,\n            'sta_smc': self._validate_sta_smc,\n            'hybrid_adaptive_sta_smc': self._validate_hybrid_smc,\n            'mpc_controller': self._validate_mpc\n        }\n\n    def validate_configuration(self, controller_type: str, config: Dict[str, Any]) -> bool:\n        \"\"\"Validate configuration for specific controller type.\"\"\"\n\n        self.validation_errors.clear()\n        self.validation_warnings.clear()\n\n        try:\n            # Basic validation\n            self._validate_basic_structure(config)\n\n            # Controller-specific validation\n            if controller_type in self.validation_rules:\n                self.validation_rules[controller_type](config)\n            else:\n                self.validation_warnings.append(f\"No specific validation rules for {controller_type}\")\n\n            # Cross-parameter validation\n            self._validate_cross_parameters(config)\n\n            return len(self.validation_errors) == 0\n\n        except Exception as e:\n            self.validation_errors.append(f\"Validation failed: {e}\")\n            return False\n\n    def _validate_basic_structure(self, config: Dict[str, Any]):\n        \"\"\"Validate basic configuration structure.\"\"\"\n\n        required_fields = ['gains', 'max_force', 'dt']\n        for field in required_fields:\n            if field not in config:\n                self.validation_errors.append(f\"Missing required field: {field}\")\n\n    def _validate_classical_smc(self, config: Dict[str, Any]):\n        \"\"\"Validate Classical SMC configuration.\"\"\"\n\n        gains = config.get('gains', [])\n\n        # Gain count validation\n        if len(gains) != 6:\n            self.validation_errors.append(\"Classical SMC requires 6 gains\")\n            return\n\n        k1, k2, lam1, lam2, K, kd = gains\n\n        # Positivity constraints\n        if not all(g > 0 for g in gains):\n            self.validation_errors.append(\"All gains must be positive\")\n\n        # Stability constraints\n        if lam1 <= 0 or lam2 <= 0:\n            self.validation_errors.append(\"Surface coefficients \u03bb1, \u03bb2 must be positive\")\n\n        # Practical constraints\n        if K > 200:\n            self.validation_warnings.append(\"High switching gain K may cause chattering\")\n\n        if lam1/k1 > 50 or lam2/k2 > 50:\n            self.validation_warnings.append(\"High surface coefficient ratios\")\n\n        # Boundary layer validation\n        boundary_layer = config.get('boundary_layer', 0)\n        if boundary_layer <= 0:\n            self.validation_errors.append(\"Boundary layer must be positive\")\n\n        if boundary_layer > 0.1:\n            self.validation_warnings.append(\"Large boundary layer may reduce tracking accuracy\")\n\n    def _validate_adaptive_smc(self, config: Dict[str, Any]):\n        \"\"\"Validate Adaptive SMC configuration.\"\"\"\n\n        gains = config.get('gains', [])\n\n        # Gain count validation\n        if len(gains) != 5:\n            self.validation_errors.append(\"Adaptive SMC requires 5 gains\")\n            return\n\n        k1, k2, lam1, lam2, gamma = gains\n\n        # Adaptation rate validation\n        if gamma <= 0:\n            self.validation_errors.append(\"Adaptation rate \u03b3 must be positive\")\n\n        if gamma > 50:\n            self.validation_warnings.append(\"High adaptation rate may cause instability\")\n\n        # Leak rate validation\n        leak_rate = config.get('leak_rate', 0.01)\n        if not 0 < leak_rate < 1:\n            self.validation_errors.append(\"Leak rate must be in (0, 1)\")\n\n        # Dead zone validation\n        dead_zone = config.get('dead_zone', 0.05)\n        if dead_zone <= 0:\n            self.validation_errors.append(\"Dead zone must be positive\")\n\n        # Adaptive gain bounds\n        K_min = config.get('K_min', 0.1)\n        K_max = config.get('K_max', 100.0)\n        K_init = config.get('K_init', 10.0)\n\n        if not 0 < K_min < K_max:\n            self.validation_errors.append(\"Must have 0 < K_min < K_max\")\n\n        if not K_min <= K_init <= K_max:\n            self.validation_errors.append(\"K_init must be in [K_min, K_max]\")\n\n    def _validate_sta_smc(self, config: Dict[str, Any]):\n        \"\"\"Validate Super-Twisting SMC configuration.\"\"\"\n\n        gains = config.get('gains', [])\n\n        if len(gains) != 6:\n            self.validation_errors.append(\"Super-twisting SMC requires 6 gains\")\n            return\n\n        K1, K2, k1, k2, lam1, lam2 = gains\n\n        # Algorithmic gains\n        if K1 <= 0 or K2 <= 0:\n            self.validation_errors.append(\"Algorithmic gains K1, K2 must be positive\")\n\n        # Convergence conditions\n        if K2 > 2 * K1:\n            self.validation_warnings.append(\"K2 > 2*K1 may cause oscillations\")\n\n        if K1 < max(k1, k2):\n            self.validation_warnings.append(\"K1 < max(k1,k2) may not achieve finite-time convergence\")\n\n        # Power exponent\n        power_exponent = config.get('power_exponent', 0.5)\n        if not 0 < power_exponent < 1:\n            self.validation_errors.append(\"Power exponent must be in (0, 1)\")\n\n    def _validate_hybrid_smc(self, config: Dict[str, Any]):\n        \"\"\"Validate Hybrid SMC configuration.\"\"\"\n\n        gains = config.get('gains', [])\n\n        if len(gains) != 4:\n            self.validation_errors.append(\"Hybrid SMC requires 4 gains\")\n\n        # Check sub-configurations\n        classical_config = config.get('classical_config')\n        adaptive_config = config.get('adaptive_config')\n\n        if classical_config is None:\n            self.validation_errors.append(\"Missing classical_config for hybrid controller\")\n        else:\n            self._validate_classical_smc(classical_config)\n\n        if adaptive_config is None:\n            self.validation_errors.append(\"Missing adaptive_config for hybrid controller\")\n        else:\n            self._validate_adaptive_smc(adaptive_config)\n\n        # Hybrid mode validation\n        hybrid_mode = config.get('hybrid_mode', 'classical_adaptive')\n        valid_modes = ['classical_adaptive', 'sta_adaptive', 'dynamic_switching']\n\n        if hybrid_mode not in valid_modes:\n            self.validation_errors.append(f\"Invalid hybrid_mode: {hybrid_mode}\")\n\n    def _validate_mpc(self, config: Dict[str, Any]):\n        \"\"\"Validate MPC configuration.\"\"\"\n\n        # Horizon validation\n        horizon = config.get('horizon', 10)\n        if not isinstance(horizon, int) or horizon < 1:\n            self.validation_errors.append(\"Horizon must be positive integer\")\n\n        if horizon > 50:\n            self.validation_warnings.append(\"Large horizon may cause computational issues\")\n\n        # Weight validation\n        weights = ['q_x', 'q_theta', 'r_u']\n        for weight in weights:\n            value = config.get(weight, 1.0)\n            if not isinstance(value, (int, float)) or value < 0:\n                self.validation_errors.append(f\"{weight} must be non-negative number\")\n\n    def _validate_cross_parameters(self, config: Dict[str, Any]):\n        \"\"\"Validate relationships between parameters.\"\"\"\n\n        max_force = config.get('max_force', 150.0)\n        dt = config.get('dt', 0.001)\n\n        # Timestep validation\n        if dt > 0.01:\n            self.validation_warnings.append(\"Large timestep (>0.01s) may cause numerical issues\")\n\n        if dt < 1e-5:\n            self.validation_warnings.append(\"Very small timestep may be computationally expensive\")\n\n        # Force limits\n        if max_force > 500:\n            self.validation_warnings.append(\"Very high force limit may be unrealistic\")\n\n        if max_force < 10:\n            self.validation_warnings.append(\"Low force limit may prevent effective control\")\n\n    def get_validation_report(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive validation report.\"\"\"\n        return {\n            'valid': len(self.validation_errors) == 0,\n            'errors': self.validation_errors.copy(),\n            'warnings': self.validation_warnings.copy(),\n            'error_count': len(self.validation_errors),\n            'warning_count': len(self.validation_warnings)\n        }\n\n# Usage\nvalidator = ConfigurationValidator()\n\n# Validate configuration\nconfig = {\n    'gains': [20, 15, 12, 8, 35, 5],\n    'max_force': 150.0,\n    'boundary_layer': 0.02,\n    'dt': 0.001\n}\n\nis_valid = validator.validate_configuration('classical_smc', config)\nreport = validator.get_validation_report()\n\nif not is_valid:\n    print(\"Configuration validation failed:\")\n    for error in report['errors']:\n        print(f\"  \u274c {error}\")\n\nif report['warnings']:\n    print(\"Configuration warnings:\")\n    for warning in report['warnings']:\n        print(f\"  \u26a0\ufe0f  {warning}\")",
    "lines": 256,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc41e7a8"
  },
  {
    "id": "configuration_integration_documentation_15_cebfa806",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 15,
    "code": "import os\nfrom typing import Dict, Any, Optional\n\nclass EnvironmentConfigurationManager:\n    \"\"\"Manage environment-based configuration overrides.\"\"\"\n\n    def __init__(self, base_config_file: str = \"config.yaml\"):\n        self.base_config = self._load_base_config(base_config_file)\n        self.environment = os.getenv('DIP_ENV', 'development')\n        self.env_overrides = self._load_environment_overrides()\n\n    def _load_base_config(self, config_file: str):\n        \"\"\"Load base configuration.\"\"\"\n        from src.config import load_config\n        return load_config(config_file)\n\n    def _load_environment_overrides(self) -> Dict[str, Any]:\n        \"\"\"Load environment-specific overrides.\"\"\"\n\n        env_configs = {\n            'development': {\n                'simulation': {'duration': 2.0},  # Shorter for testing\n                'logging': {'level': 'DEBUG'},\n                'pso': {'n_particles': 10, 'max_iter': 20}  # Faster optimization\n            },\n            'testing': {\n                'simulation': {'duration': 1.0, 'dt': 0.01},  # Fast testing\n                'logging': {'level': 'WARNING'},\n                'controllers': {\n                    'classical_smc': {'gains': [10, 8, 6, 4, 20, 2]}  # Conservative gains\n                }\n            },\n            'production': {\n                'logging': {'level': 'INFO'},\n                'monitoring': {'performance_tracking': True},\n                'pso': {'n_particles': 50, 'max_iter': 200}  # Thorough optimization\n            },\n            'hil': {\n                'hil': {'enabled': True},\n                'simulation': {'dt': 0.001},  # High precision for HIL\n                'controllers': {\n                    'classical_smc': {'dt': 0.001}  # Match simulation timestep\n                }\n            }\n        }\n\n        return env_configs.get(self.environment, {})\n\n    def get_merged_config(self) -> Any:\n        \"\"\"Get configuration with environment overrides applied.\"\"\"\n\n        merged_config = self._deep_merge(\n            self._config_to_dict(self.base_config),\n            self.env_overrides\n        )\n\n        # Apply environment variable overrides\n        env_var_overrides = self._extract_env_var_overrides()\n        if env_var_overrides:\n            merged_config = self._deep_merge(merged_config, env_var_overrides)\n\n        # Convert back to config object\n        return self._dict_to_config(merged_config)\n\n    def _extract_env_var_overrides(self) -> Dict[str, Any]:\n        \"\"\"Extract configuration overrides from environment variables.\"\"\"\n\n        overrides = {}\n\n        # Environment variable patterns:\n        # DIP_CONTROLLER_CLASSICAL_GAINS=20,15,12,8,35,5\n        # DIP_SIMULATION_DURATION=5.0\n        # DIP_PSO_N_PARTICLES=30\n\n        for key, value in os.environ.items():\n            if key.startswith('DIP_'):\n                # Parse nested key: DIP_CONTROLLER_CLASSICAL_GAINS -> controllers.classical_smc.gains\n                parts = key[4:].lower().split('_')  # Remove 'DIP_' prefix\n\n                if len(parts) >= 2:\n                    config_dict = overrides\n\n                    # Navigate/create nested structure\n                    for part in parts[:-1]:\n                        if part not in config_dict:\n                            config_dict[part] = {}\n                        config_dict = config_dict[part]\n\n                    # Set value with type conversion\n                    final_key = parts[-1]\n                    config_dict[final_key] = self._convert_env_value(value)\n\n        return overrides\n\n    def _convert_env_value(self, value: str) -> Any:\n        \"\"\"Convert environment variable string to appropriate type.\"\"\"\n\n        # Boolean conversion\n        if value.lower() in ('true', 'false'):\n            return value.lower() == 'true'\n\n        # List conversion (comma-separated)\n        if ',' in value:\n            try:\n                return [float(x.strip()) for x in value.split(',')]\n            except ValueError:\n                return [x.strip() for x in value.split(',')]\n\n        # Numeric conversion\n        try:\n            if '.' in value:\n                return float(value)\n            else:\n                return int(value)\n        except ValueError:\n            pass\n\n        # String value\n        return value\n\n    def _deep_merge(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Deep merge two dictionaries.\"\"\"\n\n        result = base.copy()\n\n        for key, value in override.items():\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                result[key] = self._deep_merge(result[key], value)\n            else:\n                result[key] = value\n\n        return result\n\n    def _config_to_dict(self, config: Any) -> Dict[str, Any]:\n        \"\"\"Convert configuration object to dictionary.\"\"\"\n\n        if hasattr(config, 'model_dump'):\n            return config.model_dump()\n        elif hasattr(config, '__dict__'):\n            return vars(config)\n        else:\n            return config\n\n    def _dict_to_config(self, config_dict: Dict[str, Any]) -> Any:\n        \"\"\"Convert dictionary back to configuration object.\"\"\"\n\n        # Create a simple namespace object\n        class ConfigNamespace:\n            def __init__(self, **kwargs):\n                for key, value in kwargs.items():\n                    if isinstance(value, dict):\n                        setattr(self, key, ConfigNamespace(**value))\n                    else:\n                        setattr(self, key, value)\n\n        return ConfigNamespace(**config_dict)\n\n# Usage\nenv_manager = EnvironmentConfigurationManager()\n\n# Set environment\nos.environ['DIP_ENV'] = 'production'\nos.environ['DIP_PSO_N_PARTICLES'] = '40'\nos.environ['DIP_CONTROLLER_CLASSICAL_GAINS'] = '22,16,14,9,38,5.5'\n\n# Get merged configuration\nconfig = env_manager.get_merged_config()\n\n# Use with factory\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 170,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cebfa806"
  },
  {
    "id": "configuration_integration_documentation_16_365bb6b1",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 16,
    "code": "from jinja2 import Template\nimport yaml\nfrom typing import Dict, Any\n\nclass ConfigurationTemplateManager:\n    \"\"\"Manage configuration templates with parameter substitution.\"\"\"\n\n    def __init__(self):\n        self.templates = self._load_templates()\n        self.parameter_sets = self._load_parameter_sets()\n\n    def _load_templates(self) -> Dict[str, Template]:\n        \"\"\"Load configuration templates.\"\"\"\n\n        templates = {}\n\n        # Base controller template\n        templates['controller_template'] = Template(\"\"\"\ncontrollers:\n  {{ controller_type }}:\n    gains: {{ gains }}\n    max_force: {{ max_force | default(150.0) }}\n    dt: {{ dt | default(0.001) }}\n    {% if controller_type == 'classical_smc' %}\n    boundary_layer: {{ boundary_layer | default(0.02) }}\n    switch_method: \"{{ switch_method | default('tanh') }}\"\n    {% elif controller_type == 'adaptive_smc' %}\n    leak_rate: {{ leak_rate | default(0.01) }}\n    dead_zone: {{ dead_zone | default(0.05) }}\n    K_min: {{ K_min | default(0.1) }}\n    K_max: {{ K_max | default(100.0) }}\n    {% elif controller_type == 'sta_smc' %}\n    power_exponent: {{ power_exponent | default(0.5) }}\n    regularization: {{ regularization | default(1e-6) }}\n    {% endif %}\n        \"\"\")\n\n        # PSO template\n        templates['pso_template'] = Template(\"\"\"\npso:\n  n_particles: {{ n_particles | default(30) }}\n  max_iter: {{ max_iter | default(100) }}\n  w: {{ inertia_weight | default(0.9) }}\n  c1: {{ cognitive_coeff | default(2.0) }}\n  c2: {{ social_coeff | default(2.0) }}\n  bounds:\n    {{ controller_type }}:\n      lower: {{ lower_bounds }}\n      upper: {{ upper_bounds }}\n        \"\"\")\n\n        # Complete system template\n        templates['system_template'] = Template(\"\"\"\n# Generated configuration for {{ system_name }}\nglobal_seed: {{ seed | default(42) }}\n\nphysics:\n  m1: {{ physics.m1 | default(0.5) }}\n  m2: {{ physics.m2 | default(0.5) }}\n  M: {{ physics.M | default(2.0) }}\n  l1: {{ physics.l1 | default(0.5) }}\n  l2: {{ physics.l2 | default(0.5) }}\n  b1: {{ physics.b1 | default(0.1) }}\n  b2: {{ physics.b2 | default(0.1) }}\n  I1: {{ physics.I1 | default(0.1) }}\n  I2: {{ physics.I2 | default(0.1) }}\n\nsimulation:\n  duration: {{ simulation.duration | default(5.0) }}\n  dt: {{ simulation.dt | default(0.001) }}\n  initial_state: {{ simulation.initial_state | default([0.1, 0.05, 0.0, 0.0, 0.0, 0.0]) }}\n  use_full_dynamics: {{ simulation.use_full_dynamics | default(false) }}\n\n{{ controller_config }}\n\n{{ pso_config }}\n\ncost_function:\n  weights:\n    ise: {{ cost_weights.ise | default(0.4) }}\n    control_effort: {{ cost_weights.control_effort | default(0.3) }}\n    settling_time: {{ cost_weights.settling_time | default(0.2) }}\n    overshoot: {{ cost_weights.overshoot | default(0.1) }}\n        \"\"\")\n\n        return templates\n\n    def _load_parameter_sets(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Load predefined parameter sets.\"\"\"\n\n        return {\n            'conservative': {\n                'gains': {\n                    'classical_smc': [15, 10, 8, 5, 25, 3],\n                    'adaptive_smc': [18, 12, 10, 6, 2.5],\n                    'sta_smc': [20, 12, 15, 8, 6, 4]\n                },\n                'max_force': 100.0,\n                'boundary_layer': 0.03,\n                'pso': {'n_particles': 20, 'max_iter': 50}\n            },\n            'aggressive': {\n                'gains': {\n                    'classical_smc': [30, 25, 20, 15, 60, 8],\n                    'adaptive_smc': [35, 28, 22, 18, 8.0],\n                    'sta_smc': [40, 25, 30, 20, 15, 10]\n                },\n                'max_force': 200.0,\n                'boundary_layer': 0.01,\n                'pso': {'n_particles': 50, 'max_iter': 150}\n            },\n            'research': {\n                'gains': {\n                    'classical_smc': [20, 15, 12, 8, 35, 5],\n                    'adaptive_smc': [25, 18, 15, 10, 4],\n                    'sta_smc': [25, 15, 20, 12, 8, 6]\n                },\n                'max_force': 150.0,\n                'boundary_layer': 0.02,\n                'pso': {'n_particles': 40, 'max_iter': 100}\n            }\n        }\n\n    def generate_configuration(self,\n                             controller_type: str,\n                             parameter_set: str = 'research',\n                             custom_params: Optional[Dict[str, Any]] = None,\n                             output_file: Optional[str] = None) -> str:\n        \"\"\"Generate configuration from template.\"\"\"\n\n        # Get base parameters\n        base_params = self.parameter_sets.get(parameter_set, self.parameter_sets['research'])\n\n        # Merge with custom parameters\n        if custom_params:\n            params = self._deep_merge(base_params, custom_params)\n        else:\n            params = base_params\n\n        # Get controller-specific gains\n        controller_gains = params['gains'].get(controller_type, [20, 15, 12, 8, 35, 5])\n\n        # Generate controller configuration\n        controller_template_params = {\n            'controller_type': controller_type,\n            'gains': controller_gains,\n            'max_force': params.get('max_force', 150.0),\n            'boundary_layer': params.get('boundary_layer', 0.02)\n        }\n\n        controller_config = self.templates['controller_template'].render(**controller_template_params)\n\n        # Generate PSO configuration\n        from src.controllers.factory import get_gain_bounds_for_pso, SMCType\n\n        try:\n            smc_type = getattr(SMCType, controller_type.upper().replace('_SMC', ''))\n            lower_bounds, upper_bounds = get_gain_bounds_for_pso(smc_type)\n        except:\n            lower_bounds = [1.0] * len(controller_gains)\n            upper_bounds = [50.0] * len(controller_gains)\n\n        pso_template_params = {\n            'controller_type': controller_type,\n            'n_particles': params.get('pso', {}).get('n_particles', 30),\n            'max_iter': params.get('pso', {}).get('max_iter', 100),\n            'lower_bounds': lower_bounds,\n            'upper_bounds': upper_bounds\n        }\n\n        pso_config = self.templates['pso_template'].render(**pso_template_params)\n\n        # Generate complete system configuration\n        system_template_params = {\n            'system_name': f\"{controller_type.upper()} Control System\",\n            'controller_config': controller_config,\n            'pso_config': pso_config,\n            'physics': params.get('physics', {}),\n            'simulation': params.get('simulation', {}),\n            'cost_weights': params.get('cost_weights', {})\n        }\n\n        system_config = self.templates['system_template'].render(**system_template_params)\n\n        # Save to file if requested\n        if output_file:\n            with open(output_file, 'w') as f:\n                f.write(system_config)\n\n        return system_config\n\n    def _deep_merge(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Deep merge dictionaries.\"\"\"\n        result = base.copy()\n        for key, value in override.items():\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                result[key] = self._deep_merge(result[key], value)\n            else:\n                result[key] = value\n        return result\n\n# Usage\ntemplate_manager = ConfigurationTemplateManager()\n\n# Generate conservative classical SMC configuration\nconfig_yaml = template_manager.generate_configuration(\n    controller_type='classical_smc',\n    parameter_set='conservative',\n    custom_params={\n        'physics': {'m1': 0.6, 'm2': 0.4},\n        'simulation': {'duration': 3.0}\n    },\n    output_file='conservative_classical_config.yaml'\n)\n\nprint(\"Generated configuration:\")\nprint(config_yaml)",
    "lines": 217,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "365bb6b1"
  },
  {
    "id": "configuration_integration_documentation_17_d89cab34",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationMigrationManager:\n    \"\"\"Handle configuration parameter migrations and deprecations.\"\"\"\n\n    def __init__(self):\n        self.migration_rules = self._initialize_migration_rules()\n        self.deprecation_warnings = []\n\n    def _initialize_migration_rules(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Initialize parameter migration rules.\"\"\"\n\n        return {\n            # Version 1.0 -> 2.0 migrations\n            'v1_to_v2': {\n                'parameter_mappings': {\n                    'use_equivalent': 'enable_equivalent_control',\n                    'k_gain': 'switching_gain',\n                    'lambda_gains': 'surface_gains',\n                    'sat_limit': 'max_force',\n                    'dt_control': 'dt',\n                    'boundary_thickness': 'boundary_layer'\n                },\n                'structure_changes': {\n                    'controllers': {\n                        'old_path': 'smc_configs',\n                        'new_path': 'controllers'\n                    }\n                },\n                'value_transformations': {\n                    'switching_gain': lambda x: max(x, 5.0),  # Ensure minimum value\n                    'boundary_layer': lambda x: min(x, 0.1)   # Ensure maximum value\n                }\n            },\n\n            # Version 2.0 -> 3.0 migrations\n            'v2_to_v3': {\n                'parameter_mappings': {\n                    'smc_classical': 'classical_smc',\n                    'smc_adaptive': 'adaptive_smc',\n                    'smc_sta': 'sta_smc'\n                },\n                'new_required_parameters': {\n                    'classical_smc': {\n                        'switch_method': 'tanh',\n                        'regularization': 1e-10\n                    },\n                    'adaptive_smc': {\n                        'smooth_switch': True,\n                        'alpha': 0.5\n                    }\n                }\n            }\n        }\n\n    def migrate_configuration(self, config: Dict[str, Any],\n                            from_version: str = 'v1',\n                            to_version: str = 'v3') -> Dict[str, Any]:\n        \"\"\"Migrate configuration between versions.\"\"\"\n\n        self.deprecation_warnings.clear()\n        migrated_config = config.copy()\n\n        # Apply migrations in sequence\n        if from_version == 'v1' and to_version in ['v2', 'v3']:\n            migrated_config = self._apply_migration(migrated_config, 'v1_to_v2')\n\n        if (from_version in ['v1', 'v2']) and to_version == 'v3':\n            migrated_config = self._apply_migration(migrated_config, 'v2_to_v3')\n\n        return migrated_config\n\n    def _apply_migration(self, config: Dict[str, Any], migration_key: str) -> Dict[str, Any]:\n        \"\"\"Apply specific migration rules.\"\"\"\n\n        rules = self.migration_rules[migration_key]\n        migrated = config.copy()\n\n        # Apply parameter mappings\n        if 'parameter_mappings' in rules:\n            migrated = self._apply_parameter_mappings(migrated, rules['parameter_mappings'])\n\n        # Apply structure changes\n        if 'structure_changes' in rules:\n            migrated = self._apply_structure_changes(migrated, rules['structure_changes'])\n\n        # Apply value transformations\n        if 'value_transformations' in rules:\n            migrated = self._apply_value_transformations(migrated, rules['value_transformations'])\n\n        # Add new required parameters\n        if 'new_required_parameters' in rules:\n            migrated = self._add_required_parameters(migrated, rules['new_required_parameters'])\n\n        return migrated\n\n    def _apply_parameter_mappings(self, config: Dict[str, Any],\n                                mappings: Dict[str, str]) -> Dict[str, Any]:\n        \"\"\"Apply parameter name mappings.\"\"\"\n\n        migrated = config.copy()\n\n        def migrate_nested(obj, path=\"\"):\n            if isinstance(obj, dict):\n                new_obj = {}\n                for key, value in obj.items():\n                    current_path = f\"{path}.{key}\" if path else key\n\n                    if key in mappings:\n                        new_key = mappings[key]\n                        new_obj[new_key] = migrate_nested(value, f\"{path}.{new_key}\" if path else new_key)\n                        self.deprecation_warnings.append(\n                            f\"Parameter '{key}' deprecated, migrated to '{new_key}'\"\n                        )\n                    else:\n                        new_obj[key] = migrate_nested(value, current_path)\n\n                return new_obj\n            else:\n                return obj\n\n        return migrate_nested(migrated)\n\n    def _apply_structure_changes(self, config: Dict[str, Any],\n                               changes: Dict[str, Dict[str, str]]) -> Dict[str, Any]:\n        \"\"\"Apply structural changes to configuration.\"\"\"\n\n        migrated = config.copy()\n\n        for change_name, change_rule in changes.items():\n            old_path = change_rule['old_path']\n            new_path = change_rule['new_path']\n\n            if old_path in migrated:\n                # Move data from old path to new path\n                migrated[new_path] = migrated.pop(old_path)\n                self.deprecation_warnings.append(\n                    f\"Configuration section '{old_path}' moved to '{new_path}'\"\n                )\n\n        return migrated\n\n    def _apply_value_transformations(self, config: Dict[str, Any],\n                                   transformations: Dict[str, callable]) -> Dict[str, Any]:\n        \"\"\"Apply value transformations.\"\"\"\n\n        def transform_nested(obj):\n            if isinstance(obj, dict):\n                new_obj = {}\n                for key, value in obj.items():\n                    if key in transformations:\n                        try:\n                            new_obj[key] = transformations[key](value)\n                            self.deprecation_warnings.append(\n                                f\"Value transformation applied to '{key}'\"\n                            )\n                        except Exception as e:\n                            new_obj[key] = value\n                            self.deprecation_warnings.append(\n                                f\"Value transformation failed for '{key}': {e}\"\n                            )\n                    else:\n                        new_obj[key] = transform_nested(value)\n                return new_obj\n            else:\n                return obj\n\n        return transform_nested(config)\n\n    def _add_required_parameters(self, config: Dict[str, Any],\n                               required_params: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Add new required parameters with default values.\"\"\"\n\n        migrated = config.copy()\n\n        # Ensure controllers section exists\n        if 'controllers' not in migrated:\n            migrated['controllers'] = {}\n\n        for controller_type, params in required_params.items():\n            if controller_type not in migrated['controllers']:\n                migrated['controllers'][controller_type] = {}\n\n            controller_config = migrated['controllers'][controller_type]\n\n            for param_name, default_value in params.items():\n                if param_name not in controller_config:\n                    controller_config[param_name] = default_value\n                    self.deprecation_warnings.append(\n                        f\"Added required parameter '{param_name}' to {controller_type}\"\n                    )\n\n        return migrated\n\n    def check_deprecated_config(self, controller_type: str,\n                              params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Check for and handle deprecated parameters.\"\"\"\n\n        # Current deprecation mappings\n        current_deprecations = {\n            'use_equivalent': 'enable_equivalent_control',\n            'k_gain': 'switching_gain',\n            'lambda_gains': 'surface_gains',\n            'sat_limit': 'max_force',\n            'boundary_thickness': 'boundary_layer'\n        }\n\n        migrated_params = params.copy()\n\n        for old_param, new_param in current_deprecations.items():\n            if old_param in migrated_params:\n                migrated_params[new_param] = migrated_params.pop(old_param)\n                self.deprecation_warnings.append(\n                    f\"Parameter '{old_param}' is deprecated. Use '{new_param}' instead.\"\n                )\n\n        return migrated_params\n\n    def get_deprecation_warnings(self) -> List[str]:\n        \"\"\"Get list of deprecation warnings.\"\"\"\n        return self.deprecation_warnings.copy()\n\n# Usage\nmigration_manager = ConfigurationMigrationManager()\n\n# Migrate old configuration\nold_config = {\n    'smc_configs': {\n        'smc_classical': {\n            'k_gain': 35.0,\n            'lambda_gains': [12.0, 8.0],\n            'sat_limit': 150.0,\n            'boundary_thickness': 0.02\n        }\n    }\n}\n\nmigrated_config = migration_manager.migrate_configuration(\n    old_config,\n    from_version='v1',\n    to_version='v3'\n)\n\nprint(\"Migrated configuration:\")\nprint(yaml.dump(migrated_config, default_flow_style=False))\n\nprint(\"\\nDeprecation warnings:\")\nfor warning in migration_manager.get_deprecation_warnings():\n    print(f\"  \u26a0\ufe0f  {warning}\")",
    "lines": 250,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d89cab34"
  },
  {
    "id": "configuration_integration_documentation_18_efc064e4",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 18,
    "code": "# \u2705 Good: Use type-safe configuration classes\n   @dataclass(frozen=True)\n   class ControllerConfig:\n       gains: List[float]\n       max_force: float\n\n   # \u274c Bad: Untyped dictionary configurations\n   config = {'gains': 'should be list', 'max_force': 'not a number'}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "efc064e4"
  },
  {
    "id": "configuration_integration_documentation_19_e3f5c5b0",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 19,
    "code": "# \u2705 Good: Multi-level validation\n   def validate_config(config):\n       # 1. Type validation\n       assert isinstance(config.gains, list)\n       # 2. Domain validation\n       assert all(g > 0 for g in config.gains)\n       # 3. Physics validation\n       assert config.max_force > max(config.gains)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3f5c5b0"
  },
  {
    "id": "configuration_integration_documentation_20_4f3c64e1",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 20,
    "code": "# \u2705 Good: Explicit priority handling\n   gains = (\n       explicit_gains or          # Priority 1\n       config_gains or           # Priority 2\n       registry_defaults         # Priority 3\n   )",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4f3c64e1"
  },
  {
    "id": "configuration_integration_documentation_21_4b9bd7b0",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 21,
    "code": "# \u2705 Good: Fallback mechanisms\n   try:\n       config = create_full_config(**params)\n   except ConfigError:\n       config = create_minimal_config(**essential_params)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b9bd7b0"
  },
  {
    "id": "configuration_integration_documentation_22_27a951a3",
    "file": "docs\\configuration_integration_documentation.md",
    "index": 22,
    "code": "#!/usr/bin/env python3\n\"\"\"Complete configuration integration example.\"\"\"\n\nimport yaml\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional\n\nclass ComprehensiveConfigurationExample:\n    \"\"\"Demonstrate comprehensive configuration integration.\"\"\"\n\n    def __init__(self):\n        self.config_manager = self._setup_configuration_manager()\n\n    def _setup_configuration_manager(self):\n        \"\"\"Setup configuration management system.\"\"\"\n\n        class ConfigManager:\n            def __init__(self):\n                self.base_config = self._load_base_config()\n                self.validator = ConfigurationValidator()\n                self.migrator = ConfigurationMigrationManager()\n\n            def _load_base_config(self):\n                \"\"\"Load base configuration.\"\"\"\n                config_path = Path(\"config.yaml\")\n                if config_path.exists():\n                    from src.config import load_config\n                    return load_config(config_path)\n                else:\n                    return self._create_default_config()\n\n            def _create_default_config(self):\n                \"\"\"Create default configuration.\"\"\"\n                return {\n                    'physics': {\n                        'm1': 0.5, 'm2': 0.5, 'M': 2.0,\n                        'l1': 0.5, 'l2': 0.5,\n                        'b1': 0.1, 'b2': 0.1,\n                        'I1': 0.1, 'I2': 0.1\n                    },\n                    'simulation': {\n                        'duration': 5.0,\n                        'dt': 0.001,\n                        'initial_state': [0.1, 0.05, 0.0, 0.0, 0.0, 0.0]\n                    },\n                    'controllers': {\n                        'classical_smc': {\n                            'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n                            'max_force': 150.0,\n                            'boundary_layer': 0.02,\n                            'dt': 0.001\n                        }\n                    }\n                }\n\n            def get_controller_config(self, controller_type: str, **overrides) -> Dict[str, Any]:\n                \"\"\"Get validated controller configuration.\"\"\"\n\n                # Get base configuration\n                base_controller_config = self.base_config['controllers'].get(controller_type, {})\n\n                # Apply overrides\n                controller_config = {**base_controller_config, **overrides}\n\n                # Migrate deprecated parameters\n                controller_config = self.migrator.check_deprecated_config(\n                    controller_type, controller_config\n                )\n\n                # Validate configuration\n                if not self.validator.validate_configuration(controller_type, controller_config):\n                    report = self.validator.get_validation_report()\n                    raise ValueError(f\"Configuration validation failed: {report['errors']}\")\n\n                return controller_config\n\n        return ConfigManager()\n\n    def demonstration_1_basic_usage(self):\n        \"\"\"Demonstrate basic configuration usage.\"\"\"\n\n        print(\"=== Demonstration 1: Basic Configuration Usage ===\")\n\n        # Get configuration for different controllers\n        for controller_type in ['classical_smc', 'adaptive_smc', 'sta_smc']:\n            try:\n                config = self.config_manager.get_controller_config(controller_type)\n                print(f\"\\n{controller_type.upper()} Configuration:\")\n                print(f\"  Gains: {config.get('gains', 'Not specified')}\")\n                print(f\"  Max Force: {config.get('max_force', 'Not specified')}\")\n                print(f\"  Timestep: {config.get('dt', 'Not specified')}\")\n\n                # Create controller with configuration\n                controller = create_controller(controller_type, **config)\n                print(f\"  \u2705 Controller created successfully\")\n\n            except Exception as e:\n                print(f\"  \u274c Failed to create {controller_type}: {e}\")\n\n    def demonstration_2_parameter_override(self):\n        \"\"\"Demonstrate parameter override patterns.\"\"\"\n\n        print(\"\\n=== Demonstration 2: Parameter Override Patterns ===\")\n\n        # Original configuration\n        print(\"Original gains:\", self.config_manager.base_config['controllers']['classical_smc']['gains'])\n\n        # Override with explicit parameters\n        config = self.config_manager.get_controller_config(\n            'classical_smc',\n            gains=[25, 20, 15, 10, 40, 6],\n            max_force=160.0\n        )\n        print(\"Overridden gains:\", config['gains'])\n        print(\"Overridden max_force:\", config['max_force'])\n\n        # Create controller with overrides\n        controller = create_controller('classical_smc', **config)\n        print(\"\u2705 Controller created with overrides\")\n\n    def demonstration_3_validation_and_migration(self):\n        \"\"\"Demonstrate validation and migration features.\"\"\"\n\n        print(\"\\n=== Demonstration 3: Validation and Migration ===\")\n\n        # Test deprecated parameter migration\n        old_config = {\n            'k_gain': 35.0,                    # Deprecated\n            'lambda_gains': [12.0, 8.0],       # Deprecated\n            'sat_limit': 150.0,                # Deprecated\n            'boundary_thickness': 0.02,        # Deprecated\n            'dt': 0.001\n        }\n\n        print(\"Old configuration (with deprecated parameters):\")\n        for key, value in old_config.items():\n            print(f\"  {key}: {value}\")\n\n        # Apply migration\n        migrated_config = self.config_manager.migrator.check_deprecated_config(\n            'classical_smc', old_config\n        )\n\n        print(\"\\nMigrated configuration:\")\n        for key, value in migrated_config.items():\n            print(f\"  {key}: {value}\")\n\n        print(\"\\nMigration warnings:\")\n        for warning in self.config_manager.migrator.get_deprecation_warnings():\n            print(f\"  \u26a0\ufe0f  {warning}\")\n\n    def demonstration_4_environment_configuration(self):\n        \"\"\"Demonstrate environment-based configuration.\"\"\"\n\n        print(\"\\n=== Demonstration 4: Environment Configuration ===\")\n\n        # Simulate different environments\n        environments = ['development', 'testing', 'production']\n\n        for env in environments:\n            print(f\"\\nEnvironment: {env}\")\n\n            # Environment-specific overrides\n            env_overrides = {\n                'development': {'gains': [15, 10, 8, 5, 25, 3]},      # Conservative\n                'testing': {'gains': [20, 15, 12, 8, 35, 5]},         # Standard\n                'production': {'gains': [25, 20, 15, 10, 45, 7]}      # Aggressive\n            }\n\n            config = self.config_manager.get_controller_config(\n                'classical_smc',\n                **env_overrides.get(env, {})\n            )\n\n            print(f\"  Gains: {config['gains']}\")\n\n            # Validate for specific environment\n            validator = ConfigurationValidator()\n            is_valid = validator.validate_configuration('classical_smc', config)\n\n            if is_valid:\n                print(f\"  \u2705 Configuration valid for {env}\")\n            else:\n                print(f\"  \u274c Configuration invalid for {env}\")\n                for error in validator.get_validation_report()['errors']:\n                    print(f\"    Error: {error}\")\n\n    def demonstration_5_pso_integration(self):\n        \"\"\"Demonstrate PSO integration with configuration.\"\"\"\n\n        print(\"\\n=== Demonstration 5: PSO Integration ===\")\n\n        # Create PSO-optimized configuration\n        base_config = self.config_manager.get_controller_config('classical_smc')\n\n        print(\"Base configuration for PSO:\")\n        print(f\"  Initial gains: {base_config['gains']}\")\n\n        # Create PSO factory with configuration\n        from src.controllers.factory import create_pso_controller_factory, SMCType\n\n        factory = create_pso_controller_factory(\n            SMCType.CLASSICAL,\n            **{k: v for k, v in base_config.items() if k != 'gains'}\n        )\n\n        print(f\"  PSO factory created: {factory.n_gains} gains required\")\n\n        # Simulate PSO optimization\n        import numpy as np\n\n        # Generate random gain variations\n        base_gains = np.array(base_config['gains'])\n\n        for i in range(3):\n            # Add random variation\n            variation = 0.1 * np.random.randn(len(base_gains))\n            test_gains = base_gains * (1 + variation)\n            test_gains = np.clip(test_gains, 0.1, 100.0)  # Keep positive\n\n            print(f\"\\n  PSO Iteration {i+1}:\")\n            print(f\"    Test gains: {test_gains.tolist()}\")\n\n            try:\n                controller = factory(test_gains)\n                print(f\"    \u2705 Controller created successfully\")\n\n                # Simulate fitness evaluation\n                fitness = np.sum(test_gains**2)  # Simple fitness function\n                print(f\"    Fitness: {fitness:.2f}\")\n\n            except Exception as e:\n                print(f\"    \u274c Controller creation failed: {e}\")\n\n    def run_all_demonstrations(self):\n        \"\"\"Run all configuration demonstrations.\"\"\"\n\n        print(\"Configuration Integration Demonstrations\")\n        print(\"=\" * 50)\n\n        try:\n            self.demonstration_1_basic_usage()\n            self.demonstration_2_parameter_override()\n            self.demonstration_3_validation_and_migration()\n            self.demonstration_4_environment_configuration()\n            self.demonstration_5_pso_integration()\n\n            print(\"\\n\" + \"=\" * 50)\n            print(\"All demonstrations completed successfully!\")\n\n        except Exception as e:\n            print(f\"\\nDemonstration failed: {e}\")\n            import traceback\n            traceback.print_exc()\n\n# Run demonstrations\nif __name__ == \"__main__\":\n    demo = ComprehensiveConfigurationExample()\n    demo.run_all_demonstrations()",
    "lines": 259,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27a951a3"
  },
  {
    "id": "configuration_schema_validation_1_6abd46ef",
    "file": "docs\\configuration_schema_validation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom pydantic import BaseModel, Field, validator\nfrom typing import List, Optional, Union\nimport numpy as np\n\nclass SystemConfig(BaseModel):\n    \"\"\"System-level configuration schema.\"\"\"\n    version: str = Field(..., regex=r\"^\\d+\\.\\d+\\.\\d+$\", description=\"Semantic version\")\n    environment: str = Field(..., regex=r\"^(development|testing|staging|production)$\")\n    logging_level: str = Field(\"INFO\", regex=r\"^(DEBUG|INFO|WARNING|ERROR|CRITICAL)$\")\n\n    @validator('version')\n    def validate_version_compatibility(cls, v):\n        \"\"\"Validate version compatibility.\"\"\"\n        major, minor, patch = map(int, v.split('.'))\n        if major < 2:\n            raise ValueError(\"Version 2.0+ required for production deployment\")\n        return v",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6abd46ef"
  },
  {
    "id": "configuration_schema_validation_2_dfa8672c",
    "file": "docs\\configuration_schema_validation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass PhysicsConfig(BaseModel):\n    \"\"\"Physical system parameters schema.\"\"\"\n    pendulum_length_1: float = Field(..., gt=0.1, le=2.0, description=\"Pendulum 1 length (m)\")\n    pendulum_length_2: float = Field(..., gt=0.1, le=2.0, description=\"Pendulum 2 length (m)\")\n    pendulum_mass_1: float = Field(..., gt=0.01, le=10.0, description=\"Pendulum 1 mass (kg)\")\n    pendulum_mass_2: float = Field(..., gt=0.01, le=10.0, description=\"Pendulum 2 mass (kg)\")\n    cart_mass: float = Field(..., gt=0.1, le=50.0, description=\"Cart mass (kg)\")\n    gravity: float = Field(9.81, gt=0.1, le=20.0, description=\"Gravitational acceleration (m/s\u00b2)\")\n\n    @validator('pendulum_length_2')\n    def validate_length_ratio(cls, v, values):\n        \"\"\"Validate pendulum length ratio for stability.\"\"\"\n        if 'pendulum_length_1' in values:\n            ratio = v / values['pendulum_length_1']\n            if not 0.3 <= ratio <= 2.0:\n                raise ValueError(\"Pendulum length ratio must be between 0.3 and 2.0\")\n        return v\n\n    @validator('pendulum_mass_2')\n    def validate_mass_ratio(cls, v, values):\n        \"\"\"Validate pendulum mass ratio for dynamic coupling.\"\"\"\n        if 'pendulum_mass_1' in values:\n            ratio = v / values['pendulum_mass_1']\n            if not 0.1 <= ratio <= 5.0:\n                raise ValueError(\"Pendulum mass ratio must be between 0.1 and 5.0\")\n        return v",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dfa8672c"
  },
  {
    "id": "configuration_schema_validation_3_da5836ad",
    "file": "docs\\configuration_schema_validation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ClassicalSMCConfig(BaseModel):\n    \"\"\"Classical SMC controller configuration schema.\"\"\"\n    gains: List[float] = Field(..., min_items=6, max_items=6, description=\"SMC gains [\u03bb\u2081, \u03bb\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\")\n    saturation_limit: float = Field(..., gt=0.1, le=100.0, description=\"Control saturation limit\")\n    boundary_layer_thickness: float = Field(0.01, gt=0.001, le=1.0, description=\"Boundary layer thickness\")\n\n    @validator('gains')\n    def validate_smc_gains(cls, v):\n        \"\"\"Validate SMC gain constraints for stability.\"\"\"\n        lambda1, lambda2, x_gain, theta1_dot_gain, theta2_dot_gain, x_dot_gain = v\n\n        # Sliding surface gains must be positive\n        if lambda1 <= 0 or lambda2 <= 0:\n            raise ValueError(\"Sliding surface gains \u03bb\u2081, \u03bb\u2082 must be positive\")\n\n        # Stability margin requirements\n        if lambda1 < 0.5 or lambda1 > 50.0:\n            raise ValueError(\"\u03bb\u2081 must be in range [0.5, 50.0] for stability\")\n\n        if lambda2 < 0.5 or lambda2 > 50.0:\n            raise ValueError(\"\u03bb\u2082 must be in range [0.5, 50.0] for stability\")\n\n        # Gain ratios for balanced control\n        ratio_lambda = lambda1 / lambda2\n        if not 0.2 <= ratio_lambda <= 5.0:\n            raise ValueError(\"\u03bb\u2081/\u03bb\u2082 ratio must be in range [0.2, 5.0]\")\n\n        return v\n\n    @validator('saturation_limit')\n    def validate_saturation_safety(cls, v, values):\n        \"\"\"Validate saturation limit for hardware safety.\"\"\"\n        if v > 50.0:\n            raise ValueError(\"Saturation limit exceeds hardware safety threshold\")\n        return v\n\nclass STASMCConfig(BaseModel):\n    \"\"\"Super-Twisting Algorithm SMC configuration schema.\"\"\"\n    alpha1: float = Field(..., gt=0.1, le=20.0, description=\"STA parameter \u03b1\u2081\")\n    alpha2: float = Field(..., gt=0.1, le=20.0, description=\"STA parameter \u03b1\u2082\")\n    saturation_limit: float = Field(..., gt=0.1, le=100.0, description=\"Control saturation limit\")\n\n    @validator('alpha2')\n    def validate_sta_stability_condition(cls, v, values):\n        \"\"\"Validate STA stability conditions.\"\"\"\n        if 'alpha1' in values:\n            alpha1 = values['alpha1']\n\n            # Stability condition: \u03b1\u2082 > \u03b1\u2081\u00b2/4\n            if v <= alpha1**2 / 4:\n                raise ValueError(f\"STA stability requires \u03b1\u2082 > \u03b1\u2081\u00b2/4, got \u03b1\u2082={v}, \u03b1\u2081\u00b2/4={alpha1**2/4}\")\n\n            # Convergence condition\n            if alpha1 > 2 * np.sqrt(v):\n                raise ValueError(\"STA convergence condition violated: \u03b1\u2081 \u2264 2\u221a\u03b1\u2082\")\n\n        return v\n\nclass AdaptiveSMCConfig(BaseModel):\n    \"\"\"Adaptive SMC configuration schema.\"\"\"\n    initial_gains: List[float] = Field(..., min_items=6, max_items=6, description=\"Initial parameter estimates\")\n    adaptation_rate: float = Field(..., gt=0.001, le=10.0, description=\"Parameter adaptation rate \u03b3\")\n    parameter_bounds: List[float] = Field(..., min_items=2, max_items=2, description=\"[min, max] parameter bounds\")\n\n    @validator('parameter_bounds')\n    def validate_parameter_bounds(cls, v):\n        \"\"\"Validate parameter bound constraints.\"\"\"\n        min_bound, max_bound = v\n\n        if min_bound <= 0:\n            raise ValueError(\"Minimum parameter bound must be positive\")\n\n        if max_bound <= min_bound:\n            raise ValueError(\"Maximum bound must be greater than minimum bound\")\n\n        if max_bound / min_bound > 1000:\n            raise ValueError(\"Parameter bound ratio exceeds numerical stability limit\")\n\n        return v\n\n    @validator('initial_gains')\n    def validate_initial_gains_bounds(cls, v, values):\n        \"\"\"Validate initial gains within parameter bounds.\"\"\"\n        if 'parameter_bounds' in values:\n            min_bound, max_bound = values['parameter_bounds']\n            for gain in v:\n                if not min_bound <= gain <= max_bound:\n                    raise ValueError(f\"Initial gain {gain} outside bounds [{min_bound}, {max_bound}]\")\n        return v",
    "lines": 92,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da5836ad"
  },
  {
    "id": "configuration_schema_validation_4_8728ad2e",
    "file": "docs\\configuration_schema_validation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOConfig(BaseModel):\n    \"\"\"PSO optimization configuration schema.\"\"\"\n    n_particles: int = Field(..., ge=10, le=200, description=\"Number of particles in swarm\")\n    max_iterations: int = Field(..., ge=10, le=1000, description=\"Maximum optimization iterations\")\n    w: float = Field(..., gt=0.1, lt=1.0, description=\"Inertia weight\")\n    c1: float = Field(..., gt=0.0, le=4.0, description=\"Cognitive acceleration coefficient\")\n    c2: float = Field(..., gt=0.0, le=4.0, description=\"Social acceleration coefficient\")\n    bounds: dict = Field(..., description=\"Parameter bounds for each controller type\")\n\n    @validator('c1', 'c2')\n    def validate_acceleration_coefficients(cls, v, values, field):\n        \"\"\"Validate PSO acceleration coefficient constraints.\"\"\"\n        # Get both c1 and c2 if available\n        c1 = values.get('c1', v if field.name == 'c1' else None)\n        c2 = values.get('c2', v if field.name == 'c2' else None)\n\n        if c1 is not None and c2 is not None:\n            # Stability condition: c1 + c2 > 4 for constriction factor\n            if c1 + c2 <= 4.0:\n                raise ValueError(\"PSO stability requires c\u2081 + c\u2082 > 4\")\n\n            # Balance condition for exploration vs exploitation\n            ratio = c1 / c2 if c2 > 0 else float('inf')\n            if not 0.2 <= ratio <= 5.0:\n                raise ValueError(\"c\u2081/c\u2082 ratio should be in range [0.2, 5.0] for balanced search\")\n\n        return v\n\n    @validator('w')\n    def validate_inertia_weight(cls, v, values):\n        \"\"\"Validate inertia weight for convergence.\"\"\"\n        # Linear decreasing inertia weight strategy\n        if v < 0.4:\n            raise ValueError(\"Inertia weight too low, may cause premature convergence\")\n        if v >= 0.9:\n            raise ValueError(\"Inertia weight too high, may prevent convergence\")\n        return v\n\n    @validator('bounds')\n    def validate_optimization_bounds(cls, v):\n        \"\"\"Validate optimization bounds for each controller.\"\"\"\n        required_controllers = ['classical_smc', 'sta_smc', 'adaptive_smc']\n\n        for controller in required_controllers:\n            if controller not in v:\n                raise ValueError(f\"Missing optimization bounds for controller: {controller}\")\n\n            bounds = v[controller]\n            if not isinstance(bounds, list):\n                raise ValueError(f\"Bounds for {controller} must be a list\")\n\n            # Validate bound structure\n            for i, bound_pair in enumerate(bounds):\n                if len(bound_pair) != 2:\n                    raise ValueError(f\"Bound {i} for {controller} must have [min, max] format\")\n\n                min_val, max_val = bound_pair\n                if min_val >= max_val:\n                    raise ValueError(f\"Invalid bound {i} for {controller}: min >= max\")\n\n                if min_val <= 0:\n                    raise ValueError(f\"Bound {i} minimum for {controller} must be positive\")\n\n        return v",
    "lines": 67,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8728ad2e"
  },
  {
    "id": "configuration_schema_validation_5_3ca90ca1",
    "file": "docs\\configuration_schema_validation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimulationConfig(BaseModel):\n    \"\"\"Simulation configuration schema.\"\"\"\n    dt: float = Field(..., gt=0.0001, le=0.1, description=\"Integration time step (s)\")\n    duration: float = Field(..., gt=0.1, le=3600.0, description=\"Simulation duration (s)\")\n    initial_state: List[float] = Field(..., min_items=6, max_items=6, description=\"Initial system state\")\n    target_state: List[float] = Field(..., min_items=6, max_items=6, description=\"Target system state\")\n\n    @validator('dt')\n    def validate_sampling_time(cls, v):\n        \"\"\"Validate sampling time for numerical stability.\"\"\"\n        # Nyquist criterion for control systems\n        max_frequency = 100  # Hz, typical control bandwidth\n        min_dt = 1 / (10 * max_frequency)  # 10x oversampling\n\n        if v > 1 / (2 * max_frequency):\n            raise ValueError(f\"Sampling time {v}s violates Nyquist criterion\")\n\n        if v < min_dt:\n            raise ValueError(f\"Sampling time {v}s too small, computational overhead\")\n\n        return v\n\n    @validator('initial_state', 'target_state')\n    def validate_state_vectors(cls, v, field):\n        \"\"\"Validate state vector constraints.\"\"\"\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = v\n\n        # Position constraints\n        if not -np.pi <= theta1 <= np.pi:\n            raise ValueError(f\"\u03b8\u2081 must be in range [-\u03c0, \u03c0], got {theta1}\")\n\n        if not -np.pi <= theta2 <= np.pi:\n            raise ValueError(f\"\u03b8\u2082 must be in range [-\u03c0, \u03c0], got {theta2}\")\n\n        if not -10.0 <= x <= 10.0:\n            raise ValueError(f\"Cart position must be in range [-10, 10]m, got {x}\")\n\n        # Velocity constraints (safety limits)\n        if abs(theta1_dot) > 50.0:\n            raise ValueError(f\"\u03b8\u0307\u2081 exceeds safety limit: {theta1_dot}\")\n\n        if abs(theta2_dot) > 50.0:\n            raise ValueError(f\"\u03b8\u0307\u2082 exceeds safety limit: {theta2_dot}\")\n\n        if abs(x_dot) > 20.0:\n            raise ValueError(f\"Cart velocity exceeds safety limit: {x_dot}\")\n\n        return v\n\n    @validator('duration')\n    def validate_simulation_duration(cls, v, values):\n        \"\"\"Validate simulation duration constraints.\"\"\"\n        if 'dt' in values:\n            dt = values['dt']\n            num_steps = int(v / dt)\n\n            if num_steps > 1000000:  # 1M steps\n                raise ValueError(\"Simulation too long, may cause memory issues\")\n\n            if num_steps < 10:\n                raise ValueError(\"Simulation too short for meaningful results\")\n\n        return v",
    "lines": 66,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ca90ca1"
  },
  {
    "id": "configuration_schema_validation_6_741ca79c",
    "file": "docs\\configuration_schema_validation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass HILConfig(BaseModel):\n    \"\"\"Hardware-in-the-loop configuration schema.\"\"\"\n    enabled: bool = Field(False, description=\"Enable HIL communication\")\n    plant_address: str = Field(..., description=\"Plant server IP address\")\n    plant_port: int = Field(..., ge=1024, le=65535, description=\"Plant server port\")\n    controller_port: int = Field(..., ge=1024, le=65535, description=\"Controller client port\")\n    timeout: float = Field(..., gt=0.1, le=10.0, description=\"Communication timeout (s)\")\n\n    @validator('plant_address')\n    def validate_ip_address(cls, v):\n        \"\"\"Validate IP address format.\"\"\"\n        import ipaddress\n        try:\n            ipaddress.ip_address(v)\n        except ValueError:\n            raise ValueError(f\"Invalid IP address format: {v}\")\n        return v\n\n    @validator('controller_port')\n    def validate_port_conflict(cls, v, values):\n        \"\"\"Validate no port conflicts.\"\"\"\n        if 'plant_port' in values and v == values['plant_port']:\n            raise ValueError(\"Controller and plant ports must be different\")\n        return v\n\n    @validator('timeout')\n    def validate_realtime_constraint(cls, v, values):\n        \"\"\"Validate real-time communication constraints.\"\"\"\n        if 'dt' in values:  # If simulation dt is available\n            dt = values.get('dt', 0.01)\n            if v > dt / 2:\n                raise ValueError(\"Communication timeout too large for real-time operation\")\n        return v",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "741ca79c"
  },
  {
    "id": "configuration_schema_validation_7_458561a2",
    "file": "docs\\configuration_schema_validation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass MasterConfig(BaseModel):\n    \"\"\"Master configuration schema with cross-validation.\"\"\"\n    system: SystemConfig\n    physics: PhysicsConfig\n    controllers: dict  # Dynamic controller configuration\n    optimization: dict\n    simulation: SimulationConfig\n    hil: Optional[HILConfig] = None\n\n    @validator('controllers')\n    def validate_controller_configurations(cls, v, values):\n        \"\"\"Validate all controller configurations.\"\"\"\n        valid_controllers = {\n            'classical_smc': ClassicalSMCConfig,\n            'sta_smc': STASMCConfig,\n            'adaptive_smc': AdaptiveSMCConfig,\n            'hybrid_adaptive_sta_smc': dict  # Complex hybrid validation\n        }\n\n        for controller_name, config_data in v.items():\n            if controller_name not in valid_controllers:\n                raise ValueError(f\"Unknown controller type: {controller_name}\")\n\n            # Validate specific controller configuration\n            schema_class = valid_controllers[controller_name]\n            if schema_class != dict:  # Skip complex schemas for now\n                try:\n                    schema_class(**config_data)\n                except ValidationError as e:\n                    raise ValueError(f\"Controller {controller_name} validation failed: {e}\")\n\n        return v\n\n    @validator('optimization')\n    def validate_optimization_configuration(cls, v, values):\n        \"\"\"Validate optimization configuration with controller compatibility.\"\"\"\n        if 'pso' in v:\n            pso_config = PSOConfig(**v['pso'])\n\n            # Validate bounds compatibility with available controllers\n            if 'controllers' in values:\n                available_controllers = set(values['controllers'].keys())\n                bound_controllers = set(pso_config.bounds.keys())\n\n                missing_bounds = available_controllers - bound_controllers\n                if missing_bounds:\n                    raise ValueError(f\"Missing PSO bounds for controllers: {missing_bounds}\")\n\n        return v\n\n    class Config:\n        \"\"\"Pydantic configuration options.\"\"\"\n        validate_assignment = True\n        arbitrary_types_allowed = True\n        extra = 'forbid'  # Prevent extra fields",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "458561a2"
  },
  {
    "id": "configuration_schema_validation_8_1c001a9e",
    "file": "docs\\configuration_schema_validation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_lyapunov_stability_constraints(controller_config: dict, physics_config: dict) -> bool:\n    \"\"\"Validate Lyapunov stability mathematical constraints.\"\"\"\n\n    if controller_config['type'] == 'classical_smc':\n        gains = controller_config['gains']\n        lambda1, lambda2 = gains[0], gains[1]\n\n        # Stability requirement: \u03bb\u1d62 > 0\n        if lambda1 <= 0 or lambda2 <= 0:\n            raise ValueError(\"Sliding surface gains must be positive for stability\")\n\n        # Convergence rate constraints\n        if lambda1 < 0.5 or lambda2 < 0.5:\n            raise ValueError(\"Sliding surface gains too small, slow convergence\")\n\n        if lambda1 > 50.0 or lambda2 > 50.0:\n            raise ValueError(\"Sliding surface gains too large, excessive control effort\")\n\n        # Relative stability margins\n        physics = PhysicsConfig(**physics_config)\n        system_inertia = physics.cart_mass + physics.pendulum_mass_1 + physics.pendulum_mass_2\n\n        max_stable_gain = 100 / system_inertia  # Heuristic stability bound\n        if max(gains) > max_stable_gain:\n            raise ValueError(f\"Control gains exceed stability bound for system inertia\")\n\n    return True",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c001a9e"
  },
  {
    "id": "configuration_schema_validation_9_3fe4242d",
    "file": "docs\\configuration_schema_validation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_pso_convergence_constraints(pso_config: dict) -> bool:\n    \"\"\"Validate PSO convergence mathematical constraints.\"\"\"\n\n    w = pso_config['w']\n    c1 = pso_config['c1']\n    c2 = pso_config['c2']\n\n    # Constriction factor stability\n    phi = c1 + c2\n    if phi <= 4.0:\n        raise ValueError(\"PSO stability requires c\u2081 + c\u2082 > 4\")\n\n    # Calculate constriction factor\n    chi = 2 / (2 - phi - np.sqrt(phi**2 - 4*phi))\n    if chi >= 1.0:\n        raise ValueError(\"Constriction factor \u2265 1, system unstable\")\n\n    # Velocity convergence\n    if w * chi >= 1.0:\n        raise ValueError(\"Velocity update factor exceeds stability limit\")\n\n    # Swarm diversity constraints\n    n_particles = pso_config['n_particles']\n    if n_particles < 10:\n        raise ValueError(\"Insufficient particles for swarm diversity\")\n\n    # Search space constraints\n    for controller_bounds in pso_config['bounds'].values():\n        for bound_pair in controller_bounds:\n            min_val, max_val = bound_pair\n            search_ratio = max_val / min_val\n            if search_ratio > 1000:\n                raise ValueError(\"Search space too large for PSO convergence\")\n\n    return True",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3fe4242d"
  },
  {
    "id": "configuration_schema_validation_10_4ea48552",
    "file": "docs\\configuration_schema_validation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_numerical_stability(simulation_config: dict, controller_config: dict) -> bool:\n    \"\"\"Validate numerical stability constraints.\"\"\"\n\n    dt = simulation_config['dt']\n\n    # Discrete-time stability for SMC\n    if controller_config['type'] == 'classical_smc':\n        K = max(controller_config['gains'])  # Maximum switching gain\n\n        # CFL-like condition for SMC\n        max_dt = 0.1 / K  # Heuristic bound\n        if dt > max_dt:\n            raise ValueError(f\"Time step {dt} too large for switching gain {K}\")\n\n    # Nyquist criterion\n    control_bandwidth = 100  # Hz, typical for this system\n    nyquist_dt = 1 / (2 * control_bandwidth)\n    if dt > nyquist_dt:\n        raise ValueError(f\"Time step {dt} violates Nyquist criterion\")\n\n    # Numerical precision constraints\n    if dt < 1e-6:\n        raise ValueError(\"Time step too small, numerical precision issues\")\n\n    return True",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4ea48552"
  },
  {
    "id": "configuration_schema_validation_11_4e501e2d",
    "file": "docs\\configuration_schema_validation.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_physics_controller_compatibility(physics_config: dict, controller_config: dict) -> bool:\n    \"\"\"Validate compatibility between physics and controller parameters.\"\"\"\n\n    physics = PhysicsConfig(**physics_config)\n\n    # System natural frequency estimation\n    g = physics.gravity\n    l1 = physics.pendulum_length_1\n    l2 = physics.pendulum_length_2\n\n    # Approximate natural frequency for upright equilibrium\n    omega_n1 = np.sqrt(g / l1)  # Pendulum 1\n    omega_n2 = np.sqrt(g / l2)  # Pendulum 2\n\n    if controller_config['type'] == 'classical_smc':\n        gains = controller_config['gains']\n        lambda1, lambda2 = gains[0], gains[1]\n\n        # Sliding surface design rule: \u03bb\u1d62 \u2248 2\u03b6\u03c9\u2099\u1d62 where \u03b6 \u2248 0.7\n        recommended_lambda1 = 2 * 0.7 * omega_n1\n        recommended_lambda2 = 2 * 0.7 * omega_n2\n\n        # Check if gains are reasonably close to recommendations\n        if lambda1 < 0.1 * recommended_lambda1 or lambda1 > 10 * recommended_lambda1:\n            raise ValueError(f\"\u03bb\u2081={lambda1} far from recommended {recommended_lambda1:.2f}\")\n\n        if lambda2 < 0.1 * recommended_lambda2 or lambda2 > 10 * recommended_lambda2:\n            raise ValueError(f\"\u03bb\u2082={lambda2} far from recommended {recommended_lambda2:.2f}\")\n\n    return True",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4e501e2d"
  },
  {
    "id": "configuration_schema_validation_12_7dddfa26",
    "file": "docs\\configuration_schema_validation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_optimization_controller_compatibility(opt_config: dict, ctrl_configs: dict) -> bool:\n    \"\"\"Validate optimization bounds with controller requirements.\"\"\"\n\n    if 'pso' not in opt_config:\n        return True\n\n    pso_config = opt_config['pso']\n\n    for controller_name, controller_config in ctrl_configs.items():\n        if controller_name not in pso_config['bounds']:\n            continue\n\n        bounds = pso_config['bounds'][controller_name]\n\n        if controller_name == 'classical_smc':\n            # Validate bounds for stability requirements\n            lambda1_bounds = bounds[0]  # [min, max] for \u03bb\u2081\n            lambda2_bounds = bounds[1]  # [min, max] for \u03bb\u2082\n\n            if lambda1_bounds[0] <= 0 or lambda2_bounds[0] <= 0:\n                raise ValueError(\"SMC gain lower bounds must be positive\")\n\n            # Current gains should be within optimization bounds\n            current_gains = controller_config.get('gains', [])\n            for i, (current_gain, bound_pair) in enumerate(zip(current_gains, bounds)):\n                if not bound_pair[0] <= current_gain <= bound_pair[1]:\n                    raise ValueError(f\"Current gain {i} outside optimization bounds\")\n\n    return True",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7dddfa26"
  },
  {
    "id": "configuration_schema_validation_13_1f3555f9",
    "file": "docs\\configuration_schema_validation.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_simulation_system_compatibility(sim_config: dict, physics_config: dict) -> bool:\n    \"\"\"Validate simulation parameters with physical system.\"\"\"\n\n    physics = PhysicsConfig(**physics_config)\n    sim = SimulationConfig(**sim_config)\n\n    # Time scale compatibility\n    g = physics.gravity\n    l_min = min(physics.pendulum_length_1, physics.pendulum_length_2)\n    time_scale = np.sqrt(l_min / g)  # Natural time scale\n\n    if sim.dt > 0.1 * time_scale:\n        raise ValueError(f\"Time step too large compared to system time scale {time_scale:.3f}s\")\n\n    # Initial condition feasibility\n    theta1, theta2, x = sim.initial_state[:3]\n\n    # Physical constraints (pendulums can't overlap with cart)\n    l1, l2 = physics.pendulum_length_1, physics.pendulum_length_2\n\n    # Simplified collision check for extreme angles\n    if abs(theta1) > np.pi/3 and abs(theta2) > np.pi/3:\n        # Check potential collision (simplified)\n        x1_end = x + l1 * np.sin(theta1)\n        x2_end = x + l2 * np.sin(theta2)\n        if abs(x1_end - x2_end) < 0.1:  # 10cm clearance\n            raise ValueError(\"Initial configuration may cause pendulum collision\")\n\n    return True",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f3555f9"
  },
  {
    "id": "configuration_schema_validation_14_447aeb8c",
    "file": "docs\\configuration_schema_validation.md",
    "index": 14,
    "code": "class RuntimeConfigValidator:\n    \"\"\"Real-time configuration validation system.\"\"\"\n\n    def __init__(self, base_config: dict):\n        self.base_config = MasterConfig(**base_config)\n        self.validation_cache = {}\n\n    def validate_parameter_update(self, parameter_path: str, new_value: any) -> bool:\n        \"\"\"Validate real-time parameter updates.\"\"\"\n\n        # Parse parameter path (e.g., \"controllers.classical_smc.gains.0\")\n        path_parts = parameter_path.split('.')\n\n        # Create temporary config with updated value\n        temp_config = self._update_config_path(self.base_config.dict(), path_parts, new_value)\n\n        try:\n            # Validate complete configuration\n            MasterConfig(**temp_config)\n\n            # Additional runtime checks\n            self._validate_runtime_constraints(parameter_path, new_value, temp_config)\n\n            return True\n\n        except ValidationError as e:\n            raise ValueError(f\"Parameter update validation failed: {e}\")\n\n    def _validate_runtime_constraints(self, param_path: str, value: any, config: dict) -> None:\n        \"\"\"Additional runtime-specific validation.\"\"\"\n\n        # Control stability constraints during operation\n        if 'gains' in param_path:\n            controller_name = param_path.split('.')[1]\n            self._validate_gain_update_stability(controller_name, config)\n\n        # Optimization parameter updates\n        if 'optimization' in param_path:\n            self._validate_optimization_update(config)\n\n        # Safety parameter updates\n        if 'saturation_limit' in param_path:\n            self._validate_saturation_update(value)\n\n    def _validate_gain_update_stability(self, controller_name: str, config: dict) -> None:\n        \"\"\"Validate controller gain updates for continued stability.\"\"\"\n\n        controller_config = config['controllers'][controller_name]\n\n        if controller_name == 'classical_smc':\n            gains = controller_config['gains']\n            lambda1, lambda2 = gains[0], gains[1]\n\n            # Real-time stability check\n            if lambda1 <= 0 or lambda2 <= 0:\n                raise ValueError(\"Gain update would destabilize system\")\n\n            # Check if new gains are too different from current\n            current_gains = self.base_config.controllers[controller_name]['gains']\n            max_change_ratio = 2.0  # Allow 2x change maximum\n\n            for new_gain, current_gain in zip(gains, current_gains):\n                change_ratio = new_gain / current_gain\n                if change_ratio > max_change_ratio or change_ratio < 1/max_change_ratio:\n                    raise ValueError(f\"Gain change ratio {change_ratio:.2f} too large\")\n\n    def _update_config_path(self, config: dict, path_parts: list, value: any) -> dict:\n        \"\"\"Update configuration at specified path.\"\"\"\n        import copy\n        updated_config = copy.deepcopy(config)\n\n        current = updated_config\n        for part in path_parts[:-1]:\n            if part.isdigit():\n                current = current[int(part)]\n            else:\n                current = current[part]\n\n        final_key = path_parts[-1]\n        if final_key.isdigit():\n            current[int(final_key)] = value\n        else:\n            current[final_key] = value\n\n        return updated_config",
    "lines": 85,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "447aeb8c"
  },
  {
    "id": "configuration_schema_validation_15_ce49c01c",
    "file": "docs\\configuration_schema_validation.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationHotReloader:\n    \"\"\"Hot-reload configuration with validation.\"\"\"\n\n    def __init__(self, config_file: str):\n        self.config_file = config_file\n        self.current_config = None\n        self.validator = None\n        self.reload_config()\n\n    def reload_config(self) -> bool:\n        \"\"\"Reload and validate configuration file.\"\"\"\n        try:\n            # Load new configuration\n            with open(self.config_file, 'r') as f:\n                new_config_data = yaml.safe_load(f)\n\n            # Validate new configuration\n            new_config = MasterConfig(**new_config_data)\n\n            # Cross-validate with current system state\n            if self.current_config:\n                self._validate_config_transition(self.current_config, new_config)\n\n            # Update current configuration\n            self.current_config = new_config\n            self.validator = RuntimeConfigValidator(new_config.dict())\n\n            return True\n\n        except Exception as e:\n            raise ConfigurationError(f\"Configuration reload failed: {e}\")\n\n    def _validate_config_transition(self, old_config: MasterConfig, new_config: MasterConfig) -> None:\n        \"\"\"Validate transition between configurations.\"\"\"\n\n        # Critical parameters that shouldn't change during operation\n        critical_params = [\n            'physics.pendulum_length_1',\n            'physics.pendulum_length_2',\n            'physics.cart_mass',\n            'system.environment'\n        ]\n\n        for param_path in critical_params:\n            old_value = self._get_config_value(old_config.dict(), param_path)\n            new_value = self._get_config_value(new_config.dict(), param_path)\n\n            if old_value != new_value:\n                raise ValueError(f\"Critical parameter {param_path} cannot change during operation\")\n\n    def _get_config_value(self, config: dict, path: str) -> any:\n        \"\"\"Get configuration value by path.\"\"\"\n        current = config\n        for part in path.split('.'):\n            current = current[part]\n        return current",
    "lines": 59,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce49c01c"
  },
  {
    "id": "configuration_schema_validation_16_cd4316e7",
    "file": "docs\\configuration_schema_validation.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationMigrator:\n    \"\"\"Handle configuration schema migrations.\"\"\"\n\n    MIGRATIONS = {\n        '1.0.0': {\n            'to': '2.0.0',\n            'changes': [\n                'Add system.version field',\n                'Restructure controller configurations',\n                'Add optimization.pso.bounds validation'\n            ],\n            'migration_func': 'migrate_1_0_to_2_0'\n        },\n        '2.0.0': {\n            'to': '2.1.0',\n            'changes': [\n                'Add HIL configuration section',\n                'Enhanced PSO stability validation',\n                'Add runtime parameter constraints'\n            ],\n            'migration_func': 'migrate_2_0_to_2_1'\n        }\n    }\n\n    def migrate_config(self, config_data: dict, target_version: str = None) -> dict:\n        \"\"\"Migrate configuration to target version.\"\"\"\n\n        current_version = config_data.get('system', {}).get('version', '1.0.0')\n        target_version = target_version or self._get_latest_version()\n\n        if current_version == target_version:\n            return config_data\n\n        # Find migration path\n        migration_path = self._find_migration_path(current_version, target_version)\n\n        # Apply migrations in sequence\n        migrated_config = config_data\n        for version in migration_path:\n            migration = self.MIGRATIONS[version]\n            migration_func = getattr(self, migration['migration_func'])\n            migrated_config = migration_func(migrated_config)\n\n        return migrated_config\n\n    def migrate_1_0_to_2_0(self, config: dict) -> dict:\n        \"\"\"Migrate from version 1.0 to 2.0.\"\"\"\n        migrated = config.copy()\n\n        # Add system section if missing\n        if 'system' not in migrated:\n            migrated['system'] = {\n                'version': '2.0.0',\n                'environment': 'development',\n                'logging_level': 'INFO'\n            }\n\n        # Restructure controller configurations\n        if 'controllers' in migrated:\n            for controller_name, controller_config in migrated['controllers'].items():\n                # Add default saturation limits if missing\n                if 'saturation_limit' not in controller_config:\n                    controller_config['saturation_limit'] = 10.0\n\n        # Add PSO bounds validation\n        if 'optimization' in migrated and 'pso' in migrated['optimization']:\n            pso_config = migrated['optimization']['pso']\n            if 'bounds' not in pso_config:\n                # Add default bounds\n                pso_config['bounds'] = {\n                    'classical_smc': [[0.1, 50.0]] * 6,\n                    'sta_smc': [[0.1, 20.0], [0.1, 20.0]],\n                    'adaptive_smc': [[0.1, 50.0]] * 6\n                }\n\n        return migrated\n\n    def migrate_2_0_to_2_1(self, config: dict) -> dict:\n        \"\"\"Migrate from version 2.0 to 2.1.\"\"\"\n        migrated = config.copy()\n\n        # Update version\n        migrated['system']['version'] = '2.1.0'\n\n        # Add HIL section if missing\n        if 'hil' not in migrated:\n            migrated['hil'] = {\n                'enabled': False,\n                'plant_address': '127.0.0.1',\n                'plant_port': 8080,\n                'controller_port': 8081,\n                'timeout': 1.0\n            }\n\n        return migrated",
    "lines": 98,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cd4316e7"
  },
  {
    "id": "configuration_schema_validation_17_152ab6f6",
    "file": "docs\\configuration_schema_validation.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_backward_compatibility(old_config: dict, new_config: dict) -> bool:\n    \"\"\"Validate backward compatibility between configuration versions.\"\"\"\n\n    # Core functionality must remain available\n    core_sections = ['physics', 'controllers', 'simulation']\n    for section in core_sections:\n        if section in old_config and section not in new_config:\n            raise ValueError(f\"Core section {section} removed in new configuration\")\n\n    # Controller types must remain supported\n    old_controllers = set(old_config.get('controllers', {}).keys())\n    new_controllers = set(new_config.get('controllers', {}).keys())\n\n    removed_controllers = old_controllers - new_controllers\n    if removed_controllers:\n        raise ValueError(f\"Controller types removed: {removed_controllers}\")\n\n    return True",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "152ab6f6"
  },
  {
    "id": "configuration_schema_validation_18_09f0cc7b",
    "file": "docs\\configuration_schema_validation.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationTestSuite:\n    \"\"\"Comprehensive configuration validation test suite.\"\"\"\n\n    def test_valid_configurations(self):\n        \"\"\"Test all valid configuration combinations.\"\"\"\n        test_configs = [\n            'config_minimal.yaml',\n            'config_development.yaml',\n            'config_testing.yaml',\n            'config_production.yaml'\n        ]\n\n        for config_file in test_configs:\n            with open(config_file) as f:\n                config_data = yaml.safe_load(f)\n\n            # Should validate without errors\n            config = MasterConfig(**config_data)\n            assert config is not None\n\n    def test_invalid_configurations(self):\n        \"\"\"Test configuration validation catches invalid inputs.\"\"\"\n        invalid_configs = [\n            {'system': {'version': '0.9.0'}},  # Version too old\n            {'physics': {'pendulum_length_1': -1.0}},  # Negative length\n            {'controllers': {'classical_smc': {'gains': [0, 1, 2, 3, 4, 5]}}},  # Zero gain\n            {'optimization': {'pso': {'c1': 2.0, 'c2': 1.0}}},  # c1 + c2 <= 4\n            {'simulation': {'dt': 1.0}}}  # Time step too large\n        ]\n\n        for invalid_config in invalid_configs:\n            with pytest.raises(ValidationError):\n                MasterConfig(**invalid_config)\n\n    def test_mathematical_constraints(self):\n        \"\"\"Test mathematical constraint validation.\"\"\"\n        # Test SMC stability constraints\n        smc_config = {\n            'type': 'classical_smc',\n            'gains': [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        }\n        physics_config = {\n            'pendulum_length_1': 0.5,\n            'pendulum_length_2': 0.3,\n            'cart_mass': 1.0,\n            'pendulum_mass_1': 0.2,\n            'pendulum_mass_2': 0.1,\n            'gravity': 9.81\n        }\n\n        assert validate_lyapunov_stability_constraints(smc_config, physics_config)\n\n        # Test PSO convergence constraints\n        pso_config = {\n            'w': 0.7298,\n            'c1': 1.49618,\n            'c2': 1.49618,\n            'n_particles': 30,\n            'bounds': {\n                'classical_smc': [[0.1, 50.0]] * 6\n            }\n        }\n\n        assert validate_pso_convergence_constraints(pso_config)\n\n    def test_runtime_validation(self):\n        \"\"\"Test runtime parameter validation.\"\"\"\n        base_config = load_test_config('config_production.yaml')\n        validator = RuntimeConfigValidator(base_config)\n\n        # Test valid parameter update\n        assert validator.validate_parameter_update('controllers.classical_smc.gains.0', 12.0)\n\n        # Test invalid parameter update\n        with pytest.raises(ValueError):\n            validator.validate_parameter_update('controllers.classical_smc.gains.0', -5.0)\n\n    def test_configuration_migration(self):\n        \"\"\"Test configuration version migration.\"\"\"\n        migrator = ConfigurationMigrator()\n\n        # Load old version configuration\n        old_config = load_test_config('config_v1_0.yaml')\n\n        # Migrate to current version\n        migrated_config = migrator.migrate_config(old_config, '2.1.0')\n\n        # Validate migrated configuration\n        config = MasterConfig(**migrated_config)\n        assert config.system.version == '2.1.0'",
    "lines": 93,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "09f0cc7b"
  },
  {
    "id": "configuration_schema_validation_19_72146435",
    "file": "docs\\configuration_schema_validation.md",
    "index": 19,
    "code": "from hypothesis import given, strategies as st\n\nclass PropertyBasedConfigurationTests:\n    \"\"\"Property-based testing for configuration validation.\"\"\"\n\n    @given(\n        lambda1=st.floats(min_value=0.1, max_value=50.0),\n        lambda2=st.floats(min_value=0.1, max_value=50.0),\n        k_gains=st.lists(st.floats(min_value=0.1, max_value=100.0), min_size=4, max_size=4)\n    )\n    def test_smc_stability_property(self, lambda1, lambda2, k_gains):\n        \"\"\"Property: SMC with positive gains should always validate.\"\"\"\n        gains = [lambda1, lambda2] + k_gains\n\n        config = {\n            'type': 'classical_smc',\n            'gains': gains,\n            'saturation_limit': 10.0,\n            'boundary_layer_thickness': 0.01\n        }\n\n        # Should always validate for positive gains\n        smc_config = ClassicalSMCConfig(**config)\n        assert all(g > 0 for g in smc_config.gains)\n\n    @given(\n        c1=st.floats(min_value=0.1, max_value=4.0),\n        c2=st.floats(min_value=0.1, max_value=4.0)\n    )\n    def test_pso_convergence_property(self, c1, c2):\n        \"\"\"Property: PSO with c1 + c2 > 4 should converge.\"\"\"\n        if c1 + c2 > 4.0:\n            config = {\n                'w': 0.7298,\n                'c1': c1,\n                'c2': c2,\n                'n_particles': 30,\n                'max_iterations': 100,\n                'bounds': {'classical_smc': [[0.1, 50.0]] * 6}\n            }\n\n            # Should validate without error\n            pso_config = PSOConfig(**config)\n            assert pso_config.c1 + pso_config.c2 > 4.0",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72146435"
  },
  {
    "id": "controller_pso_interface_api_documentation_1_fb6e2cbe",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef controller_factory(gains: np.ndarray, **kwargs) -> BaseController",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb6e2cbe"
  },
  {
    "id": "controller_pso_interface_api_documentation_2_0719bc92",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 2,
    "code": "from typing import Protocol, Optional, Union, Any\nimport numpy as np\n\nclass PSO_ControllerInterface(Protocol):\n    \"\"\"PSO-compatible controller interface protocol.\"\"\"\n\n    def __init__(self, gains: np.ndarray, **kwargs) -> None:\n        \"\"\"Initialize controller with PSO-optimized gains.\n\n        Parameters\n        ----------\n        gains : np.ndarray, shape (n,)\n            Controller gain vector from PSO particle\n            - Classical SMC: [c1, \u03bb1, c2, \u03bb2, K, kd] \u2208 \u211d\u2076\n            - STA-SMC: [K1, K2, k1, k2, \u03bb1, \u03bb2] \u2208 \u211d\u2076\n            - Adaptive SMC: [c1, \u03bb1, c2, \u03bb2, \u03b3] \u2208 \u211d\u2075\n            - Hybrid Adaptive: [c1, \u03bb1, c2, \u03bb2] \u2208 \u211d\u2074\n        **kwargs\n            Additional controller-specific parameters\n        \"\"\"\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit [N].\n\n        Required for PSO simulation bounds.\n        Typical range: [50.0, 200.0] N\n        \"\"\"\n\n    def compute_control(self,\n                       state: np.ndarray,\n                       dt: float = 0.001,\n                       **kwargs) -> float:\n        \"\"\"Compute control command for current state.\n\n        Parameters\n        ----------\n        state : np.ndarray, shape (6,)\n            System state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n        dt : float, optional\n            Sampling time [s]\n\n        Returns\n        -------\n        float\n            Control command u(t) \u2208 [-max_force, max_force]\n        \"\"\"\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Optional: Pre-filter invalid particles.\n\n        Parameters\n        ----------\n        particles : np.ndarray, shape (n_particles, n_gains)\n            Swarm particle matrix\n\n        Returns\n        -------\n        np.ndarray, shape (n_particles,), dtype=bool\n            Boolean mask indicating valid particles\n\n        Notes\n        -----\n        This method enables early rejection of unstable gain combinations\n        before expensive simulation evaluation.\n        \"\"\"",
    "lines": 66,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0719bc92"
  },
  {
    "id": "controller_pso_interface_api_documentation_3_87708dd0",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 3,
    "code": "from typing import Dict, Type, Callable\nfrom abc import ABC, abstractmethod\n\nclass ControllerFactory:\n    \"\"\"Centralized controller factory with PSO integration.\"\"\"\n\n    _controller_registry: Dict[str, Callable] = {}\n\n    @classmethod\n    def register_controller(cls,\n                          name: str,\n                          controller_class: Type[PSO_ControllerInterface]) -> None:\n        \"\"\"Register controller class for PSO optimization.\n\n        Parameters\n        ----------\n        name : str\n            Controller identifier (e.g., 'classical_smc')\n        controller_class : Type[PSO_ControllerInterface]\n            Controller class implementing required interface\n        \"\"\"\n        if not hasattr(controller_class, 'max_force'):\n            raise TypeError(f\"Controller {name} missing required 'max_force' property\")\n\n        cls._controller_registry[name] = controller_class\n\n    @classmethod\n    def create_controller(cls,\n                         controller_type: str,\n                         gains: np.ndarray,\n                         **kwargs) -> PSO_ControllerInterface:\n        \"\"\"Create controller instance from PSO gains.\n\n        Parameters\n        ----------\n        controller_type : str\n            Registered controller name\n        gains : np.ndarray\n            PSO-optimized gain vector\n        **kwargs\n            Additional parameters\n\n        Returns\n        -------\n        PSO_ControllerInterface\n            Configured controller instance\n        \"\"\"\n        if controller_type not in cls._controller_registry:\n            raise ValueError(f\"Unknown controller type: {controller_type}\")\n\n        controller_class = cls._controller_registry[controller_type]\n        return controller_class(gains, **kwargs)",
    "lines": 52,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87708dd0"
  },
  {
    "id": "controller_pso_interface_api_documentation_4_089badcc",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Classical SMC Gains: [c1, \u03bb1, c2, \u03bb2, K, kd] \u2208 \u211d\u2076\nCLASSICAL_SMC_GAINS = {\n    'c1': 'Sliding surface gain for \u03b8\u2081 error',\n    'lambda1': 'Sliding surface coefficient for \u03b8\u2081',\n    'c2': 'Sliding surface gain for \u03b8\u2082 error',\n    'lambda2': 'Sliding surface coefficient for \u03b8\u2082',\n    'K': 'Control gain',\n    'kd': 'Derivative gain'\n}\n\n# Typical bounds for PSO optimization:\nCLASSICAL_SMC_BOUNDS = {\n    'lower': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n    'upper': [20.0, 20.0, 20.0, 20.0, 100.0, 10.0]\n}",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "089badcc"
  },
  {
    "id": "controller_pso_interface_api_documentation_5_cab0e550",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass ClassicalSMC(PSO_ControllerInterface):\n    \"\"\"Classical Sliding Mode Controller with PSO interface.\"\"\"\n\n    def __init__(self, gains: np.ndarray, **kwargs) -> None:\n        \"\"\"Initialize Classical SMC.\n\n        Mathematical Model:\n        Sliding surface: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n        Control law: u = -K\u00b7sign(s) - kd\u00b7\u1e61\n\n        Parameters\n        ----------\n        gains : np.ndarray, shape (6,)\n            [c1, \u03bb1, c2, \u03bb2, K, kd]\n        \"\"\"\n        if len(gains) != 6:\n            raise ValueError(f\"Classical SMC requires 6 gains, got {len(gains)}\")\n\n        self.c1, self.lambda1, self.c2, self.lambda2, self.K, self.kd = gains\n        self._max_force = kwargs.get('max_force', 150.0)\n        self.boundary_layer = kwargs.get('boundary_layer', 0.02)\n\n        # Validate stability conditions\n        if self.lambda1 <= 0 or self.lambda2 <= 0:\n            raise ValueError(\"Sliding surface coefficients must be positive\")\n        if self.K <= 0:\n            raise ValueError(\"Control gain must be positive\")\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit.\"\"\"\n        return self._max_force\n\n    def compute_control(self, state: np.ndarray, dt: float = 0.001) -> float:\n        \"\"\"Compute classical SMC control.\n\n        Mathematical Implementation:\n        1. Compute position errors: e\u2081 = \u03b8\u2081, e\u2082 = \u03b8\u2082\n        2. Compute velocity errors: \u0117\u2081 = \u03b8\u0307\u2081, \u0117\u2082 = \u03b8\u0307\u2082\n        3. Sliding surface: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n        4. Control law: u = -K\u00b7sat(s/\u03b5) - kd\u00b7\u1e61\n        \"\"\"\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n        # Position errors (target is upright: \u03b8\u2081 = \u03b8\u2082 = 0)\n        e1 = theta1\n        e2 = theta2\n\n        # Velocity errors (target velocities are zero)\n        e1_dot = theta1_dot\n        e2_dot = theta2_dot\n\n        # Sliding surface\n        s = self.lambda1 * e1 + self.lambda2 * e2 + e1_dot + e2_dot\n\n        # Boundary layer saturation function\n        if abs(s) <= self.boundary_layer:\n            sat_s = s / self.boundary_layer\n        else:\n            sat_s = np.sign(s)\n\n        # Control law\n        u = -self.K * sat_s - self.kd * s\n\n        # Apply actuator saturation\n        return np.clip(u, -self.max_force, self.max_force)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate Classical SMC gain combinations.\n\n        Stability Requirements:\n        1. \u03bb\u2081, \u03bb\u2082 > 0 (sliding surface stability)\n        2. K > 0 (control authority)\n        3. Reasonable gain ratios to prevent numerical issues\n        \"\"\"\n        n_particles = particles.shape[0]\n        valid = np.ones(n_particles, dtype=bool)\n\n        # Extract gain components\n        c1, lambda1, c2, lambda2, K, kd = particles.T\n\n        # Stability conditions\n        valid &= (lambda1 > 0) & (lambda2 > 0)  # Surface coefficients\n        valid &= (K > 0)                        # Control gain\n        valid &= (kd >= 0)                      # Derivative gain\n\n        # Numerical stability bounds\n        valid &= (lambda1 < 100) & (lambda2 < 100)  # Prevent excessive stiffness\n        valid &= (K < 1000)                         # Prevent actuator abuse\n\n        return valid",
    "lines": 94,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cab0e550"
  },
  {
    "id": "controller_pso_interface_api_documentation_6_53c09811",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# STA-SMC Gains: [K1, K2, k1, k2, \u03bb1, \u03bb2] \u2208 \u211d\u2076\nSTA_SMC_GAINS = {\n    'K1': 'First-order sliding mode gain',\n    'K2': 'Second-order sliding mode gain',\n    'k1': 'Surface gain for \u03b8\u2081',\n    'k2': 'Surface gain for \u03b8\u2082',\n    'lambda1': 'Surface coefficient for \u03b8\u2081',\n    'lambda2': 'Surface coefficient for \u03b8\u2082'\n}\n\n# Optimized bounds from Issue #2 resolution:\nSTA_SMC_BOUNDS = {\n    'lower': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    'upper': [20.0, 20.0, 20.0, 20.0, 10.0, 10.0]\n}",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53c09811"
  },
  {
    "id": "controller_pso_interface_api_documentation_7_6ae29300",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass STASMC(PSO_ControllerInterface):\n    \"\"\"Super-Twisting Algorithm Sliding Mode Controller.\"\"\"\n\n    def __init__(self, gains: np.ndarray, **kwargs) -> None:\n        \"\"\"Initialize STA-SMC.\n\n        Mathematical Model:\n        Sliding surface: s = k\u2081\u03b8\u2081 + k\u2082\u03b8\u2082 + \u03bb\u2081\u03b8\u0307\u2081 + \u03bb\u2082\u03b8\u0307\u2082\n        Super-twisting control:\n        u\u0307 = -K\u2082\u00b7sign(s)\n        u = -K\u2081\u00b7|s|^(1/2)\u00b7sign(s) + \u222bu\u0307dt\n\n        Parameters\n        ----------\n        gains : np.ndarray, shape (6,)\n            [K1, K2, k1, k2, \u03bb1, \u03bb2]\n        \"\"\"\n        if len(gains) != 6:\n            raise ValueError(f\"STA-SMC requires 6 gains, got {len(gains)}\")\n\n        self.K1, self.K2, self.k1, self.k2, self.lambda1, self.lambda2 = gains\n        self._max_force = kwargs.get('max_force', 150.0)\n        self.dt = kwargs.get('dt', 0.001)\n\n        # Internal states for super-twisting algorithm\n        self.u_integral = 0.0\n        self.boundary_layer = kwargs.get('boundary_layer', 0.05)\n\n        # Validate super-twisting stability conditions\n        if self.K1 <= 0 or self.K2 <= 0:\n            raise ValueError(\"Super-twisting gains must be positive\")\n        if self.lambda1 <= 0 or self.lambda2 <= 0:\n            raise ValueError(\"Surface coefficients must be positive\")\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit.\"\"\"\n        return self._max_force\n\n    def compute_control(self, state: np.ndarray, dt: float = 0.001) -> float:\n        \"\"\"Compute super-twisting SMC control.\n\n        Mathematical Implementation:\n        1. Sliding surface: s = k\u2081\u03b8\u2081 + k\u2082\u03b8\u2082 + \u03bb\u2081\u03b8\u0307\u2081 + \u03bb\u2082\u03b8\u0307\u2082\n        2. First-order term: u\u2081 = -K\u2081\u00b7|s|^(1/2)\u00b7sign(s)\n        3. Second-order term: u\u0307\u2082 = -K\u2082\u00b7sign(s)\n        4. Total control: u = u\u2081 + u\u2082\n        \"\"\"\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n        # Sliding surface computation\n        s = (self.k1 * theta1 + self.k2 * theta2 +\n             self.lambda1 * theta1_dot + self.lambda2 * theta2_dot)\n\n        # Super-twisting algorithm\n        if abs(s) <= self.boundary_layer:\n            # Boundary layer approximation\n            u1 = -self.K1 * (abs(s) / self.boundary_layer)**0.5 * s / self.boundary_layer\n            u2_dot = -self.K2 * s / self.boundary_layer\n        else:\n            # Traditional super-twisting\n            u1 = -self.K1 * np.sqrt(abs(s)) * np.sign(s)\n            u2_dot = -self.K2 * np.sign(s)\n\n        # Integrate second-order term\n        self.u_integral += u2_dot * dt\n\n        # Total control\n        u = u1 + self.u_integral\n\n        # Apply actuator saturation\n        return np.clip(u, -self.max_force, self.max_force)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate STA-SMC gain combinations.\n\n        Super-Twisting Stability Conditions:\n        1. K\u2081, K\u2082 > 0 (algorithmic gains)\n        2. \u03bb\u2081, \u03bb\u2082 > 0 (surface coefficients)\n        3. Sufficient condition: K\u2081 > L, K\u2082 > K\u2081\u00b7C (where L, C are bounds)\n        \"\"\"\n        n_particles = particles.shape[0]\n        valid = np.ones(n_particles, dtype=bool)\n\n        # Extract gains\n        K1, K2, k1, k2, lambda1, lambda2 = particles.T\n\n        # Basic positivity\n        valid &= (K1 > 0) & (K2 > 0)\n        valid &= (k1 > 0) & (k2 > 0)\n        valid &= (lambda1 > 0) & (lambda2 > 0)\n\n        # Super-twisting stability condition (simplified)\n        valid &= (K2 > K1 * 0.5)  # Simplified sufficient condition\n\n        # Practical bounds to prevent excessive oscillations\n        valid &= (K1 < 50) & (K2 < 50)\n        valid &= (lambda1 < 20) & (lambda2 < 20)\n\n        return valid",
    "lines": 103,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ae29300"
  },
  {
    "id": "controller_pso_interface_api_documentation_8_45bceff8",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Adaptive SMC Gains: [c1, \u03bb1, c2, \u03bb2, \u03b3] \u2208 \u211d\u2075\nADAPTIVE_SMC_GAINS = {\n    'c1': 'Sliding surface gain for \u03b8\u2081',\n    'lambda1': 'Sliding surface coefficient for \u03b8\u2081',\n    'c2': 'Sliding surface gain for \u03b8\u2082',\n    'lambda2': 'Sliding surface coefficient for \u03b8\u2082',\n    'gamma': 'Adaptation rate'\n}\n\nADAPTIVE_SMC_BOUNDS = {\n    'lower': [0.1, 0.1, 0.1, 0.1, 0.01],\n    'upper': [20.0, 20.0, 20.0, 20.0, 5.0]\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45bceff8"
  },
  {
    "id": "controller_pso_interface_api_documentation_9_dd966e52",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptiveSMC(PSO_ControllerInterface):\n    \"\"\"Adaptive Sliding Mode Controller with uncertainty estimation.\"\"\"\n\n    def __init__(self, gains: np.ndarray, **kwargs) -> None:\n        \"\"\"Initialize Adaptive SMC.\n\n        Mathematical Model:\n        Sliding surface: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n        Adaptive control: u = -K\u0302(t)\u00b7sign(s)\n        Adaptation law: K\u0307 = \u03b3\u00b7|s| for |s| > \u03b4, 0 otherwise\n\n        Parameters\n        ----------\n        gains : np.ndarray, shape (5,)\n            [c1, \u03bb1, c2, \u03bb2, \u03b3]\n        \"\"\"\n        if len(gains) != 5:\n            raise ValueError(f\"Adaptive SMC requires 5 gains, got {len(gains)}\")\n\n        self.c1, self.lambda1, self.c2, self.lambda2, self.gamma = gains\n        self._max_force = kwargs.get('max_force', 150.0)\n\n        # Adaptive gain initialization\n        self.K_adaptive = kwargs.get('K_init', 1.0)\n        self.K_min = kwargs.get('K_min', 0.1)\n        self.K_max = kwargs.get('K_max', 100.0)\n        self.dead_zone = kwargs.get('dead_zone', 0.05)\n\n        # Validate adaptation parameters\n        if self.gamma <= 0:\n            raise ValueError(\"Adaptation rate must be positive\")\n        if self.lambda1 <= 0 or self.lambda2 <= 0:\n            raise ValueError(\"Surface coefficients must be positive\")\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit.\"\"\"\n        return self._max_force\n\n    def compute_control(self, state: np.ndarray, dt: float = 0.001) -> float:\n        \"\"\"Compute adaptive SMC control.\n\n        Mathematical Implementation:\n        1. Sliding surface: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n        2. Adaptation law: K\u0307 = \u03b3\u00b7|s| (outside dead zone)\n        3. Control law: u = -K\u0302(t)\u00b7sign(s)\n        \"\"\"\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n        # Position and velocity errors\n        e1, e2 = theta1, theta2\n        e1_dot, e2_dot = theta1_dot, theta2_dot\n\n        # Sliding surface\n        s = self.lambda1 * e1 + self.lambda2 * e2 + e1_dot + e2_dot\n\n        # Adaptive gain update (outside dead zone)\n        if abs(s) > self.dead_zone:\n            K_dot = self.gamma * abs(s)\n            self.K_adaptive += K_dot * dt\n            self.K_adaptive = np.clip(self.K_adaptive, self.K_min, self.K_max)\n\n        # Control law\n        if abs(s) <= self.dead_zone:\n            sat_s = s / self.dead_zone\n        else:\n            sat_s = np.sign(s)\n\n        u = -self.K_adaptive * sat_s\n\n        return np.clip(u, -self.max_force, self.max_force)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate Adaptive SMC parameters.\"\"\"\n        n_particles = particles.shape[0]\n        valid = np.ones(n_particles, dtype=bool)\n\n        c1, lambda1, c2, lambda2, gamma = particles.T\n\n        # Basic constraints\n        valid &= (lambda1 > 0) & (lambda2 > 0)  # Surface stability\n        valid &= (gamma > 0)                    # Adaptation positivity\n        valid &= (c1 > 0) & (c2 > 0)          # Surface gains\n\n        # Practical bounds\n        valid &= (gamma < 10)  # Prevent excessive adaptation speed\n        valid &= (lambda1 < 50) & (lambda2 < 50)  # Numerical stability\n\n        return valid",
    "lines": 92,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd966e52"
  },
  {
    "id": "controller_pso_interface_api_documentation_10_280430a5",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Hybrid Adaptive STA-SMC Gains: [c1, \u03bb1, c2, \u03bb2] \u2208 \u211d\u2074\nHYBRID_ADAPTIVE_STA_SMC_GAINS = {\n    'c1': 'Proportional-like sliding surface gain',\n    'lambda1': 'Integral-like sliding surface coefficient',\n    'c2': 'Proportional-like sliding surface gain',\n    'lambda2': 'Integral-like sliding surface coefficient'\n}\n\nHYBRID_ADAPTIVE_STA_SMC_BOUNDS = {\n    'lower': [0.1, 0.1, 0.1, 0.1],\n    'upper': [20.0, 20.0, 20.0, 20.0]\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "280430a5"
  },
  {
    "id": "controller_pso_interface_api_documentation_11_26fddf8f",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass HybridAdaptiveSTASMC(PSO_ControllerInterface):\n    \"\"\"Hybrid Adaptive Super-Twisting SMC with dual adaptation.\"\"\"\n\n    def __init__(self, gains: np.ndarray, **kwargs) -> None:\n        \"\"\"Initialize Hybrid Adaptive STA-SMC.\n\n        Mathematical Model:\n        Combines adaptive gain estimation with super-twisting algorithm.\n        Sliding surface: s = c\u2081\u03b8\u2081 + c\u2082\u03b8\u2082 + \u03bb\u2081\u222b\u03b8\u2081dt + \u03bb\u2082\u222b\u03b8\u2082dt\n        Adaptive STA: u = -k\u2081(t)\u00b7|s|^(1/2)\u00b7sign(s) + u\u2082\n        where k\u2081(t) adapts based on sliding surface magnitude.\n\n        Parameters\n        ----------\n        gains : np.ndarray, shape (4,)\n            [c1, \u03bb1, c2, \u03bb2]\n        \"\"\"\n        if len(gains) != 4:\n            raise ValueError(f\"Hybrid Adaptive STA-SMC requires 4 gains, got {len(gains)}\")\n\n        self.c1, self.lambda1, self.c2, self.lambda2 = gains\n        self._max_force = kwargs.get('max_force', 150.0)\n\n        # Adaptive parameters\n        self.k1_adaptive = kwargs.get('k1_init', 4.0)\n        self.k2_adaptive = kwargs.get('k2_init', 0.4)\n        self.k1_adapt_rate = kwargs.get('k1_adapt_rate', 0.5)\n        self.k2_adapt_rate = kwargs.get('k2_adapt_rate', 0.05)\n\n        # Internal states\n        self.theta1_integral = 0.0\n        self.theta2_integral = 0.0\n        self.u2_integral = 0.0\n        self.dt = kwargs.get('dt', 0.001)\n\n        # Validation\n        if any(g <= 0 for g in gains):\n            raise ValueError(\"All gains must be positive\")\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit.\"\"\"\n        return self._max_force\n\n    def compute_control(self, state: np.ndarray, dt: float = 0.001) -> float:\n        \"\"\"Compute hybrid adaptive STA control.\n\n        Mathematical Implementation:\n        1. Update integral terms\n        2. Compute sliding surface with integral action\n        3. Adapt gains based on sliding surface\n        4. Apply super-twisting algorithm\n        \"\"\"\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n        # Update integral terms\n        self.theta1_integral += theta1 * dt\n        self.theta2_integral += theta2 * dt\n\n        # Sliding surface with integral action\n        s = (self.c1 * theta1 + self.c2 * theta2 +\n             self.lambda1 * self.theta1_integral +\n             self.lambda2 * self.theta2_integral)\n\n        # Adaptive gain updates\n        if abs(s) > 0.01:  # Dead zone\n            self.k1_adaptive += self.k1_adapt_rate * abs(s) * dt\n            self.k2_adaptive += self.k2_adapt_rate * abs(s) * dt\n\n        # Bound adaptive gains\n        self.k1_adaptive = np.clip(self.k1_adaptive, 0.1, 50.0)\n        self.k2_adaptive = np.clip(self.k2_adaptive, 0.01, 5.0)\n\n        # Super-twisting control\n        u1 = -self.k1_adaptive * np.sqrt(abs(s)) * np.sign(s)\n        u2_dot = -self.k2_adaptive * np.sign(s)\n        self.u2_integral += u2_dot * dt\n\n        u = u1 + self.u2_integral\n\n        return np.clip(u, -self.max_force, self.max_force)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate Hybrid Adaptive STA-SMC gains.\"\"\"\n        n_particles = particles.shape[0]\n        valid = np.ones(n_particles, dtype=bool)\n\n        c1, lambda1, c2, lambda2 = particles.T\n\n        # All gains must be positive\n        valid &= (c1 > 0) & (lambda1 > 0) & (c2 > 0) & (lambda2 > 0)\n\n        # Practical bounds for stability\n        valid &= (c1 < 100) & (c2 < 100)\n        valid &= (lambda1 < 50) & (lambda2 < 50)\n\n        return valid",
    "lines": 100,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26fddf8f"
  },
  {
    "id": "controller_pso_interface_api_documentation_12_c6a0082f",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOTuner:\n    \"\"\"High-performance PSO tuner for SMC controllers.\"\"\"\n\n    def __init__(self,\n                 controller_factory: Callable[[np.ndarray], PSO_ControllerInterface],\n                 config: Union[ConfigSchema, str, Path],\n                 seed: Optional[int] = None,\n                 rng: Optional[np.random.Generator] = None,\n                 **kwargs) -> None:\n        \"\"\"Initialize PSO tuner with controller factory.\n\n        Parameters\n        ----------\n        controller_factory : Callable\n            Function mapping gain vectors to controller instances.\n            Must return objects implementing PSO_ControllerInterface.\n        config : ConfigSchema or path\n            System configuration with PSO parameters\n        seed : int, optional\n            Random seed for reproducibility\n        rng : np.random.Generator, optional\n            External random number generator\n        **kwargs\n            Additional PSO parameters\n        \"\"\"\n\n    def optimize(self,\n                 bounds: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n                 n_particles: Optional[int] = None,\n                 n_iterations: Optional[int] = None,\n                 **kwargs) -> Dict[str, Any]:\n        \"\"\"Run PSO optimization.\n\n        Parameters\n        ----------\n        bounds : tuple of arrays, optional\n            (lower_bounds, upper_bounds) for gain parameters\n        n_particles : int, optional\n            Number of particles in swarm\n        n_iterations : int, optional\n            Maximum optimization iterations\n        **kwargs\n            Additional PSO options\n\n        Returns\n        -------\n        Dict[str, Any]\n            Optimization results with keys:\n            - 'best_gains': Optimal gain vector\n            - 'best_cost': Best fitness value\n            - 'cost_history': Convergence history\n            - 'success': Optimization success flag\n            - 'message': Status message\n        \"\"\"",
    "lines": 57,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6a0082f"
  },
  {
    "id": "controller_pso_interface_api_documentation_13_20b84748",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 13,
    "code": "from src.controllers.factory import ControllerFactory\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller factory for specific type\ndef create_classical_smc(gains: np.ndarray) -> ClassicalSMC:\n    return ControllerFactory.create_controller('classical_smc', gains)\n\n# Initialize PSO tuner\npso_tuner = PSOTuner(\n    controller_factory=create_classical_smc,\n    config=config,\n    seed=42\n)\n\n# Extract bounds from configuration\nbounds_config = config.pso.bounds.classical_smc\nlower_bounds = np.array(bounds_config.lower)\nupper_bounds = np.array(bounds_config.upper)\n\n# Run optimization\nresults = pso_tuner.optimize(\n    bounds=(lower_bounds, upper_bounds),\n    n_particles=50,\n    n_iterations=100\n)\n\n# Extract optimized gains\noptimal_gains = results['best_gains']\noptimal_controller = create_classical_smc(optimal_gains)",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20b84748"
  },
  {
    "id": "controller_pso_interface_api_documentation_14_b1f7e9a3",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import List, Tuple\nfrom dataclasses import dataclass\n\n@dataclass\nclass ValidationResult:\n    \"\"\"Parameter validation result.\"\"\"\n    is_valid: bool\n    errors: List[str]\n    warnings: List[str]\n\nclass ParameterValidator:\n    \"\"\"Controller parameter validation utilities.\"\"\"\n\n    @staticmethod\n    def validate_gain_vector(gains: np.ndarray,\n                           controller_type: str) -> ValidationResult:\n        \"\"\"Validate gain vector for specific controller type.\n\n        Parameters\n        ----------\n        gains : np.ndarray\n            Controller gain vector\n        controller_type : str\n            Controller type identifier\n\n        Returns\n        -------\n        ValidationResult\n            Validation outcome with error details\n        \"\"\"\n        errors = []\n        warnings = []\n\n        # Check dimensionality\n        expected_dims = {\n            'classical_smc': 6,\n            'sta_smc': 6,\n            'adaptive_smc': 5,\n            'hybrid_adaptive_sta_smc': 4\n        }\n\n        if controller_type not in expected_dims:\n            errors.append(f\"Unknown controller type: {controller_type}\")\n            return ValidationResult(False, errors, warnings)\n\n        expected_dim = expected_dims[controller_type]\n        if len(gains) != expected_dim:\n            errors.append(f\"Expected {expected_dim} gains, got {len(gains)}\")\n\n        # Check for NaN/Inf values\n        if not np.all(np.isfinite(gains)):\n            errors.append(\"Gains contain NaN or infinite values\")\n\n        # Controller-specific validation\n        if controller_type == 'classical_smc':\n            c1, lambda1, c2, lambda2, K, kd = gains\n            if lambda1 <= 0 or lambda2 <= 0:\n                errors.append(\"Sliding surface coefficients must be positive\")\n            if K <= 0:\n                errors.append(\"Control gain must be positive\")\n            if kd < 0:\n                warnings.append(\"Negative derivative gain may cause instability\")\n\n        # Add similar validation for other controller types...\n\n        return ValidationResult(len(errors) == 0, errors, warnings)",
    "lines": 69,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1f7e9a3"
  },
  {
    "id": "controller_pso_interface_api_documentation_15_46e44d54",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_ControllerError(Exception):\n    \"\"\"Base exception for PSO-controller interface errors.\"\"\"\n    pass\n\nclass InvalidGainsError(PSO_ControllerError):\n    \"\"\"Raised when gain vector is invalid.\"\"\"\n    def __init__(self, gains: np.ndarray, controller_type: str, reason: str):\n        self.gains = gains\n        self.controller_type = controller_type\n        self.reason = reason\n        super().__init__(f\"Invalid gains for {controller_type}: {reason}\")\n\nclass ControllerInstantiationError(PSO_ControllerError):\n    \"\"\"Raised when controller creation fails.\"\"\"\n    pass\n\nclass SimulationError(PSO_ControllerError):\n    \"\"\"Raised when control simulation fails.\"\"\"\n    pass",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46e44d54"
  },
  {
    "id": "controller_pso_interface_api_documentation_16_43ace34a",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef robust_controller_factory(gains: np.ndarray,\n                            controller_type: str,\n                            fallback_gains: Optional[np.ndarray] = None) -> PSO_ControllerInterface:\n    \"\"\"Robust controller factory with error recovery.\n\n    Parameters\n    ----------\n    gains : np.ndarray\n        Primary gain vector\n    controller_type : str\n        Controller type\n    fallback_gains : np.ndarray, optional\n        Fallback gains for error recovery\n\n    Returns\n    -------\n    PSO_ControllerInterface\n        Controller instance (primary or fallback)\n\n    Raises\n    ------\n    ControllerInstantiationError\n        If both primary and fallback creation fail\n    \"\"\"\n    try:\n        # Validate gains first\n        validation = ParameterValidator.validate_gain_vector(gains, controller_type)\n        if not validation.is_valid:\n            raise InvalidGainsError(gains, controller_type, '; '.join(validation.errors))\n\n        # Create controller\n        return ControllerFactory.create_controller(controller_type, gains)\n\n    except Exception as e:\n        if fallback_gains is not None:\n            try:\n                return ControllerFactory.create_controller(controller_type, fallback_gains)\n            except Exception:\n                pass\n\n        raise ControllerInstantiationError(\n            f\"Failed to create {controller_type} controller: {str(e)}\"\n        ) from e",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43ace34a"
  },
  {
    "id": "controller_pso_interface_api_documentation_17_7ad22736",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 17,
    "code": "from time import perf_counter\nfrom dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass PerformanceMetrics:\n    \"\"\"Controller performance metrics.\"\"\"\n    creation_time: float = 0.0\n    control_computation_times: List[float] = field(default_factory=list)\n    memory_usage: float = 0.0\n    cache_hits: int = 0\n    cache_misses: int = 0\n\n    @property\n    def mean_control_time(self) -> float:\n        \"\"\"Mean control computation time.\"\"\"\n        return np.mean(self.control_computation_times) if self.control_computation_times else 0.0\n\n    @property\n    def max_control_time(self) -> float:\n        \"\"\"Maximum control computation time.\"\"\"\n        return np.max(self.control_computation_times) if self.control_computation_times else 0.0\n\nclass PerformanceMonitoredController:\n    \"\"\"Wrapper for performance monitoring.\"\"\"\n\n    def __init__(self, controller: PSO_ControllerInterface):\n        self.controller = controller\n        self.metrics = PerformanceMetrics()\n        self._creation_start = perf_counter()\n\n    def __getattr__(self, name):\n        \"\"\"Delegate attribute access to wrapped controller.\"\"\"\n        return getattr(self.controller, name)\n\n    def compute_control(self, state: np.ndarray, **kwargs) -> float:\n        \"\"\"Timed control computation.\"\"\"\n        start_time = perf_counter()\n        result = self.controller.compute_control(state, **kwargs)\n        end_time = perf_counter()\n\n        self.metrics.control_computation_times.append(end_time - start_time)\n        return result",
    "lines": 43,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ad22736"
  },
  {
    "id": "controller_pso_interface_api_documentation_18_e5b81680",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerBenchmark:\n    \"\"\"Standardized controller benchmarking.\"\"\"\n\n    @staticmethod\n    def benchmark_creation(controller_factory: Callable,\n                         gain_samples: List[np.ndarray],\n                         n_runs: int = 100) -> Dict[str, float]:\n        \"\"\"Benchmark controller creation time.\n\n        Parameters\n        ----------\n        controller_factory : Callable\n            Factory function to benchmark\n        gain_samples : List[np.ndarray]\n            Sample gain vectors for testing\n        n_runs : int\n            Number of benchmark runs\n\n        Returns\n        -------\n        Dict[str, float]\n            Timing statistics\n        \"\"\"\n        creation_times = []\n\n        for _ in range(n_runs):\n            gains = gain_samples[np.random.randint(len(gain_samples))]\n\n            start_time = perf_counter()\n            controller = controller_factory(gains)\n            end_time = perf_counter()\n\n            creation_times.append(end_time - start_time)\n\n        return {\n            'mean_time': np.mean(creation_times),\n            'std_time': np.std(creation_times),\n            'min_time': np.min(creation_times),\n            'max_time': np.max(creation_times),\n            'p95_time': np.percentile(creation_times, 95)\n        }\n\n    @staticmethod\n    def benchmark_control_computation(controller: PSO_ControllerInterface,\n                                    state_samples: List[np.ndarray],\n                                    n_runs: int = 1000) -> Dict[str, float]:\n        \"\"\"Benchmark control computation performance.\"\"\"\n        computation_times = []\n\n        for _ in range(n_runs):\n            state = state_samples[np.random.randint(len(state_samples))]\n\n            start_time = perf_counter()\n            control = controller.compute_control(state)\n            end_time = perf_counter()\n\n            computation_times.append(end_time - start_time)\n\n        return {\n            'mean_time': np.mean(computation_times),\n            'std_time': np.std(computation_times),\n            'min_time': np.min(computation_times),\n            'max_time': np.max(computation_times),\n            'p95_time': np.percentile(computation_times, 95),\n            'p99_time': np.percentile(computation_times, 99)\n        }",
    "lines": 69,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e5b81680"
  },
  {
    "id": "controller_pso_interface_api_documentation_19_4ebe7e80",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 19,
    "code": "import pytest\nfrom typing import Type\n\ndef test_pso_controller_interface_compliance(controller_class: Type[PSO_ControllerInterface],\n                                           sample_gains: np.ndarray):\n    \"\"\"Test PSO controller interface compliance.\n\n    Parameters\n    ----------\n    controller_class : Type[PSO_ControllerInterface]\n        Controller class to test\n    sample_gains : np.ndarray\n        Valid gain vector for testing\n    \"\"\"\n    # Test instantiation\n    controller = controller_class(sample_gains)\n\n    # Test required properties\n    assert hasattr(controller, 'max_force'), \"Controller missing max_force property\"\n    assert isinstance(controller.max_force, (int, float)), \"max_force must be numeric\"\n    assert controller.max_force > 0, \"max_force must be positive\"\n\n    # Test required methods\n    assert hasattr(controller, 'compute_control'), \"Controller missing compute_control method\"\n    assert callable(controller.compute_control), \"compute_control must be callable\"\n\n    # Test control computation\n    test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    control = controller.compute_control(test_state)\n\n    assert isinstance(control, (int, float)), \"Control output must be numeric\"\n    assert abs(control) <= controller.max_force, \"Control must respect actuator limits\"\n\n    # Test optional validate_gains method\n    if hasattr(controller, 'validate_gains'):\n        test_particles = np.array([sample_gains, sample_gains])\n        mask = controller.validate_gains(test_particles)\n        assert mask.shape == (2,), \"validate_gains must return boolean mask\"\n        assert mask.dtype == bool, \"validate_gains must return boolean array\"\n\ndef test_controller_factory_integration(controller_type: str, sample_gains: np.ndarray):\n    \"\"\"Test controller factory integration.\"\"\"\n    from src.controllers.factory import ControllerFactory\n\n    # Test factory creation\n    controller = ControllerFactory.create_controller(controller_type, sample_gains)\n\n    # Verify interface compliance\n    test_pso_controller_interface_compliance(type(controller), sample_gains)\n\n    # Test multiple creations with same gains\n    controller2 = ControllerFactory.create_controller(controller_type, sample_gains)\n    assert type(controller) == type(controller2), \"Factory must return consistent types\"",
    "lines": 53,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4ebe7e80"
  },
  {
    "id": "controller_pso_interface_api_documentation_20_5b3bf60b",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 20,
    "code": "def test_pso_optimization_integration(controller_type: str):\n    \"\"\"Test complete PSO optimization workflow.\"\"\"\n    from src.config import load_config\n    from src.optimization.algorithms.pso_optimizer import PSOTuner\n\n    # Load test configuration\n    config = load_config('config.yaml')\n\n    # Create controller factory\n    def factory(gains: np.ndarray):\n        return ControllerFactory.create_controller(controller_type, gains)\n\n    # Initialize PSO tuner\n    pso_tuner = PSOTuner(\n        controller_factory=factory,\n        config=config,\n        seed=42  # Reproducible testing\n    )\n\n    # Run short optimization\n    bounds_config = getattr(config.pso.bounds, controller_type)\n    lower_bounds = np.array(bounds_config.lower)\n    upper_bounds = np.array(bounds_config.upper)\n\n    results = pso_tuner.optimize(\n        bounds=(lower_bounds, upper_bounds),\n        n_particles=10,  # Small for testing\n        n_iterations=5   # Short for testing\n    )\n\n    # Validate results\n    assert 'best_gains' in results, \"Results missing best_gains\"\n    assert 'best_cost' in results, \"Results missing best_cost\"\n    assert 'success' in results, \"Results missing success flag\"\n\n    best_gains = results['best_gains']\n    assert len(best_gains) == len(lower_bounds), \"Invalid best_gains dimension\"\n    assert np.all(best_gains >= lower_bounds), \"best_gains violate lower bounds\"\n    assert np.all(best_gains <= upper_bounds), \"best_gains violate upper bounds\"\n\n    # Test optimized controller creation\n    optimized_controller = factory(best_gains)\n    test_state = np.zeros(6)\n    control = optimized_controller.compute_control(test_state)\n    assert np.isfinite(control), \"Optimized controller produces invalid control\"",
    "lines": 45,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b3bf60b"
  },
  {
    "id": "controller_pso_interface_api_documentation_21_e2c499bf",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"Example: PSO optimization for Classical SMC.\"\"\"\n\nimport numpy as np\nfrom src.controllers.factory import ControllerFactory\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\ndef main():\n    \"\"\"Run PSO optimization example.\"\"\"\n\n    # Load configuration\n    config = load_config('config.yaml')\n\n    # Define controller factory\n    def create_classical_smc(gains: np.ndarray):\n        return ControllerFactory.create_controller('classical_smc', gains)\n\n    # Initialize PSO tuner\n    pso_tuner = PSOTuner(\n        controller_factory=create_classical_smc,\n        config=config,\n        seed=42\n    )\n\n    # Set optimization bounds\n    lower_bounds = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n    upper_bounds = np.array([20.0, 20.0, 20.0, 20.0, 100.0, 10.0])\n\n    # Run optimization\n    print(\"Starting PSO optimization...\")\n    results = pso_tuner.optimize(\n        bounds=(lower_bounds, upper_bounds),\n        n_particles=50,\n        n_iterations=100,\n        verbose=True\n    )\n\n    # Display results\n    if results['success']:\n        print(f\"Optimization successful!\")\n        print(f\"Best gains: {results['best_gains']}\")\n        print(f\"Best cost: {results['best_cost']:.6f}\")\n\n        # Test optimized controller\n        controller = create_classical_smc(results['best_gains'])\n        test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n        control = controller.compute_control(test_state)\n        print(f\"Test control output: {control:.3f} N\")\n    else:\n        print(f\"Optimization failed: {results.get('message', 'Unknown error')}\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 57,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2c499bf"
  },
  {
    "id": "controller_pso_interface_api_documentation_22_609425b3",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 22,
    "code": "\"\"\"Example: Custom controller with PSO interface.\"\"\"\n\nimport numpy as np\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\n\nclass CustomSMC:\n    \"\"\"Custom SMC implementing PSO interface.\"\"\"\n\n    def __init__(self, gains: np.ndarray):\n        if len(gains) != 3:\n            raise ValueError(\"Custom SMC requires 3 gains\")\n        self.k1, self.k2, self.k3 = gains\n        self._max_force = 100.0\n\n    @property\n    def max_force(self) -> float:\n        return self._max_force\n\n    def compute_control(self, state: np.ndarray, **kwargs) -> float:\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n        # Custom control law\n        u = -self.k1 * theta1 - self.k2 * theta2 - self.k3 * x\n        return np.clip(u, -self.max_force, self.max_force)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        # All gains must be positive\n        return np.all(particles > 0, axis=1)\n\ndef optimize_custom_controller():\n    \"\"\"Optimize custom controller with PSO.\"\"\"\n\n    # Create factory function\n    def create_custom_smc(gains: np.ndarray) -> CustomSMC:\n        return CustomSMC(gains)\n\n    # Mock configuration (normally loaded from YAML)\n    class MockConfig:\n        simulation = type('obj', (object,), {'duration': 10.0, 'dt': 0.001})\n        cost_function = type('obj', (object,), {\n            'weights': type('obj', (object,), {\n                'state_error': 1.0, 'control_effort': 0.01,\n                'control_rate': 0.001, 'stability': 10.0\n            })()\n        })()\n\n    # Initialize PSO tuner\n    pso_tuner = PSOTuner(\n        controller_factory=create_custom_smc,\n        config=MockConfig(),\n        seed=42\n    )\n\n    # Optimize\n    bounds = (np.array([0.1, 0.1, 0.1]), np.array([10.0, 10.0, 10.0]))\n    results = pso_tuner.optimize(bounds=bounds, n_particles=20, n_iterations=50)\n\n    return results",
    "lines": 58,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "609425b3"
  },
  {
    "id": "controller_pso_interface_api_documentation_23_a427c057",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\ndef legacy_controller_adapter(legacy_controller_class):\n    \"\"\"Adapter for legacy controllers without PSO interface.\"\"\"\n\n    class PSO_CompatibleAdapter(PSO_ControllerInterface):\n        def __init__(self, gains: np.ndarray, **kwargs):\n            # Convert gains to legacy format\n            legacy_params = self._convert_gains_to_legacy(gains)\n            self._legacy_controller = legacy_controller_class(**legacy_params)\n            self._max_force = kwargs.get('max_force', 150.0)\n\n        @property\n        def max_force(self) -> float:\n            return self._max_force\n\n        def compute_control(self, state: np.ndarray, **kwargs) -> float:\n            return self._legacy_controller.compute_control(state, **kwargs)\n\n        def _convert_gains_to_legacy(self, gains: np.ndarray) -> dict:\n            # Implementation-specific conversion\n            pass\n\n    return PSO_CompatibleAdapter\n\n# Usage:\n# PSO_CompatibleLegacyController = legacy_controller_adapter(LegacyControllerClass)",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a427c057"
  },
  {
    "id": "controller_pso_interface_api_documentation_24_91a34761",
    "file": "docs\\controller_pso_interface_api_documentation.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_controller_api_version(controller_class: Type) -> str:\n    \"\"\"Check controller API version compatibility.\"\"\"\n\n    # Check for PSO interface compliance\n    required_methods = ['compute_control']\n    required_properties = ['max_force']\n    optional_methods = ['validate_gains']\n\n    has_required = all(hasattr(controller_class, method) for method in required_methods)\n    has_properties = all(hasattr(controller_class, prop) for prop in required_properties)\n    has_optional = any(hasattr(controller_class, method) for method in optional_methods)\n\n    if has_required and has_properties:\n        if has_optional:\n            return \"PSO_v2.0\"  # Full PSO interface\n        else:\n            return \"PSO_v1.0\"  # Basic PSO interface\n    else:\n        return \"Legacy\"     # Requires adapter",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91a34761"
  },
  {
    "id": "control_law_testing_standards_1_60c8b4ba",
    "file": "docs\\control_law_testing_standards.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass LyapunovStabilityTestSuite:\n    \"\"\"Comprehensive Lyapunov stability test suite for SMC controllers.\"\"\"\n\n    def __init__(self, controller: SMCController):\n        self.controller = controller\n        self.test_scenarios = self._generate_stability_test_scenarios()\n        self.tolerance = 1e-8\n\n    def _generate_stability_test_scenarios(self) -> List[StabilityTestScenario]:\n        \"\"\"Generate comprehensive test scenarios for stability verification.\"\"\"\n\n        scenarios = []\n\n        # Scenario 1: Small angle perturbations\n        scenarios.append(StabilityTestScenario(\n            name=\"small_angle_perturbations\",\n            initial_states=self._generate_small_angle_states(),\n            target_state=np.zeros(6),\n            test_duration=5.0,\n            mathematical_property=\"small_angle_stability\"\n        ))\n\n        # Scenario 2: Large angle perturbations\n        scenarios.append(StabilityTestScenario(\n            name=\"large_angle_perturbations\",\n            initial_states=self._generate_large_angle_states(),\n            target_state=np.zeros(6),\n            test_duration=10.0,\n            mathematical_property=\"large_angle_stability\"\n        ))\n\n        # Scenario 3: High velocity initial conditions\n        scenarios.append(StabilityTestScenario(\n            name=\"high_velocity_conditions\",\n            initial_states=self._generate_high_velocity_states(),\n            target_state=np.zeros(6),\n            test_duration=8.0,\n            mathematical_property=\"high_energy_stability\"\n        ))\n\n        # Scenario 4: Cart position perturbations\n        scenarios.append(StabilityTestScenario(\n            name=\"cart_position_perturbations\",\n            initial_states=self._generate_cart_position_states(),\n            target_state=np.zeros(6),\n            test_duration=6.0,\n            mathematical_property=\"cart_stabilization\"\n        ))\n\n        return scenarios\n\n    def test_lyapunov_stability_comprehensive(self) -> LyapunovTestResult:\n        \"\"\"Execute comprehensive Lyapunov stability testing.\"\"\"\n\n        all_test_results = []\n        stability_violations = []\n\n        for scenario in self.test_scenarios:\n            scenario_results = []\n\n            for initial_state in scenario.initial_states:\n                # Simulate system response\n                t, states = self._simulate_control_response(\n                    initial_state, scenario.target_state, scenario.test_duration\n                )\n\n                # Verify Lyapunov condition at each time step\n                for i, state in enumerate(states):\n                    lyapunov_result = self._verify_lyapunov_condition(\n                        state, scenario.target_state, t[i]\n                    )\n\n                    scenario_results.append(lyapunov_result)\n\n                    if not lyapunov_result.stability_satisfied:\n                        stability_violations.append(StabilityViolation(\n                            scenario=scenario.name,\n                            time=t[i],\n                            state=state,\n                            sliding_surface=lyapunov_result.sliding_surface,\n                            lyapunov_derivative=lyapunov_result.lyapunov_derivative,\n                            violation_magnitude=lyapunov_result.lyapunov_derivative\n                        ))\n\n            all_test_results.extend(scenario_results)\n\n        # Calculate stability metrics\n        total_test_points = len(all_test_results)\n        stable_points = len([r for r in all_test_results if r.stability_satisfied])\n        stability_percentage = (stable_points / total_test_points) * 100\n\n        return LyapunovTestResult(\n            total_test_points=total_test_points,\n            stable_points=stable_points,\n            stability_percentage=stability_percentage,\n            stability_violations=stability_violations,\n            mathematical_property_verified=stability_percentage >= 99.9,\n            test_coverage_complete=True,\n            mathematical_interpretation=self._interpret_stability_results(\n                stability_percentage, stability_violations\n            )\n        )\n\n    def _verify_lyapunov_condition(self,\n                                  state: np.ndarray,\n                                  target: np.ndarray,\n                                  time: float) -> LyapunovTestPoint:\n        \"\"\"Verify Lyapunov stability condition at a single point.\"\"\"\n\n        # Compute sliding surface value\n        sliding_surface = self.controller.compute_sliding_surface(state, target)\n\n        # Skip verification if on sliding surface (within tolerance)\n        if abs(sliding_surface) < self.tolerance:\n            return LyapunovTestPoint(\n                time=time,\n                state=state,\n                sliding_surface=sliding_surface,\n                lyapunov_derivative=0.0,\n                stability_satisfied=True,\n                on_sliding_surface=True\n            )\n\n        # Compute sliding surface time derivative\n        surface_derivative = self.controller.compute_surface_derivative(state, target)\n\n        # Lyapunov stability condition: V\u0307 = s\u00b7\u1e61 < 0\n        lyapunov_derivative = sliding_surface * surface_derivative\n        stability_satisfied = lyapunov_derivative < -self.tolerance\n\n        return LyapunovTestPoint(\n            time=time,\n            state=state,\n            sliding_surface=sliding_surface,\n            surface_derivative=surface_derivative,\n            lyapunov_derivative=lyapunov_derivative,\n            stability_satisfied=stability_satisfied,\n            on_sliding_surface=False\n        )",
    "lines": 142,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60c8b4ba"
  },
  {
    "id": "control_law_testing_standards_2_f4460563",
    "file": "docs\\control_law_testing_standards.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass SlidingSurfaceReachabilityTestSuite:\n    \"\"\"Test suite for sliding surface reachability verification.\"\"\"\n\n    def test_finite_time_reachability(self) -> ReachabilityTestResult:\n        \"\"\"Test finite-time reachability property.\"\"\"\n\n        reachability_scenarios = self._generate_reachability_scenarios()\n        test_results = []\n\n        for scenario in reachability_scenarios:\n            # Compute initial sliding surface value\n            s0 = self.controller.compute_sliding_surface(\n                scenario.initial_state, scenario.target_state\n            )\n\n            if abs(s0) < SLIDING_SURFACE_TOLERANCE:\n                continue  # Already on sliding surface\n\n            # Simulate trajectory to sliding surface\n            reaching_result = self._simulate_reaching_phase(scenario)\n\n            # Verify reachability condition throughout trajectory\n            reachability_validated = self._validate_reachability_condition(\n                reaching_result.trajectory, scenario\n            )\n\n            test_results.append(ReachabilityTestCase(\n                scenario=scenario,\n                initial_sliding_surface=s0,\n                reaching_time=reaching_result.reaching_time,\n                theoretical_bound=self._calculate_theoretical_reaching_time(s0, scenario),\n                reachability_condition_satisfied=reachability_validated,\n                trajectory_analysis=reaching_result.trajectory_analysis\n            ))\n\n        return ReachabilityTestResult(\n            test_cases=test_results,\n            overall_reachability=all(tc.reachability_condition_satisfied for tc in test_results),\n            finite_time_convergence=all(tc.reaching_time < float('inf') for tc in test_results),\n            mathematical_property_verified=self._assess_reachability_property(test_results)\n        )\n\n    def _validate_reachability_condition(self,\n                                        trajectory: List[StatePoint],\n                                        scenario: ReachabilityScenario) -> bool:\n        \"\"\"Validate reachability condition s\u00b7\u1e61 \u2264 -\u03b7|s| along trajectory.\"\"\"\n\n        for state_point in trajectory:\n            if state_point.reached_sliding_surface:\n                break  # Stop validation after reaching surface\n\n            s = self.controller.compute_sliding_surface(\n                state_point.state, scenario.target_state\n            )\n            s_dot = self.controller.compute_surface_derivative(\n                state_point.state, scenario.target_state\n            )\n\n            # Reachability condition\n            reaching_term = s * s_dot\n            required_reaching_rate = -self.controller.reaching_parameter * abs(s)\n\n            if reaching_term > required_reaching_rate + NUMERICAL_TOLERANCE:\n                return False\n\n        return True",
    "lines": 69,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4460563"
  },
  {
    "id": "control_law_testing_standards_3_06854e2d",
    "file": "docs\\control_law_testing_standards.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConvergenceRateTestSuite:\n    \"\"\"Test suite for convergence rate verification.\"\"\"\n\n    def test_exponential_convergence_rate(self) -> ConvergenceRateTestResult:\n        \"\"\"Test exponential convergence rate properties.\"\"\"\n\n        convergence_scenarios = self._generate_convergence_scenarios()\n        rate_test_results = []\n\n        for scenario in convergence_scenarios:\n            # Simulate closed-loop response\n            t, states = self._simulate_convergence_response(scenario)\n\n            # Extract convergence metric (error norm)\n            error_trajectory = [\n                np.linalg.norm(state - scenario.target_state)\n                for state in states\n            ]\n\n            # Fit exponential decay model: ||e(t)|| = ||e\u2080|| * exp(-\u03bbt)\n            convergence_analysis = self._analyze_exponential_convergence(\n                t, error_trajectory\n            )\n\n            # Verify convergence rate meets specifications\n            rate_specification_met = self._verify_convergence_rate_specification(\n                convergence_analysis, scenario.required_convergence_rate\n            )\n\n            rate_test_results.append(ConvergenceRateTestCase(\n                scenario=scenario,\n                measured_convergence_rate=convergence_analysis.convergence_rate,\n                required_convergence_rate=scenario.required_convergence_rate,\n                rate_specification_met=rate_specification_met,\n                convergence_analysis=convergence_analysis,\n                mathematical_model_fit=convergence_analysis.model_fit_quality\n            ))\n\n        return ConvergenceRateTestResult(\n            test_cases=rate_test_results,\n            overall_convergence_rate_verified=all(tc.rate_specification_met for tc in rate_test_results),\n            mathematical_property_verified=self._assess_convergence_property(rate_test_results)\n        )\n\n    def _analyze_exponential_convergence(self,\n                                        time: np.ndarray,\n                                        error_trajectory: List[float]) -> ConvergenceAnalysis:\n        \"\"\"Analyze exponential convergence characteristics.\"\"\"\n\n        error_array = np.array(error_trajectory)\n\n        # Remove zero or very small errors to avoid log issues\n        valid_indices = error_array > CONVERGENCE_TOLERANCE\n        valid_times = time[valid_indices]\n        valid_errors = error_array[valid_indices]\n\n        if len(valid_errors) < 10:\n            return ConvergenceAnalysis(\n                convergence_rate=0.0,\n                model_fit_quality=0.0,\n                exponential_fit_valid=False\n            )\n\n        # Fit exponential model: log(e(t)) = log(e\u2080) - \u03bbt\n        log_errors = np.log(valid_errors)\n        coefficients = np.polyfit(valid_times, log_errors, 1)\n        convergence_rate = -coefficients[0]  # \u03bb = -slope\n\n        # Assess model fit quality\n        predicted_log_errors = np.polyval(coefficients, valid_times)\n        r_squared = self._calculate_r_squared(log_errors, predicted_log_errors)\n\n        return ConvergenceAnalysis(\n            convergence_rate=convergence_rate,\n            initial_error=valid_errors[0],\n            final_error=valid_errors[-1],\n            model_fit_quality=r_squared,\n            exponential_fit_valid=r_squared > 0.95,\n            time_to_convergence=self._estimate_convergence_time(\n                valid_errors[0], convergence_rate\n            )\n        )",
    "lines": 85,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06854e2d"
  },
  {
    "id": "control_law_testing_standards_4_bfabcbb5",
    "file": "docs\\control_law_testing_standards.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControlSaturationTestSuite:\n    \"\"\"Safety-critical testing for control input saturation.\"\"\"\n\n    def test_control_saturation_safety(self) -> ControlSaturationTestResult:\n        \"\"\"Test control saturation under extreme conditions.\"\"\"\n\n        # Generate extreme test scenarios\n        extreme_scenarios = self._generate_extreme_test_scenarios()\n        saturation_violations = []\n        saturation_test_results = []\n\n        for scenario in extreme_scenarios:\n            # Simulate under extreme conditions\n            t, states, controls = self._simulate_with_control_history(scenario)\n\n            # Check for saturation violations\n            for i, control in enumerate(controls):\n                if abs(control) > self.max_control_force:\n                    saturation_violations.append(ControlSaturationViolation(\n                        scenario=scenario.name,\n                        time=t[i],\n                        state=states[i],\n                        control_value=control,\n                        max_allowed=self.max_control_force,\n                        violation_magnitude=abs(control) - self.max_control_force\n                    ))\n\n            # Analyze saturation behavior\n            saturation_analysis = self._analyze_saturation_behavior(controls, scenario)\n\n            saturation_test_results.append(ControlSaturationTestCase(\n                scenario=scenario,\n                max_control_used=np.max(np.abs(controls)),\n                control_margin=self.max_control_force - np.max(np.abs(controls)),\n                saturation_violations=len([v for v in saturation_violations if v.scenario == scenario.name]),\n                saturation_analysis=saturation_analysis,\n                safety_requirements_met=np.max(np.abs(controls)) <= self.max_control_force\n            ))\n\n        return ControlSaturationTestResult(\n            test_cases=saturation_test_results,\n            total_violations=len(saturation_violations),\n            safety_critical_requirements_met=len(saturation_violations) == 0,\n            control_safety_verified=all(tc.safety_requirements_met for tc in saturation_test_results)\n        )\n\n    def _generate_extreme_test_scenarios(self) -> List[ExtremeTestScenario]:\n        \"\"\"Generate extreme scenarios for safety testing.\"\"\"\n\n        scenarios = []\n\n        # Scenario 1: Maximum initial angle displacement\n        scenarios.append(ExtremeTestScenario(\n            name=\"maximum_angle_displacement\",\n            initial_state=np.array([np.pi/2, np.pi/3, 0.0, 0.0, 0.0, 0.0]),\n            disturbances=None,\n            test_duration=15.0,\n            safety_criticality=\"high\"\n        ))\n\n        # Scenario 2: High velocity initial conditions\n        scenarios.append(ExtremeTestScenario(\n            name=\"high_velocity_initial\",\n            initial_state=np.array([0.1, 0.1, 0.0, 5.0, 4.0, 2.0]),\n            disturbances=None,\n            test_duration=10.0,\n            safety_criticality=\"high\"\n        ))\n\n        # Scenario 3: Large cart displacement with angles\n        scenarios.append(ExtremeTestScenario(\n            name=\"large_cart_displacement\",\n            initial_state=np.array([0.2, 0.15, 2.0, 0.0, 0.0, 0.0]),\n            disturbances=None,\n            test_duration=12.0,\n            safety_criticality=\"medium\"\n        ))\n\n        # Scenario 4: External disturbances during control\n        scenarios.append(ExtremeTestScenario(\n            name=\"external_disturbances\",\n            initial_state=np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0]),\n            disturbances=self._create_disturbance_profile(),\n            test_duration=20.0,\n            safety_criticality=\"high\"\n        ))\n\n        return scenarios",
    "lines": 91,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfabcbb5"
  },
  {
    "id": "control_law_testing_standards_5_9d502290",
    "file": "docs\\control_law_testing_standards.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass StateConstraintTestSuite:\n    \"\"\"Test suite for state constraint verification.\"\"\"\n\n    def test_state_constraint_satisfaction(self) -> StateConstraintTestResult:\n        \"\"\"Test state constraint satisfaction under various conditions.\"\"\"\n\n        # Define state constraints\n        state_constraints = StateConstraints(\n            angle_limits=(-np.pi, np.pi),           # \u00b1180 degrees\n            velocity_limits=(-10.0, 10.0),         # \u00b110 rad/s\n            cart_position_limits=(-3.0, 3.0),      # \u00b13 meters\n            cart_velocity_limits=(-5.0, 5.0)       # \u00b15 m/s\n        )\n\n        constraint_test_scenarios = self._generate_constraint_test_scenarios()\n        constraint_violations = []\n        test_results = []\n\n        for scenario in constraint_test_scenarios:\n            # Simulate system response\n            t, states = self._simulate_control_response(scenario)\n\n            # Check constraints at each time step\n            scenario_violations = []\n            for i, state in enumerate(states):\n                violations = self._check_state_constraints(state, state_constraints)\n                if violations:\n                    for violation in violations:\n                        violation.time = t[i]\n                        violation.scenario = scenario.name\n                        scenario_violations.append(violation)\n                        constraint_violations.append(violation)\n\n            # Analyze constraint behavior\n            constraint_analysis = self._analyze_constraint_behavior(states, state_constraints)\n\n            test_results.append(StateConstraintTestCase(\n                scenario=scenario,\n                constraint_violations=scenario_violations,\n                constraint_margins=constraint_analysis.constraint_margins,\n                worst_case_states=constraint_analysis.worst_case_states,\n                constraints_satisfied=len(scenario_violations) == 0\n            ))\n\n        return StateConstraintTestResult(\n            test_cases=test_results,\n            total_constraint_violations=len(constraint_violations),\n            constraint_types_violated=self._categorize_violations(constraint_violations),\n            safety_constraints_satisfied=len(constraint_violations) == 0\n        )\n\n    def _check_state_constraints(self,\n                                state: np.ndarray,\n                                constraints: StateConstraints) -> List[StateConstraintViolation]:\n        \"\"\"Check if state violates any constraints.\"\"\"\n\n        violations = []\n        \u03b81, \u03b82, x, \u03b81_dot, \u03b82_dot, x_dot = state\n\n        # Angle constraints\n        if not (constraints.angle_limits[0] <= \u03b81 <= constraints.angle_limits[1]):\n            violations.append(StateConstraintViolation(\n                constraint_type=\"angle_limit\",\n                variable=\"theta1\",\n                value=\u03b81,\n                limit=constraints.angle_limits,\n                violation_magnitude=max(\u03b81 - constraints.angle_limits[1],\n                                      constraints.angle_limits[0] - \u03b81)\n            ))\n\n        if not (constraints.angle_limits[0] <= \u03b82 <= constraints.angle_limits[1]):\n            violations.append(StateConstraintViolation(\n                constraint_type=\"angle_limit\",\n                variable=\"theta2\",\n                value=\u03b82,\n                limit=constraints.angle_limits,\n                violation_magnitude=max(\u03b82 - constraints.angle_limits[1],\n                                      constraints.angle_limits[0] - \u03b82)\n            ))\n\n        # Velocity constraints\n        if not (constraints.velocity_limits[0] <= \u03b81_dot <= constraints.velocity_limits[1]):\n            violations.append(StateConstraintViolation(\n                constraint_type=\"velocity_limit\",\n                variable=\"theta1_dot\",\n                value=\u03b81_dot,\n                limit=constraints.velocity_limits,\n                violation_magnitude=max(\u03b81_dot - constraints.velocity_limits[1],\n                                      constraints.velocity_limits[0] - \u03b81_dot)\n            ))\n\n        # Cart position constraints\n        if not (constraints.cart_position_limits[0] <= x <= constraints.cart_position_limits[1]):\n            violations.append(StateConstraintViolation(\n                constraint_type=\"position_limit\",\n                variable=\"cart_position\",\n                value=x,\n                limit=constraints.cart_position_limits,\n                violation_magnitude=max(x - constraints.cart_position_limits[1],\n                                      constraints.cart_position_limits[0] - x)\n            ))\n\n        return violations",
    "lines": 106,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d502290"
  },
  {
    "id": "control_law_testing_standards_6_93e34d20",
    "file": "docs\\control_law_testing_standards.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControlObjectiveTestSuite:\n    \"\"\"Test suite for control objective verification.\"\"\"\n\n    def test_control_objectives_achievement(self) -> ControlObjectiveTestResult:\n        \"\"\"Test achievement of control objectives.\"\"\"\n\n        # Define control objectives\n        control_objectives = ControlObjectives(\n            settling_time_requirement=5.0,          # seconds\n            overshoot_requirement=0.1,             # 10%\n            steady_state_error_requirement=0.01,   # 1% of reference\n            rise_time_requirement=2.0              # seconds\n        )\n\n        objective_test_scenarios = self._generate_objective_test_scenarios()\n        test_results = []\n\n        for scenario in objective_test_scenarios:\n            # Simulate step response\n            t, states = self._simulate_step_response(scenario)\n\n            # Calculate performance metrics\n            performance_metrics = self._calculate_performance_metrics(\n                t, states, scenario.reference_trajectory, control_objectives\n            )\n\n            # Verify objectives\n            objectives_met = self._verify_control_objectives(\n                performance_metrics, control_objectives\n            )\n\n            test_results.append(ControlObjectiveTestCase(\n                scenario=scenario,\n                performance_metrics=performance_metrics,\n                objectives_met=objectives_met,\n                control_quality_score=self._calculate_control_quality_score(performance_metrics)\n            ))\n\n        return ControlObjectiveTestResult(\n            test_cases=test_results,\n            overall_objectives_met=all(tc.objectives_met.all_objectives_satisfied for tc in test_results),\n            performance_summary=self._summarize_performance(test_results)\n        )\n\n    def _calculate_performance_metrics(self,\n                                     time: np.ndarray,\n                                     states: np.ndarray,\n                                     reference: np.ndarray,\n                                     objectives: ControlObjectives) -> PerformanceMetrics:\n        \"\"\"Calculate comprehensive performance metrics.\"\"\"\n\n        # Extract angle trajectories (primary control variables)\n        \u03b81_trajectory = states[:, 0]\n        \u03b82_trajectory = states[:, 1]\n\n        # Calculate settling time\n        settling_time = self._calculate_settling_time(\n            time, \u03b81_trajectory, objectives.steady_state_error_requirement\n        )\n\n        # Calculate overshoot\n        overshoot = self._calculate_overshoot(\u03b81_trajectory)\n\n        # Calculate rise time\n        rise_time = self._calculate_rise_time(time, \u03b81_trajectory)\n\n        # Calculate steady-state error\n        steady_state_error = self._calculate_steady_state_error(\n            \u03b81_trajectory, reference[0]\n        )\n\n        # Calculate ISE (Integral of Squared Error)\n        ise = self._calculate_ise(time, states, reference)\n\n        # Calculate ITAE (Integral of Time-weighted Absolute Error)\n        itae = self._calculate_itae(time, states, reference)\n\n        return PerformanceMetrics(\n            settling_time=settling_time,\n            overshoot=overshoot,\n            rise_time=rise_time,\n            steady_state_error=steady_state_error,\n            ise=ise,\n            itae=itae,\n            control_energy=self._calculate_control_energy(time, states)\n        )\n\n    def _verify_control_objectives(self,\n                                  metrics: PerformanceMetrics,\n                                  objectives: ControlObjectives) -> ObjectiveVerificationResult:\n        \"\"\"Verify control objectives are met.\"\"\"\n\n        settling_time_met = metrics.settling_time <= objectives.settling_time_requirement\n        overshoot_met = metrics.overshoot <= objectives.overshoot_requirement\n        steady_state_error_met = metrics.steady_state_error <= objectives.steady_state_error_requirement\n        rise_time_met = metrics.rise_time <= objectives.rise_time_requirement\n\n        return ObjectiveVerificationResult(\n            settling_time_met=settling_time_met,\n            overshoot_met=overshoot_met,\n            steady_state_error_met=steady_state_error_met,\n            rise_time_met=rise_time_met,\n            all_objectives_satisfied=all([\n                settling_time_met, overshoot_met, steady_state_error_met, rise_time_met\n            ]),\n            objective_margins=self._calculate_objective_margins(metrics, objectives)\n        )",
    "lines": 110,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93e34d20"
  },
  {
    "id": "control_law_testing_standards_7_cb495b75",
    "file": "docs\\control_law_testing_standards.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass RobustnessTestSuite:\n    \"\"\"Test suite for control robustness verification.\"\"\"\n\n    def test_parameter_uncertainty_robustness(self) -> RobustnessTestResult:\n        \"\"\"Test robustness to parameter uncertainties.\"\"\"\n\n        # Define parameter uncertainty ranges\n        parameter_uncertainties = ParameterUncertainties(\n            mass_uncertainty=0.2,      # \u00b120%\n            length_uncertainty=0.1,    # \u00b110%\n            friction_uncertainty=0.5,  # \u00b150%\n            inertia_uncertainty=0.15   # \u00b115%\n        )\n\n        robustness_scenarios = self._generate_robustness_scenarios(parameter_uncertainties)\n        robustness_results = []\n\n        for scenario in robustness_scenarios:\n            # Test with perturbed parameters\n            perturbed_results = []\n\n            for parameter_set in scenario.parameter_variations:\n                # Create system with perturbed parameters\n                perturbed_system = self._create_perturbed_system(parameter_set)\n\n                # Test control performance\n                performance = self._test_control_performance(\n                    perturbed_system, scenario.test_conditions\n                )\n\n                perturbed_results.append(RobustnessTestCase(\n                    parameter_variation=parameter_set,\n                    performance_degradation=self._calculate_performance_degradation(\n                        performance, scenario.nominal_performance\n                    ),\n                    stability_maintained=performance.stable,\n                    robustness_margin=self._calculate_robustness_margin(performance)\n                ))\n\n            # Analyze robustness characteristics\n            robustness_analysis = self._analyze_robustness_characteristics(perturbed_results)\n\n            robustness_results.append(RobustnessScenarioResult(\n                scenario=scenario,\n                test_cases=perturbed_results,\n                robustness_analysis=robustness_analysis,\n                robust_performance_maintained=robustness_analysis.robust_performance\n            ))\n\n        return RobustnessTestResult(\n            scenario_results=robustness_results,\n            overall_robustness=all(sr.robust_performance_maintained for sr in robustness_results),\n            robustness_summary=self._summarize_robustness(robustness_results)\n        )\n\n    def test_disturbance_rejection(self) -> DisturbanceRejectionTestResult:\n        \"\"\"Test disturbance rejection capabilities.\"\"\"\n\n        disturbance_scenarios = self._generate_disturbance_scenarios()\n        rejection_results = []\n\n        for scenario in disturbance_scenarios:\n            # Simulate with disturbances\n            t, states, disturbances = self._simulate_with_disturbances(scenario)\n\n            # Analyze disturbance rejection\n            rejection_analysis = self._analyze_disturbance_rejection(\n                t, states, disturbances, scenario\n            )\n\n            rejection_results.append(DisturbanceRejectionTestCase(\n                scenario=scenario,\n                rejection_analysis=rejection_analysis,\n                disturbance_attenuation=rejection_analysis.attenuation_factor,\n                recovery_time=rejection_analysis.recovery_time,\n                disturbance_rejection_adequate=rejection_analysis.adequate_rejection\n            ))\n\n        return DisturbanceRejectionTestResult(\n            test_cases=rejection_results,\n            overall_disturbance_rejection=all(tc.disturbance_rejection_adequate for tc in rejection_results),\n            rejection_summary=self._summarize_disturbance_rejection(rejection_results)\n        )",
    "lines": 86,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb495b75"
  },
  {
    "id": "control_law_testing_standards_8_e2c2c28e",
    "file": "docs\\control_law_testing_standards.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass NumericalPrecisionTestSuite:\n    \"\"\"Test suite for numerical precision and stability.\"\"\"\n\n    def test_numerical_precision_stability(self) -> NumericalPrecisionTestResult:\n        \"\"\"Test numerical precision and stability.\"\"\"\n\n        precision_scenarios = self._generate_precision_test_scenarios()\n        precision_results = []\n\n        for scenario in precision_scenarios:\n            # Test with different numerical precisions\n            precision_test_cases = []\n\n            for precision_config in scenario.precision_configurations:\n                # Configure numerical precision\n                with numerical_precision_context(precision_config):\n                    # Run control computation\n                    computation_result = self._run_precision_test(scenario)\n\n                    # Analyze numerical behavior\n                    numerical_analysis = self._analyze_numerical_behavior(\n                        computation_result, precision_config\n                    )\n\n                    precision_test_cases.append(NumericalPrecisionTestCase(\n                        precision_config=precision_config,\n                        computation_result=computation_result,\n                        numerical_stability=numerical_analysis.stable,\n                        precision_loss=numerical_analysis.precision_loss,\n                        conditioning_issues=numerical_analysis.conditioning_issues\n                    ))\n\n            precision_results.append(NumericalPrecisionScenarioResult(\n                scenario=scenario,\n                test_cases=precision_test_cases,\n                numerical_robustness=self._assess_numerical_robustness(precision_test_cases)\n            ))\n\n        return NumericalPrecisionTestResult(\n            scenario_results=precision_results,\n            overall_numerical_stability=all(sr.numerical_robustness.stable for sr in precision_results),\n            precision_requirements_met=self._verify_precision_requirements(precision_results)\n        )\n\n    def test_matrix_conditioning(self) -> MatrixConditioningTestResult:\n        \"\"\"Test matrix conditioning in control computations.\"\"\"\n\n        # Test critical matrices in control computation\n        critical_matrices = self._identify_critical_matrices()\n        conditioning_results = []\n\n        for matrix_name, matrix_generator in critical_matrices.items():\n            # Generate test matrices under various conditions\n            matrix_test_cases = []\n\n            for test_condition in self._generate_matrix_test_conditions():\n                test_matrix = matrix_generator(test_condition)\n\n                # Analyze conditioning\n                conditioning_analysis = self._analyze_matrix_conditioning(test_matrix)\n\n                matrix_test_cases.append(MatrixConditioningTestCase(\n                    test_condition=test_condition,\n                    matrix=test_matrix,\n                    condition_number=conditioning_analysis.condition_number,\n                    conditioning_quality=conditioning_analysis.quality,\n                    numerical_stability=conditioning_analysis.stable\n                ))\n\n            conditioning_results.append(MatrixConditioningResult(\n                matrix_name=matrix_name,\n                test_cases=matrix_test_cases,\n                worst_case_conditioning=max(tc.condition_number for tc in matrix_test_cases),\n                conditioning_acceptable=all(tc.numerical_stability for tc in matrix_test_cases)\n            ))\n\n        return MatrixConditioningTestResult(\n            matrix_results=conditioning_results,\n            overall_conditioning_acceptable=all(mr.conditioning_acceptable for mr in conditioning_results)\n        )",
    "lines": 83,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2c2c28e"
  },
  {
    "id": "control_law_testing_standards_9_383866b6",
    "file": "docs\\control_law_testing_standards.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass EdgeCaseTestSuite:\n    \"\"\"Test suite for edge case verification.\"\"\"\n\n    def test_boundary_conditions(self) -> BoundaryConditionTestResult:\n        \"\"\"Test behavior at system boundaries.\"\"\"\n\n        boundary_scenarios = self._generate_boundary_scenarios()\n        boundary_results = []\n\n        for scenario in boundary_scenarios:\n            try:\n                # Test at boundary condition\n                boundary_response = self._test_boundary_response(scenario)\n\n                # Verify graceful handling\n                graceful_handling = self._verify_graceful_boundary_handling(\n                    boundary_response, scenario\n                )\n\n                boundary_results.append(BoundaryConditionTestCase(\n                    scenario=scenario,\n                    boundary_response=boundary_response,\n                    graceful_handling=graceful_handling,\n                    boundary_behavior_acceptable=graceful_handling.acceptable\n                ))\n\n            except Exception as e:\n                boundary_results.append(BoundaryConditionTestCase(\n                    scenario=scenario,\n                    exception_occurred=True,\n                    exception_message=str(e),\n                    boundary_behavior_acceptable=False\n                ))\n\n        return BoundaryConditionTestResult(\n            test_cases=boundary_results,\n            all_boundaries_handled_gracefully=all(tc.boundary_behavior_acceptable for tc in boundary_results),\n            boundary_failure_modes=self._analyze_boundary_failures(boundary_results)\n        )\n\n    def test_degenerate_conditions(self) -> DegenerateConditionTestResult:\n        \"\"\"Test behavior under degenerate conditions.\"\"\"\n\n        degenerate_scenarios = [\n            DegenerateScenario(\"zero_gains\", gains=np.zeros(6)),\n            DegenerateScenario(\"infinite_gains\", gains=np.full(6, 1e6)),\n            DegenerateScenario(\"nan_state\", initial_state=np.array([np.nan, 0, 0, 0, 0, 0])),\n            DegenerateScenario(\"inf_state\", initial_state=np.array([np.inf, 0, 0, 0, 0, 0])),\n            DegenerateScenario(\"zero_dt\", dt=0.0),\n            DegenerateScenario(\"negative_dt\", dt=-0.01)\n        ]\n\n        degenerate_results = []\n\n        for scenario in degenerate_scenarios:\n            try:\n                # Test degenerate condition\n                degenerate_response = self._test_degenerate_condition(scenario)\n\n                # Verify error handling\n                error_handling = self._verify_error_handling(degenerate_response, scenario)\n\n                degenerate_results.append(DegenerateConditionTestCase(\n                    scenario=scenario,\n                    degenerate_response=degenerate_response,\n                    error_handling=error_handling,\n                    appropriate_error_handling=error_handling.appropriate\n                ))\n\n            except Exception as e:\n                # Expected for some degenerate conditions\n                appropriate_exception = self._is_appropriate_exception(e, scenario)\n\n                degenerate_results.append(DegenerateConditionTestCase(\n                    scenario=scenario,\n                    exception_occurred=True,\n                    exception_type=type(e).__name__,\n                    exception_message=str(e),\n                    appropriate_error_handling=appropriate_exception\n                ))\n\n        return DegenerateConditionTestResult(\n            test_cases=degenerate_results,\n            all_degenerate_conditions_handled=all(tc.appropriate_error_handling for tc in degenerate_results),\n            error_handling_summary=self._summarize_error_handling(degenerate_results)\n        )",
    "lines": 89,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "383866b6"
  },
  {
    "id": "control_law_testing_standards_10_1dc0ee93",
    "file": "docs\\control_law_testing_standards.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass SystemIntegrationTestSuite:\n    \"\"\"Test suite for system-level integration verification.\"\"\"\n\n    def test_controller_dynamics_integration(self) -> ControllerDynamicsIntegrationTestResult:\n        \"\"\"Test integration between controller and dynamics models.\"\"\"\n\n        integration_scenarios = self._generate_integration_scenarios()\n        integration_results = []\n\n        for scenario in integration_scenarios:\n            # Test controller-dynamics integration\n            integration_response = self._test_controller_dynamics_integration(scenario)\n\n            # Verify consistent behavior\n            consistency_analysis = self._analyze_integration_consistency(\n                integration_response, scenario\n            )\n\n            # Check for interface issues\n            interface_validation = self._validate_component_interfaces(\n                integration_response, scenario\n            )\n\n            integration_results.append(ControllerDynamicsIntegrationTestCase(\n                scenario=scenario,\n                integration_response=integration_response,\n                consistency_analysis=consistency_analysis,\n                interface_validation=interface_validation,\n                integration_successful=consistency_analysis.consistent and interface_validation.valid\n            ))\n\n        return ControllerDynamicsIntegrationTestResult(\n            test_cases=integration_results,\n            overall_integration_successful=all(tc.integration_successful for tc in integration_results),\n            integration_issues=self._identify_integration_issues(integration_results)\n        )\n\n    def test_multi_controller_consistency(self) -> MultiControllerConsistencyTestResult:\n        \"\"\"Test consistency across different controller implementations.\"\"\"\n\n        controller_types = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n        consistency_scenarios = self._generate_consistency_test_scenarios()\n        consistency_results = []\n\n        for scenario in consistency_scenarios:\n            controller_responses = {}\n\n            # Test each controller type\n            for controller_type in controller_types:\n                try:\n                    controller = self._create_controller(controller_type, scenario.gains[controller_type])\n                    response = self._test_controller_response(controller, scenario)\n                    controller_responses[controller_type] = response\n\n                except Exception as e:\n                    controller_responses[controller_type] = ControllerTestFailure(\n                        controller_type=controller_type,\n                        error=str(e)\n                    )\n\n            # Analyze consistency across controllers\n            consistency_analysis = self._analyze_controller_consistency(\n                controller_responses, scenario\n            )\n\n            consistency_results.append(MultiControllerConsistencyTestCase(\n                scenario=scenario,\n                controller_responses=controller_responses,\n                consistency_analysis=consistency_analysis,\n                controllers_consistent=consistency_analysis.consistent\n            ))\n\n        return MultiControllerConsistencyTestResult(\n            test_cases=consistency_results,\n            overall_consistency=all(tc.controllers_consistent for tc in consistency_results),\n            consistency_summary=self._summarize_controller_consistency(consistency_results)\n        )",
    "lines": 80,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1dc0ee93"
  },
  {
    "id": "control_law_testing_standards_11_3b01a10e",
    "file": "docs\\control_law_testing_standards.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass FactoryConfigurationTestSuite:\n    \"\"\"Test suite for factory and configuration verification.\"\"\"\n\n    def test_controller_factory_consistency(self) -> FactoryConsistencyTestResult:\n        \"\"\"Test controller factory consistency and correctness.\"\"\"\n\n        factory_test_cases = []\n\n        # Test all supported controller types\n        for controller_type in SUPPORTED_CONTROLLER_TYPES:\n            # Test factory creation\n            factory_result = self._test_factory_creation(controller_type)\n\n            # Verify controller properties\n            property_verification = self._verify_controller_properties(\n                factory_result.controller, controller_type\n            )\n\n            # Test configuration consistency\n            config_consistency = self._test_configuration_consistency(\n                factory_result.controller, factory_result.configuration\n            )\n\n            factory_test_cases.append(FactoryTestCase(\n                controller_type=controller_type,\n                factory_result=factory_result,\n                property_verification=property_verification,\n                config_consistency=config_consistency,\n                factory_creation_successful=factory_result.successful and property_verification.valid\n            ))\n\n        return FactoryConsistencyTestResult(\n            test_cases=factory_test_cases,\n            all_factory_creations_successful=all(tc.factory_creation_successful for tc in factory_test_cases),\n            factory_issues=self._identify_factory_issues(factory_test_cases)\n        )\n\n    def test_configuration_validation(self) -> ConfigurationValidationTestResult:\n        \"\"\"Test configuration validation and error handling.\"\"\"\n\n        # Test valid configurations\n        valid_config_results = self._test_valid_configurations()\n\n        # Test invalid configurations\n        invalid_config_results = self._test_invalid_configurations()\n\n        # Test edge case configurations\n        edge_case_config_results = self._test_edge_case_configurations()\n\n        return ConfigurationValidationTestResult(\n            valid_config_results=valid_config_results,\n            invalid_config_results=invalid_config_results,\n            edge_case_results=edge_case_config_results,\n            configuration_validation_working=self._assess_configuration_validation(\n                valid_config_results, invalid_config_results, edge_case_config_results\n            )\n        )",
    "lines": 60,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b01a10e"
  },
  {
    "id": "control_law_testing_standards_12_597f0354",
    "file": "docs\\control_law_testing_standards.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControlLawTestOrchestrator:\n    \"\"\"Orchestrates comprehensive control law testing.\"\"\"\n\n    def __init__(self):\n        self.test_suites = {\n            'mathematical_properties': MathematicalPropertyTestSuite(),\n            'safety_critical': SafetyCriticalTestSuite(),\n            'performance': PerformanceTestSuite(),\n            'implementation': ImplementationTestSuite(),\n            'integration': IntegrationTestSuite()\n        }\n\n    def execute_comprehensive_testing(self) -> ComprehensiveTestResult:\n        \"\"\"Execute complete control law test suite.\"\"\"\n\n        test_results = {}\n\n        # Execute test suites in order of criticality\n        test_execution_order = [\n            'safety_critical',        # Most critical - must pass\n            'mathematical_properties', # Theoretical correctness\n            'implementation',         # Code correctness\n            'performance',           # Control objectives\n            'integration'            # System behavior\n        ]\n\n        for suite_name in test_execution_order:\n            test_suite = self.test_suites[suite_name]\n\n            try:\n                suite_result = test_suite.execute_full_test_suite()\n                test_results[suite_name] = suite_result\n\n                # Stop execution if safety-critical tests fail\n                if suite_name == 'safety_critical' and not suite_result.all_tests_passed:\n                    break\n\n            except Exception as e:\n                test_results[suite_name] = TestSuiteFailure(\n                    suite_name=suite_name,\n                    error=str(e),\n                    execution_time=time.time()\n                )\n\n        # Generate comprehensive report\n        comprehensive_report = self._generate_comprehensive_report(test_results)\n\n        return ComprehensiveTestResult(\n            test_suite_results=test_results,\n            comprehensive_report=comprehensive_report,\n            overall_test_status=self._determine_overall_test_status(test_results),\n            deployment_approval=self._make_deployment_decision(test_results)\n        )\n\n    def _generate_comprehensive_report(self,\n                                     test_results: Dict[str, TestSuiteResult]) -> ComprehensiveTestReport:\n        \"\"\"Generate comprehensive test report.\"\"\"\n\n        # Calculate test statistics\n        total_tests = sum(result.total_tests for result in test_results.values()\n                         if hasattr(result, 'total_tests'))\n        passed_tests = sum(result.passed_tests for result in test_results.values()\n                          if hasattr(result, 'passed_tests'))\n\n        # Analyze test coverage\n        test_coverage = self._analyze_test_coverage(test_results)\n\n        # Identify critical issues\n        critical_issues = self._identify_critical_issues(test_results)\n\n        # Generate recommendations\n        recommendations = self._generate_test_recommendations(test_results)\n\n        return ComprehensiveTestReport(\n            executive_summary=self._generate_executive_summary(test_results),\n            test_statistics=TestStatistics(\n                total_tests=total_tests,\n                passed_tests=passed_tests,\n                pass_rate=passed_tests / total_tests if total_tests > 0 else 0.0\n            ),\n            test_coverage=test_coverage,\n            critical_issues=critical_issues,\n            recommendations=recommendations,\n            mathematical_properties_verified=self._count_verified_mathematical_properties(test_results),\n            safety_requirements_met=self._assess_safety_requirements(test_results),\n            performance_objectives_achieved=self._assess_performance_objectives(test_results)\n        )",
    "lines": 90,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "597f0354"
  },
  {
    "id": "control_law_testing_standards_13_a65cde75",
    "file": "docs\\control_law_testing_standards.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass RegressionTestingFramework:\n    \"\"\"Framework for continuous regression testing.\"\"\"\n\n    def execute_regression_testing(self) -> RegressionTestResult:\n        \"\"\"Execute regression testing against baseline.\"\"\"\n\n        # Load baseline test results\n        baseline_results = self._load_baseline_results()\n\n        # Execute current test suite\n        current_results = self.test_orchestrator.execute_comprehensive_testing()\n\n        # Compare against baseline\n        regression_analysis = self._analyze_regression(baseline_results, current_results)\n\n        # Identify regressions\n        regressions = self._identify_regressions(regression_analysis)\n\n        # Generate regression report\n        regression_report = self._generate_regression_report(\n            baseline_results, current_results, regressions\n        )\n\n        return RegressionTestResult(\n            baseline_results=baseline_results,\n            current_results=current_results,\n            regression_analysis=regression_analysis,\n            regressions_detected=regressions,\n            regression_report=regression_report,\n            regression_testing_passed=len(regressions) == 0\n        )",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a65cde75"
  },
  {
    "id": "coverage_analysis_methodology_1_3fd1ecbd",
    "file": "docs\\coverage_analysis_methodology.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Mathematical Model for Isolated Coverage\ndef isolated_coverage_measurement(module_path: str) -> CoverageMetrics:\n    \"\"\"\n    Collect coverage data with failure isolation.\n\n    Mathematical Foundation:\n    Coverage C_i for module i is measured independently:\n    C_i = (L_covered / L_total) \u00d7 100\n\n    Where measurement continues even if T_i (test success) = False\n    \"\"\"\n    try:\n        # Step 1: Attempt full test execution\n        coverage_data = execute_tests_with_coverage(module_path)\n        return coverage_data\n    except TestExecutionFailure:\n        # Step 2: Fallback to partial coverage analysis\n        return analyze_partial_coverage(module_path)\n    except CoverageCollectionFailure:\n        # Step 3: Static analysis fallback\n        return static_coverage_estimation(module_path)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3fd1ecbd"
  },
  {
    "id": "coverage_analysis_methodology_2_52f82fac",
    "file": "docs\\coverage_analysis_methodology.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass FailureTolerantCoverageAnalyzer:\n    \"\"\"\n    Multi-tier coverage analysis with progressive fallback.\n\n    Tier 1: Full test execution with complete coverage\n    Tier 2: Partial test execution with isolated coverage\n    Tier 3: Static analysis with estimated coverage\n    Tier 4: Historical coverage with trend analysis\n    \"\"\"\n\n    def analyze_with_fallback(self, module: str) -> CoverageResult:\n        for tier in [self.full_analysis, self.partial_analysis,\n                    self.static_analysis, self.historical_analysis]:\n            try:\n                result = tier(module)\n                if result.confidence_level >= 0.7:\n                    return result\n            except AnalysisFailure:\n                continue\n\n        return CoverageResult(\n            coverage=0,\n            confidence_level=0.1,\n            analysis_method=\"failed_all_tiers\",\n            gaps_identified=True\n        )",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52f82fac"
  },
  {
    "id": "coverage_analysis_methodology_3_991b5955",
    "file": "docs\\coverage_analysis_methodology.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef selective_coverage_collection(test_suite: TestSuite) -> AggregatedCoverage:\n    \"\"\"\n    Collect coverage from passing tests while isolating failures.\n\n    Mathematical Model:\n    Total_Coverage = \u03a3(C_i \u00d7 S_i) / \u03a3(S_i)\n    Where C_i = coverage of test i, S_i = success indicator\n    \"\"\"\n    passing_coverage = []\n    failed_tests = []\n\n    for test in test_suite:\n        try:\n            coverage = execute_test_with_coverage(test)\n            passing_coverage.append(coverage)\n        except TestFailure as e:\n            failed_tests.append((test, e))\n            # Continue with other tests - no cascade failure\n\n    return AggregatedCoverage(\n        total_coverage=aggregate_passing_coverage(passing_coverage),\n        passing_tests=len(passing_coverage),\n        failed_tests=failed_tests,\n        coverage_confidence=calculate_confidence(passing_coverage, failed_tests)\n    )",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "991b5955"
  },
  {
    "id": "coverage_analysis_methodology_4_7376231a",
    "file": "docs\\coverage_analysis_methodology.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass ValidationGapMatrix:\n    \"\"\"\n    Systematic gap identification across validation dimensions.\n\n    Provides actionable improvement paths when quality gates fail.\n    \"\"\"\n\n    def identify_gaps(self, validation_results: ValidationResults) -> GapMatrix:\n        gaps = {\n            'theoretical': self.analyze_theoretical_gaps(validation_results.theory),\n            'performance': self.analyze_performance_gaps(validation_results.performance),\n            'coverage': self.analyze_coverage_gaps(validation_results.coverage),\n            'integration': self.analyze_integration_gaps(validation_results.integration)\n        }\n\n        return GapMatrix(\n            gaps=gaps,\n            priority_actions=self.prioritize_improvements(gaps),\n            estimated_effort=self.estimate_improvement_effort(gaps)\n        )",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7376231a"
  },
  {
    "id": "DEPENDENCIES_1_2568c868",
    "file": "docs\\DEPENDENCIES.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Uses PySwarms for PSO optimization (Miranda 2018)\n# Citation: https://doi.org/10.21105/joss.00433\nfrom pyswarms.single import GlobalBestPSO",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2568c868"
  },
  {
    "id": "deployment_validation_checklists_1_3ed18bd6",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef safety_validation_protocol():\n    \"\"\"Execute comprehensive safety validation.\"\"\"\n    results = {\n        'emergency_stop': test_emergency_stop_response(),\n        'fault_injection': test_fault_injection_scenarios(),\n        'parameter_bounds': test_parameter_boundary_detection(),\n        'stability_monitoring': test_stability_monitoring_system(),\n        'control_saturation': test_control_signal_saturation()\n    }\n\n    # All safety tests must pass\n    assert all(results.values()), f\"Safety validation failed: {results}\"\n    return True",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ed18bd6"
  },
  {
    "id": "deployment_validation_checklists_2_1b1b768d",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_test_environment():\n    \"\"\"Validate testing environment setup.\"\"\"\n    checks = {\n        'test_data_available': check_test_data_integrity(),\n        'mock_services_running': verify_mock_services(),\n        'database_isolated': validate_test_database(),\n        'ci_configuration': check_ci_pipeline(),\n        'parallel_execution': test_parallel_capability()\n    }\n\n    failed_checks = [k for k, v in checks.items() if not v]\n    if failed_checks:\n        raise EnvironmentError(f\"Test environment validation failed: {failed_checks}\")\n\n    return True",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1b1b768d"
  },
  {
    "id": "deployment_validation_checklists_3_657c58af",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_controller_factory_integration():\n    \"\"\"Test controller factory integration.\"\"\"\n    factory = ControllerFactory()\n\n    # Test all controller types\n    controller_types = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n\n    for controller_type in controller_types:\n        # Test instantiation\n        controller = factory.create_controller(controller_type, test_config)\n        assert controller is not None\n\n        # Test basic functionality\n        control_signal = controller.compute_control(test_state, test_target)\n        assert isinstance(control_signal, (int, float))\n        assert not np.isnan(control_signal)\n\n        # Test parameter validation\n        assert controller.validate_parameters()\n\n    return True",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "657c58af"
  },
  {
    "id": "deployment_validation_checklists_4_531edca1",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_pso_integration():\n    \"\"\"Test PSO optimization integration.\"\"\"\n    optimizer = PSOOptimizer()\n    controller_factory = ControllerFactory()\n\n    # Test optimization workflow\n    best_params = optimizer.optimize(\n        controller_type='classical_smc',\n        factory=controller_factory,\n        bounds=optimization_bounds\n    )\n\n    # Validate optimized parameters\n    assert all(bounds[0] <= param <= bounds[1] for param, bounds in zip(best_params, optimization_bounds))\n\n    # Test optimized controller performance\n    controller = controller_factory.create_controller('classical_smc', gains=best_params)\n    performance = evaluate_controller_performance(controller)\n    assert performance.stability_achieved\n    assert performance.settling_time < max_settling_time\n\n    return True",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "531edca1"
  },
  {
    "id": "deployment_validation_checklists_5_6f626e67",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_configuration_integration():\n    \"\"\"Test configuration system integration.\"\"\"\n    # Test configuration loading\n    config = load_config('config.yaml')\n    assert validate_configuration_schema(config)\n\n    # Test parameter propagation\n    controller = create_controller_from_config(config)\n    assert controller.gains == config['controllers']['classical_smc']['gains']\n\n    # Test configuration updates\n    updated_config = update_configuration(config, {'optimization': {'max_iterations': 200}})\n    assert updated_config['optimization']['max_iterations'] == 200\n\n    return True",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6f626e67"
  },
  {
    "id": "deployment_validation_checklists_6_c7393747",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_monitoring_integration():\n    \"\"\"Test monitoring system integration.\"\"\"\n    monitor = SystemMonitor()\n\n    # Test metric collection\n    metrics = monitor.collect_metrics()\n    required_metrics = ['cpu_usage', 'memory_usage', 'control_frequency', 'stability_margin']\n    assert all(metric in metrics for metric in required_metrics)\n\n    # Test alerting system\n    monitor.set_threshold('cpu_usage', 80.0)\n    monitor.simulate_high_cpu()\n    alerts = monitor.get_active_alerts()\n    assert any(alert.type == 'cpu_usage' for alert in alerts)\n\n    return True",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c7393747"
  },
  {
    "id": "deployment_validation_checklists_7_55a70e70",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 7,
    "code": "class PerformanceBenchmarks:\n    \"\"\"Performance benchmarking test suite.\"\"\"\n\n    def benchmark_control_loop_frequency(self):\n        \"\"\"Benchmark control loop execution frequency.\"\"\"\n        controller = ClassicalSMC()\n        target_frequency = 100  # Hz\n        test_duration = 10  # seconds\n\n        start_time = time.time()\n        iterations = 0\n\n        while time.time() - start_time < test_duration:\n            control_signal = controller.compute_control(test_state, test_target)\n            iterations += 1\n\n        actual_frequency = iterations / test_duration\n        assert actual_frequency >= 0.98 * target_frequency\n\n        return actual_frequency\n\n    def benchmark_pso_convergence_time(self):\n        \"\"\"Benchmark PSO optimization convergence time.\"\"\"\n        optimizer = PSOOptimizer()\n\n        start_time = time.time()\n        best_params = optimizer.optimize(\n            controller_type='classical_smc',\n            max_iterations=100\n        )\n        convergence_time = time.time() - start_time\n\n        assert convergence_time < 300  # 5 minutes maximum\n        assert optimizer.convergence_achieved\n\n        return convergence_time\n\n    def benchmark_memory_usage(self):\n        \"\"\"Benchmark system memory usage.\"\"\"\n        import psutil\n\n        process = psutil.Process()\n        initial_memory = process.memory_info().rss\n\n        # Run intensive simulation\n        run_extended_simulation(duration=3600)  # 1 hour\n\n        final_memory = process.memory_info().rss\n        memory_growth = final_memory - initial_memory\n\n        # Memory growth should be <10% over 1 hour\n        assert memory_growth < 0.1 * initial_memory\n\n        return memory_growth",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55a70e70"
  },
  {
    "id": "deployment_validation_checklists_8_f2949ec0",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_fault_tolerance():\n    \"\"\"Test system fault tolerance.\"\"\"\n    system = ControlSystem()\n\n    # Test controller failure recovery\n    system.inject_fault('controller_failure')\n    assert system.enter_safe_mode()\n    assert system.recover_from_fault('controller_failure')\n\n    # Test sensor failure handling\n    system.inject_fault('sensor_failure')\n    assert system.switch_to_backup_sensors()\n\n    # Test network interruption handling\n    system.inject_fault('network_interruption')\n    assert system.maintain_operation_offline()\n\n    return True",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2949ec0"
  },
  {
    "id": "deployment_validation_checklists_9_7a964773",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef run_load_testing():\n    \"\"\"Execute comprehensive load testing.\"\"\"\n    load_scenarios = [\n        {'name': 'normal_load', 'multiplier': 1.0, 'duration': 3600},\n        {'name': 'high_load', 'multiplier': 1.5, 'duration': 1800},\n        {'name': 'peak_load', 'multiplier': 2.0, 'duration': 900},\n        {'name': 'stress_load', 'multiplier': 3.0, 'duration': 300}\n    ]\n\n    results = {}\n    for scenario in load_scenarios:\n        result = execute_load_scenario(scenario)\n        results[scenario['name']] = result\n\n        # Validate performance under load\n        assert result.success_rate > 0.95\n        assert result.average_response_time < 20  # ms\n        assert result.memory_usage < 800  # MB\n\n    return results",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a964773"
  },
  {
    "id": "deployment_validation_checklists_10_0e765059",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef comprehensive_safety_testing():\n    \"\"\"Execute comprehensive safety validation.\"\"\"\n    safety_tests = {\n        'emergency_stop': test_emergency_stop_response,\n        'parameter_bounds': test_parameter_boundary_enforcement,\n        'control_saturation': test_control_signal_saturation,\n        'stability_monitoring': test_stability_monitoring_system,\n        'fault_detection': test_fault_detection_system\n    }\n\n    results = {}\n    for test_name, test_function in safety_tests.items():\n        try:\n            result = test_function()\n            results[test_name] = {'status': 'PASS', 'result': result}\n        except AssertionError as e:\n            results[test_name] = {'status': 'FAIL', 'error': str(e)}\n\n    # All safety tests must pass\n    failed_tests = [name for name, result in results.items() if result['status'] == 'FAIL']\n    if failed_tests:\n        raise SafetyValidationError(f\"Safety tests failed: {failed_tests}\")\n\n    return results",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e765059"
  },
  {
    "id": "deployment_validation_checklists_11_3d510aef",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_hardware_safety_integration():\n    \"\"\"Test hardware safety system integration.\"\"\"\n    safety_system = HardwareSafetySystem()\n\n    # Test emergency stop hardware\n    assert safety_system.test_emergency_stop_button()\n    assert safety_system.emergency_stop_response_time < 0.050  # 50ms\n\n    # Test hardware limits\n    assert safety_system.test_position_limits()\n    assert safety_system.test_velocity_limits()\n    assert safety_system.test_acceleration_limits()\n\n    # Test safety interlocks\n    assert safety_system.test_safety_interlocks()\n\n    return True",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d510aef"
  },
  {
    "id": "deployment_validation_checklists_12_61213ad3",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef execute_smoke_tests():\n    \"\"\"Execute smoke tests immediately after deployment.\"\"\"\n    smoke_tests = [\n        test_system_startup,\n        test_basic_controller_operation,\n        test_configuration_loading,\n        test_monitoring_systems,\n        test_api_endpoints,\n        test_database_connectivity\n    ]\n\n    for test in smoke_tests:\n        result = test()\n        if not result.success:\n            raise DeploymentValidationError(f\"Smoke test failed: {test.__name__}\")\n\n    return True",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61213ad3"
  },
  {
    "id": "deployment_validation_checklists_13_f691f74f",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_system_health():\n    \"\"\"Validate system health after deployment.\"\"\"\n    health_metrics = {\n        'cpu_usage': get_cpu_usage(),\n        'memory_usage': get_memory_usage(),\n        'disk_usage': get_disk_usage(),\n        'network_connectivity': test_network_connectivity(),\n        'database_health': test_database_health(),\n        'application_health': test_application_health()\n    }\n\n    # Define acceptable thresholds\n    thresholds = {\n        'cpu_usage': 80.0,\n        'memory_usage': 80.0,\n        'disk_usage': 90.0,\n        'network_connectivity': True,\n        'database_health': True,\n        'application_health': True\n    }\n\n    # Validate all metrics\n    for metric, value in health_metrics.items():\n        threshold = thresholds[metric]\n        if isinstance(threshold, bool):\n            assert value == threshold, f\"Health check failed: {metric}\"\n        else:\n            assert value <= threshold, f\"Health check failed: {metric} = {value} > {threshold}\"\n\n    return health_metrics",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f691f74f"
  },
  {
    "id": "deployment_validation_checklists_14_a003f613",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef establish_performance_baselines():\n    \"\"\"Establish performance baselines for monitoring.\"\"\"\n    baseline_tests = [\n        ('control_loop_frequency', measure_control_frequency),\n        ('response_time', measure_response_time),\n        ('memory_usage', measure_memory_usage),\n        ('cpu_utilization', measure_cpu_utilization),\n        ('optimization_time', measure_optimization_time)\n    ]\n\n    baselines = {}\n    for metric_name, measurement_func in baseline_tests:\n        baseline_value = measurement_func()\n        baselines[metric_name] = {\n            'value': baseline_value,\n            'timestamp': datetime.now().isoformat(),\n            'measurement_duration': 300  # 5 minutes\n        }\n\n    # Store baselines for future comparison\n    save_performance_baselines(baselines)\n    return baselines",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a003f613"
  },
  {
    "id": "deployment_validation_checklists_15_bd3e7be4",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_rollback_success():\n    \"\"\"Validate successful rollback to previous version.\"\"\"\n    # Check system is running\n    assert check_system_status() == 'running'\n\n    # Verify version rollback\n    current_version = get_current_version()\n    expected_version = get_previous_version()\n    assert current_version == expected_version\n\n    # Run basic functionality tests\n    assert test_basic_functionality()\n\n    # Check performance metrics\n    metrics = collect_performance_metrics()\n    assert metrics['response_time'] < 50  # ms\n    assert metrics['error_rate'] < 0.01   # 1%\n\n    return True",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd3e7be4"
  },
  {
    "id": "deployment_validation_checklists_16_cfd94aa4",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef execute_data_recovery():\n    \"\"\"Execute data recovery procedure.\"\"\"\n    recovery_steps = [\n        validate_backup_integrity,\n        stop_application_services,\n        restore_database_from_backup,\n        restore_configuration_files,\n        restore_application_data,\n        start_application_services,\n        verify_data_integrity\n    ]\n\n    for step in recovery_steps:\n        try:\n            step()\n            log_recovery_step(step.__name__, 'SUCCESS')\n        except Exception as e:\n            log_recovery_step(step.__name__, 'FAILED', str(e))\n            raise RecoveryError(f\"Recovery failed at step: {step.__name__}\")\n\n    return True",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfd94aa4"
  },
  {
    "id": "deployment_validation_checklists_17_c7272b7c",
    "file": "docs\\deployment_validation_checklists.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef execute_service_recovery():\n    \"\"\"Execute service recovery procedure.\"\"\"\n    # Identify failed services\n    failed_services = identify_failed_services()\n\n    for service in failed_services:\n        # Attempt service restart\n        restart_result = restart_service(service)\n\n        if not restart_result.success:\n            # Escalate to full recovery\n            execute_full_service_recovery(service)\n\n        # Validate service health\n        assert validate_service_health(service)\n\n    return True",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c7272b7c"
  },
  {
    "id": "DOCUMENTATION_IMPLEMENTATION_PLAN_1_92d406f8",
    "file": "docs\\DOCUMENTATION_IMPLEMENTATION_PLAN.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n   from typing import Tuple, Optional, Callable, Dict, List\n   import numpy.typing as npt\n\n   def f(state: npt.NDArray[np.float64], u: float) -> npt.NDArray[np.float64]:\n       ...",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92d406f8"
  },
  {
    "id": "DOCUMENTATION_IMPLEMENTATION_PLAN_2_bb0bcf1b",
    "file": "docs\\DOCUMENTATION_IMPLEMENTATION_PLAN.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass MPCConfig:\n    \"\"\"\n    Configuration dataclass for Model Predictive Controller.\n\n    Encapsulates MPC-specific parameters including prediction horizon,\n    control horizon, and constraint matrices.\n\n    Parameters\n    ----------\n    prediction_horizon : int\n        Number of steps to predict ahead (N).\n    control_horizon : int\n        Number of control moves to optimize (M).\n    Q : np.ndarray\n        State cost matrix (n x n).\n    R : np.ndarray\n        Control cost matrix (m x m).\n\n    Attributes\n    ----------\n    N : int\n        Prediction horizon.\n    M : int\n        Control horizon.\n\n    Examples\n    --------\n    >>> config = MPCConfig(prediction_horizon=10, control_horizon=5, Q=np.eye(4), R=np.eye(1))\n    >>> print(config.N)\n    10\n    \"\"\"",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb0bcf1b"
  },
  {
    "id": "DOCUMENTATION_IMPLEMENTATION_PLAN_3_803bbe71",
    "file": "docs\\DOCUMENTATION_IMPLEMENTATION_PLAN.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(\n    self,\n    state: np.ndarray,\n    state_vars: Dict[str, Any],\n    history: Dict[str, np.ndarray]\n) -> Tuple[float, Dict[str, Any], Dict[str, np.ndarray]]:\n    \"\"\"\n    Compute control output using hybrid adaptive super-twisting SMC.\n\n    Combines adaptive gain tuning with super-twisting algorithm for\n    chattering reduction while maintaining robustness.\n\n    Parameters\n    ----------\n    state : np.ndarray, shape (4,)\n        Current system state [x, theta1, theta2, x_dot, theta1_dot, theta2_dot].\n    state_vars : dict\n        Controller internal state variables.\n    history : dict\n        Historical data for control computation.\n\n    Returns\n    -------\n    u : float\n        Control force in Newtons.\n    updated_state_vars : dict\n        Updated controller state variables.\n    updated_history : dict\n        Updated historical data.\n\n    Notes\n    -----\n    The hybrid controller switches between adaptive and STA modes based on\n    the magnitude of the sliding surface. See [1]_ for theoretical details.\n\n    References\n    ----------\n    .. [1] Utkin, V., Guldner, J., & Shi, J. (2009). Sliding Mode Control\n           in Electro-Mechanical Systems. CRC Press.\n\n    Examples\n    --------\n    >>> controller = HybridAdaptiveSTASMC(gains=[...])\n    >>> state = np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0])\n    >>> u, state_vars, history = controller.compute_control(state, {}, {})\n    \"\"\"",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "803bbe71"
  },
  {
    "id": "EXAMPLE_VALIDATION_REPORT_1_7512bf7f",
    "file": "docs\\EXAMPLE_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# Example from CLAUDE.md - missing parent context\nadd_completed_todo(\"Create PowerShell backup script\")  # IndentationError",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7512bf7f"
  },
  {
    "id": "EXAMPLE_VALIDATION_REPORT_2_56c7cbef",
    "file": "docs\\EXAMPLE_VALIDATION_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n     # runnable: false\n     # conceptual: true\n     # context: Partial snippet from larger function",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "56c7cbef"
  },
  {
    "id": "factory_integration_documentation_1_6991cb35",
    "file": "docs\\factory_integration_documentation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any:\n    \"\"\"\n    Create a controller instance of the specified type.\n\n    Thread-safe operation with comprehensive validation.\n\n    Args:\n        controller_type: Type of controller ('classical_smc', 'sta_smc', etc.)\n        config: Configuration object (optional)\n        gains: Controller gains array (optional)\n\n    Returns:\n        Configured controller instance\n\n    Raises:\n        ValueError: If controller_type is not recognized\n        ImportError: If required dependencies are missing\n    \"\"\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6991cb35"
  },
  {
    "id": "factory_integration_documentation_2_ceda1b2c",
    "file": "docs\\factory_integration_documentation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    # ... additional controllers\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceda1b2c"
  },
  {
    "id": "factory_integration_documentation_3_61136e5c",
    "file": "docs\\factory_integration_documentation.md",
    "index": 3,
    "code": "# Thread-safe factory operations\n_factory_lock = threading.RLock()\n_LOCK_TIMEOUT = 10.0  # seconds\n\ndef create_controller(controller_type: str, config: Optional[Any] = None,\n                     gains: Optional[Union[list, np.ndarray]] = None) -> Any:\n    \"\"\"Thread-safe controller creation.\"\"\"\n    with _factory_lock:\n        # Controller creation logic protected by lock\n        return _create_controller_impl(controller_type, config, gains)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61136e5c"
  },
  {
    "id": "factory_integration_documentation_4_a4fe4286",
    "file": "docs\\factory_integration_documentation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Protocol defining the standard controller interface.\"\"\"\n\n    def compute_control(\n        self,\n        state: StateVector,\n        last_control: float,\n        history: ConfigDict\n    ) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller internal state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4fe4286"
  },
  {
    "id": "factory_integration_documentation_5_1bcd75a7",
    "file": "docs\\factory_integration_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"Wrapper for SMC controllers to provide PSO-compatible interface.\"\"\"\n\n    def __init__(self, controller, n_gains: int, controller_type: str):\n        self.controller = controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate gain particles for PSO optimization.\"\"\"\n        # Domain-specific validation logic\n        return valid_mask\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"PSO-compatible control computation interface.\"\"\"\n        # Standardized interface for PSO fitness evaluation\n        return control_output",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1bcd75a7"
  },
  {
    "id": "factory_integration_documentation_6_67e15eb9",
    "file": "docs\\factory_integration_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(\n    smc_type: SMCType,\n    gains: Union[list, np.ndarray],\n    plant_config_or_model: Optional[Any] = None,\n    **kwargs: Any\n) -> Any:\n    \"\"\"Create SMC controller optimized for PSO usage.\"\"\"\n\ndef create_pso_controller_factory(\n    smc_type: SMCType,\n    plant_config: Optional[Any] = None,\n    **kwargs: Any\n) -> Callable:\n    \"\"\"Create a PSO-optimized controller factory function.\"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "67e15eb9"
  },
  {
    "id": "factory_integration_documentation_7_4582fabc",
    "file": "docs\\factory_integration_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]:\n    \"\"\"Get PSO gain bounds for a controller type.\"\"\"\n    bounds_map = {\n        SMCType.CLASSICAL: {\n            'lower': [1.0, 1.0, 1.0, 1.0, 5.0, 0.1],   # [k1, k2, lam1, lam2, K, kd]\n            'upper': [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]\n        },\n        SMCType.ADAPTIVE: {\n            'lower': [2.0, 2.0, 1.0, 1.0, 0.5],        # [k1, k2, lam1, lam2, gamma]\n            'upper': [40.0, 40.0, 25.0, 25.0, 10.0]\n        },\n        # ... additional controller types\n    }\n    return (bounds_map[smc_type]['lower'], bounds_map[smc_type]['upper'])",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4582fabc"
  },
  {
    "id": "factory_integration_documentation_8_5db0ae5e",
    "file": "docs\\factory_integration_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef _resolve_controller_gains(\n    gains: Optional[Union[List[float], np.ndarray]],\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> List[float]:\n    \"\"\"Resolve controller gains from multiple sources.\"\"\"\n\n    # Priority 1: Explicit gains\n    if gains is not None:\n        return gains.tolist() if isinstance(gains, np.ndarray) else gains\n\n    # Priority 2: Configuration object\n    if config is not None:\n        extracted_gains = _extract_gains_from_config(config, controller_type)\n        if extracted_gains is not None:\n            return extracted_gains\n\n    # Priority 3: Registry defaults\n    return controller_info['default_gains']",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5db0ae5e"
  },
  {
    "id": "factory_integration_documentation_9_1876a3da",
    "file": "docs\\factory_integration_documentation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    \"\"\"Type-safe configuration for Classical SMC controller.\"\"\"\n\n    gains: List[float] = field()                           # [k1, k2, lam1, lam2, K, kd]\n    max_force: float = field()                             # Control saturation limit\n    boundary_layer: float = field()                        # Chattering reduction thickness\n    dt: float = field(default=0.01)                       # Control timestep\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = field(default=\"tanh\")\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after creation.\"\"\"\n        self._validate_gains()\n        self._validate_control_parameters()\n        self._validate_stability_requirements()",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1876a3da"
  },
  {
    "id": "factory_integration_documentation_10_a22ddeab",
    "file": "docs\\factory_integration_documentation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_deprecated_config(controller_type: str, params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Check for deprecated parameters and apply migrations.\"\"\"\n\n    # Handle deprecated parameter names\n    deprecated_mappings = {\n        'use_equivalent': 'enable_equivalent_control',\n        'k_gain': 'switching_gain',\n        'lambda_gains': 'surface_gains'\n    }\n\n    migrated_params = params.copy()\n    for old_param, new_param in deprecated_mappings.items():\n        if old_param in migrated_params:\n            migrated_params[new_param] = migrated_params.pop(old_param)\n            logger.warning(f\"Parameter '{old_param}' is deprecated. Use '{new_param}' instead.\")\n\n    return migrated_params",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a22ddeab"
  },
  {
    "id": "factory_integration_documentation_11_0882f6ee",
    "file": "docs\\factory_integration_documentation.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(controller_type: str, config: Optional[Any] = None,\n                     gains: Optional[Union[list, np.ndarray]] = None) -> Any:\n    \"\"\"Create controller with graceful degradation.\"\"\"\n\n    try:\n        # Attempt full configuration creation\n        controller_config = create_full_config(controller_type, config, gains)\n        return controller_class(controller_config)\n\n    except Exception as e:\n        logger.warning(f\"Full config creation failed: {e}. Using minimal config.\")\n\n        # Fallback to minimal configuration\n        minimal_config = create_minimal_config(controller_type, gains)\n        return controller_class(minimal_config)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0882f6ee"
  },
  {
    "id": "factory_integration_documentation_12_8188dc09",
    "file": "docs\\factory_integration_documentation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Optional MPC controller import with graceful fallback\ntry:\n    from src.controllers.mpc.controller import MPCController\n    MPC_AVAILABLE = True\nexcept ImportError:\n    MPCController = None\n    MPC_AVAILABLE = False\n    logger.debug(\"MPC controller not available - optional dependency\")\n\n# Registry entry with availability check\nif MPC_AVAILABLE:\n    CONTROLLER_REGISTRY['mpc_controller'] = {\n        'class': MPCController,\n        'config_class': MPCConfig,\n        # ... full configuration\n    }\nelse:\n    CONTROLLER_REGISTRY['mpc_controller'] = {\n        'class': None,\n        'config_class': UnavailableMPCConfig,\n        'description': 'Model predictive controller (unavailable)',\n        # ... placeholder configuration\n    }",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8188dc09"
  },
  {
    "id": "factory_integration_documentation_13_913e7ff8",
    "file": "docs\\factory_integration_documentation.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(\n    gains: List[float],\n    controller_info: Dict[str, Any]\n) -> None:\n    \"\"\"Validate controller gains with domain-specific checks.\"\"\"\n\n    # Basic structural validation\n    expected_count = controller_info['gain_count']\n    if len(gains) != expected_count:\n        raise ValueError(f\"Expected {expected_count} gains, got {len(gains)}\")\n\n    # Numerical validation\n    if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in gains):\n        raise ValueError(\"All gains must be finite numbers\")\n\n    # Domain-specific validation\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive for SMC stability\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "913e7ff8"
  },
  {
    "id": "factory_integration_documentation_14_62c1acf0",
    "file": "docs\\factory_integration_documentation.md",
    "index": 14,
    "code": "class SMCType(Enum):\n    \"\"\"SMC Controller types enumeration.\"\"\"\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62c1acf0"
  },
  {
    "id": "factory_integration_documentation_15_5cb17d6d",
    "file": "docs\\factory_integration_documentation.md",
    "index": 15,
    "code": "class SMCConfig:\n    \"\"\"Configuration class for SMC controllers.\"\"\"\n    def __init__(self, gains: List[float], max_force: float = 150.0,\n                 dt: float = 0.001, **kwargs: Any) -> None:\n        # Configuration initialization",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cb17d6d"
  },
  {
    "id": "factory_integration_documentation_16_9d914d17",
    "file": "docs\\factory_integration_documentation.md",
    "index": 16,
    "code": "from src.controllers.factory import create_controller\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create controller through factory\ncontroller = create_controller('classical_smc', config=sim_config)\n\n# Integrate with simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics_model,\n    config=sim_config\n)\n\nresults = runner.run_simulation()",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d914d17"
  },
  {
    "id": "factory_integration_documentation_17_e6fea8fc",
    "file": "docs\\factory_integration_documentation.md",
    "index": 17,
    "code": "from src.controllers.factory import create_pso_controller_factory, SMCType\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\n\n# Create PSO-optimized factory\ncontroller_factory = create_pso_controller_factory(\n    SMCType.CLASSICAL,\n    plant_config=config\n)\n\n# Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config\n)\n\n# Run optimization\nbest_gains, best_fitness = tuner.optimize()",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6fea8fc"
  },
  {
    "id": "factory_integration_documentation_18_92555cce",
    "file": "docs\\factory_integration_documentation.md",
    "index": 18,
    "code": "from src.config import load_config\nfrom src.controllers.factory import create_controller\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Create controller with configuration\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92555cce"
  },
  {
    "id": "factory_integration_documentation_19_a9b5e399",
    "file": "docs\\factory_integration_documentation.md",
    "index": 19,
    "code": "from src.controllers.factory import create_controller\nfrom src.hil.controller_client import ControllerClient\n\n# Create controller\ncontroller = create_controller('adaptive_smc', gains=optimized_gains)\n\n# HIL integration\nhil_client = ControllerClient(\n    controller=controller,\n    host='localhost',\n    port=8888\n)\n\nhil_client.run()",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9b5e399"
  },
  {
    "id": "factory_integration_documentation_20_3a646ae9",
    "file": "docs\\factory_integration_documentation.md",
    "index": 20,
    "code": "from src.controllers.factory import list_available_controllers\n   print(\"Available controllers:\", list_available_controllers())",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a646ae9"
  },
  {
    "id": "factory_integration_documentation_21_ffde3d55",
    "file": "docs\\factory_integration_documentation.md",
    "index": 21,
    "code": "# These aliases are supported:\n   'classic_smc' -> 'classical_smc'\n   'super_twisting' -> 'sta_smc'\n   'adaptive' -> 'adaptive_smc'\n   'hybrid' -> 'hybrid_adaptive_sta_smc'",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ffde3d55"
  },
  {
    "id": "factory_integration_documentation_22_46a8bb91",
    "file": "docs\\factory_integration_documentation.md",
    "index": 22,
    "code": "from src.controllers.factory import CONTROLLER_REGISTRY\n   controller_info = CONTROLLER_REGISTRY['mpc_controller']\n   if controller_info['class'] is None:\n       print(\"Controller not available - check dependencies\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46a8bb91"
  },
  {
    "id": "factory_integration_documentation_23_7bd3d7bc",
    "file": "docs\\factory_integration_documentation.md",
    "index": 23,
    "code": "try:\n       from src.controllers.mpc.controller import MPCController\n       print(\"MPC controller available\")\n   except ImportError as e:\n       print(f\"MPC controller not available: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7bd3d7bc"
  },
  {
    "id": "factory_integration_documentation_24_1dfebc51",
    "file": "docs\\factory_integration_documentation.md",
    "index": 24,
    "code": "from src.controllers.factory import get_default_gains\n   default_gains = get_default_gains('classical_smc')\n   print(f\"Required gains: {len(default_gains)}\")\n   print(f\"Default values: {default_gains}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1dfebc51"
  },
  {
    "id": "factory_integration_documentation_25_344cef36",
    "file": "docs\\factory_integration_documentation.md",
    "index": 25,
    "code": "import numpy as np\n\n   gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n\n   # Check basic validity\n   assert len(gains) == 6, f\"Expected 6 gains, got {len(gains)}\"\n   assert all(isinstance(g, (int, float)) for g in gains), \"All gains must be numbers\"\n   assert all(np.isfinite(g) for g in gains), \"All gains must be finite\"\n   assert all(g > 0 for g in gains), \"All gains must be positive\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "344cef36"
  },
  {
    "id": "factory_integration_documentation_26_ec8ca7f5",
    "file": "docs\\factory_integration_documentation.md",
    "index": 26,
    "code": "from src.controllers.factory import validate_smc_gains, SMCType\n\n   is_valid = validate_smc_gains(SMCType.CLASSICAL, gains)\n   if not is_valid:\n       print(\"Gains failed validation\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec8ca7f5"
  },
  {
    "id": "factory_integration_documentation_27_78cb49d4",
    "file": "docs\\factory_integration_documentation.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\n   # Priority order (highest to lowest):\n   # 1. Explicit gains parameter\n   # 2. Configuration object attributes\n   # 3. YAML configuration file\n   # 4. Registry defaults\n\n   controller = create_controller(\n       'classical_smc',\n       gains=[10, 8, 15, 12, 50, 5],  # Highest priority\n       config=config_object            # Lower priority\n   )",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "78cb49d4"
  },
  {
    "id": "factory_integration_documentation_28_c9bd56c0",
    "file": "docs\\factory_integration_documentation.md",
    "index": 28,
    "code": "# Deprecated -> Current\n   'use_equivalent' -> 'enable_equivalent_control'\n   'k_gain' -> 'switching_gain'\n   'lambda_gains' -> 'surface_gains'",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9bd56c0"
  },
  {
    "id": "factory_integration_documentation_29_384f62ae",
    "file": "docs\\factory_integration_documentation.md",
    "index": 29,
    "code": "# Classical SMC required parameters:\n   config_params = {\n       'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n       'max_force': 150.0,\n       'boundary_layer': 0.02,\n       'dt': 0.001\n   }",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "384f62ae"
  },
  {
    "id": "factory_integration_documentation_30_c42de6c3",
    "file": "docs\\factory_integration_documentation.md",
    "index": 30,
    "code": "# Instead of many concurrent calls:\n   controllers = []\n   for i in range(100):\n       controller = create_controller('classical_smc')  # Can cause contention\n       controllers.append(controller)\n\n   # Use batch creation:\n   from src.controllers.factory import create_all_smc_controllers\n   controllers = create_all_smc_controllers(gains_dict)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42de6c3"
  },
  {
    "id": "factory_integration_documentation_31_67b4706f",
    "file": "docs\\factory_integration_documentation.md",
    "index": 31,
    "code": "try:\n       controller = create_controller('classical_smc')\n   except RuntimeError as e:\n       if \"timeout\" in str(e).lower():\n           # Retry with exponential backoff\n           time.sleep(random.uniform(0.1, 0.5))\n           controller = create_controller('classical_smc')\n       else:\n           raise",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "67b4706f"
  },
  {
    "id": "factory_integration_documentation_32_de50dfc2",
    "file": "docs\\factory_integration_documentation.md",
    "index": 32,
    "code": "# Pre-create factory function (once)\n   factory = create_pso_controller_factory(SMCType.CLASSICAL)\n\n   # Use factory in PSO fitness function (many times)\n   def fitness_function(gains):\n       controller = factory(gains)  # Thread-safe, fast\n       return evaluate_performance(controller)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "de50dfc2"
  },
  {
    "id": "factory_integration_documentation_33_515ed94b",
    "file": "docs\\factory_integration_documentation.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\n# Avoid creating unnecessary controllers\ndef optimize_controller_creation():\n    # \u274c Creates many controller instances\n    controllers = []\n    for gains_set in gain_sets:\n        controller = create_controller('classical_smc', gains=gains_set)\n        controllers.append(controller)\n\n    # \u2705 Use single factory function\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n    controllers = [factory(gains_set) for gains_set in gain_sets]",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "515ed94b"
  },
  {
    "id": "factory_integration_documentation_34_547c4ba4",
    "file": "docs\\factory_integration_documentation.md",
    "index": 34,
    "code": "# example-metadata:\n# runnable: false\n\n# \u274c Imports all controllers at module level\nfrom src.controllers.factory import (\n    create_controller,\n    create_classical_smc_controller,\n    create_sta_smc_controller,\n    # ... all functions\n)\n\n# \u2705 Import only what you need\nfrom src.controllers.factory import create_controller\n\n# \u2705 Or use lazy imports\ndef get_factory_function():\n    from src.controllers.factory import create_pso_controller_factory\n    return create_pso_controller_factory",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "547c4ba4"
  },
  {
    "id": "factory_integration_documentation_35_723054ca",
    "file": "docs\\factory_integration_documentation.md",
    "index": 35,
    "code": "# Performance benchmarks (typical values)\nSingle controller creation: ~1-2 ms\nPSO factory creation: ~0.5-1 ms\nGain validation: ~0.1-0.2 ms\nConfiguration resolution: ~0.2-0.5 ms",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "723054ca"
  },
  {
    "id": "factory_integration_documentation_36_0e2c70b7",
    "file": "docs\\factory_integration_documentation.md",
    "index": 36,
    "code": "# example-metadata:\n# runnable: false\n\n# Memory-efficient patterns:\n\n# 1. Reuse factory functions\nfactory = create_pso_controller_factory(SMCType.CLASSICAL)\n# Use factory many times without recreating\n\n# 2. Use minimal configurations when possible\ncontroller = create_controller('classical_smc', gains=simple_gains)\n# Avoid complex config objects for simple use cases\n\n# 3. Batch operations\ncontrollers = create_all_smc_controllers(gains_dict)\n# More efficient than individual creation",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e2c70b7"
  },
  {
    "id": "factory_integration_documentation_37_2a97f6bb",
    "file": "docs\\factory_integration_documentation.md",
    "index": 37,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe patterns:\n\n# 1. Pre-create factories for concurrent use\nfactories = {\n    SMCType.CLASSICAL: create_pso_controller_factory(SMCType.CLASSICAL),\n    SMCType.ADAPTIVE: create_pso_controller_factory(SMCType.ADAPTIVE),\n}\n\n# 2. Use factories in parallel PSO\ndef parallel_fitness_evaluation(gains_batch):\n    factory = factories[controller_type]\n    return [evaluate_controller(factory(gains)) for gains in gains_batch]",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a97f6bb"
  },
  {
    "id": "factory_integration_documentation_38_d27002fc",
    "file": "docs\\factory_integration_documentation.md",
    "index": 38,
    "code": "# example-metadata:\n# runnable: false\n\n# Test controller creation\ndef test_controller_creation():\n    controller = create_controller('classical_smc')\n    assert hasattr(controller, 'compute_control')\n    assert hasattr(controller, 'gains')\n\n# Test gain validation\ndef test_gain_validation():\n    valid_gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n    controller = create_controller('classical_smc', gains=valid_gains)\n    assert controller.gains == valid_gains\n\n# Test error handling\ndef test_invalid_controller_type():\n    with pytest.raises(ValueError, match=\"Unknown controller type\"):\n        create_controller('invalid_controller')",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d27002fc"
  },
  {
    "id": "factory_integration_documentation_39_3c274863",
    "file": "docs\\factory_integration_documentation.md",
    "index": 39,
    "code": "# example-metadata:\n# runnable: false\n\n# Test PSO integration\ndef test_pso_integration():\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n    assert hasattr(factory, 'n_gains')\n    assert hasattr(factory, 'controller_type')\n\n    controller = factory([10, 8, 15, 12, 50, 5])\n    assert hasattr(controller, 'validate_gains')\n    assert hasattr(controller, 'compute_control')\n\n# Test configuration integration\ndef test_config_integration():\n    config = load_config(\"config.yaml\")\n    controller = create_controller('classical_smc', config=config)\n    # Verify configuration applied correctly",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c274863"
  },
  {
    "id": "factory_integration_documentation_40_8a948ebc",
    "file": "docs\\factory_integration_documentation.md",
    "index": 40,
    "code": "# Benchmark factory performance\ndef benchmark_factory_performance():\n    import time\n\n    start_time = time.time()\n    for _ in range(1000):\n        controller = create_controller('classical_smc')\n    end_time = time.time()\n\n    avg_time = (end_time - start_time) / 1000\n    assert avg_time < 0.005, f\"Factory too slow: {avg_time:.6f}s\"",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a948ebc"
  },
  {
    "id": "factory_integration_documentation_41_008c554d",
    "file": "docs\\factory_integration_documentation.md",
    "index": 41,
    "code": "# example-metadata:\n# runnable: false\n\n# Validate control theory properties\ndef test_controller_stability():\n    controller = create_controller('classical_smc', gains=[10, 8, 15, 12, 50, 5])\n\n    # Test Lyapunov stability\n    state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    control_output = controller.compute_control(state, 0.0, {})\n\n    # Verify control output bounds\n    assert abs(control_output.u) <= controller.max_force\n\n# Validate PSO optimization compatibility\ndef test_pso_optimization_compatibility():\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n\n    # Test gain bounds\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n    assert len(lower_bounds) == factory.n_gains\n    assert all(l < u for l, u in zip(lower_bounds, upper_bounds))\n\n    # Test gain validation\n    wrapper = factory([10, 8, 15, 12, 50, 5])\n    test_gains = np.array([[10, 8, 15, 12, 50, 5], [0, 0, 0, 0, 0, 0]])\n    validity = wrapper.validate_gains(test_gains)\n    assert validity[0] == True   # Valid gains\n    assert validity[1] == False  # Invalid gains (zeros)",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "008c554d"
  },
  {
    "id": "factory_integration_troubleshooting_guide_1_46ac6692",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"Factory integration quick diagnostic tool.\"\"\"\n\nimport logging\nimport traceback\nfrom src.controllers.factory import (\n    list_available_controllers,\n    list_all_controllers,\n    create_controller,\n    get_default_gains\n)\n\ndef quick_diagnosis():\n    \"\"\"Run quick diagnostic checks for factory integration.\"\"\"\n\n    print(\"=== Factory Integration Diagnostic ===\\n\")\n\n    # 1. Check available controllers\n    print(\"1. Checking available controllers...\")\n    try:\n        available = list_available_controllers()\n        all_controllers = list_all_controllers()\n        unavailable = set(all_controllers) - set(available)\n\n        print(f\"   \u2705 Available: {available}\")\n        if unavailable:\n            print(f\"   \u26a0\ufe0f  Unavailable: {unavailable}\")\n        print()\n    except Exception as e:\n        print(f\"   \u274c Controller listing failed: {e}\")\n        return False\n\n    # 2. Test basic controller creation\n    print(\"2. Testing basic controller creation...\")\n    for controller_type in available:\n        try:\n            controller = create_controller(controller_type)\n            print(f\"   \u2705 {controller_type}: Created successfully\")\n        except Exception as e:\n            print(f\"   \u274c {controller_type}: {e}\")\n    print()\n\n    # 3. Test gain access\n    print(\"3. Testing default gains access...\")\n    for controller_type in available:\n        try:\n            gains = get_default_gains(controller_type)\n            print(f\"   \u2705 {controller_type}: {len(gains)} gains\")\n        except Exception as e:\n            print(f\"   \u274c {controller_type}: {e}\")\n    print()\n\n    # 4. Test PSO integration\n    print(\"4. Testing PSO integration...\")\n    try:\n        from src.controllers.factory import create_pso_controller_factory, SMCType\n        factory = create_pso_controller_factory(SMCType.CLASSICAL)\n        test_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        controller = factory(test_gains)\n        print(f\"   \u2705 PSO factory: Working\")\n    except Exception as e:\n        print(f\"   \u274c PSO factory: {e}\")\n    print()\n\n    # 5. Test configuration integration\n    print(\"5. Testing configuration integration...\")\n    try:\n        from src.config import load_config\n        config = load_config(\"config.yaml\")\n        controller = create_controller('classical_smc', config=config)\n        print(f\"   \u2705 Configuration: Working\")\n    except Exception as e:\n        print(f\"   \u274c Configuration: {e}\")\n    print()\n\n    print(\"=== Diagnostic Complete ===\")\n    return True\n\nif __name__ == \"__main__\":\n    quick_diagnosis()",
    "lines": 83,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46ac6692"
  },
  {
    "id": "factory_integration_troubleshooting_guide_2_21f3a774",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 2,
    "code": "from src.controllers.factory import list_available_controllers\n\n# Check what's actually available\navailable = list_available_controllers()\nprint(f\"Available controllers: {available}\")\n\n# Use correct names\ncontroller = create_controller('classical_smc')  # \u2705 Correct\n# controller = create_controller('classical')    # \u274c Incorrect",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21f3a774"
  },
  {
    "id": "factory_integration_troubleshooting_guide_3_951a1b21",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# These aliases are supported for backward compatibility\nvalid_names = {\n    'classical_smc': ['classical_smc', 'classic_smc', 'smc_classical', 'smc_v1'],\n    'sta_smc': ['sta_smc', 'super_twisting', 'sta'],\n    'adaptive_smc': ['adaptive_smc', 'adaptive'],\n    'hybrid_adaptive_sta_smc': ['hybrid_adaptive_sta_smc', 'hybrid', 'hybrid_sta']\n}\n\n# Use any valid name\ncontroller = create_controller('classic_smc')      # \u2705 Alias works\ncontroller = create_controller('super_twisting')   # \u2705 Alias works",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "951a1b21"
  },
  {
    "id": "factory_integration_troubleshooting_guide_4_fc741baf",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_create_controller(preferred_types, **kwargs):\n    \"\"\"Create controller with fallback options.\"\"\"\n    available = list_available_controllers()\n\n    for controller_type in preferred_types:\n        if controller_type in available:\n            try:\n                return create_controller(controller_type, **kwargs)\n            except Exception as e:\n                print(f\"Failed to create {controller_type}: {e}\")\n                continue\n\n    raise RuntimeError(f\"None of {preferred_types} could be created. Available: {available}\")\n\n# Usage with fallbacks\ncontroller = safe_create_controller(['classical_smc', 'adaptive_smc'])",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc741baf"
  },
  {
    "id": "factory_integration_troubleshooting_guide_5_be61d323",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 5,
    "code": "def check_controller_dependencies():\n    \"\"\"Check which controllers are available and why others aren't.\"\"\"\n\n    from src.controllers.factory import CONTROLLER_REGISTRY\n\n    for controller_type, info in CONTROLLER_REGISTRY.items():\n        if info['class'] is None:\n            print(f\"\u274c {controller_type}: Class not available\")\n\n            if controller_type == 'mpc_controller':\n                print(\"   Reason: Optional MPC dependencies not installed\")\n                print(\"   Solution: pip install control-systems-toolkit\")\n        else:\n            print(f\"\u2705 {controller_type}: Available\")\n\ncheck_controller_dependencies()",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be61d323"
  },
  {
    "id": "factory_integration_troubleshooting_guide_6_c75a3f2b",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller_with_fallback(preferred_type, fallback_type, **kwargs):\n    \"\"\"Create controller with automatic fallback.\"\"\"\n\n    try:\n        return create_controller(preferred_type, **kwargs)\n    except ImportError:\n        print(f\"Warning: {preferred_type} not available, using {fallback_type}\")\n        return create_controller(fallback_type, **kwargs)\n\n# Example: Try MPC, fallback to classical SMC\ncontroller = create_controller_with_fallback(\n    'mpc_controller',\n    'classical_smc',\n    gains=[20, 15, 12, 8, 35, 5]\n)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c75a3f2b"
  },
  {
    "id": "factory_integration_troubleshooting_guide_7_d2bee562",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 7,
    "code": "def validate_controller_parameters(controller_type, **params):\n    \"\"\"Validate parameters before controller creation.\"\"\"\n\n    from src.controllers.factory import CONTROLLER_REGISTRY\n\n    controller_info = CONTROLLER_REGISTRY[controller_type]\n    required_params = controller_info['required_params']\n\n    # Check required parameters\n    missing = set(required_params) - set(params.keys())\n    if missing:\n        print(f\"Missing required parameters: {missing}\")\n        return False\n\n    # Controller-specific validation\n    if controller_type == 'classical_smc':\n        if 'gains' in params and len(params['gains']) != 6:\n            print(\"Classical SMC requires exactly 6 gains\")\n            return False\n\n        if 'boundary_layer' in params and params['boundary_layer'] <= 0:\n            print(\"Boundary layer must be positive\")\n            return False\n\n    elif controller_type == 'mpc_controller':\n        if 'horizon' in params and (not isinstance(params['horizon'], int) or params['horizon'] < 1):\n            print(\"MPC horizon must be positive integer\")\n            return False\n\n    return True\n\n# Usage\nparams = {'gains': [20, 15, 12, 8, 35, 5], 'max_force': 150.0, 'boundary_layer': 0.02}\nif validate_controller_parameters('classical_smc', **params):\n    controller = create_controller('classical_smc', **params)",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2bee562"
  },
  {
    "id": "factory_integration_troubleshooting_guide_8_bb5f3b05",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 8,
    "code": "def create_controller_robust(controller_type, **kwargs):\n    \"\"\"Create controller with robust parameter handling.\"\"\"\n\n    try:\n        # Try with provided parameters\n        return create_controller(controller_type, **kwargs)\n\n    except TypeError as e:\n        if \"unexpected keyword argument\" in str(e):\n            # Extract parameter name from error\n            import re\n            match = re.search(r\"'(\\w+)'\", str(e))\n            if match:\n                invalid_param = match.group(1)\n                print(f\"Removing invalid parameter: {invalid_param}\")\n\n                # Remove invalid parameter and retry\n                filtered_kwargs = {k: v for k, v in kwargs.items() if k != invalid_param}\n                return create_controller(controller_type, **filtered_kwargs)\n\n        raise  # Re-raise if we can't handle it\n\n# Usage\ncontroller = create_controller_robust(\n    'classical_smc',\n    gains=[20, 15, 12, 8, 35, 5],\n    invalid_param='will_be_removed'  # This will be filtered out\n)",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb5f3b05"
  },
  {
    "id": "factory_integration_troubleshooting_guide_9_20715406",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 9,
    "code": "from src.controllers.factory import create_pso_controller_factory, SMCType\n\ndef verify_pso_factory(smc_type):\n    \"\"\"Verify PSO factory has required attributes.\"\"\"\n\n    factory = create_pso_controller_factory(smc_type)\n\n    required_attributes = ['n_gains', 'controller_type', 'max_force']\n    for attr in required_attributes:\n        if not hasattr(factory, attr):\n            print(f\"\u274c Missing attribute: {attr}\")\n            return False\n        else:\n            value = getattr(factory, attr)\n            print(f\"\u2705 {attr}: {value}\")\n\n    return True\n\n# Test factory\nif verify_pso_factory(SMCType.CLASSICAL):\n    print(\"PSO factory is properly configured\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20715406"
  },
  {
    "id": "factory_integration_troubleshooting_guide_10_2efd83e6",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef debug_pso_factory_creation(smc_type):\n    \"\"\"Debug PSO factory creation step by step.\"\"\"\n\n    print(f\"Creating PSO factory for {smc_type.value}...\")\n\n    try:\n        # Step 1: Check controller availability\n        from src.controllers.factory import list_available_controllers\n        available = list_available_controllers()\n        if smc_type.value not in available:\n            print(f\"\u274c Controller {smc_type.value} not available\")\n            return None\n\n        # Step 2: Create factory\n        factory = create_pso_controller_factory(smc_type)\n        print(f\"\u2705 Factory created successfully\")\n\n        # Step 3: Test factory attributes\n        print(f\"   n_gains: {factory.n_gains}\")\n        print(f\"   controller_type: {factory.controller_type}\")\n        print(f\"   max_force: {factory.max_force}\")\n\n        # Step 4: Test factory function\n        from src.controllers.factory import get_default_gains\n        test_gains = get_default_gains(smc_type.value)\n        controller = factory(test_gains)\n        print(f\"\u2705 Factory function works\")\n\n        return factory\n\n    except Exception as e:\n        print(f\"\u274c Factory creation failed: {e}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\n# Debug factory creation\nfactory = debug_pso_factory_creation(SMCType.CLASSICAL)",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2efd83e6"
  },
  {
    "id": "factory_integration_troubleshooting_guide_11_c6d2acb7",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 11,
    "code": "from src.controllers.factory import validate_smc_gains, get_gain_bounds_for_pso, SMCType\nimport numpy as np\n\ndef debug_gain_validation(smc_type, gains):\n    \"\"\"Debug gain validation step by step.\"\"\"\n\n    print(f\"Validating gains for {smc_type.value}: {gains}\")\n\n    # Step 1: Check gain count\n    from src.controllers.factory import get_expected_gain_count\n    expected_count = get_expected_gain_count(smc_type)\n    actual_count = len(gains)\n\n    print(f\"Gain count: expected {expected_count}, got {actual_count}\")\n    if actual_count != expected_count:\n        print(f\"\u274c Wrong gain count\")\n        return False\n\n    # Step 2: Check gain types\n    for i, gain in enumerate(gains):\n        if not isinstance(gain, (int, float)):\n            print(f\"\u274c Gain {i} has wrong type: {type(gain)}\")\n            return False\n\n        if not np.isfinite(gain):\n            print(f\"\u274c Gain {i} is not finite: {gain}\")\n            return False\n\n        if gain <= 0:\n            print(f\"\u274c Gain {i} is not positive: {gain}\")\n            return False\n\n    print(\"\u2705 All validation checks passed\")\n\n    # Step 3: Check against bounds\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(smc_type)\n    for i, (gain, lower, upper) in enumerate(zip(gains, lower_bounds, upper_bounds)):\n        if not (lower <= gain <= upper):\n            print(f\"\u26a0\ufe0f  Gain {i} outside recommended bounds: {gain} not in [{lower}, {upper}]\")\n\n    return True\n\n# Test validation\ntest_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\ndebug_gain_validation(SMCType.CLASSICAL, test_gains)",
    "lines": 45,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6d2acb7"
  },
  {
    "id": "factory_integration_troubleshooting_guide_12_4d66136d",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 12,
    "code": "def fix_common_gain_issues(gains, smc_type):\n    \"\"\"Fix common gain validation issues.\"\"\"\n\n    import numpy as np\n\n    # Convert to list if numpy array\n    if isinstance(gains, np.ndarray):\n        gains = gains.tolist()\n\n    # Ensure all gains are float\n    gains = [float(g) for g in gains]\n\n    # Clamp to valid range\n    for i, gain in enumerate(gains):\n        if not np.isfinite(gain):\n            gains[i] = 1.0  # Default for invalid values\n        elif gain <= 0:\n            gains[i] = 0.1  # Minimum positive value\n        elif gain > 1000:\n            gains[i] = 100.0  # Maximum reasonable value\n\n    # Ensure correct count\n    expected_count = get_expected_gain_count(smc_type)\n    if len(gains) < expected_count:\n        # Pad with defaults\n        default_gains = get_default_gains(smc_type.value)\n        gains.extend(default_gains[len(gains):])\n    elif len(gains) > expected_count:\n        # Truncate\n        gains = gains[:expected_count]\n\n    return gains\n\n# Usage in PSO fitness function\ndef robust_fitness_function(gains):\n    \"\"\"PSO fitness function with gain fixing.\"\"\"\n\n    # Fix common issues\n    fixed_gains = fix_common_gain_issues(gains, SMCType.CLASSICAL)\n\n    # Validate\n    if not validate_smc_gains(SMCType.CLASSICAL, fixed_gains):\n        return float('inf')\n\n    # Create controller\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n    controller = factory(fixed_gains)\n\n    # Evaluate performance\n    return evaluate_controller_performance(controller)",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d66136d"
  },
  {
    "id": "factory_integration_troubleshooting_guide_13_493e4b73",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 13,
    "code": "class OptimizedPSOWorkflow:\n    \"\"\"Optimized PSO workflow for maximum performance.\"\"\"\n\n    def __init__(self, smc_type, config):\n        self.smc_type = smc_type\n        self.config = config\n\n        # Create factory once (expensive operation)\n        self.factory = create_pso_controller_factory(smc_type, plant_config=config)\n\n        # Pre-compute test scenarios\n        self.test_scenarios = self._generate_test_scenarios()\n\n        # Performance monitoring\n        self.evaluation_count = 0\n        self.evaluation_times = []\n\n    def _generate_test_scenarios(self):\n        \"\"\"Pre-generate test scenarios for consistent evaluation.\"\"\"\n        import numpy as np\n\n        scenarios = []\n\n        # Standard test points\n        test_states = [\n            np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0]),  # Small angle\n            np.array([0.3, 0.2, 0.0, 0.0, 0.0, 0.0]),   # Medium angle\n            np.array([0.0, 0.0, 0.1, 0.0, 0.0, 0.0]),   # Cart displacement\n        ]\n\n        for state in test_states:\n            scenarios.append({\n                'initial_state': state,\n                'simulation_time': 2.0,\n                'target_state': np.zeros(6)\n            })\n\n        return scenarios\n\n    def fast_fitness_function(self, gains):\n        \"\"\"Optimized fitness function for PSO.\"\"\"\n        import time\n        start_time = time.time()\n\n        try:\n            # Quick validation\n            if not validate_smc_gains(self.smc_type, gains):\n                return float('inf')\n\n            # Create controller (fast operation with pre-created factory)\n            controller = self.factory(gains)\n\n            # Fast performance evaluation\n            total_cost = 0.0\n\n            for scenario in self.test_scenarios:\n                # Simplified simulation\n                state = scenario['initial_state'].copy()\n                cost = 0.0\n\n                for _ in range(10):  # Short simulation steps\n                    control_output = controller.compute_control(state, 0.0, {})\n                    control_value = control_output.u if hasattr(control_output, 'u') else control_output\n\n                    # Simple cost computation\n                    state_cost = np.sum(state[:4]**2)  # Position and angle errors\n                    control_cost = 0.1 * control_value**2\n                    cost += state_cost + control_cost\n\n                    # Simple state update (for speed)\n                    state += 0.01 * np.random.randn(6) * 0.1  # Simplified dynamics\n\n                total_cost += cost\n\n            # Performance monitoring\n            self.evaluation_count += 1\n            elapsed = time.time() - start_time\n            self.evaluation_times.append(elapsed)\n\n            if self.evaluation_count % 100 == 0:\n                avg_time = np.mean(self.evaluation_times[-100:])\n                print(f\"Evaluation {self.evaluation_count}: {avg_time:.4f}s avg\")\n\n            return total_cost\n\n        except Exception as e:\n            return float('inf')\n\n    def run_optimization(self):\n        \"\"\"Run optimized PSO.\"\"\"\n\n        from src.optimization.algorithms.pso_optimizer import PSOTuner\n\n        # Optimized PSO parameters\n        pso_config = {\n            'n_particles': 20,      # Smaller swarm for speed\n            'max_iter': 50,         # Fewer iterations\n            'w': 0.9,\n            'c1': 2.0,\n            'c2': 2.0,\n            'early_stopping': True,\n            'patience': 10\n        }\n\n        tuner = PSOTuner(\n            controller_factory=self.fast_fitness_function,\n            config=self.config,\n            **pso_config\n        )\n\n        return tuner.optimize()\n\n# Usage\noptimizer = OptimizedPSOWorkflow(SMCType.CLASSICAL, config)\nbest_gains, best_fitness = optimizer.run_optimization()",
    "lines": 115,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "493e4b73"
  },
  {
    "id": "factory_integration_troubleshooting_guide_14_72577678",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 14,
    "code": "def debug_configuration_priority(controller_type, config=None, gains=None, **kwargs):\n    \"\"\"Debug configuration parameter resolution.\"\"\"\n\n    print(f\"Configuration priority debug for {controller_type}:\")\n    print(f\"Parameters provided:\")\n    print(f\"  gains: {gains}\")\n    print(f\"  config: {config is not None}\")\n    print(f\"  kwargs: {kwargs}\")\n    print()\n\n    # Priority 1: Explicit gains\n    if gains is not None:\n        print(f\"\u2705 Priority 1 - Explicit gains: {gains}\")\n        final_gains = gains\n    else:\n        # Priority 2: Configuration object\n        config_gains = None\n        if config is not None:\n            try:\n                # Try different config structures\n                if hasattr(config, 'controllers') and controller_type in config.controllers:\n                    controller_config = config.controllers[controller_type]\n                    if hasattr(controller_config, 'gains'):\n                        config_gains = controller_config.gains\n                        print(f\"\u2705 Priority 2 - Config gains: {config_gains}\")\n            except Exception as e:\n                print(f\"\u274c Config extraction failed: {e}\")\n\n        if config_gains is not None:\n            final_gains = config_gains\n        else:\n            # Priority 3: Registry defaults\n            from src.controllers.factory import get_default_gains\n            default_gains = get_default_gains(controller_type)\n            print(f\"\u2705 Priority 3 - Default gains: {default_gains}\")\n            final_gains = default_gains\n\n    print(f\"\\nFinal gains: {final_gains}\")\n    return final_gains\n\n# Test configuration priority\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\n\ngains = debug_configuration_priority(\n    'classical_smc',\n    config=config,\n    gains=[25, 20, 15, 10, 40, 6]  # Should override config\n)",
    "lines": 49,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72577678"
  },
  {
    "id": "factory_integration_troubleshooting_guide_15_b93a7f75",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_and_clean_config(controller_type, config):\n    \"\"\"Validate and clean configuration object.\"\"\"\n\n    cleaned_config = {}\n    warnings = []\n\n    # Extract controller-specific configuration\n    try:\n        if hasattr(config, 'controllers') and controller_type in config.controllers:\n            controller_config = config.controllers[controller_type]\n\n            # Handle different config types\n            if hasattr(controller_config, 'model_dump'):\n                # Pydantic model\n                cleaned_config = controller_config.model_dump()\n            elif isinstance(controller_config, dict):\n                # Dictionary\n                cleaned_config = controller_config.copy()\n            else:\n                # Object with attributes\n                cleaned_config = {\n                    attr: getattr(controller_config, attr)\n                    for attr in dir(controller_config)\n                    if not attr.startswith('_') and not callable(getattr(controller_config, attr))\n                }\n\n    except Exception as e:\n        warnings.append(f\"Config extraction failed: {e}\")\n\n    # Validate parameters\n    if 'gains' in cleaned_config:\n        gains = cleaned_config['gains']\n        if not isinstance(gains, (list, tuple)) or len(gains) == 0:\n            warnings.append(\"Invalid gains format\")\n            del cleaned_config['gains']\n\n    if 'max_force' in cleaned_config:\n        if not isinstance(cleaned_config['max_force'], (int, float)) or cleaned_config['max_force'] <= 0:\n            warnings.append(\"Invalid max_force value\")\n            cleaned_config['max_force'] = 150.0  # Default\n\n    # Handle deprecated parameters\n    deprecated_mappings = {\n        'use_equivalent': 'enable_equivalent_control',\n        'k_gain': 'switching_gain',\n        'lambda_gains': 'surface_gains'\n    }\n\n    for old_param, new_param in deprecated_mappings.items():\n        if old_param in cleaned_config:\n            cleaned_config[new_param] = cleaned_config.pop(old_param)\n            warnings.append(f\"Deprecated parameter '{old_param}' migrated to '{new_param}'\")\n\n    if warnings:\n        print(\"Configuration warnings:\")\n        for warning in warnings:\n            print(f\"  \u26a0\ufe0f  {warning}\")\n\n    return cleaned_config\n\n# Usage\nconfig = load_config(\"config.yaml\")\ncleaned = validate_and_clean_config('classical_smc', config)\ncontroller = create_controller('classical_smc', **cleaned)",
    "lines": 67,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b93a7f75"
  },
  {
    "id": "factory_integration_troubleshooting_guide_16_bbb16674",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 16,
    "code": "def validate_yaml_configuration(config_path):\n    \"\"\"Validate YAML configuration file.\"\"\"\n\n    import yaml\n    from pathlib import Path\n\n    print(f\"Validating configuration: {config_path}\")\n\n    # Check file exists\n    if not Path(config_path).exists():\n        print(f\"\u274c Configuration file not found: {config_path}\")\n        return False\n\n    # Check YAML syntax\n    try:\n        with open(config_path, 'r') as f:\n            config_data = yaml.safe_load(f)\n        print(\"\u2705 YAML syntax valid\")\n    except yaml.YAMLError as e:\n        print(f\"\u274c YAML syntax error: {e}\")\n        return False\n\n    # Check required sections\n    required_sections = ['controllers', 'physics', 'simulation']\n    for section in required_sections:\n        if section not in config_data:\n            print(f\"\u26a0\ufe0f  Missing section: {section}\")\n        else:\n            print(f\"\u2705 Section found: {section}\")\n\n    # Check controller configurations\n    if 'controllers' in config_data:\n        controllers = config_data['controllers']\n\n        for controller_type, controller_config in controllers.items():\n            print(f\"\\nValidating {controller_type}:\")\n\n            # Check gains\n            if 'gains' in controller_config:\n                gains = controller_config['gains']\n                if not isinstance(gains, list):\n                    print(f\"  \u274c gains must be a list, got {type(gains)}\")\n                elif len(gains) == 0:\n                    print(f\"  \u274c gains list is empty\")\n                else:\n                    print(f\"  \u2705 gains: {len(gains)} values\")\n\n            # Check numeric parameters\n            numeric_params = ['max_force', 'dt', 'boundary_layer']\n            for param in numeric_params:\n                if param in controller_config:\n                    value = controller_config[param]\n                    if not isinstance(value, (int, float)):\n                        print(f\"  \u274c {param} must be numeric, got {type(value)}\")\n                    elif value <= 0:\n                        print(f\"  \u274c {param} must be positive, got {value}\")\n                    else:\n                        print(f\"  \u2705 {param}: {value}\")\n\n    return True\n\n# Validate configuration\nvalidate_yaml_configuration(\"config.yaml\")",
    "lines": 63,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bbb16674"
  },
  {
    "id": "factory_integration_troubleshooting_guide_17_feb153e5",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 17,
    "code": "def fix_configuration_file(config_path, backup=True):\n    \"\"\"Fix common configuration file issues.\"\"\"\n\n    import yaml\n    import shutil\n    from pathlib import Path\n\n    config_file = Path(config_path)\n\n    if backup:\n        backup_file = config_file.with_suffix('.yaml.backup')\n        shutil.copy2(config_file, backup_file)\n        print(f\"Created backup: {backup_file}\")\n\n    # Load current configuration\n    with open(config_file, 'r') as f:\n        config_data = yaml.safe_load(f)\n\n    fixes_applied = []\n\n    # Fix 1: Ensure required sections exist\n    required_sections = {\n        'controllers': {},\n        'physics': {\n            'm1': 0.5, 'm2': 0.5, 'M': 2.0,\n            'l1': 0.5, 'l2': 0.5,\n            'b1': 0.1, 'b2': 0.1, 'I1': 0.1, 'I2': 0.1\n        },\n        'simulation': {\n            'duration': 5.0,\n            'dt': 0.001\n        }\n    }\n\n    for section, defaults in required_sections.items():\n        if section not in config_data:\n            config_data[section] = defaults\n            fixes_applied.append(f\"Added missing section: {section}\")\n\n    # Fix 2: Ensure controller defaults\n    controller_defaults = {\n        'classical_smc': {\n            'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n            'max_force': 150.0,\n            'boundary_layer': 0.02,\n            'dt': 0.001\n        },\n        'adaptive_smc': {\n            'gains': [25.0, 18.0, 15.0, 10.0, 4.0],\n            'max_force': 150.0,\n            'dt': 0.001\n        },\n        'sta_smc': {\n            'gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n            'max_force': 150.0,\n            'dt': 0.001\n        }\n    }\n\n    for controller_type, defaults in controller_defaults.items():\n        if controller_type not in config_data['controllers']:\n            config_data['controllers'][controller_type] = defaults\n            fixes_applied.append(f\"Added controller defaults: {controller_type}\")\n        else:\n            # Fix missing parameters\n            controller_config = config_data['controllers'][controller_type]\n            for param, default_value in defaults.items():\n                if param not in controller_config:\n                    controller_config[param] = default_value\n                    fixes_applied.append(f\"Added missing parameter {controller_type}.{param}\")\n\n    # Fix 3: Validate and fix data types\n    for controller_type, controller_config in config_data['controllers'].items():\n        if 'gains' in controller_config:\n            gains = controller_config['gains']\n            if not isinstance(gains, list):\n                # Try to convert to list\n                try:\n                    controller_config['gains'] = list(gains)\n                    fixes_applied.append(f\"Converted {controller_type}.gains to list\")\n                except:\n                    controller_config['gains'] = controller_defaults.get(controller_type, {}).get('gains', [1.0])\n                    fixes_applied.append(f\"Reset invalid {controller_type}.gains\")\n\n    # Write fixed configuration\n    with open(config_file, 'w') as f:\n        yaml.dump(config_data, f, default_flow_style=False, sort_keys=False)\n\n    if fixes_applied:\n        print(\"Fixes applied:\")\n        for fix in fixes_applied:\n            print(f\"  \u2705 {fix}\")\n    else:\n        print(\"No fixes needed\")\n\n    return len(fixes_applied) > 0\n\n# Fix configuration file\nfix_configuration_file(\"config.yaml\")",
    "lines": 99,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "feb153e5"
  },
  {
    "id": "factory_integration_troubleshooting_guide_18_867251c7",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 18,
    "code": "def profile_controller_creation(controller_type, n_iterations=100):\n    \"\"\"Profile controller creation performance.\"\"\"\n\n    import time\n    import psutil\n    import os\n\n    process = psutil.Process(os.getpid())\n\n    # Warmup\n    controller = create_controller(controller_type)\n\n    # Measure performance\n    times = []\n    memory_usage = []\n\n    for i in range(n_iterations):\n        # Measure memory before\n        mem_before = process.memory_info().rss / 1024 / 1024  # MB\n\n        # Time controller creation\n        start_time = time.time()\n        controller = create_controller(controller_type)\n        end_time = time.time()\n\n        # Measure memory after\n        mem_after = process.memory_info().rss / 1024 / 1024  # MB\n\n        times.append(end_time - start_time)\n        memory_usage.append(mem_after - mem_before)\n\n        # Cleanup\n        del controller\n\n    # Analysis\n    import numpy as np\n\n    print(f\"Performance Profile for {controller_type}:\")\n    print(f\"  Iterations: {n_iterations}\")\n    print(f\"  Average time: {np.mean(times):.4f}s\")\n    print(f\"  Std deviation: {np.std(times):.4f}s\")\n    print(f\"  Min time: {np.min(times):.4f}s\")\n    print(f\"  Max time: {np.max(times):.4f}s\")\n    print(f\"  Average memory per creation: {np.mean(memory_usage):.2f}MB\")\n\n    # Performance thresholds\n    if np.mean(times) > 0.1:\n        print(\"\u26a0\ufe0f  Controller creation is slow (>0.1s)\")\n\n    if np.mean(memory_usage) > 10:\n        print(\"\u26a0\ufe0f  High memory usage per controller (>10MB)\")\n\n    return {\n        'mean_time': np.mean(times),\n        'std_time': np.std(times),\n        'mean_memory': np.mean(memory_usage)\n    }\n\n# Profile different controllers\nfor controller_type in ['classical_smc', 'adaptive_smc', 'sta_smc']:\n    try:\n        profile_controller_creation(controller_type)\n        print()\n    except Exception as e:\n        print(f\"Profiling failed for {controller_type}: {e}\")",
    "lines": 65,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "867251c7"
  },
  {
    "id": "factory_integration_troubleshooting_guide_19_92bffdc1",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizedControllerFactory:\n    \"\"\"Optimized controller factory with caching and pooling.\"\"\"\n\n    def __init__(self):\n        self._config_cache = {}\n        self._controller_pool = {}\n        self._pool_size = 10\n\n    def _get_cached_config(self, controller_type, config_key):\n        \"\"\"Get cached configuration to avoid repeated processing.\"\"\"\n\n        cache_key = (controller_type, config_key)\n\n        if cache_key not in self._config_cache:\n            # Create and cache configuration\n            if config_key is None:\n                # Use defaults\n                from src.controllers.factory import get_default_gains\n                gains = get_default_gains(controller_type)\n                config_obj = self._create_minimal_config(controller_type, gains)\n            else:\n                # Process provided configuration\n                config_obj = self._process_config(controller_type, config_key)\n\n            self._config_cache[cache_key] = config_obj\n\n        return self._config_cache[cache_key]\n\n    def _create_minimal_config(self, controller_type, gains):\n        \"\"\"Create minimal configuration object.\"\"\"\n\n        from src.controllers.factory import CONTROLLER_REGISTRY\n\n        controller_info = CONTROLLER_REGISTRY[controller_type]\n        config_class = controller_info['config_class']\n\n        # Minimal required parameters\n        if controller_type == 'classical_smc':\n            return config_class(\n                gains=gains,\n                max_force=150.0,\n                boundary_layer=0.02,\n                dt=0.001\n            )\n        elif controller_type == 'adaptive_smc':\n            return config_class(\n                gains=gains,\n                max_force=150.0,\n                dt=0.001\n            )\n        # ... other controller types\n\n    def create_optimized_controller(self, controller_type, gains=None, config=None):\n        \"\"\"Create controller with optimization.\"\"\"\n\n        # Use pooling for identical configurations\n        pool_key = (controller_type, tuple(gains) if gains else None)\n\n        if pool_key in self._controller_pool:\n            # Reuse existing controller\n            controller = self._controller_pool[pool_key]\n            controller.reset()  # Reset state\n            return controller\n\n        # Create new controller\n        if gains is not None:\n            controller = create_controller(controller_type, gains=gains)\n        else:\n            controller = create_controller(controller_type, config=config)\n\n        # Add to pool if space available\n        if len(self._controller_pool) < self._pool_size:\n            self._controller_pool[pool_key] = controller\n\n        return controller\n\n    def clear_cache(self):\n        \"\"\"Clear all caches to free memory.\"\"\"\n        self._config_cache.clear()\n        self._controller_pool.clear()\n\n# Usage\nfactory = OptimizedControllerFactory()\n\n# Create controllers efficiently\ncontrollers = []\nfor i in range(100):\n    gains = [20.0 + i*0.1, 15.0, 12.0, 8.0, 35.0, 5.0]\n    controller = factory.create_optimized_controller('classical_smc', gains=gains)\n    controllers.append(controller)\n\n# Cleanup\nfactory.clear_cache()",
    "lines": 96,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92bffdc1"
  },
  {
    "id": "factory_integration_troubleshooting_guide_20_d30291ad",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 20,
    "code": "class MemoryMonitor:\n    \"\"\"Monitor memory usage during controller operations.\"\"\"\n\n    def __init__(self):\n        import psutil\n        import os\n        self.process = psutil.Process(os.getpid())\n        self.baseline_memory = self.get_memory_usage()\n        self.peak_memory = self.baseline_memory\n        self.measurements = []\n\n    def get_memory_usage(self):\n        \"\"\"Get current memory usage in MB.\"\"\"\n        return self.process.memory_info().rss / 1024 / 1024\n\n    def record_measurement(self, operation_name):\n        \"\"\"Record memory measurement.\"\"\"\n        current_memory = self.get_memory_usage()\n        self.peak_memory = max(self.peak_memory, current_memory)\n\n        measurement = {\n            'operation': operation_name,\n            'memory_mb': current_memory,\n            'delta_mb': current_memory - self.baseline_memory\n        }\n\n        self.measurements.append(measurement)\n\n        if measurement['delta_mb'] > 100:  # Alert if >100MB growth\n            print(f\"\u26a0\ufe0f  Memory alert: {operation_name} - {current_memory:.1f}MB (+{measurement['delta_mb']:.1f}MB)\")\n\n    def print_summary(self):\n        \"\"\"Print memory usage summary.\"\"\"\n        current_memory = self.get_memory_usage()\n        total_growth = current_memory - self.baseline_memory\n\n        print(f\"Memory Usage Summary:\")\n        print(f\"  Baseline: {self.baseline_memory:.1f}MB\")\n        print(f\"  Current: {current_memory:.1f}MB\")\n        print(f\"  Peak: {self.peak_memory:.1f}MB\")\n        print(f\"  Total growth: {total_growth:.1f}MB\")\n\n        if total_growth > 50:\n            print(\"\u26a0\ufe0f  Significant memory growth detected\")\n\n# Usage with memory monitoring\nmonitor = MemoryMonitor()\n\n# Monitor PSO operation\nfactory = create_pso_controller_factory(SMCType.CLASSICAL)\nmonitor.record_measurement(\"Factory creation\")\n\nfor i in range(1000):\n    gains = np.random.uniform(1, 50, 6)\n    controller = factory(gains)\n\n    if i % 100 == 0:\n        monitor.record_measurement(f\"Iteration {i}\")\n\n    # Explicit cleanup\n    del controller\n\nmonitor.record_measurement(\"PSO complete\")\nmonitor.print_summary()",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d30291ad"
  },
  {
    "id": "factory_integration_troubleshooting_guide_21_97288e82",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\nimport gc\nimport weakref\n\nclass ManagedControllerFactory:\n    \"\"\"Controller factory with explicit memory management.\"\"\"\n\n    def __init__(self):\n        self._weak_references = set()\n        self._creation_count = 0\n        self._cleanup_threshold = 100\n\n    def create_managed_controller(self, controller_type, **kwargs):\n        \"\"\"Create controller with memory management.\"\"\"\n\n        # Create controller\n        controller = create_controller(controller_type, **kwargs)\n\n        # Add weak reference for tracking\n        weak_ref = weakref.ref(controller, self._on_controller_deleted)\n        self._weak_references.add(weak_ref)\n\n        self._creation_count += 1\n\n        # Periodic cleanup\n        if self._creation_count % self._cleanup_threshold == 0:\n            self._perform_cleanup()\n\n        return controller\n\n    def _on_controller_deleted(self, weak_ref):\n        \"\"\"Callback when controller is garbage collected.\"\"\"\n        self._weak_references.discard(weak_ref)\n\n    def _perform_cleanup(self):\n        \"\"\"Perform explicit cleanup.\"\"\"\n\n        # Remove dead weak references\n        dead_refs = set()\n        for ref in self._weak_references:\n            if ref() is None:\n                dead_refs.add(ref)\n\n        self._weak_references -= dead_refs\n\n        # Force garbage collection\n        gc.collect()\n\n        print(f\"Cleanup: {len(self._weak_references)} controllers active, \"\n              f\"{self._creation_count} total created\")\n\n    def get_active_controller_count(self):\n        \"\"\"Get number of active controllers.\"\"\"\n        return len([ref for ref in self._weak_references if ref() is not None])\n\n    def force_cleanup(self):\n        \"\"\"Force immediate cleanup.\"\"\"\n        self._perform_cleanup()\n\n# Usage with managed factory\nmanaged_factory = ManagedControllerFactory()\n\n# PSO with memory management\ndef managed_pso_fitness(gains):\n    \"\"\"PSO fitness function with memory management.\"\"\"\n\n    controller = managed_factory.create_managed_controller('classical_smc', gains=gains)\n\n    try:\n        # Evaluate controller\n        performance = evaluate_controller_performance(controller)\n        return performance['total_cost']\n\n    finally:\n        # Explicit cleanup\n        del controller\n\n        # Periodic forced cleanup\n        if managed_factory._creation_count % 50 == 0:\n            managed_factory.force_cleanup()\n\n# Run PSO with memory management\n# ... PSO optimization code",
    "lines": 85,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "97288e82"
  },
  {
    "id": "factory_integration_troubleshooting_guide_22_bd21ebc4",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 22,
    "code": "def fix_python_path():\n    \"\"\"Fix Python path for project imports.\"\"\"\n\n    import sys\n    import os\n    from pathlib import Path\n\n    # Get project root directory\n    current_dir = Path(__file__).resolve().parent\n    project_root = current_dir\n\n    # Find project root by looking for key files\n    while project_root.parent != project_root:\n        if (project_root / 'src').exists() and (project_root / 'config.yaml').exists():\n            break\n        project_root = project_root.parent\n\n    # Add to Python path\n    if str(project_root) not in sys.path:\n        sys.path.insert(0, str(project_root))\n        print(f\"Added to Python path: {project_root}\")\n\n    # Verify imports work\n    try:\n        from src.controllers.factory import create_controller\n        print(\"\u2705 Factory imports working\")\n        return True\n    except ImportError as e:\n        print(f\"\u274c Import still failing: {e}\")\n        return False\n\n# Fix path before imports\nfix_python_path()",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd21ebc4"
  },
  {
    "id": "factory_integration_troubleshooting_guide_23_e42fb3b9",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_dependencies():\n    \"\"\"Check all project dependencies.\"\"\"\n\n    required_packages = {\n        'numpy': 'pip install numpy',\n        'scipy': 'pip install scipy',\n        'matplotlib': 'pip install matplotlib',\n        'pydantic': 'pip install pydantic',\n        'yaml': 'pip install pyyaml',\n        'numba': 'pip install numba'\n    }\n\n    optional_packages = {\n        'control': 'pip install control-systems-toolkit (for MPC)',\n        'cvxopt': 'pip install cvxopt (for optimization-based MPC)',\n        'streamlit': 'pip install streamlit (for web interface)'\n    }\n\n    print(\"Checking required dependencies:\")\n    missing_required = []\n\n    for package, install_cmd in required_packages.items():\n        try:\n            __import__(package)\n            print(f\"  \u2705 {package}\")\n        except ImportError:\n            print(f\"  \u274c {package} - {install_cmd}\")\n            missing_required.append((package, install_cmd))\n\n    print(\"\\nChecking optional dependencies:\")\n    missing_optional = []\n\n    for package, install_cmd in optional_packages.items():\n        try:\n            __import__(package)\n            print(f\"  \u2705 {package}\")\n        except ImportError:\n            print(f\"  \u26a0\ufe0f  {package} - {install_cmd}\")\n            missing_optional.append((package, install_cmd))\n\n    # Installation script\n    if missing_required:\n        print(\"\\nTo install missing required packages:\")\n        for package, install_cmd in missing_required:\n            print(f\"  {install_cmd}\")\n\n    if missing_optional:\n        print(\"\\nTo install missing optional packages:\")\n        for package, install_cmd in missing_optional:\n            print(f\"  {install_cmd}\")\n\n    return len(missing_required) == 0\n\n# Check dependencies\ncheck_dependencies()",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e42fb3b9"
  },
  {
    "id": "factory_integration_troubleshooting_guide_24_395b091b",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef debug_import_issues():\n    \"\"\"Debug specific import issues.\"\"\"\n\n    import sys\n    print(f\"Python version: {sys.version}\")\n    print(f\"Python path: {sys.path[:3]}...\")  # Show first 3 entries\n\n    # Test specific imports\n    import_tests = [\n        ('src', 'Basic src module'),\n        ('src.controllers', 'Controllers module'),\n        ('src.controllers.factory', 'Factory module'),\n        ('src.config', 'Config module'),\n        ('src.optimization.algorithms.pso_optimizer', 'PSO optimizer')\n    ]\n\n    for module_name, description in import_tests:\n        try:\n            module = __import__(module_name, fromlist=[''])\n            print(f\"\u2705 {description}: {module}\")\n        except ImportError as e:\n            print(f\"\u274c {description}: {e}\")\n\n            # Try to give specific help\n            if 'src' in module_name:\n                print(\"   Try: sys.path.insert(0, '/path/to/project/root')\")\n            elif 'mpc' in module_name.lower():\n                print(\"   Try: pip install control-systems-toolkit\")\n\ndebug_import_issues()",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "395b091b"
  },
  {
    "id": "factory_integration_troubleshooting_guide_25_17a3bea3",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\nimport threading\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef parallel_controller_creation_safe(controller_configs):\n    \"\"\"Safe parallel controller creation with reduced contention.\"\"\"\n\n    # Strategy 1: Batch creation to reduce lock contention\n    batch_size = 4  # Limit concurrent factory calls\n    results = []\n\n    def create_controller_batch(config_batch):\n        \"\"\"Create a batch of controllers.\"\"\"\n        batch_results = []\n\n        for config in config_batch:\n            try:\n                controller = create_controller(**config)\n                batch_results.append(('success', controller))\n            except Exception as e:\n                batch_results.append(('error', str(e)))\n\n        return batch_results\n\n    # Split configs into batches\n    batches = [\n        controller_configs[i:i+batch_size]\n        for i in range(0, len(controller_configs), batch_size)\n    ]\n\n    # Process batches sequentially to avoid lock contention\n    for batch in batches:\n        batch_results = create_controller_batch(batch)\n        results.extend(batch_results)\n\n    return results\n\n# Usage\nconfigs = [\n    {'controller_type': 'classical_smc', 'gains': [20, 15, 12, 8, 35, 5]},\n    {'controller_type': 'adaptive_smc', 'gains': [25, 18, 15, 10, 4]},\n    # ... more configs\n]\n\nresults = parallel_controller_creation_safe(configs)",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17a3bea3"
  },
  {
    "id": "factory_integration_troubleshooting_guide_26_1f591536",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\nclass LockFreeControllerCache:\n    \"\"\"Lock-free controller cache using pre-created controllers.\"\"\"\n\n    def __init__(self):\n        self._controller_cache = {}\n        self._cache_lock = threading.RLock()\n        self._initialized = False\n\n    def initialize_cache(self, preload_configs):\n        \"\"\"Pre-create controllers to avoid runtime factory calls.\"\"\"\n\n        if self._initialized:\n            return\n\n        print(\"Initializing controller cache...\")\n\n        # Create controllers sequentially during initialization\n        for config in preload_configs:\n            try:\n                controller = create_controller(**config)\n                cache_key = self._make_cache_key(config)\n                self._controller_cache[cache_key] = controller\n                print(f\"Cached: {config['controller_type']}\")\n            except Exception as e:\n                print(f\"Failed to cache {config}: {e}\")\n\n        self._initialized = True\n        print(f\"Cache initialized with {len(self._controller_cache)} controllers\")\n\n    def _make_cache_key(self, config):\n        \"\"\"Create cache key from configuration.\"\"\"\n        key_parts = [config['controller_type']]\n\n        if 'gains' in config:\n            key_parts.extend([f\"{g:.3f}\" for g in config['gains']])\n\n        return tuple(key_parts)\n\n    def get_controller(self, config):\n        \"\"\"Get controller from cache (thread-safe read).\"\"\"\n\n        cache_key = self._make_cache_key(config)\n\n        if cache_key in self._controller_cache:\n            # Clone controller to avoid shared state issues\n            cached_controller = self._controller_cache[cache_key]\n            return self._clone_controller(cached_controller, config)\n        else:\n            # Fallback to factory (with lock)\n            return create_controller(**config)\n\n    def _clone_controller(self, cached_controller, config):\n        \"\"\"Create a new controller with same configuration.\"\"\"\n        # Reset cached controller state\n        cached_controller.reset()\n        return cached_controller\n\n# Initialize cache at startup\ncache = LockFreeControllerCache()\n\n# Pre-define common configurations\ncommon_configs = [\n    {'controller_type': 'classical_smc', 'gains': [20, 15, 12, 8, 35, 5]},\n    {'controller_type': 'adaptive_smc', 'gains': [25, 18, 15, 10, 4]},\n    {'controller_type': 'sta_smc', 'gains': [25, 15, 20, 12, 8, 6]},\n]\n\ncache.initialize_cache(common_configs)\n\n# Use cache in PSO (thread-safe)\ndef thread_safe_fitness_function(gains):\n    \"\"\"PSO fitness function using cached controllers.\"\"\"\n\n    config = {'controller_type': 'classical_smc', 'gains': gains}\n    controller = cache.get_controller(config)\n\n    return evaluate_controller_performance(controller)",
    "lines": 80,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f591536"
  },
  {
    "id": "factory_integration_troubleshooting_guide_27_218c3349",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\nclass IsolatedControllerWrapper:\n    \"\"\"Wrapper to ensure controller state isolation.\"\"\"\n\n    def __init__(self, controller):\n        self._controller = controller\n        self._state_lock = threading.RLock()\n        self._initial_state = self._capture_state()\n\n    def _capture_state(self):\n        \"\"\"Capture controller's initial state.\"\"\"\n        state = {}\n\n        # Capture gains\n        if hasattr(self._controller, 'gains'):\n            state['gains'] = self._controller.gains.copy()\n\n        # Capture configuration\n        if hasattr(self._controller, 'config'):\n            state['config'] = self._controller.config\n\n        # Controller-specific state\n        if hasattr(self._controller, '_adaptive_gains'):\n            state['adaptive_gains'] = self._controller._adaptive_gains.copy()\n\n        return state\n\n    def reset_state(self):\n        \"\"\"Reset controller to initial state.\"\"\"\n        with self._state_lock:\n            # Reset gains\n            if 'gains' in self._initial_state:\n                self._controller.gains = self._initial_state['gains'].copy()\n\n            # Reset adaptive state\n            if hasattr(self._controller, '_adaptive_gains') and 'adaptive_gains' in self._initial_state:\n                self._controller._adaptive_gains = self._initial_state['adaptive_gains'].copy()\n\n            # Call controller's reset method\n            if hasattr(self._controller, 'reset'):\n                self._controller.reset()\n\n    def compute_control(self, state, last_control=0.0, history=None):\n        \"\"\"Thread-safe control computation.\"\"\"\n        with self._state_lock:\n            # Ensure clean state\n            if history is None:\n                history = {}\n\n            # Compute control\n            result = self._controller.compute_control(state, last_control, history)\n\n            return result\n\n    def __getattr__(self, name):\n        \"\"\"Delegate other attributes to wrapped controller.\"\"\"\n        return getattr(self._controller, name)\n\n# Usage with thread safety\ndef create_isolated_controller(controller_type, **kwargs):\n    \"\"\"Create controller with state isolation.\"\"\"\n\n    base_controller = create_controller(controller_type, **kwargs)\n    return IsolatedControllerWrapper(base_controller)\n\n# PSO with isolated controllers\ndef isolated_fitness_function(gains):\n    \"\"\"PSO fitness function with isolated controllers.\"\"\"\n\n    controller = create_isolated_controller('classical_smc', gains=gains)\n\n    try:\n        performance = evaluate_controller_performance(controller)\n        return performance['total_cost']\n    finally:\n        # Ensure clean state for next use\n        controller.reset_state()",
    "lines": 79,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "218c3349"
  },
  {
    "id": "factory_integration_troubleshooting_guide_28_5e8228e5",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"Comprehensive factory debugging suite.\"\"\"\n\nimport logging\nimport traceback\nimport time\nimport json\nfrom pathlib import Path\n\nclass FactoryDebugger:\n    \"\"\"Comprehensive debugging tools for factory integration.\"\"\"\n\n    def __init__(self, log_file='factory_debug.log'):\n        self.log_file = log_file\n        self._setup_logging()\n        self.debug_data = {}\n\n    def _setup_logging(self):\n        \"\"\"Setup detailed logging.\"\"\"\n        logging.basicConfig(\n            level=logging.DEBUG,\n            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n            handlers=[\n                logging.FileHandler(self.log_file),\n                logging.StreamHandler()\n            ]\n        )\n        self.logger = logging.getLogger('FactoryDebugger')\n\n    def debug_controller_creation(self, controller_type, **kwargs):\n        \"\"\"Debug controller creation step by step.\"\"\"\n\n        debug_info = {\n            'timestamp': time.time(),\n            'controller_type': controller_type,\n            'kwargs': kwargs,\n            'steps': [],\n            'errors': [],\n            'success': False\n        }\n\n        try:\n            # Step 1: Check controller availability\n            step1 = self._debug_step_availability(controller_type)\n            debug_info['steps'].append(step1)\n\n            if not step1['success']:\n                return debug_info\n\n            # Step 2: Parameter resolution\n            step2 = self._debug_step_parameters(controller_type, kwargs)\n            debug_info['steps'].append(step2)\n\n            # Step 3: Configuration creation\n            step3 = self._debug_step_configuration(controller_type, step2['resolved_params'])\n            debug_info['steps'].append(step3)\n\n            # Step 4: Controller instantiation\n            step4 = self._debug_step_instantiation(controller_type, step3['config'])\n            debug_info['steps'].append(step4)\n\n            if step4['success']:\n                debug_info['success'] = True\n                debug_info['controller'] = step4['controller']\n\n        except Exception as e:\n            debug_info['errors'].append({\n                'type': type(e).__name__,\n                'message': str(e),\n                'traceback': traceback.format_exc()\n            })\n\n        # Store debug data\n        self.debug_data[f\"{controller_type}_{time.time()}\"] = debug_info\n\n        return debug_info\n\n    def _debug_step_availability(self, controller_type):\n        \"\"\"Debug controller availability.\"\"\"\n        step = {'name': 'availability_check', 'success': False}\n\n        try:\n            from src.controllers.factory import list_available_controllers, CONTROLLER_REGISTRY\n\n            available = list_available_controllers()\n            step['available_controllers'] = available\n            step['controller_in_registry'] = controller_type in CONTROLLER_REGISTRY\n            step['controller_available'] = controller_type in available\n\n            if controller_type in available:\n                controller_info = CONTROLLER_REGISTRY[controller_type]\n                step['controller_info'] = {\n                    'class_available': controller_info['class'] is not None,\n                    'description': controller_info['description'],\n                    'gain_count': controller_info['gain_count']\n                }\n                step['success'] = True\n            else:\n                step['error'] = f\"Controller {controller_type} not available\"\n\n        except Exception as e:\n            step['error'] = str(e)\n\n        return step\n\n    def _debug_step_parameters(self, controller_type, kwargs):\n        \"\"\"Debug parameter resolution.\"\"\"\n        step = {'name': 'parameter_resolution', 'success': False}\n\n        try:\n            # Analyze provided parameters\n            step['provided_params'] = list(kwargs.keys())\n            step['gains_provided'] = 'gains' in kwargs\n            step['config_provided'] = 'config' in kwargs\n\n            # Check gains if provided\n            if 'gains' in kwargs:\n                gains = kwargs['gains']\n                step['gains_analysis'] = {\n                    'type': type(gains).__name__,\n                    'length': len(gains) if hasattr(gains, '__len__') else 'N/A',\n                    'all_numeric': all(isinstance(g, (int, float)) for g in gains) if hasattr(gains, '__iter__') else False\n                }\n\n            # Resolve final parameters\n            from src.controllers.factory import get_default_gains\n\n            if 'gains' not in kwargs:\n                default_gains = get_default_gains(controller_type)\n                step['using_default_gains'] = True\n                step['default_gains'] = default_gains\n                resolved_gains = default_gains\n            else:\n                resolved_gains = kwargs['gains']\n\n            step['resolved_params'] = kwargs.copy()\n            step['resolved_params']['gains'] = resolved_gains\n            step['success'] = True\n\n        except Exception as e:\n            step['error'] = str(e)\n\n        return step\n\n    def _debug_step_configuration(self, controller_type, params):\n        \"\"\"Debug configuration creation.\"\"\"\n        step = {'name': 'configuration_creation', 'success': False}\n\n        try:\n            from src.controllers.factory import CONTROLLER_REGISTRY\n\n            controller_info = CONTROLLER_REGISTRY[controller_type]\n            config_class = controller_info['config_class']\n\n            step['config_class'] = config_class.__name__\n            step['required_params'] = controller_info['required_params']\n\n            # Try to create configuration\n            if controller_type == 'classical_smc':\n                config = config_class(\n                    gains=params['gains'],\n                    max_force=params.get('max_force', 150.0),\n                    boundary_layer=params.get('boundary_layer', 0.02),\n                    dt=params.get('dt', 0.001)\n                )\n            elif controller_type == 'adaptive_smc':\n                config = config_class(\n                    gains=params['gains'],\n                    max_force=params.get('max_force', 150.0),\n                    dt=params.get('dt', 0.001)\n                )\n            # ... other controller types\n            else:\n                # Generic creation\n                config = config_class(**params)\n\n            step['config'] = config\n            step['success'] = True\n\n        except Exception as e:\n            step['error'] = str(e)\n            step['traceback'] = traceback.format_exc()\n\n        return step\n\n    def _debug_step_instantiation(self, controller_type, config):\n        \"\"\"Debug controller instantiation.\"\"\"\n        step = {'name': 'controller_instantiation', 'success': False}\n\n        try:\n            from src.controllers.factory import CONTROLLER_REGISTRY\n\n            controller_info = CONTROLLER_REGISTRY[controller_type]\n            controller_class = controller_info['class']\n\n            step['controller_class'] = controller_class.__name__\n\n            # Create controller\n            controller = controller_class(config)\n\n            # Verify controller interface\n            step['has_compute_control'] = hasattr(controller, 'compute_control')\n            step['has_reset'] = hasattr(controller, 'reset')\n            step['has_gains'] = hasattr(controller, 'gains')\n\n            if hasattr(controller, 'gains'):\n                step['controller_gains'] = controller.gains\n\n            step['controller'] = controller\n            step['success'] = True\n\n        except Exception as e:\n            step['error'] = str(e)\n            step['traceback'] = traceback.format_exc()\n\n        return step\n\n    def generate_debug_report(self, output_file='debug_report.json'):\n        \"\"\"Generate comprehensive debug report.\"\"\"\n\n        report = {\n            'timestamp': time.time(),\n            'total_debug_sessions': len(self.debug_data),\n            'sessions': self.debug_data\n        }\n\n        with open(output_file, 'w') as f:\n            json.dump(report, f, indent=2, default=str)\n\n        print(f\"Debug report saved to: {output_file}\")\n        return report\n\n# Usage\ndebugger = FactoryDebugger()\n\n# Debug controller creation\ndebug_info = debugger.debug_controller_creation(\n    'classical_smc',\n    gains=[20, 15, 12, 8, 35, 5]\n)\n\nif debug_info['success']:\n    print(\"\u2705 Controller creation successful\")\nelse:\n    print(\"\u274c Controller creation failed\")\n    for error in debug_info['errors']:\n        print(f\"Error: {error['message']}\")\n\n# Generate report\ndebugger.generate_debug_report()",
    "lines": 253,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e8228e5"
  },
  {
    "id": "factory_integration_troubleshooting_guide_29_31d737b9",
    "file": "docs\\factory_integration_troubleshooting_guide.md",
    "index": 29,
    "code": "#!/usr/bin/env python3\n\"\"\"Best practices for robust factory integration.\"\"\"\n\nclass RobustFactoryIntegration:\n    \"\"\"Demonstrates best practices for factory integration.\"\"\"\n\n    def __init__(self):\n        self.factory_cache = {}\n        self.validation_cache = {}\n\n    def create_controller_robust(self, controller_type, **kwargs):\n        \"\"\"Create controller with comprehensive robustness patterns.\"\"\"\n\n        # 1. Input validation\n        if not self._validate_inputs(controller_type, kwargs):\n            raise ValueError(\"Invalid inputs\")\n\n        # 2. Pre-creation checks\n        if not self._pre_creation_checks(controller_type):\n            raise ImportError(f\"Controller {controller_type} not available\")\n\n        # 3. Safe creation with fallbacks\n        try:\n            return self._create_with_fallbacks(controller_type, kwargs)\n        except Exception as e:\n            self._log_creation_failure(controller_type, kwargs, e)\n            raise\n\n    def _validate_inputs(self, controller_type, kwargs):\n        \"\"\"Validate inputs before creation.\"\"\"\n\n        # Check controller type\n        if not isinstance(controller_type, str) or not controller_type.strip():\n            return False\n\n        # Check gains if provided\n        if 'gains' in kwargs:\n            gains = kwargs['gains']\n\n            if not isinstance(gains, (list, tuple)):\n                return False\n\n            if not all(isinstance(g, (int, float)) for g in gains):\n                return False\n\n            if not all(g > 0 for g in gains):\n                return False\n\n        return True\n\n    def _pre_creation_checks(self, controller_type):\n        \"\"\"Perform pre-creation availability checks.\"\"\"\n\n        try:\n            from src.controllers.factory import list_available_controllers\n            available = list_available_controllers()\n            return controller_type in available\n        except Exception:\n            return False\n\n    def _create_with_fallbacks(self, controller_type, kwargs):\n        \"\"\"Create controller with fallback strategies.\"\"\"\n\n        strategies = [\n            self._strategy_direct_creation,\n            self._strategy_minimal_config,\n            self._strategy_default_parameters\n        ]\n\n        last_exception = None\n\n        for strategy in strategies:\n            try:\n                return strategy(controller_type, kwargs)\n            except Exception as e:\n                last_exception = e\n                continue\n\n        # All strategies failed\n        raise last_exception\n\n    def _strategy_direct_creation(self, controller_type, kwargs):\n        \"\"\"Strategy 1: Direct creation with provided parameters.\"\"\"\n        from src.controllers.factory import create_controller\n        return create_controller(controller_type, **kwargs)\n\n    def _strategy_minimal_config(self, controller_type, kwargs):\n        \"\"\"Strategy 2: Minimal configuration creation.\"\"\"\n\n        # Use only essential parameters\n        essential_params = {}\n\n        if 'gains' in kwargs:\n            essential_params['gains'] = kwargs['gains']\n\n        # Add required defaults\n        if controller_type == 'classical_smc':\n            essential_params.update({\n                'max_force': 150.0,\n                'boundary_layer': 0.02,\n                'dt': 0.001\n            })\n        elif controller_type == 'adaptive_smc':\n            essential_params.update({\n                'max_force': 150.0,\n                'dt': 0.001\n            })\n\n        from src.controllers.factory import create_controller\n        return create_controller(controller_type, **essential_params)\n\n    def _strategy_default_parameters(self, controller_type, kwargs):\n        \"\"\"Strategy 3: Use all default parameters.\"\"\"\n\n        from src.controllers.factory import create_controller\n        return create_controller(controller_type)\n\n    def _log_creation_failure(self, controller_type, kwargs, exception):\n        \"\"\"Log creation failure for debugging.\"\"\"\n\n        import logging\n        logger = logging.getLogger(__name__)\n\n        logger.error(f\"Controller creation failed:\")\n        logger.error(f\"  Type: {controller_type}\")\n        logger.error(f\"  Parameters: {kwargs}\")\n        logger.error(f\"  Exception: {exception}\")\n\n# Validation patterns\nclass FactoryValidationPatterns:\n    \"\"\"Common validation patterns for factory integration.\"\"\"\n\n    @staticmethod\n    def validate_controller_type(controller_type):\n        \"\"\"Validate controller type string.\"\"\"\n        if not isinstance(controller_type, str):\n            raise TypeError(\"Controller type must be string\")\n\n        if not controller_type.strip():\n            raise ValueError(\"Controller type cannot be empty\")\n\n        # Normalize\n        return controller_type.strip().lower()\n\n    @staticmethod\n    def validate_gains(gains, expected_count=None):\n        \"\"\"Validate gain array.\"\"\"\n\n        if gains is None:\n            return True  # Allow None for default gains\n\n        # Convert numpy arrays\n        if hasattr(gains, 'tolist'):\n            gains = gains.tolist()\n\n        if not isinstance(gains, (list, tuple)):\n            raise TypeError(\"Gains must be list or tuple\")\n\n        if len(gains) == 0:\n            raise ValueError(\"Gains cannot be empty\")\n\n        # Check types\n        if not all(isinstance(g, (int, float)) for g in gains):\n            raise TypeError(\"All gains must be numeric\")\n\n        # Check finite values\n        import numpy as np\n        if not all(np.isfinite(g) for g in gains):\n            raise ValueError(\"All gains must be finite\")\n\n        # Check positivity\n        if not all(g > 0 for g in gains):\n            raise ValueError(\"All gains must be positive\")\n\n        # Check count if specified\n        if expected_count is not None and len(gains) != expected_count:\n            raise ValueError(f\"Expected {expected_count} gains, got {len(gains)}\")\n\n        return True\n\n    @staticmethod\n    def validate_configuration(config, controller_type):\n        \"\"\"Validate configuration object.\"\"\"\n\n        if config is None:\n            return True  # Allow None for default config\n\n        # Check for required attributes based on controller type\n        if controller_type == 'classical_smc':\n            required_attrs = ['max_force', 'boundary_layer']\n            for attr in required_attrs:\n                if hasattr(config, attr):\n                    value = getattr(config, attr)\n                    if not isinstance(value, (int, float)) or value <= 0:\n                        raise ValueError(f\"Invalid {attr}: {value}\")\n\n        return True\n\n# Testing patterns\nclass FactoryTestingPatterns:\n    \"\"\"Testing patterns for factory integration.\"\"\"\n\n    def test_all_controllers(self):\n        \"\"\"Test all available controllers.\"\"\"\n\n        from src.controllers.factory import list_available_controllers\n\n        results = {}\n        available = list_available_controllers()\n\n        for controller_type in available:\n            try:\n                # Test with defaults\n                controller = create_controller(controller_type)\n                results[controller_type] = {'default': 'success'}\n\n                # Test with custom gains\n                from src.controllers.factory import get_default_gains\n                custom_gains = [g * 1.1 for g in get_default_gains(controller_type)]\n                controller = create_controller(controller_type, gains=custom_gains)\n                results[controller_type]['custom_gains'] = 'success'\n\n            except Exception as e:\n                results[controller_type] = {'error': str(e)}\n\n        return results\n\n    def stress_test_factory(self, n_iterations=1000):\n        \"\"\"Stress test factory with many creations.\"\"\"\n\n        import time\n\n        start_time = time.time()\n        errors = []\n\n        for i in range(n_iterations):\n            try:\n                controller = create_controller('classical_smc')\n                del controller  # Explicit cleanup\n            except Exception as e:\n                errors.append((i, str(e)))\n\n        end_time = time.time()\n\n        return {\n            'total_time': end_time - start_time,\n            'avg_time_per_creation': (end_time - start_time) / n_iterations,\n            'errors': errors,\n            'success_rate': (n_iterations - len(errors)) / n_iterations\n        }\n\n# Usage examples\nif __name__ == \"__main__\":\n    # Robust factory integration\n    robust_factory = RobustFactoryIntegration()\n\n    try:\n        controller = robust_factory.create_controller_robust(\n            'classical_smc',\n            gains=[20, 15, 12, 8, 35, 5]\n        )\n        print(\"\u2705 Robust controller creation successful\")\n    except Exception as e:\n        print(f\"\u274c Robust controller creation failed: {e}\")\n\n    # Validation patterns\n    try:\n        FactoryValidationPatterns.validate_gains([20, 15, 12, 8, 35, 5], expected_count=6)\n        print(\"\u2705 Gain validation passed\")\n    except Exception as e:\n        print(f\"\u274c Gain validation failed: {e}\")\n\n    # Testing patterns\n    tester = FactoryTestingPatterns()\n    test_results = tester.test_all_controllers()\n    print(f\"Controller test results: {test_results}\")",
    "lines": 276,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "31d737b9"
  },
  {
    "id": "fault_detection_guide_1_2d966f8c",
    "file": "docs\\fault_detection_guide.md",
    "index": 1,
    "code": "from src.fault_detection.fdi import FDIsystem\nfrom src.core.dynamics import DoublePendulum\nimport numpy as np\n\n# Create FDI system with calibrated threshold and hysteresis\nfdi = FDIsystem(\n    residual_threshold=0.150,     # Statistically calibrated (Issue #18)\n    persistence_counter=10,\n    residual_states=[0, 1, 2],    # Monitor position and angles\n    hysteresis_enabled=True,      # Prevent oscillation near threshold\n    hysteresis_upper=0.165,\n    hysteresis_lower=0.135\n)\n\n# Create dynamics model for predictions\ndynamics = DoublePendulum()\n\n# Simulation loop with FDI monitoring\nfor t in np.arange(0, 10, 0.001):\n    # Get measurement (in practice, from sensors)\n    x_measured = get_sensor_data()\n\n    # Get control input\n    u = controller.compute_control(x_measured, x_ref, t)\n\n    # FDI check\n    status, residual_norm = fdi.check(\n        t=t,\n        meas=x_measured,\n        u=u,\n        dt=0.001,\n        dynamics_model=dynamics\n    )\n\n    if status == \"FAULT\":\n        print(f\"FAULT DETECTED at t={t:.3f}s, residual={residual_norm:.3f}\")\n        # Implement safety response\n        break\n\n    # Continue simulation\n    x_next = dynamics.step(x_measured, u, 0.001)",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d966f8c"
  },
  {
    "id": "fault_detection_guide_2_380e8daa",
    "file": "docs\\fault_detection_guide.md",
    "index": 2,
    "code": "# Access FDI history for custom analysis\nimport matplotlib.pyplot as plt\n\n# After simulation with FDI enabled\ntimes = fdi.times\nresiduals = fdi.residuals\n\n# Plot residual statistics\nplt.figure(figsize=(12, 8))\n\n# Residual time series\nplt.subplot(2, 2, 1)\nplt.plot(times, residuals)\nplt.axhline(fdi.residual_threshold, color='r', linestyle='--')\nplt.ylabel('Residual Norm')\nplt.title('FDI Residual History')\n\n# Residual histogram\nplt.subplot(2, 2, 2)\nplt.hist(residuals, bins=50, alpha=0.7)\nplt.xlabel('Residual Norm')\nplt.ylabel('Frequency')\nplt.title('Residual Distribution')\n\n# Moving statistics\nwindow = 50\nif len(residuals) > window:\n    moving_mean = np.convolve(residuals, np.ones(window)/window, mode='valid')\n    moving_std = [np.std(residuals[i:i+window]) for i in range(len(residuals)-window+1)]\n\n    plt.subplot(2, 2, 3)\n    plt.plot(times[window-1:], moving_mean, label='Moving Mean')\n    plt.plot(times[window-1:], np.array(moving_mean) + 3*np.array(moving_std),\n             'r--', label='\u03bc + 3\u03c3')\n    plt.ylabel('Residual Statistics')\n    plt.legend()\n    plt.title('Adaptive Threshold Evolution')\n\nplt.tight_layout()\nplt.show()",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "380e8daa"
  },
  {
    "id": "fault_detection_guide_3_9e183bed",
    "file": "docs\\fault_detection_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nif status == \"FAULT\":\n    # Log fault information\n    logging.critical(f\"FAULT at t={t:.3f}s: residual={residual_norm:.3f}\")\n\n    # Safety responses (choose appropriate action)\n\n    # Option 1: Emergency stop\n    u = 0.0\n\n    # Option 2: Switch to safe controller\n    controller = safe_mode_controller\n\n    # Option 3: Graceful shutdown\n    target_state = safe_equilibrium\n\n    # Option 4: Reduce performance\n    controller.reduce_gains(factor=0.5)",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9e183bed"
  },
  {
    "id": "fault_detection_guide_4_050ec89f",
    "file": "docs\\fault_detection_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Fault-tolerant control example\nclass FaultTolerantController:\n    def __init__(self, primary_controller, backup_controller, fdi_system):\n        self.primary = primary_controller\n        self.backup = backup_controller\n        self.fdi = fdi_system\n        self.active_controller = primary_controller\n\n    def compute_control(self, x, x_ref, t, u_prev, dt, dynamics):\n        # FDI check\n        status, residual = self.fdi.check(t, x, u_prev, dt, dynamics)\n\n        # Switch controllers if fault detected\n        if status == \"FAULT\" and self.active_controller == self.primary:\n            logging.warning(\"Switching to backup controller due to fault\")\n            self.active_controller = self.backup\n\n        return self.active_controller.compute_control(x, x_ref, t)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "050ec89f"
  },
  {
    "id": "fault_detection_system_documentation_1_af60ad23",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass FDIsystem:\n    # Detection state\n    _counter: int                    # Persistence violation counter\n    _last_state: np.ndarray         # Previous state for prediction\n    tripped_at: Optional[float]     # Fault detection timestamp\n\n    # Adaptive thresholding state\n    _residual_window: List[float]   # Sliding window of residuals\n\n    # CUSUM state\n    _cusum: float                   # Cumulative sum statistic\n\n    # Analysis history\n    times: List[float]              # Timestamps for analysis\n    residuals: List[float]          # Residual history for analysis",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "af60ad23"
  },
  {
    "id": "fault_detection_system_documentation_2_8d88f7e5",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Initialize fault detector\nfdi = FDIsystem(\n    residual_threshold=0.1,\n    persistence_counter=5,\n    residual_states=[0, 1, 2],  # Position and first pendulum angle\n    residual_weights=[2.0, 1.0, 3.0],  # Emphasize position and pendulum\n    adaptive=True,\n    cusum_enabled=True\n)\n\n# Fault detection loop\nfor t, measurement in simulation_data:\n    status, residual = fdi.check(t, measurement, control_input, dt, dynamics)\n\n    if status == \"FAULT\":\n        logging.critical(f\"Fault detected at t={t:.3f}s, residual={residual:.4f}\")\n        # Trigger safe shutdown or fault accommodation\n        break",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d88f7e5"
  },
  {
    "id": "fault_detection_system_documentation_3_e628c14e",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Threshold parameters\nassert residual_threshold > 0, \"Threshold must be positive\"\nassert persistence_counter >= 1, \"Persistence counter must be \u2265 1\"\n\n# Adaptive parameters\nassert window_size >= 5, \"Window size too small for robust statistics\"\nassert threshold_factor > 0, \"Threshold factor must be positive\"\n\n# State selection validation\nassert all(i >= 0 for i in residual_states), \"Invalid state indices\"\nif residual_weights is not None:\n    assert len(residual_weights) == len(residual_states), \"Weight/state mismatch\"\n    assert all(w > 0 for w in residual_weights), \"Weights must be positive\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e628c14e"
  },
  {
    "id": "fault_detection_system_documentation_4_46da0b75",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nfault_test_matrix = {\n    \"sensor_bias\": {\n        \"magnitude\": np.array([0.1, 0.0, 0.0, 0.0]),\n        \"expected_detection_time\": \"<50 timesteps\",\n        \"method\": \"threshold_based\"\n    },\n    \"parameter_drift\": {\n        \"evolution\": \"linear_drift(rate=0.001)\",\n        \"expected_detection_time\": \"<100 timesteps\",\n        \"method\": \"cusum_based\"\n    },\n    \"intermittent_fault\": {\n        \"pattern\": \"periodic_dropout(period=20)\",\n        \"expected_behavior\": \"no_false_alarms\",\n        \"method\": \"persistence_filtering\"\n    }\n}",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46da0b75"
  },
  {
    "id": "fault_detection_system_documentation_5_b7a64c2c",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_false_alarm_rate(n_trials=10000):\n    \"\"\"Validate false alarm rate under normal conditions.\"\"\"\n    false_alarms = 0\n    for trial in range(n_trials):\n        fdi = FDIsystem(residual_threshold=0.1)\n        # Generate normal operation data with known statistics\n        for measurement in generate_normal_data():\n            status, _ = fdi.check(...)\n            if status == \"FAULT\":\n                false_alarms += 1\n                break\n\n    actual_far = false_alarms / n_trials\n    theoretical_far = compute_theoretical_far()\n\n    assert abs(actual_far - theoretical_far) < 0.01  # 1% tolerance",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b7a64c2c"
  },
  {
    "id": "fault_detection_system_documentation_6_61c61adc",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@given(residuals=arrays(float, min_size=10, max_size=1000))\n@assume(all(r >= 0 for r in residuals))\ndef test_adaptive_threshold_monotonicity(residuals):\n    \"\"\"Adaptive threshold should increase with residual variance.\"\"\"\n    fdi = FDIsystem(adaptive=True)\n\n    # Feed residuals to build window\n    for r in residuals:\n        fdi._residual_window.append(r)\n\n    # Higher variance should result in higher threshold\n    if len(residuals) >= fdi.window_size:\n        threshold = compute_adaptive_threshold(fdi._residual_window)\n        assert threshold >= fdi.residual_threshold",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61c61adc"
  },
  {
    "id": "fault_detection_system_documentation_7_ab39ae09",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass FaultTolerantController:\n    def __init__(self, controller, dynamics_model):\n        self.controller = controller\n        self.fdi = FDIsystem(\n            residual_threshold=0.05,  # Tuned for system noise level\n            persistence_counter=5,    # Balance responsiveness vs. robustness\n            adaptive=True,            # Handle varying operating conditions\n            cusum_enabled=True        # Detect slow drifts\n        )\n        self.dynamics_model = dynamics_model\n        self.fault_detected = False\n\n    def compute_control(self, t, state, reference):\n        # Fault detection\n        if not self.fault_detected:\n            status, residual = self.fdi.check(t, state, self.last_control, dt, self.dynamics_model)\n            if status == \"FAULT\":\n                self.fault_detected = True\n                logging.critical(f\"Fault detected at t={t:.3f}s\")\n                return self.safe_shutdown_sequence()\n\n        # Normal control computation\n        if not self.fault_detected:\n            control = self.controller.compute_control(state, reference)\n            self.last_control = control\n            return control\n        else:\n            return self.fault_accommodation_control(state, reference)",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab39ae09"
  },
  {
    "id": "fault_detection_system_documentation_8_23a5ac7b",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass SafetyManager:\n    def __init__(self):\n        # Primary fault detector (sensitive)\n        self.primary_fdi = FDIsystem(residual_threshold=0.03, persistence_counter=3)\n\n        # Secondary fault detector (conservative)\n        self.secondary_fdi = FDIsystem(residual_threshold=0.1, persistence_counter=10)\n\n        # Tertiary detector with different algorithm\n        self.tertiary_fdi = EnhancedFaultDetector(\n            FaultDetectionConfig(enable_cusum=True, enable_statistical_tests=True)\n        )\n\n    def assess_system_health(self, data):\n        results = {}\n\n        # Multiple detection layers\n        results['primary'] = self.primary_fdi.check(...)\n        results['secondary'] = self.secondary_fdi.check(...)\n        results['tertiary'] = self.tertiary_fdi.detect(data)\n\n        # Consensus-based fault declaration\n        fault_votes = sum(1 for r in results.values() if self.indicates_fault(r))\n\n        if fault_votes >= 2:  # Majority voting\n            return \"FAULT\", results\n        else:\n            return \"OK\", results",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23a5ac7b"
  },
  {
    "id": "fault_detection_system_documentation_9_fde6c9ee",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass RealTimeFDI:\n    def __init__(self, max_execution_time_ms=1.0):\n        self.fdi = FDIsystem()\n        self.max_execution_time = max_execution_time_ms / 1000.0\n        self.execution_times = []\n\n    def check_with_timing(self, *args):\n        start_time = time.perf_counter()\n        result = self.fdi.check(*args)\n        execution_time = time.perf_counter() - start_time\n\n        self.execution_times.append(execution_time)\n\n        if execution_time > self.max_execution_time:\n            logging.warning(f\"FDI execution time exceeded limit: {execution_time*1000:.2f}ms\")\n\n        return result",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fde6c9ee"
  },
  {
    "id": "fault_detection_system_documentation_10_d4a6944d",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass HILFaultDetection:\n    def __init__(self, plant_server_config):\n        self.fdi = FDIsystem(\n            # HIL-specific tuning for communication delays\n            persistence_counter=8,  # Account for network latency\n            adaptive=True,          # Handle varying HIL conditions\n            cusum_enabled=False     # Disable for real-time constraints\n        )\n        self.plant_server = PlantServer(plant_server_config)\n\n    def run_hil_fault_detection(self):\n        while self.plant_server.is_running():\n            # Receive measurement from hardware\n            measurement = self.plant_server.receive_measurement()\n\n            # Fault detection with timing validation\n            start = time.perf_counter()\n            status, residual = self.fdi.check(\n                measurement.timestamp,\n                measurement.state,\n                self.last_control,\n                measurement.dt,\n                self.dynamics_model\n            )\n            detection_time = time.perf_counter() - start\n\n            # Send fault status to controller\n            fault_message = FaultStatusMessage(\n                status=status,\n                residual=residual,\n                detection_latency=detection_time\n            )\n            self.plant_server.send_fault_status(fault_message)",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4a6944d"
  },
  {
    "id": "fault_detection_system_documentation_11_cf7e2394",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 11,
    "code": "if current_state == \"OK\":\n    if residual > hysteresis_upper for persistence_counter steps:\n        transition to \"FAULT\"\nelif current_state == \"FAULT\":\n    # Current: persistent (no automatic recovery)\n    # Future: if residual < hysteresis_lower: transition to \"OK\"\n    pass",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf7e2394"
  },
  {
    "id": "fault_detection_system_documentation_12_250f5e28",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 12,
    "code": "@dataclass\nclass FDIsystem:\n    residual_threshold: float = 0.150      # Calibrated from 0.5\n    hysteresis_enabled: bool = False       # Backward compatible\n    hysteresis_upper: float = 0.165\n    hysteresis_lower: float = 0.135",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "250f5e28"
  },
  {
    "id": "fault_detection_system_documentation_13_be71324e",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 13,
    "code": "# WRONG: Weight applied after norm computation\nresidual_norm = np.linalg.norm(residual[self.residual_states])\nif weights is not None:\n    residual_norm *= np.linalg.norm(weights)  # INCORRECT",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be71324e"
  },
  {
    "id": "fault_detection_system_documentation_14_52bb675b",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 14,
    "code": "# CORRECT: Element-wise weight multiplication before norm\nsub = residual[self.residual_states]\nif weights is not None:\n    sub = sub * np.asarray(weights, dtype=float)  # Element-wise multiplication\nresidual_norm = float(np.linalg.norm(sub))        # Then compute norm",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52bb675b"
  },
  {
    "id": "fault_detection_system_documentation_15_ca21a8e1",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_weighted_residual_correction():\n    \"\"\"Verify weighted residual calculation is mathematically correct.\"\"\"\n    residual = np.array([0.1, 0.2, 0.3])\n    weights = np.array([10.0, 1.0, 5.0])\n\n    # Manual calculation\n    weighted_residual = residual * weights  # [1.0, 0.2, 1.5]\n    expected_norm = np.linalg.norm(weighted_residual)  # \u2248 1.844\n\n    # FDI calculation\n    fdi = FDIsystem(residual_states=[0, 1, 2], residual_weights=weights.tolist())\n    # ... (call fdi.check with test data)\n\n    assert abs(computed_norm - expected_norm) < 1e-10",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca21a8e1"
  },
  {
    "id": "fault_detection_system_documentation_16_9ba09ab4",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# CORRECTED CUSUM update logic\nif self.cusum_enabled:\n    # Robust reference value selection\n    if self.adaptive and mu is not None:\n        ref = mu  # Use adaptive mean when available\n    else:\n        ref = self.residual_threshold  # Fallback to base threshold\n\n    # Standard CUSUM update with negative clipping\n    self._cusum = max(0.0, self._cusum + (residual_norm - ref))\n\n    if self._cusum > self.cusum_threshold:\n        self.tripped_at = t\n        logging.info(f\"CUSUM fault detected: {self._cusum:.4f} > {self.cusum_threshold}\")\n        return \"FAULT\", residual_norm",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ba09ab4"
  },
  {
    "id": "fault_detection_system_documentation_17_eaf9804b",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef check(self, t, meas, u, dt, dynamics_model):\n    # ... validation and prediction logic ...\n\n    # FIXED: Always record history, including first measurement\n    self.times.append(t)\n    self.residuals.append(residual_norm)\n\n    # Ensure history consistency\n    assert len(self.times) == len(self.residuals), \"History synchronization error\"\n\n    # ... rest of detection logic ...",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eaf9804b"
  },
  {
    "id": "fault_detection_system_documentation_18_36b25d59",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_safety_critical_fault_detection():\n    \"\"\"Verify FDI system meets safety requirements.\"\"\"\n\n    safety_requirements = {\n        \"max_detection_delay\": 50,      # timesteps\n        \"max_false_alarm_rate\": 0.01,   # 1% during normal operation\n        \"fault_persistence\": True,      # Once faulted, remain faulted\n        \"graceful_degradation\": True    # No crashes on model failures\n    }\n\n    # Test large fault detection delay\n    large_fault = inject_sensor_bias(magnitude=0.5)\n    detection_delay = run_fault_scenario(large_fault)\n    assert detection_delay <= safety_requirements[\"max_detection_delay\"]\n\n    # Test false alarm rate\n    false_alarm_rate = monte_carlo_false_alarm_test(trials=10000)\n    assert false_alarm_rate <= safety_requirements[\"max_false_alarm_rate\"]\n\n    # Test fault persistence\n    assert test_fault_persistence() == True\n\n    # Test error handling\n    assert test_graceful_degradation() == True",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36b25d59"
  },
  {
    "id": "fault_detection_system_documentation_19_735afb8e",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 19,
    "code": "# Typical execution times (Intel i7-9750H @ 2.6GHz)\nMeasurement_Cases = {\n    \"basic_detection\": \"~0.05ms per timestep\",\n    \"adaptive_enabled\": \"~0.12ms per timestep\",\n    \"full_featured\": \"~0.18ms per timestep\",\n    \"10k_timesteps\": \"~1.2s total processing\"\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735afb8e"
  },
  {
    "id": "fault_detection_system_documentation_20_19558d18",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 20,
    "code": "OPERATIONAL_LIMITS = {\n    \"residual_threshold\": (1e-6, 1e3),    # Avoid numerical issues\n    \"persistence_counter\": (1, 1000),     # Practical response time limits\n    \"window_size\": (5, 10000),            # Statistical validity vs. memory\n    \"threshold_factor\": (0.1, 10.0),      # Reasonable sensitivity range\n    \"cusum_threshold\": (0.1, 100.0),      # Detection sensitivity bounds\n    \"max_state_dimension\": 50,             # Memory and computation limits\n    \"max_simulation_time\": 1e6             # History storage limits\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19558d18"
  },
  {
    "id": "fault_detection_system_documentation_21_c59d0b02",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_false_alarms(fdi_system):\n    \"\"\"Diagnostic procedure for false alarm investigation.\"\"\"\n\n    # Check threshold appropriateness\n    residual_stats = np.array(fdi_system.residuals[-100:])  # Recent residuals\n    mean_residual = np.mean(residual_stats)\n    std_residual = np.std(residual_stats)\n\n    recommended_threshold = mean_residual + 3 * std_residual\n\n    print(f\"Current threshold: {fdi_system.residual_threshold}\")\n    print(f\"Recommended threshold: {recommended_threshold:.4f}\")\n    print(f\"Residual statistics: \u03bc={mean_residual:.4f}, \u03c3={std_residual:.4f}\")\n\n    # Check noise characterization\n    if std_residual > 0.1 * mean_residual:\n        print(\"WARNING: High residual noise detected\")\n        print(\"RECOMMENDATION: Enable adaptive thresholding\")\n\n    # Check persistence counter\n    violation_rate = sum(r > fdi_system.residual_threshold for r in residual_stats) / len(residual_stats)\n    if violation_rate > 0.1:  # > 10% violation rate\n        print(f\"High violation rate: {violation_rate:.2%}\")\n        print(\"RECOMMENDATION: Increase persistence counter or threshold\")",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c59d0b02"
  },
  {
    "id": "fault_detection_system_documentation_22_1e0657d8",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_missed_faults(fault_injection_results):\n    \"\"\"Analyze fault detection performance.\"\"\"\n\n    for fault_type, results in fault_injection_results.items():\n        detection_rate = results['detected'] / results['total_injected']\n        avg_delay = np.mean(results['detection_delays'])\n\n        print(f\"Fault type: {fault_type}\")\n        print(f\"Detection rate: {detection_rate:.2%}\")\n        print(f\"Average delay: {avg_delay:.1f} timesteps\")\n\n        if detection_rate < 0.95:  # < 95% detection rate\n            print(\"LOW DETECTION RATE WARNING\")\n            if avg_delay > 50:\n                print(\"RECOMMENDATION: Decrease threshold or persistence counter\")\n            else:\n                print(\"RECOMMENDATION: Review fault signature and weights\")",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e0657d8"
  },
  {
    "id": "fault_detection_system_documentation_23_2a3e7cce",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimize_fdi_performance(fdi_system):\n    \"\"\"Performance optimization recommendations.\"\"\"\n\n    # Check window size\n    if fdi_system.window_size > 100:\n        print(\"RECOMMENDATION: Reduce window_size for faster adaptation\")\n\n    # Check history growth\n    if len(fdi_system.times) > 100000:\n        print(\"WARNING: Large history detected\")\n        print(\"RECOMMENDATION: Implement history truncation\")\n\n        # Example truncation\n        keep_recent = 10000\n        fdi_system.times = fdi_system.times[-keep_recent:]\n        fdi_system.residuals = fdi_system.residuals[-keep_recent:]\n\n    # Check state dimension\n    if len(fdi_system.residual_states) > 10:\n        print(\"RECOMMENDATION: Reduce number of monitored states\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a3e7cce"
  },
  {
    "id": "fault_detection_system_documentation_24_2bb899d7",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef characterize_system_baseline(simulation_data):\n    \"\"\"Establish baseline noise characteristics.\"\"\"\n    residuals = []\n\n    # Run fault-free simulation\n    for measurement in simulation_data['normal_operation']:\n        residual = compute_residual(measurement)\n        residuals.append(residual)\n\n    baseline_stats = {\n        'mean': np.mean(residuals),\n        'std': np.std(residuals),\n        'p95': np.percentile(residuals, 95),\n        'p99': np.percentile(residuals, 99)\n    }\n\n    return baseline_stats",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb899d7"
  },
  {
    "id": "fault_detection_system_documentation_25_cb6f45c0",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 25,
    "code": "def recommend_threshold(baseline_stats, target_far=0.01):\n    \"\"\"Recommend threshold based on desired false alarm rate.\"\"\"\n\n    # For normal distribution, use quantile-based approach\n    from scipy import stats\n    z_score = stats.norm.ppf(1 - target_far)  # Z-score for desired FAR\n\n    recommended_threshold = baseline_stats['mean'] + z_score * baseline_stats['std']\n\n    print(f\"Recommended threshold: {recommended_threshold:.4f}\")\n    print(f\"This targets {target_far:.1%} false alarm rate\")\n\n    return recommended_threshold",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb6f45c0"
  },
  {
    "id": "fault_detection_system_documentation_26_032e235e",
    "file": "docs\\fault_detection_system_documentation.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\ndef tune_persistence_counter(fault_scenarios, detection_delay_target=20):\n    \"\"\"Tune persistence counter based on detection delay requirements.\"\"\"\n\n    optimal_persistence = {}\n\n    for fault_type, magnitude in fault_scenarios.items():\n        delays = []\n\n        for persistence in range(1, 21):  # Test 1-20\n            fdi = FDIsystem(persistence_counter=persistence)\n            delay = simulate_fault_detection(fdi, fault_type, magnitude)\n            delays.append(delay)\n\n            if delay <= detection_delay_target:\n                optimal_persistence[fault_type] = persistence\n                break\n\n    return optimal_persistence",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "032e235e"
  },
  {
    "id": "fdi_threshold_calibration_methodology_1_b03169cf",
    "file": "docs\\fdi_threshold_calibration_methodology.md",
    "index": 1,
    "code": "if current_state == \"OK\":\n    if residual > hysteresis_upper for persistence_counter consecutive steps:\n        transition to \"FAULT\"\nelif current_state == \"FAULT\":\n    # Current: persistent fault (no recovery)\n    # Future: if residual < hysteresis_lower: transition to \"OK\"\n    pass",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b03169cf"
  },
  {
    "id": "fdi_threshold_calibration_methodology_2_44a5137b",
    "file": "docs\\fdi_threshold_calibration_methodology.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass FDIsystem:\n    # Core parameters\n    residual_threshold: float = 0.150  # Updated from 0.5 \u2192 0.150\n    persistence_counter: int = 10\n    residual_states: List[int] = field(default_factory=lambda: [0, 1, 2])\n    residual_weights: Optional[List[float]] = None\n\n    # Hysteresis parameters (new)\n    hysteresis_enabled: bool = False\n    hysteresis_upper: float = 0.165  # threshold * 1.1\n    hysteresis_lower: float = 0.135  # threshold * 0.9",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "44a5137b"
  },
  {
    "id": "fdi_threshold_calibration_methodology_3_27c76192",
    "file": "docs\\fdi_threshold_calibration_methodology.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef check(self, t, meas, u, dt, dynamics_model):\n    # ... residual computation ...\n\n    if self.hysteresis_enabled:\n        # Use upper threshold for fault detection\n        threshold = self.hysteresis_upper\n    else:\n        # Legacy single-threshold behavior\n        threshold = self.residual_threshold\n\n    # Persistence filtering\n    if residual_norm > threshold:\n        self._counter += 1\n        if self._counter >= self.persistence_counter:\n            self.tripped_at = t\n            return \"FAULT\", residual_norm\n    else:\n        self._counter = 0  # Reset on good measurement\n\n    return \"OK\", residual_norm",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27c76192"
  },
  {
    "id": "fdi_threshold_calibration_methodology_4_90795d5e",
    "file": "docs\\fdi_threshold_calibration_methodology.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_fixed_threshold_operation():\n    \"\"\"Verify FDI operates with fixed threshold.\"\"\"\n    fdi = FDIsystem(\n        residual_threshold=0.150,  # Updated from 0.100\n        persistence_counter=10\n    )\n\n    # Test normal operation (no fault)\n    for t in np.linspace(0, 1.0, 100):\n        measurement = np.zeros(6) + np.random.normal(0, 0.05, 6)\n        status, residual = fdi.check(t, measurement, 0.0, 0.01, dynamics)\n\n        if residual < 0.150:\n            assert status == \"OK\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "90795d5e"
  },
  {
    "id": "fdi_threshold_calibration_methodology_5_3ee880db",
    "file": "docs\\fdi_threshold_calibration_methodology.md",
    "index": 5,
    "code": "from src.analysis.fault_detection.fdi import FDIsystem\n\nfdi = FDIsystem(\n    residual_threshold=0.145,  # Post-Kalman filtering\n    use_ekf=True,              # Enable Kalman-based residual\n    ekf_process_noise=0.01,\n    ekf_measurement_noise=0.05\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ee880db"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_1_096ac82d",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOTuner:\n    \"\"\"\n    Rebuilt PSO optimization engine with robust controller integration.\n\n    Key Improvements:\n    - Unified controller factory interface\n    - Dynamic parameter count adaptation\n    - Enhanced bounds management\n    - Improved convergence monitoring\n    \"\"\"\n\n    def __init__(self, controller_factory: Callable, config: dict, seed: int = 42):\n        \"\"\"\n        Initialize PSO tuner with enhanced validation and error handling.\n\n        Args:\n            controller_factory: Factory function with n_gains attribute\n            config: Complete configuration with PSO parameters\n            seed: Random seed for reproducible optimization\n        \"\"\"\n        # Robust parameter extraction with fallbacks\n        self.pso_config = config.get('pso', {})\n        self.controller_factory = controller_factory\n\n        # Enhanced parameter count detection\n        self.n_gains = getattr(controller_factory, 'n_gains', 6)\n\n        # Dynamic bounds adaptation\n        self.bounds = self._extract_bounds(config)\n\n        # Validation and safety checks\n        self._validate_configuration()",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "096ac82d"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_2_40a49924",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_pso_parameters(self) -> bool:\n    \"\"\"\n    Validate PSO parameters for mathematical consistency.\n\n    Validation Rules:\n    1. Clerc-Kennedy stability: \u03c6 = c\u2081 + c\u2082 > 4\n    2. Balanced coefficients: |c\u2081 - c\u2082| \u2264 0.5\n    3. Inertia bounds: w \u2208 [0.4, 0.9]\n    4. Parameter count consistency\n    \"\"\"\n    c1, c2 = self.pso_config['c1'], self.pso_config['c2']\n    phi = c1 + c2\n\n    if phi <= 4.0:\n        raise ValueError(f\"PSO convergence risk: \u03c6 = {phi:.3f} \u2264 4.0\")\n\n    if abs(c1 - c2) > 0.5:\n        raise ValueError(f\"Unbalanced coefficients: |c\u2081 - c\u2082| = {abs(c1 - c2):.3f}\")\n\n    return True",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40a49924"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_3_fefe742a",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 3,
    "code": "# Enhanced factory with PSO-specific interface\nfrom enum import Enum\nfrom typing import Protocol, Union, List, Optional, Tuple\nimport numpy as np\n\nclass SMCType(Enum):\n    \"\"\"Enumeration of SMC controller types for PSO optimization.\"\"\"\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"\n\nclass PSOControllerWrapper:\n    \"\"\"PSO-friendly wrapper that simplifies control interface.\"\"\"\n\n    def __init__(self, controller: Any):\n        self.controller = controller\n        self._history = {}\n\n        # Initialize appropriate state_vars based on controller type\n        controller_name = type(controller).__name__\n        if 'SuperTwisting' in controller_name or 'STA' in controller_name:\n            self._state_vars = (0.0, 0.0)  # (z, sigma)\n        elif 'Hybrid' in controller_name:\n            self._state_vars = (4.0, 0.4, 0.0)  # (k1_init, k2_init, u_int_prev)\n        else:\n            self._state_vars = ()  # Classical and Adaptive\n\n    def compute_control(self, state: np.ndarray, state_vars=None, history=None):\n        \"\"\"\n        Flexible interface supporting both:\n        1. compute_control(state) - PSO-friendly simplified\n        2. compute_control(state, state_vars, history) - Full interface\n        \"\"\"\n        final_state_vars = state_vars if state_vars is not None else self._state_vars\n        final_history = history if history is not None else self._history\n\n        result = self.controller.compute_control(state, final_state_vars, final_history)\n\n        # For PSO usage, return numpy array\n        if state_vars is None and history is None:\n            if hasattr(result, 'u'):\n                control_value = result.u\n            elif isinstance(result, dict) and 'u' in result:\n                control_value = result['u']\n            elif isinstance(result, tuple) and len(result) > 0:\n                control_value = result[0]\n            else:\n                control_value = result\n\n            # Ensure numpy array output\n            if isinstance(control_value, (int, float)):\n                return np.array([control_value])\n            elif isinstance(control_value, np.ndarray):\n                return control_value.flatten()\n            else:\n                return np.array([float(control_value)])\n        else:\n            return result",
    "lines": 59,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fefe742a"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_4_613cf41d",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(\n    smc_type: Union[SMCType, str],\n    gains: Union[List[float], np.ndarray],\n    plant_config_or_max_force: Union[Any, float] = 100.0,\n    dt: float = 0.01,\n    dynamics_model: Optional[Any] = None\n) -> PSOControllerWrapper:\n    \"\"\"\n    Convenience function optimized for PSO parameter tuning.\n\n    Usage in PSO fitness function:\n        controller = create_smc_for_pso(SMCType.CLASSICAL, pso_params)\n        performance = evaluate_controller(controller, test_scenarios)\n        return performance\n    \"\"\"\n    # Handle different calling patterns\n    if isinstance(plant_config_or_max_force, (int, float)):\n        max_force = float(plant_config_or_max_force)\n        final_dynamics_model = dynamics_model\n    else:\n        max_force = 100.0\n        final_dynamics_model = plant_config_or_max_force\n\n    controller = SMCFactory.create_from_gains(\n        smc_type=smc_type,\n        gains=gains,\n        max_force=max_force,\n        dt=dt,\n        dynamics_model=final_dynamics_model\n    )\n\n    return PSOControllerWrapper(controller)\n\ndef get_gain_bounds_for_pso(smc_type: Union[SMCType, str]) -> Tuple[List[float], List[float]]:\n    \"\"\"Get PSO optimization bounds for SMC controller gains.\"\"\"\n    spec = SMCFactory.get_gain_specification(smc_type)\n    bounds = spec.gain_bounds\n\n    # Convert to PSO format: (lower_bounds, upper_bounds)\n    lower_bounds = [bound[0] for bound in bounds]\n    upper_bounds = [bound[1] for bound in bounds]\n\n    return (lower_bounds, upper_bounds)\n\ndef validate_smc_gains(smc_type: Union[SMCType, str], gains: Union[List[float], np.ndarray]) -> bool:\n    \"\"\"Validate gains for SMC controller type with stability requirements.\"\"\"\n    try:\n        spec = SMCFactory.get_gain_specification(smc_type)\n        gains_array = np.asarray(gains)\n\n        # Check length\n        if len(gains_array) < spec.n_gains:\n            return False\n\n        # Check positivity for surface gains (SMC stability requirement)\n        if smc_type in [SMCType.CLASSICAL, SMCType.ADAPTIVE, SMCType.SUPER_TWISTING]:\n            if any(g <= 0 for g in gains_array[:4]):  # First 4 are surface gains\n                return False\n        elif smc_type == SMCType.HYBRID:\n            if any(g <= 0 for g in gains_array[:4]):  # All 4 gains must be positive\n                return False\n\n        return True\n    except Exception:\n        return False",
    "lines": 68,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "613cf41d"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_5_4a5c9fff",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_ConfigurationValidator:\n    \"\"\"Comprehensive PSO configuration validation.\"\"\"\n\n    def validate_complete_config(self, config: dict) -> ValidationReport:\n        \"\"\"Multi-level validation with mathematical rigor.\"\"\"\n        report = ValidationReport()\n\n        # Level 1: Syntax and structure validation\n        syntax_result = self._validate_syntax(config)\n        report.add_level_result('syntax', syntax_result)\n\n        # Level 2: Mathematical consistency\n        math_result = self._validate_mathematical_consistency(config)\n        report.add_level_result('mathematical', math_result)\n\n        # Level 3: Controller-specific constraints\n        controller_result = self._validate_controller_constraints(config)\n        report.add_level_result('controller', controller_result)\n\n        # Level 4: Performance optimization\n        performance_result = self._validate_performance_config(config)\n        report.add_level_result('performance', performance_result)\n\n        return report\n\n    def _validate_mathematical_consistency(self, config: dict) -> ValidationResult:\n        \"\"\"Validate PSO mathematical properties.\"\"\"\n        errors = []\n\n        if 'algorithm_params' in config.get('pso', {}):\n            params = config['pso']['algorithm_params']\n\n            # PSO convergence condition: \u03c6 = c\u2081 + c\u2082 > 4\n            if 'c1' in params and 'c2' in params:\n                phi = params['c1'] + params['c2']\n                if phi <= 4.0:\n                    errors.append(f\"PSO convergence risk: \u03c6 = {phi:.3f} \u2264 4.0\")\n\n            # Coefficient balance: |c\u2081 - c\u2082| \u2264 0.5\n            if 'c1' in params and 'c2' in params:\n                diff = abs(params['c1'] - params['c2'])\n                if diff > 0.5:\n                    errors.append(f\"Unbalanced coefficients: |c\u2081 - c\u2082| = {diff:.3f}\")\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a5c9fff"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_6_3a00fa01",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef cost_function(gains: np.ndarray) -> float:\n    \"\"\"\n    Comprehensive cost function for SMC parameter optimization.\n\n    Cost Components:\n    1. Tracking performance (ISE, ITAE)\n    2. Control effort minimization\n    3. Stability margins\n    4. Constraint violations\n    5. Issue #2 overshoot penalties (STA-SMC)\n    \"\"\"\n    try:\n        # Create controller with PSO gains\n        controller = create_smc_for_pso(controller_type, gains)\n\n        # Simulate across multiple scenarios\n        total_cost = 0.0\n        for scenario in test_scenarios:\n            sim_result = simulate_scenario(controller, scenario)\n\n            # Performance metrics\n            tracking_cost = compute_tracking_cost(sim_result)\n            control_cost = compute_control_effort(sim_result)\n            stability_cost = compute_stability_margin(sim_result)\n\n            # Issue #2 specific penalty for STA-SMC\n            if controller_type == 'sta_smc':\n                overshoot_penalty = compute_overshoot_penalty(sim_result)\n                total_cost += overshoot_penalty\n\n            total_cost += tracking_cost + 0.1 * control_cost + 0.05 * stability_cost\n\n        return total_cost\n\n    except Exception:\n        return 1e6  # High penalty for invalid parameters",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a00fa01"
  },
  {
    "id": "GitHub_Issue_4_PSO_Integration_Resolution_Report_7_0716627f",
    "file": "docs\\GitHub_Issue_4_PSO_Integration_Resolution_Report.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef production_safety_check() -> dict:\n    \"\"\"Verify production safety for PSO optimization system.\"\"\"\n    safety_report = {\n        'memory_bounded': True,         # \u2705 <2GB limit enforced\n        'thread_safe': True,           # \u2705 Single-threaded operation\n        'constraint_enforced': True,   # \u2705 All stability constraints active\n        'error_handling': True,        # \u2705 Robust exception handling\n        'timeout_protected': True,     # \u2705 5-minute timeout limit\n        'configuration_validated': True, # \u2705 Schema validation active\n        'mathematical_consistent': True  # \u2705 PSO parameters validated\n    }\n\n    overall_safety = all(safety_report.values())\n    safety_report['overall_status'] = 'PRODUCTION_READY' if overall_safety else 'NEEDS_ATTENTION'\n\n    return safety_report",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0716627f"
  },
  {
    "id": "hil_quickstart_1_08325789",
    "file": "docs\\hil_quickstart.md",
    "index": 1,
    "code": "import struct\nimport zlib\n\n# For control packet: sequence + command\npayload = struct.pack(\"!I d\", sequence_num, control_force)\ncrc = zlib.crc32(payload) & 0xFFFFFFFF\npacket = payload + struct.pack(\"!I\", crc)\n\n# For state packet: sequence + 6 measurements\npayload = struct.pack(\"!I 6d\", sequence_num, x, theta1, theta2, x_dot, theta1_dot, theta2_dot)\ncrc = zlib.crc32(payload) & 0xFFFFFFFF\npacket = payload + struct.pack(\"!I\", crc)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "08325789"
  },
  {
    "id": "hil_quickstart_2_538efedf",
    "file": "docs\\hil_quickstart.md",
    "index": 2,
    "code": "import logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Run HIL with debug output\npython simulate.py --run-hil --plot --verbose",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "538efedf"
  },
  {
    "id": "hil_quickstart_3_aab57718",
    "file": "docs\\hil_quickstart.md",
    "index": 3,
    "code": "import socket\nimport struct\n\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nsock.bind(('127.0.0.1', 9001))\n\nwhile True:\n    data, addr = sock.recvfrom(1024)\n    # Unpack state: timestamp, x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072\n    state = struct.unpack('!7f', data)\n\n    # Your controller logic here\n    control_force = your_controller(state[1:])  # Exclude timestamp\n\n    # Send control response\n    response = struct.pack('!2f', state[0], control_force)\n    sock.sendto(response, addr)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aab57718"
  },
  {
    "id": "hil_quickstart_4_1fe7650b",
    "file": "docs\\hil_quickstart.md",
    "index": 4,
    "code": "from src.fault_detection.fdi import FaultDetector\nfrom src.interfaces.hil.plant_server import PlantServer\n\n# Create FDI system with HIL-specific fault types\nfdi = FaultDetector(\n    fault_types=['sensor_failure', 'actuator_saturation', 'network_timeout']\n)\n\n# Initialize HIL with FDI monitoring\nplant_server = PlantServer(config, fault_detector=fdi)\n\n# FDI automatically monitors:\n# - Sensor value bounds and rate limits\n# - Network packet integrity and timing\n# - Control signal saturation and discontinuities",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1fe7650b"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_1_a8476dbf",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 1,
    "code": "from src.plant.core.numerical_stability import (\n    AdaptiveRegularizer,\n    NumericalInstabilityError\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8476dbf"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_2_a54f1e38",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 2,
    "code": "regularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-6,   # Minimal for accuracy\n    max_condition_number=1e12,   # Accept modest ill-conditioning\n    min_regularization=1e-12,    # Very small minimum\n    use_fixed_regularization=False\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a54f1e38"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_3_9ef4ab4f",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 3,
    "code": "cond_A = np.linalg.cond(A)\nif not np.isfinite(cond_A) or cond_A > 1e14:\n    A_reg = regularizer.regularize_matrix(A)  # Apply regularization\n    A_to_solve = A_reg\nelse:\n    A_to_solve = A  # Use original (fast path)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ef4ab4f"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_4_2e510a4d",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 4,
    "code": "try:\n    P = linalg.solve_lyapunov(A_to_solve.T, -Q)  # Fast direct method\nexcept (np.linalg.LinAlgError, ValueError):\n    P = self._solve_lyapunov_svd(A_to_solve, Q, regularizer)  # Robust fallback",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e510a4d"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_5_d7e7dce2",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 5,
    "code": "P_sym = 0.5 * (P + P.T)  # Symmetrize\ntry:\n    np.linalg.cholesky(P_sym)  # Definitive positive definiteness test\n    is_positive_definite = True\nexcept np.linalg.LinAlgError:\n    # Fallback to eigenvalue check with tolerance\n    eigenvals_P = linalg.eigvals(P_sym)\n    min_eigval = np.min(np.real(eigenvals_P))\n    is_positive_definite = (min_eigval > -tolerance)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d7e7dce2"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_6_2ada3a91",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 6,
    "code": "lyapunov_residual = A_to_solve.T @ P + P @ A_to_solve + Q\nresidual_norm = np.linalg.norm(lyapunov_residual, ord='fro')\nresidual_relative = residual_norm / (np.linalg.norm(Q, ord='fro') + 1e-15)\n\nis_stable = is_positive_definite and residual_relative < 1e-6",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ada3a91"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_7_ceffc7c2",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef _solve_lyapunov_svd(self, A, Q, regularizer):\n    # Vectorize: (I \u2297 A^T + A^T \u2297 I) vec(P) = -vec(Q)\n    n = A.shape[0]\n    I_n = np.eye(n)\n    K = np.kron(I_n, A.T) + np.kron(A.T, I_n)\n\n    # Regularize Kronecker matrix\n    K_reg = regularizer.regularize_matrix(K)\n\n    # Solve and reshape\n    q_vec = -Q.flatten()\n    p_vec = np.linalg.solve(K_reg, q_vec)  # or lstsq as ultimate fallback\n    P = p_vec.reshape((n, n))\n\n    return 0.5 * (P + P.T)  # Symmetrize",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceffc7c2"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_8_d250234b",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 8,
    "code": "A = np.array([\n    [0, 0, 0, 1, 0, 0],\n    [0, 0, 0, 0, 1, 0],\n    [0, 0, 0, 0, 0, 1],\n    [-2, -1, 0, -1, 0, 0],\n    [0, -3, -1, 0, -1, 0],\n    [0, 0, -2, 0, 0, -1]\n])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d250234b"
  },
  {
    "id": "issue_11_lyapunov_robustness_resolution_9_4c6bed94",
    "file": "docs\\issue_11_lyapunov_robustness_resolution.md",
    "index": 9,
    "code": "from src.analysis.performance.stability_analysis import StabilityAnalyzer, StabilityAnalysisConfig\n\n# Initialize analyzer\nconfig = StabilityAnalysisConfig(eigenvalue_tolerance=1e-10)\nanalyzer = StabilityAnalyzer(config=config)\n\n# Analyze system stability\nA = np.array([[-1.0, 0.5], [0.0, -2.0]])\nresult = analyzer._analyze_analytical_lyapunov(A)\n\nprint(f\"Stable: {result['is_stable']}\")\nprint(f\"Positive definite: {result['is_positive_definite']}\")\nprint(f\"Residual: {result['residual_relative']:.2e}\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c6bed94"
  },
  {
    "id": "issue_11_test_fix_completion_1_2bb757fd",
    "file": "docs\\issue_11_test_fix_completion.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# System from test (lines 313-321)\nA = [[0, 0, 0, 1, 0, 0],\n     [0, 0, 0, 0, 1, 0],\n     [0, 0, 0, 0, 0, 1],\n     [-2, -1, 0, -1, 0, 0],\n     [0, -3, -1, 0, -1, 0],\n     [0, 0, -2, 0, 0, -1]]\n\nB = [0, 0, 0, 1, 0, 0]\n\n# LQR design parameters\nQ = 100 * I\u2086  # Strong state penalty for fast convergence\nR = 1         # Control effort weight\n\n# Optimal gains via CARE\nK_optimal = [8.20, -0.91, -0.01, 9.83, -0.05, -0.01]",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb757fd"
  },
  {
    "id": "issue_12_chattering_reduction_resolution_1_1aec0cf1",
    "file": "docs\\issue_12_chattering_reduction_resolution.md",
    "index": 1,
    "code": "def get_chattering_index(self, control_history, dt=0.01):\n    \"\"\"FFT-based spectral analysis + time-domain Total Variation.\"\"\"\n    # Time-domain: RMS of control derivative\n    control_derivative = np.gradient(control_array, dt)\n    time_domain_index = np.sqrt(np.mean(control_derivative**2))\n\n    # Frequency-domain: High-frequency power ratio (>10 Hz)\n    from scipy.fft import fft, fftfreq\n    spectrum = np.abs(fft(control_array))\n    freqs = fftfreq(len(control_array), d=dt)\n    hf_power = np.sum(spectrum[np.abs(freqs) > 10])\n    freq_domain_index = hf_power / (np.sum(spectrum) + 1e-12)\n\n    # Combined weighted index\n    return 0.7 * time_domain_index + 0.3 * freq_domain_index",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1aec0cf1"
  },
  {
    "id": "issue_12_chattering_reduction_resolution_2_b09c1ec4",
    "file": "docs\\issue_12_chattering_reduction_resolution.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_performance(self, surface_history, control_history, dt, state_history):\n    \"\"\"Comprehensive chattering reduction metrics.\"\"\"\n    return {\n        'chattering_index': ...,                # Enhanced FFT-based metric\n        'control_smoothness_index': ...,        # Total Variation Diminishing\n        'high_frequency_power_ratio': ...,      # Spectral power >10 Hz\n        'boundary_layer_effectiveness': ...,     # Time in boundary layer\n        'lipschitz_constant': ...,              # Smoothness measure\n        'tracking_error_rms': ...               # Performance validation\n    }",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b09c1ec4"
  },
  {
    "id": "issue_12_chattering_reduction_resolution_3_6248ccf8",
    "file": "docs\\issue_12_chattering_reduction_resolution.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _tanh_switching(self, s, epsilon, slope=3.0):\n    \"\"\"Configurable slope for tunable smoothness.\n\n    Formula: tanh((slope * s) / \u03b5)\n\n    Slope Parameter:\n    - Original: Implicit 10+ (steep, near-discontinuous)\n    - Optimized: 3.0 (gentle, smooth transitions)\n    - Range: 2-5 for chattering reduction\n    \"\"\"\n    ratio = (slope * s) / epsilon\n    if abs(ratio) > 700:\n        return np.sign(s)\n    return np.tanh(ratio)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6248ccf8"
  },
  {
    "id": "issue_12_chattering_reduction_resolution_4_0b61835b",
    "file": "docs\\issue_12_chattering_reduction_resolution.md",
    "index": 4,
    "code": "def sign_switching(s, epsilon=0.0):\n    \"\"\"DEPRECATED - causes severe chattering.\n\n    WARNING: Use tanh_switching(s, epsilon, slope=3.0) instead.\n    \"\"\"\n    warnings.warn(\"sign_switching() causes severe chattering\", DeprecationWarning)\n    return np.sign(s)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0b61835b"
  },
  {
    "id": "issue_12_chattering_reduction_resolution_5_4214da73",
    "file": "docs\\issue_12_chattering_reduction_resolution.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.chattering_reduction\n@pytest.mark.parametrize(\"controller_type\", [\n    \"classical_smc\", \"adaptive_smc\", \"sta_smc\", \"hybrid_adaptive_sta_smc\"\n])\nclass TestChatteringReductionEffectiveness:\n    \"\"\"Validates all 5 acceptance criteria for Issue #12.\"\"\"\n\n    def test_chattering_reduction_effectiveness(self, controller_type):\n        # Run 10-second simulation\n        # Collect control signal, states, sliding surface\n\n        # === CRITERION 1: Chattering Index < 2.0 ===\n        chattering_index = 0.7 * time_domain + 0.3 * freq_domain\n        assert chattering_index < 2.0\n\n        # === CRITERION 2: Boundary Layer Effectiveness > 0.8 ===\n        time_in_boundary = np.sum(|sigma| <= epsilon) / len(sigma)\n        assert time_in_boundary > 0.8\n\n        # === CRITERION 3: Control Smoothness > 0.7 ===\n        smoothness = 1.0 / (1.0 + TotalVariation(control))\n        assert smoothness > 0.7\n\n        # === CRITERION 4: High-Freq Power < 0.1 ===\n        hf_ratio = PowerAbove10Hz / TotalPower\n        assert hf_ratio < 0.1\n\n        # === CRITERION 5: Performance Degradation < 5% ===\n        degradation = (actual_error - baseline) / baseline\n        assert degradation < 0.05",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4214da73"
  },
  {
    "id": "issue_12_continuation_prompt_1_3c3b05cd",
    "file": "docs\\issue_12_continuation_prompt.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Multi-objective fitness function\nfitness = tracking_error_rms + 10.0 * max(0, chattering_index - 2.0)\n\n# Chattering metric (matches validation test)\nchattering_index = 0.7 * RMS(du/dt) + 0.3 * FFT_high_freq_power\n\n# PSO parameters\nn_particles = 30\niters = 150\nseed = 42\nc1 = 2.0  # cognitive\nc2 = 2.0  # social\nw = 0.7   # inertia\n\n# Simulation config\ndt = 0.01\nt_final = 10.0\ninitial_state = [0.0, 0.1, 0.1, 0.0, 0.0, 0.0]",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c3b05cd"
  },
  {
    "id": "issue_12_continuation_prompt_2_94d6ac9d",
    "file": "docs\\issue_12_continuation_prompt.md",
    "index": 2,
    "code": "# Update controller_defaults (factory fallback)\n  updated_default = default_ctrl_config.model_copy(update={'gains': gains.tolist()})\n  setattr(temp_config.controller_defaults, controller_type, updated_default)\n\n  # Update controllers (primary source)\n  updated_ctrl = ctrl_config.model_copy(update={'gains': gains.tolist()})\n  setattr(temp_config.controllers, controller_type, updated_ctrl)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94d6ac9d"
  },
  {
    "id": "issue_12_continuation_prompt_3_e3f43381",
    "file": "docs\\issue_12_continuation_prompt.md",
    "index": 3,
    "code": "# WRONG - Silent failure (Pydantic models are frozen)\nsetattr(config.controllers.classical_smc, 'gains', new_gains)\n\n# CORRECT - Creates new immutable object\nupdated = config.controllers.classical_smc.model_copy(update={'gains': new_gains})\nsetattr(config.controllers, 'classical_smc', updated)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3f43381"
  },
  {
    "id": "issue_12_continuation_prompt_4_949b5f6a",
    "file": "docs\\issue_12_continuation_prompt.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Time domain: RMS of control derivative\ncontrol_derivative = np.gradient(control_history, dt)\ntime_domain_index = np.sqrt(np.mean(control_derivative**2))\n\n# Frequency domain: High-frequency power ratio\nspectrum = np.abs(fft(control_history))\nfreqs = fftfreq(len(control_history), d=dt)\nhf_power = np.sum(spectrum[np.abs(freqs) > 10.0])\ntotal_power = np.sum(spectrum) + 1e-12\nfreq_domain_index = hf_power / total_power\n\n# Composite index (0.7/0.3 weighting)\nchattering_index = 0.7 * time_domain_index + 0.3 * freq_domain_index",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "949b5f6a"
  },
  {
    "id": "issue_12_continuation_prompt_5_17ba6bbf",
    "file": "docs\\issue_12_continuation_prompt.md",
    "index": 5,
    "code": "# In optimize_chattering_direct.py, update control extraction logic:\nif controller_type == \"hybrid_adaptive_sta_smc\":\n    result = controller.compute_control(state, last_control)\n    # Hybrid returns dict, not standard output\n    if isinstance(result, dict):\n        control_output = result.get('control', result.get('u', 0.0))\n    else:\n        control_output = float(result)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17ba6bbf"
  },
  {
    "id": "issue_12_final_completion_guide_1_c663989a",
    "file": "docs\\issue_12_final_completion_guide.md",
    "index": 1,
    "code": "fitness = tracking_error_rms + chattering_penalty + tracking_penalty + effort_penalty",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c663989a"
  },
  {
    "id": "issue_12_final_completion_guide_2_0f0fcdad",
    "file": "docs\\issue_12_final_completion_guide.md",
    "index": 2,
    "code": "fitness = chattering_index * 10.0 + tracking_error_rms * 1.0\n   # Or pure chattering: fitness = chattering_index",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f0fcdad"
  },
  {
    "id": "issue_12_final_resolution_1_c836bea8",
    "file": "docs\\issue_12_final_resolution.md",
    "index": 1,
    "code": "# Original fitness (optimize_chattering_direct.py):\nfitness = tracking_error_rms + chattering_penalty + tracking_penalty + effort_penalty\n\n# Where:\nchattering_penalty = max(0, chattering_index - 2.0) * 10.0",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c836bea8"
  },
  {
    "id": "issue_12_final_resolution_2_7eb27afa",
    "file": "docs\\issue_12_final_resolution.md",
    "index": 2,
    "code": "# Corrected fitness:\nfitness = chattering_index  # Direct minimization!\n# + tracking_constraint_penalty if tracking > 0.1",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7eb27afa"
  },
  {
    "id": "issue_12_final_resolution_3_dd901646",
    "file": "docs\\issue_12_final_resolution.md",
    "index": 3,
    "code": "elif isinstance(result, np.ndarray):\n    control_output = float(result.flat[0])",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd901646"
  },
  {
    "id": "issue_12_pso_failure_analysis_1_fe550886",
    "file": "docs\\issue_12_pso_failure_analysis.md",
    "index": 1,
    "code": "# From optimize_chattering_direct.py\nfitness = tracking_error + chattering_penalty\nchattering_penalty = max(0, chattering - 2.0) * 10.0  # ZERO if chattering < 2.0!\n\n# If tracking good and chattering < 2.0: fitness = 0.0\n# Result: No optimization pressure on chattering!",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe550886"
  },
  {
    "id": "issue_12_pso_failure_analysis_2_98a3fcb1",
    "file": "docs\\issue_12_pso_failure_analysis.md",
    "index": 2,
    "code": "# From optimize_chattering_focused.py (CORRECT)\nfitness = chattering_index + tracking_constraint_penalty\n\n# Direct chattering minimization\nif tracking_error_rms > 0.1:\n    tracking_constraint_penalty = (tracking_error_rms - 0.1) * 1000.0\nelse:\n    tracking_constraint_penalty = 0.0\n\n# Chattering is PRIMARY objective, tracking is CONSTRAINT",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "98a3fcb1"
  },
  {
    "id": "issue_12_pso_implementation_summary_1_9c6bbd5b",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 1,
    "code": "# In pso_optimizer.py _compute_cost_from_traj\ncontrol_rate_normalized = du_sq / 1000.0  # e.g., 500 / 1000 = 0.5\nweighted_rate = 0.01 * 0.5 = 0.005        # Negligible!\n\n# Chattering (high du_sq) is invisible to optimizer",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c6bbd5b"
  },
  {
    "id": "issue_12_pso_implementation_summary_2_ce758686",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef simulate_and_evaluate(gains, controller_type, config, dynamics):\n    \"\"\"Direct simulation with explicit chattering metrics.\"\"\"\n\n    # No excessive normalization\n    control_derivative = np.gradient(control_hist, dt)\n    time_domain_index = np.sqrt(np.mean(control_derivative**2))\n\n    # FFT spectral analysis\n    spectrum = np.abs(fft(control_hist))\n    hf_power_ratio = high_freq_power / total_power  # f > 10 Hz\n\n    # Combined chattering index (Issue #12 metric)\n    chattering_index = 0.7 * time_domain_index + 0.3 * hf_power_ratio\n\n    # Multi-objective fitness with explicit penalties\n    chattering_penalty = max(0.0, chattering_index - 2.0) * 10.0\n    tracking_penalty = max(0.0, tracking_error_rms - 0.1) * 100.0\n    effort_penalty = max(0.0, control_effort_rms - 100.0) * 0.1\n\n    fitness = tracking_error_rms + chattering_penalty + tracking_penalty + effort_penalty\n    return fitness",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce758686"
  },
  {
    "id": "issue_12_pso_implementation_summary_3_deed636f",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 3,
    "code": "n_particles: 50          # Increased for better exploration\niters: 300               # Longer convergence for multi-objective\nw: 0.7                   # Inertia weight (exploration vs exploitation)\nc1: 2.0                  # Cognitive coefficient (personal best)\nc2: 2.0                  # Social coefficient (global best)\nseed: 42                 # Reproducibility",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "deed636f"
  },
  {
    "id": "issue_12_pso_implementation_summary_4_ffb54aa0",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 4,
    "code": "chattering_target = 2.0           # Issue #12 target\ntracking_target = 0.1             # Tracking constraint (rad)\neffort_target = 100.0             # Control effort constraint (N RMS)\n\n# Penalty weights\nchattering_penalty_weight = 10.0   # Secondary objective\ntracking_penalty_weight = 100.0    # Hard constraint (must not violate)\neffort_penalty_weight = 0.1        # Soft constraint",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ffb54aa0"
  },
  {
    "id": "issue_12_pso_implementation_summary_5_33a4b0c9",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 5,
    "code": "def test_pso_tuner_chattering_optimization():\n       \"\"\"Verify PSOTuner properly optimizes for chattering.\"\"\"\n       tuner = PSOTuner(controller_factory, config, seed=42)\n       result = tuner.optimise(iters_override=10)\n\n       # Assert cost is not zero\n       assert result['best_cost'] > 0.0\n\n       # Assert chattering metric is included\n       validation = validate_controller_chattering(result['best_pos'])\n       assert validation['chattering_index'] < baseline_chattering",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33a4b0c9"
  },
  {
    "id": "issue_12_pso_implementation_summary_6_351f6c76",
    "file": "docs\\issue_12_pso_implementation_summary.md",
    "index": 6,
    "code": "chattering_index = 0.7 * sqrt(mean((du/dt)^2)) + 0.3 * (HF_power / total_power)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "351f6c76"
  },
  {
    "id": "issue_12_pso_optimization_report_1_a16c3fe7",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Primary Objective: Maintain tracking performance\ntracking_error_rms = sqrt(mean(theta1^2 + theta2^2))\n\n# Secondary Objective: Reduce chattering\nchattering_index = 0.7 * time_domain_index + 0.3 * freq_domain_index\n\nwhere:\n  time_domain_index = RMS(d(control)/dt)\n  freq_domain_index = HF_power / total_power (f > 10 Hz)\n\n# Combined Fitness\nfitness = tracking_error_rms + 10.0 * max(0, chattering_index - 2.0)\n\n# Constraints:\n- tracking_error_rms < 0.1 rad\n- chattering_index < 2.0\n- control_effort < 100 N RMS",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a16c3fe7"
  },
  {
    "id": "issue_12_pso_optimization_report_2_0a16b490",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 2,
    "code": "# In _compute_cost_from_traj:\nise_normalized = ise / 10.0       # e.g., 5.0 / 10.0 = 0.5\nweighted_cost = 1.0 * 0.5 = 0.5\n\ncontrol_effort_norm = u_sq / 100.0  # e.g., 1000 / 100 = 10.0\nweighted_ctrl = 0.1 * 10.0 = 1.0\n\ncontrol_rate_norm = du_sq / 1000.0  # e.g., 500 / 1000 = 0.5\nweighted_rate = 0.01 * 0.5 = 0.005  # Negligible!\n\n# Total cost is dominated by tracking, control derivative term vanishes\n# PSO sees all particles as nearly equivalent (cost \u2248 0.0)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a16b490"
  },
  {
    "id": "issue_12_pso_optimization_report_3_76d14a34",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# optimize_chattering_direct.py\n\ndef simulate_and_evaluate(gains, controller_type, config, dynamics):\n    \"\"\"Direct simulation with chattering metrics.\"\"\"\n\n    # Compute chattering without excessive normalization\n    control_derivative = np.gradient(control_hist, dt)\n    time_domain_index = np.sqrt(np.mean(control_derivative**2))\n\n    spectrum = np.abs(fft(control_hist))\n    hf_power_ratio = high_freq_power / total_power\n\n    chattering_index = 0.7 * time_domain_index + 0.3 * hf_power_ratio\n\n    # Explicit multi-objective fitness\n    chattering_penalty = max(0.0, chattering_index - 2.0) * 10.0\n    tracking_penalty = max(0.0, tracking_error - 0.1) * 100.0\n\n    fitness = tracking_error_rms + chattering_penalty + tracking_penalty\n    return fitness\n\n# Use PySwarms GlobalBestPSO directly\noptimizer = GlobalBestPSO(n_particles=50, dimensions=n_dims, options=pso_options, bounds=bounds)\nbest_cost, best_gains = optimizer.optimize(objective_function, iters=300)",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76d14a34"
  },
  {
    "id": "issue_12_pso_optimization_report_4_8fe0e34d",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 4,
    "code": "# From config.yaml pso.bounds\nclassical_smc:  6 gains [1.0-100.0, 1.0-100.0, 1.0-20.0, 1.0-20.0, 5.0-150.0, 0.1-10.0]\nadaptive_smc:   5 gains [1.0-100.0, 1.0-100.0, 1.0-20.0, 1.0-20.0, 0.1-10.0]\nsta_smc:        6 gains [2.0-100.0, 1.0-99.0, 1.0-20.0, 1.0-20.0, 5.0-150.0, 0.1-10.0]\nhybrid_adaptive_sta_smc: 4 gains [1.0-100.0, 1.0-100.0, 1.0-20.0, 1.0-20.0]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8fe0e34d"
  },
  {
    "id": "issue_12_pso_optimization_report_5_454f1bd1",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 5,
    "code": "chattering_target = 2.0           # Issue #12 target\ntracking_target = 0.1             # Max acceptable tracking error (rad)\neffort_target = 100.0             # Control effort constraint (N RMS)\n\nchattering_penalty_weight = 10.0  # Secondary objective weight\ntracking_penalty_weight = 100.0   # Hard constraint weight\neffort_penalty_weight = 0.1       # Soft constraint weight",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "454f1bd1"
  },
  {
    "id": "issue_12_pso_optimization_report_6_d444fb97",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n   # In pso_optimizer.py _compute_cost_from_traj\n\n   # Add chattering index calculation\n   control_derivative = np.gradient(u_b, dt_const, axis=1)\n   chattering_time = np.sqrt(np.mean(control_derivative**2, axis=1))\n\n   # Add FFT spectral analysis\n   # ... (similar to optimize_chattering_direct.py)\n\n   # Add to fitness\n   chattering_index = 0.7 * chattering_time + 0.3 * freq_index\n   chattering_penalty = max(0, chattering_index - 2.0) * penalty_weight\n   J += chattering_penalty",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d444fb97"
  },
  {
    "id": "issue_12_pso_optimization_report_7_73b550d6",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 7,
    "code": "def test_pso_tuner_chattering_optimization():\n       \"\"\"Verify PSOTuner properly optimizes for chattering reduction.\"\"\"\n       # Create tuner with chattering-focused cost\n       # Run optimization\n       # Assert chattering_index decreased\n       # Assert cost > 0.0 (no more zero-cost bug)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "73b550d6"
  },
  {
    "id": "issue_12_pso_optimization_report_8_f13c1b8a",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 8,
    "code": "control_derivative = np.gradient(control_signal, dt)\ntime_domain_index = np.sqrt(np.mean(control_derivative**2))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f13c1b8a"
  },
  {
    "id": "issue_12_pso_optimization_report_9_21cdc3bc",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 9,
    "code": "spectrum = np.abs(fft(control_signal))\nfreqs = fftfreq(len(control_signal), d=dt)\nhf_mask = np.abs(freqs) > 10.0  # High-frequency threshold\nhf_power_ratio = sum(spectrum[hf_mask]) / sum(spectrum)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21cdc3bc"
  },
  {
    "id": "issue_12_pso_optimization_report_10_164dd5d8",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 10,
    "code": "chattering_index = 0.7 * time_domain_index + 0.3 * hf_power_ratio",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "164dd5d8"
  },
  {
    "id": "issue_12_pso_optimization_report_11_a6bf1b06",
    "file": "docs\\issue_12_pso_optimization_report.md",
    "index": 11,
    "code": "# Run comprehensive validation\npytest tests/test_integration/test_numerical_stability/test_numerical_stability_deep.py::TestChatteringReductionEffectiveness -v\n\n# Expected output:\n# 1. Chattering Index: X.XX / 2.0 (PASS/FAIL)\n# 2. Boundary Layer Effectiveness: X.XX / 0.8 (PASS/FAIL)\n# 3. Control Smoothness: X.XX / 0.7 (PASS/FAIL)\n# 4. High-Frequency Power Ratio: X.XX / 0.1 (PASS/FAIL)\n# 5. Performance Degradation: X.X% / 5% (PASS/FAIL)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6bf1b06"
  },
  {
    "id": "issue_12_session_continuation_20250930_1_0edf2356",
    "file": "docs\\issue_12_session_continuation_20250930.md",
    "index": 1,
    "code": "# Current fitness (optimize_chattering_direct.py):\nchattering_penalty = max(0, chattering_index - 2.0) * 10.0\n# \u2191 This is ZERO when chattering < 2.0!\n\nfitness = tracking_error_rms + chattering_penalty + tracking_penalty + effort_penalty\n# \u2191 Dominated by tracking_error_rms",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0edf2356"
  },
  {
    "id": "issue_12_session_continuation_20250930_2_a2010789",
    "file": "docs\\issue_12_session_continuation_20250930.md",
    "index": 2,
    "code": "fitness = chattering_index  # Direct minimization!\n  # + tracking_constraint_penalty if tracking > 0.1",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a2010789"
  },
  {
    "id": "issue_2_resolution_verification_report_1_479b3a9a",
    "file": "docs\\issue_2_resolution_verification_report.md",
    "index": 1,
    "code": "optimized_gains = [8.0, 5.0, 12.0, 6.0, 4.85, 3.43]\ncontroller = SuperTwistingSMC(gains=optimized_gains, dt=0.01, max_force=150.0)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "479b3a9a"
  },
  {
    "id": "mathematical_algorithm_validation_1_a929e401",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state: np.ndarray, target: np.ndarray) -> float:\n    \"\"\"Compute SMC control signal.\"\"\"\n    # Extract state variables\n    theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n\n    # Compute errors\n    e1 = theta1 - target[0]  # Position error pendulum 1\n    e2 = theta2 - target[1]  # Position error pendulum 2\n    e1_dot = theta1_dot - target[3]  # Velocity error pendulum 1\n    e2_dot = theta2_dot - target[4]  # Velocity error pendulum 2\n\n    # Sliding surface: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n    s = self.lambda1 * e1 + self.lambda2 * e2 + e1_dot + e2_dot\n\n    # Control law: u = u_eq + u_sw\n    u_equivalent = self._compute_equivalent_control(state, target)\n    u_switching = -self.K * np.sign(s)\n\n    return u_equivalent + u_switching",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a929e401"
  },
  {
    "id": "mathematical_algorithm_validation_2_bc036f8e",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state: np.ndarray, target: np.ndarray) -> float:\n    \"\"\"Compute Super-Twisting control signal.\"\"\"\n    # Compute sliding surface\n    s = self._compute_sliding_surface(state, target)\n\n    # Super-Twisting control law\n    # u\u2081 = -\u03b1\u2081|s|^(1/2) sign(s)\n    u1 = -self.alpha1 * np.power(np.abs(s), 0.5) * np.sign(s)\n\n    # u\u2082 = \u222b(-\u03b1\u2082 sign(s)) dt\n    self.integral_term += -self.alpha2 * np.sign(s) * self.dt\n\n    return u1 + self.integral_term",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc036f8e"
  },
  {
    "id": "mathematical_algorithm_validation_3_911e3aff",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 3,
    "code": "def update_parameters(self, state: np.ndarray, s: float) -> None:\n    \"\"\"Update adaptive parameters.\"\"\"\n    # Regressor vector \u03a6(x, \u1e8b)\n    phi = self._compute_regressor(state)\n\n    # Adaptive law: \u03b8\u0307 = \u03b3 \u03a6(x, \u1e8b) s\n    self.theta_hat += self.gamma * phi * s * self.dt\n\n    # Parameter bounds enforcement\n    self.theta_hat = np.clip(self.theta_hat, self.theta_min, self.theta_max)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "911e3aff"
  },
  {
    "id": "mathematical_algorithm_validation_4_a2aba1e3",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef update_particles(self):\n    \"\"\"Update particle velocities and positions.\"\"\"\n    for i in range(self.n_particles):\n        # Random coefficients\n        r1, r2 = np.random.random(2)\n\n        # Velocity update with constriction factor\n        self.velocities[i] = self.chi * (\n            self.w * self.velocities[i] +\n            self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) +\n            self.c2 * r2 * (self.global_best_position - self.positions[i])\n        )\n\n        # Position update\n        self.positions[i] += self.velocities[i]\n\n        # Boundary handling\n        self.positions[i] = np.clip(self.positions[i], self.bounds_min, self.bounds_max)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a2aba1e3"
  },
  {
    "id": "mathematical_algorithm_validation_5_603db041",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_numerical_stability(self, dt: float, control_signal: float) -> bool:\n    \"\"\"Validate numerical stability conditions.\"\"\"\n    # Check sampling time constraint\n    max_dt = 2 * self.K - 2 * self.d_max / (self.K ** 2)\n    if dt > max_dt:\n        raise ValueError(f\"Sampling time {dt} too large for stability\")\n\n    # Check control signal bounds\n    if abs(control_signal) > self.u_max:\n        warnings.warn(\"Control signal exceeds saturation limits\")\n\n    return True",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "603db041"
  },
  {
    "id": "mathematical_algorithm_validation_6_1e2c0c4d",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef monte_carlo_validation(n_trials: int = 10000) -> Dict[str, float]:\n    \"\"\"Monte Carlo validation of algorithm robustness.\"\"\"\n    success_rate = 0\n    performance_metrics = []\n\n    for trial in range(n_trials):\n        # Random parameter perturbation\n        perturbed_params = add_random_perturbation(base_params)\n\n        # Run simulation\n        result = run_simulation(perturbed_params)\n\n        if result.stability_achieved:\n            success_rate += 1\n            performance_metrics.append(result.performance_index)\n\n    return {\n        'success_rate': success_rate / n_trials,\n        'mean_performance': np.mean(performance_metrics),\n        'std_performance': np.std(performance_metrics)\n    }",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e2c0c4d"
  },
  {
    "id": "mathematical_algorithm_validation_7_1849dfe5",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 7,
    "code": "# Mathematical definition: s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\ndef compute_sliding_surface(self, state, target):\n    e1 = state[0] - target[0]  # \u03b8\u2081 error\n    e2 = state[1] - target[1]  # \u03b8\u2082 error\n    e1_dot = state[3] - target[3]  # \u03b8\u0307\u2081 error\n    e2_dot = state[4] - target[4]  # \u03b8\u0307\u2082 error\n\n    return self.lambda1 * e1 + self.lambda2 * e2 + e1_dot + e2_dot",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1849dfe5"
  },
  {
    "id": "mathematical_algorithm_validation_8_0664d84e",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 8,
    "code": "# Mathematical definition: v\u1d62^(t+1) = \u03c7[w\u00b7v\u1d62^t + c\u2081r\u2081(p\u1d62 - x\u1d62^t) + c\u2082r\u2082(g - x\u1d62^t)]\ndef update_velocity(self, particle_idx):\n    r1, r2 = np.random.random(2)\n    velocity = self.chi * (\n        self.w * self.velocities[particle_idx] +\n        self.c1 * r1 * (self.personal_best[particle_idx] - self.positions[particle_idx]) +\n        self.c2 * r2 * (self.global_best - self.positions[particle_idx])\n    )\n    return velocity",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0664d84e"
  },
  {
    "id": "mathematical_algorithm_validation_9_a9e12828",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestMathematicalCorrectness:\n    \"\"\"Test mathematical properties of implementations.\"\"\"\n\n    def test_lyapunov_function_properties(self):\n        \"\"\"Test Lyapunov function is positive definite.\"\"\"\n        controller = ClassicalSMC()\n        for _ in range(1000):\n            state = np.random.uniform(-\u03c0, \u03c0, 6)\n            V = controller.compute_lyapunov_function(state)\n\n            # Property 1: V \u2265 0\n            assert V >= 0\n\n            # Property 2: V = 0 only at equilibrium\n            if not np.allclose(state, 0):\n                assert V > 0\n\n    def test_sliding_surface_stability(self):\n        \"\"\"Test sliding surface leads to stable dynamics.\"\"\"\n        controller = ClassicalSMC(lambda1=2.0, lambda2=1.5)\n\n        # Test exponential stability on sliding surface\n        dt = 0.01\n        times = np.arange(0, 5, dt)\n\n        for initial_error in [0.1, 0.5, 1.0]:\n            e1_history = [initial_error]\n            e2_history = [initial_error]\n\n            for t in times[1:]:\n                # Sliding dynamics: \u0117\u2081 + \u03bb\u2081e\u2081 = 0, \u0117\u2082 + \u03bb\u2082e\u2082 = 0\n                e1_new = e1_history[-1] * np.exp(-controller.lambda1 * dt)\n                e2_new = e2_history[-1] * np.exp(-controller.lambda2 * dt)\n\n                e1_history.append(e1_new)\n                e2_history.append(e2_new)\n\n            # Verify exponential decay\n            assert e1_history[-1] < 0.01 * initial_error\n            assert e2_history[-1] < 0.01 * initial_error",
    "lines": 43,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9e12828"
  },
  {
    "id": "mathematical_algorithm_validation_10_1afe4932",
    "file": "docs\\mathematical_algorithm_validation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_end_to_end_mathematical_properties():\n    \"\"\"Test mathematical properties in complete system.\"\"\"\n\n    # Initialize system\n    system = DoubleInvertedPendulum()\n    controller = ClassicalSMC()\n\n    # Initial condition away from equilibrium\n    x0 = np.array([0.2, 0.1, 0.0, 0.0, 0.0, 0.0])\n    target = np.zeros(6)\n\n    # Simulate system\n    trajectory = simulate_system(system, controller, x0, target, t_final=10.0)\n\n    # Mathematical property verification\n\n    # 1. Verify Lyapunov function decreases\n    V_values = [controller.compute_lyapunov_function(state) for state in trajectory.states]\n    assert np.all(np.diff(V_values) <= 0), \"Lyapunov function must be non-increasing\"\n\n    # 2. Verify convergence to target\n    final_error = np.linalg.norm(trajectory.states[-1] - target)\n    assert final_error < 0.01, f\"Final error {final_error} too large\"\n\n    # 3. Verify control signal bounds\n    max_control = np.max(np.abs(trajectory.controls))\n    assert max_control <= controller.u_max, \"Control signal exceeds limits\"",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1afe4932"
  },
  {
    "id": "mathematical_validation_procedures_1_d32d1a7e",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_lyapunov_stability(controller: SMCController,\n                              test_scenarios: List[TestScenario]) -> LyapunovValidationResult:\n    \"\"\"\n    Validate Lyapunov stability condition for SMC controller.\n\n    Mathematical Verification:\n    - Verifies V\u0307(s) = s\u00b7\u1e61 < 0 for all s \u2260 0\n    - Tests across representative state space\n    - Validates finite-time convergence properties\n\n    Parameters\n    ----------\n    controller : SMCController\n        Controller instance to validate\n    test_scenarios : List[TestScenario]\n        Representative test scenarios covering state space\n\n    Returns\n    -------\n    LyapunovValidationResult\n        Comprehensive stability validation results\n    \"\"\"\n\n    validation_results = []\n    stability_violations = []\n\n    for scenario in test_scenarios:\n        # Generate state trajectory\n        t, states = simulate_scenario(controller, scenario)\n\n        for i, state in enumerate(states):\n            # Compute sliding surface value\n            s = controller.compute_sliding_surface(state, scenario.target)\n\n            # Skip points on sliding surface (within tolerance)\n            if abs(s) < SLIDING_SURFACE_TOLERANCE:\n                continue\n\n            # Compute sliding surface derivative\n            s_dot = controller.compute_surface_derivative(state, scenario.target)\n\n            # Lyapunov stability condition: V\u0307 = s\u00b7\u1e61 < 0\n            v_dot = s * s_dot\n\n            if v_dot >= 0:\n                stability_violations.append(StabilityViolation(\n                    scenario=scenario.name,\n                    time=t[i],\n                    state=state,\n                    sliding_surface=s,\n                    surface_derivative=s_dot,\n                    lyapunov_derivative=v_dot,\n                    violation_magnitude=v_dot\n                ))\n\n            validation_results.append(LyapunovTestPoint(\n                scenario=scenario.name,\n                time=t[i],\n                sliding_surface=s,\n                lyapunov_derivative=v_dot,\n                stable=v_dot < 0\n            ))\n\n    # Calculate stability metrics\n    total_points = len(validation_results)\n    stable_points = len([r for r in validation_results if r.stable])\n    stability_percentage = (stable_points / total_points) * 100 if total_points > 0 else 0\n\n    return LyapunovValidationResult(\n        total_test_points=total_points,\n        stable_points=stable_points,\n        stability_percentage=stability_percentage,\n        stability_violations=stability_violations,\n        validation_status='passed' if not stability_violations else 'failed',\n        mathematical_interpretation=_interpret_lyapunov_results(stability_percentage, stability_violations)\n    )\n\ndef _interpret_lyapunov_results(stability_percentage: float,\n                               violations: List[StabilityViolation]) -> str:\n    \"\"\"Generate mathematical interpretation of Lyapunov stability results.\"\"\"\n\n    if stability_percentage >= 99.9:\n        return \"Lyapunov stability condition satisfied across test space. Controller theoretically stable.\"\n    elif stability_percentage >= 95.0:\n        interpretation = f\"Lyapunov stability satisfied for {stability_percentage:.1f}% of test points. \"\n        if violations:\n            violation_regions = _analyze_violation_regions(violations)\n            interpretation += f\"Violations concentrated in {violation_regions}. Consider gain tuning.\"\n        return interpretation\n    else:\n        return f\"Significant Lyapunov stability violations ({100-stability_percentage:.1f}%). Controller stability not verified.\"",
    "lines": 94,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d32d1a7e"
  },
  {
    "id": "mathematical_validation_procedures_2_99add07c",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_sliding_surface_reachability(controller: SMCController,\n                                        test_scenarios: List[TestScenario]) -> ReachabilityValidationResult:\n    \"\"\"\n    Validate sliding surface reachability condition.\n\n    Mathematical Foundation:\n    Reachability condition: s\u00b7\u1e61 \u2264 -\u03b7|s| where \u03b7 > 0\n\n    Finite-time reaching: t_reach \u2264 |s\u2080|/\u03b7\n    \"\"\"\n\n    reachability_results = []\n\n    for scenario in test_scenarios:\n        initial_state = scenario.initial_state\n        target_state = scenario.target_state\n\n        # Compute initial sliding surface value\n        s0 = controller.compute_sliding_surface(initial_state, target_state)\n\n        if abs(s0) < SLIDING_SURFACE_TOLERANCE:\n            # Already on sliding surface\n            continue\n\n        # Simulate trajectory to sliding surface\n        t, states = simulate_to_sliding_surface(controller, scenario)\n\n        # Find reaching time\n        reaching_time = None\n        for i, state in enumerate(states):\n            s = controller.compute_sliding_surface(state, target_state)\n            if abs(s) < SLIDING_SURFACE_TOLERANCE:\n                reaching_time = t[i]\n                break\n\n        # Validate reachability condition along trajectory\n        reachability_condition_satisfied = True\n        reaching_rate_violations = []\n\n        for i, state in enumerate(states):\n            if reaching_time and t[i] > reaching_time:\n                break  # Stop after reaching sliding surface\n\n            s = controller.compute_sliding_surface(state, target_state)\n            s_dot = controller.compute_surface_derivative(state, target_state)\n\n            # Reachability condition: s\u00b7\u1e61 \u2264 -\u03b7|s|\n            reaching_condition = s * s_dot\n            required_reaching_rate = -controller.reaching_rate * abs(s)\n\n            if reaching_condition > required_reaching_rate:\n                reachability_condition_satisfied = False\n                reaching_rate_violations.append(ReachingRateViolation(\n                    time=t[i],\n                    state=state,\n                    sliding_surface=s,\n                    surface_derivative=s_dot,\n                    reaching_condition=reaching_condition,\n                    required_rate=required_reaching_rate\n                ))\n\n        # Theoretical reaching time bound\n        theoretical_reaching_time = abs(s0) / controller.reaching_rate if controller.reaching_rate > 0 else float('inf')\n\n        reachability_results.append(ReachabilityTestResult(\n            scenario=scenario.name,\n            initial_sliding_surface=s0,\n            actual_reaching_time=reaching_time,\n            theoretical_reaching_time=theoretical_reaching_time,\n            reachability_condition_satisfied=reachability_condition_satisfied,\n            reaching_rate_violations=reaching_rate_violations,\n            finite_time_reachable=reaching_time is not None and reaching_time < float('inf')\n        ))\n\n    return ReachabilityValidationResult(\n        test_results=reachability_results,\n        overall_reachability=all(r.finite_time_reachable for r in reachability_results),\n        reachability_percentage=len([r for r in reachability_results if r.finite_time_reachable]) / len(reachability_results) * 100,\n        mathematical_interpretation=_interpret_reachability_results(reachability_results)\n    )",
    "lines": 83,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "99add07c"
  },
  {
    "id": "mathematical_validation_procedures_3_d57d6185",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_chattering_characteristics(controller: SMCController,\n                                      test_scenarios: List[TestScenario]) -> ChatteringValidationResult:\n    \"\"\"\n    Analyze and validate chattering characteristics.\n\n    Mathematical Metrics:\n    - Chattering Index: CI = (1/T)\u222b|u(t) - u_avg(t)|dt\n    - Frequency Content: Dominant frequencies in control signal\n    - Amplitude Analysis: Peak-to-peak chattering amplitude\n    \"\"\"\n\n    chattering_results = []\n\n    for scenario in test_scenarios:\n        t, states, controls = simulate_with_control_history(controller, scenario)\n\n        # Calculate chattering index\n        control_signal = np.array(controls)\n\n        # Moving average filter for averaged control\n        window_size = int(0.1 / scenario.dt)  # 100ms window\n        u_avg = np.convolve(control_signal, np.ones(window_size)/window_size, mode='same')\n\n        # Chattering index calculation\n        chattering_deviation = np.abs(control_signal - u_avg)\n        chattering_index = np.mean(chattering_deviation)\n\n        # Frequency analysis\n        frequencies, power_spectrum = signal.welch(control_signal, fs=1/scenario.dt)\n        dominant_frequency = frequencies[np.argmax(power_spectrum)]\n\n        # Amplitude analysis\n        control_range = np.max(control_signal) - np.min(control_signal)\n\n        # Assess chattering severity\n        chattering_severity = _assess_chattering_severity(\n            chattering_index, dominant_frequency, control_range\n        )\n\n        chattering_results.append(ChatteringTestResult(\n            scenario=scenario.name,\n            chattering_index=chattering_index,\n            dominant_frequency=dominant_frequency,\n            control_range=control_range,\n            chattering_severity=chattering_severity,\n            acceptable_chattering=chattering_index < ACCEPTABLE_CHATTERING_THRESHOLD\n        ))\n\n    return ChatteringValidationResult(\n        test_results=chattering_results,\n        overall_chattering_acceptable=all(r.acceptable_chattering for r in chattering_results),\n        average_chattering_index=np.mean([r.chattering_index for r in chattering_results]),\n        mathematical_interpretation=_interpret_chattering_results(chattering_results)\n    )\n\ndef _assess_chattering_severity(chattering_index: float,\n                               dominant_frequency: float,\n                               control_range: float) -> str:\n    \"\"\"Assess chattering severity based on multiple metrics.\"\"\"\n\n    # Chattering severity classification\n    if chattering_index < 0.1:\n        severity = \"minimal\"\n    elif chattering_index < 0.5:\n        severity = \"low\"\n    elif chattering_index < 1.0:\n        severity = \"moderate\"\n    else:\n        severity = \"high\"\n\n    # Frequency considerations\n    if dominant_frequency > 100:  # Hz\n        severity += \"_high_frequency\"\n\n    # Control range considerations\n    if control_range > 0.8 * MAX_CONTROL_INPUT:\n        severity += \"_large_amplitude\"\n\n    return severity",
    "lines": 82,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d57d6185"
  },
  {
    "id": "mathematical_validation_procedures_4_1818c598",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_pso_convergence_properties(pso_optimizer: PSOOptimizer,\n                                       benchmark_functions: List[BenchmarkFunction]) -> PSOConvergenceValidationResult:\n    \"\"\"\n    Validate PSO convergence properties using benchmark functions.\n\n    Mathematical Foundation:\n    - Clerc-Kennedy convergence conditions\n    - Global convergence analysis\n    - Convergence rate estimation\n    \"\"\"\n\n    convergence_results = []\n\n    for benchmark_func in benchmark_functions:\n        # Run multiple PSO trials\n        trial_results = []\n\n        for trial in range(NUM_PSO_TRIALS):\n            # Initialize PSO with validated parameters\n            pso_result = pso_optimizer.optimize(\n                objective_function=benchmark_func.objective,\n                bounds=benchmark_func.bounds,\n                max_iterations=MAX_PSO_ITERATIONS\n            )\n\n            # Analyze convergence properties\n            convergence_analysis = _analyze_pso_convergence(\n                pso_result.cost_history,\n                benchmark_func.global_minimum,\n                pso_result.final_cost\n            )\n\n            trial_results.append(convergence_analysis)\n\n        # Aggregate trial results\n        success_rate = len([r for r in trial_results if r.converged_to_global]) / len(trial_results)\n        average_convergence_rate = np.mean([r.convergence_rate for r in trial_results if r.converged])\n\n        convergence_results.append(PSOBenchmarkResult(\n            benchmark_function=benchmark_func.name,\n            success_rate=success_rate,\n            average_convergence_rate=average_convergence_rate,\n            trial_results=trial_results,\n            mathematical_properties=_analyze_mathematical_properties(trial_results)\n        ))\n\n    return PSOConvergenceValidationResult(\n        benchmark_results=convergence_results,\n        overall_convergence_validated=all(r.success_rate >= MIN_PSO_SUCCESS_RATE for r in convergence_results),\n        mathematical_interpretation=_interpret_pso_convergence(convergence_results)\n    )\n\ndef _analyze_pso_convergence(cost_history: List[float],\n                           global_minimum: float,\n                           final_cost: float) -> ConvergenceAnalysis:\n    \"\"\"Analyze PSO convergence characteristics.\"\"\"\n\n    # Check if converged to global minimum\n    convergence_tolerance = abs(global_minimum) * 0.01 if global_minimum != 0 else 0.01\n    converged_to_global = abs(final_cost - global_minimum) < convergence_tolerance\n\n    # Estimate convergence rate\n    if len(cost_history) > 10:\n        # Fit exponential decay model: cost(t) = A * exp(-\u03bbt) + C\n        log_costs = np.log(np.array(cost_history) - global_minimum + 1e-8)\n        convergence_rate = -np.polyfit(range(len(log_costs)), log_costs, 1)[0]\n    else:\n        convergence_rate = 0.0\n\n    # Detect premature convergence\n    cost_variance = np.var(cost_history[-10:]) if len(cost_history) >= 10 else float('inf')\n    premature_convergence = cost_variance < PREMATURE_CONVERGENCE_THRESHOLD and not converged_to_global\n\n    return ConvergenceAnalysis(\n        converged=final_cost <= global_minimum + convergence_tolerance,\n        converged_to_global=converged_to_global,\n        convergence_rate=convergence_rate,\n        premature_convergence=premature_convergence,\n        final_error=abs(final_cost - global_minimum)\n    )",
    "lines": 83,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1818c598"
  },
  {
    "id": "mathematical_validation_procedures_5_cb8d665b",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_multi_objective_pso(multi_obj_optimizer: MultiObjectivePSOOptimizer,\n                               test_problems: List[MultiObjectiveTestProblem]) -> MultiObjectiveValidationResult:\n    \"\"\"\n    Validate multi-objective PSO using standard test problems.\n\n    Mathematical Foundation:\n    - Pareto optimality verification\n    - Hypervolume indicator calculation\n    - Convergence to Pareto front analysis\n    \"\"\"\n\n    validation_results = []\n\n    for test_problem in test_problems:\n        # Run multi-objective optimization\n        pareto_result = multi_obj_optimizer.optimize(\n            objective_functions=test_problem.objectives,\n            bounds=test_problem.bounds,\n            max_iterations=MAX_MULTI_OBJ_ITERATIONS\n        )\n\n        # Validate Pareto optimality\n        pareto_validation = _validate_pareto_optimality(\n            pareto_result.pareto_front,\n            test_problem.true_pareto_front\n        )\n\n        # Calculate hypervolume indicator\n        hypervolume = _calculate_hypervolume(\n            pareto_result.pareto_front,\n            test_problem.reference_point\n        )\n\n        # Analyze convergence to Pareto front\n        convergence_analysis = _analyze_pareto_convergence(\n            pareto_result.pareto_history,\n            test_problem.true_pareto_front\n        )\n\n        validation_results.append(MultiObjectiveTestResult(\n            test_problem=test_problem.name,\n            pareto_validation=pareto_validation,\n            hypervolume=hypervolume,\n            convergence_analysis=convergence_analysis,\n            mathematical_properties=_analyze_multi_objective_properties(pareto_result)\n        ))\n\n    return MultiObjectiveValidationResult(\n        test_results=validation_results,\n        overall_validation=all(r.pareto_validation.valid for r in validation_results),\n        mathematical_interpretation=_interpret_multi_objective_results(validation_results)\n    )",
    "lines": 55,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb8d665b"
  },
  {
    "id": "mathematical_validation_procedures_6_5efdc280",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_numerical_integration_stability(integrators: List[NumericalIntegrator],\n                                           test_scenarios: List[IntegrationTestScenario]) -> NumericalStabilityResult:\n    \"\"\"\n    Validate numerical integration stability and accuracy.\n\n    Mathematical Foundation:\n    - Energy conservation verification\n    - Truncation error analysis\n    - Stability region analysis\n    \"\"\"\n\n    stability_results = {}\n\n    for integrator in integrators:\n        integrator_results = []\n\n        for scenario in test_scenarios:\n            # Run integration\n            t, states = integrator.integrate(\n                initial_state=scenario.initial_state,\n                dynamics=scenario.dynamics,\n                time_span=scenario.time_span,\n                dt=scenario.dt\n            )\n\n            # Energy conservation analysis (for Hamiltonian systems)\n            if scenario.is_conservative:\n                energy_conservation = _validate_energy_conservation(\n                    states, scenario.physics_params\n                )\n            else:\n                energy_conservation = None\n\n            # Truncation error estimation\n            truncation_error = _estimate_truncation_error(\n                integrator, scenario, reference_solution=scenario.reference_solution\n            )\n\n            # Stability analysis\n            stability_analysis = _analyze_numerical_stability(\n                states, scenario.dt, integrator.stability_region\n            )\n\n            integrator_results.append(IntegrationTestResult(\n                scenario=scenario.name,\n                energy_conservation=energy_conservation,\n                truncation_error=truncation_error,\n                stability_analysis=stability_analysis,\n                numerical_accuracy=_calculate_numerical_accuracy(states, scenario.reference_solution)\n            ))\n\n        stability_results[integrator.name] = integrator_results\n\n    return NumericalStabilityResult(\n        integrator_results=stability_results,\n        overall_stability=_assess_overall_numerical_stability(stability_results),\n        mathematical_interpretation=_interpret_numerical_stability(stability_results)\n    )\n\ndef _validate_energy_conservation(states: np.ndarray,\n                                physics_params: PhysicsParameters) -> EnergyConservationResult:\n    \"\"\"Validate energy conservation for Hamiltonian systems.\"\"\"\n\n    energies = []\n\n    for state in states:\n        # Calculate kinetic energy\n        q = state[:3]  # [\u03b8\u2081, \u03b8\u2082, x]\n        q_dot = state[3:]  # [\u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n\n        # Mass matrix for double inverted pendulum\n        M = calculate_mass_matrix(q, physics_params)\n        kinetic_energy = 0.5 * q_dot.T @ M @ q_dot\n\n        # Potential energy\n        potential_energy = calculate_potential_energy(q, physics_params)\n\n        # Total energy\n        total_energy = kinetic_energy + potential_energy\n        energies.append(total_energy)\n\n    energies = np.array(energies)\n    initial_energy = energies[0]\n\n    # Energy drift analysis\n    energy_drift = energies - initial_energy\n    max_absolute_drift = np.max(np.abs(energy_drift))\n    max_relative_drift = max_absolute_drift / abs(initial_energy) if initial_energy != 0 else max_absolute_drift\n\n    # Energy conservation quality\n    if max_relative_drift < 1e-6:\n        conservation_quality = \"excellent\"\n    elif max_relative_drift < 1e-4:\n        conservation_quality = \"good\"\n    elif max_relative_drift < 1e-2:\n        conservation_quality = \"acceptable\"\n    else:\n        conservation_quality = \"poor\"\n\n    return EnergyConservationResult(\n        initial_energy=initial_energy,\n        final_energy=energies[-1],\n        max_absolute_drift=max_absolute_drift,\n        max_relative_drift=max_relative_drift,\n        conservation_quality=conservation_quality,\n        energy_conserved=max_relative_drift < ENERGY_CONSERVATION_TOLERANCE\n    )",
    "lines": 110,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5efdc280"
  },
  {
    "id": "mathematical_validation_procedures_7_e68b7eb0",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_matrix_conditioning(matrices: Dict[str, np.ndarray],\n                               operations: List[MatrixOperation]) -> ConditioningValidationResult:\n    \"\"\"\n    Validate numerical conditioning of matrix operations.\n\n    Mathematical Foundation:\n    - Condition number analysis: \u03ba(A) = ||A|| ||A\u207b\u00b9||\n    - Numerical stability bounds\n    - Precision loss estimation\n    \"\"\"\n\n    conditioning_results = {}\n\n    for matrix_name, matrix in matrices.items():\n        # Calculate condition number\n        try:\n            condition_number = np.linalg.cond(matrix)\n        except np.linalg.LinAlgError:\n            condition_number = float('inf')\n\n        # Assess conditioning quality\n        if condition_number < 1e3:\n            conditioning_quality = \"excellent\"\n        elif condition_number < 1e6:\n            conditioning_quality = \"good\"\n        elif condition_number < 1e12:\n            conditioning_quality = \"acceptable\"\n        else:\n            conditioning_quality = \"ill_conditioned\"\n\n        # Estimate precision loss\n        precision_loss_bits = np.log2(condition_number) if condition_number > 1 else 0\n\n        conditioning_results[matrix_name] = MatrixConditioningResult(\n            condition_number=condition_number,\n            conditioning_quality=conditioning_quality,\n            precision_loss_bits=precision_loss_bits,\n            numerically_stable=condition_number < CONDITIONING_THRESHOLD\n        )\n\n    # Validate matrix operations\n    operation_results = []\n\n    for operation in operations:\n        try:\n            # Perform operation and check for numerical issues\n            result = operation.execute(matrices)\n\n            # Check for NaN or Inf values\n            has_numerical_issues = np.any(np.isnan(result)) or np.any(np.isinf(result))\n\n            # Estimate accumulated round-off error\n            roundoff_error = _estimate_roundoff_error(operation, matrices)\n\n            operation_results.append(MatrixOperationResult(\n                operation_name=operation.name,\n                successful=not has_numerical_issues,\n                roundoff_error=roundoff_error,\n                numerical_stability=_assess_operation_stability(operation, result, roundoff_error)\n            ))\n\n        except Exception as e:\n            operation_results.append(MatrixOperationResult(\n                operation_name=operation.name,\n                successful=False,\n                error=str(e)\n            ))\n\n    return ConditioningValidationResult(\n        matrix_conditioning=conditioning_results,\n        operation_results=operation_results,\n        overall_conditioning=_assess_overall_conditioning(conditioning_results, operation_results),\n        mathematical_interpretation=_interpret_conditioning_results(conditioning_results, operation_results)\n    )",
    "lines": 77,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e68b7eb0"
  },
  {
    "id": "mathematical_validation_procedures_8_411e5f79",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_real_time_constraints(control_system: ControlSystem,\n                                 timing_requirements: TimingRequirements) -> RealTimeValidationResult:\n    \"\"\"\n    Validate real-time mathematical constraints.\n\n    Mathematical Foundation:\n    - Schedulability analysis: \u03a3(C\u1d62/T\u1d62) \u2264 U_bound\n    - Deadline satisfaction probability\n    - Worst-case execution time (WCET) analysis\n    \"\"\"\n\n    # Measure execution times for critical functions\n    execution_times = {}\n\n    for function_name, function in control_system.critical_functions.items():\n        # Run timing measurements\n        measured_times = []\n\n        for _ in range(NUM_TIMING_MEASUREMENTS):\n            start_time = time.perf_counter()\n            function()\n            end_time = time.perf_counter()\n            measured_times.append(end_time - start_time)\n\n        # Statistical analysis of execution times\n        mean_time = np.mean(measured_times)\n        std_time = np.std(measured_times)\n        max_time = np.max(measured_times)\n\n        # Estimate worst-case execution time (WCET)\n        # Using 99.9th percentile as WCET estimate\n        wcet_estimate = np.percentile(measured_times, 99.9)\n\n        execution_times[function_name] = ExecutionTimeAnalysis(\n            mean_time=mean_time,\n            std_time=std_time,\n            max_measured_time=max_time,\n            wcet_estimate=wcet_estimate,\n            deadline=timing_requirements.deadlines[function_name]\n        )\n\n    # Schedulability analysis\n    utilization = 0.0\n    deadline_violations = []\n\n    for function_name, timing_analysis in execution_times.items():\n        period = timing_requirements.periods[function_name]\n        deadline = timing_requirements.deadlines[function_name]\n\n        # Calculate utilization\n        function_utilization = timing_analysis.wcet_estimate / period\n        utilization += function_utilization\n\n        # Check deadline satisfaction\n        if timing_analysis.wcet_estimate > deadline:\n            deadline_violations.append(DeadlineViolation(\n                function_name=function_name,\n                wcet=timing_analysis.wcet_estimate,\n                deadline=deadline,\n                violation_magnitude=timing_analysis.wcet_estimate - deadline\n            ))\n\n    # Determine schedulability\n    utilization_bound = timing_requirements.utilization_bound\n    schedulable = utilization <= utilization_bound and not deadline_violations\n\n    return RealTimeValidationResult(\n        execution_time_analysis=execution_times,\n        total_utilization=utilization,\n        utilization_bound=utilization_bound,\n        deadline_violations=deadline_violations,\n        schedulable=schedulable,\n        real_time_constraints_satisfied=schedulable,\n        mathematical_interpretation=_interpret_real_time_results(\n            utilization, utilization_bound, deadline_violations\n        )\n    )",
    "lines": 80,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "411e5f79"
  },
  {
    "id": "mathematical_validation_procedures_9_0229b9ea",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_timing_jitter_and_latency(control_loop: ControlLoop,\n                                     jitter_requirements: JitterRequirements) -> JitterValidationResult:\n    \"\"\"\n    Validate timing jitter and latency characteristics.\n\n    Mathematical Foundation:\n    - Jitter probability: P(jitter > J_max) \u2264 \u03b5_acceptable\n    - Latency distribution analysis\n    - Phase margin impact assessment\n    \"\"\"\n\n    # Collect timing measurements\n    timing_measurements = []\n\n    for _ in range(NUM_JITTER_MEASUREMENTS):\n        measurement = control_loop.run_single_iteration_with_timing()\n        timing_measurements.append(measurement)\n\n    # Extract timing components\n    sensor_latencies = [m.sensor_latency for m in timing_measurements]\n    computation_times = [m.computation_time for m in timing_measurements]\n    actuator_latencies = [m.actuator_latency for m in timing_measurements]\n    total_latencies = [m.total_latency for m in timing_measurements]\n\n    # Jitter analysis (timing variability)\n    def analyze_jitter(times: List[float], component_name: str) -> JitterAnalysis:\n        times_array = np.array(times)\n\n        # Calculate jitter metrics\n        mean_time = np.mean(times_array)\n        jitter_std = np.std(times_array)\n        max_jitter = np.max(times_array) - np.min(times_array)\n\n        # Jitter probability analysis\n        jitter_threshold = jitter_requirements.max_acceptable_jitter[component_name]\n        jitter_violations = times_array[times_array > mean_time + jitter_threshold]\n        jitter_violation_probability = len(jitter_violations) / len(times_array)\n\n        return JitterAnalysis(\n            component=component_name,\n            mean_time=mean_time,\n            jitter_std=jitter_std,\n            max_jitter=max_jitter,\n            jitter_violation_probability=jitter_violation_probability,\n            acceptable_jitter=jitter_violation_probability <= jitter_requirements.acceptable_violation_probability\n        )\n\n    # Analyze jitter for each component\n    jitter_analyses = {\n        'sensor': analyze_jitter(sensor_latencies, 'sensor'),\n        'computation': analyze_jitter(computation_times, 'computation'),\n        'actuator': analyze_jitter(actuator_latencies, 'actuator'),\n        'total': analyze_jitter(total_latencies, 'total')\n    }\n\n    # Control system impact analysis\n    control_impact = _analyze_jitter_control_impact(\n        jitter_analyses, control_loop.controller_parameters\n    )\n\n    return JitterValidationResult(\n        jitter_analyses=jitter_analyses,\n        control_impact=control_impact,\n        overall_timing_acceptable=all(j.acceptable_jitter for j in jitter_analyses.values()),\n        mathematical_interpretation=_interpret_jitter_results(jitter_analyses, control_impact)\n    )\n\ndef _analyze_jitter_control_impact(jitter_analyses: Dict[str, JitterAnalysis],\n                                 controller_params: ControllerParameters) -> ControlImpactAnalysis:\n    \"\"\"Analyze impact of timing jitter on control performance.\"\"\"\n\n    # Phase margin impact estimation\n    total_jitter_std = jitter_analyses['total'].jitter_std\n    control_frequency = controller_params.control_frequency\n\n    # Phase delay due to jitter (in radians)\n    phase_delay_std = 2 * np.pi * control_frequency * total_jitter_std\n\n    # Estimate phase margin degradation\n    nominal_phase_margin = controller_params.nominal_phase_margin\n    phase_margin_degradation = phase_delay_std\n    remaining_phase_margin = nominal_phase_margin - phase_margin_degradation\n\n    # Stability impact assessment\n    if remaining_phase_margin > np.pi/6:  # 30 degrees\n        stability_impact = \"minimal\"\n    elif remaining_phase_margin > np.pi/12:  # 15 degrees\n        stability_impact = \"moderate\"\n    else:\n        stability_impact = \"significant\"\n\n    return ControlImpactAnalysis(\n        phase_delay_std=phase_delay_std,\n        phase_margin_degradation=phase_margin_degradation,\n        remaining_phase_margin=remaining_phase_margin,\n        stability_impact=stability_impact,\n        performance_degradation_estimate=_estimate_performance_degradation(phase_margin_degradation)\n    )",
    "lines": 101,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0229b9ea"
  },
  {
    "id": "mathematical_validation_procedures_10_fb4e482e",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 10,
    "code": "from hypothesis import given, strategies as st, assume\nimport hypothesis.extra.numpy as hnp\n\n@given(\n    state=hnp.arrays(dtype=np.float64, shape=(6,), elements=st.floats(-10.0, 10.0, allow_nan=False)),\n    gains=hnp.arrays(dtype=np.float64, shape=(6,), elements=st.floats(0.1, 100.0))\n)\ndef test_lyapunov_stability_property(state: np.ndarray, gains: np.ndarray):\n    \"\"\"\n    Property-based test for Lyapunov stability condition.\n\n    Mathematical Property: V\u0307(s) = s\u00b7\u1e61 < 0 for all s \u2260 0\n    \"\"\"\n    # Assume physical constraints\n    assume(all(g > 0 for g in gains))  # Positive gains required\n    assume(np.linalg.norm(state) < 5.0)  # Reasonable state magnitude\n\n    # Create controller with given gains\n    controller = ClassicalSMC(gains=gains.tolist())\n    target = np.zeros(6)\n\n    # Compute sliding surface\n    sliding_surface = controller.compute_sliding_surface(state, target)\n\n    # Skip if on sliding surface\n    assume(abs(sliding_surface) > 1e-6)\n\n    # Compute surface derivative\n    surface_derivative = controller.compute_surface_derivative(state, target)\n\n    # Lyapunov stability condition\n    lyapunov_derivative = sliding_surface * surface_derivative\n\n    # Mathematical property: V\u0307 < 0 for s \u2260 0\n    assert lyapunov_derivative < 0, f\"Lyapunov condition violated: V\u0307 = {lyapunov_derivative}\"\n\n@given(\n    bounds=st.lists(\n        st.tuples(st.floats(0.1, 10.0), st.floats(10.1, 100.0)),\n        min_size=4, max_size=8\n    ),\n    c1=st.floats(0.1, 2.0),\n    c2=st.floats(0.1, 2.0)\n)\ndef test_pso_convergence_property(bounds: List[Tuple[float, float]], c1: float, c2: float):\n    \"\"\"\n    Property-based test for PSO convergence conditions.\n\n    Mathematical Property: \u03c6 = c1 + c2 > 4 ensures convergence\n    \"\"\"\n    phi = c1 + c2\n    assume(phi > 4.0)  # Convergence condition\n\n    # Calculate constriction factor\n    chi = 2 / abs(2 - phi - np.sqrt(phi**2 - 4*phi))\n\n    # Constriction factor should be positive and less than 1\n    assert 0 < chi < 1, f\"Invalid constriction factor: \u03c7 = {chi}\"\n\n    # Test PSO with these parameters\n    pso = PSOOptimizer(c1=c1, c2=c2, w=chi)\n\n    # Use simple quadratic test function\n    def quadratic_function(x):\n        return np.sum(x**2)\n\n    result = pso.optimize(quadratic_function, bounds, max_iterations=50)\n\n    # Should converge to approximately zero for quadratic function\n    assert result.best_cost < 1e-2, f\"PSO failed to converge: final cost = {result.best_cost}\"\n\n@given(\n    dt=st.floats(1e-4, 1e-2),\n    simulation_time=st.floats(1.0, 10.0)\n)\ndef test_numerical_integration_energy_conservation(dt: float, simulation_time: float):\n    \"\"\"\n    Property-based test for energy conservation in numerical integration.\n\n    Mathematical Property: E(t) = constant for Hamiltonian systems\n    \"\"\"\n    assume(simulation_time / dt < 10000)  # Reasonable number of steps\n\n    # Create conservative test system (simple pendulum)\n    def pendulum_dynamics(t, state):\n        theta, theta_dot = state\n        g, L = 9.81, 1.0\n        return np.array([theta_dot, -(g/L) * np.sin(theta)])\n\n    # Initial condition\n    initial_state = np.array([0.1, 0.0])  # Small angle, no initial velocity\n\n    # Integrate using RK4\n    integrator = RK4Integrator()\n    t, states = integrator.integrate(\n        dynamics=pendulum_dynamics,\n        initial_state=initial_state,\n        time_span=(0, simulation_time),\n        dt=dt\n    )\n\n    # Calculate energy at each time step\n    g, L = 9.81, 1.0\n    energies = []\n\n    for state in states:\n        theta, theta_dot = state\n        kinetic = 0.5 * theta_dot**2\n        potential = g/L * (1 - np.cos(theta))\n        total_energy = kinetic + potential\n        energies.append(total_energy)\n\n    energies = np.array(energies)\n    initial_energy = energies[0]\n\n    # Energy should be conserved (within numerical tolerance)\n    max_energy_error = np.max(np.abs(energies - initial_energy))\n    relative_energy_error = max_energy_error / initial_energy\n\n    # Energy conservation tolerance depends on dt and simulation time\n    tolerance = min(1e-6, dt**2 * simulation_time * 100)\n\n    assert relative_energy_error < tolerance, f\"Energy not conserved: relative error = {relative_energy_error}\"",
    "lines": 123,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb4e482e"
  },
  {
    "id": "mathematical_validation_procedures_11_638f93d8",
    "file": "docs\\mathematical_validation_procedures.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass ComprehensiveMathematicalValidator:\n    \"\"\"Comprehensive mathematical validation for control systems.\"\"\"\n\n    def __init__(self):\n        self.validators = {\n            'stability': LyapunovStabilityValidator(),\n            'reachability': SlidingSurfaceReachabilityValidator(),\n            'convergence': PSOConvergenceValidator(),\n            'numerical': NumericalStabilityValidator(),\n            'real_time': RealTimeConstraintValidator()\n        }\n\n    def validate_all_mathematical_properties(self,\n                                           control_system: ControlSystem) -> ComprehensiveMathematicalValidationResult:\n        \"\"\"Execute complete mathematical validation suite.\"\"\"\n\n        validation_results = {}\n\n        for validator_name, validator in self.validators.items():\n            try:\n                validation_results[validator_name] = validator.validate(control_system)\n            except Exception as e:\n                validation_results[validator_name] = ValidationResult(\n                    status='error',\n                    error=str(e),\n                    mathematical_interpretation=f\"Failed to validate {validator_name}\"\n                )\n\n        # Calculate overall mathematical rigor score\n        rigor_score = self._calculate_mathematical_rigor_score(validation_results)\n\n        # Generate mathematical soundness assessment\n        soundness_assessment = self._assess_mathematical_soundness(validation_results)\n\n        return ComprehensiveMathematicalValidationResult(\n            validation_results=validation_results,\n            mathematical_rigor_score=rigor_score,\n            mathematical_soundness=soundness_assessment,\n            theoretical_properties_verified=self._count_verified_properties(validation_results),\n            deployment_mathematical_approval=rigor_score >= MATHEMATICAL_DEPLOYMENT_THRESHOLD\n        )\n\n    def _calculate_mathematical_rigor_score(self,\n                                          validation_results: Dict[str, ValidationResult]) -> float:\n        \"\"\"Calculate overall mathematical rigor score.\"\"\"\n\n        # Weight different validation aspects\n        weights = {\n            'stability': 0.3,        # Critical for safety\n            'reachability': 0.25,    # Critical for performance\n            'convergence': 0.2,      # Important for optimization\n            'numerical': 0.15,       # Important for accuracy\n            'real_time': 0.1         # Important for implementation\n        }\n\n        weighted_score = 0.0\n        total_weight = 0.0\n\n        for validator_name, result in validation_results.items():\n            if validator_name in weights and result.status != 'error':\n                # Extract numerical score from validation result\n                if hasattr(result, 'score'):\n                    score = result.score\n                elif result.status == 'passed':\n                    score = 1.0\n                elif result.status == 'partial':\n                    score = 0.7\n                else:\n                    score = 0.0\n\n                weighted_score += weights[validator_name] * score\n                total_weight += weights[validator_name]\n\n        return weighted_score / total_weight if total_weight > 0 else 0.0",
    "lines": 77,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "638f93d8"
  },
  {
    "id": "memory_management_patterns_1_df7c2485",
    "file": "docs\\memory_management_patterns.md",
    "index": 1,
    "code": "# \u274c BEFORE: Creates circular reference\nclass Controller:\n    def __init__(self, dynamics_model):\n        self._dynamics = dynamics_model  # Strong reference",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "df7c2485"
  },
  {
    "id": "memory_management_patterns_2_051f58ce",
    "file": "docs\\memory_management_patterns.md",
    "index": 2,
    "code": "# \u2705 AFTER: Weakref prevents circular reference\nimport weakref\n\nclass Controller:\n    def __init__(self, dynamics_model):\n        if dynamics_model is not None:\n            self._dynamics_ref = weakref.ref(dynamics_model)\n        else:\n            self._dynamics_ref = lambda: None\n\n    @property\n    def dyn(self):\n        \"\"\"Access dynamics via weakref.\"\"\"\n        return self._dynamics_ref() if callable(self._dynamics_ref) else None",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "051f58ce"
  },
  {
    "id": "memory_management_patterns_3_bf663ab5",
    "file": "docs\\memory_management_patterns.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass Controller:\n    def cleanup(self):\n        \"\"\"Explicit memory cleanup (call before deletion).\"\"\"\n        # Clear history buffers\n        if hasattr(self, '_history') and isinstance(self._history, list):\n            self._history.clear()\n\n        # Nullify large arrays\n        for attr in ['_state_buffer', '_control_buffer', '_surface_buffer']:\n            if hasattr(self, attr):\n                setattr(self, attr, None)\n\n        # Clear dynamics reference\n        if hasattr(self, '_dynamics_ref'):\n            self._dynamics_ref = lambda: None",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bf663ab5"
  },
  {
    "id": "memory_management_patterns_4_6ab887e1",
    "file": "docs\\memory_management_patterns.md",
    "index": 4,
    "code": "class Controller:\n    def __del__(self):\n        \"\"\"Automatic cleanup on deletion.\"\"\"\n        try:\n            self.cleanup()\n        except Exception:\n            pass  # Never raise in destructor",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ab887e1"
  },
  {
    "id": "memory_management_patterns_5_214cf906",
    "file": "docs\\memory_management_patterns.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass Controller:\n    def reset(self):\n        \"\"\"Reset controller state with memory cleanup.\"\"\"\n        # Original reset logic\n        self._integral_state = 0.0\n        self._previous_error = 0.0\n\n        # NEW: Clear history buffers\n        if hasattr(self, '_history'):\n            self._history.clear()\n\n        # NEW: Reset large arrays\n        self._state_buffer = None\n        self._control_buffer = None",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "214cf906"
  },
  {
    "id": "memory_management_patterns_6_eaebbf22",
    "file": "docs\\memory_management_patterns.md",
    "index": 6,
    "code": "# No explicit cleanup needed (automatic via __del__)\nfrom src.controllers.smc import ClassicalSMC\n\ncontroller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100, boundary_layer=0.01)\nresults = simulate(controller, duration=5.0)\n# Controller automatically cleaned up when out of scope",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eaebbf22"
  },
  {
    "id": "memory_management_patterns_7_e3fcddd1",
    "file": "docs\\memory_management_patterns.md",
    "index": 7,
    "code": "# Explicit cleanup recommended\nfrom src.controllers.smc import HybridAdaptiveSTASMC\nimport gc\nimport time\n\ncontroller = HybridAdaptiveSTASMC(\n    gains=[15,12,18,15],\n    dt=0.01,\n    max_force=100,\n    k1_init=10,\n    k2_init=8,\n    gamma1=0.5,\n    gamma2=0.5,\n    dead_zone=0.01\n)\n\nlast_cleanup = time.time()\n\ntry:\n    while server_running:\n        state = get_state()\n        control, state_vars, history = controller.compute_control(state, last_state_vars, history)\n        apply_control(control)\n\n        # Periodic cleanup (every hour)\n        if time.time() - last_cleanup > 3600:\n            # Clear history buffers to prevent unbounded growth\n            history = controller.initialize_history()\n            gc.collect()\n            last_cleanup = time.time()\nfinally:\n    controller.cleanup()  # Explicit cleanup before deletion\n    del controller",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3fcddd1"
  },
  {
    "id": "memory_management_patterns_8_d588d862",
    "file": "docs\\memory_management_patterns.md",
    "index": 8,
    "code": "# Cleanup every N iterations\nfrom src.controllers.smc import AdaptiveSMC\nimport gc\n\nfor i in range(10000):\n    controller = AdaptiveSMC(\n        gains=candidate_gains[i],\n        dt=0.01,\n        max_force=100,\n        k1_init=10,\n        k2_init=8,\n        gamma1=0.5,\n        gamma2=0.5,\n        dead_zone=0.01\n    )\n    fitness = evaluate_controller(controller)\n\n    # Cleanup every 100 iterations\n    if i % 100 == 99:\n        controller.cleanup()\n        del controller\n        gc.collect()",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d588d862"
  },
  {
    "id": "memory_management_patterns_9_f565a518",
    "file": "docs\\memory_management_patterns.md",
    "index": 9,
    "code": "import psutil\nimport os\n\nclass ProductionMemoryMonitor:\n    \"\"\"Production-grade memory monitoring for controller deployments.\"\"\"\n\n    def __init__(self, threshold_mb=500.0):\n        self.threshold_mb = threshold_mb\n        self.process = psutil.Process(os.getpid())\n\n    def check_memory(self):\n        \"\"\"Check current memory usage against threshold.\"\"\"\n        memory_mb = self.process.memory_info().rss / 1024 / 1024\n\n        if memory_mb > self.threshold_mb:\n            return {\n                'alert': True,\n                'current_mb': memory_mb,\n                'threshold_mb': self.threshold_mb,\n                'message': f\"Memory usage ({memory_mb:.1f}MB) exceeds threshold ({self.threshold_mb}MB)\"\n            }\n        return None\n\n# Usage\nmonitor = ProductionMemoryMonitor(threshold_mb=500.0)\n\n# Check periodically\nif alert := monitor.check_memory():\n    logger.warning(f\"Memory alert: {alert['message']}\")\n    controller.reset()  # Clear buffers\n    gc.collect()",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f565a518"
  },
  {
    "id": "memory_management_patterns_10_01d45223",
    "file": "docs\\memory_management_patterns.md",
    "index": 10,
    "code": "import time\nimport gc\n\nclass ControllerManager:\n    def __init__(self, controller_type, **kwargs):\n        from src.controllers.factory import create_controller\n        self.controller = create_controller(controller_type, **kwargs)\n        self.created_at = time.time()\n        self.max_lifetime_hours = 24\n\n    def should_recreate(self):\n        \"\"\"Recreate controller every 24 hours to prevent memory accumulation.\"\"\"\n        lifetime_hours = (time.time() - self.created_at) / 3600\n        return lifetime_hours > self.max_lifetime_hours\n\n    def refresh(self):\n        \"\"\"Safely recreate controller.\"\"\"\n        from src.controllers.factory import create_controller\n        controller_type = type(self.controller).__name__.lower()\n\n        old_controller = self.controller\n        self.controller = create_controller(controller_type, **self.get_controller_params())\n        old_controller.cleanup()\n        del old_controller\n        gc.collect()\n        self.created_at = time.time()\n\n    def get_controller_params(self):\n        \"\"\"Extract controller parameters for recreation.\"\"\"\n        return {\n            'gains': self.controller.gains,\n            'max_force': self.controller.max_force,\n            # Add other controller-specific parameters\n        }",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "01d45223"
  },
  {
    "id": "memory_management_patterns_11_3c86fb18",
    "file": "docs\\memory_management_patterns.md",
    "index": 11,
    "code": "# Uses weakref for dynamics model\nif dynamics_model is not None:\n    self._dynamics_ref = weakref.ref(dynamics_model)\nelse:\n    self._dynamics_ref = lambda: None\n\n# Access via property\n@property\ndef dyn(self):\n    return self._dynamics_ref() if callable(self._dynamics_ref) else None",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c86fb18"
  },
  {
    "id": "memory_management_patterns_12_5dd47b85",
    "file": "docs\\memory_management_patterns.md",
    "index": 12,
    "code": "# Stores dynamics model with weakref internally\nself.dyn: Optional[Any] = dynamics_model",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5dd47b85"
  },
  {
    "id": "memory_management_patterns_13_a2b10fcf",
    "file": "docs\\memory_management_patterns.md",
    "index": 13,
    "code": "# Problem: History dict grows unbounded\nhistory = controller.initialize_history()\nfor i in range(100000):\n    control = controller.compute_control(state, state_vars, history)\n    # history dict now contains 100000 entries\n\n# Solution: Clear history periodically\nif i % 1000 == 999:\n    history = controller.initialize_history()",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a2b10fcf"
  },
  {
    "id": "memory_management_patterns_14_dae6c328",
    "file": "docs\\memory_management_patterns.md",
    "index": 14,
    "code": "import tracemalloc\nimport gc\n\ntracemalloc.start()\n\n# Create many controllers\ncontrollers = []\nfor i in range(1000):\n    c = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100, boundary_layer=0.01)\n    controllers.append(c)\n\nsnapshot1 = tracemalloc.take_snapshot()\n\n# Clear controllers\ncontrollers.clear()\ngc.collect()\n\nsnapshot2 = tracemalloc.take_snapshot()\ndiff = snapshot2.compare_to(snapshot1, 'lineno')\n\n# Should show memory decrease\nfor stat in diff[:10]:\n    print(stat)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dae6c328"
  },
  {
    "id": "memory_management_quick_reference_1_8e915751",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 1,
    "code": "from src.controllers.smc import ClassicalSMC\n\ncontroller = ClassicalSMC(\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100,\n    boundary_layer=0.01\n)\nresult = simulate(controller, duration=5.0)\n# Done - automatic cleanup",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e915751"
  },
  {
    "id": "memory_management_quick_reference_2_f8606b49",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 2,
    "code": "from src.controllers.smc import HybridAdaptiveSTASMC\nimport gc\nimport time\n\ncontroller = HybridAdaptiveSTASMC(\n    gains=[15, 12, 18, 15],\n    dt=0.01,\n    max_force=100,\n    k1_init=10,\n    k2_init=8,\n    gamma1=0.5,\n    gamma2=0.5,\n    dead_zone=0.01\n)\n\nhistory = controller.initialize_history()\nstate_vars = controller.initialize_state()\nlast_cleanup = time.time()\n\nwhile running:\n    control, state_vars, history = controller.compute_control(state, state_vars, history)\n\n    # Hourly cleanup\n    if time.time() - last_cleanup > 3600:\n        history = controller.initialize_history()\n        gc.collect()\n        last_cleanup = time.time()\n\n    # Memory monitoring (optional)\n    memory_mb = psutil.Process().memory_info().rss / 1024 / 1024\n    if memory_mb > 500:\n        logger.warning(f\"High memory usage: {memory_mb:.1f}MB\")\n        history = controller.initialize_history()\n        gc.collect()",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8606b49"
  },
  {
    "id": "memory_management_quick_reference_3_ccc33e42",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 3,
    "code": "from src.controllers.smc import AdaptiveSMC\nimport gc\n\nfor i in range(10000):\n    controller = AdaptiveSMC(\n        gains=candidates[i],\n        dt=0.01,\n        max_force=100,\n        k1_init=10,\n        k2_init=8,\n        gamma1=0.5,\n        gamma2=0.5,\n        dead_zone=0.01\n    )\n    fitness[i] = evaluate(controller)\n\n    if i % 100 == 99:\n        controller.cleanup()\n        del controller\n        gc.collect()",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccc33e42"
  },
  {
    "id": "memory_management_quick_reference_4_b90c9505",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 4,
    "code": "import psutil\nimport os\n\nprocess = psutil.Process(os.getpid())\nmemory_mb = process.memory_info().rss / 1024 / 1024\nprint(f\"Memory usage: {memory_mb:.1f}MB\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b90c9505"
  },
  {
    "id": "memory_management_quick_reference_5_f7f171a9",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass MemoryMonitor:\n    def __init__(self, threshold_mb=500):\n        self.threshold_mb = threshold_mb\n        self.process = psutil.Process(os.getpid())\n\n    def check(self):\n        memory_mb = self.process.memory_info().rss / 1024 / 1024\n        if memory_mb > self.threshold_mb:\n            return f\"Memory alert: {memory_mb:.1f}MB > {self.threshold_mb}MB\"\n        return None\n\nmonitor = MemoryMonitor(threshold_mb=500)\nif alert := monitor.check():\n    logger.warning(alert)\n    # Take action: clear history, reset controller, etc.",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f7f171a9"
  },
  {
    "id": "memory_management_quick_reference_6_afd877cf",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 6,
    "code": "# Clear history dict periodically\nif iteration % 1000 == 999:\n    history = controller.initialize_history()",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "afd877cf"
  },
  {
    "id": "memory_management_quick_reference_7_b34410fa",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 7,
    "code": "if i % 100 == 99:\n    controller.cleanup()\n    del controller\n    gc.collect()",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b34410fa"
  },
  {
    "id": "memory_management_quick_reference_8_0500ecc8",
    "file": "docs\\memory_management_quick_reference.md",
    "index": 8,
    "code": "if time.time() - last_cleanup > 3600:\n    history = controller.initialize_history()\n    gc.collect()",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0500ecc8"
  },
  {
    "id": "numerical_stability_guide_1_cfdf7462",
    "file": "docs\\numerical_stability_guide.md",
    "index": 1,
    "code": "\u03bb = alpha * \u03c3_max * scale_factor",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfdf7462"
  },
  {
    "id": "numerical_stability_guide_2_4a430d40",
    "file": "docs\\numerical_stability_guide.md",
    "index": 2,
    "code": "if sv_ratio < 2e-9:\n    reg_scale = alpha * s[0] * 1e5",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a430d40"
  },
  {
    "id": "numerical_stability_guide_3_5737f27b",
    "file": "docs\\numerical_stability_guide.md",
    "index": 3,
    "code": "# Matrix with singular value ratio 2e-9\nM = U @ diag([1.0, 2e-8, 2e-9]) @ V.T\n# Regularization: \u03bb = 1e-4 * 1.0 * 100000 = 10.0",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5737f27b"
  },
  {
    "id": "numerical_stability_guide_4_4c76aa7a",
    "file": "docs\\numerical_stability_guide.md",
    "index": 4,
    "code": "if sv_ratio < 1e-8:\n    reg_scale = alpha * s[0] * 1e4",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c76aa7a"
  },
  {
    "id": "numerical_stability_guide_5_b94e8a94",
    "file": "docs\\numerical_stability_guide.md",
    "index": 5,
    "code": "if sv_ratio < 1e-6:\n    reg_scale = alpha * s[0] * 1e2",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b94e8a94"
  },
  {
    "id": "numerical_stability_guide_6_2687ca76",
    "file": "docs\\numerical_stability_guide.md",
    "index": 6,
    "code": "if cond_num > 1e10:\n    reg_scale = alpha * s[0] * 10",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2687ca76"
  },
  {
    "id": "numerical_stability_guide_7_ccec0ccf",
    "file": "docs\\numerical_stability_guide.md",
    "index": 7,
    "code": "else:\n    reg_scale = alpha * s[0]",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccec0ccf"
  },
  {
    "id": "numerical_stability_guide_8_dff891a0",
    "file": "docs\\numerical_stability_guide.md",
    "index": 8,
    "code": "from src.plant.core.numerical_stability import AdaptiveRegularizer, MatrixInverter\n\n# Initialize with standardized parameters\nregularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-4,        # Base scaling factor\n    max_condition_number=1e14,        # Condition threshold\n    min_regularization=1e-10,         # Safety floor\n    use_fixed_regularization=False    # Enable adaptive mode\n)\n\nmatrix_inverter = MatrixInverter(regularizer=regularizer)\n\n# Robust matrix inversion\ntry:\n    M_inv = matrix_inverter.invert_matrix(M)\nexcept NumericalInstabilityError as e:\n    print(f\"Matrix inversion failed: {e}\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dff891a0"
  },
  {
    "id": "numerical_stability_guide_9_3aa6434b",
    "file": "docs\\numerical_stability_guide.md",
    "index": 9,
    "code": "from src.controllers.smc.core.equivalent_control import EquivalentControl\n\n# Controllers automatically use AdaptiveRegularizer\neq_control = EquivalentControl(\n    dynamics_model=dynamics,\n    regularization_alpha=1e-4,\n    min_regularization=1e-10,\n    max_condition_number=1e14,\n    use_fixed_regularization=False\n)\n\n# Equivalent control computation with robust matrix operations\nu_eq = eq_control.compute(state, sliding_surface)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3aa6434b"
  },
  {
    "id": "numerical_stability_guide_10_fa7f3e71",
    "file": "docs\\numerical_stability_guide.md",
    "index": 10,
    "code": "# For well-conditioned systems or debugging\nregularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-6,           # Single parameter\n    use_fixed_regularization=True        # Disable adaptive scaling\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fa7f3e71"
  },
  {
    "id": "numerical_stability_guide_11_71544a82",
    "file": "docs\\numerical_stability_guide.md",
    "index": 11,
    "code": "# OLD (v1.1.0 and earlier)\ncontroller_config = {\n    'regularization': 1e-6  # Single fixed parameter\n}",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71544a82"
  },
  {
    "id": "numerical_stability_guide_12_998b239e",
    "file": "docs\\numerical_stability_guide.md",
    "index": 12,
    "code": "# NEW (v1.2.0+)\ncontroller_config = {\n    'regularization_alpha': 1e-4,          # Base scaling factor\n    'min_regularization': 1e-10,           # Safety floor\n    'max_condition_number': 1e14,          # Condition threshold\n    'use_adaptive_regularization': True    # Enable adaptive mode\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "998b239e"
  },
  {
    "id": "numerical_stability_guide_13_3bb78f19",
    "file": "docs\\numerical_stability_guide.md",
    "index": 13,
    "code": "# Automatic conversion\nif hasattr(config, 'regularization'):\n    # Convert to fixed regularization mode\n    regularizer = AdaptiveRegularizer(\n        regularization_alpha=config.regularization,\n        use_fixed_regularization=True\n    )",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3bb78f19"
  },
  {
    "id": "numerical_stability_guide_14_94ac3e26",
    "file": "docs\\numerical_stability_guide.md",
    "index": 14,
    "code": "# From test_matrix_regularization()\nextreme_ratios = [1e-8, 2e-9, 5e-9, 1e-10]\nfor ratio in extreme_ratios:\n    # All ratios handled without LinAlgError\n    assert linalg_errors == 0",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94ac3e26"
  },
  {
    "id": "numerical_stability_guide_15_07936331",
    "file": "docs\\numerical_stability_guide.md",
    "index": 15,
    "code": "# High condition matrix\nM = diag([1.0, 1e-6, 1e-13])  # cond ~ 1e13\n# Automatic regularization triggered -> No LinAlgError",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07936331"
  },
  {
    "id": "numerical_stability_guide_16_3d79c836",
    "file": "docs\\numerical_stability_guide.md",
    "index": 16,
    "code": "# Well-conditioned matrix (cond ~ 1.25)\nM = diag([1.0, 0.9, 0.8])\nM_inv = matrix_inverter.invert_matrix(M)\nerror = max(abs((M @ M_inv) - I))\nassert error < 1e-10  # High precision maintained",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d79c836"
  },
  {
    "id": "numerical_stability_guide_17_ddc3bc07",
    "file": "docs\\numerical_stability_guide.md",
    "index": 17,
    "code": "# Check if adaptive mode is enabled\nprint(regularizer.use_fixed)  # Should be False\n\n# Check condition number\ncond_num = np.linalg.cond(M)\nprint(f\"Condition number: {cond_num:.2e}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ddc3bc07"
  },
  {
    "id": "numerical_stability_guide_18_b89fc58f",
    "file": "docs\\numerical_stability_guide.md",
    "index": 18,
    "code": "# Check if over-regularization is occurring\nsv_ratio = s[-1] / s[0]\nprint(f\"SV ratio: {sv_ratio:.2e}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b89fc58f"
  },
  {
    "id": "numerical_stability_guide_19_583ecf6d",
    "file": "docs\\numerical_stability_guide.md",
    "index": 19,
    "code": "# Check regularization trigger frequency\nmonitor = NumericalStabilityMonitor()\nstats = monitor.get_statistics()\nprint(f\"Regularization rate: {stats['regularization_rate']:.1%}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "583ecf6d"
  },
  {
    "id": "numerical_stability_guide_20_36a68cfa",
    "file": "docs\\numerical_stability_guide.md",
    "index": 20,
    "code": "# Recommended defaults for production\nregularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-4,\n    max_condition_number=1e14,\n    min_regularization=1e-10,\n    use_fixed_regularization=False\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36a68cfa"
  },
  {
    "id": "numerical_stability_guide_21_cae22f33",
    "file": "docs\\numerical_stability_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Track regularization in production\nfrom src.plant.core.numerical_stability import NumericalStabilityMonitor\n\nmonitor = NumericalStabilityMonitor()\n# ... run simulations ...\nstats = monitor.get_statistics()\nif stats['regularization_rate'] > 0.5:\n    warnings.warn(\"High regularization frequency detected\")",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cae22f33"
  },
  {
    "id": "numerical_stability_guide_22_34005518",
    "file": "docs\\numerical_stability_guide.md",
    "index": 22,
    "code": "# Include edge cases in tests\ntest_matrices = [\n    np.diag([1.0, 1e-8, 1e-10]),  # Extreme conditioning\n    np.eye(3) * 1e-15,             # Near-zero elements\n    np.random.randn(3, 3) * 1e12   # Large magnitudes\n]",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "34005518"
  },
  {
    "id": "numerical_stability_guide_23_0b52b293",
    "file": "docs\\numerical_stability_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Track where ill-conditioned matrices originate\ndef compute_inertia_matrix(state):\n    \"\"\"\n    Compute inertia matrix M(q).\n\n    Known conditioning issues:\n    - Singular when theta1 = theta2 = 0 (upright equilibrium)\n    - Condition number ~ 1e8 for typical trajectories\n    - Requires adaptive regularization for robustness\n    \"\"\"\n    # ... implementation ...",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0b52b293"
  },
  {
    "id": "PATTERNS_1_a1a93fcd",
    "file": "docs\\PATTERNS.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/factory.py (lines 507-543)\n\ndef create_controller(controller_type: str,\n                     config: Optional[Any] = None,\n                     gains: Optional[Union[list, np.ndarray]] = None) -> Any:\n    \"\"\"\n    Create a controller instance of the specified type.\n\n    This function is thread-safe and can be called concurrently.\n\n    Supported types: 'classical_smc', 'sta_smc', 'adaptive_smc',\n                     'hybrid_adaptive_sta_smc', 'mpc_controller'\n    \"\"\"\n    # Normalize controller type (handles aliases)\n    controller_type = _canonicalize_controller_type(controller_type)\n\n    # Retrieve from registry\n    controller_info = _get_controller_info(controller_type)\n    controller_class = controller_info['class']\n\n    # Resolve gains from config/defaults\n    controller_gains = _resolve_controller_gains(gains, config, controller_type)\n\n    # Validate gains with controller-specific rules\n    _validate_controller_gains(controller_gains, controller_info)\n\n    # Create and return configured instance\n    return controller_class(controller_gains, **kwargs)",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a1a93fcd"
  },
  {
    "id": "PATTERNS_2_a0ca615f",
    "file": "docs\\PATTERNS.md",
    "index": 2,
    "code": "from src.controllers.factory import create_controller\n\n# Simple instantiation\ncontroller = create_controller('classical_smc', gains=[10, 8, 15, 12, 50, 5])\n\n# With configuration\ncontroller = create_controller('adaptive_smc', config=app_config, gains=optimized_gains)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0ca615f"
  },
  {
    "id": "PATTERNS_3_207b1f0e",
    "file": "docs\\PATTERNS.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Controller registry with comprehensive metadata (lines 181-218)\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    'sta_smc': { ... },\n    'adaptive_smc': { ... },\n    'hybrid_adaptive_sta_smc': { ... }\n}",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "207b1f0e"
  },
  {
    "id": "PATTERNS_4_01eb4200",
    "file": "docs\\PATTERNS.md",
    "index": 4,
    "code": "# src/simulation/strategies/monte_carlo.py (lines 16-71)\n\nfrom ..core.interfaces import SimulationStrategy\n\nclass MonteCarloStrategy(SimulationStrategy):\n    \"\"\"Monte Carlo simulation strategy for statistical analysis.\"\"\"\n\n    def __init__(self, n_samples: int = 1000, parallel: bool = True):\n        self.n_samples = n_samples\n        self.parallel = parallel\n\n    def analyze(self, simulation_fn: Callable,\n                parameters: Dict[str, Any], **kwargs) -> Dict[str, Any]:\n        \"\"\"Perform Monte Carlo analysis with parameter distributions.\"\"\"\n        param_distributions = parameters.get('distributions', {})\n        samples = self._generate_samples(param_distributions)\n\n        if self.parallel:\n            results = self._run_parallel_simulations(simulation_fn, samples)\n        else:\n            results = self._run_sequential_simulations(simulation_fn, samples)\n\n        return self._analyze_results(results, samples)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "01eb4200"
  },
  {
    "id": "PATTERNS_5_a3722978",
    "file": "docs\\PATTERNS.md",
    "index": 5,
    "code": "# Client code selects strategy at runtime\nif analysis_type == 'monte_carlo':\n    strategy = MonteCarloStrategy(n_samples=1000)\nelif analysis_type == 'sensitivity':\n    strategy = SensitivityAnalysisStrategy(perturbation=0.01)\n\n# Execute with chosen strategy\nresults = strategy.analyze(simulation_fn, parameters)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a3722978"
  },
  {
    "id": "PATTERNS_6_f4c6b026",
    "file": "docs\\PATTERNS.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# src/interfaces/monitoring/health_monitor.py (lines 85-100)\n\n@dataclass\nclass ComponentHealth:\n    \"\"\"Health status of a system component.\"\"\"\n    component_name: str\n    status: HealthStatus = HealthStatus.UNKNOWN\n    check_results: List[HealthCheckResult] = field(default_factory=list)\n\n    def update_status(self, new_status: HealthStatus) -> None:\n        \"\"\"Update component health status and notify observers.\"\"\"\n        if self.status != new_status:\n            self.status = new_status\n            self.last_check = time.time()\n            self._notify_observers(new_status)\n\n    def _notify_observers(self, status: HealthStatus) -> None:\n        \"\"\"Notify all registered observers of status change.\"\"\"\n        for observer in self._observers:\n            observer.on_health_change(self.component_name, status)",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4c6b026"
  },
  {
    "id": "PATTERNS_7_a5a196e6",
    "file": "docs\\PATTERNS.md",
    "index": 7,
    "code": "# Register observers\nhealth_monitor.register_observer(logger_observer)\nhealth_monitor.register_observer(alert_system_observer)\nhealth_monitor.register_observer(dashboard_observer)\n\n# Status change automatically notifies all observers\ncomponent.update_status(HealthStatus.CRITICAL)  # All observers notified",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5a196e6"
  },
  {
    "id": "PATTERNS_8_95aefd05",
    "file": "docs\\PATTERNS.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/factory.py (lines 942-1012)\n\nclass PSOControllerWrapper:\n    \"\"\"Adapter for SMC controllers to provide PSO-compatible interface.\"\"\"\n\n    def __init__(self, controller, n_gains: int, controller_type: str):\n        self.controller = controller  # Wrapped legacy controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Adapt legacy controller interface to PSO-compatible format.\"\"\"\n        # Legacy interface: compute_control(state, last_control, history)\n        # PSO interface: compute_control(state) -> control_array\n\n        result = self.controller.compute_control(state, (), {})\n\n        # Extract and format control output for PSO\n        if hasattr(result, 'u'):\n            u = result.u\n        else:\n            u = result\n\n        return np.array([u])  # Convert to numpy array",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "95aefd05"
  },
  {
    "id": "PATTERNS_9_c604b37d",
    "file": "docs\\PATTERNS.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Legacy controller\nlegacy_controller = ClassicalSMC(gains=[...])\n\n# Wrap for PSO compatibility\npso_compatible = PSOControllerWrapper(legacy_controller, n_gains=6,\n                                      controller_type='classical_smc')\n\n# Now works with PSO optimizer\noptimizer.optimize(pso_compatible.compute_control)",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c604b37d"
  },
  {
    "id": "PATTERNS_10_87882a71",
    "file": "docs\\PATTERNS.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# OLD APPROACH (Inheritance - 427 lines, hard to test):\nclass AdaptiveSMC(BaseSMC):\n    def compute_control(self, state):\n        # 427 lines of monolithic code\n        # - Surface computation\n        # - Switching logic\n        # - Adaptation law\n        # - Uncertainty estimation\n        # - Control computation\n        # All tightly coupled, hard to test independently\n\n# NEW APPROACH (Composition - 4 focused modules):\n\n# src/controllers/smc/algorithms/adaptive/controller.py\nclass ModularAdaptiveSMC:\n    \"\"\"Adaptive SMC using composed components.\"\"\"\n\n    def __init__(self, config: AdaptiveSMCConfig):\n        # Compose from focused modules\n        self.surface = LinearSlidingSurface(config.k1, config.k2,\n                                            config.lam1, config.lam2)\n        self.adaptation = AdaptationLaw(config.gamma, config.leak_rate)\n        self.estimator = UncertaintyEstimator(config.K_min, config.K_max)\n        self.switching = SwitchingFunction(method='boundary_layer',\n                                          epsilon=config.boundary_layer)\n\n    def compute_control(self, state):\n        \"\"\"Compute control using composed modules.\"\"\"\n        # Each module is independently testable\n        s = self.surface.compute(state)\n        K_adapted = self.adaptation.update(s, self.K_current)\n        uncertainty = self.estimator.estimate(state, s)\n        u_switch = self.switching.compute(s, K_adapted)\n\n        return u_switch",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87882a71"
  },
  {
    "id": "PATTERNS_11_4e26efa9",
    "file": "docs\\PATTERNS.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# BAD: Tight coupling (hardcoded dependency)\nclass ClassicalSMC:\n    def __init__(self, gains):\n        self.gains = gains\n        self.dynamics = DIPDynamics()  # \u274c Hardcoded dependency\n\n    def compute_control(self, state):\n        # Can't test without real dynamics\n        dynamics_info = self.dynamics.compute(state, u=0)\n\n# GOOD: Dependency Injection\nclass ClassicalSMC:\n    def __init__(self, gains, dynamics_model=None):  # \u2705 Injected dependency\n        self.gains = gains\n        self._dynamics_ref = weakref.ref(dynamics_model) if dynamics_model else None\n\n    def compute_control(self, state):\n        if self._dynamics_ref:\n            dynamics = self._dynamics_ref()  # Use injected dynamics\n        # Controller logic works with or without dynamics",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4e26efa9"
  },
  {
    "id": "PATTERNS_12_790b600b",
    "file": "docs\\PATTERNS.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/factory.py (lines 569-580)\n\ndef create_controller(controller_type: str, config: Optional[Any] = None):\n    # Create dynamics model from config\n    dynamics_model = None\n    if config is not None and hasattr(config, 'physics'):\n        dynamics_model = DIPDynamics(config.physics)\n\n    # Inject dynamics into controller\n    if dynamics_model is not None:\n        config_params['dynamics_model'] = dynamics_model\n\n    return controller_class(**config_params)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "790b600b"
  },
  {
    "id": "PATTERNS_13_77df2bad",
    "file": "docs\\PATTERNS.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/factory.py (lines 114-134)\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Minimal controller interface - only essential methods.\"\"\"\n\n    def compute_control(self, state: StateVector, last_control: float,\n                       history: ConfigDict) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller internal state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "77df2bad"
  },
  {
    "id": "PATTERNS_14_bfd9bd19",
    "file": "docs\\PATTERNS.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Optional protocols for advanced features\nclass DynamicsAwareController(Protocol):\n    \"\"\"Protocol for controllers that use plant dynamics.\"\"\"\n    def set_dynamics(self, dynamics: DIPDynamics) -> None: ...\n\nclass AdaptiveController(Protocol):\n    \"\"\"Protocol for controllers with online adaptation.\"\"\"\n    def get_adapted_gains(self) -> List[float]: ...\n    def reset_adaptation(self) -> None: ...\n\nclass ObservableController(Protocol):\n    \"\"\"Protocol for controllers that provide internal state.\"\"\"\n    def get_internal_state(self) -> Dict[str, Any]: ...",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfd9bd19"
  },
  {
    "id": "PATTERNS_15_0605bba7",
    "file": "docs\\PATTERNS.md",
    "index": 15,
    "code": "# src/utils/monitoring/memory_monitor.py\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef memory_tracking(threshold_mb: float = 500.0):\n    \"\"\"Context manager for tracking memory usage.\"\"\"\n    import psutil\n    import gc\n\n    process = psutil.Process()\n    initial_memory = process.memory_info().rss / 1024 / 1024\n\n    try:\n        yield process\n    finally:\n        final_memory = process.memory_info().rss / 1024 / 1024\n        delta = final_memory - initial_memory\n\n        if delta > threshold_mb:\n            gc.collect()  # Force garbage collection\n            logging.warning(f\"Memory increased by {delta:.1f}MB\")\n\n# Usage\nwith memory_tracking(threshold_mb=100.0) as process:\n    # Run memory-intensive operation\n    results = run_pso_optimization(n_iterations=1000)\n# Automatic cleanup and memory check",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0605bba7"
  },
  {
    "id": "PATTERNS_16_f2317dfc",
    "file": "docs\\PATTERNS.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# src/utils/validation/parameter_validators.py\n\ndef validate_gains(n_expected: int):\n    \"\"\"Decorator to validate gain array length.\"\"\"\n    def decorator(func):\n        def wrapper(self, gains, *args, **kwargs):\n            if len(gains) != n_expected:\n                raise ValueError(f\"Expected {n_expected} gains, got {len(gains)}\")\n            return func(self, gains, *args, **kwargs)\n        return wrapper\n    return decorator\n\n# Usage\nclass ClassicalSMC:\n    @validate_gains(n_expected=6)\n    def __init__(self, gains):\n        self.gains = gains  # Guaranteed to have 6 elements",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2317dfc"
  },
  {
    "id": "PATTERNS_17_41343e94",
    "file": "docs\\PATTERNS.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/factory.py (lines 95-102)\n\nfrom typing import Any, Callable, Dict, List, Optional, Union, Protocol\nfrom numpy.typing import NDArray\nimport numpy as np\n\n# Type aliases for clarity\nStateVector = NDArray[np.float64]\nControlOutput = Union[float, NDArray[np.float64]]\nGainsArray = Union[List[float], NDArray[np.float64]]\nConfigDict = Dict[str, Any]\n\ndef create_controller(controller_type: str,\n                     config: Optional[Any] = None,\n                     gains: Optional[GainsArray] = None) -> ControllerProtocol:\n    \"\"\"Type-safe controller instantiation.\"\"\"\n    ...",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "41343e94"
  },
  {
    "id": "PATTERNS_18_62f60c2b",
    "file": "docs\\PATTERNS.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# src/simulation/engines/vector_sim.py\n\ndef run_batch_simulation(controller, dynamics, initial_conditions_batch, dt=0.001):\n    \"\"\"Vectorized batch simulation - process 1000 simulations simultaneously.\"\"\"\n    n_simulations = initial_conditions_batch.shape[0]\n    n_steps = int(T / dt)\n\n    # Allocate batch arrays (vectorized storage)\n    states_batch = np.zeros((n_simulations, n_steps, 6))  # 1000 x 10000 x 6\n    controls_batch = np.zeros((n_simulations, n_steps))\n\n    states_batch[:, 0, :] = initial_conditions_batch\n\n    for i in range(1, n_steps):\n        # Vectorized control computation (1000 controllers at once)\n        controls_batch[:, i] = controller.compute_control_batch(states_batch[:, i-1, :])\n\n        # Vectorized dynamics integration (1000 integrations at once)\n        states_batch[:, i, :] = dynamics.step_batch(states_batch[:, i-1, :],\n                                                     controls_batch[:, i], dt)\n\n    return states_batch, controls_batch",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62f60c2b"
  },
  {
    "id": "PATTERNS_19_32d7a095",
    "file": "docs\\PATTERNS.md",
    "index": 19,
    "code": "from numba import jit\n\n@jit(nopython=True, cache=True)\ndef compute_sliding_surface_batch(states, k1, k2, lam1, lam2):\n    \"\"\"JIT-compiled sliding surface computation (1000\u00d7 faster).\"\"\"\n    n = states.shape[0]\n    surfaces = np.zeros(n)\n\n    for i in range(n):\n        x, x_dot, theta1, theta1_dot, theta2, theta2_dot = states[i]\n        surfaces[i] = (k1 * x + lam1 * x_dot +\n                      k2 * theta1 + lam2 * theta1_dot)\n\n    return surfaces",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32d7a095"
  },
  {
    "id": "PATTERNS_20_7e3f6b89",
    "file": "docs\\PATTERNS.md",
    "index": 20,
    "code": "# src/utils/reproducibility/seeding.py\n\ndef set_global_seed(seed: int) -> None:\n    \"\"\"Set seeds for all random number generators.\"\"\"\n    import random\n    import numpy as np\n\n    random.seed(seed)\n    np.random.seed(seed)\n\n    # Set environment variables for determinism\n    import os\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n    # Numba RNG seeding (if applicable)\n    try:\n        import numba\n        numba.core.config.RANDOM_SEED = seed\n    except ImportError:\n        pass\n\n# Usage in all experiments\nset_global_seed(42)  # Ensures reproducible results",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e3f6b89"
  },
  {
    "id": "PHASE_1_2_VS_1_3_VALIDATION_1_e3ac38c3",
    "file": "docs\\PHASE_1_2_VS_1_3_VALIDATION.md",
    "index": 1,
    "code": "# Phase 1.3 filter logic:\nis_public = not method.name.startswith('_')\nundoc_methods = sum(1 for m in all_methods if not m.docstring.has_docstring and m.is_public)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3ac38c3"
  },
  {
    "id": "PHASE_1_2_VS_1_3_VALIDATION_2_cc4e90ba",
    "file": "docs\\PHASE_1_2_VS_1_3_VALIDATION.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Type hint detection\ndef analyze_type_hints(node: ast.FunctionDef):\n    args = node.args\n    all_args = args.args + args.posonlyargs + args.kwonlyargs\n    annotated = sum(1 for arg in all_args if arg.annotation is not None)\n    has_return = node.returns is not None\n    coverage = (annotated / total) * 100 if total > 0 else 100.0\n\n# Docstring detection\ndef analyze_docstring(docstring: str):\n    has_params = \"Parameters\" in docstring or \"Args:\" in docstring\n    has_returns = \"Returns\" in docstring or \":return\" in docstring\n    style = detect_style(docstring)  # numpy, google, sphinx",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc4e90ba"
  },
  {
    "id": "PHASE_5_3_COMPLETION_REPORT_1_11582999",
    "file": "docs\\PHASE_5_3_COMPLETION_REPORT.md",
    "index": 1,
    "code": "Default Gains:  [8.0, 4.0, 12.0, 6.0, 4.85, 3.43]\nOptimized Gains: [23.67, 13.29, 8.87, 3.55, 6.52, 2.93]\nBest Cost: 0.000000\nK2/K1 Ratio: 0.561 \u2705 (Stability condition satisfied)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "11582999"
  },
  {
    "id": "PHASE_5_4_COMPLETION_REPORT_1_b8cf1950",
    "file": "docs\\PHASE_5_4_COMPLETION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Confidence Intervals (t-distribution)\ndef compute_statistics(data, metric='ise', confidence=0.95):\n    mean, std = data.mean(), data.std()\n    se = std / np.sqrt(len(data))\n    t_critical = stats.t.ppf(1 - (1-confidence)/2, df=len(data)-1)\n    ci = (mean - t_critical*se, mean + t_critical*se)\n    return {'mean': mean, 'std': std, 'ci': ci}\n\n# Hypothesis Testing (Welch's t-test)\nt_stat, p_value = ttest_ind(classical, sta, equal_var=False)\n\n# Effect Size (Cohen's d)\ncohens_d = abs(classical.mean() - sta.mean()) / pooled_std\n\n# Power Analysis (required sample size)\nrequired_n = tt_solve_power(effect_size=0.68, alpha=0.05, power=0.80)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b8cf1950"
  },
  {
    "id": "PHASE_6_3_COMPLETION_REPORT_1_bc795a08",
    "file": "docs\\PHASE_6_3_COMPLETION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nextensions = [\n    # ... other extensions ...\n    'chartjs_extension',  # Chart.js interactive visualizations\n]",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc795a08"
  },
  {
    "id": "PHASE_6_COMPLETION_REPORT_1_ba6a6373",
    "file": "docs\\PHASE_6_COMPLETION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n   # runnable: true\n   # requires: [numpy, scipy]\n   # timeout: 60s",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": true,
      "requires": [
        "numpy",
        "scipy"
      ],
      "timeout": 60,
      "expected_output": null
    },
    "hash": "ba6a6373"
  },
  {
    "id": "pso_algorithm_mathematical_foundations_1_75c4c90d",
    "file": "docs\\pso_algorithm_mathematical_foundations.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Mathematical implementation in PSO cost function\ndef _combine_costs(self, costs: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Combine costs across uncertainty draws.\n\n    costs: Array of shape (n_draws, n_particles)\n    Returns: Array of shape (n_particles,)\n    \"\"\"\n    mean_cost = np.mean(costs, axis=0)\n    max_cost = np.max(costs, axis=0)\n    return self.combine_weights[0] * mean_cost + self.combine_weights[1] * max_cost",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75c4c90d"
  },
  {
    "id": "pso_configuration_schema_documentation_1_b1aa37f8",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_pso_algorithm_params(params: dict) -> ValidationResult:\n    \"\"\"\n    Validate core PSO algorithm parameters for mathematical consistency.\n\n    Validation Rules:\n    1. Clerc-Kennedy stability: \u03c6 = c\u2081 + c\u2082 > 4 for guaranteed convergence\n    2. Balanced coefficients: |c\u2081 - c\u2082| \u2264 0.5 for exploration-exploitation balance\n    3. Inertia bounds: w \u2208 [0.4, 0.9] for optimal performance\n    4. Swarm size: n \u2208 [10, 50] for computational efficiency vs quality\n    \"\"\"\n    errors = []\n\n    # PSO stability condition (Clerc-Kennedy)\n    phi = params['c1'] + params['c2']\n    if phi <= 4.0:\n        errors.append(f\"PSO convergence risk: \u03c6 = c\u2081 + c\u2082 = {phi:.3f} \u2264 4.0\")\n\n    # Coefficient balance\n    coeff_diff = abs(params['c1'] - params['c2'])\n    if coeff_diff > 0.5:\n        errors.append(f\"Unbalanced coefficients: |c\u2081 - c\u2082| = {coeff_diff:.3f} > 0.5\")\n\n    # Inertia weight validation\n    if not (0.4 <= params['w'] <= 0.9):\n        errors.append(f\"Inertia weight w = {params['w']:.3f} outside optimal range [0.4, 0.9]\")\n\n    # Swarm size validation\n    if not (10 <= params['n_particles'] <= 50):\n        errors.append(f\"Swarm size {params['n_particles']} outside recommended range [10, 50]\")\n\n    return ValidationResult(is_valid=len(errors) == 0, errors=errors)",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1aa37f8"
  },
  {
    "id": "pso_configuration_schema_documentation_2_da8cd51c",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass DynamicBoundsSelector:\n    \"\"\"\n    Intelligent bounds selection based on controller type and system requirements.\n    \"\"\"\n\n    def __init__(self, config_schema: dict):\n        self.base_bounds = config_schema['bounds']\n        self.controller_bounds = {\n            key: value for key, value in config_schema['bounds'].items()\n            if key not in ['base', 'min', 'max']\n        }\n\n    def get_bounds_for_controller(self, controller_type: str,\n                                dynamic_adjustment: bool = True) -> dict:\n        \"\"\"\n        Get optimized bounds for specific controller type.\n\n        Parameters:\n        controller_type: SMC variant identifier\n        dynamic_adjustment: Enable runtime bounds optimization\n\n        Returns:\n        dict: Complete bounds specification with validation rules\n        \"\"\"\n        # Start with controller-specific bounds\n        if controller_type in self.controller_bounds:\n            bounds = self.controller_bounds[controller_type].copy()\n        else:\n            # Fallback to default bounds\n            bounds = {\n                'min': self.base_bounds['min'],\n                'max': self.base_bounds['max']\n            }\n\n        # Apply dynamic adjustments if enabled\n        if dynamic_adjustment:\n            bounds = self._apply_dynamic_adjustments(bounds, controller_type)\n\n        # Add validation constraints\n        bounds['validation_rules'] = self._get_validation_rules(controller_type)\n\n        return bounds\n\n    def _apply_dynamic_adjustments(self, bounds: dict, controller_type: str) -> dict:\n        \"\"\"\n        Apply runtime bounds optimization based on system state and performance.\n        \"\"\"\n        if controller_type == 'sta_smc':\n            # Issue #2 specific adjustments\n            current_performance = self._assess_current_performance()\n            if current_performance.overshoot > 0.05:  # >5% overshoot\n                # Further restrict lambda bounds\n                bounds['max'][4] = min(bounds['max'][4], 5.0)  # lambda1\n                bounds['max'][5] = min(bounds['max'][5], 5.0)  # lambda2\n\n        return bounds\n\n    def _get_validation_rules(self, controller_type: str) -> list:\n        \"\"\"\n        Get controller-specific validation rules for PSO bounds enforcement.\n        \"\"\"\n        rules = ['positive_gains', 'actuator_saturation']\n\n        if controller_type == 'sta_smc':\n            rules.extend(['k1_greater_k2', 'finite_time_convergence', 'issue2_overshoot'])\n        elif controller_type == 'adaptive_smc':\n            rules.extend(['adaptation_stability'])\n        elif controller_type == 'classical_smc':\n            rules.extend(['damping_ratio_bounds'])\n\n        return rules",
    "lines": 74,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da8cd51c"
  },
  {
    "id": "pso_configuration_schema_documentation_3_639f79a1",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConstraintPropagator:\n    \"\"\"\n    Intelligent constraint propagation for interdependent PSO parameters.\n    \"\"\"\n\n    def __init__(self, controller_type: str):\n        self.controller_type = controller_type\n        self.constraint_graph = self._build_constraint_graph()\n\n    def propagate_constraints(self, initial_bounds: dict) -> dict:\n        \"\"\"\n        Propagate constraints through parameter dependency graph.\n\n        Example: If \u03bb\u2081 is constrained to [0.1, 5.0] for Issue #2,\n        then c\u2081 bounds must ensure \u03b6\u2081 = \u03bb\u2081/(2\u221ac\u2081) \u2208 [0.69, 0.8]\n        \"\"\"\n        propagated_bounds = initial_bounds.copy()\n\n        # Iterative constraint propagation\n        converged = False\n        max_iterations = 10\n        iteration = 0\n\n        while not converged and iteration < max_iterations:\n            old_bounds = propagated_bounds.copy()\n\n            # Apply constraint rules\n            for constraint in self.constraint_graph:\n                propagated_bounds = self._apply_constraint_rule(\n                    constraint, propagated_bounds\n                )\n\n            # Check convergence\n            converged = self._bounds_converged(old_bounds, propagated_bounds)\n            iteration += 1\n\n        return propagated_bounds\n\n    def _apply_constraint_rule(self, constraint: dict, bounds: dict) -> dict:\n        \"\"\"\n        Apply individual constraint rule with mathematical validation.\n        \"\"\"\n        if constraint['type'] == 'damping_ratio':\n            # \u03b6 = \u03bb/(2\u221ac) constraint propagation\n            lambda_idx = constraint['lambda_idx']\n            c_idx = constraint['c_idx']\n            target_zeta_range = constraint['zeta_range']\n\n            lambda_min, lambda_max = bounds['min'][lambda_idx], bounds['max'][lambda_idx]\n\n            # Derive c bounds from lambda bounds and zeta constraints\n            # For \u03b6_min \u2264 \u03bb/(2\u221ac) \u2264 \u03b6_max:\n            # c_min = (\u03bb/(2\u03b6_max))\u00b2, c_max = (\u03bb/(2\u03b6_min))\u00b2\n\n            c_min_from_lambda = (lambda_min / (2 * target_zeta_range[1]))**2\n            c_max_from_lambda = (lambda_max / (2 * target_zeta_range[0]))**2\n\n            # Update c bounds with constraint propagation\n            bounds['min'][c_idx] = max(bounds['min'][c_idx], c_min_from_lambda)\n            bounds['max'][c_idx] = min(bounds['max'][c_idx], c_max_from_lambda)\n\n        elif constraint['type'] == 'sta_stability':\n            # K\u2081 > K\u2082 constraint with margin\n            k1_idx, k2_idx = constraint['k1_idx'], constraint['k2_idx']\n            margin = constraint.get('margin', 0.1)\n\n            # Ensure K\u2081_min > K\u2082_max + margin\n            bounds['min'][k1_idx] = max(\n                bounds['min'][k1_idx],\n                bounds['max'][k2_idx] + margin\n            )\n\n        return bounds\n\n    def _build_constraint_graph(self) -> list:\n        \"\"\"\n        Build constraint dependency graph for controller type.\n        \"\"\"\n        if self.controller_type == 'classical_smc':\n            return [\n                {\n                    'type': 'damping_ratio',\n                    'lambda_idx': 1, 'c_idx': 0,\n                    'zeta_range': [0.6, 0.8]\n                },\n                {\n                    'type': 'damping_ratio',\n                    'lambda_idx': 3, 'c_idx': 2,\n                    'zeta_range': [0.6, 0.8]\n                },\n                {\n                    'type': 'actuator_saturation',\n                    'gain_indices': [4, 5],  # K, kd\n                    'max_total': 150.0\n                }\n            ]\n\n        elif self.controller_type == 'sta_smc':\n            return [\n                {\n                    'type': 'sta_stability',\n                    'k1_idx': 0, 'k2_idx': 1,\n                    'margin': 0.1\n                },\n                {\n                    'type': 'damping_ratio',\n                    'lambda_idx': 4, 'c_idx': 2,  # lambda1, k1\n                    'zeta_range': [0.69, 0.8]  # Issue #2 requirement\n                },\n                {\n                    'type': 'damping_ratio',\n                    'lambda_idx': 5, 'c_idx': 3,  # lambda2, k2\n                    'zeta_range': [0.69, 0.8]  # Issue #2 requirement\n                }\n            ]\n\n        return []",
    "lines": 120,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "639f79a1"
  },
  {
    "id": "pso_configuration_schema_documentation_4_5ac0f6ba",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_ConfigurationValidator:\n    \"\"\"\n    Comprehensive PSO configuration validation with mathematical rigor.\n    \"\"\"\n\n    def __init__(self):\n        self.validation_levels = [\n            'syntax_validation',      # YAML structure and types\n            'range_validation',       # Parameter bounds checking\n            'mathematical_validation', # Stability and convergence\n            'controller_validation',   # Controller-specific constraints\n            'performance_validation',  # Expected performance bounds\n            'safety_validation'       # Hardware and operational safety\n        ]\n\n    def validate_complete_config(self, config: dict) -> ValidationReport:\n        \"\"\"\n        Perform complete multi-level validation of PSO configuration.\n        \"\"\"\n        report = ValidationReport()\n\n        for level in self.validation_levels:\n            validator_method = getattr(self, level)\n            level_result = validator_method(config)\n            report.add_level_result(level, level_result)\n\n            # Stop on critical failures\n            if level_result.severity == 'CRITICAL':\n                break\n\n        return report\n\n    def syntax_validation(self, config: dict) -> ValidationResult:\n        \"\"\"\n        Level 1: Validate YAML structure and data types.\n        \"\"\"\n        errors = []\n\n        # Required sections\n        required_sections = ['algorithm_params', 'bounds', 'execution']\n        for section in required_sections:\n            if section not in config:\n                errors.append(f\"Missing required section: {section}\")\n\n        # Type checking\n        if 'algorithm_params' in config:\n            params = config['algorithm_params']\n            type_checks = [\n                ('n_particles', int), ('iters', int),\n                ('w', (float, int)), ('c1', (float, int)), ('c2', (float, int))\n            ]\n            for param_name, expected_type in type_checks:\n                if param_name in params:\n                    if not isinstance(params[param_name], expected_type):\n                        errors.append(f\"Type error: {param_name} must be {expected_type}\")\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)\n\n    def mathematical_validation(self, config: dict) -> ValidationResult:\n        \"\"\"\n        Level 3: Validate mathematical consistency and stability.\n        \"\"\"\n        errors = []\n\n        if 'algorithm_params' in config:\n            params = config['algorithm_params']\n\n            # PSO convergence condition: \u03c6 = c\u2081 + c\u2082 > 4\n            if 'c1' in params and 'c2' in params:\n                phi = params['c1'] + params['c2']\n                if phi <= 4.0:\n                    errors.append(f\"PSO convergence risk: \u03c6 = {phi:.3f} \u2264 4.0\")\n\n            # Coefficient balance: |c\u2081 - c\u2082| \u2264 0.5\n            if 'c1' in params and 'c2' in params:\n                diff = abs(params['c1'] - params['c2'])\n                if diff > 0.5:\n                    errors.append(f\"Unbalanced coefficients: |c\u2081 - c\u2082| = {diff:.3f}\")\n\n            # Inertia weight bounds: w \u2208 [0.4, 0.9]\n            if 'w' in params:\n                w = params['w']\n                if not (0.4 <= w <= 0.9):\n                    errors.append(f\"Inertia weight w = {w:.3f} outside optimal range\")\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)\n\n    def controller_validation(self, config: dict) -> ValidationResult:\n        \"\"\"\n        Level 4: Validate controller-specific constraints.\n        \"\"\"\n        errors = []\n\n        if 'bounds' not in config:\n            return ValidationResult(is_valid=False, errors=[\"Missing bounds configuration\"])\n\n        bounds_config = config['bounds']\n\n        # Validate each controller type\n        for controller_type in ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']:\n            if controller_type in bounds_config:\n                controller_errors = self._validate_controller_bounds(\n                    controller_type, bounds_config[controller_type]\n                )\n                errors.extend(controller_errors)\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)\n\n    def _validate_controller_bounds(self, controller_type: str, bounds: dict) -> list:\n        \"\"\"\n        Validate bounds for specific controller type.\n        \"\"\"\n        errors = []\n\n        if 'min' not in bounds or 'max' not in bounds:\n            return [f\"{controller_type}: Missing min/max bounds\"]\n\n        min_bounds, max_bounds = bounds['min'], bounds['max']\n\n        # Check bounds consistency\n        if len(min_bounds) != len(max_bounds):\n            errors.append(f\"{controller_type}: min/max bounds length mismatch\")\n            return errors\n\n        # Check min < max for all parameters\n        for i, (min_val, max_val) in enumerate(zip(min_bounds, max_bounds)):\n            if min_val >= max_val:\n                errors.append(f\"{controller_type}: Parameter {i}: min {min_val} >= max {max_val}\")\n\n        # Controller-specific validation\n        if controller_type == 'sta_smc':\n            # Issue #2 specific validation\n            if len(min_bounds) >= 6:  # lambda1, lambda2 are indices 4, 5\n                lambda1_max, lambda2_max = max_bounds[4], max_bounds[5]\n                if lambda1_max > 10.0 or lambda2_max > 10.0:\n                    errors.append(f\"STA-SMC Issue #2: Lambda bounds too large (max: {lambda1_max}, {lambda2_max})\")\n\n        elif controller_type == 'adaptive_smc':\n            # Check adaptation rate bounds\n            if len(min_bounds) >= 5:  # gamma is index 4\n                gamma_min, gamma_max = min_bounds[4], max_bounds[4]\n                if gamma_min <= 0:\n                    errors.append(f\"Adaptive SMC: Adaptation rate must be positive\")\n                if gamma_max > 10.0:\n                    errors.append(f\"Adaptive SMC: Adaptation rate too large: {gamma_max}\")\n\n        return errors",
    "lines": 150,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ac0f6ba"
  },
  {
    "id": "pso_configuration_schema_documentation_5_e4c8a52b",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationMonitor:\n    \"\"\"\n    Real-time monitoring of PSO configuration performance and adaptation.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.performance_history = []\n        self.adaptation_triggers = {\n            'poor_convergence': self._handle_poor_convergence,\n            'parameter_instability': self._handle_parameter_instability,\n            'safety_violation': self._handle_safety_violation\n        }\n\n    def monitor_optimization_run(self, pso_state: dict) -> dict:\n        \"\"\"\n        Monitor PSO optimization run and suggest configuration adaptations.\n        \"\"\"\n        current_performance = self._assess_performance(pso_state)\n        self.performance_history.append(current_performance)\n\n        # Check for adaptation triggers\n        adaptations = {}\n        for trigger_name, handler in self.adaptation_triggers.items():\n            if self._check_trigger(trigger_name, current_performance):\n                adaptation = handler(current_performance)\n                if adaptation:\n                    adaptations[trigger_name] = adaptation\n\n        return {\n            'performance': current_performance,\n            'suggested_adaptations': adaptations,\n            'config_health': self._assess_config_health()\n        }\n\n    def _handle_poor_convergence(self, performance: dict) -> dict:\n        \"\"\"\n        Handle poor convergence by adjusting PSO parameters.\n        \"\"\"\n        if performance['convergence_rate'] < 0.1:  # Very slow convergence\n            return {\n                'parameter': 'w',\n                'adjustment': 'decrease',\n                'new_value': max(0.4, self.config['algorithm_params']['w'] - 0.1),\n                'reason': 'Increase exploitation for faster convergence'\n            }\n\n        if performance['diversity'] < 1e-8:  # Premature convergence\n            return {\n                'parameter': 'w',\n                'adjustment': 'increase',\n                'new_value': min(0.9, self.config['algorithm_params']['w'] + 0.1),\n                'reason': 'Increase exploration to escape local optimum'\n            }\n\n        return None\n\n    def _assess_config_health(self) -> dict:\n        \"\"\"\n        Assess overall configuration health and optimization efficiency.\n        \"\"\"\n        if len(self.performance_history) < 5:\n            return {'status': 'insufficient_data'}\n\n        recent_performance = self.performance_history[-5:]\n\n        # Convergence trend analysis\n        convergence_trend = np.polyfit(range(5), [p['convergence_rate'] for p in recent_performance], 1)[0]\n\n        # Stability assessment\n        cost_variance = np.var([p['best_cost'] for p in recent_performance])\n\n        health_score = 100.0\n        issues = []\n\n        if convergence_trend < -0.01:  # Degrading convergence\n            health_score -= 20\n            issues.append('degrading_convergence')\n\n        if cost_variance > 1.0:  # High cost variance\n            health_score -= 15\n            issues.append('unstable_optimization')\n\n        avg_diversity = np.mean([p['diversity'] for p in recent_performance])\n        if avg_diversity < 1e-10:  # Very low diversity\n            health_score -= 25\n            issues.append('diversity_collapse')\n\n        return {\n            'status': 'healthy' if health_score > 80 else 'needs_attention',\n            'score': health_score,\n            'issues': issues,\n            'recommendations': self._generate_recommendations(issues)\n        }",
    "lines": 97,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4c8a52b"
  },
  {
    "id": "pso_configuration_schema_documentation_6_30b58eae",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationMigrator:\n    \"\"\"\n    Automatic migration framework for PSO configuration schema evolution.\n    \"\"\"\n\n    def __init__(self):\n        self.migration_rules = {\n            \"1.0\": self._migrate_from_v1_0,\n            \"1.5\": self._migrate_from_v1_5,\n            \"2.0\": self._migrate_from_v2_0\n        }\n\n    def migrate_configuration(self, config: dict, source_version: str) -> tuple:\n        \"\"\"\n        Migrate configuration from source version to current schema.\n\n        Returns:\n        tuple: (migrated_config, migration_warnings, compatibility_issues)\n        \"\"\"\n        if source_version not in self.migration_rules:\n            raise ValueError(f\"Unsupported source version: {source_version}\")\n\n        migrated_config = config.copy()\n        warnings = []\n        issues = []\n\n        # Apply migration rules in sequence\n        current_version = source_version\n        while current_version != CURRENT_SCHEMA_VERSION:\n            migrator = self.migration_rules[current_version]\n            migrated_config, step_warnings = migrator(migrated_config)\n            warnings.extend(step_warnings)\n            current_version = self._get_next_version(current_version)\n\n        # Validate migrated configuration\n        validation_result = PSO_ConfigurationValidator().validate_complete_config(migrated_config)\n        if not validation_result.is_valid:\n            issues.extend(validation_result.errors)\n\n        return migrated_config, warnings, issues\n\n    def _migrate_from_v1_0(self, config: dict) -> tuple:\n        \"\"\"\n        Migrate from v1.0 to v1.5: Remove deprecated fields, update bounds.\n        \"\"\"\n        migrated = config.copy()\n        warnings = []\n\n        # Remove deprecated fields\n        deprecated_fields = ['n_processes', 'hyper_trials', 'hyper_search', 'study_timeout']\n        for field in deprecated_fields:\n            if field in migrated.get('pso', {}):\n                del migrated['pso'][field]\n                warnings.append(f\"Removed deprecated field: {field}\")\n\n        # Update PSO bounds structure\n        if 'pso' in migrated and 'bounds' in migrated['pso']:\n            old_bounds = migrated['pso']['bounds']\n            new_bounds = self._restructure_bounds_v1_5(old_bounds)\n            migrated['pso']['bounds'] = new_bounds\n            warnings.append(\"Restructured bounds for controller-specific optimization\")\n\n        return migrated, warnings\n\n    def _migrate_from_v2_0(self, config: dict) -> tuple:\n        \"\"\"\n        Migrate from v2.0 to v2.1: Issue #2 bounds updates and enhanced features.\n        \"\"\"\n        migrated = config.copy()\n        warnings = []\n\n        # Update STA-SMC bounds for Issue #2 compliance\n        if 'pso' in migrated and 'bounds' in migrated['pso']:\n            bounds = migrated['pso']['bounds']\n            if 'sta_smc' in bounds:\n                sta_bounds = bounds['sta_smc']\n\n                # Check for Issue #2 problematic bounds\n                if 'max' in sta_bounds and len(sta_bounds['max']) >= 6:\n                    lambda1_max, lambda2_max = sta_bounds['max'][4], sta_bounds['max'][5]\n                    if lambda1_max > 10.0 or lambda2_max > 10.0:\n                        # Apply Issue #2 corrections\n                        sta_bounds['max'][4] = min(lambda1_max, 10.0)  # lambda1\n                        sta_bounds['max'][5] = min(lambda2_max, 10.0)  # lambda2\n                        warnings.append(\"Applied Issue #2 lambda bounds corrections for overshoot mitigation\")\n\n        # Add enhanced features if missing\n        if 'enhanced_features' not in migrated.get('pso', {}):\n            migrated['pso']['enhanced_features'] = {\n                'w_schedule': [0.9, 0.4],\n                'velocity_clamp': [0.1, 0.2],\n                'early_stopping': {'patience': 50, 'tolerance': 1e-6}\n            }\n            warnings.append(\"Added enhanced PSO features for improved convergence\")\n\n        return migrated, warnings\n\n    def generate_migration_report(self, old_config: dict, new_config: dict,\n                                warnings: list, issues: list) -> str:\n        \"\"\"\n        Generate comprehensive migration report for documentation.\n        \"\"\"\n        report = f\"\"\"\n# PSO Configuration Migration Report\n\n## Summary\n- **Source Version**: {old_config.get('schema_version', 'unknown')}\n- **Target Version**: {CURRENT_SCHEMA_VERSION}\n- **Migration Status**: {'SUCCESS' if not issues else 'NEEDS ATTENTION'}\n\n## Changes Applied\n\"\"\"\n        for warning in warnings:\n            report += f\"- {warning}\\n\"\n\n        if issues:\n            report += \"\\n## Issues Requiring Attention\\n\"\n            for issue in issues:\n                report += f\"- {issue}\\n\"\n\n        report += f\"\"\"\n## Validation Summary\n- **Mathematical Consistency**: {'\u2713' if self._check_math_consistency(new_config) else '\u2717'}\n- **Controller Compatibility**: {'\u2713' if self._check_controller_compatibility(new_config) else '\u2717'}\n- **Issue #2 Compliance**: {'\u2713' if self._check_issue2_compliance(new_config) else '\u2717'}\n- **Performance Optimized**: {'\u2713' if self._check_performance_optimization(new_config) else '\u2717'}\n\n## Next Steps\n1. Review configuration changes and validate against system requirements\n2. Test PSO optimization with migrated configuration\n3. Monitor performance and adjust parameters if necessary\n4. Update documentation to reflect configuration changes\n\"\"\"\n        return report",
    "lines": 137,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30b58eae"
  },
  {
    "id": "pso_configuration_schema_documentation_7_a3586b3a",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptivePSOTuner:\n    \"\"\"\n    Adaptive PSO parameter tuning based on real-time performance feedback.\n    \"\"\"\n\n    def __init__(self, initial_config: dict):\n        self.config = initial_config\n        self.performance_history = []\n        self.adaptation_strategy = 'conservative'  # conservative, aggressive, balanced\n\n    def adapt_parameters_realtime(self, pso_state: dict, iteration: int) -> dict:\n        \"\"\"\n        Adapt PSO parameters during optimization based on performance indicators.\n        \"\"\"\n        adaptations = {}\n\n        # Analyze current performance\n        performance_metrics = self._analyze_performance(pso_state, iteration)\n\n        # Inertia weight adaptation\n        if self._should_adapt_inertia(performance_metrics):\n            new_w = self._compute_adaptive_inertia(performance_metrics, iteration)\n            adaptations['w'] = new_w\n\n        # Diversity maintenance\n        if self._should_restart_particles(performance_metrics):\n            restart_indices = self._select_restart_particles(pso_state)\n            adaptations['restart_particles'] = restart_indices\n\n        # Bounds adaptation (for Issue #2 compliance)\n        if self._should_adapt_bounds(performance_metrics):\n            adapted_bounds = self._adapt_bounds_for_performance(performance_metrics)\n            adaptations['bounds'] = adapted_bounds\n\n        return adaptations\n\n    def _compute_adaptive_inertia(self, performance: dict, iteration: int) -> float:\n        \"\"\"\n        Compute adaptive inertia weight based on convergence state.\n        \"\"\"\n        base_w = self.config['algorithm_params']['w']\n        max_iters = self.config['algorithm_params']['iters']\n\n        # Linear decrease with performance-based adjustment\n        linear_w = 0.9 - 0.5 * (iteration / max_iters)\n\n        # Performance-based adjustment\n        if performance['convergence_rate'] < 0.05:  # Slow convergence\n            adjustment = -0.1  # Reduce inertia for more exploitation\n        elif performance['diversity'] < 1e-8:  # Low diversity\n            adjustment = +0.15  # Increase inertia for more exploration\n        else:\n            adjustment = 0.0\n\n        adaptive_w = np.clip(linear_w + adjustment, 0.1, 0.95)\n        return adaptive_w\n\n    def _adapt_bounds_for_performance(self, performance: dict) -> dict:\n        \"\"\"\n        Adapt bounds based on optimization performance and Issue #2 compliance.\n        \"\"\"\n        current_bounds = self.config['bounds']\n        adapted_bounds = current_bounds.copy()\n\n        # Issue #2 specific adaptation for STA-SMC\n        if 'sta_smc' in current_bounds and performance['controller_type'] == 'sta_smc':\n            if performance.get('overshoot', 0) > 0.05:  # >5% overshoot detected\n                # Further restrict lambda bounds\n                sta_bounds = adapted_bounds['sta_smc']\n                if 'max' in sta_bounds and len(sta_bounds['max']) >= 6:\n                    # Progressively tighten bounds\n                    reduction_factor = 0.8\n                    sta_bounds['max'][4] *= reduction_factor  # lambda1\n                    sta_bounds['max'][5] *= reduction_factor  # lambda2\n\n        return adapted_bounds\n\n    def generate_tuning_recommendations(self) -> dict:\n        \"\"\"\n        Generate parameter tuning recommendations based on historical performance.\n        \"\"\"\n        if len(self.performance_history) < 10:\n            return {'status': 'insufficient_data'}\n\n        # Analyze performance trends\n        convergence_rates = [p['convergence_rate'] for p in self.performance_history[-10:]]\n        final_costs = [p['final_cost'] for p in self.performance_history[-10:]]\n        optimization_times = [p['optimization_time'] for p in self.performance_history[-10:]]\n\n        recommendations = {\n            'parameter_adjustments': [],\n            'configuration_changes': [],\n            'performance_outlook': 'stable'\n        }\n\n        # Convergence analysis\n        avg_convergence = np.mean(convergence_rates)\n        if avg_convergence < 0.1:\n            recommendations['parameter_adjustments'].append({\n                'parameter': 'n_particles',\n                'current': self.config['algorithm_params']['n_particles'],\n                'recommended': min(50, self.config['algorithm_params']['n_particles'] + 5),\n                'reason': 'Slow convergence - increase swarm size'\n            })\n\n        # Cost analysis\n        cost_variance = np.var(final_costs)\n        if cost_variance > 0.01:\n            recommendations['parameter_adjustments'].append({\n                'parameter': 'early_stopping.tolerance',\n                'current': self.config.get('enhanced_features', {}).get('early_stopping', {}).get('tolerance', 1e-6),\n                'recommended': 1e-7,\n                'reason': 'High cost variance - tighten convergence tolerance'\n            })\n\n        # Performance outlook\n        if avg_convergence > 0.2 and cost_variance < 0.005:\n            recommendations['performance_outlook'] = 'excellent'\n        elif avg_convergence < 0.05 or cost_variance > 0.02:\n            recommendations['performance_outlook'] = 'needs_improvement'\n\n        return recommendations",
    "lines": 125,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a3586b3a"
  },
  {
    "id": "pso_configuration_schema_documentation_8_ac88892e",
    "file": "docs\\pso_configuration_schema_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationErrorHandler:\n    \"\"\"\n    Comprehensive error handling and diagnostic system for PSO configuration.\n    \"\"\"\n\n    ERROR_CATEGORIES = {\n        'SYNTAX': {\n            'severity': 'CRITICAL',\n            'auto_fixable': False,\n            'description': 'YAML syntax or structure errors'\n        },\n        'TYPE': {\n            'severity': 'CRITICAL',\n            'auto_fixable': True,\n            'description': 'Data type mismatches'\n        },\n        'BOUNDS': {\n            'severity': 'HIGH',\n            'auto_fixable': True,\n            'description': 'Parameter bounds violations'\n        },\n        'MATHEMATICAL': {\n            'severity': 'HIGH',\n            'auto_fixable': False,\n            'description': 'Mathematical consistency violations'\n        },\n        'PERFORMANCE': {\n            'severity': 'MEDIUM',\n            'auto_fixable': True,\n            'description': 'Suboptimal performance configuration'\n        },\n        'COMPATIBILITY': {\n            'severity': 'MEDIUM',\n            'auto_fixable': True,\n            'description': 'Controller compatibility issues'\n        }\n    }\n\n    def diagnose_configuration_errors(self, config: dict,\n                                    controller_type: str = None) -> dict:\n        \"\"\"\n        Comprehensive configuration error diagnosis with auto-fix suggestions.\n        \"\"\"\n        diagnosis = {\n            'errors': [],\n            'warnings': [],\n            'auto_fixes': [],\n            'manual_actions': [],\n            'overall_status': 'UNKNOWN'\n        }\n\n        # Run diagnostic checks\n        for category, info in self.ERROR_CATEGORIES.items():\n            category_errors = self._check_category(category, config, controller_type)\n\n            for error in category_errors:\n                error['category'] = category\n                error['severity'] = info['severity']\n                error['auto_fixable'] = info['auto_fixable']\n\n                if error['severity'] == 'CRITICAL':\n                    diagnosis['errors'].append(error)\n                else:\n                    diagnosis['warnings'].append(error)\n\n                # Generate fix suggestions\n                if error['auto_fixable']:\n                    fix = self._generate_auto_fix(error, config)\n                    if fix:\n                        diagnosis['auto_fixes'].append(fix)\n                else:\n                    manual_action = self._generate_manual_action(error)\n                    if manual_action:\n                        diagnosis['manual_actions'].append(manual_action)\n\n        # Determine overall status\n        if diagnosis['errors']:\n            diagnosis['overall_status'] = 'CRITICAL'\n        elif len(diagnosis['warnings']) > 5:\n            diagnosis['overall_status'] = 'NEEDS_ATTENTION'\n        elif diagnosis['warnings']:\n            diagnosis['overall_status'] = 'MINOR_ISSUES'\n        else:\n            diagnosis['overall_status'] = 'HEALTHY'\n\n        return diagnosis\n\n    def _check_category(self, category: str, config: dict, controller_type: str) -> list:\n        \"\"\"\n        Check specific error category and return found issues.\n        \"\"\"\n        errors = []\n\n        if category == 'MATHEMATICAL':\n            # PSO convergence check\n            if 'algorithm_params' in config:\n                params = config['algorithm_params']\n                if 'c1' in params and 'c2' in params:\n                    phi = params['c1'] + params['c2']\n                    if phi <= 4.0:\n                        errors.append({\n                            'code': 'PSO_CONVERGENCE_RISK',\n                            'message': f'PSO may not converge: \u03c6 = c\u2081 + c\u2082 = {phi:.3f} \u2264 4.0',\n                            'location': 'algorithm_params.c1, algorithm_params.c2',\n                            'impact': 'Optimization may fail to converge'\n                        })\n\n        elif category == 'BOUNDS' and controller_type:\n            # Issue #2 specific checks for STA-SMC\n            if controller_type == 'sta_smc' and 'bounds' in config:\n                bounds = config['bounds']\n                if 'sta_smc' in bounds and 'max' in bounds['sta_smc']:\n                    max_bounds = bounds['sta_smc']['max']\n                    if len(max_bounds) >= 6:\n                        lambda1_max, lambda2_max = max_bounds[4], max_bounds[5]\n                        if lambda1_max > 10.0 or lambda2_max > 10.0:\n                            errors.append({\n                                'code': 'ISSUE2_BOUNDS_VIOLATION',\n                                'message': f'STA-SMC lambda bounds may cause overshoot: \u03bb\u2081_max={lambda1_max}, \u03bb\u2082_max={lambda2_max}',\n                                'location': 'bounds.sta_smc.max[4:6]',\n                                'impact': 'May cause >5% overshoot (Issue #2 regression)'\n                            })\n\n        elif category == 'PERFORMANCE':\n            # Suboptimal parameter detection\n            if 'algorithm_params' in config:\n                params = config['algorithm_params']\n                if 'n_particles' in params:\n                    n_particles = params['n_particles']\n                    if n_particles < 10 or n_particles > 50:\n                        errors.append({\n                            'code': 'SUBOPTIMAL_SWARM_SIZE',\n                            'message': f'Swarm size {n_particles} outside optimal range [10, 50]',\n                            'location': 'algorithm_params.n_particles',\n                            'impact': 'Suboptimal convergence speed or quality'\n                        })\n\n        return errors\n\n    def _generate_auto_fix(self, error: dict, config: dict) -> dict:\n        \"\"\"\n        Generate automatic fix for fixable errors.\n        \"\"\"\n        if error['code'] == 'PSO_CONVERGENCE_RISK':\n            return {\n                'error_code': error['code'],\n                'fix_type': 'parameter_adjustment',\n                'action': 'Increase c\u2081 and c\u2082 to ensure \u03c6 > 4',\n                'changes': {\n                    'algorithm_params.c1': 2.1,\n                    'algorithm_params.c2': 2.1\n                },\n                'justification': 'Ensures PSO convergence with \u03c6 = 4.2 > 4'\n            }\n\n        elif error['code'] == 'ISSUE2_BOUNDS_VIOLATION':\n            return {\n                'error_code': error['code'],\n                'fix_type': 'bounds_correction',\n                'action': 'Apply Issue #2 lambda bounds corrections',\n                'changes': {\n                    'bounds.sta_smc.max[4]': 10.0,  # lambda1\n                    'bounds.sta_smc.max[5]': 10.0   # lambda2\n                },\n                'justification': 'Prevents overshoot regression from Issue #2'\n            }\n\n        elif error['code'] == 'SUBOPTIMAL_SWARM_SIZE':\n            current_size = config['algorithm_params']['n_particles']\n            optimal_size = np.clip(current_size, 15, 25)  # Clamp to optimal range\n            return {\n                'error_code': error['code'],\n                'fix_type': 'parameter_optimization',\n                'action': f'Adjust swarm size to optimal range',\n                'changes': {\n                    'algorithm_params.n_particles': optimal_size\n                },\n                'justification': f'Optimizes convergence for {optimal_size} particles'\n            }\n\n        return None\n\n    def apply_auto_fixes(self, config: dict, fixes: list) -> tuple:\n        \"\"\"\n        Apply automatic fixes to configuration.\n\n        Returns:\n        tuple: (fixed_config, applied_fixes, failed_fixes)\n        \"\"\"\n        fixed_config = config.copy()\n        applied_fixes = []\n        failed_fixes = []\n\n        for fix in fixes:\n            try:\n                for path, new_value in fix['changes'].items():\n                    self._set_nested_value(fixed_config, path, new_value)\n                applied_fixes.append(fix)\n            except Exception as e:\n                fix['error'] = str(e)\n                failed_fixes.append(fix)\n\n        return fixed_config, applied_fixes, failed_fixes\n\n    def _set_nested_value(self, config: dict, path: str, value: any) -> None:\n        \"\"\"\n        Set nested configuration value using dot notation path.\n        \"\"\"\n        keys = path.split('.')\n        current = config\n\n        for key in keys[:-1]:\n            if '[' in key and ']' in key:\n                # Handle array indexing\n                array_key, index_str = key.split('[')\n                index = int(index_str.rstrip(']'))\n                if array_key not in current:\n                    current[array_key] = []\n                current = current[array_key]\n\n                # Extend array if necessary\n                while len(current) <= index:\n                    current.append(None)\n                current = current[index]\n            else:\n                if key not in current:\n                    current[key] = {}\n                current = current[key]\n\n        # Set the final value\n        final_key = keys[-1]\n        if '[' in final_key and ']' in final_key:\n            array_key, index_str = final_key.split('[')\n            index = int(index_str.rstrip(']'))\n            if array_key not in current:\n                current[array_key] = []\n            while len(current[array_key]) <= index:\n                current[array_key].append(None)\n            current[array_key][index] = value\n        else:\n            current[final_key] = value",
    "lines": 244,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac88892e"
  },
  {
    "id": "PSO_Documentation_Validation_Report_1_7eacae69",
    "file": "docs\\PSO_Documentation_Validation_Report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nParticle Swarm Optimisation (PSO) tuner for sliding-mode controllers.\n\nThis module defines the high-throughput, vectorised `PSOTuner` class that wraps\na particle swarm optimisation algorithm around the vectorised simulation of a\ndouble inverted pendulum (DIP) system.  It incorporates improvements from\ndesign review steps, including decoupling of global state, explicit random\nnumber generation, dynamic instability penalties and configurable cost\nnormalisation.  The implementation follows robust control theory practices\nand is fully documented with theoretical backing.\n\nReferences used throughout this module are provided in the accompanying\ndesign-review report.\n\"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7eacae69"
  },
  {
    "id": "PSO_Documentation_Validation_Report_2_a85b24c2",
    "file": "docs\\PSO_Documentation_Validation_Report.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef __init__(\n    self,\n    controller_factory: Callable[[np.ndarray], Any],\n    config: Union[ConfigSchema, str, Path],\n    seed: Optional[int] = None,\n    rng: Optional[np.random.Generator] = None,\n    *,\n    instability_penalty_factor: float = 100.0,\n) -> None:\n    \"\"\"Initialise the PSOTuner.\n\n    Parameters\n    ----------\n    controller_factory : Callable[[np.ndarray], Any]\n        A function returning a controller instance given a gain vector.\n    config : ConfigSchema or path-like\n        A validated configuration object or path to the YAML file.\n    seed : int or None, optional\n        Seed to initialise the local RNG.  When ``None``, the seed from\n        the configuration (``global_seed``) is used if present; otherwise\n        the RNG is unseeded.\n    rng : numpy.random.Generator or None, optional\n        External PRNG.  If provided, this generator is used directly and\n        ``seed`` is ignored.\n    instability_penalty_factor : float, optional\n        Scale factor used to compute the penalty for unstable simulations.\n        The penalty is computed as\n        ``instability_penalty_factor * (norm_ise + norm_u + norm_du + norm_sigma)``.\n        Larger values penalise instability more heavily.  Default is 100.\n    \"\"\"",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a85b24c2"
  },
  {
    "id": "PSO_Documentation_Validation_Report_3_22410583",
    "file": "docs\\PSO_Documentation_Validation_Report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _compute_cost_from_traj(\n    self, t: np.ndarray, x_b: np.ndarray, u_b: np.ndarray, sigma_b: np.ndarray\n) -> np.ndarray:\n    \"\"\"Compute the cost per particle from simulated trajectories.\n\n    The cost combines state error, control effort, control slew and a\n    sliding-mode stability term.  State error integrates the squared\n    deviation of all state components over the horizon.  Control terms\n    integrate squared commands and their rates.  A graded instability\n    penalty is applied when trajectories fail early.\n    \"\"\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "22410583"
  },
  {
    "id": "pso_factory_integration_patterns_1_a96aacf2",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 1,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\nimport numpy as np\n\ndef simple_fitness_function(gains_array: np.ndarray) -> float:\n    \"\"\"Simple PSO fitness evaluation using direct controller creation.\"\"\"\n\n    # Create controller directly from gains\n    controller = create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains=gains_array,\n        max_force=150.0,\n        dt=0.001\n    )\n\n    # Evaluate controller performance\n    performance_metrics = evaluate_controller_performance(controller)\n\n    # Return fitness value (minimize)\n    return performance_metrics['total_cost']\n\n# PSO optimization setup\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\n\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\ntuner = PSOTuner(\n    controller_factory=simple_fitness_function,\n    config=config\n)\nbest_gains, best_fitness = tuner.optimize()",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a96aacf2"
  },
  {
    "id": "pso_factory_integration_patterns_2_518d0dad",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 2,
    "code": "from src.controllers.factory import create_pso_controller_factory, SMCType\n\ndef optimized_pso_workflow():\n    \"\"\"High-performance PSO workflow using factory function pattern.\"\"\"\n\n    # Create factory function once (expensive operation)\n    controller_factory = create_pso_controller_factory(\n        SMCType.CLASSICAL,\n        plant_config=config.physics,\n        max_force=150.0,\n        dt=0.001\n    )\n\n    # Factory function has required PSO attributes\n    assert hasattr(controller_factory, 'n_gains')         # Number of gains required\n    assert hasattr(controller_factory, 'controller_type') # Controller type string\n    assert hasattr(controller_factory, 'max_force')       # Force saturation limit\n\n    # Define fitness function using pre-created factory\n    def fitness_function(gains_array: np.ndarray) -> float:\n        \"\"\"Fast fitness evaluation using factory function.\"\"\"\n\n        # Create controller (fast operation)\n        controller = controller_factory(gains_array)\n\n        # Evaluate performance\n        return evaluate_controller_performance(controller)['total_cost']\n\n    # PSO optimization with optimized factory\n    tuner = PSOTuner(\n        controller_factory=fitness_function,\n        config=config\n    )\n\n    return tuner.optimize()",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "518d0dad"
  },
  {
    "id": "pso_factory_integration_patterns_3_39ea5dee",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 3,
    "code": "from src.controllers.factory import create_all_smc_controllers\n\ndef multi_controller_optimization():\n    \"\"\"Optimize gains for multiple controller types simultaneously.\"\"\"\n\n    # Define gain sets for all controller types\n    gains_dict = {\n        'classical': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'adaptive': [25.0, 18.0, 15.0, 10.0, 4.0],\n        'sta': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n        'hybrid': [18.0, 12.0, 10.0, 8.0]\n    }\n\n    # Create all controllers efficiently\n    controllers = create_all_smc_controllers(\n        gains_dict,\n        max_force=150.0,\n        dt=0.001\n    )\n\n    # Evaluate all controllers\n    performance_results = {}\n    for controller_type, controller in controllers.items():\n        performance_results[controller_type] = evaluate_controller_performance(controller)\n\n    return performance_results\n\ndef parallel_multi_objective_pso():\n    \"\"\"Multi-objective PSO across different controller types.\"\"\"\n\n    controller_types = [SMCType.CLASSICAL, SMCType.ADAPTIVE, SMCType.SUPER_TWISTING]\n\n    # Create factory functions for each type\n    factories = {\n        ctrl_type: create_pso_controller_factory(ctrl_type)\n        for ctrl_type in controller_types\n    }\n\n    def multi_objective_fitness(gains_dict: Dict[str, np.ndarray]) -> List[float]:\n        \"\"\"Multi-objective fitness evaluation.\"\"\"\n        objectives = []\n\n        for ctrl_type, gains in gains_dict.items():\n            controller = factories[ctrl_type](gains)\n            performance = evaluate_controller_performance(controller)\n            objectives.append(performance['total_cost'])\n\n        return objectives  # Pareto optimization\n\n    # Run multi-objective PSO\n    return run_multi_objective_pso(multi_objective_fitness)",
    "lines": 51,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "39ea5dee"
  },
  {
    "id": "pso_factory_integration_patterns_4_6916c7e1",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef basic_pso_optimization(controller_type: SMCType) -> Tuple[np.ndarray, float]:\n    \"\"\"Standard PSO optimization workflow for SMC controllers.\"\"\"\n\n    # Step 1: Get gain bounds based on control theory\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(controller_type)\n\n    # Step 2: Create optimized factory function\n    controller_factory = create_pso_controller_factory(\n        controller_type,\n        plant_config=load_config(\"config.yaml\").physics\n    )\n\n    # Step 3: Define fitness function with validation\n    def fitness_function(gains: np.ndarray) -> float:\n        \"\"\"PSO fitness function with robust error handling.\"\"\"\n\n        # Pre-validate gains\n        if not validate_smc_gains(controller_type, gains):\n            return float('inf')  # Invalid gains get worst fitness\n\n        try:\n            # Create controller\n            controller = controller_factory(gains)\n\n            # Evaluate performance\n            metrics = evaluate_controller_performance(controller)\n\n            # Combine multiple objectives\n            fitness = (\n                0.4 * metrics['control_effort'] +\n                0.3 * metrics['tracking_error'] +\n                0.2 * metrics['settling_time'] +\n                0.1 * metrics['overshoot_penalty']\n            )\n\n            return fitness\n\n        except Exception as e:\n            logger.warning(f\"Controller evaluation failed: {e}\")\n            return float('inf')\n\n    # Step 4: Configure and run PSO\n    pso_config = {\n        'n_particles': 30,\n        'max_iter': 100,\n        'bounds': (lower_bounds, upper_bounds),\n        'w': 0.9,       # Inertia weight\n        'c1': 2.0,      # Cognitive coefficient\n        'c2': 2.0       # Social coefficient\n    }\n\n    tuner = PSOTuner(\n        controller_factory=fitness_function,\n        config=config,\n        **pso_config\n    )\n\n    # Step 5: Run optimization\n    best_gains, best_fitness = tuner.optimize()\n\n    # Step 6: Validate results\n    final_controller = controller_factory(best_gains)\n    final_metrics = evaluate_controller_performance(final_controller)\n\n    logger.info(f\"Optimization complete:\")\n    logger.info(f\"Best gains: {best_gains}\")\n    logger.info(f\"Best fitness: {best_fitness}\")\n    logger.info(f\"Final metrics: {final_metrics}\")\n\n    return best_gains, best_fitness",
    "lines": 73,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6916c7e1"
  },
  {
    "id": "pso_factory_integration_patterns_5_f64aae8d",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef constrained_pso_optimization(controller_type: SMCType) -> Tuple[np.ndarray, float]:\n    \"\"\"Advanced PSO with stability constraints and adaptive bounds.\"\"\"\n\n    # Get base bounds\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(controller_type)\n\n    # Create constraint functions based on control theory\n    def stability_constraint(gains: np.ndarray) -> bool:\n        \"\"\"Verify closed-loop stability constraints.\"\"\"\n\n        if controller_type == SMCType.CLASSICAL:\n            k1, k2, lam1, lam2, K, kd = gains\n\n            # Sliding surface stability (Hurwitz condition)\n            if lam1 <= 0 or lam2 <= 0:\n                return False\n\n            # Reaching condition constraint\n            if K <= 0:\n                return False\n\n            # Practical stability margins\n            if lam1/k1 > 20 or lam2/k2 > 20:  # Avoid overly aggressive surfaces\n                return False\n\n            # Chattering prevention\n            if K > 100:  # Excessive switching gain\n                return False\n\n        elif controller_type == SMCType.ADAPTIVE:\n            k1, k2, lam1, lam2, gamma = gains\n\n            # Adaptation rate constraints\n            if gamma <= 0 or gamma > 20:\n                return False\n\n            # Surface stability\n            if lam1 <= 0 or lam2 <= 0:\n                return False\n\n        return True\n\n    # Create factory with constraint checking\n    base_factory = create_pso_controller_factory(controller_type)\n\n    def constrained_factory(gains: np.ndarray):\n        \"\"\"Factory with built-in constraint checking.\"\"\"\n\n        # Check stability constraints\n        if not stability_constraint(gains):\n            raise ValueError(\"Stability constraints violated\")\n\n        return base_factory(gains)\n\n    # Enhanced fitness function\n    def constrained_fitness_function(gains: np.ndarray) -> float:\n        \"\"\"Fitness function with constraint penalties.\"\"\"\n\n        try:\n            # Check basic validity\n            if not validate_smc_gains(controller_type, gains):\n                return 1e6\n\n            # Check stability constraints\n            if not stability_constraint(gains):\n                return 1e6\n\n            # Create and evaluate controller\n            controller = constrained_factory(gains)\n            metrics = evaluate_controller_performance(controller)\n\n            # Multi-objective fitness with penalties\n            base_fitness = (\n                0.4 * metrics['ise'] +                    # Control performance\n                0.3 * metrics['settling_time'] +          # Speed\n                0.2 * metrics['control_effort'] +         # Efficiency\n                0.1 * metrics['overshoot']                # Stability margin\n            )\n\n            # Add constraint penalties\n            penalty = 0.0\n\n            # Chattering penalty\n            if 'chattering_index' in metrics and metrics['chattering_index'] > 0.1:\n                penalty += 100 * metrics['chattering_index']\n\n            # Control saturation penalty\n            if 'saturation_ratio' in metrics and metrics['saturation_ratio'] > 0.05:\n                penalty += 50 * metrics['saturation_ratio']\n\n            return base_fitness + penalty\n\n        except Exception as e:\n            return 1e6  # Severe penalty for failed evaluations\n\n    # Adaptive PSO configuration\n    adaptive_config = {\n        'n_particles': 50,\n        'max_iter': 150,\n        'bounds': (lower_bounds, upper_bounds),\n        'w': 0.9,\n        'c1': 2.0,\n        'c2': 2.0,\n        'early_stopping': True,\n        'patience': 20,\n        'min_improvement': 1e-6\n    }\n\n    # Run constrained optimization\n    tuner = PSOTuner(\n        controller_factory=constrained_fitness_function,\n        config=config,\n        **adaptive_config\n    )\n\n    return tuner.optimize()",
    "lines": 119,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f64aae8d"
  },
  {
    "id": "pso_factory_integration_patterns_6_e2a57e15",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_stage_pso_optimization(controller_type: SMCType) -> Tuple[np.ndarray, float]:\n    \"\"\"Multi-stage PSO with progressive refinement.\"\"\"\n\n    # Stage 1: Coarse optimization with wide bounds\n    logger.info(\"Stage 1: Coarse optimization\")\n\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(controller_type)\n\n    # Expand bounds for exploration\n    exploration_lower = [0.5 * lb for lb in lower_bounds]\n    exploration_upper = [2.0 * ub for ub in upper_bounds]\n\n    coarse_config = {\n        'n_particles': 40,\n        'max_iter': 50,\n        'bounds': (exploration_lower, exploration_upper),\n        'w': 0.9,  # High inertia for exploration\n        'c1': 1.5,\n        'c2': 1.5\n    }\n\n    coarse_factory = create_pso_controller_factory(controller_type)\n    coarse_tuner = PSOTuner(\n        controller_factory=lambda gains: evaluate_basic_performance(coarse_factory(gains)),\n        config=config,\n        **coarse_config\n    )\n\n    stage1_gains, stage1_fitness = coarse_tuner.optimize()\n\n    # Stage 2: Fine optimization around best solution\n    logger.info(\"Stage 2: Fine optimization\")\n\n    # Narrow bounds around stage 1 result\n    bound_margin = 0.2  # 20% margin\n    fine_lower = [max(lb, (1 - bound_margin) * g) for lb, g in zip(lower_bounds, stage1_gains)]\n    fine_upper = [min(ub, (1 + bound_margin) * g) for ub, g in zip(upper_bounds, stage1_gains)]\n\n    fine_config = {\n        'n_particles': 30,\n        'max_iter': 100,\n        'bounds': (fine_lower, fine_upper),\n        'w': 0.4,  # Low inertia for exploitation\n        'c1': 2.0,\n        'c2': 2.0\n    }\n\n    fine_factory = create_pso_controller_factory(controller_type)\n    fine_tuner = PSOTuner(\n        controller_factory=lambda gains: evaluate_detailed_performance(fine_factory(gains)),\n        config=config,\n        **fine_config\n    )\n\n    stage2_gains, stage2_fitness = fine_tuner.optimize()\n\n    # Stage 3: Validation and robustness testing\n    logger.info(\"Stage 3: Robustness validation\")\n\n    final_controller = fine_factory(stage2_gains)\n    robustness_metrics = evaluate_robustness(final_controller)\n\n    logger.info(f\"Multi-stage optimization complete:\")\n    logger.info(f\"Stage 1 (coarse): {stage1_fitness}\")\n    logger.info(f\"Stage 2 (fine): {stage2_fitness}\")\n    logger.info(f\"Final gains: {stage2_gains}\")\n    logger.info(f\"Robustness score: {robustness_metrics['robustness_index']}\")\n\n    return stage2_gains, stage2_fitness",
    "lines": 72,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2a57e15"
  },
  {
    "id": "pso_factory_integration_patterns_7_17034965",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 7,
    "code": "def memory_efficient_pso():\n    \"\"\"Memory-optimized PSO for large-scale optimization.\"\"\"\n\n    # Pattern 1: Reuse controller instances\n    controller_pool = {}\n\n    def pooled_factory(gains: np.ndarray, controller_type: SMCType):\n        \"\"\"Factory with controller pooling.\"\"\"\n        gains_key = tuple(gains)\n\n        if gains_key not in controller_pool:\n            # Create new controller only if not in pool\n            controller_pool[gains_key] = create_smc_for_pso(controller_type, gains)\n\n        return controller_pool[gains_key]\n\n    # Pattern 2: Batch evaluation for parallel PSO\n    def batch_fitness_evaluation(gains_batch: List[np.ndarray]) -> List[float]:\n        \"\"\"Evaluate multiple gain sets in batch.\"\"\"\n\n        # Create controllers in batch\n        controllers = [\n            create_smc_for_pso(SMCType.CLASSICAL, gains)\n            for gains in gains_batch\n        ]\n\n        # Parallel evaluation\n        from concurrent.futures import ProcessPoolExecutor\n\n        with ProcessPoolExecutor(max_workers=4) as executor:\n            fitness_values = list(executor.map(\n                evaluate_controller_performance,\n                controllers\n            ))\n\n        return [f['total_cost'] for f in fitness_values]\n\n    # Pattern 3: Incremental evaluation\n    class IncrementalEvaluator:\n        \"\"\"Incremental controller evaluation with caching.\"\"\"\n\n        def __init__(self, controller_type: SMCType):\n            self.controller_type = controller_type\n            self.evaluation_cache = {}\n            self.factory = create_pso_controller_factory(controller_type)\n\n        def evaluate(self, gains: np.ndarray) -> float:\n            \"\"\"Evaluate with caching.\"\"\"\n            gains_key = tuple(np.round(gains, 6))  # Round for cache efficiency\n\n            if gains_key not in self.evaluation_cache:\n                controller = self.factory(gains)\n                performance = evaluate_controller_performance(controller)\n                self.evaluation_cache[gains_key] = performance['total_cost']\n\n            return self.evaluation_cache[gains_key]\n\n        def clear_cache(self):\n            \"\"\"Clear evaluation cache to manage memory.\"\"\"\n            self.evaluation_cache.clear()",
    "lines": 60,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17034965"
  },
  {
    "id": "pso_factory_integration_patterns_8_cae87d7c",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 8,
    "code": "def high_performance_pso_integration():\n    \"\"\"High-performance PSO integration with optimizations.\"\"\"\n\n    # Pre-compile Numba functions for controller evaluation\n    from numba import jit\n\n    @jit(nopython=True)\n    def fast_control_computation(state, gains, max_force):\n        \"\"\"Numba-compiled control computation.\"\"\"\n        # Simplified controller logic for speed\n        k1, k2, lam1, lam2, K, kd = gains\n\n        # Sliding surface\n        s = lam1 * state[0] + lam2 * state[1] + state[3] + state[4]\n\n        # Control law\n        u = -K * np.tanh(s / 0.01)\n\n        # Saturation\n        return np.clip(u, -max_force, max_force)\n\n    # Vectorized fitness evaluation\n    @jit(nopython=True)\n    def vectorized_fitness_evaluation(gains_matrix, states_batch):\n        \"\"\"Vectorized evaluation for multiple gain sets.\"\"\"\n        n_particles, n_gains = gains_matrix.shape\n        n_states, state_dim = states_batch.shape\n\n        fitness_values = np.zeros(n_particles)\n\n        for i in range(n_particles):\n            gains = gains_matrix[i]\n            total_cost = 0.0\n\n            for j in range(n_states):\n                state = states_batch[j]\n                control = fast_control_computation(state, gains, 150.0)\n                total_cost += np.sum(state**2) + 0.1 * control**2\n\n            fitness_values[i] = total_cost / n_states\n\n        return fitness_values\n\n    # High-performance PSO workflow\n    def optimized_pso_workflow():\n        \"\"\"Optimized PSO workflow using vectorized operations.\"\"\"\n\n        # Pre-generate test states for evaluation\n        test_states = generate_test_state_batch(1000)\n\n        # Vectorized fitness function\n        def fitness_function(gains_matrix: np.ndarray) -> np.ndarray:\n            \"\"\"Vectorized fitness evaluation.\"\"\"\n            if gains_matrix.ndim == 1:\n                gains_matrix = gains_matrix.reshape(1, -1)\n\n            return vectorized_fitness_evaluation(gains_matrix, test_states)\n\n        # Use vectorized PSO\n        from src.optimization.algorithms.vectorized_pso import VectorizedPSO\n\n        optimizer = VectorizedPSO(\n            fitness_function=fitness_function,\n            n_particles=50,\n            n_dimensions=6,\n            bounds=get_gain_bounds_for_pso(SMCType.CLASSICAL),\n            max_iterations=100\n        )\n\n        return optimizer.optimize()",
    "lines": 70,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cae87d7c"
  },
  {
    "id": "pso_factory_integration_patterns_9_3219552b",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_pso_optimized_controller(gains: np.ndarray, controller_type: SMCType) -> Dict[str, Any]:\n    \"\"\"Comprehensive validation of PSO-optimized controller.\"\"\"\n\n    validation_results = {}\n\n    # Create optimized controller\n    controller = create_smc_for_pso(controller_type, gains)\n\n    # 1. Stability Analysis\n    validation_results['stability'] = validate_lyapunov_stability(controller)\n\n    # 2. Performance Metrics\n    validation_results['performance'] = {\n        'ise': compute_integral_squared_error(controller),\n        'itae': compute_integral_time_absolute_error(controller),\n        'settling_time': compute_settling_time(controller),\n        'overshoot': compute_overshoot(controller)\n    }\n\n    # 3. Robustness Analysis\n    validation_results['robustness'] = {\n        'parameter_sensitivity': analyze_parameter_sensitivity(controller),\n        'disturbance_rejection': test_disturbance_rejection(controller),\n        'noise_tolerance': evaluate_noise_tolerance(controller)\n    }\n\n    # 4. Chattering Analysis\n    validation_results['chattering'] = {\n        'chattering_index': compute_chattering_index(controller),\n        'high_frequency_content': analyze_frequency_content(controller),\n        'actuator_stress': evaluate_actuator_stress(controller)\n    }\n\n    # 5. Control Theory Properties\n    if controller_type == SMCType.CLASSICAL:\n        validation_results['theory'] = validate_classical_smc_properties(gains)\n    elif controller_type == SMCType.ADAPTIVE:\n        validation_results['theory'] = validate_adaptive_smc_properties(gains)\n    elif controller_type == SMCType.SUPER_TWISTING:\n        validation_results['theory'] = validate_sta_smc_properties(gains)\n\n    return validation_results\n\ndef validate_classical_smc_properties(gains: np.ndarray) -> Dict[str, bool]:\n    \"\"\"Validate classical SMC theoretical properties.\"\"\"\n    k1, k2, lam1, lam2, K, kd = gains\n\n    return {\n        'surface_stability': lam1 > 0 and lam2 > 0,  # Hurwitz stability\n        'reaching_condition': K > 0,                  # Reaching condition\n        'finite_time_convergence': True,              # Guaranteed by SMC theory\n        'robustness_margin': K > 2 * max(k1, k2),    # Sufficient robustness\n        'chattering_bound': K < 100,                  # Practical chattering limit\n        'damping_sufficient': kd >= 0                 # Non-negative damping\n    }\n\ndef validate_adaptive_smc_properties(gains: np.ndarray) -> Dict[str, bool]:\n    \"\"\"Validate adaptive SMC theoretical properties.\"\"\"\n    k1, k2, lam1, lam2, gamma = gains\n\n    return {\n        'surface_stability': lam1 > 0 and lam2 > 0,\n        'adaptation_convergence': gamma > 0,\n        'adaptation_rate_bound': 0.1 <= gamma <= 20,\n        'finite_time_reaching': True,\n        'parameter_convergence': gamma > 0.5  # Sufficient for convergence\n    }",
    "lines": 70,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3219552b"
  },
  {
    "id": "pso_factory_integration_patterns_10_84c99852",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 10,
    "code": "def statistical_validation_of_pso_results(controller_type: SMCType,\n                                        optimized_gains: np.ndarray,\n                                        n_trials: int = 50) -> Dict[str, Any]:\n    \"\"\"Statistical validation of PSO optimization results.\"\"\"\n\n    # Multiple independent evaluations\n    performance_samples = []\n\n    for trial in range(n_trials):\n        # Add small random perturbations to test robustness\n        perturbed_gains = optimized_gains * (1 + 0.01 * np.random.randn(len(optimized_gains)))\n\n        # Create controller with perturbed gains\n        controller = create_smc_for_pso(controller_type, perturbed_gains)\n\n        # Evaluate performance\n        metrics = evaluate_controller_performance(controller)\n        performance_samples.append(metrics['total_cost'])\n\n    # Statistical analysis\n    performance_array = np.array(performance_samples)\n\n    validation_stats = {\n        'mean_performance': np.mean(performance_array),\n        'std_performance': np.std(performance_array),\n        'coefficient_variation': np.std(performance_array) / np.mean(performance_array),\n        'confidence_interval_95': np.percentile(performance_array, [2.5, 97.5]),\n        'worst_case_performance': np.max(performance_array),\n        'best_case_performance': np.min(performance_array),\n        'robustness_score': 1.0 / (1.0 + np.std(performance_array))\n    }\n\n    # Statistical significance tests\n    from scipy import stats\n\n    # Test for normality\n    _, normality_p_value = stats.shapiro(performance_array)\n    validation_stats['performance_distribution_normal'] = normality_p_value > 0.05\n\n    # Compare with default gains\n    default_gains = get_default_gains(controller_type.value)\n    default_controller = create_smc_for_pso(controller_type, default_gains)\n    default_performance = evaluate_controller_performance(default_controller)['total_cost']\n\n    # Statistical improvement test\n    improvement_ratio = default_performance / np.mean(performance_array)\n    validation_stats['improvement_ratio'] = improvement_ratio\n    validation_stats['significant_improvement'] = improvement_ratio > 1.1  # 10% improvement threshold\n\n    return validation_stats",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84c99852"
  },
  {
    "id": "pso_factory_integration_patterns_11_8b3eb923",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 11,
    "code": "def multi_objective_pso_optimization(controller_type: SMCType) -> Dict[str, Any]:\n    \"\"\"Multi-objective PSO optimization for SMC controllers.\"\"\"\n\n    # Define multiple objectives\n    objectives = {\n        'tracking_performance': lambda controller: evaluate_tracking_error(controller),\n        'control_efficiency': lambda controller: evaluate_control_effort(controller),\n        'robustness': lambda controller: evaluate_robustness_index(controller),\n        'chattering_minimization': lambda controller: evaluate_chattering_index(controller)\n    }\n\n    # Create controller factory\n    factory = create_pso_controller_factory(controller_type)\n\n    # Multi-objective fitness function\n    def multi_objective_fitness(gains: np.ndarray) -> List[float]:\n        \"\"\"Evaluate multiple objectives.\"\"\"\n        try:\n            controller = factory(gains)\n            return [objective_func(controller) for objective_func in objectives.values()]\n        except:\n            return [float('inf')] * len(objectives)\n\n    # Pareto optimization using NSGA-II-style PSO\n    from src.optimization.algorithms.multi_objective_pso import MultiObjectivePSO\n\n    optimizer = MultiObjectivePSO(\n        fitness_function=multi_objective_fitness,\n        n_objectives=len(objectives),\n        n_particles=100,\n        n_dimensions=factory.n_gains,\n        bounds=get_gain_bounds_for_pso(controller_type),\n        max_iterations=200\n    )\n\n    pareto_solutions = optimizer.optimize()\n\n    # Analyze Pareto front\n    pareto_analysis = {\n        'n_solutions': len(pareto_solutions),\n        'objective_ranges': analyze_objective_ranges(pareto_solutions),\n        'recommended_solution': select_best_tradeoff_solution(pareto_solutions),\n        'diversity_metric': compute_pareto_diversity(pareto_solutions)\n    }\n\n    return {\n        'pareto_solutions': pareto_solutions,\n        'analysis': pareto_analysis,\n        'objective_names': list(objectives.keys())\n    }",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b3eb923"
  },
  {
    "id": "pso_factory_integration_patterns_12_767481b8",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef adaptive_pso_optimization(controller_type: SMCType) -> Tuple[np.ndarray, float]:\n    \"\"\"Adaptive PSO with dynamic parameter adjustment.\"\"\"\n\n    factory = create_pso_controller_factory(controller_type)\n\n    class AdaptivePSOController:\n        \"\"\"Adaptive PSO controller with factory integration.\"\"\"\n\n        def __init__(self):\n            self.iteration = 0\n            self.best_fitness_history = []\n            self.stagnation_counter = 0\n            self.current_bounds = get_gain_bounds_for_pso(controller_type)\n\n        def adapt_parameters(self, current_best_fitness: float) -> Dict[str, float]:\n            \"\"\"Adapt PSO parameters based on progress.\"\"\"\n\n            # Check for stagnation\n            if (len(self.best_fitness_history) > 0 and\n                abs(current_best_fitness - self.best_fitness_history[-1]) < 1e-6):\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n            self.best_fitness_history.append(current_best_fitness)\n\n            # Adaptive parameter adjustment\n            if self.stagnation_counter > 10:\n                # Increase exploration\n                w = 0.9  # High inertia\n                c1, c2 = 2.5, 1.5  # High cognitive, low social\n\n                # Expand search bounds slightly\n                lower, upper = self.current_bounds\n                expansion = 0.1\n                self.current_bounds = (\n                    [l * (1 - expansion) for l in lower],\n                    [u * (1 + expansion) for u in upper]\n                )\n\n            elif self.iteration < 50:\n                # Early exploration phase\n                w = 0.9\n                c1, c2 = 2.0, 2.0\n            else:\n                # Late exploitation phase\n                w = 0.4\n                c1, c2 = 1.5, 2.5\n\n            self.iteration += 1\n\n            return {\n                'w': w,\n                'c1': c1,\n                'c2': c2,\n                'bounds': self.current_bounds\n            }\n\n        def fitness_function(self, gains: np.ndarray) -> float:\n            \"\"\"Adaptive fitness function with dynamic objectives.\"\"\"\n\n            try:\n                controller = factory(gains)\n                metrics = evaluate_controller_performance(controller)\n\n                # Dynamic objective weighting based on iteration\n                if self.iteration < 30:\n                    # Early phase: focus on basic performance\n                    return 0.7 * metrics['ise'] + 0.3 * metrics['control_effort']\n                elif self.iteration < 80:\n                    # Middle phase: balance performance and robustness\n                    return (0.4 * metrics['ise'] +\n                           0.3 * metrics['control_effort'] +\n                           0.3 * metrics['robustness_penalty'])\n                else:\n                    # Late phase: focus on refinement\n                    return (0.3 * metrics['ise'] +\n                           0.2 * metrics['control_effort'] +\n                           0.3 * metrics['robustness_penalty'] +\n                           0.2 * metrics['chattering_penalty'])\n\n            except:\n                return float('inf')\n\n    # Run adaptive PSO\n    adaptive_controller = AdaptivePSOController()\n\n    # Initial PSO configuration\n    pso_params = adaptive_controller.adapt_parameters(float('inf'))\n\n    optimizer = PSOTuner(\n        controller_factory=adaptive_controller.fitness_function,\n        config=config,\n        adaptive_callback=adaptive_controller.adapt_parameters\n    )\n\n    return optimizer.optimize_adaptive()",
    "lines": 100,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "767481b8"
  },
  {
    "id": "pso_factory_integration_patterns_13_743255b3",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 13,
    "code": "# \u2705 Good: Create factory once, use many times\nfactory = create_pso_controller_factory(SMCType.CLASSICAL)\n\ndef fitness_function(gains):\n    controller = factory(gains)  # Fast operation\n    return evaluate_performance(controller)\n\n# \u274c Bad: Recreate factory every time\ndef fitness_function(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)  # Slow operation\n    return evaluate_performance(controller)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "743255b3"
  },
  {
    "id": "pso_factory_integration_patterns_14_b10c9cf4",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Good: Validate gains before expensive simulation\ndef robust_fitness_function(gains):\n    if not validate_smc_gains(controller_type, gains):\n        return float('inf')  # Early exit for invalid gains\n\n    controller = factory(gains)\n    return evaluate_performance(controller)\n\n# \u274c Bad: No validation, let controller creation fail\ndef fragile_fitness_function(gains):\n    controller = factory(gains)  # May fail with cryptic error\n    return evaluate_performance(controller)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b10c9cf4"
  },
  {
    "id": "pso_factory_integration_patterns_15_b42bf623",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Good: Comprehensive error handling\ndef robust_fitness_function(gains):\n    try:\n        # Validate inputs\n        if not validate_smc_gains(controller_type, gains):\n            return float('inf')\n\n        # Create controller\n        controller = factory(gains)\n\n        # Evaluate with timeout\n        with timeout(30):  # 30-second timeout\n            performance = evaluate_performance(controller)\n\n        # Check for numerical issues\n        if not np.isfinite(performance['total_cost']):\n            return float('inf')\n\n        return performance['total_cost']\n\n    except TimeoutError:\n        logger.warning(f\"Evaluation timeout for gains: {gains}\")\n        return float('inf')\n    except Exception as e:\n        logger.warning(f\"Evaluation failed for gains {gains}: {e}\")\n        return float('inf')",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b42bf623"
  },
  {
    "id": "pso_factory_integration_patterns_16_659b88c3",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Good: Monitor PSO progress and performance\nclass PSO_Monitor:\n    def __init__(self):\n        self.iteration_times = []\n        self.fitness_history = []\n        self.evaluation_count = 0\n\n    def log_iteration(self, iteration, best_fitness, elapsed_time):\n        self.fitness_history.append(best_fitness)\n        self.iteration_times.append(elapsed_time)\n\n        if iteration % 10 == 0:\n            avg_time = np.mean(self.iteration_times[-10:])\n            logger.info(f\"Iteration {iteration}: fitness={best_fitness:.6f}, \"\n                       f\"avg_time={avg_time:.3f}s\")\n\n    def log_evaluation(self):\n        self.evaluation_count += 1\n\n        if self.evaluation_count % 100 == 0:\n            logger.info(f\"Completed {self.evaluation_count} evaluations\")\n\nmonitor = PSO_Monitor()\n\ndef monitored_fitness_function(gains):\n    monitor.log_evaluation()\n    # ... fitness computation\n    return fitness_value",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "659b88c3"
  },
  {
    "id": "pso_factory_integration_patterns_17_03674a79",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Good: Centralized PSO configuration\nPSO_CONFIGS = {\n    SMCType.CLASSICAL: {\n        'n_particles': 30,\n        'max_iter': 100,\n        'w': 0.9,\n        'c1': 2.0,\n        'c2': 2.0,\n        'early_stopping': True\n    },\n    SMCType.ADAPTIVE: {\n        'n_particles': 40,\n        'max_iter': 150,\n        'w': 0.8,\n        'c1': 2.2,\n        'c2': 1.8,\n        'early_stopping': True\n    }\n}\n\ndef get_pso_config(controller_type: SMCType) -> Dict[str, Any]:\n    \"\"\"Get optimized PSO configuration for controller type.\"\"\"\n    return PSO_CONFIGS.get(controller_type, PSO_CONFIGS[SMCType.CLASSICAL])",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "03674a79"
  },
  {
    "id": "pso_factory_integration_patterns_18_ada2d98d",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 18,
    "code": "#!/usr/bin/env python3\n\"\"\"Basic PSO optimization example.\"\"\"\n\nfrom src.controllers.factory import create_pso_controller_factory, SMCType, get_gain_bounds_for_pso\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\ndef basic_pso_example():\n    \"\"\"Basic PSO optimization example.\"\"\"\n\n    # Load configuration\n    config = load_config(\"config.yaml\")\n\n    # Create controller factory\n    factory = create_pso_controller_factory(\n        SMCType.CLASSICAL,\n        plant_config=config.physics\n    )\n\n    # Define fitness function\n    def fitness_function(gains):\n        controller = factory(gains)\n        metrics = evaluate_controller_performance(controller)\n        return metrics['total_cost']\n\n    # Get optimization bounds\n    bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n    # Run PSO optimization\n    tuner = PSOTuner(\n        controller_factory=fitness_function,\n        config=config\n    )\n\n    best_gains, best_fitness = tuner.optimize()\n\n    print(f\"Optimization complete!\")\n    print(f\"Best gains: {best_gains}\")\n    print(f\"Best fitness: {best_fitness}\")\n\n    return best_gains, best_fitness\n\nif __name__ == \"__main__\":\n    basic_pso_example()",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ada2d98d"
  },
  {
    "id": "pso_factory_integration_patterns_19_3807506b",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"Comparative study of different SMC controllers.\"\"\"\n\nfrom src.controllers.factory import create_all_smc_controllers, SMCType\nimport matplotlib.pyplot as plt\n\ndef comparative_controller_study():\n    \"\"\"Compare performance of different SMC controllers.\"\"\"\n\n    controller_types = [\n        SMCType.CLASSICAL,\n        SMCType.ADAPTIVE,\n        SMCType.SUPER_TWISTING\n    ]\n\n    results = {}\n\n    for controller_type in controller_types:\n        print(f\"Optimizing {controller_type.value}...\")\n\n        # Run PSO optimization\n        best_gains, best_fitness = basic_pso_optimization(controller_type)\n\n        # Create optimized controller\n        factory = create_pso_controller_factory(controller_type)\n        controller = factory(best_gains)\n\n        # Comprehensive evaluation\n        performance = evaluate_comprehensive_performance(controller)\n\n        results[controller_type.value] = {\n            'gains': best_gains,\n            'fitness': best_fitness,\n            'performance': performance\n        }\n\n    # Generate comparison report\n    generate_comparison_report(results)\n    plot_performance_comparison(results)\n\n    return results\n\ndef plot_performance_comparison(results):\n    \"\"\"Plot performance comparison.\"\"\"\n\n    metrics = ['ise', 'itae', 'settling_time', 'overshoot', 'control_effort']\n    controller_names = list(results.keys())\n\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n\n    for i, metric in enumerate(metrics):\n        values = [results[name]['performance'][metric] for name in controller_names]\n\n        axes[i].bar(controller_names, values)\n        axes[i].set_title(f'{metric.upper()}')\n        axes[i].set_ylabel('Value')\n\n        # Rotate x-axis labels for readability\n        plt.setp(axes[i].get_xticklabels(), rotation=45)\n\n    plt.tight_layout()\n    plt.savefig('controller_performance_comparison.png', dpi=300)\n    plt.show()\n\nif __name__ == \"__main__\":\n    comparative_controller_study()",
    "lines": 70,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3807506b"
  },
  {
    "id": "pso_factory_integration_patterns_20_b2e6a046",
    "file": "docs\\pso_factory_integration_patterns.md",
    "index": 20,
    "code": "#!/usr/bin/env python3\n\"\"\"Real-time PSO optimization with live monitoring.\"\"\"\n\nimport time\nfrom typing import Dict, List\nfrom dataclasses import dataclass\nimport numpy as np\n\n@dataclass\nclass OptimizationProgress:\n    \"\"\"Track optimization progress.\"\"\"\n    iteration: int\n    best_fitness: float\n    best_gains: np.ndarray\n    population_diversity: float\n    elapsed_time: float\n\ndef real_time_pso_optimization():\n    \"\"\"Real-time PSO optimization with live monitoring.\"\"\"\n\n    # Setup real-time monitoring\n    progress_history: List[OptimizationProgress] = []\n\n    def progress_callback(iteration: int, best_fitness: float,\n                         best_gains: np.ndarray, population: np.ndarray) -> None:\n        \"\"\"Real-time progress monitoring callback.\"\"\"\n\n        # Compute population diversity\n        diversity = np.std(population, axis=0).mean()\n        elapsed_time = time.time() - start_time\n\n        # Record progress\n        progress = OptimizationProgress(\n            iteration=iteration,\n            best_fitness=best_fitness,\n            best_gains=best_gains.copy(),\n            population_diversity=diversity,\n            elapsed_time=elapsed_time\n        )\n        progress_history.append(progress)\n\n        # Live display\n        print(f\"Iteration {iteration:3d}: \"\n              f\"fitness={best_fitness:.6f}, \"\n              f\"diversity={diversity:.4f}, \"\n              f\"time={elapsed_time:.1f}s\")\n\n        # Early stopping based on convergence\n        if len(progress_history) >= 20:\n            recent_improvements = [\n                progress_history[-i].best_fitness for i in range(1, 11)\n            ]\n\n            improvement_rate = (max(recent_improvements) - min(recent_improvements)) / max(recent_improvements)\n\n            if improvement_rate < 1e-4:\n                print(\"Convergence detected. Early stopping.\")\n                return True  # Signal early stopping\n\n        return False\n\n    # Create factory and bounds\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n    bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n    # Enhanced fitness function with real-time monitoring\n    evaluation_count = 0\n\n    def monitored_fitness_function(gains: np.ndarray) -> float:\n        nonlocal evaluation_count\n        evaluation_count += 1\n\n        try:\n            controller = factory(gains)\n            performance = evaluate_controller_performance(controller)\n\n            # Log periodic updates\n            if evaluation_count % 50 == 0:\n                print(f\"  Evaluated {evaluation_count} candidates\")\n\n            return performance['total_cost']\n\n        except Exception as e:\n            print(f\"  Evaluation failed: {e}\")\n            return float('inf')\n\n    # Run optimization with real-time monitoring\n    start_time = time.time()\n\n    tuner = PSOTuner(\n        controller_factory=monitored_fitness_function,\n        config=config,\n        progress_callback=progress_callback\n    )\n\n    best_gains, best_fitness = tuner.optimize()\n\n    total_time = time.time() - start_time\n\n    # Generate real-time optimization report\n    print(f\"\\nOptimization Summary:\")\n    print(f\"Total time: {total_time:.1f}s\")\n    print(f\"Total evaluations: {evaluation_count}\")\n    print(f\"Evaluations per second: {evaluation_count/total_time:.1f}\")\n    print(f\"Final fitness: {best_fitness:.6f}\")\n    print(f\"Best gains: {best_gains}\")\n\n    # Plot convergence history\n    plot_convergence_history(progress_history)\n\n    return best_gains, best_fitness, progress_history\n\ndef plot_convergence_history(progress_history: List[OptimizationProgress]):\n    \"\"\"Plot real-time optimization convergence.\"\"\"\n\n    iterations = [p.iteration for p in progress_history]\n    fitness_values = [p.best_fitness for p in progress_history]\n    diversity_values = [p.population_diversity for p in progress_history]\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n\n    # Fitness convergence\n    ax1.plot(iterations, fitness_values, 'b-', linewidth=2)\n    ax1.set_xlabel('Iteration')\n    ax1.set_ylabel('Best Fitness')\n    ax1.set_title('PSO Convergence History')\n    ax1.grid(True, alpha=0.3)\n\n    # Population diversity\n    ax2.plot(iterations, diversity_values, 'r-', linewidth=2)\n    ax2.set_xlabel('Iteration')\n    ax2.set_ylabel('Population Diversity')\n    ax2.set_title('Population Diversity Evolution')\n    ax2.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig('pso_convergence_history.png', dpi=300)\n    plt.show()\n\nif __name__ == \"__main__\":\n    real_time_pso_optimization()",
    "lines": 141,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2e6a046"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_1_30851258",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 1,
    "code": "def validate_sta_damping(lambda1, lambda2):\n    \"\"\"Validate STA surface coefficients for Issue #2 compliance.\"\"\"\n    damping_ratio = lambda2 / (2 * np.sqrt(lambda1))\n    natural_freq = np.sqrt(lambda1)\n\n    # Issue #2 compliance checks\n    damping_ok = 0.6 <= damping_ratio <= 0.8  # Avoid underdamping\n    frequency_ok = 0.3 <= natural_freq <= 3.2  # Physical realizability\n    overshoot_ok = damping_ratio >= 0.69       # <5% overshoot guarantee\n\n    return damping_ok and frequency_ok and overshoot_ok",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30851258"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_2_af9f3dab",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_stability_realtime(gains: np.ndarray, controller_type: str) -> bool:\n    \"\"\"\n    Real-time stability validation for PSO-generated gains.\n\n    Mathematical Validation Chain:\n    1. Positivity constraints (all gains > 0)\n    2. Hurwitz stability (characteristic polynomial roots)\n    3. Damping ratio bounds (transient performance)\n    4. Actuator compatibility (saturation limits)\n    5. Controller-specific constraints (e.g., K\u2081 > K\u2082 for STA)\n    \"\"\"\n\n    if controller_type == \"classical_smc\":\n        c1, lambda1, c2, lambda2, K, kd = gains\n\n        # Positivity\n        if not all(g > 0 for g in gains):\n            return False\n\n        # Damping ratios\n        zeta1 = lambda1 / (2 * np.sqrt(c1))\n        zeta2 = lambda2 / (2 * np.sqrt(c2))\n        if not (0.6 <= zeta1 <= 0.8 and 0.6 <= zeta2 <= 0.8):\n            return False\n\n        # Actuator limits\n        if K + kd > 150:\n            return False\n\n    elif controller_type == \"sta_smc\":\n        K1, K2, k1, k2, lambda1, lambda2 = gains\n\n        # STA stability condition\n        if K1 <= K2:\n            return False\n\n        # Issue #2 compliance: damping ratio check\n        zeta1 = lambda1 / (2 * np.sqrt(k1))\n        zeta2 = lambda2 / (2 * np.sqrt(k2))\n        if not (0.6 <= zeta1 <= 0.8 and 0.6 <= zeta2 <= 0.8):\n            return False\n\n        # Finite-time convergence condition (simplified)\n        L_estimate = 10.0  # Conservative Lipschitz constant\n        if K1**2 <= 4 * K2 * L_estimate:\n            return False\n\n    return True",
    "lines": 51,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "af9f3dab"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_3_63fc18b0",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass SafetyBoundsEnforcer:\n    \"\"\"\n    Hardware and safety constraint enforcement for PSO optimization.\n    \"\"\"\n\n    def __init__(self):\n        self.max_force = 150.0  # Hardware actuator limit\n        self.max_angle = np.pi/4  # Safe angular range\n        self.max_angular_velocity = 10.0  # rad/s\n\n    def enforce_safety_bounds(self, gains: np.ndarray, controller_type: str) -> np.ndarray:\n        \"\"\"\n        Enforce safety-critical bounds with hardware protection.\n        \"\"\"\n        safe_gains = gains.copy()\n\n        # Controller-specific safety enforcement\n        if controller_type in [\"classical_smc\", \"sta_smc\"]:\n            # Limit total switching gain to prevent actuator damage\n            if controller_type == \"classical_smc\":\n                K, kd = gains[4], gains[5]\n                if K + kd > self.max_force:\n                    scale_factor = self.max_force / (K + kd)\n                    safe_gains[4] *= scale_factor\n                    safe_gains[5] *= scale_factor\n\n            elif controller_type == \"sta_smc\":\n                K1, K2 = gains[0], gains[1]\n                if K1 + K2 > self.max_force:\n                    scale_factor = self.max_force / (K1 + K2)\n                    safe_gains[0] *= scale_factor\n                    safe_gains[1] *= scale_factor\n\n        return safe_gains",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "63fc18b0"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_4_9a7d5a53",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef log_space_pso_bounds(linear_bounds: tuple) -> tuple:\n    \"\"\"\n    Convert linear bounds to log-space for better PSO exploration.\n\n    Example: K \u2208 [0.1, 100] \u2192 log(K) \u2208 [-2.3, 4.6]\n    \"\"\"\n    min_val, max_val = linear_bounds\n    log_min = np.log10(min_val)\n    log_max = np.log10(max_val)\n    return (log_min, log_max)\n\n# PSO operates in log-space, then transforms back:\ndef transform_gains_from_log(log_gains: np.ndarray) -> np.ndarray:\n    return 10**log_gains",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a7d5a53"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_5_799179d0",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_constraint_penalty(gains: np.ndarray, controller_type: str) -> float:\n    \"\"\"\n    Compute penalty for constraint violations in PSO fitness function.\n\n    Penalty Structure:\n    P = w\u2081 \u00d7 bounds_violation + w\u2082 \u00d7 stability_violation + w\u2083 \u00d7 safety_violation\n    \"\"\"\n    penalty = 0.0\n\n    # Bounds violation penalty\n    bounds = get_controller_bounds(controller_type)\n    for i, (gain, (min_val, max_val)) in enumerate(zip(gains, bounds)):\n        if gain < min_val:\n            penalty += 1000 * (min_val - gain)**2\n        elif gain > max_val:\n            penalty += 1000 * (gain - max_val)**2\n\n    # Stability constraint penalties\n    if controller_type == \"sta_smc\":\n        K1, K2 = gains[0], gains[1]\n        if K1 <= K2:\n            penalty += 10000  # Large penalty for stability violation\n\n        # Issue #2 damping penalty\n        lambda1, lambda2 = gains[4], gains[5]\n        damping = lambda2 / (2 * np.sqrt(lambda1))\n        if damping < 0.6 or damping > 0.8:\n            penalty += 5000 * abs(damping - 0.7)**2\n\n    return penalty",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "799179d0"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_6_4dc73ab0",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_issue2_compliance(lambda1: float, lambda2: float) -> tuple:\n    \"\"\"\n    Verify Issue #2 overshoot compliance through theoretical analysis.\n    \"\"\"\n    # Calculate damping ratio\n    zeta = lambda2 / (2 * np.sqrt(lambda1))\n\n    # Predict overshoot\n    if zeta >= 1.0:\n        predicted_overshoot = 0.0  # Overdamped\n    else:\n        predicted_overshoot = 100 * np.exp(-zeta * np.pi / np.sqrt(1 - zeta**2))\n\n    # Issue #2 compliance check\n    compliant = predicted_overshoot < 5.0\n\n    return predicted_overshoot, compliant, zeta\n\n# Example verification\novershoot, compliant, zeta = verify_issue2_compliance(4.85, 3.43)\nprint(f\"Predicted overshoot: {overshoot:.2f}%, Compliant: {compliant}, \u03b6: {zeta:.3f}\")\n# Output: Predicted overshoot: 4.79%, Compliant: True, \u03b6: 0.780",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4dc73ab0"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_7_69735e98",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef issue2_compliant_constraints(gains: np.ndarray) -> bool:\n    \"\"\"\n    Issue #2 specific constraints for STA-SMC optimization.\n    \"\"\"\n    K1, K2, k1, k2, lambda1, lambda2 = gains\n\n    # Original STA constraints\n    if K1 <= K2:\n        return False\n\n    # Issue #2 specific: damping ratio constraint\n    zeta1 = lambda1 / (2 * np.sqrt(k1))\n    zeta2 = lambda2 / (2 * np.sqrt(k2))\n\n    # Target damping for <5% overshoot\n    if not (0.69 <= zeta1 <= 0.8 and 0.69 <= zeta2 <= 0.8):\n        return False\n\n    return True",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69735e98"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_8_ab270135",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass VectorizedBoundsValidator:\n    \"\"\"\n    Optimized bounds validation for PSO swarm evaluation.\n    \"\"\"\n\n    def __init__(self, controller_type: str):\n        self.controller_type = controller_type\n        self.bounds = self._get_optimized_bounds()\n\n    def validate_swarm(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Vectorized validation for entire PSO swarm.\n\n        Parameters:\n        particles: shape (n_particles, n_dims)\n\n        Returns:\n        valid_mask: shape (n_particles,) boolean array\n        \"\"\"\n        n_particles = particles.shape[0]\n        valid_mask = np.ones(n_particles, dtype=bool)\n\n        # Vectorized bounds checking\n        for i, (min_val, max_val) in enumerate(self.bounds):\n            valid_mask &= (particles[:, i] >= min_val) & (particles[:, i] <= max_val)\n\n        # Controller-specific constraints\n        if self.controller_type == \"sta_smc\":\n            # K1 > K2 constraint\n            valid_mask &= particles[:, 0] > particles[:, 1]\n\n            # Issue #2 damping constraints\n            lambda1, lambda2 = particles[:, 4], particles[:, 5]\n            k1, k2 = particles[:, 2], particles[:, 3]\n\n            zeta1 = lambda1 / (2 * np.sqrt(k1))\n            zeta2 = lambda2 / (2 * np.sqrt(k2))\n\n            damping_ok = (zeta1 >= 0.69) & (zeta1 <= 0.8) & (zeta2 >= 0.69) & (zeta2 <= 0.8)\n            valid_mask &= damping_ok\n\n        return valid_mask",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab270135"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_9_f0fc61b9",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 9,
    "code": "CLASSICAL_SMC_BOUNDS = {\n    'c1': (1.0, 100.0),      # Position error weighting\n    'lambda1': (1.0, 20.0),  # Damping coefficient\n    'c2': (1.0, 100.0),      # Position error weighting\n    'lambda2': (1.0, 20.0),  # Damping coefficient\n    'K': (5.0, 150.0),       # Switching gain\n    'kd': (0.1, 10.0)        # Derivative gain\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0fc61b9"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_10_b0e7dd32",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 10,
    "code": "STA_SMC_BOUNDS_ISSUE2 = {\n    'K1': (1.0, 100.0),      # First-order STA gain\n    'K2': (1.0, 100.0),      # Second-order STA gain (K1 > K2)\n    'k1': (1.0, 20.0),       # Surface gain\n    'k2': (1.0, 20.0),       # Surface gain\n    'lambda1': (0.1, 10.0),  # Surface coefficient (Issue #2 optimized)\n    'lambda2': (0.1, 10.0)   # Surface coefficient (Issue #2 optimized)\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0e7dd32"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_11_ca3ce9ee",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 11,
    "code": "ADAPTIVE_SMC_BOUNDS = {\n    'c1': (1.0, 100.0),      # Position error weighting\n    'lambda1': (1.0, 20.0),  # Damping coefficient\n    'c2': (1.0, 100.0),      # Position error weighting\n    'lambda2': (1.0, 20.0),  # Damping coefficient\n    'gamma': (0.1, 10.0)     # Adaptation rate\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca3ce9ee"
  },
  {
    "id": "pso_gain_bounds_mathematical_foundations_12_66001cdc",
    "file": "docs\\pso_gain_bounds_mathematical_foundations.md",
    "index": 12,
    "code": "HYBRID_SMC_BOUNDS = {\n    'c1': (1.0, 100.0),      # Shared surface gain\n    'lambda1': (1.0, 20.0),  # Shared surface coefficient\n    'c2': (1.0, 100.0),      # Shared surface gain\n    'lambda2': (1.0, 20.0)   # Shared surface coefficient\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "66001cdc"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_1_3243ccf3",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 1,
    "code": "from src.controllers.factory import SMCType, create_smc_for_pso\nfrom src.plant.configurations import ConfigurationFactory\n\n# Create plant configuration\nplant_config = ConfigurationFactory.create_default_config(\"simplified\")\n\n# Create controller with PSO-friendly interface\ngains = [10.0, 5.0, 8.0, 3.0, 15.0, 2.0]  # 6 gains for Classical SMC\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, gains, plant_config)\n\n# Use simplified control interface\nstate = np.array([0.1, 0.2, 0.3, 0.0, 0.0, 0.0])\ncontrol = controller.compute_control(state)  # Returns np.ndarray([control_value])",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3243ccf3"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_2_d99b2c21",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 2,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, validate_smc_gains\n\n# Get optimization bounds\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nlower_bounds, upper_bounds = bounds\n\n# Example PSO fitness function\ndef fitness_function(gains):\n    \"\"\"PSO fitness function for controller tuning.\"\"\"\n    # Validate gains first\n    if not validate_smc_gains(SMCType.CLASSICAL, gains):\n        return 1e6  # High penalty for invalid gains\n\n    try:\n        # Create controller\n        controller = create_smc_for_pso(SMCType.CLASSICAL, gains, plant_config)\n\n        # Evaluate performance across test scenarios\n        total_cost = 0.0\n        test_states = [\n            np.array([0.1, 0.2, 0.3, 0.0, 0.0, 0.0]),\n            np.array([0.2, 0.1, 0.4, 0.1, 0.0, 0.0]),\n        ]\n\n        for state in test_states:\n            control = controller.compute_control(state)\n\n            # Cost function: state error + control effort\n            state_cost = np.sum(state[:3]**2)\n            control_cost = np.sum(control**2)\n            total_cost += state_cost + 0.1 * control_cost\n\n        return total_cost\n\n    except Exception:\n        return 1e6  # High penalty for errors\n\n# Use with PySwarms or other PSO libraries\n# bounds = (lower_bounds, upper_bounds)\n# optimizer.optimize(fitness_function, bounds=bounds)",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d99b2c21"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_3_f36711b3",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 3,
    "code": "# PSO-friendly simplified interface\ncontrol = controller.compute_control(state)\n\n# Full interface (backward compatibility)\ncontrol_output = controller.compute_control(state, state_vars, history)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f36711b3"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_4_aa936ffc",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Classical SMC bounds\nCLASSICAL_BOUNDS = {\n    'k1': (0.1, 50.0),      # Surface gain 1\n    'k2': (0.1, 50.0),      # Surface gain 2\n    'lam1': (0.1, 50.0),    # Sliding surface parameter 1\n    'lam2': (0.1, 50.0),    # Sliding surface parameter 2\n    'K': (1.0, 200.0),      # Switching gain\n    'kd': (0.0, 50.0)       # Damping gain (can be zero)\n}\n\n# Adaptive SMC bounds\nADAPTIVE_BOUNDS = {\n    'k1': (0.1, 50.0),      # Surface gain 1\n    'k2': (0.1, 50.0),      # Surface gain 2\n    'lam1': (0.1, 50.0),    # Sliding surface parameter 1\n    'lam2': (0.1, 50.0),    # Sliding surface parameter 2\n    'gamma': (0.01, 10.0)   # Adaptation rate\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa936ffc"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_5_ae8f6a93",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 5,
    "code": "# Check gain requirements\nfrom src.controllers.factory import SMC_GAIN_SPECS\nspec = SMC_GAIN_SPECS[SMCType.CLASSICAL]\nprint(f\"Required gains: {spec.n_gains}\")\nprint(f\"Gain names: {spec.gain_names}\")\n\n# Validate gains before optimization\ngains = [10.0, 5.0, 8.0, 3.0, 15.0, 2.0]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, gains)\nprint(f\"Gains valid: {is_valid}\")\n\n# Check bounds format\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nprint(f\"Bounds format: {type(bounds)}\")\nprint(f\"Lower bounds: {bounds[0]}\")\nprint(f\"Upper bounds: {bounds[1]}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae8f6a93"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_6_da1aa373",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 6,
    "code": "# Old interface still works\nfrom src.controllers.factory import SMCFactory, SMCConfig\n\nconfig = SMCConfig(gains=gains, max_force=100.0, dt=0.01)\ncontroller = SMCFactory.create_controller(SMCType.CLASSICAL, config)\n\n# New PSO interface provides simplified access\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, gains, plant_config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da1aa373"
  },
  {
    "id": "PSO_INTEGRATION_GUIDE_7_57e006f6",
    "file": "docs\\PSO_INTEGRATION_GUIDE.md",
    "index": 7,
    "code": "# Run PSO integration tests\npython -m pytest tests/test_controllers/factory/test_controller_factory.py::TestPSOIntegration -v\n\n# Run end-to-end validation\npython test_pso_integration_workflow.py",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57e006f6"
  },
  {
    "id": "pso_integration_system_architecture_1_1a3e87de",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOTuner:\n    \"\"\"High-throughput, vectorised tuner for sliding-mode controllers.\"\"\"\n\n    # Core Components:\n    def __init__(self, controller_factory, config, seed=None, rng=None):\n        \"\"\"\n        Architecture Elements:\n        - Local PRNG management (avoid global side effects)\n        - Instance-level normalization constants\n        - Adaptive penalty computation\n        - Configuration validation and deprecation handling\n        \"\"\"\n\n    def _fitness(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Vectorized fitness evaluation pipeline:\n        1. Pre-filter invalid particles via validate_gains()\n        2. Batch simulation via vector_sim\n        3. Cost computation with instability penalties\n        4. Uncertainty aggregation (if configured)\n        \"\"\"\n\n    def optimize(self, **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        PySwarms integration with enhancements:\n        - Velocity clamping for stability\n        - Inertia weight scheduling\n        - Convergence monitoring\n        - Result validation and storage\n        \"\"\"",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a3e87de"
  },
  {
    "id": "pso_integration_system_architecture_2_19686add",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(controller_type: str, gains: np.ndarray, **kwargs) -> Controller:\n    \"\"\"\n    PSO-compatible factory interface.\n\n    Integration Requirements:\n    1. Standardized gain vector interface across all controller types\n    2. Built-in parameter validation with bounds checking\n    3. Consistent actuator saturation limits (max_force)\n    4. Optional validate_gains() method for PSO pre-filtering\n    \"\"\"\n\n# Controller-Specific Interfaces:\nclass ClassicalSMC:\n    def __init__(self, gains: np.ndarray): # [c1, \u03bb1, c2, \u03bb2, K, kd]\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray: # Optional\n    @property\n    def max_force(self) -> float: # Required for PSO\n\nclass STASMC:\n    def __init__(self, gains: np.ndarray): # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    # Same interface requirements...\n\nclass AdaptiveSMC:\n    def __init__(self, gains: np.ndarray): # [c1, \u03bb1, c2, \u03bb2, \u03b3]\n    # Same interface requirements...",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19686add"
  },
  {
    "id": "pso_integration_system_architecture_3_e95cd219",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef simulate_system_batch(\n    controller_factory: Callable,\n    particles: np.ndarray,\n    sim_time: float,\n    dt: float,\n    u_max: float,\n    params_list: Optional[List[DIPParams]] = None\n) -> Union[Tuple, List[Tuple]]:\n    \"\"\"\n    High-performance batch simulation architecture:\n\n    Performance Features:\n    - Vectorized integration (Numba-optimized)\n    - Memory-efficient trajectory storage\n    - Parallel controller evaluation\n    - Early termination for unstable trajectories\n\n    Returns:\n    - Time vectors: t \u2208 \u211d\u1d40\n    - State trajectories: x \u2208 \u211d\u1d2e\u02e3\u1d40\u02e3\u2076\n    - Control trajectories: u \u2208 \u211d\u1d2e\u02e3\u1d40\n    - Sliding variables: \u03c3 \u2208 \u211d\u1d2e\u02e3\u1d40\n    \"\"\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e95cd219"
  },
  {
    "id": "pso_integration_system_architecture_4_79593d1c",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 4,
    "code": "def _compute_cost_from_traj(self, t, x_b, u_b, sigma_b) -> np.ndarray:\n    \"\"\"\n    Multi-stage cost computation:\n    1. Detect instability (angle limits, trajectory explosion)\n    2. Compute time-mask for early termination\n    3. Integrate weighted cost components\n    4. Apply graded penalties for failure\n    5. Normalize by baseline performance constants\n    \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79593d1c"
  },
  {
    "id": "pso_integration_system_architecture_5_48d72243",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerInterface:\n    def __init__(self, gains: np.ndarray):\n        \"\"\"Initialize with gain vector from PSO particle.\"\"\"\n\n    @property\n    def max_force(self) -> float:\n        \"\"\"Actuator saturation limit for simulation.\"\"\"\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Optional: Pre-filter invalid particles (returns boolean mask).\"\"\"\n\n    def compute_control(self, state: np.ndarray, **kwargs) -> float:\n        \"\"\"Required: Control law implementation.\"\"\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48d72243"
  },
  {
    "id": "pso_integration_system_architecture_6_f89daba4",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 6,
    "code": "# Controller-specific gain vector dimensions:\nGAIN_DIMENSIONS = {\n    'classical_smc': 6,      # [c1, \u03bb1, c2, \u03bb2, K, kd]\n    'sta_smc': 6,            # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    'adaptive_smc': 5,       # [c1, \u03bb1, c2, \u03bb2, \u03b3]\n    'hybrid_adaptive_sta_smc': 4,  # [c1, \u03bb1, c2, \u03bb2]\n    'swing_up_smc': 6        # Uses stabilizing controller gains\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f89daba4"
  },
  {
    "id": "pso_integration_system_architecture_7_46c0993f",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 7,
    "code": "# Typical performance characteristics:\nPARTICLES = 50\nITERATIONS = 100\nSIMULATION_TIME = 10.0  # seconds\nDT = 0.001             # seconds\n\n# Expected performance:\nITERATION_TIME = 0.8    # seconds per iteration\nTOTAL_OPTIMIZATION = 80  # seconds for full PSO run\nMEMORY_USAGE = 200      # MB peak memory",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46c0993f"
  },
  {
    "id": "pso_integration_system_architecture_8_5b0b5260",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 8,
    "code": "# Multi-level instability detection:\n1. NaN/Inf trajectory values (immediate penalty)\n2. Pendulum angle limits |\u03b8| > \u03c0/2 (early termination)\n3. State explosion |x| > 1e6 (numerical instability)\n4. Control saturation violations (soft penalty)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b0b5260"
  },
  {
    "id": "pso_integration_system_architecture_9_37f84188",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 9,
    "code": "# Penalty application hierarchy:\n1. Invalid gains \u2192 validate_gains() pre-filtering\n2. Simulation failure \u2192 instability_penalty\n3. NaN cost computation \u2192 instability_penalty\n4. Convergence failure \u2192 return best available solution",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37f84188"
  },
  {
    "id": "pso_integration_system_architecture_10_b8c1b68d",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 10,
    "code": "# Comprehensive test suite:\n1. Unit tests: Individual component validation\n2. Integration tests: End-to-end PSO workflows\n3. Performance tests: Benchmark timing and memory\n4. Robustness tests: Parameter boundary conditions\n5. Scientific tests: Theoretical property validation",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b8c1b68d"
  },
  {
    "id": "pso_integration_system_architecture_11_b61f2cfb",
    "file": "docs\\pso_integration_system_architecture.md",
    "index": 11,
    "code": "# PSO integration success metrics:\nCONVERGENCE_RATE = 0.95      # 95% of runs converge successfully\nMAX_ITERATION_TIME = 1.0     # seconds per iteration upper bound\nSTABILITY_MARGIN = 0.1       # minimum phase margin for optimized gains\nREPEATABILITY = 0.05         # cost variation between identical runs",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b61f2cfb"
  },
  {
    "id": "pso_integration_technical_specification_1_bff5bc45",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef controller_factory(gains: np.ndarray) -> Controller:\n    \"\"\"\n    PSO-compatible controller factory interface.\n\n    Mathematical Foundation:\n    The factory must instantiate controllers with gain vector G \u2208 \u211d\u207f\n    where n is controller-specific dimensionality:\n    - Classical SMC: G \u2208 \u211d\u2076 (c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082, K, kd)\n    - STA-SMC: G \u2208 \u211d\u2076 (K\u2081, K\u2082, k\u2081, k\u2082, \u03bb\u2081, \u03bb\u2082)\n    - Adaptive SMC: G \u2208 \u211d\u2075 (c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082, \u03b3)\n    - Hybrid Adaptive STA-SMC: G \u2208 \u211d\u2074 (c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082)\n\n    Parameters\n    ----------\n    gains : np.ndarray, shape (n,)\n        Controller gain vector with validated bounds\n\n    Returns\n    -------\n    Controller\n        Configured SMC instance with required attributes:\n        - max_force: float (actuator saturation limit)\n        - validate_gains: Optional[Callable] (pre-filtering function)\n\n    Interface Contracts\n    ------------------\n    1. Factory function MUST have attribute 'n_gains' specifying dimensionality\n    2. Returned controller MUST implement control computation interface\n    3. All gains MUST be positive and within specified bounds\n    4. Controller MUST handle edge cases (singularities, saturation)\n    \"\"\"\n    return create_controller(controller_type, config, gains=gains)\n\n# Required factory attribute\ncontroller_factory.n_gains = 6  # Controller-specific dimensionality",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bff5bc45"
  },
  {
    "id": "pso_integration_technical_specification_2_c4b8d8db",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Controller Registry with PSO Integration Metadata\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [5.0, 5.0, 5.0, 0.5, 0.5, 0.5],\n        'n_gains': 6,\n        'gain_bounds': [(0.1, 50.0)] * 6,\n        'stability_requirements': {\n            'sliding_surface_gains': [0, 1, 2, 3],  # Indices for c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082\n            'switching_gains': [4, 5],              # Indices for K, kd\n            'positive_definite': True\n        }\n    },\n    'sta_smc': {\n        'class': ModularSuperTwistingSMC,\n        'config_class': STASMCConfig,\n        'default_gains': [8.0, 4.0, 12.0, 6.0, 4.85, 3.43],  # Issue #2 optimized\n        'n_gains': 6,\n        'gain_bounds': [(1.0, 100.0), (1.0, 100.0), (1.0, 20.0), (1.0, 20.0), (0.1, 10.0), (0.1, 10.0)],\n        'stability_requirements': {\n            'algorithmic_gains': [0, 1],    # K\u2081, K\u2082 with K\u2081 > K\u2082 condition\n            'surface_gains': [2, 3],        # k\u2081, k\u2082\n            'surface_coefficients': [4, 5], # \u03bb\u2081, \u03bb\u2082 for target damping \u03b6 = 0.7\n            'finite_time_convergence': True\n        }\n    }\n    # Additional controller specifications...\n}",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4b8d8db"
  },
  {
    "id": "pso_integration_technical_specification_3_f84c6e6b",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_controller_gains(controller_type: str, gains: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Validate gain vectors for controller-specific stability requirements.\n\n    Mathematical Validation Rules:\n\n    Classical SMC:\n    - All gains > 0 (positive definiteness)\n    - Sliding surface gains c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082 ensure Hurwitz characteristic polynomial\n    - Switching gains K, kd provide reaching condition satisfaction\n\n    STA-SMC (Super-Twisting):\n    - Algorithmic gains: K\u2081 > K\u2082 > 0 (stability condition)\n    - Surface coefficients: \u03bb\u2081, \u03bb\u2082 for target damping ratio \u03b6 \u2208 [0.6, 0.8]\n    - Finite-time convergence: K\u2081\u00b2 > 4K\u2082|\u03bb\u2081\u03bb\u2082|\n\n    Parameters\n    ----------\n    controller_type : str\n        Controller identifier from registry\n    gains : np.ndarray, shape (B, n)\n        Batch of gain vectors to validate\n\n    Returns\n    -------\n    np.ndarray, shape (B,), dtype=bool\n        Validity mask for each gain vector\n    \"\"\"\n    registry_info = CONTROLLER_REGISTRY[controller_type]\n    bounds = registry_info['gain_bounds']\n\n    # Basic bounds checking\n    valid_mask = np.ones(gains.shape[0], dtype=bool)\n    for i, (min_val, max_val) in enumerate(bounds):\n        valid_mask &= (gains[:, i] >= min_val) & (gains[:, i] <= max_val)\n\n    # Controller-specific stability checks\n    if controller_type == 'sta_smc':\n        # K\u2081 > K\u2082 condition for STA stability\n        valid_mask &= gains[:, 0] > gains[:, 1]\n\n        # Surface coefficient bounds for target damping\n        lambda1, lambda2 = gains[:, 4], gains[:, 5]\n        damping_ratio = lambda2 / (2 * np.sqrt(lambda1))\n        valid_mask &= (damping_ratio >= 0.6) & (damping_ratio <= 0.8)\n\n    return valid_mask",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f84c6e6b"
  },
  {
    "id": "pso_integration_technical_specification_4_2b4c3994",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_gain_bounds(controller_type: str, gains: np.ndarray) -> tuple[bool, str]:\n    \"\"\"\n    Comprehensive gain bounds validation with mathematical reasoning.\n\n    Implements controller-specific stability and performance constraints\n    derived from Lyapunov stability theory and sliding mode control theory.\n\n    Returns\n    -------\n    tuple[bool, str]\n        (is_valid, error_message) with detailed mathematical justification\n    \"\"\"\n    bounds_spec = CONTROLLER_REGISTRY[controller_type]['gain_bounds']\n    stability_req = CONTROLLER_REGISTRY[controller_type]['stability_requirements']\n\n    # Basic bounds validation\n    for i, (gain, (min_val, max_val)) in enumerate(zip(gains, bounds_spec)):\n        if not (min_val <= gain <= max_val):\n            return False, f\"Gain {i} = {gain:.3f} outside bounds [{min_val}, {max_val}]\"\n\n    # Controller-specific mathematical constraints\n    if controller_type == 'sta_smc':\n        K1, K2 = gains[0], gains[1]\n        if K1 <= K2:\n            return False, f\"STA stability requires K\u2081 > K\u2082, got K\u2081={K1:.3f}, K\u2082={K2:.3f}\"\n\n        lambda1, lambda2 = gains[4], gains[5]\n        damping = lambda2 / (2 * np.sqrt(lambda1))\n        if not (0.6 <= damping <= 0.8):\n            return False, f\"Damping ratio \u03b6={damping:.3f} outside optimal range [0.6, 0.8]\"\n\n    return True, \"All constraints satisfied\"",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b4c3994"
  },
  {
    "id": "pso_integration_technical_specification_5_42a0c3ad",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOConfigValidator:\n    \"\"\"\n    Validates PSO configuration for mathematical consistency and stability.\n    \"\"\"\n\n    @staticmethod\n    def validate_hyperparameters(pso_config: PSOConfig) -> ValidationResult:\n        \"\"\"\n        Validate PSO hyperparameter relationships for convergence guarantee.\n\n        Mathematical Foundations:\n        - Clerc-Kennedy constriction factor: \u03c7 = 2/|2 - \u03c6 - \u221a(\u03c6\u00b2 - 4\u03c6)|\n        - Stability condition: \u03c6 = c\u2081 + c\u2082 > 4 for guaranteed convergence\n        - Inertia weight bounds: \u03c9 \u2208 [0.4, 0.9] for balanced exploration\n        \"\"\"\n        errors = []\n\n        # PSO stability condition\n        phi = pso_config.c1 + pso_config.c2\n        if phi <= 4.0:\n            errors.append(f\"PSO divergence risk: c\u2081 + c\u2082 = {phi:.3f} \u2264 4.0\")\n\n        # Balanced cognitive/social coefficients\n        if abs(pso_config.c1 - pso_config.c2) > 0.5:\n            errors.append(f\"Unbalanced coefficients: |c\u2081 - c\u2082| = {abs(pso_config.c1 - pso_config.c2):.3f} > 0.5\")\n\n        # Inertia weight bounds\n        if not (0.4 <= pso_config.w <= 0.9):\n            errors.append(f\"Inertia weight \u03c9 = {pso_config.w:.3f} outside optimal range [0.4, 0.9]\")\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)\n\n    @staticmethod\n    def validate_bounds_consistency(bounds: PSOBounds, controller_type: str) -> ValidationResult:\n        \"\"\"\n        Ensure PSO bounds align with controller stability requirements.\n        \"\"\"\n        registry_bounds = CONTROLLER_REGISTRY[controller_type]['gain_bounds']\n        errors = []\n\n        for i, ((pso_min, pso_max), (theory_min, theory_max)) in enumerate(zip(\n            zip(bounds.min, bounds.max), registry_bounds\n        )):\n            if pso_min < theory_min:\n                errors.append(f\"Gain {i}: PSO min {pso_min} < theoretical min {theory_min}\")\n            if pso_max > theory_max:\n                errors.append(f\"Gain {i}: PSO max {pso_max} > theoretical max {theory_max}\")\n\n        return ValidationResult(is_valid=len(errors) == 0, errors=errors)",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42a0c3ad"
  },
  {
    "id": "pso_integration_technical_specification_6_9587ec0a",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_fitness_cost(t: np.ndarray, x: np.ndarray, u: np.ndarray, sigma: np.ndarray) -> float:\n    \"\"\"\n    Multi-objective fitness function for PSO optimization.\n\n    Mathematical Formulation:\n    J = w\u2081\u222b\u2080\u1d40||e(t)||\u00b2dt + w\u2082\u222b\u2080\u1d40u\u00b2(t)dt + w\u2083\u222b\u2080\u1d40(du/dt)\u00b2dt + w\u2084\u222b\u2080\u1d40\u03c3\u00b2(t)dt + P\n\n    Where:\n    - e(t) = x(t) - x_ref: state error vector\n    - u(t): control effort\n    - du/dt: control rate (chattering penalty)\n    - \u03c3(t): sliding variable magnitude\n    - P: instability penalty for early termination\n\n    Cost Function Components:\n    1. State Error (ISE): \u222b\u2080\u1d40||e(t)||\u00b2dt\n    2. Control Effort: \u222b\u2080\u1d40u\u00b2(t)dt\n    3. Control Rate: \u222b\u2080\u1d40(du/dt)\u00b2dt\n    4. Sliding Variable Energy: \u222b\u2080\u1d40\u03c3\u00b2(t)dt\n    5. Stability Penalty: Graded penalty for premature failure\n    \"\"\"\n    dt = np.diff(t)\n    dt_matrix = dt[None, :]  # Shape (1, N-1)\n\n    # State error integration (all state components)\n    state_error_sq = np.sum(x[:, :-1, :]**2 * dt_matrix[:, :, None], axis=(1, 2))\n\n    # Control effort integration\n    control_effort_sq = np.sum(u**2 * dt_matrix, axis=1)\n\n    # Control rate penalty (anti-chattering)\n    du = np.diff(u, axis=1, prepend=u[:, 0:1])\n    control_rate_sq = np.sum(du**2 * dt_matrix, axis=1)\n\n    # Sliding variable energy\n    sliding_energy = np.sum(sigma**2 * dt_matrix, axis=1)\n\n    # Instability detection and penalty\n    instability_mask = detect_instability(x, u, sigma)\n    stability_penalty = compute_graded_penalty(instability_mask, t)\n\n    # Weighted cost aggregation\n    total_cost = (\n        weights.state_error * normalize(state_error_sq, norms.ise) +\n        weights.control_effort * normalize(control_effort_sq, norms.control) +\n        weights.control_rate * normalize(control_rate_sq, norms.rate) +\n        weights.stability * normalize(sliding_energy, norms.sliding) +\n        stability_penalty\n    )\n\n    return total_cost",
    "lines": 54,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9587ec0a"
  },
  {
    "id": "pso_integration_technical_specification_7_6d1c66fc",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_ConvergenceMonitor:\n    \"\"\"\n    Advanced convergence monitoring with multiple termination criteria.\n    \"\"\"\n\n    def __init__(self, patience: int = 50, tolerance: float = 1e-6,\n                 diversity_threshold: float = 1e-8):\n        self.patience = patience\n        self.tolerance = tolerance\n        self.diversity_threshold = diversity_threshold\n        self.best_cost_history = []\n        self.diversity_history = []\n        self.stagnation_counter = 0\n\n    def check_convergence(self, swarm_positions: np.ndarray,\n                         swarm_costs: np.ndarray) -> tuple[bool, str]:\n        \"\"\"\n        Multi-criteria convergence detection:\n        1. Cost improvement stagnation\n        2. Swarm diversity collapse\n        3. Gradient-based local optimum detection\n        \"\"\"\n        current_best = np.min(swarm_costs)\n        self.best_cost_history.append(current_best)\n\n        # Swarm diversity (standard deviation of positions)\n        diversity = np.mean(np.std(swarm_positions, axis=0))\n        self.diversity_history.append(diversity)\n\n        # Check improvement stagnation\n        if len(self.best_cost_history) >= 2:\n            improvement = abs(self.best_cost_history[-2] - current_best)\n            relative_improvement = improvement / (abs(current_best) + 1e-12)\n\n            if relative_improvement < self.tolerance:\n                self.stagnation_counter += 1\n            else:\n                self.stagnation_counter = 0\n\n        # Convergence conditions\n        if self.stagnation_counter >= self.patience:\n            return True, f\"Cost stagnation: {self.stagnation_counter} iterations without improvement\"\n\n        if diversity < self.diversity_threshold:\n            return True, f\"Diversity collapse: \u03c3 = {diversity:.2e} < {self.diversity_threshold:.2e}\"\n\n        return False, \"Optimization continuing\"",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d1c66fc"
  },
  {
    "id": "pso_integration_technical_specification_8_fb9fb3cd",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef robust_optimization_under_uncertainty(pso_tuner: PSOTuner,\n                                        uncertainty_config: PhysicsUncertaintySchema) -> dict:\n    \"\"\"\n    Monte Carlo robust optimization with uncertainty quantification.\n\n    Methodology:\n    1. Sample N physics realizations from uncertainty distributions\n    2. Evaluate each particle against all realizations\n    3. Aggregate costs using risk-sensitive criteria (mean + \u03b1\u00b7std)\n    4. Report confidence intervals for optimal gains\n\n    Mathematical Framework:\n    - Uncertain parameters: \u03b8 ~ N(\u03b8\u2080, \u03c3\u00b2) for each physics parameter\n    - Robust cost: J_robust = E[J(G,\u03b8)] + \u03b1\u00b7Std[J(G,\u03b8)]\n    - Risk parameter: \u03b1 \u2208 [0, 1] balancing mean vs variance\n    \"\"\"\n    # Generate uncertainty samples\n    physics_samples = generate_physics_samples(uncertainty_config)\n\n    # Multi-realization evaluation\n    costs_per_realization = []\n    for physics_params in physics_samples:\n        # Evaluate swarm under this realization\n        realization_costs = pso_tuner.evaluate_swarm_with_physics(physics_params)\n        costs_per_realization.append(realization_costs)\n\n    # Risk-sensitive aggregation\n    mean_costs = np.mean(costs_per_realization, axis=0)\n    std_costs = np.std(costs_per_realization, axis=0)\n    robust_costs = mean_costs + uncertainty_config.risk_factor * std_costs\n\n    return {\n        'robust_costs': robust_costs,\n        'mean_costs': mean_costs,\n        'std_costs': std_costs,\n        'confidence_intervals': compute_confidence_intervals(costs_per_realization),\n        'physics_samples': physics_samples\n    }",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb9fb3cd"
  },
  {
    "id": "pso_integration_technical_specification_9_f484079e",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_IntegrationTestSuite:\n    \"\"\"\n    Comprehensive integration testing for PSO-controller system.\n    \"\"\"\n\n    def test_controller_factory_integration(self):\n        \"\"\"\n        Test 1: Controller Factory PSO Compatibility\n\n        Acceptance Criteria:\n        \u2713 Factory function has required n_gains attribute\n        \u2713 All controller types instantiate with PSO-provided gains\n        \u2713 Controller validation methods work correctly\n        \u2713 Memory usage remains bounded during batch creation\n        \"\"\"\n\n    def test_pso_optimization_convergence(self):\n        \"\"\"\n        Test 2: PSO Optimization Convergence\n\n        Acceptance Criteria:\n        \u2713 Convergence within 200 iterations for standard test cases\n        \u2713 Final cost < 0.1 for nominal initial conditions\n        \u2713 Optimized gains satisfy stability constraints\n        \u2713 Reproducible results with fixed random seed\n        \"\"\"\n\n    def test_uncertainty_robustness(self):\n        \"\"\"\n        Test 3: Robust Optimization Under Uncertainty\n\n        Acceptance Criteria:\n        \u2713 Monte Carlo evaluation completes without errors\n        \u2713 Robust gains show \u226410% performance degradation across uncertainty\n        \u2713 Confidence intervals properly computed and reasonable\n        \u2713 No numerical instabilities during uncertainty sampling\n        \"\"\"\n\n    def test_bounds_validation_enforcement(self):\n        \"\"\"\n        Test 4: Bounds Validation and Enforcement\n\n        Acceptance Criteria:\n        \u2713 Out-of-bounds particles properly penalized\n        \u2713 Controller-specific stability constraints enforced\n        \u2713 STA-SMC K\u2081 > K\u2082 condition always satisfied\n        \u2713 Damping ratio bounds maintained for surface coefficients\n        \"\"\"\n\n    def test_performance_regression(self):\n        \"\"\"\n        Test 5: Performance Regression Detection\n\n        Acceptance Criteria:\n        \u2713 Issue #2 overshoot resolution maintained (<5% overshoot)\n        \u2713 Optimization time \u2264 60 seconds for standard configuration\n        \u2713 Memory usage \u2264 2GB during full PSO run\n        \u2713 All controller types achieve acceptable performance\n        \"\"\"",
    "lines": 62,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f484079e"
  },
  {
    "id": "pso_integration_technical_specification_10_d0686044",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_QualityGates:\n    \"\"\"\n    Automated quality gates for PSO integration deployment.\n    \"\"\"\n\n    @staticmethod\n    def validate_optimization_result(result: Dict[str, Any],\n                                   test_config: TestConfig) -> QualityGateResult:\n        \"\"\"\n        Comprehensive quality gate validation for PSO optimization results.\n        \"\"\"\n        checks = []\n\n        # Performance Gate\n        final_cost = result['best_cost']\n        checks.append(QualityCheck(\n            name=\"Performance\",\n            passed=final_cost < test_config.max_acceptable_cost,\n            value=final_cost,\n            threshold=test_config.max_acceptable_cost\n        ))\n\n        # Stability Gate\n        optimized_gains = result['best_pos']\n        stability_valid, stability_msg = validate_controller_stability(optimized_gains)\n        checks.append(QualityCheck(\n            name=\"Stability\",\n            passed=stability_valid,\n            message=stability_msg\n        ))\n\n        # Convergence Gate\n        cost_history = result['history']['cost']\n        converged = check_convergence_quality(cost_history)\n        checks.append(QualityCheck(\n            name=\"Convergence\",\n            passed=converged,\n            message=f\"Converged in {len(cost_history)} iterations\"\n        ))\n\n        # Issue #2 Regression Gate (STA-SMC specific)\n        if test_config.controller_type == 'sta_smc':\n            overshoot = simulate_and_measure_overshoot(optimized_gains)\n            checks.append(QualityCheck(\n                name=\"Issue2_Regression\",\n                passed=overshoot < 0.05,  # 5% threshold\n                value=overshoot,\n                threshold=0.05\n            ))\n\n        overall_passed = all(check.passed for check in checks)\n        return QualityGateResult(passed=overall_passed, checks=checks)",
    "lines": 55,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0686044"
  },
  {
    "id": "pso_integration_technical_specification_11_7243a281",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_pso_configuration(legacy_config: dict) -> PSOConfig:\n    \"\"\"\n    Migrate legacy PSO configuration to current schema with validation.\n\n    Migration Rules:\n    1. Remove deprecated fields with warnings\n    2. Update bounds for Issue #2 resolution compatibility\n    3. Add new enhanced features with sensible defaults\n    4. Validate mathematical consistency of migrated parameters\n    \"\"\"\n    warnings = []\n\n    # Remove deprecated fields\n    deprecated_fields = ['n_processes', 'hyper_trials', 'hyper_search', 'study_timeout']\n    for field in deprecated_fields:\n        if field in legacy_config:\n            warnings.append(f\"Deprecated field '{field}' removed during migration\")\n            del legacy_config[field]\n\n    # Update bounds for Issue #2 compatibility\n    if 'bounds' in legacy_config:\n        old_bounds = legacy_config['bounds']\n        if 'max' in old_bounds and len(old_bounds['max']) >= 6:\n            # Check for problematic lambda bounds from Issue #2\n            if old_bounds['max'][4] > 10.0 or old_bounds['max'][5] > 10.0:\n                warnings.append(\"Updated lambda bounds for Issue #2 overshoot resolution\")\n                old_bounds['max'][4] = min(old_bounds['max'][4], 10.0)\n                old_bounds['max'][5] = min(old_bounds['max'][5], 10.0)\n\n    # Add enhanced features if missing\n    if 'w_schedule' not in legacy_config:\n        legacy_config['w_schedule'] = [0.9, 0.4]\n        warnings.append(\"Added inertia weight scheduling for improved convergence\")\n\n    if 'velocity_clamp' not in legacy_config:\n        legacy_config['velocity_clamp'] = [0.1, 0.2]\n        warnings.append(\"Added velocity clamping for stability\")\n\n    # Validate migrated configuration\n    migrated_config = PSOConfig(**legacy_config)\n    validation_result = PSO_ConfigValidator.validate_hyperparameters(migrated_config)\n\n    if not validation_result.is_valid:\n        raise ConfigurationError(f\"Migration failed validation: {validation_result.errors}\")\n\n    return migrated_config, warnings",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7243a281"
  },
  {
    "id": "pso_integration_technical_specification_12_baae0817",
    "file": "docs\\pso_integration_technical_specification.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_PerformanceMonitor:\n    \"\"\"\n    Real-time performance monitoring for PSO optimization process.\n    \"\"\"\n\n    def __init__(self):\n        self.metrics = {\n            'iteration_times': [],\n            'memory_usage': [],\n            'convergence_rate': [],\n            'particle_diversity': [],\n            'cost_improvement': []\n        }\n\n    def monitor_iteration(self, iteration: int, swarm_state: SwarmState) -> None:\n        \"\"\"\n        Collect performance metrics for each PSO iteration.\n        \"\"\"\n        # Timing metrics\n        iteration_time = time.time() - swarm_state.iteration_start_time\n        self.metrics['iteration_times'].append(iteration_time)\n\n        # Memory monitoring\n        memory_mb = psutil.Process().memory_info().rss / 1024 / 1024\n        self.metrics['memory_usage'].append(memory_mb)\n\n        # Convergence rate\n        if len(swarm_state.cost_history) >= 2:\n            improvement_rate = (swarm_state.cost_history[-2] - swarm_state.cost_history[-1])\n            self.metrics['cost_improvement'].append(improvement_rate)\n\n        # Alert on performance degradation\n        if iteration_time > 5.0:  # 5-second threshold\n            logging.warning(f\"Slow iteration {iteration}: {iteration_time:.2f}s\")\n\n        if memory_mb > 2048:  # 2GB threshold\n            logging.warning(f\"High memory usage: {memory_mb:.1f}MB\")\n\n    def generate_performance_report(self) -> Dict[str, Any]:\n        \"\"\"\n        Generate comprehensive performance analysis report.\n        \"\"\"\n        return {\n            'average_iteration_time': np.mean(self.metrics['iteration_times']),\n            'peak_memory_usage': np.max(self.metrics['memory_usage']),\n            'total_optimization_time': np.sum(self.metrics['iteration_times']),\n            'convergence_efficiency': self._compute_convergence_efficiency(),\n            'performance_bottlenecks': self._identify_bottlenecks(),\n            'recommendations': self._generate_optimization_recommendations()\n        }",
    "lines": 53,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "baae0817"
  },
  {
    "id": "pso_optimization_workflow_specifications_1_f1f1d325",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationLoader:\n    \"\"\"\n    Robust configuration loading with comprehensive validation.\n    \"\"\"\n\n    def __init__(self):\n        self.validation_chain = [\n            self._validate_syntax,\n            self._validate_structure,\n            self._validate_types,\n            self._validate_bounds,\n            self._validate_mathematical_consistency,\n            self._validate_controller_compatibility\n        ]\n\n    def load_and_validate_config(self, config_path: str,\n                                controller_type: str = None) -> ConfigLoadResult:\n        \"\"\"\n        Load configuration with full validation chain.\n\n        Workflow Steps:\n        1. YAML syntax validation\n        2. Schema structure verification\n        3. Data type consistency checking\n        4. Parameter bounds validation\n        5. Mathematical constraint verification\n        6. Controller-specific compatibility\n\n        Returns:\n        ConfigLoadResult with validation status and error details\n        \"\"\"\n        result = ConfigLoadResult()\n\n        try:\n            # Load raw configuration\n            with open(config_path, 'r') as f:\n                raw_config = yaml.safe_load(f)\n\n            result.raw_config = raw_config\n\n            # Apply validation chain\n            for validator in self.validation_chain:\n                validation_result = validator(raw_config, controller_type)\n                result.add_validation_result(validator.__name__, validation_result)\n\n                if validation_result.severity == 'CRITICAL':\n                    result.status = 'FAILED'\n                    return result\n\n            # Configuration migration if needed\n            if self._needs_migration(raw_config):\n                migrated_config, warnings = self._migrate_configuration(raw_config)\n                result.config = migrated_config\n                result.migration_warnings = warnings\n            else:\n                result.config = raw_config\n\n            result.status = 'SUCCESS'\n\n        except Exception as e:\n            result.status = 'ERROR'\n            result.error_message = str(e)\n\n        return result\n\n    def _validate_mathematical_consistency(self, config: dict,\n                                         controller_type: str) -> ValidationResult:\n        \"\"\"\n        Validate mathematical consistency of PSO parameters.\n        \"\"\"\n        errors = []\n\n        pso_config = config.get('pso', {})\n        algorithm_params = pso_config.get('algorithm_params', {})\n\n        # PSO Convergence Condition: \u03c6 = c\u2081 + c\u2082 > 4\n        c1 = algorithm_params.get('c1', 2.0)\n        c2 = algorithm_params.get('c2', 2.0)\n        phi = c1 + c2\n\n        if phi <= 4.0:\n            errors.append({\n                'code': 'PSO_CONVERGENCE_RISK',\n                'message': f'PSO convergence risk: \u03c6 = {phi:.3f} \u2264 4.0',\n                'severity': 'HIGH',\n                'fix_suggestion': 'Increase c1 or c2 to ensure \u03c6 > 4.0'\n            })\n\n        # Coefficient Balance: |c\u2081 - c\u2082| \u2264 0.5\n        coeff_diff = abs(c1 - c2)\n        if coeff_diff > 0.5:\n            errors.append({\n                'code': 'UNBALANCED_COEFFICIENTS',\n                'message': f'Unbalanced PSO coefficients: |c\u2081 - c\u2082| = {coeff_diff:.3f}',\n                'severity': 'MEDIUM',\n                'fix_suggestion': 'Balance c1 and c2 for optimal exploration/exploitation'\n            })\n\n        # Controller-specific mathematical validation\n        if controller_type == 'sta_smc':\n            bounds = pso_config.get('bounds', {}).get('sta_smc', {})\n            if 'max' in bounds and len(bounds['max']) >= 6:\n                lambda1_max, lambda2_max = bounds['max'][4], bounds['max'][5]\n                if lambda1_max > 10.0 or lambda2_max > 10.0:\n                    errors.append({\n                        'code': 'ISSUE2_REGRESSION_RISK',\n                        'message': f'STA-SMC lambda bounds may cause overshoot: \u03bb\u2081_max={lambda1_max}, \u03bb\u2082_max={lambda2_max}',\n                        'severity': 'HIGH',\n                        'fix_suggestion': 'Apply Issue #2 bounds: \u03bb\u2081, \u03bb\u2082 \u2264 10.0'\n                    })\n\n        return ValidationResult(\n            is_valid=len(errors) == 0,\n            errors=errors,\n            severity='CRITICAL' if any(e['severity'] == 'HIGH' for e in errors) else 'MINOR'\n        )",
    "lines": 119,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1f1d325"
  },
  {
    "id": "pso_optimization_workflow_specifications_2_35426ca4",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass BoundsValidator:\n    \"\"\"\n    Advanced bounds validation with constraint propagation.\n    \"\"\"\n\n    def validate_and_propagate_bounds(self, config: dict,\n                                    controller_type: str) -> BoundsValidationResult:\n        \"\"\"\n        Validate bounds and propagate mathematical constraints.\n\n        Constraint Propagation Rules:\n        1. Damping ratio constraints: \u03b6 = \u03bb/(2\u221ac) \u2208 [0.6, 0.8]\n        2. STA stability: K\u2081 > K\u2082 for finite-time convergence\n        3. Actuator saturation: \u2211gains \u2264 150 N\n        4. Issue #2 compliance: \u03b6 \u2265 0.69 for STA-SMC\n        \"\"\"\n        result = BoundsValidationResult()\n\n        bounds_config = config.get('pso', {}).get('bounds', {})\n        controller_bounds = bounds_config.get(controller_type, bounds_config)\n\n        if 'min' not in controller_bounds or 'max' not in controller_bounds:\n            result.errors.append('Missing min/max bounds for controller')\n            result.is_valid = False\n            return result\n\n        min_bounds = np.array(controller_bounds['min'])\n        max_bounds = np.array(controller_bounds['max'])\n\n        # Basic bounds validation\n        if len(min_bounds) != len(max_bounds):\n            result.errors.append('Min/max bounds length mismatch')\n            result.is_valid = False\n            return result\n\n        invalid_bounds = min_bounds >= max_bounds\n        if np.any(invalid_bounds):\n            invalid_indices = np.where(invalid_bounds)[0]\n            result.errors.append(f'Invalid bounds at indices: {invalid_indices.tolist()}')\n            result.is_valid = False\n\n        # Controller-specific constraint propagation\n        if controller_type == 'classical_smc' and len(min_bounds) >= 6:\n            propagated_bounds = self._propagate_classical_smc_constraints(min_bounds, max_bounds)\n            result.propagated_bounds = propagated_bounds\n            result.constraint_violations = self._check_classical_smc_constraints(propagated_bounds)\n\n        elif controller_type == 'sta_smc' and len(min_bounds) >= 6:\n            propagated_bounds = self._propagate_sta_smc_constraints(min_bounds, max_bounds)\n            result.propagated_bounds = propagated_bounds\n            result.constraint_violations = self._check_sta_smc_constraints(propagated_bounds)\n\n            # Issue #2 specific validation\n            lambda1_max, lambda2_max = propagated_bounds[1][4], propagated_bounds[1][5]\n            if lambda1_max > 10.0 or lambda2_max > 10.0:\n                result.warnings.append(f'Issue #2 risk: lambda bounds [{lambda1_max}, {lambda2_max}] > 10.0')\n\n        result.is_valid = len(result.errors) == 0 and len(result.constraint_violations) == 0\n        return result\n\n    def _propagate_sta_smc_constraints(self, min_bounds: np.ndarray,\n                                     max_bounds: np.ndarray) -> tuple:\n        \"\"\"\n        Propagate STA-SMC mathematical constraints through bounds.\n\n        Constraints:\n        1. K\u2081 > K\u2082 (stability condition)\n        2. \u03b6 = \u03bb/(2\u221ak) \u2208 [0.69, 0.8] (Issue #2 damping requirement)\n        3. K\u2081\u00b2 > 4K\u2082L (finite-time convergence)\n        \"\"\"\n        prop_min = min_bounds.copy()\n        prop_max = max_bounds.copy()\n\n        # K\u2081 > K\u2082 constraint propagation\n        # Ensure K\u2081_min > K\u2082_max + margin\n        margin = 0.1\n        if prop_max[1] + margin > prop_min[0]:\n            prop_min[0] = prop_max[1] + margin\n\n        # Damping ratio constraint propagation (Issue #2)\n        # For \u03b6 = \u03bb/(2\u221ak) \u2208 [0.69, 0.8]:\n        target_zeta_min, target_zeta_max = 0.69, 0.8\n\n        # k\u2081, \u03bb\u2081 relationship\n        k1_min, k1_max = prop_min[2], prop_max[2]\n        lambda1_min, lambda1_max = prop_min[4], prop_max[4]\n\n        # Propagate k\u2081 bounds from \u03bb\u2081 bounds and \u03b6 constraints\n        k1_min_from_lambda = (lambda1_min / (2 * target_zeta_max))**2\n        k1_max_from_lambda = (lambda1_max / (2 * target_zeta_min))**2\n\n        prop_min[2] = max(prop_min[2], k1_min_from_lambda)\n        prop_max[2] = min(prop_max[2], k1_max_from_lambda)\n\n        # Similarly for k\u2082, \u03bb\u2082\n        k2_min_from_lambda = (prop_min[5] / (2 * target_zeta_max))**2\n        k2_max_from_lambda = (prop_max[5] / (2 * target_zeta_min))**2\n\n        prop_min[3] = max(prop_min[3], k2_min_from_lambda)\n        prop_max[3] = min(prop_max[3], k2_max_from_lambda)\n\n        return prop_min, prop_max\n\n    def _check_sta_smc_constraints(self, bounds: tuple) -> list:\n        \"\"\"\n        Check STA-SMC constraint violations after propagation.\n        \"\"\"\n        min_bounds, max_bounds = bounds\n        violations = []\n\n        # Check if K\u2081 > K\u2082 is feasible\n        if min_bounds[0] <= max_bounds[1]:\n            violations.append('STA stability constraint K\u2081 > K\u2082 not satisfiable with given bounds')\n\n        # Check damping ratio feasibility\n        for i, (k_idx, lambda_idx) in enumerate([(2, 4), (3, 5)]):  # (k\u2081,\u03bb\u2081), (k\u2082,\u03bb\u2082)\n            k_min, k_max = min_bounds[k_idx], max_bounds[k_idx]\n            lambda_min, lambda_max = min_bounds[lambda_idx], max_bounds[lambda_idx]\n\n            # Check if target damping range [0.69, 0.8] is achievable\n            zeta_min_possible = lambda_min / (2 * np.sqrt(k_max))\n            zeta_max_possible = lambda_max / (2 * np.sqrt(k_min))\n\n            if zeta_max_possible < 0.69:\n                violations.append(f'Damping ratio {i+1} cannot achieve \u03b6 \u2265 0.69 (Issue #2 requirement)')\n            if zeta_min_possible > 0.8:\n                violations.append(f'Damping ratio {i+1} cannot achieve \u03b6 \u2264 0.8')\n\n        return violations",
    "lines": 132,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "35426ca4"
  },
  {
    "id": "pso_optimization_workflow_specifications_3_a4680e2c",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizationWorkflowManager:\n    \"\"\"\n    Comprehensive management of PSO optimization workflow execution.\n    \"\"\"\n\n    def __init__(self, config: dict, controller_type: str):\n        self.config = config\n        self.controller_type = controller_type\n        self.monitors = {\n            'performance': PerformanceMonitor(),\n            'convergence': ConvergenceMonitor(),\n            'memory': MemoryMonitor(),\n            'safety': SafetyMonitor()\n        }\n        self.workflow_state = WorkflowState()\n\n    def execute_optimization_workflow(self, controller_factory: Callable) -> OptimizationResult:\n        \"\"\"\n        Execute complete PSO optimization workflow with monitoring.\n\n        Workflow Phases:\n        1. Pre-optimization setup and validation\n        2. PSO tuner initialization\n        3. Optimization loop execution\n        4. Real-time monitoring and adaptation\n        5. Post-optimization validation\n        6. Result analysis and reporting\n        \"\"\"\n        workflow_start_time = time.time()\n        result = OptimizationResult()\n\n        try:\n            # Phase 1: Pre-optimization Setup\n            setup_result = self._execute_setup_phase(controller_factory)\n            result.setup_results = setup_result\n            if not setup_result.success:\n                result.status = 'SETUP_FAILED'\n                return result\n\n            # Phase 2: PSO Tuner Initialization\n            tuner_result = self._execute_tuner_initialization()\n            result.tuner_results = tuner_result\n            if not tuner_result.success:\n                result.status = 'TUNER_FAILED'\n                return result\n\n            # Phase 3: Optimization Execution\n            optimization_result = self._execute_optimization_loop()\n            result.optimization_results = optimization_result\n            if not optimization_result.success:\n                result.status = 'OPTIMIZATION_FAILED'\n                return result\n\n            # Phase 4: Post-optimization Validation\n            validation_result = self._execute_validation_phase(optimization_result)\n            result.validation_results = validation_result\n\n            # Phase 5: Result Analysis\n            analysis_result = self._execute_analysis_phase(optimization_result)\n            result.analysis_results = analysis_result\n\n            result.status = 'SUCCESS'\n            result.total_time = time.time() - workflow_start_time\n\n        except Exception as e:\n            result.status = 'ERROR'\n            result.error_message = str(e)\n            result.total_time = time.time() - workflow_start_time\n\n        return result\n\n    def _execute_setup_phase(self, controller_factory: Callable) -> SetupResult:\n        \"\"\"\n        Execute pre-optimization setup and validation.\n        \"\"\"\n        setup_result = SetupResult()\n\n        # Validate controller factory\n        if not hasattr(controller_factory, 'n_gains'):\n            setup_result.errors.append('Controller factory missing n_gains attribute')\n            setup_result.success = False\n            return setup_result\n\n        # Validate factory functionality\n        try:\n            test_gains = np.ones(controller_factory.n_gains)\n            test_controller = controller_factory(test_gains)\n            if not hasattr(test_controller, 'max_force'):\n                setup_result.warnings.append('Controller missing max_force attribute')\n        except Exception as e:\n            setup_result.errors.append(f'Controller factory test failed: {str(e)}')\n            setup_result.success = False\n            return setup_result\n\n        # Setup monitoring systems\n        for name, monitor in self.monitors.items():\n            try:\n                monitor.initialize(self.config)\n                setup_result.monitors_initialized.append(name)\n            except Exception as e:\n                setup_result.errors.append(f'Monitor {name} initialization failed: {str(e)}')\n\n        # Validate memory availability\n        available_memory = psutil.virtual_memory().available / (1024**3)  # GB\n        required_memory = self._estimate_memory_requirement()\n        if available_memory < required_memory:\n            setup_result.warnings.append(f'Low memory: {available_memory:.1f}GB available, {required_memory:.1f}GB recommended')\n\n        setup_result.success = len(setup_result.errors) == 0\n        return setup_result\n\n    def _execute_optimization_loop(self) -> OptimizationLoopResult:\n        \"\"\"\n        Execute PSO optimization loop with real-time monitoring.\n        \"\"\"\n        result = OptimizationLoopResult()\n\n        try:\n            # Initialize PSO tuner\n            tuner = PSOTuner(\n                controller_factory=self.controller_factory,\n                config=self.config,\n                seed=self.config.get('pso', {}).get('execution', {}).get('seed', 42)\n            )\n\n            # Setup optimization monitoring\n            optimization_monitor = OptimizationMonitor(\n                monitors=self.monitors,\n                config=self.config\n            )\n\n            # Execute optimization with monitoring\n            pso_result = tuner.optimise()\n\n            # Extract results\n            result.best_cost = pso_result['best_cost']\n            result.best_gains = pso_result['best_pos']\n            result.cost_history = pso_result['history']['cost']\n            result.position_history = pso_result['history']['pos']\n\n            # Get monitoring data\n            result.performance_metrics = optimization_monitor.get_performance_summary()\n            result.convergence_analysis = optimization_monitor.get_convergence_analysis()\n\n            result.success = True\n\n        except Exception as e:\n            result.success = False\n            result.error_message = str(e)\n\n        return result",
    "lines": 154,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4680e2c"
  },
  {
    "id": "pso_optimization_workflow_specifications_4_a2ce379b",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizationMonitor:\n    \"\"\"\n    Real-time monitoring system for PSO optimization with adaptive capabilities.\n    \"\"\"\n\n    def __init__(self, monitors: dict, config: dict):\n        self.monitors = monitors\n        self.config = config\n        self.monitoring_data = {\n            'iteration_times': [],\n            'memory_usage': [],\n            'cost_improvements': [],\n            'diversity_metrics': [],\n            'constraint_violations': [],\n            'safety_alerts': []\n        }\n\n    def monitor_iteration(self, iteration: int, swarm_state: dict) -> MonitoringResult:\n        \"\"\"\n        Monitor single PSO iteration with comprehensive metrics collection.\n        \"\"\"\n        iteration_start = time.time()\n        result = MonitoringResult()\n\n        # Performance monitoring\n        perf_metrics = self.monitors['performance'].collect_metrics(swarm_state)\n        self.monitoring_data['iteration_times'].append(perf_metrics['iteration_time'])\n        self.monitoring_data['memory_usage'].append(perf_metrics['memory_mb'])\n\n        # Convergence monitoring\n        conv_metrics = self.monitors['convergence'].analyze_convergence(swarm_state)\n        self.monitoring_data['cost_improvements'].append(conv_metrics['cost_improvement'])\n        self.monitoring_data['diversity_metrics'].append(conv_metrics['diversity'])\n\n        # Constraint validation\n        constraint_result = self._validate_constraints_realtime(swarm_state)\n        self.monitoring_data['constraint_violations'].extend(constraint_result['violations'])\n\n        # Safety monitoring\n        safety_result = self.monitors['safety'].check_safety_conditions(swarm_state)\n        if safety_result['alerts']:\n            self.monitoring_data['safety_alerts'].extend(safety_result['alerts'])\n\n        # Adaptive parameter adjustment\n        if self._should_adapt_parameters(iteration, swarm_state):\n            adaptations = self._compute_parameter_adaptations(swarm_state)\n            result.parameter_adaptations = adaptations\n\n        # Issue #2 specific monitoring for STA-SMC\n        if self.config.get('controller_type') == 'sta_smc':\n            issue2_result = self._monitor_issue2_compliance(swarm_state)\n            result.issue2_compliance = issue2_result\n\n        result.monitoring_data = self.monitoring_data\n        result.iteration_time = time.time() - iteration_start\n\n        return result\n\n    def _validate_constraints_realtime(self, swarm_state: dict) -> dict:\n        \"\"\"\n        Real-time validation of mathematical and physical constraints.\n        \"\"\"\n        violations = []\n        particles = swarm_state.get('positions', np.array([]))\n\n        if particles.size == 0:\n            return {'violations': violations}\n\n        controller_type = self.config.get('controller_type', 'classical_smc')\n\n        # Controller-specific constraint checking\n        if controller_type == 'sta_smc' and particles.shape[1] >= 6:\n            # K\u2081 > K\u2082 constraint\n            k1_particles, k2_particles = particles[:, 0], particles[:, 1]\n            k1_le_k2_mask = k1_particles <= k2_particles\n            if np.any(k1_le_k2_mask):\n                violation_count = np.sum(k1_le_k2_mask)\n                violations.append({\n                    'type': 'STA_STABILITY_VIOLATION',\n                    'count': violation_count,\n                    'particles': np.where(k1_le_k2_mask)[0].tolist(),\n                    'severity': 'HIGH'\n                })\n\n            # Issue #2 damping ratio constraint\n            if particles.shape[1] >= 6:\n                lambda1, lambda2 = particles[:, 4], particles[:, 5]\n                k1, k2 = particles[:, 2], particles[:, 3]\n\n                # Safe computation with epsilon to avoid division by zero\n                epsilon = 1e-12\n                zeta1 = lambda1 / (2 * np.sqrt(k1 + epsilon))\n                zeta2 = lambda2 / (2 * np.sqrt(k2 + epsilon))\n\n                # Check Issue #2 requirement: \u03b6 \u2265 0.69\n                zeta1_violation = zeta1 < 0.69\n                zeta2_violation = zeta2 < 0.69\n\n                if np.any(zeta1_violation) or np.any(zeta2_violation):\n                    violation_particles = np.where(zeta1_violation | zeta2_violation)[0]\n                    violations.append({\n                        'type': 'ISSUE2_DAMPING_VIOLATION',\n                        'count': len(violation_particles),\n                        'particles': violation_particles.tolist(),\n                        'severity': 'HIGH',\n                        'details': {\n                            'min_zeta1': np.min(zeta1),\n                            'min_zeta2': np.min(zeta2),\n                            'requirement': '\u03b6 \u2265 0.69 for <5% overshoot'\n                        }\n                    })\n\n        return {'violations': violations}\n\n    def _monitor_issue2_compliance(self, swarm_state: dict) -> dict:\n        \"\"\"\n        Specialized monitoring for Issue #2 overshoot compliance.\n        \"\"\"\n        particles = swarm_state.get('positions', np.array([]))\n        if particles.size == 0 or particles.shape[1] < 6:\n            return {'status': 'insufficient_data'}\n\n        # Extract surface coefficients\n        lambda1, lambda2 = particles[:, 4], particles[:, 5]\n        k1, k2 = particles[:, 2], particles[:, 3]\n\n        # Compute damping ratios\n        epsilon = 1e-12\n        zeta1 = lambda1 / (2 * np.sqrt(k1 + epsilon))\n        zeta2 = lambda2 / (2 * np.sqrt(k2 + epsilon))\n\n        # Issue #2 compliance analysis\n        compliance_stats = {\n            'compliant_particles': 0,\n            'total_particles': len(particles),\n            'min_damping_ratio': min(np.min(zeta1), np.min(zeta2)),\n            'avg_damping_ratio': (np.mean(zeta1) + np.mean(zeta2)) / 2,\n            'predicted_overshoot_range': [],\n            'lambda_bounds_status': 'unknown'\n        }\n\n        # Count compliant particles (\u03b6 \u2265 0.69)\n        compliant_mask = (zeta1 >= 0.69) & (zeta2 >= 0.69)\n        compliance_stats['compliant_particles'] = np.sum(compliant_mask)\n\n        # Predict overshoot for representative particles\n        for i in range(min(5, len(particles))):  # Sample first 5 particles\n            zeta_avg = (zeta1[i] + zeta2[i]) / 2\n            if zeta_avg < 1.0:  # Underdamped\n                predicted_overshoot = 100 * np.exp(-zeta_avg * np.pi / np.sqrt(1 - zeta_avg**2))\n            else:  # Overdamped\n                predicted_overshoot = 0.0\n            compliance_stats['predicted_overshoot_range'].append(predicted_overshoot)\n\n        # Check lambda bounds status\n        max_lambda1, max_lambda2 = np.max(lambda1), np.max(lambda2)\n        if max_lambda1 <= 10.0 and max_lambda2 <= 10.0:\n            compliance_stats['lambda_bounds_status'] = 'compliant'\n        else:\n            compliance_stats['lambda_bounds_status'] = 'violation'\n\n        return compliance_stats",
    "lines": 165,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a2ce379b"
  },
  {
    "id": "pso_optimization_workflow_specifications_5_38478066",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 5,
    "code": "class PostOptimizationValidator:\n    \"\"\"\n    Comprehensive validation of PSO optimization results.\n    \"\"\"\n\n    def __init__(self, config: dict, controller_type: str):\n        self.config = config\n        self.controller_type = controller_type\n        self.validation_criteria = self._load_validation_criteria()\n\n    def validate_optimization_results(self, optimization_result: dict) -> ValidationReport:\n        \"\"\"\n        Comprehensive validation of PSO optimization results.\n\n        Validation Components:\n        1. Mathematical consistency verification\n        2. Controller-specific constraint compliance\n        3. Performance benchmark comparison\n        4. Issue #2 overshoot validation (STA-SMC)\n        5. Safety and operational limits checking\n        6. Convergence quality assessment\n        \"\"\"\n        report = ValidationReport()\n\n        # Extract optimization results\n        best_gains = optimization_result['best_gains']\n        best_cost = optimization_result['best_cost']\n        cost_history = optimization_result['cost_history']\n\n        # Validation 1: Mathematical Consistency\n        math_result = self._validate_mathematical_consistency(best_gains)\n        report.add_validation_result('mathematical_consistency', math_result)\n\n        # Validation 2: Controller-Specific Constraints\n        constraint_result = self._validate_controller_constraints(best_gains)\n        report.add_validation_result('controller_constraints', constraint_result)\n\n        # Validation 3: Performance Benchmarks\n        performance_result = self._validate_performance_benchmarks(best_cost, cost_history)\n        report.add_validation_result('performance_benchmarks', performance_result)\n\n        # Validation 4: Issue #2 Compliance (STA-SMC specific)\n        if self.controller_type == 'sta_smc':\n            issue2_result = self._validate_issue2_compliance(best_gains)\n            report.add_validation_result('issue2_compliance', issue2_result)\n\n        # Validation 5: Safety and Operational Limits\n        safety_result = self._validate_safety_limits(best_gains)\n        report.add_validation_result('safety_limits', safety_result)\n\n        # Validation 6: Convergence Quality\n        convergence_result = self._validate_convergence_quality(cost_history)\n        report.add_validation_result('convergence_quality', convergence_result)\n\n        # Generate overall assessment\n        report.generate_overall_assessment()\n\n        return report\n\n    def _validate_issue2_compliance(self, gains: np.ndarray) -> ValidationResult:\n        \"\"\"\n        Validate Issue #2 overshoot compliance for STA-SMC gains.\n        \"\"\"\n        if len(gains) < 6:\n            return ValidationResult(\n                is_valid=False,\n                errors=['Insufficient gains for STA-SMC validation'],\n                severity='CRITICAL'\n            )\n\n        K1, K2, k1, k2, lambda1, lambda2 = gains[:6]\n        errors = []\n        warnings = []\n\n        # STA stability condition: K\u2081 > K\u2082\n        if K1 <= K2:\n            errors.append(f'STA stability violation: K\u2081 ({K1:.3f}) \u2264 K\u2082 ({K2:.3f})')\n\n        # Issue #2 damping ratio requirement: \u03b6 \u2265 0.69\n        zeta1 = lambda1 / (2 * np.sqrt(k1))\n        zeta2 = lambda2 / (2 * np.sqrt(k2))\n\n        if zeta1 < 0.69:\n            errors.append(f'Issue #2 violation: \u03b6\u2081 = {zeta1:.3f} < 0.69 (may cause overshoot)')\n        if zeta2 < 0.69:\n            errors.append(f'Issue #2 violation: \u03b6\u2082 = {zeta2:.3f} < 0.69 (may cause overshoot)')\n\n        # Lambda bounds check (Issue #2 prevention)\n        if lambda1 > 10.0:\n            warnings.append(f'Lambda1 = {lambda1:.3f} > 10.0 (Issue #2 risk)')\n        if lambda2 > 10.0:\n            warnings.append(f'Lambda2 = {lambda2:.3f} > 10.0 (Issue #2 risk)')\n\n        # Predicted overshoot calculation\n        avg_zeta = (zeta1 + zeta2) / 2\n        if avg_zeta < 1.0:\n            predicted_overshoot = 100 * np.exp(-avg_zeta * np.pi / np.sqrt(1 - avg_zeta**2))\n        else:\n            predicted_overshoot = 0.0\n\n        # Issue #2 compliance check\n        overshoot_compliant = predicted_overshoot < 5.0\n\n        return ValidationResult(\n            is_valid=(len(errors) == 0 and overshoot_compliant),\n            errors=errors,\n            warnings=warnings,\n            metadata={\n                'damping_ratios': [zeta1, zeta2],\n                'predicted_overshoot': predicted_overshoot,\n                'overshoot_compliant': overshoot_compliant,\n                'issue2_status': 'compliant' if overshoot_compliant else 'violation'\n            }\n        )\n\n    def _validate_performance_benchmarks(self, best_cost: float,\n                                       cost_history: list) -> ValidationResult:\n        \"\"\"\n        Validate optimization performance against established benchmarks.\n        \"\"\"\n        benchmarks = self.validation_criteria['performance_benchmarks'][self.controller_type]\n        errors = []\n        warnings = []\n\n        # Cost quality check\n        expected_cost_range = benchmarks['final_cost_range']\n        if not (expected_cost_range[0] <= best_cost <= expected_cost_range[1]):\n            if best_cost > expected_cost_range[1]:\n                errors.append(f'Poor optimization: cost {best_cost:.6f} > expected max {expected_cost_range[1]:.6f}')\n            else:\n                warnings.append(f'Unexpectedly good cost: {best_cost:.6f} < expected min {expected_cost_range[0]:.6f}')\n\n        # Convergence speed check\n        convergence_iterations = len(cost_history)\n        expected_convergence = benchmarks['convergence_iterations']\n        if convergence_iterations > expected_convergence * 1.5:\n            warnings.append(f'Slow convergence: {convergence_iterations} > expected {expected_convergence}')\n\n        # Convergence quality assessment\n        if len(cost_history) >= 10:\n            final_costs = cost_history[-10:]\n            cost_variance = np.var(final_costs)\n            if cost_variance > 1e-6:\n                warnings.append(f'Unstable convergence: final cost variance {cost_variance:.2e}')\n\n        return ValidationResult(\n            is_valid=len(errors) == 0,\n            errors=errors,\n            warnings=warnings,\n            metadata={\n                'final_cost': best_cost,\n                'convergence_iterations': convergence_iterations,\n                'benchmark_comparison': {\n                    'cost_within_range': expected_cost_range[0] <= best_cost <= expected_cost_range[1],\n                    'convergence_acceptable': convergence_iterations <= expected_convergence * 1.5\n                }\n            }\n        )\n\n    def simulate_and_verify_performance(self, gains: np.ndarray) -> SimulationValidationResult:\n        \"\"\"\n        Simulate optimized controller and verify actual performance.\n        \"\"\"\n        result = SimulationValidationResult()\n\n        try:\n            # Create controller with optimized gains\n            controller = self._create_test_controller(gains)\n\n            # Run verification simulations\n            test_conditions = self.validation_criteria['test_conditions']\n            for condition in test_conditions:\n                sim_result = self._run_verification_simulation(controller, condition)\n                result.add_simulation_result(condition['name'], sim_result)\n\n            # Issue #2 specific overshoot measurement for STA-SMC\n            if self.controller_type == 'sta_smc':\n                overshoot_result = self._measure_actual_overshoot(controller)\n                result.overshoot_measurement = overshoot_result\n\n            result.overall_success = all(sim.success for sim in result.simulation_results.values())\n\n        except Exception as e:\n            result.overall_success = False\n            result.error_message = str(e)\n\n        return result\n\n    def _measure_actual_overshoot(self, controller) -> dict:\n        \"\"\"\n        Measure actual overshoot for Issue #2 compliance verification.\n        \"\"\"\n        from src.simulation.core.simulation_runner import SimulationRunner\n\n        # Standard step response test\n        initial_state = np.array([0.0, 0.1, 0.0, 0.0, 0.0, 0.0])  # 0.1 rad initial angle\n        target_state = np.zeros(6)\n\n        runner = SimulationRunner(\n            controller=controller,\n            dynamics=self._create_test_dynamics(),\n            config=self.config\n        )\n\n        # Run simulation\n        sim_result = runner.run_simulation(\n            initial_state=initial_state,\n            duration=10.0,\n            dt=0.01\n        )\n\n        # Analyze overshoot\n        time_series = sim_result['time']\n        angle1_series = sim_result['states'][:, 0]  # First pendulum angle\n\n        # Find peak overshoot\n        steady_state_value = angle1_series[-100:].mean()  # Last 1 second average\n        peak_value = np.max(np.abs(angle1_series))\n        overshoot_percent = (peak_value - abs(steady_state_value)) / 0.1 * 100  # Relative to initial 0.1 rad\n\n        return {\n            'measured_overshoot_percent': overshoot_percent,\n            'peak_value': peak_value,\n            'steady_state_value': steady_state_value,\n            'issue2_compliant': overshoot_percent < 5.0,\n            'time_series': time_series,\n            'angle_series': angle1_series\n        }",
    "lines": 228,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38478066"
  },
  {
    "id": "pso_optimization_workflow_specifications_6_df62e659",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass QualityGateSystem:\n    \"\"\"\n    Automated quality gate system for PSO optimization workflow.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config\n        self.quality_gates = [\n            ConfigurationQualityGate(),\n            OptimizationQualityGate(),\n            PerformanceQualityGate(),\n            SafetyQualityGate(),\n            Issue2ComplianceQualityGate(),\n            RegressionQualityGate()\n        ]\n\n    def evaluate_quality_gates(self, workflow_result: dict) -> QualityGateReport:\n        \"\"\"\n        Evaluate all quality gates and generate comprehensive report.\n        \"\"\"\n        report = QualityGateReport()\n\n        for gate in self.quality_gates:\n            gate_result = gate.evaluate(workflow_result, self.config)\n            report.add_gate_result(gate.name, gate_result)\n\n        # Generate overall assessment\n        report.generate_overall_assessment()\n\n        return report\n\nclass Issue2ComplianceQualityGate(QualityGate):\n    \"\"\"\n    Quality gate specifically for Issue #2 overshoot compliance.\n    \"\"\"\n\n    def __init__(self):\n        self.name = \"Issue2_Overshoot_Compliance\"\n        self.acceptance_criteria = {\n            'max_predicted_overshoot': 5.0,    # % maximum theoretical overshoot\n            'min_damping_ratio': 0.69,         # Minimum damping for compliance\n            'max_lambda_bounds': 10.0,         # Maximum lambda values\n            'simulation_overshoot_limit': 5.0   # % maximum measured overshoot\n        }\n\n    def evaluate(self, workflow_result: dict, config: dict) -> QualityGateResult:\n        \"\"\"\n        Evaluate Issue #2 overshoot compliance.\n        \"\"\"\n        result = QualityGateResult(gate_name=self.name)\n\n        # Skip if not STA-SMC\n        if config.get('controller_type') != 'sta_smc':\n            result.status = 'SKIPPED'\n            result.message = 'Issue #2 compliance only applies to STA-SMC'\n            return result\n\n        optimized_gains = workflow_result.get('best_gains')\n        if optimized_gains is None or len(optimized_gains) < 6:\n            result.status = 'FAILED'\n            result.message = 'Missing or insufficient optimized gains'\n            return result\n\n        # Extract surface coefficients\n        lambda1, lambda2 = optimized_gains[4], optimized_gains[5]\n        k1, k2 = optimized_gains[2], optimized_gains[3]\n\n        # Check 1: Lambda bounds compliance\n        lambda_bounds_ok = (lambda1 <= self.acceptance_criteria['max_lambda_bounds'] and\n                          lambda2 <= self.acceptance_criteria['max_lambda_bounds'])\n\n        # Check 2: Damping ratio compliance\n        zeta1 = lambda1 / (2 * np.sqrt(k1))\n        zeta2 = lambda2 / (2 * np.sqrt(k2))\n        damping_ok = (zeta1 >= self.acceptance_criteria['min_damping_ratio'] and\n                     zeta2 >= self.acceptance_criteria['min_damping_ratio'])\n\n        # Check 3: Predicted overshoot\n        avg_zeta = (zeta1 + zeta2) / 2\n        if avg_zeta < 1.0:\n            predicted_overshoot = 100 * np.exp(-avg_zeta * np.pi / np.sqrt(1 - avg_zeta**2))\n        else:\n            predicted_overshoot = 0.0\n\n        overshoot_prediction_ok = predicted_overshoot <= self.acceptance_criteria['max_predicted_overshoot']\n\n        # Check 4: Simulation validation (if available)\n        simulation_ok = True\n        measured_overshoot = None\n        if 'overshoot_measurement' in workflow_result:\n            overshoot_data = workflow_result['overshoot_measurement']\n            measured_overshoot = overshoot_data.get('measured_overshoot_percent', 0)\n            simulation_ok = measured_overshoot <= self.acceptance_criteria['simulation_overshoot_limit']\n\n        # Overall assessment\n        all_checks_pass = lambda_bounds_ok and damping_ok and overshoot_prediction_ok and simulation_ok\n\n        if all_checks_pass:\n            result.status = 'PASSED'\n            result.message = f'Issue #2 compliance verified: predicted overshoot {predicted_overshoot:.2f}%'\n        else:\n            result.status = 'FAILED'\n            failed_checks = []\n            if not lambda_bounds_ok:\n                failed_checks.append(f'Lambda bounds: \u03bb\u2081={lambda1:.3f}, \u03bb\u2082={lambda2:.3f} > {self.acceptance_criteria[\"max_lambda_bounds\"]}')\n            if not damping_ok:\n                failed_checks.append(f'Damping ratios: \u03b6\u2081={zeta1:.3f}, \u03b6\u2082={zeta2:.3f} < {self.acceptance_criteria[\"min_damping_ratio\"]}')\n            if not overshoot_prediction_ok:\n                failed_checks.append(f'Predicted overshoot: {predicted_overshoot:.2f}% > {self.acceptance_criteria[\"max_predicted_overshoot\"]}%')\n            if not simulation_ok and measured_overshoot is not None:\n                failed_checks.append(f'Measured overshoot: {measured_overshoot:.2f}% > {self.acceptance_criteria[\"simulation_overshoot_limit\"]}%')\n            result.message = f'Issue #2 compliance failed: {\"; \".join(failed_checks)}'\n\n        # Add detailed metrics\n        result.metrics = {\n            'lambda1': lambda1,\n            'lambda2': lambda2,\n            'damping_ratio_1': zeta1,\n            'damping_ratio_2': zeta2,\n            'predicted_overshoot_percent': predicted_overshoot,\n            'measured_overshoot_percent': measured_overshoot,\n            'lambda_bounds_compliant': lambda_bounds_ok,\n            'damping_compliant': damping_ok,\n            'overshoot_prediction_compliant': overshoot_prediction_ok,\n            'simulation_compliant': simulation_ok\n        }\n\n        return result",
    "lines": 131,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "df62e659"
  },
  {
    "id": "pso_optimization_workflow_specifications_7_8183f050",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass WorkflowErrorHandler:\n    \"\"\"\n    Comprehensive error handling and recovery for PSO optimization workflow.\n    \"\"\"\n\n    ERROR_CATEGORIES = {\n        'CONFIGURATION_ERROR': {\n            'severity': 'CRITICAL',\n            'recovery_strategy': 'configuration_repair',\n            'retry_enabled': True\n        },\n        'OPTIMIZATION_FAILURE': {\n            'severity': 'HIGH',\n            'recovery_strategy': 'parameter_adjustment',\n            'retry_enabled': True\n        },\n        'CONSTRAINT_VIOLATION': {\n            'severity': 'HIGH',\n            'recovery_strategy': 'bounds_correction',\n            'retry_enabled': True\n        },\n        'CONVERGENCE_FAILURE': {\n            'severity': 'MEDIUM',\n            'recovery_strategy': 'adaptive_tuning',\n            'retry_enabled': True\n        },\n        'SAFETY_VIOLATION': {\n            'severity': 'CRITICAL',\n            'recovery_strategy': 'immediate_termination',\n            'retry_enabled': False\n        }\n    }\n\n    def handle_workflow_error(self, error: Exception, workflow_state: dict) -> ErrorHandlingResult:\n        \"\"\"\n        Handle workflow errors with appropriate recovery strategies.\n        \"\"\"\n        # Classify error\n        error_category = self._classify_error(error, workflow_state)\n        error_info = self.ERROR_CATEGORIES[error_category]\n\n        result = ErrorHandlingResult()\n        result.error_category = error_category\n        result.severity = error_info['severity']\n\n        # Apply recovery strategy\n        if error_info['recovery_strategy'] == 'configuration_repair':\n            recovery_result = self._attempt_configuration_repair(error, workflow_state)\n        elif error_info['recovery_strategy'] == 'parameter_adjustment':\n            recovery_result = self._attempt_parameter_adjustment(error, workflow_state)\n        elif error_info['recovery_strategy'] == 'bounds_correction':\n            recovery_result = self._attempt_bounds_correction(error, workflow_state)\n        elif error_info['recovery_strategy'] == 'adaptive_tuning':\n            recovery_result = self._attempt_adaptive_tuning(error, workflow_state)\n        else:  # immediate_termination\n            recovery_result = RecoveryResult(success=False, terminate=True)\n\n        result.recovery_result = recovery_result\n        result.retry_recommended = error_info['retry_enabled'] and recovery_result.success\n\n        return result\n\n    def _attempt_bounds_correction(self, error: Exception, workflow_state: dict) -> RecoveryResult:\n        \"\"\"\n        Attempt to correct bounds-related errors, especially Issue #2 violations.\n        \"\"\"\n        result = RecoveryResult()\n\n        try:\n            config = workflow_state.get('config', {})\n            controller_type = workflow_state.get('controller_type', 'classical_smc')\n\n            if controller_type == 'sta_smc':\n                # Apply Issue #2 bounds corrections\n                pso_bounds = config.get('pso', {}).get('bounds', {})\n                sta_bounds = pso_bounds.get('sta_smc', pso_bounds)\n\n                if 'max' in sta_bounds and len(sta_bounds['max']) >= 6:\n                    # Apply Issue #2 corrections\n                    original_lambda1_max = sta_bounds['max'][4]\n                    original_lambda2_max = sta_bounds['max'][5]\n\n                    # Reduce lambda bounds if they exceed Issue #2 limits\n                    if original_lambda1_max > 10.0:\n                        sta_bounds['max'][4] = 10.0\n                        result.corrections.append(f'Reduced lambda1_max from {original_lambda1_max} to 10.0')\n\n                    if original_lambda2_max > 10.0:\n                        sta_bounds['max'][5] = 10.0\n                        result.corrections.append(f'Reduced lambda2_max from {original_lambda2_max} to 10.0')\n\n                    # Adjust corresponding min bounds if necessary\n                    if sta_bounds['min'][4] > 5.0:\n                        sta_bounds['min'][4] = 0.1\n                        result.corrections.append('Adjusted lambda1_min for Issue #2 compliance')\n\n                    if sta_bounds['min'][5] > 5.0:\n                        sta_bounds['min'][5] = 0.1\n                        result.corrections.append('Adjusted lambda2_min for Issue #2 compliance')\n\n                    result.success = True\n                    result.corrected_config = config\n\n        except Exception as e:\n            result.success = False\n            result.error_message = str(e)\n\n        return result",
    "lines": 111,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8183f050"
  },
  {
    "id": "pso_optimization_workflow_specifications_8_504ceaf1",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass WorkflowPerformanceOptimizer:\n    \"\"\"\n    Adaptive optimization of workflow performance based on runtime metrics.\n    \"\"\"\n\n    def __init__(self):\n        self.performance_history = []\n        self.optimization_strategies = {\n            'memory_optimization': self._optimize_memory_usage,\n            'convergence_acceleration': self._accelerate_convergence,\n            'bounds_tightening': self._tighten_bounds_dynamically,\n            'parameter_adaptation': self._adapt_pso_parameters\n        }\n\n    def optimize_workflow_performance(self, current_metrics: dict,\n                                    workflow_config: dict) -> OptimizationResult:\n        \"\"\"\n        Analyze current performance and apply optimization strategies.\n        \"\"\"\n        result = OptimizationResult()\n\n        # Analyze performance trends\n        performance_analysis = self._analyze_performance_trends(current_metrics)\n\n        # Apply relevant optimization strategies\n        for strategy_name, strategy_func in self.optimization_strategies.items():\n            if self._should_apply_strategy(strategy_name, performance_analysis):\n                strategy_result = strategy_func(current_metrics, workflow_config)\n                result.add_strategy_result(strategy_name, strategy_result)\n\n        return result\n\n    def _accelerate_convergence(self, metrics: dict, config: dict) -> dict:\n        \"\"\"\n        Apply convergence acceleration strategies based on performance analysis.\n        \"\"\"\n        acceleration_result = {\n            'applied_optimizations': [],\n            'expected_improvement': 0.0\n        }\n\n        # Check convergence rate\n        convergence_rate = metrics.get('convergence_rate', 0.0)\n        if convergence_rate < 0.05:  # Slow convergence detected\n            # Suggest inertia weight adjustment\n            current_w = config.get('pso', {}).get('algorithm_params', {}).get('w', 0.7)\n            if current_w > 0.5:\n                suggested_w = max(0.4, current_w - 0.1)\n                acceleration_result['applied_optimizations'].append({\n                    'parameter': 'inertia_weight',\n                    'current_value': current_w,\n                    'suggested_value': suggested_w,\n                    'justification': 'Reduce inertia for faster exploitation'\n                })\n                acceleration_result['expected_improvement'] += 15.0  # 15% improvement\n\n        # Check diversity metrics\n        diversity = metrics.get('swarm_diversity', 1.0)\n        if diversity < 1e-8:  # Very low diversity\n            acceleration_result['applied_optimizations'].append({\n                'parameter': 'restart_mechanism',\n                'action': 'enable',\n                'fraction': 0.2,\n                'justification': 'Restart 20% of particles to escape local optimum'\n            })\n            acceleration_result['expected_improvement'] += 20.0  # 20% improvement\n\n        return acceleration_result",
    "lines": 71,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "504ceaf1"
  },
  {
    "id": "pso_optimization_workflow_specifications_9_cfb4bfe0",
    "file": "docs\\pso_optimization_workflow_specifications.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSO_WorkflowOrchestrator:\n    \"\"\"\n    Integration point for PSO optimization workflow within multi-agent system.\n    \"\"\"\n\n    def __init__(self, agents: dict):\n        self.agents = agents\n        self.workflow_manager = OptimizationWorkflowManager()\n        self.coordination_protocol = AgentCoordinationProtocol()\n\n    def execute_coordinated_optimization(self, request: OptimizationRequest) -> OrchestrationResult:\n        \"\"\"\n        Execute PSO optimization with multi-agent coordination.\n\n        Agent Coordination:\n        - Control Systems Specialist: Controller validation and analysis\n        - PSO Optimization Engineer: Algorithm tuning and execution\n        - Documentation Expert: Process documentation and reporting\n        - Integration Coordinator: Cross-domain validation\n        \"\"\"\n        result = OrchestrationResult()\n\n        # Phase 1: Pre-optimization coordination\n        prep_result = self.coordination_protocol.coordinate_preparation(\n            request, self.agents\n        )\n        if not prep_result.success:\n            result.status = 'PREPARATION_FAILED'\n            return result\n\n        # Phase 2: Parallel agent execution\n        optimization_tasks = {\n            'pso_execution': self.agents['pso_engineer'].execute_optimization,\n            'controller_validation': self.agents['control_specialist'].validate_controller,\n            'documentation': self.agents['documentation_expert'].document_process,\n            'integration_check': self.agents['integration_coordinator'].validate_integration\n        }\n\n        parallel_results = self.coordination_protocol.execute_parallel_tasks(optimization_tasks)\n\n        # Phase 3: Result integration and validation\n        integration_result = self.coordination_protocol.integrate_results(parallel_results)\n        result.integration_results = integration_result\n\n        # Phase 4: Quality gate evaluation\n        quality_gates = QualityGateSystem(request.config)\n        gate_results = quality_gates.evaluate_quality_gates(integration_result)\n        result.quality_gate_results = gate_results\n\n        result.status = 'SUCCESS' if gate_results.overall_pass else 'QUALITY_GATE_FAILED'\n        return result",
    "lines": 54,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfb4bfe0"
  },
  {
    "id": "pso_optimization_workflow_user_guide_1_ca06577f",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 1,
    "code": "# Lower bounds: [c1, \u03bb1, c2, \u03bb2, K, kd]\nlower_bounds = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n\n# Upper bounds\nupper_bounds = [20.0, 20.0, 20.0, 20.0, 100.0, 10.0]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca06577f"
  },
  {
    "id": "pso_optimization_workflow_user_guide_2_21eae194",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 2,
    "code": "# STA-SMC gains: [K1, K2, k1, k2, \u03bb1, \u03bb2]\ngains_meaning = {\n    'K1': 'First-order sliding gain (0.5-power term)',\n    'K2': 'Second-order sliding gain (integral term)',\n    'k1': 'Surface gain for pendulum 1',\n    'k2': 'Surface gain for pendulum 2',\n    'lambda1': 'Surface coefficient for pendulum 1',\n    'lambda2': 'Surface coefficient for pendulum 2'\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21eae194"
  },
  {
    "id": "pso_optimization_workflow_user_guide_3_208dd630",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 3,
    "code": "# Adaptive SMC gains: [c1, \u03bb1, c2, \u03bb2, \u03b3]\noptimization_tips = {\n    'c1, c2': 'Surface gains (1.0-10.0 typical range)',\n    'lambda1, lambda2': 'Surface coefficients (0.5-5.0 typical)',\n    'gamma': 'Adaptation rate (0.1-2.0, higher = faster adaptation)'\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "208dd630"
  },
  {
    "id": "pso_optimization_workflow_user_guide_4_2d7eb757",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 4,
    "code": "# Hybrid gains: [c1, \u03bb1, c2, \u03bb2]\n# Note: K1, K2 are adapted online automatically\nhybrid_features = {\n    'c1, c2': 'Proportional-like surface gains',\n    'lambda1, lambda2': 'Integral-like surface coefficients',\n    'adaptation': 'K1, K2 adapt based on sliding surface magnitude'\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d7eb757"
  },
  {
    "id": "pso_optimization_workflow_user_guide_5_113ef026",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 5,
    "code": "import numpy as np\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import ControllerFactory\n\n# Custom bounds for aggressive tuning\ncustom_bounds = {\n    'lower': np.array([1.0, 1.0, 1.0, 1.0, 5.0, 0.5]),\n    'upper': np.array([25.0, 25.0, 25.0, 25.0, 150.0, 15.0])\n}\n\n# Create factory and run optimization\ndef create_controller(gains):\n    return ControllerFactory.create_controller('classical_smc', gains)\n\npso_tuner = PSOTuner(create_controller, config, seed=42)\nresults = pso_tuner.optimize(\n    bounds=(custom_bounds['lower'], custom_bounds['upper']),\n    n_particles=75,\n    n_iterations=150\n)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "113ef026"
  },
  {
    "id": "pso_optimization_workflow_user_guide_6_e8bdd343",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 6,
    "code": "import concurrent.futures\nimport subprocess\nfrom pathlib import Path\n\ndef optimize_controller(controller_type):\n    \"\"\"Optimize single controller type.\"\"\"\n    cmd = [\n        'python', 'simulate.py',\n        '--ctrl', controller_type,\n        '--run-pso',\n        '--save', f'{controller_type}_parallel.json'\n    ]\n\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    return controller_type, result.returncode == 0, result.stdout\n\ndef parallel_optimization():\n    \"\"\"Run parallel PSO optimization for multiple controllers.\"\"\"\n    controllers = ['classical_smc', 'sta_smc', 'adaptive_smc']\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n        futures = {executor.submit(optimize_controller, ctrl): ctrl for ctrl in controllers}\n\n        for future in concurrent.futures.as_completed(futures):\n            controller = futures[future]\n            ctrl_name, success, output = future.result()\n\n            if success:\n                print(f\"\u2713 {ctrl_name} optimization completed\")\n            else:\n                print(f\"\u2717 {ctrl_name} optimization failed\")\n                print(f\"Error output: {output}\")\n\nif __name__ == \"__main__\":\n    parallel_optimization()",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8bdd343"
  },
  {
    "id": "pso_optimization_workflow_user_guide_7_ee343e83",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 7,
    "code": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndef compare_optimization_results(result_files):\n    \"\"\"Compare PSO optimization results across controllers.\"\"\"\n\n    results = {}\n    for file in result_files:\n        with open(file, 'r') as f:\n            data = json.load(f)\n            controller_type = data['controller_type']\n            results[controller_type] = data\n\n    # Create comparison plot\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n    # Plot 1: Best cost comparison\n    controllers = list(results.keys())\n    costs = [results[ctrl]['best_cost'] for ctrl in controllers]\n\n    axes[0, 0].bar(controllers, costs)\n    axes[0, 0].set_title('Best Cost Comparison')\n    axes[0, 0].set_ylabel('Cost')\n    axes[0, 0].tick_params(axis='x', rotation=45)\n\n    # Plot 2: Convergence comparison\n    for ctrl in controllers:\n        if 'cost_history' in results[ctrl]:\n            axes[0, 1].plot(results[ctrl]['cost_history'], label=ctrl)\n    axes[0, 1].set_title('Convergence History')\n    axes[0, 1].set_xlabel('Iteration')\n    axes[0, 1].set_ylabel('Cost')\n    axes[0, 1].legend()\n\n    # Plot 3: Performance metrics\n    metrics = ['ise', 'control_effort', 'control_rate', 'sliding_energy']\n    x = np.arange(len(metrics))\n    width = 0.2\n\n    for i, ctrl in enumerate(controllers):\n        if 'performance_metrics' in results[ctrl]:\n            values = [results[ctrl]['performance_metrics'].get(m, 0) for m in metrics]\n            axes[1, 0].bar(x + i*width, values, width, label=ctrl)\n\n    axes[1, 0].set_title('Performance Metrics')\n    axes[1, 0].set_xlabel('Metrics')\n    axes[1, 0].set_xticks(x + width)\n    axes[1, 0].set_xticklabels(metrics, rotation=45)\n    axes[1, 0].legend()\n\n    # Plot 4: Optimization info\n    info_data = []\n    for ctrl in controllers:\n        info = results[ctrl]['optimization_info']\n        info_data.append([\n            info['n_iterations'],\n            info.get('convergence_iteration', info['n_iterations']),\n            info.get('final_diversity', 0)\n        ])\n\n    info_array = np.array(info_data)\n    x = np.arange(len(controllers))\n\n    axes[1, 1].bar(x - 0.2, info_array[:, 0], 0.4, label='Total Iterations')\n    axes[1, 1].bar(x + 0.2, info_array[:, 1], 0.4, label='Convergence Iteration')\n    axes[1, 1].set_title('Optimization Statistics')\n    axes[1, 1].set_xlabel('Controller')\n    axes[1, 1].set_xticks(x)\n    axes[1, 1].set_xticklabels(controllers, rotation=45)\n    axes[1, 1].legend()\n\n    plt.tight_layout()\n    plt.savefig('optimization_comparison.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    return results\n\n# Usage example\nresult_files = [\n    'classical_smc_optimized.json',\n    'sta_smc_optimized.json',\n    'adaptive_smc_optimized.json'\n]\n\ncomparison = compare_optimization_results(result_files)",
    "lines": 87,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee343e83"
  },
  {
    "id": "pso_optimization_workflow_user_guide_8_fc2caf7c",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Tighten parameter bounds\ncustom_bounds = {\n    'lower': [1.0, 1.0, 1.0, 1.0, 5.0, 0.5],   # More conservative\n    'upper': [10.0, 10.0, 10.0, 10.0, 50.0, 5.0]  # Reduced ranges\n}\n\n# Increase stability weight in cost function\nstability_focused_weights = {\n    'state_error': 1.0,\n    'control_effort': 0.01,\n    'control_rate': 0.001,\n    'stability': 50.0  # Heavily penalize instability\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc2caf7c"
  },
  {
    "id": "pso_optimization_workflow_user_guide_9_45cbcd8f",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# HIL optimization with realistic constraints\nhil_config = {\n    'max_control_time': 0.001,  # 1ms control computation limit\n    'actuator_bandwidth': 100,   # 100 Hz actuator bandwidth\n    'sensor_noise_std': 0.01,    # 1% measurement noise\n    'communication_delay': 0.0005  # 0.5ms delay\n}\n\n# Run optimization with HIL constraints\nresults = pso_tuner.optimize(\n    bounds=bounds,\n    hil_constraints=hil_config,\n    real_time_validation=True\n)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45cbcd8f"
  },
  {
    "id": "pso_optimization_workflow_user_guide_10_bba90572",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_optimized_controller(gains_file):\n    \"\"\"Comprehensive validation before deployment.\"\"\"\n\n    checks = {\n        'stability_margins': False,\n        'actuator_limits': False,\n        'robustness': False,\n        'performance': False\n    }\n\n    # Load optimized gains\n    with open(gains_file, 'r') as f:\n        data = json.load(f)\n\n    gains = data['best_gains']\n    controller_type = data['controller_type']\n\n    # Stability margin check\n    # ... implementation details\n\n    # Actuator saturation check\n    # ... implementation details\n\n    # Robustness analysis\n    # ... implementation details\n\n    # Performance verification\n    # ... implementation details\n\n    return all(checks.values()), checks\n\n# Usage\nis_ready, check_results = validate_optimized_controller('optimized_gains.json')\nif is_ready:\n    print(\"\u2713 Controller ready for production deployment\")\nelse:\n    print(\"\u2717 Validation failed:\", check_results)",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bba90572"
  },
  {
    "id": "pso_optimization_workflow_user_guide_11_f3e3446f",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 11,
    "code": "from src.optimization.multi_objective import ParetoFrontPSO\n\n# Define multiple objectives\nobjectives = {\n    'performance': {'weight': 1.0, 'minimize': True},\n    'energy': {'weight': 0.01, 'minimize': True},\n    'robustness': {'weight': 10.0, 'minimize': True}\n}\n\n# Multi-objective PSO\nmo_pso = ParetoFrontPSO(\n    controller_factory=create_controller,\n    objectives=objectives,\n    config=config\n)\n\n# Get Pareto front\npareto_solutions = mo_pso.optimize(\n    bounds=bounds,\n    n_particles=100,\n    n_iterations=200\n)\n\n# Select solution based on preferences\nselected_solution = mo_pso.select_solution(\n    pareto_solutions,\n    preferences={'performance': 0.6, 'energy': 0.2, 'robustness': 0.2}\n)",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3e3446f"
  },
  {
    "id": "pso_optimization_workflow_user_guide_12_854d3209",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptivePSO(PSOTuner):\n    \"\"\"PSO with adaptive parameters based on convergence.\"\"\"\n\n    def adapt_parameters(self, iteration, diversity, improvement):\n        \"\"\"Adapt PSO parameters during optimization.\"\"\"\n\n        if diversity < 0.01:  # Low diversity\n            self.cognitive_weight *= 1.1  # Increase exploration\n            self.social_weight *= 0.9\n\n        if improvement < 0.001:  # Slow improvement\n            self.inertia_weight *= 0.95  # Decrease inertia\n\n        # Restart mechanism for stagnation\n        if iteration > 50 and improvement < 1e-6:\n            self.restart_particles(fraction=0.3)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "854d3209"
  },
  {
    "id": "pso_optimization_workflow_user_guide_13_b5f916f6",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 13,
    "code": "def hybrid_pso_local_search(controller_factory, config):\n    \"\"\"Combine PSO global search with local refinement.\"\"\"\n\n    # Phase 1: Global PSO search\n    pso_tuner = PSOTuner(controller_factory, config)\n    pso_results = pso_tuner.optimize(\n        bounds=bounds,\n        n_particles=50,\n        n_iterations=100\n    )\n\n    # Phase 2: Local refinement around best solution\n    from scipy.optimize import minimize\n\n    def local_objective(gains):\n        controller = controller_factory(gains)\n        # Simulate and return cost\n        cost = simulate_and_evaluate(controller)\n        return cost\n\n    # Local optimization starting from PSO result\n    local_result = minimize(\n        local_objective,\n        x0=pso_results['best_gains'],\n        bounds=[(bounds[0][i], bounds[1][i]) for i in range(len(bounds[0]))],\n        method='L-BFGS-B'\n    )\n\n    return {\n        'pso_result': pso_results,\n        'local_result': local_result,\n        'final_gains': local_result.x,\n        'final_cost': local_result.fun\n    }",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5f916f6"
  },
  {
    "id": "pso_optimization_workflow_user_guide_14_ff1cc65f",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimization_callback(iteration, best_cost, best_position, **kwargs):\n    \"\"\"Real-time optimization monitoring callback.\"\"\"\n\n    # Log progress\n    print(f\"Iteration {iteration:3d}: Cost = {best_cost:.6f}\")\n\n    # Update visualization\n    plt.scatter(iteration, best_cost, c='blue', alpha=0.7)\n    plt.xlabel('Iteration')\n    plt.ylabel('Best Cost')\n    plt.pause(0.01)\n\n    # Save intermediate results\n    if iteration % 20 == 0:\n        save_checkpoint(iteration, best_position, best_cost)\n\n    # Early stopping condition\n    if best_cost < 10.0:  # Target achieved\n        return True  # Stop optimization\n\n    return False  # Continue optimization\n\n# Use callback in optimization\nresults = pso_tuner.optimize(\n    bounds=bounds,\n    callback=optimization_callback,\n    n_particles=50,\n    n_iterations=200\n)",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ff1cc65f"
  },
  {
    "id": "pso_optimization_workflow_user_guide_15_b8fe78f9",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_convergence(cost_history, window_size=10):\n    \"\"\"Analyze PSO convergence characteristics.\"\"\"\n\n    analysis = {}\n\n    # Convergence rate\n    if len(cost_history) > window_size:\n        recent_improvement = cost_history[-window_size] - cost_history[-1]\n        analysis['improvement_rate'] = recent_improvement / window_size\n\n    # Stagnation detection\n    if len(cost_history) > 20:\n        recent_costs = cost_history[-20:]\n        stagnation = np.std(recent_costs) < 0.001\n        analysis['is_stagnant'] = stagnation\n\n    # Convergence quality\n    final_cost = cost_history[-1]\n    if final_cost < 50:\n        analysis['convergence_quality'] = 'excellent'\n    elif final_cost < 100:\n        analysis['convergence_quality'] = 'good'\n    elif final_cost < 200:\n        analysis['convergence_quality'] = 'acceptable'\n    else:\n        analysis['convergence_quality'] = 'poor'\n\n    return analysis\n\n# Analyze optimization results\nconvergence_analysis = analyze_convergence(results['cost_history'])\nprint(f\"Convergence Quality: {convergence_analysis['convergence_quality']}\")",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b8fe78f9"
  },
  {
    "id": "pso_optimization_workflow_user_guide_16_a6237f90",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 16,
    "code": "import time\nimport psutil\nimport os\n\nclass OptimizationProfiler:\n    \"\"\"Profile PSO optimization performance.\"\"\"\n\n    def __init__(self):\n        self.start_time = None\n        self.memory_samples = []\n        self.cpu_samples = []\n\n    def start_profiling(self):\n        \"\"\"Start performance profiling.\"\"\"\n        self.start_time = time.time()\n        self.process = psutil.Process(os.getpid())\n\n    def sample_performance(self):\n        \"\"\"Sample current performance metrics.\"\"\"\n        if self.start_time:\n            self.memory_samples.append(self.process.memory_info().rss / 1024 / 1024)  # MB\n            self.cpu_samples.append(self.process.cpu_percent())\n\n    def get_summary(self):\n        \"\"\"Get performance summary.\"\"\"\n        total_time = time.time() - self.start_time\n\n        return {\n            'total_time': total_time,\n            'peak_memory_mb': max(self.memory_samples) if self.memory_samples else 0,\n            'avg_cpu_percent': np.mean(self.cpu_samples) if self.cpu_samples else 0,\n            'memory_trend': np.polyfit(range(len(self.memory_samples)),\n                                     self.memory_samples, 1)[0] if len(self.memory_samples) > 1 else 0\n        }\n\n# Usage in optimization\nprofiler = OptimizationProfiler()\nprofiler.start_profiling()\n\n# Optimization with profiling callback\ndef profiling_callback(iteration, **kwargs):\n    profiler.sample_performance()\n    return False\n\nresults = pso_tuner.optimize(\n    bounds=bounds,\n    callback=profiling_callback,\n    n_particles=50,\n    n_iterations=100\n)\n\nperformance_summary = profiler.get_summary()\nprint(f\"Optimization completed in {performance_summary['total_time']:.1f} seconds\")\nprint(f\"Peak memory usage: {performance_summary['peak_memory_mb']:.1f} MB\")",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6237f90"
  },
  {
    "id": "pso_optimization_workflow_user_guide_17_295cba06",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Systematic bounds exploration\nbounds_sets = [\n    ([0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [10, 10, 10, 10, 50, 5]),    # Conservative\n    ([0.5, 0.5, 0.5, 0.5, 1.0, 0.5], [20, 20, 20, 20, 100, 10]),  # Standard\n    ([1.0, 1.0, 1.0, 1.0, 5.0, 1.0], [30, 30, 30, 30, 150, 15])   # Aggressive\n]\n\nbest_overall = None\nbest_cost = float('inf')\n\nfor i, (lower, upper) in enumerate(bounds_sets):\n    print(f\"Testing bounds set {i+1}/3...\")\n\n    results = pso_tuner.optimize(\n        bounds=(np.array(lower), np.array(upper)),\n        n_particles=50,\n        n_iterations=100\n    )\n\n    if results['best_cost'] < best_cost:\n        best_cost = results['best_cost']\n        best_overall = results\n\n    print(f\"Bounds set {i+1}: Best cost = {results['best_cost']:.3f}\")\n\nprint(f\"Overall best cost: {best_cost:.3f}\")",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "295cba06"
  },
  {
    "id": "pso_optimization_workflow_user_guide_18_aa2cf4b4",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\noptimization_report = {\n    'metadata': {\n        'date': '2024-01-15',\n        'operator': 'user_name',\n        'objective': 'Optimize Classical SMC for improved settling time',\n        'system_version': 'v2.1.0'\n    },\n    'configuration': {\n        'controller_type': 'classical_smc',\n        'pso_parameters': {...},\n        'bounds': {...},\n        'cost_weights': {...}\n    },\n    'results': {\n        'best_gains': [...],\n        'best_cost': 67.34,\n        'convergence_iteration': 78,\n        'total_iterations': 100\n    },\n    'validation': {\n        'stability_margin': 0.65,\n        'settling_time': 2.3,\n        'overshoot': 0.05,\n        'robustness_score': 0.82\n    },\n    'recommendations': [\n        'Deploy gains for production use',\n        'Monitor performance during initial operation',\n        'Schedule re-optimization in 6 months'\n    ]\n}\n\n# Save comprehensive report\nwith open('optimization_report.json', 'w') as f:\n    json.dump(optimization_report, f, indent=2)",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa2cf4b4"
  },
  {
    "id": "pso_optimization_workflow_user_guide_19_7a3f88be",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 19,
    "code": "# Save intermediate results every 20 iterations\ndef checkpoint_callback(iteration, best_position, best_cost, **kwargs):\n    if iteration % 20 == 0:\n        np.save(f'checkpoint_{iteration}.npy', {\n            'iteration': iteration,\n            'best_position': best_position,\n            'best_cost': best_cost\n        })",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a3f88be"
  },
  {
    "id": "pso_optimization_workflow_user_guide_20_81fac7df",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ncontroller_configs = {\n    'classical_smc': {'bounds': [...], 'weights': {...}},\n    'sta_smc': {'bounds': [...], 'weights': {...}},\n    # ... etc\n}\n\nfor ctrl_type, config in controller_configs.items():\n    optimize_with_config(ctrl_type, config)",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81fac7df"
  },
  {
    "id": "pso_optimization_workflow_user_guide_21_85262617",
    "file": "docs\\pso_optimization_workflow_user_guide.md",
    "index": 21,
    "code": "def custom_cost_function(self, trajectory_data):\n    \"\"\"Custom cost function implementation.\"\"\"\n    t, x, u, sigma = trajectory_data\n\n    # Custom performance metrics\n    custom_metric = compute_custom_performance(x, u)\n\n    # Combine with standard metrics\n    standard_cost = self._compute_cost_from_traj(t, x, u, sigma)\n\n    return standard_cost + 0.1 * custom_metric",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85262617"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_1_ba116d14",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"PSO System Health Checker\"\"\"\n\nimport numpy as np\nimport json\nimport subprocess\nimport psutil\nimport time\nfrom pathlib import Path\nfrom src.config import load_config\nfrom src.controllers.factory import ControllerFactory\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\n\nclass PSOHealthChecker:\n    \"\"\"Comprehensive PSO system health assessment.\"\"\"\n\n    def __init__(self, config_path=\"config.yaml\"):\n        self.config_path = config_path\n        self.health_report = {\n            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n            'overall_status': 'unknown',\n            'component_status': {},\n            'performance_metrics': {},\n            'issues_found': [],\n            'recommendations': []\n        }\n\n    def run_comprehensive_check(self):\n        \"\"\"Execute complete health check suite.\"\"\"\n        print(\"\ud83d\udd0d Starting PSO System Health Check...\")\n\n        # Component checks\n        self._check_configuration()\n        self._check_controller_factory()\n        self._check_pso_engine()\n        self._check_simulation_engine()\n        self._check_dependencies()\n        self._check_system_resources()\n\n        # Performance benchmarks\n        self._benchmark_performance()\n\n        # Overall assessment\n        self._assess_overall_health()\n\n        return self.health_report\n\n    def _check_configuration(self):\n        \"\"\"Validate PSO configuration integrity.\"\"\"\n        print(\"  \ud83d\udccb Checking configuration...\")\n\n        try:\n            config = load_config(self.config_path)\n            issues = []\n\n            # Check required sections\n            required_sections = ['pso', 'cost_function', 'simulation', 'controllers']\n            for section in required_sections:\n                if not hasattr(config, section):\n                    issues.append(f\"Missing configuration section: {section}\")\n\n            # Validate PSO parameters\n            if hasattr(config, 'pso'):\n                pso_cfg = config.pso\n                if not (10 <= getattr(pso_cfg, 'n_particles', 0) <= 200):\n                    issues.append(\"PSO n_particles outside recommended range [10, 200]\")\n                if not (20 <= getattr(pso_cfg, 'n_iterations', 0) <= 1000):\n                    issues.append(\"PSO n_iterations outside recommended range [20, 1000]\")\n\n            # Validate bounds\n            if hasattr(config.pso, 'bounds'):\n                for ctrl_type in ['classical_smc', 'sta_smc', 'adaptive_smc']:\n                    if hasattr(config.pso.bounds, ctrl_type):\n                        bounds = getattr(config.pso.bounds, ctrl_type)\n                        lower = np.array(bounds.lower)\n                        upper = np.array(bounds.upper)\n                        if not np.all(lower < upper):\n                            issues.append(f\"Invalid bounds for {ctrl_type}: lower >= upper\")\n\n            self.health_report['component_status']['configuration'] = {\n                'status': 'healthy' if not issues else 'issues',\n                'issues': issues\n            }\n\n        except Exception as e:\n            self.health_report['component_status']['configuration'] = {\n                'status': 'failed',\n                'error': str(e)\n            }\n\n    def _check_controller_factory(self):\n        \"\"\"Test controller factory functionality.\"\"\"\n        print(\"  \ud83c\udfed Checking controller factory...\")\n\n        try:\n            issues = []\n            test_results = {}\n\n            # Test each controller type\n            controller_tests = {\n                'classical_smc': np.array([5.0, 3.0, 7.0, 2.0, 25.0, 1.0]),\n                'sta_smc': np.array([8.0, 4.0, 12.0, 6.0, 4.85, 3.43]),\n                'adaptive_smc': np.array([5.0, 3.0, 7.0, 2.0, 1.5]),\n                'hybrid_adaptive_sta_smc': np.array([5.0, 5.0, 5.0, 0.5])\n            }\n\n            for ctrl_type, test_gains in controller_tests.items():\n                try:\n                    controller = ControllerFactory.create_controller(ctrl_type, test_gains)\n\n                    # Test required attributes\n                    if not hasattr(controller, 'max_force'):\n                        issues.append(f\"{ctrl_type}: Missing max_force property\")\n                    if not hasattr(controller, 'compute_control'):\n                        issues.append(f\"{ctrl_type}: Missing compute_control method\")\n\n                    # Test control computation\n                    test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n                    control = controller.compute_control(test_state)\n\n                    if not np.isfinite(control):\n                        issues.append(f\"{ctrl_type}: Non-finite control output\")\n\n                    test_results[ctrl_type] = 'passed'\n\n                except Exception as e:\n                    issues.append(f\"{ctrl_type}: Factory creation failed - {str(e)}\")\n                    test_results[ctrl_type] = 'failed'\n\n            self.health_report['component_status']['controller_factory'] = {\n                'status': 'healthy' if not issues else 'issues',\n                'test_results': test_results,\n                'issues': issues\n            }\n\n        except Exception as e:\n            self.health_report['component_status']['controller_factory'] = {\n                'status': 'failed',\n                'error': str(e)\n            }\n\n    def _check_pso_engine(self):\n        \"\"\"Test PSO optimization engine.\"\"\"\n        print(\"  \ud83d\udd2c Checking PSO engine...\")\n\n        try:\n            config = load_config(self.config_path)\n\n            # Create test factory\n            def test_factory(gains):\n                return ControllerFactory.create_controller('classical_smc', gains)\n\n            # Initialize PSO tuner\n            pso_tuner = PSOTuner(test_factory, config, seed=42)\n\n            # Quick optimization test (minimal resources)\n            test_bounds = (\n                np.array([1.0, 1.0, 1.0, 1.0, 1.0, 0.1]),\n                np.array([10.0, 10.0, 10.0, 10.0, 50.0, 5.0])\n            )\n\n            start_time = time.time()\n            results = pso_tuner.optimize(\n                bounds=test_bounds,\n                n_particles=10,\n                n_iterations=5,\n                verbose=False\n            )\n            optimization_time = time.time() - start_time\n\n            issues = []\n            if not results.get('success', False):\n                issues.append(\"PSO optimization test failed\")\n            if optimization_time > 30:  # Should complete quickly\n                issues.append(f\"PSO test took too long: {optimization_time:.1f}s\")\n            if not np.all(np.isfinite(results.get('best_gains', [np.nan]))):\n                issues.append(\"PSO returned non-finite gains\")\n\n            self.health_report['component_status']['pso_engine'] = {\n                'status': 'healthy' if not issues else 'issues',\n                'test_time': optimization_time,\n                'test_result': results.get('success', False),\n                'issues': issues\n            }\n\n        except Exception as e:\n            self.health_report['component_status']['pso_engine'] = {\n                'status': 'failed',\n                'error': str(e)\n            }\n\n    def _check_simulation_engine(self):\n        \"\"\"Test vectorized simulation engine.\"\"\"\n        print(\"  \ud83c\udfaf Checking simulation engine...\")\n\n        try:\n            from src.simulation.engines.vector_sim import simulate_system_batch\n\n            # Test controller factory\n            def test_factory(gains):\n                return ControllerFactory.create_controller('classical_smc', gains)\n\n            # Test particles\n            test_particles = np.array([\n                [5.0, 3.0, 7.0, 2.0, 25.0, 1.0],\n                [4.0, 2.5, 6.0, 1.8, 20.0, 0.8]\n            ])\n\n            start_time = time.time()\n            result = simulate_system_batch(\n                controller_factory=test_factory,\n                particles=test_particles,\n                sim_time=1.0,  # Short simulation\n                dt=0.01,\n                u_max=150.0\n            )\n            sim_time = time.time() - start_time\n\n            issues = []\n            if result is None:\n                issues.append(\"Simulation returned None\")\n            else:\n                t, x_batch, u_batch, sigma_batch = result\n                if not np.all(np.isfinite(x_batch)):\n                    issues.append(\"Simulation produced non-finite states\")\n                if not np.all(np.isfinite(u_batch)):\n                    issues.append(\"Simulation produced non-finite controls\")\n\n            if sim_time > 5.0:  # Should be fast for short simulation\n                issues.append(f\"Simulation too slow: {sim_time:.1f}s\")\n\n            self.health_report['component_status']['simulation_engine'] = {\n                'status': 'healthy' if not issues else 'issues',\n                'test_time': sim_time,\n                'issues': issues\n            }\n\n        except Exception as e:\n            self.health_report['component_status']['simulation_engine'] = {\n                'status': 'failed',\n                'error': str(e)\n            }\n\n    def _check_dependencies(self):\n        \"\"\"Check critical dependencies.\"\"\"\n        print(\"  \ud83d\udce6 Checking dependencies...\")\n\n        required_packages = {\n            'numpy': '1.20.0',\n            'scipy': '1.7.0',\n            'matplotlib': '3.3.0',\n            'pyyaml': '5.4.0'\n        }\n\n        issues = []\n        installed_versions = {}\n\n        for package, min_version in required_packages.items():\n            try:\n                module = __import__(package)\n                version = getattr(module, '__version__', 'unknown')\n                installed_versions[package] = version\n\n                # Simple version comparison (for basic cases)\n                if version != 'unknown':\n                    try:\n                        from packaging import version as pkg_version\n                        if pkg_version.parse(version) < pkg_version.parse(min_version):\n                            issues.append(f\"{package} version {version} < required {min_version}\")\n                    except ImportError:\n                        pass  # Skip version comparison if packaging not available\n\n            except ImportError:\n                issues.append(f\"Missing required package: {package}\")\n                installed_versions[package] = 'not installed'\n\n        self.health_report['component_status']['dependencies'] = {\n            'status': 'healthy' if not issues else 'issues',\n            'installed_versions': installed_versions,\n            'issues': issues\n        }\n\n    def _check_system_resources(self):\n        \"\"\"Check system resource availability.\"\"\"\n        print(\"  \ud83d\udcbb Checking system resources...\")\n\n        # Memory check\n        memory = psutil.virtual_memory()\n        available_gb = memory.available / (1024**3)\n\n        # CPU check\n        cpu_count = psutil.cpu_count()\n        cpu_percent = psutil.cpu_percent(interval=1)\n\n        # Disk space check\n        disk = psutil.disk_usage('.')\n        free_gb = disk.free / (1024**3)\n\n        issues = []\n        if available_gb < 1.0:\n            issues.append(f\"Low memory: {available_gb:.1f}GB available\")\n        if cpu_percent > 90:\n            issues.append(f\"High CPU usage: {cpu_percent:.1f}%\")\n        if free_gb < 1.0:\n            issues.append(f\"Low disk space: {free_gb:.1f}GB free\")\n\n        self.health_report['component_status']['system_resources'] = {\n            'status': 'healthy' if not issues else 'issues',\n            'memory_gb': available_gb,\n            'cpu_percent': cpu_percent,\n            'disk_free_gb': free_gb,\n            'cpu_count': cpu_count,\n            'issues': issues\n        }\n\n    def _benchmark_performance(self):\n        \"\"\"Run performance benchmarks.\"\"\"\n        print(\"  \u26a1 Running performance benchmarks...\")\n\n        try:\n            # Quick PSO benchmark\n            config = load_config(self.config_path)\n\n            def benchmark_factory(gains):\n                return ControllerFactory.create_controller('classical_smc', gains)\n\n            pso_tuner = PSOTuner(benchmark_factory, config, seed=42)\n\n            # Benchmark optimization iteration\n            start_time = time.time()\n            results = pso_tuner.optimize(\n                bounds=(np.array([1.0, 1.0, 1.0, 1.0, 1.0, 0.1]),\n                       np.array([10.0, 10.0, 10.0, 10.0, 50.0, 5.0])),\n                n_particles=20,\n                n_iterations=10\n            )\n            benchmark_time = time.time() - start_time\n\n            self.health_report['performance_metrics'] = {\n                'benchmark_time': benchmark_time,\n                'time_per_iteration': benchmark_time / 10,\n                'particles_per_second': (20 * 10) / benchmark_time,\n                'optimization_success': results.get('success', False)\n            }\n\n        except Exception as e:\n            self.health_report['performance_metrics'] = {\n                'benchmark_failed': str(e)\n            }\n\n    def _assess_overall_health(self):\n        \"\"\"Assess overall system health.\"\"\"\n        component_statuses = [\n            comp['status'] for comp in self.health_report['component_status'].values()\n        ]\n\n        failed_components = sum(1 for status in component_statuses if status == 'failed')\n        issue_components = sum(1 for status in component_statuses if status == 'issues')\n\n        if failed_components > 0:\n            self.health_report['overall_status'] = 'critical'\n            self.health_report['recommendations'].append(\"Critical components failed - system unusable\")\n        elif issue_components > 2:\n            self.health_report['overall_status'] = 'degraded'\n            self.health_report['recommendations'].append(\"Multiple issues detected - maintenance required\")\n        elif issue_components > 0:\n            self.health_report['overall_status'] = 'warnings'\n            self.health_report['recommendations'].append(\"Minor issues detected - monitoring recommended\")\n        else:\n            self.health_report['overall_status'] = 'healthy'\n            self.health_report['recommendations'].append(\"System operating normally\")\n\n        # Performance recommendations\n        perf = self.health_report.get('performance_metrics', {})\n        if perf.get('time_per_iteration', 0) > 2.0:\n            self.health_report['recommendations'].append(\"Slow optimization performance - consider system tuning\")\n\n    def save_report(self, filename='pso_health_report.json'):\n        \"\"\"Save health report to file.\"\"\"\n        with open(filename, 'w') as f:\n            json.dump(self.health_report, f, indent=2)\n        print(f\"\ud83d\udcca Health report saved to: {filename}\")\n\n    def print_summary(self):\n        \"\"\"Print health check summary.\"\"\"\n        status_colors = {\n            'healthy': '\u2705',\n            'warnings': '\u26a0\ufe0f',\n            'degraded': '\ud83d\udd36',\n            'critical': '\u274c',\n            'failed': '\ud83d\udca5'\n        }\n\n        print(f\"\\n{'='*60}\")\n        print(f\"\ud83c\udfe5 PSO SYSTEM HEALTH REPORT\")\n        print(f\"{'='*60}\")\n        print(f\"Overall Status: {status_colors.get(self.health_report['overall_status'], '\u2753')} {self.health_report['overall_status'].upper()}\")\n        print(f\"Timestamp: {self.health_report['timestamp']}\")\n        print(f\"\\n\ud83d\udd27 Component Status:\")\n\n        for component, status_info in self.health_report['component_status'].items():\n            status = status_info['status']\n            print(f\"  {status_colors.get(status, '\u2753')} {component}: {status}\")\n            if 'issues' in status_info and status_info['issues']:\n                for issue in status_info['issues']:\n                    print(f\"    - {issue}\")\n\n        print(f\"\\n\ud83d\udcc8 Performance Metrics:\")\n        perf = self.health_report.get('performance_metrics', {})\n        if 'time_per_iteration' in perf:\n            print(f\"  \u23f1\ufe0f  Time per iteration: {perf['time_per_iteration']:.2f}s\")\n            print(f\"  \ud83d\ude80 Particles per second: {perf['particles_per_second']:.1f}\")\n\n        print(f\"\\n\ud83d\udca1 Recommendations:\")\n        for rec in self.health_report['recommendations']:\n            print(f\"  \u2022 {rec}\")\n\n# Usage\nif __name__ == \"__main__\":\n    checker = PSOHealthChecker()\n    health_report = checker.run_comprehensive_check()\n    checker.print_summary()\n    checker.save_report()",
    "lines": 426,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba116d14"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_2_82e13df6",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 2,
    "code": "# Analyze convergence history\nimport json\nimport matplotlib.pyplot as plt\n\nwith open('optimization_results.json', 'r') as f:\n    results = json.load(f)\n\ncost_history = results.get('cost_history', [])\nplt.plot(cost_history)\nplt.title('PSO Convergence History')\nplt.xlabel('Iteration')\nplt.ylabel('Best Cost')\nplt.show()\n\n# Check final gains against bounds\ngains = results['best_gains']\nbounds = results.get('bounds', {})\nprint(f\"Final gains: {gains}\")\nprint(f\"At lower bound: {[g <= b+0.001 for g, b in zip(gains, bounds.get('lower', []))]}\")\nprint(f\"At upper bound: {[g >= b-0.001 for g, b in zip(gains, bounds.get('upper', []))]}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82e13df6"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_3_80eda3cb",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Profile optimization performance\nimport time\nimport psutil\nimport os\n\ndef profile_pso_iteration():\n    \"\"\"Profile single PSO iteration.\"\"\"\n    process = psutil.Process(os.getpid())\n\n    # Baseline measurements\n    start_time = time.time()\n    start_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n    # Run minimal PSO test\n    # ... PSO code here ...\n\n    end_time = time.time()\n    end_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n    print(f\"Iteration time: {end_time - start_time:.2f}s\")\n    print(f\"Memory usage: {end_memory:.1f}MB (\u0394{end_memory - start_memory:.1f}MB)\")\n    print(f\"CPU count: {psutil.cpu_count()}\")\n    print(f\"CPU usage: {psutil.cpu_percent()}%\")\n\nprofile_pso_iteration()",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80eda3cb"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_4_723850e3",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 4,
    "code": "# Check if Numba is available\n   try:\n       import numba\n       print(\"\u2705 Numba available for acceleration\")\n   except ImportError:\n       print(\"\u274c Numba not available - install with: pip install numba\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "723850e3"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_5_5f5a7ad6",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nimport gc\nimport psutil\nimport matplotlib.pyplot as plt\n\ndef monitor_memory_usage():\n    \"\"\"Monitor memory usage during optimization.\"\"\"\n    memory_samples = []\n    process = psutil.Process()\n\n    # Sample memory every 10 iterations (add to PSO callback)\n    def memory_callback(iteration, **kwargs):\n        if iteration % 10 == 0:\n            memory_mb = process.memory_info().rss / 1024 / 1024\n            memory_samples.append(memory_mb)\n            print(f\"Iteration {iteration}: Memory usage = {memory_mb:.1f}MB\")\n\n            # Force garbage collection\n            gc.collect()\n\n    return memory_callback, memory_samples\n\n# Use in optimization\ncallback, samples = monitor_memory_usage()\n# results = pso_tuner.optimize(callback=callback, ...)\n\n# Plot memory usage\nplt.plot(samples)\nplt.title('Memory Usage During Optimization')\nplt.xlabel('Sample')\nplt.ylabel('Memory (MB)')\nplt.show()",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5f5a7ad6"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_6_9f46a4a8",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n   import gc\n\n   def cleanup_callback(iteration, **kwargs):\n       if iteration % 20 == 0:\n           gc.collect()  # Force garbage collection\n       return False\n\n   results = pso_tuner.optimize(callback=cleanup_callback, ...)",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f46a4a8"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_7_0ffe3b64",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 7,
    "code": "# Use smaller data types\n   import numpy as np\n\n   # In PSO configuration\n   pso_config = {\n       'n_particles': 30,  # Reduce from 50\n       'store_history': False,  # Don't store full history\n       'dtype': np.float32  # Use 32-bit floats\n   }",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ffe3b64"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_8_2d8f2d5c",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 8,
    "code": "def diagnose_controller_stability(gains, controller_type):\n    \"\"\"Diagnose controller stability issues.\"\"\"\n    from src.controllers.factory import ControllerFactory\n    import numpy as np\n\n    # Create controller\n    controller = ControllerFactory.create_controller(controller_type, gains)\n\n    # Test with various states\n    test_states = [\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),  # Equilibrium\n        np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0]),  # Small perturbation\n        np.array([0.5, 0.3, 0.1, 0.0, 0.0, 0.0]),  # Large perturbation\n        np.array([0.1, 0.1, 0.0, 0.2, 0.2, 0.0])   # With velocities\n    ]\n\n    print(f\"\ud83d\udd0d Stability diagnosis for {controller_type}\")\n    print(f\"Gains: {gains}\")\n\n    for i, state in enumerate(test_states):\n        try:\n            control = controller.compute_control(state)\n            status = \"\u2705\" if np.isfinite(control) and abs(control) <= controller.max_force else \"\u274c\"\n            print(f\"Test {i+1}: {status} u = {control:.3f}, |u| <= {controller.max_force}\")\n        except Exception as e:\n            print(f\"Test {i+1}: \u274c Error: {e}\")\n\n    # Check gain ratios (controller-specific)\n    if controller_type == 'classical_smc':\n        lambda1, lambda2 = gains[1], gains[3]\n        K = gains[4]\n        print(f\"\u03bb\u2081/\u03bb\u2082 ratio: {lambda1/lambda2:.2f} (should be 0.5-2.0)\")\n        print(f\"K/\u03bb\u2081 ratio: {K/lambda1:.2f} (should be 5-50)\")\n\n# Usage\ndiagnose_controller_stability([5.0, 3.0, 7.0, 2.0, 25.0, 1.0], 'classical_smc')",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d8f2d5c"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_9_38c2db63",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n   def validate_gain_ratios(particles, controller_type):\n       \"\"\"Enhanced gain validation with ratio constraints.\"\"\"\n       valid = np.ones(particles.shape[0], dtype=bool)\n\n       if controller_type == 'classical_smc':\n           c1, lambda1, c2, lambda2, K, kd = particles.T\n\n           # Ratio constraints\n           valid &= (lambda1 / lambda2 > 0.5) & (lambda1 / lambda2 < 2.0)\n           valid &= (K / lambda1 > 5) & (K / lambda1 < 50)\n           valid &= (kd / K > 0.01) & (kd / K < 0.5)\n\n       return valid",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38c2db63"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_10_72860458",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizedPSOConfig:\n    \"\"\"Optimized PSO configurations for different scenarios.\"\"\"\n\n    @staticmethod\n    def fast_exploration():\n        \"\"\"Configuration for rapid initial exploration.\"\"\"\n        return {\n            'n_particles': 30,\n            'n_iterations': 50,\n            'cognitive_weight': 2.5,\n            'social_weight': 0.5,\n            'inertia_weight': 0.9,\n            'velocity_clamp': [0.2, 0.8]\n        }\n\n    @staticmethod\n    def precision_optimization():\n        \"\"\"Configuration for high-precision results.\"\"\"\n        return {\n            'n_particles': 100,\n            'n_iterations': 300,\n            'cognitive_weight': 1.49445,\n            'social_weight': 1.49445,\n            'inertia_weight': 0.729,\n            'w_schedule': [0.9, 0.4],\n            'tolerance': 1e-8\n        }\n\n    @staticmethod\n    def balanced_performance():\n        \"\"\"Configuration balancing speed and quality.\"\"\"\n        return {\n            'n_particles': 50,\n            'n_iterations': 150,\n            'cognitive_weight': 1.8,\n            'social_weight': 1.2,\n            'inertia_weight': 0.8,\n            'w_schedule': [0.8, 0.3],\n            'velocity_clamp': [0.1, 0.5]\n        }\n\n# Usage\ndef optimize_with_config(controller_type, config_type='balanced'):\n    \"\"\"Optimize controller with specific PSO configuration.\"\"\"\n    from src.optimization.algorithms.pso_optimizer import PSOTuner\n\n    config_map = {\n        'fast': OptimizedPSOConfig.fast_exploration(),\n        'precision': OptimizedPSOConfig.precision_optimization(),\n        'balanced': OptimizedPSOConfig.balanced_performance()\n    }\n\n    pso_config = config_map[config_type]\n\n    # Apply configuration and run optimization\n    # ... implementation details",
    "lines": 59,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72860458"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_11_cdc09fa6",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptivePSOTuner(PSOTuner):\n    \"\"\"PSO tuner with adaptive parameter adjustment.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.stagnation_threshold = 20\n        self.diversity_threshold = 0.01\n        self.restart_fraction = 0.3\n\n    def adaptive_callback(self, iteration, best_cost, best_position, **kwargs):\n        \"\"\"Adaptive PSO parameter adjustment callback.\"\"\"\n\n        # Get swarm statistics\n        diversity = kwargs.get('diversity', 0)\n        cost_history = kwargs.get('cost_history', [])\n\n        # Detect stagnation\n        if len(cost_history) > self.stagnation_threshold:\n            recent_improvement = cost_history[-self.stagnation_threshold] - cost_history[-1]\n            if recent_improvement < 1e-6:\n                print(f\"\ud83d\udd04 Stagnation detected at iteration {iteration} - adapting parameters\")\n                self._adapt_for_stagnation()\n\n        # Detect low diversity\n        if diversity < self.diversity_threshold:\n            print(f\"\ud83c\udf1f Low diversity detected at iteration {iteration} - increasing exploration\")\n            self._adapt_for_low_diversity()\n\n        # Convergence acceleration\n        if iteration > 100 and iteration % 50 == 0:\n            self._adapt_for_convergence(iteration)\n\n        return False  # Continue optimization\n\n    def _adapt_for_stagnation(self):\n        \"\"\"Adapt parameters for stagnation recovery.\"\"\"\n        # Increase cognitive weight, decrease social weight\n        self.cognitive_weight *= 1.2\n        self.social_weight *= 0.8\n\n        # Restart some particles\n        n_restart = int(self.n_particles * self.restart_fraction)\n        # ... particle restart implementation\n\n    def _adapt_for_low_diversity(self):\n        \"\"\"Adapt parameters for diversity enhancement.\"\"\"\n        # Increase inertia weight temporarily\n        self.inertia_weight = min(0.9, self.inertia_weight * 1.1)\n\n        # Increase velocity limits\n        if hasattr(self, 'velocity_clamp'):\n            self.velocity_clamp = [v * 1.2 for v in self.velocity_clamp]\n\n    def _adapt_for_convergence(self, iteration):\n        \"\"\"Adapt parameters for convergence acceleration.\"\"\"\n        progress = iteration / self.max_iterations\n\n        # Linear adaptation schedule\n        self.inertia_weight = 0.9 - 0.5 * progress\n        self.cognitive_weight = 2.0 - 0.5 * progress\n        self.social_weight = 0.5 + 1.5 * progress",
    "lines": 64,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cdc09fa6"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_12_dcb790ad",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 12,
    "code": "import multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nimport numpy as np\n\nclass ParallelPSOOptimizer:\n    \"\"\"PSO optimizer with parallel fitness evaluation.\"\"\"\n\n    def __init__(self, controller_factory, config, n_processes=None):\n        self.controller_factory = controller_factory\n        self.config = config\n        self.n_processes = n_processes or mp.cpu_count()\n\n    def parallel_fitness_evaluation(self, particles):\n        \"\"\"Evaluate fitness for particles in parallel.\"\"\"\n\n        def evaluate_single_particle(gains):\n            \"\"\"Evaluate single particle fitness.\"\"\"\n            try:\n                controller = self.controller_factory(gains)\n                # Simulate and compute cost\n                cost = self._simulate_and_evaluate(controller)\n                return cost\n            except Exception as e:\n                return float('inf')  # Penalty for failed evaluation\n\n        # Parallel evaluation\n        with ProcessPoolExecutor(max_workers=self.n_processes) as executor:\n            fitness_values = list(executor.map(evaluate_single_particle, particles))\n\n        return np.array(fitness_values)\n\n    def _simulate_and_evaluate(self, controller):\n        \"\"\"Simulate controller and compute cost.\"\"\"\n        # Implementation depends on simulation engine\n        # This is a placeholder for the actual simulation\n        pass\n\n# Usage\ndef parallel_optimization(controller_type, n_processes=4):\n    \"\"\"Run PSO optimization with parallel processing.\"\"\"\n\n    def factory(gains):\n        return ControllerFactory.create_controller(controller_type, gains)\n\n    parallel_optimizer = ParallelPSOOptimizer(\n        controller_factory=factory,\n        config=load_config('config.yaml'),\n        n_processes=n_processes\n    )\n\n    results = parallel_optimizer.optimize(\n        bounds=get_controller_bounds(controller_type),\n        n_particles=50,\n        n_iterations=100\n    )\n\n    return results",
    "lines": 57,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcb790ad"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_13_ad17a8b7",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass MemoryEfficientPSO:\n    \"\"\"PSO implementation optimized for memory usage.\"\"\"\n\n    def __init__(self, max_memory_mb=1000):\n        self.max_memory_mb = max_memory_mb\n        self.memory_monitor = psutil.Process()\n\n    def optimize_with_memory_management(self, *args, **kwargs):\n        \"\"\"Run optimization with active memory management.\"\"\"\n\n        def memory_callback(iteration, **cb_kwargs):\n            current_memory = self.memory_monitor.memory_info().rss / 1024 / 1024\n\n            if current_memory > self.max_memory_mb:\n                print(f\"\u26a0\ufe0f  Memory limit exceeded: {current_memory:.1f}MB > {self.max_memory_mb}MB\")\n\n                # Force garbage collection\n                import gc\n                gc.collect()\n\n                # Reduce particle count if memory still high\n                new_memory = self.memory_monitor.memory_info().rss / 1024 / 1024\n                if new_memory > self.max_memory_mb * 0.9:\n                    self.n_particles = max(10, int(self.n_particles * 0.8))\n                    print(f\"\ud83d\udd3d Reduced particle count to {self.n_particles}\")\n\n            return False\n\n        # Add memory callback to optimization\n        kwargs['callback'] = memory_callback\n        return self.base_optimize(*args, **kwargs)\n\n# Usage\nmemory_efficient_pso = MemoryEfficientPSO(max_memory_mb=2000)\nresults = memory_efficient_pso.optimize_with_memory_management(...)",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad17a8b7"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_14_16a64db7",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 14,
    "code": "def optimize_simulation_performance():\n    \"\"\"Optimize simulation engine performance.\"\"\"\n\n    # Check Numba availability and configuration\n    try:\n        import numba\n        print(f\"\u2705 Numba version: {numba.__version__}\")\n\n        # Configure Numba for optimal performance\n        numba.config.THREADING_LAYER = 'omp'  # Use OpenMP\n        numba.config.NUMBA_NUM_THREADS = psutil.cpu_count()\n\n        print(f\"\ud83d\ude80 Numba configured for {numba.config.NUMBA_NUM_THREADS} threads\")\n\n    except ImportError:\n        print(\"\u274c Numba not available - install for acceleration:\")\n        print(\"   pip install numba\")\n\n    # Optimize NumPy settings\n    import numpy as np\n    print(f\"\ud83d\udcca NumPy version: {np.__version__}\")\n    print(f\"\ud83d\udd27 BLAS library: {np.__config__.get_info('blas_opt_info', {}).get('libraries', 'Unknown')}\")\n\n    # Check for optimized BLAS\n    blas_info = np.__config__.get_info('blas_opt_info')\n    if 'openblas' in str(blas_info).lower() or 'mkl' in str(blas_info).lower():\n        print(\"\u2705 Optimized BLAS library detected\")\n    else:\n        print(\"\u26a0\ufe0f  Basic BLAS - consider installing optimized version:\")\n        print(\"   conda install numpy mkl\")\n\n# Run performance optimization check\noptimize_simulation_performance()",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "16a64db7"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_15_a06c9302",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptiveSimulation:\n    \"\"\"Simulation with adaptive time step for efficiency.\"\"\"\n\n    def __init__(self, base_dt=0.001, max_dt=0.01, error_tolerance=1e-6):\n        self.base_dt = base_dt\n        self.max_dt = max_dt\n        self.error_tolerance = error_tolerance\n\n    def simulate_with_adaptive_timestep(self, controller, initial_state, duration):\n        \"\"\"Simulate with adaptive time step control.\"\"\"\n\n        t = 0\n        state = initial_state.copy()\n        dt = self.base_dt\n\n        trajectory = {'t': [0], 'x': [state.copy()], 'u': [], 'dt': []}\n\n        while t < duration:\n            # Compute control\n            u = controller.compute_control(state, dt=dt)\n\n            # Try two time steps: dt and dt/2\n            state_full = self._integrate_step(state, u, dt)\n            state_half1 = self._integrate_step(state, u, dt/2)\n            state_half2 = self._integrate_step(state_half1, u, dt/2)\n\n            # Estimate error\n            error = np.linalg.norm(state_full - state_half2)\n\n            if error < self.error_tolerance:\n                # Accept step and possibly increase dt\n                state = state_full\n                t += dt\n                trajectory['t'].append(t)\n                trajectory['x'].append(state.copy())\n                trajectory['u'].append(u)\n                trajectory['dt'].append(dt)\n\n                # Increase time step if error is very small\n                if error < self.error_tolerance / 4:\n                    dt = min(self.max_dt, dt * 1.2)\n\n            else:\n                # Reduce time step and retry\n                dt = max(self.base_dt, dt * 0.5)\n\n        return trajectory\n\n    def _integrate_step(self, state, u, dt):\n        \"\"\"Single integration step (placeholder).\"\"\"\n        # Implement actual dynamics integration\n        # This is controller and system dependent\n        pass",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a06c9302"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_16_c88c6fd7",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 16,
    "code": "import matplotlib.pyplot as plt\nimport json\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\nclass PSOPerformanceDashboard:\n    \"\"\"Performance monitoring dashboard for PSO system.\"\"\"\n\n    def __init__(self, log_directory='./logs'):\n        self.log_directory = Path(log_directory)\n\n    def generate_performance_report(self, days=7):\n        \"\"\"Generate performance report for last N days.\"\"\"\n\n        # Collect health reports\n        reports = []\n        for i in range(days):\n            date = datetime.now() - timedelta(days=i)\n            report_file = self.log_directory / f\"health_report_{date.strftime('%Y%m%d')}.json\"\n\n            if report_file.exists():\n                with open(report_file) as f:\n                    report = json.load(f)\n                    report['date'] = date\n                    reports.append(report)\n\n        if not reports:\n            print(\"No health reports found\")\n            return\n\n        # Create performance dashboard\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        fig.suptitle('PSO System Performance Dashboard (Last 7 Days)')\n\n        # Plot 1: Overall health status\n        dates = [r['date'] for r in reports]\n        statuses = [r['overall_status'] for r in reports]\n        status_colors = {'healthy': 'green', 'warnings': 'yellow', 'degraded': 'orange', 'critical': 'red'}\n\n        axes[0, 0].scatter(dates, range(len(dates)), c=[status_colors.get(s, 'gray') for s in statuses], s=100)\n        axes[0, 0].set_title('System Health Status')\n        axes[0, 0].set_yticks(range(len(dates)))\n        axes[0, 0].set_yticklabels([d.strftime('%m/%d') for d in dates])\n\n        # Plot 2: Performance metrics\n        perf_times = [r.get('performance_metrics', {}).get('time_per_iteration', 0) for r in reports]\n        axes[0, 1].plot(dates, perf_times, 'b-o')\n        axes[0, 1].set_title('Optimization Performance')\n        axes[0, 1].set_ylabel('Time per Iteration (s)')\n        axes[0, 1].tick_params(axis='x', rotation=45)\n\n        # Plot 3: System resources\n        memory_usage = [r.get('component_status', {}).get('system_resources', {}).get('memory_gb', 0) for r in reports]\n        cpu_usage = [r.get('component_status', {}).get('system_resources', {}).get('cpu_percent', 0) for r in reports]\n\n        axes[1, 0].plot(dates, memory_usage, 'g-o', label='Memory (GB)')\n        axes[1, 0].plot(dates, cpu_usage, 'r-o', label='CPU (%)')\n        axes[1, 0].set_title('System Resources')\n        axes[1, 0].legend()\n        axes[1, 0].tick_params(axis='x', rotation=45)\n\n        # Plot 4: Component status summary\n        component_names = ['configuration', 'controller_factory', 'pso_engine', 'simulation_engine']\n        component_health = {}\n\n        for comp in component_names:\n            health_scores = []\n            for report in reports:\n                status = report.get('component_status', {}).get(comp, {}).get('status', 'unknown')\n                score = {'healthy': 3, 'warnings': 2, 'issues': 1, 'failed': 0}.get(status, 0)\n                health_scores.append(score)\n            component_health[comp] = sum(health_scores) / len(health_scores)\n\n        comp_names = list(component_health.keys())\n        comp_scores = list(component_health.values())\n\n        axes[1, 1].bar(comp_names, comp_scores, color=['green' if s > 2.5 else 'orange' if s > 1.5 else 'red' for s in comp_scores])\n        axes[1, 1].set_title('Component Health Average')\n        axes[1, 1].set_ylabel('Health Score')\n        axes[1, 1].tick_params(axis='x', rotation=45)\n\n        plt.tight_layout()\n        plt.savefig('pso_performance_dashboard.png', dpi=300, bbox_inches='tight')\n        plt.show()\n\n        # Generate summary statistics\n        print(\"\\n\ud83d\udcca PSO PERFORMANCE SUMMARY (Last 7 Days)\")\n        print(\"=\" * 50)\n        print(f\"Average iteration time: {np.mean(perf_times):.2f}s\")\n        print(f\"Best iteration time: {np.min(perf_times):.2f}s\")\n        print(f\"Worst iteration time: {np.max(perf_times):.2f}s\")\n        print(f\"Healthy days: {statuses.count('healthy')}/{len(statuses)}\")\n\n        return reports\n\n# Usage\ndashboard = PSOPerformanceDashboard()\nreports = dashboard.generate_performance_report(days=7)",
    "lines": 98,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c88c6fd7"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_17_a02dabd9",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 17,
    "code": "import yaml\nimport jsonschema\nfrom pathlib import Path\n\nclass ConfigurationValidator:\n    \"\"\"Validate PSO configuration files.\"\"\"\n\n    def __init__(self):\n        self.schema = self._load_config_schema()\n\n    def _load_config_schema(self):\n        \"\"\"Load configuration validation schema.\"\"\"\n        return {\n            \"type\": \"object\",\n            \"required\": [\"pso\", \"cost_function\", \"simulation\", \"controllers\"],\n            \"properties\": {\n                \"pso\": {\n                    \"type\": \"object\",\n                    \"required\": [\"n_particles\", \"n_iterations\"],\n                    \"properties\": {\n                        \"n_particles\": {\"type\": \"integer\", \"minimum\": 5, \"maximum\": 500},\n                        \"n_iterations\": {\"type\": \"integer\", \"minimum\": 10, \"maximum\": 2000},\n                        \"cognitive_weight\": {\"type\": \"number\", \"minimum\": 0.1, \"maximum\": 5.0},\n                        \"social_weight\": {\"type\": \"number\", \"minimum\": 0.1, \"maximum\": 5.0},\n                        \"inertia_weight\": {\"type\": \"number\", \"minimum\": 0.1, \"maximum\": 1.0}\n                    }\n                },\n                \"cost_function\": {\n                    \"type\": \"object\",\n                    \"required\": [\"weights\"],\n                    \"properties\": {\n                        \"weights\": {\n                            \"type\": \"object\",\n                            \"required\": [\"state_error\", \"control_effort\", \"control_rate\", \"stability\"],\n                            \"properties\": {\n                                \"state_error\": {\"type\": \"number\", \"minimum\": 0},\n                                \"control_effort\": {\"type\": \"number\", \"minimum\": 0},\n                                \"control_rate\": {\"type\": \"number\", \"minimum\": 0},\n                                \"stability\": {\"type\": \"number\", \"minimum\": 0}\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n    def validate_config(self, config_path):\n        \"\"\"Validate configuration file.\"\"\"\n        try:\n            with open(config_path, 'r') as f:\n                config = yaml.safe_load(f)\n\n            # JSON Schema validation\n            jsonschema.validate(config, self.schema)\n\n            # Custom validations\n            validation_results = {\n                'syntax_valid': True,\n                'schema_valid': True,\n                'warnings': [],\n                'errors': []\n            }\n\n            # Check parameter ranges\n            pso_config = config.get('pso', {})\n            if pso_config.get('n_particles', 0) * pso_config.get('n_iterations', 0) > 50000:\n                validation_results['warnings'].append(\n                    \"High computational load: particles \u00d7 iterations > 50,000\"\n                )\n\n            # Check cost function weights\n            weights = config.get('cost_function', {}).get('weights', {})\n            total_weight = sum(weights.values()) if weights else 0\n            if total_weight < 0.1:\n                validation_results['warnings'].append(\n                    \"Very low total cost function weights - optimization may be ineffective\"\n                )\n\n            return validation_results\n\n        except yaml.YAMLError as e:\n            return {\n                'syntax_valid': False,\n                'schema_valid': False,\n                'errors': [f\"YAML syntax error: {e}\"],\n                'warnings': []\n            }\n\n        except jsonschema.ValidationError as e:\n            return {\n                'syntax_valid': True,\n                'schema_valid': False,\n                'errors': [f\"Schema validation error: {e.message}\"],\n                'warnings': []\n            }\n\n    def backup_config(self, config_path):\n        \"\"\"Create timestamped backup of configuration.\"\"\"\n        config_file = Path(config_path)\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        backup_path = config_file.parent / f\"{config_file.stem}_backup_{timestamp}{config_file.suffix}\"\n\n        shutil.copy2(config_path, backup_path)\n        print(f\"\u2705 Configuration backed up to: {backup_path}\")\n        return backup_path\n\n# Usage\nvalidator = ConfigurationValidator()\nvalidation_result = validator.validate_config('config.yaml')\n\nif validation_result['schema_valid']:\n    print(\"\u2705 Configuration is valid\")\n    if validation_result['warnings']:\n        print(\"\u26a0\ufe0f  Warnings:\")\n        for warning in validation_result['warnings']:\n            print(f\"  - {warning}\")\nelse:\n    print(\"\u274c Configuration validation failed:\")\n    for error in validation_result['errors']:\n        print(f\"  - {error}\")",
    "lines": 120,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a02dabd9"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_18_07011719",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nimport logging\nimport logging.handlers\nfrom pathlib import Path\nimport gzip\nimport os\nfrom datetime import datetime, timedelta\n\nclass PSOLogManager:\n    \"\"\"Centralized PSO log management.\"\"\"\n\n    def __init__(self, log_directory='./logs', max_log_size_mb=100, backup_count=10):\n        self.log_directory = Path(log_directory)\n        self.log_directory.mkdir(exist_ok=True)\n        self.max_log_size = max_log_size_mb * 1024 * 1024  # Convert to bytes\n        self.backup_count = backup_count\n\n        self._setup_loggers()\n\n    def _setup_loggers(self):\n        \"\"\"Setup rotating file handlers for different log types.\"\"\"\n\n        # PSO optimization logs\n        pso_handler = logging.handlers.RotatingFileHandler(\n            self.log_directory / 'pso_optimization.log',\n            maxBytes=self.max_log_size,\n            backupCount=self.backup_count\n        )\n        pso_handler.setFormatter(logging.Formatter(\n            '%(asctime)s - %(levelname)s - %(module)s - %(message)s'\n        ))\n\n        self.pso_logger = logging.getLogger('pso_optimization')\n        self.pso_logger.addHandler(pso_handler)\n        self.pso_logger.setLevel(logging.INFO)\n\n        # System health logs\n        health_handler = logging.handlers.RotatingFileHandler(\n            self.log_directory / 'system_health.log',\n            maxBytes=self.max_log_size,\n            backupCount=self.backup_count\n        )\n        health_handler.setFormatter(logging.Formatter(\n            '%(asctime)s - %(levelname)s - %(message)s'\n        ))\n\n        self.health_logger = logging.getLogger('system_health')\n        self.health_logger.addHandler(health_handler)\n        self.health_logger.setLevel(logging.INFO)\n\n    def log_optimization_start(self, controller_type, config):\n        \"\"\"Log optimization start.\"\"\"\n        self.pso_logger.info(f\"Starting PSO optimization for {controller_type}\")\n        self.pso_logger.info(f\"PSO config: particles={config.get('n_particles')}, iterations={config.get('n_iterations')}\")\n\n    def log_optimization_result(self, controller_type, results):\n        \"\"\"Log optimization results.\"\"\"\n        success = results.get('success', False)\n        best_cost = results.get('best_cost', 'unknown')\n        convergence_iter = results.get('convergence_iteration', 'unknown')\n\n        self.pso_logger.info(f\"PSO optimization for {controller_type} completed: success={success}\")\n        self.pso_logger.info(f\"Best cost: {best_cost}, Convergence iteration: {convergence_iter}\")\n\n        if not success:\n            self.pso_logger.warning(f\"PSO optimization failed for {controller_type}\")\n\n    def log_health_check(self, health_status, issues):\n        \"\"\"Log system health check results.\"\"\"\n        self.health_logger.info(f\"Health check completed: status={health_status}\")\n\n        if issues:\n            for issue in issues:\n                self.health_logger.warning(f\"Health issue: {issue}\")\n\n    def cleanup_old_logs(self, days_to_keep=30):\n        \"\"\"Clean up old log files.\"\"\"\n        cutoff_date = datetime.now() - timedelta(days=days_to_keep)\n\n        for log_file in self.log_directory.glob('*.log*'):\n            if log_file.stat().st_mtime < cutoff_date.timestamp():\n                # Compress old logs before deletion\n                if not log_file.name.endswith('.gz'):\n                    compressed_name = f\"{log_file}.gz\"\n                    with open(log_file, 'rb') as f_in:\n                        with gzip.open(compressed_name, 'wb') as f_out:\n                            f_out.writelines(f_in)\n                    os.remove(log_file)\n                    self.health_logger.info(f\"Compressed and archived log: {log_file}\")\n\n    def get_log_summary(self, days=7):\n        \"\"\"Get summary of recent log activity.\"\"\"\n        summary = {\n            'optimization_runs': 0,\n            'successful_optimizations': 0,\n            'health_checks': 0,\n            'warnings': 0,\n            'errors': 0\n        }\n\n        cutoff_date = datetime.now() - timedelta(days=days)\n\n        # Analyze PSO logs\n        pso_log_file = self.log_directory / 'pso_optimization.log'\n        if pso_log_file.exists():\n            with open(pso_log_file, 'r') as f:\n                for line in f:\n                    # Parse log lines and count events\n                    if 'Starting PSO optimization' in line:\n                        summary['optimization_runs'] += 1\n                    elif 'completed: success=True' in line:\n                        summary['successful_optimizations'] += 1\n                    elif 'WARNING' in line:\n                        summary['warnings'] += 1\n                    elif 'ERROR' in line:\n                        summary['errors'] += 1\n\n        # Analyze health logs\n        health_log_file = self.log_directory / 'system_health.log'\n        if health_log_file.exists():\n            with open(health_log_file, 'r') as f:\n                for line in f:\n                    if 'Health check completed' in line:\n                        summary['health_checks'] += 1\n\n        return summary\n\n# Usage\nlog_manager = PSOLogManager()\n\n# Log optimization session\nlog_manager.log_optimization_start('classical_smc', {'n_particles': 50, 'n_iterations': 100})\n# ... run optimization ...\nlog_manager.log_optimization_result('classical_smc', {'success': True, 'best_cost': 67.3})\n\n# Daily maintenance\nlog_manager.cleanup_old_logs(days_to_keep=30)\nsummary = log_manager.get_log_summary(days=7)\nprint(f\"Last 7 days: {summary['optimization_runs']} optimizations, {summary['successful_optimizations']} successful\")",
    "lines": 141,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07011719"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_19_72a13b30",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 19,
    "code": "def validate_emergency_recovery():\n    \"\"\"Validate system after emergency recovery.\"\"\"\n\n    print(\"\ud83d\udd0d VALIDATING EMERGENCY RECOVERY\")\n    print(\"=\" * 40)\n\n    validation_results = {\n        'configuration_valid': False,\n        'controllers_functional': False,\n        'pso_engine_operational': False,\n        'simulation_working': False,\n        'overall_success': False\n    }\n\n    # Test 1: Configuration validation\n    try:\n        from src.config import load_config\n        config = load_config('config.yaml')\n        validation_results['configuration_valid'] = True\n        print(\"\u2705 Configuration loads successfully\")\n    except Exception as e:\n        print(f\"\u274c Configuration error: {e}\")\n\n    # Test 2: Controller factory\n    try:\n        from src.controllers.factory import ControllerFactory\n        import numpy as np\n\n        test_gains = np.array([5.0, 3.0, 7.0, 2.0, 25.0, 1.0])\n        controller = ControllerFactory.create_controller('classical_smc', test_gains)\n\n        test_state = np.zeros(6)\n        control = controller.compute_control(test_state)\n\n        if np.isfinite(control):\n            validation_results['controllers_functional'] = True\n            print(\"\u2705 Controller factory operational\")\n        else:\n            print(\"\u274c Controller produces invalid output\")\n\n    except Exception as e:\n        print(f\"\u274c Controller factory error: {e}\")\n\n    # Test 3: PSO engine\n    try:\n        from src.optimization.algorithms.pso_optimizer import PSOTuner\n\n        def test_factory(gains):\n            return ControllerFactory.create_controller('classical_smc', gains)\n\n        pso_tuner = PSOTuner(test_factory, config, seed=42)\n\n        # Quick test optimization\n        test_bounds = (\n            np.array([1.0, 1.0, 1.0, 1.0, 1.0, 0.1]),\n            np.array([10.0, 10.0, 10.0, 10.0, 50.0, 5.0])\n        )\n\n        results = pso_tuner.optimize(\n            bounds=test_bounds,\n            n_particles=5,\n            n_iterations=3\n        )\n\n        if results.get('success', False):\n            validation_results['pso_engine_operational'] = True\n            print(\"\u2705 PSO engine operational\")\n        else:\n            print(\"\u274c PSO engine test failed\")\n\n    except Exception as e:\n        print(f\"\u274c PSO engine error: {e}\")\n\n    # Test 4: Simulation engine\n    try:\n        from src.simulation.engines.vector_sim import simulate_system_batch\n\n        test_particles = np.array([[5.0, 3.0, 7.0, 2.0, 25.0, 1.0]])\n\n        result = simulate_system_batch(\n            controller_factory=test_factory,\n            particles=test_particles,\n            sim_time=0.5,\n            dt=0.01,\n            u_max=150.0\n        )\n\n        if result is not None:\n            validation_results['simulation_working'] = True\n            print(\"\u2705 Simulation engine operational\")\n        else:\n            print(\"\u274c Simulation engine test failed\")\n\n    except Exception as e:\n        print(f\"\u274c Simulation engine error: {e}\")\n\n    # Overall assessment\n    success_count = sum(validation_results.values())\n    total_tests = len(validation_results) - 1  # Exclude overall_success\n\n    if success_count == total_tests:\n        validation_results['overall_success'] = True\n        print(\"\\n\ud83c\udf89 RECOVERY VALIDATION SUCCESSFUL\")\n        print(\"System is ready for normal operation\")\n    else:\n        print(f\"\\n\u274c RECOVERY VALIDATION FAILED\")\n        print(f\"Only {success_count}/{total_tests} tests passed\")\n        print(\"Manual intervention required\")\n\n    return validation_results\n\n# Run validation\nif __name__ == \"__main__\":\n    results = validate_emergency_recovery()\n    exit(0 if results['overall_success'] else 1)",
    "lines": 115,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72a13b30"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_20_bff8a052",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 20,
    "code": "import shutil\nimport json\nfrom pathlib import Path\nfrom datetime import datetime\n\nclass ConfigurationRecovery:\n    \"\"\"Handle configuration file recovery and restoration.\"\"\"\n\n    def __init__(self, config_dir='.', backup_dir='./config_backups'):\n        self.config_dir = Path(config_dir)\n        self.backup_dir = Path(backup_dir)\n        self.backup_dir.mkdir(exist_ok=True)\n\n    def create_emergency_backup(self, description=\"emergency\"):\n        \"\"\"Create emergency backup of current configuration.\"\"\"\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        backup_name = f\"config_emergency_{description}_{timestamp}.yaml\"\n        backup_path = self.backup_dir / backup_name\n\n        try:\n            shutil.copy2(self.config_dir / 'config.yaml', backup_path)\n            print(f\"\u2705 Emergency backup created: {backup_path}\")\n            return backup_path\n        except Exception as e:\n            print(f\"\u274c Failed to create emergency backup: {e}\")\n            return None\n\n    def list_available_backups(self):\n        \"\"\"List all available configuration backups.\"\"\"\n        backups = sorted(self.backup_dir.glob('config_*.yaml'))\n\n        print(\"\ud83d\udccb Available Configuration Backups:\")\n        print(\"=\" * 50)\n\n        for i, backup in enumerate(backups, 1):\n            # Extract timestamp from filename\n            parts = backup.stem.split('_')\n            if len(parts) >= 3:\n                timestamp = f\"{parts[-2]}_{parts[-1]}\"\n                try:\n                    dt = datetime.strptime(timestamp, '%Y%m%d_%H%M%S')\n                    formatted_date = dt.strftime('%Y-%m-%d %H:%M:%S')\n                except:\n                    formatted_date = timestamp\n\n                print(f\"  {i:2d}. {backup.name}\")\n                print(f\"      Date: {formatted_date}\")\n                print(f\"      Size: {backup.stat().st_size} bytes\")\n                print()\n\n        return backups\n\n    def restore_from_backup(self, backup_index=None, backup_name=None):\n        \"\"\"Restore configuration from backup.\"\"\"\n        backups = sorted(self.backup_dir.glob('config_*.yaml'))\n\n        if backup_index is not None:\n            if 1 <= backup_index <= len(backups):\n                selected_backup = backups[backup_index - 1]\n            else:\n                print(f\"\u274c Invalid backup index: {backup_index}\")\n                return False\n\n        elif backup_name is not None:\n            selected_backup = self.backup_dir / backup_name\n            if not selected_backup.exists():\n                print(f\"\u274c Backup not found: {backup_name}\")\n                return False\n\n        else:\n            print(\"\u274c Must specify either backup_index or backup_name\")\n            return False\n\n        try:\n            # Create backup of current config before restoration\n            self.create_emergency_backup(\"pre_restore\")\n\n            # Restore from backup\n            shutil.copy2(selected_backup, self.config_dir / 'config.yaml')\n            print(f\"\u2705 Configuration restored from: {selected_backup.name}\")\n\n            # Validate restored configuration\n            from src.config import load_config\n            try:\n                config = load_config('config.yaml')\n                print(\"\u2705 Restored configuration is valid\")\n                return True\n            except Exception as e:\n                print(f\"\u274c Restored configuration is invalid: {e}\")\n                return False\n\n        except Exception as e:\n            print(f\"\u274c Failed to restore configuration: {e}\")\n            return False\n\n    def restore_factory_defaults(self):\n        \"\"\"Restore factory default configuration.\"\"\"\n        default_config = {\n            'global_seed': 42,\n            'pso': {\n                'n_particles': 50,\n                'n_iterations': 100,\n                'cognitive_weight': 1.49445,\n                'social_weight': 1.49445,\n                'inertia_weight': 0.729,\n                'bounds': {\n                    'classical_smc': {\n                        'lower': [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n                        'upper': [20.0, 20.0, 20.0, 20.0, 100.0, 10.0]\n                    }\n                }\n            },\n            'cost_function': {\n                'weights': {\n                    'state_error': 1.0,\n                    'control_effort': 0.01,\n                    'control_rate': 0.001,\n                    'stability': 10.0\n                }\n            },\n            'simulation': {\n                'duration': 10.0,\n                'dt': 0.001\n            },\n            'controllers': {\n                'classical_smc': {\n                    'max_force': 150.0,\n                    'boundary_layer': 0.02\n                }\n            }\n        }\n\n        try:\n            # Backup current config\n            self.create_emergency_backup(\"pre_factory_reset\")\n\n            # Write factory defaults\n            import yaml\n            with open(self.config_dir / 'config.yaml', 'w') as f:\n                yaml.dump(default_config, f, default_flow_style=False, indent=2)\n\n            print(\"\u2705 Factory default configuration restored\")\n            return True\n\n        except Exception as e:\n            print(f\"\u274c Failed to restore factory defaults: {e}\")\n            return False\n\n# Usage example\nrecovery = ConfigurationRecovery()\n\n# List backups and restore\nrecovery.list_available_backups()\n# recovery.restore_from_backup(backup_index=1)\n# recovery.restore_factory_defaults()",
    "lines": 155,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bff8a052"
  },
  {
    "id": "pso_troubleshooting_maintenance_manual_21_936cf55d",
    "file": "docs\\pso_troubleshooting_maintenance_manual.md",
    "index": 21,
    "code": "class OptimizationResultsRecovery:\n    \"\"\"Recover and validate optimization results.\"\"\"\n\n    def __init__(self, results_dir='./results'):\n        self.results_dir = Path(results_dir)\n\n    def scan_for_results(self):\n        \"\"\"Scan for all optimization result files.\"\"\"\n        result_files = list(self.results_dir.glob('*.json'))\n        print(f\"\ud83d\udcca Found {len(result_files)} result files\")\n\n        valid_results = []\n        corrupted_results = []\n\n        for result_file in result_files:\n            try:\n                with open(result_file, 'r') as f:\n                    data = json.load(f)\n\n                # Validate result structure\n                required_fields = ['controller_type', 'best_gains', 'best_cost']\n                if all(field in data for field in required_fields):\n                    valid_results.append(result_file)\n                    print(f\"\u2705 {result_file.name} - Valid\")\n                else:\n                    corrupted_results.append(result_file)\n                    print(f\"\u26a0\ufe0f  {result_file.name} - Missing required fields\")\n\n            except json.JSONDecodeError:\n                corrupted_results.append(result_file)\n                print(f\"\u274c {result_file.name} - JSON corruption\")\n            except Exception as e:\n                corrupted_results.append(result_file)\n                print(f\"\u274c {result_file.name} - Error: {e}\")\n\n        return valid_results, corrupted_results\n\n    def recover_partial_results(self, corrupted_file):\n        \"\"\"Attempt to recover partial data from corrupted files.\"\"\"\n        print(f\"\ud83d\udd27 Attempting recovery of {corrupted_file.name}\")\n\n        try:\n            with open(corrupted_file, 'r') as f:\n                content = f.read()\n\n            # Try to extract partial JSON\n            # Look for gains array pattern\n            import re\n            gains_pattern = r'\"best_gains\"\\s*:\\s*\\[([\\d.,\\s]+)\\]'\n            gains_match = re.search(gains_pattern, content)\n\n            if gains_match:\n                gains_str = gains_match.group(1)\n                gains = [float(x.strip()) for x in gains_str.split(',')]\n                print(f\"\u2705 Recovered gains: {gains}\")\n\n                # Try to extract controller type\n                ctrl_pattern = r'\"controller_type\"\\s*:\\s*\"([^\"]+)\"'\n                ctrl_match = re.search(ctrl_pattern, content)\n\n                if ctrl_match:\n                    controller_type = ctrl_match.group(1)\n                    print(f\"\u2705 Recovered controller type: {controller_type}\")\n\n                    # Create minimal valid result\n                    recovered_result = {\n                        'controller_type': controller_type,\n                        'best_gains': gains,\n                        'best_cost': 'unknown',\n                        'recovery_note': f\"Partial recovery from {corrupted_file.name}\",\n                        'recovery_timestamp': datetime.now().isoformat()\n                    }\n\n                    # Save recovered result\n                    recovery_file = corrupted_file.parent / f\"recovered_{corrupted_file.name}\"\n                    with open(recovery_file, 'w') as f:\n                        json.dump(recovered_result, f, indent=2)\n\n                    print(f\"\u2705 Recovered result saved to: {recovery_file.name}\")\n                    return recovery_file\n\n        except Exception as e:\n            print(f\"\u274c Recovery failed: {e}\")\n\n        return None\n\n# Usage\nrecovery = OptimizationResultsRecovery()\nvalid, corrupted = recovery.scan_for_results()\n\n# Attempt recovery of corrupted files\nfor corrupted_file in corrupted:\n    recovery.recover_partial_results(corrupted_file)",
    "lines": 93,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "936cf55d"
  },
  {
    "id": "quality_gate_independence_framework_1_6fa3c3f6",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass IndependentValidationPaths:\n    \"\"\"Four independent validation paths preventing cascade failures.\"\"\"\n\n    def __init__(self):\n        self.validation_paths = {\n            'coverage_validation': CoverageValidationPath(),\n            'mathematical_validation': MathematicalValidationPath(),\n            'performance_validation': PerformanceValidationPath(),\n            'compliance_validation': ComplianceValidationPath()\n        }\n\n    def execute_independent_validation(self) -> IndependentValidationResults:\n        \"\"\"Execute all validation paths independently with failure isolation.\"\"\"\n        results = {}\n\n        for path_name, validator in self.validation_paths.items():\n            try:\n                # Each path executes in complete isolation\n                results[path_name] = validator.validate_independently()\n            except Exception as e:\n                # Failure isolation: one path failure doesn't affect others\n                results[path_name] = ValidationResult(\n                    status='failed',\n                    error=str(e),\n                    partial_results=validator.get_partial_results()\n                )\n\n        return IndependentValidationResults(\n            path_results=results,\n            overall_status=self._calculate_composite_status(results),\n            deployment_recommendation=self._make_deployment_decision(results)\n        )",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fa3c3f6"
  },
  {
    "id": "quality_gate_independence_framework_2_0816ef6f",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass CoverageValidationPath:\n    \"\"\"Independent coverage analysis with failure tolerance.\"\"\"\n\n    def validate_independently(self) -> CoverageValidationResult:\n        \"\"\"Run coverage validation independent of other systems.\"\"\"\n\n        # Collect coverage data with timeout protection\n        coverage_data = self._collect_coverage_with_timeout()\n\n        # Analyze coverage against tier requirements\n        tier_analysis = self._analyze_coverage_tiers(coverage_data)\n\n        # Generate gap analysis with specific remediation\n        gap_analysis = self._generate_gap_analysis(tier_analysis)\n\n        return CoverageValidationResult(\n            overall_coverage=tier_analysis.overall_coverage,\n            tier_compliance={\n                'safety_critical': tier_analysis.safety_critical_compliance,\n                'critical': tier_analysis.critical_compliance,\n                'general': tier_analysis.general_compliance\n            },\n            gap_analysis=gap_analysis,\n            validation_confidence=self._calculate_confidence(coverage_data),\n            deployment_approved=self._approve_deployment(tier_analysis)\n        )\n\n    def _collect_coverage_with_timeout(self) -> CoverageData:\n        \"\"\"Collect coverage with graceful timeout handling.\"\"\"\n        coverage_modules = {}\n\n        for module in ANALYZED_MODULES:\n            try:\n                with timeout_context(COVERAGE_TIMEOUT):\n                    coverage_modules[module] = collect_module_coverage(module)\n            except TimeoutError:\n                # Graceful timeout handling - continue with other modules\n                coverage_modules[module] = CoverageData(\n                    module=module,\n                    status='timeout',\n                    estimated_coverage=get_historical_coverage(module)\n                )\n            except Exception as e:\n                # Error isolation - don't propagate to other modules\n                coverage_modules[module] = CoverageData(\n                    module=module,\n                    status='error',\n                    error=str(e)\n                )\n\n        return CoverageData(modules=coverage_modules)",
    "lines": 54,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0816ef6f"
  },
  {
    "id": "quality_gate_independence_framework_3_05255441",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass MathematicalValidationPath:\n    \"\"\"Independent mathematical property validation.\"\"\"\n\n    def validate_independently(self) -> MathematicalValidationResult:\n        \"\"\"Validate mathematical properties independent of test execution.\"\"\"\n\n        # Validate control theory properties\n        stability_results = self._validate_stability_properties()\n\n        # Validate optimization convergence\n        convergence_results = self._validate_convergence_properties()\n\n        # Validate numerical stability\n        numerical_results = self._validate_numerical_properties()\n\n        return MathematicalValidationResult(\n            stability_validation=stability_results,\n            convergence_validation=convergence_results,\n            numerical_validation=numerical_results,\n            theoretical_soundness=self._assess_theoretical_soundness(\n                stability_results, convergence_results, numerical_results\n            ),\n            mathematical_rigor_score=self._calculate_rigor_score(\n                stability_results, convergence_results, numerical_results\n            )\n        )\n\n    def _validate_stability_properties(self) -> StabilityValidationResult:\n        \"\"\"Validate Lyapunov stability and sliding surface properties.\"\"\"\n\n        stability_tests = {\n            'lyapunov_conditions': self._test_lyapunov_stability,\n            'sliding_surface_reachability': self._test_sliding_surface_reachability,\n            'finite_time_convergence': self._test_finite_time_convergence,\n            'robustness_properties': self._test_robustness_properties\n        }\n\n        results = {}\n        for test_name, test_function in stability_tests.items():\n            try:\n                results[test_name] = test_function()\n            except Exception as e:\n                # Mathematical validation failures are isolated\n                results[test_name] = TestResult(\n                    status='failed',\n                    error=str(e),\n                    mathematical_interpretation=f\"Failed to verify {test_name}\"\n                )\n\n        return StabilityValidationResult(\n            test_results=results,\n            overall_stability=self._assess_overall_stability(results)\n        )\n\n    def _test_lyapunov_stability(self) -> TestResult:\n        \"\"\"Test Lyapunov stability conditions for SMC controllers.\"\"\"\n\n        # Test Lyapunov function V(s) = 1/2 * s^2\n        # Verify V\u0307(s) = s * \u1e61 < 0 for s \u2260 0\n\n        stability_violations = []\n\n        for controller_type in SMC_CONTROLLER_TYPES:\n            try:\n                controller = create_test_controller(controller_type)\n\n                # Test with multiple state conditions\n                for test_state in generate_lyapunov_test_states():\n                    sliding_surface = controller.compute_sliding_surface(test_state, target=np.zeros(6))\n                    surface_derivative = controller.compute_surface_derivative(test_state, target=np.zeros(6))\n\n                    # Lyapunov condition: V\u0307 = s * \u1e61 < 0 for s \u2260 0\n                    if abs(sliding_surface) > SLIDING_SURFACE_TOLERANCE:\n                        lyapunov_derivative = sliding_surface * surface_derivative\n\n                        if lyapunov_derivative >= 0:\n                            stability_violations.append({\n                                'controller': controller_type,\n                                'state': test_state,\n                                'sliding_surface': sliding_surface,\n                                'lyapunov_derivative': lyapunov_derivative\n                            })\n\n            except Exception as e:\n                stability_violations.append({\n                    'controller': controller_type,\n                    'error': str(e),\n                    'test_type': 'lyapunov_stability'\n                })\n\n        return TestResult(\n            status='passed' if not stability_violations else 'failed',\n            violations=stability_violations,\n            mathematical_interpretation=\"Lyapunov stability verified\" if not stability_violations else f\"Found {len(stability_violations)} stability violations\"\n        )",
    "lines": 98,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "05255441"
  },
  {
    "id": "quality_gate_independence_framework_4_645f2c50",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass PerformanceValidationPath:\n    \"\"\"Independent performance and benchmark validation.\"\"\"\n\n    def validate_independently(self) -> PerformanceValidationResult:\n        \"\"\"Validate performance independent of coverage and tests.\"\"\"\n\n        # Run performance benchmarks\n        benchmark_results = self._run_performance_benchmarks()\n\n        # Check for performance regressions\n        regression_analysis = self._analyze_performance_regressions(benchmark_results)\n\n        # Validate real-time constraints\n        realtime_validation = self._validate_realtime_constraints()\n\n        return PerformanceValidationResult(\n            benchmark_results=benchmark_results,\n            regression_analysis=regression_analysis,\n            realtime_validation=realtime_validation,\n            performance_score=self._calculate_performance_score(\n                benchmark_results, regression_analysis, realtime_validation\n            ),\n            deployment_performance_approved=self._approve_performance_deployment(\n                benchmark_results, regression_analysis\n            )\n        )\n\n    def _run_performance_benchmarks(self) -> BenchmarkResults:\n        \"\"\"Run isolated performance benchmarks.\"\"\"\n\n        benchmark_results = {}\n\n        # Controller performance benchmarks\n        for controller_type in SMC_CONTROLLER_TYPES:\n            try:\n                benchmark_results[f'{controller_type}_performance'] = self._benchmark_controller(controller_type)\n            except Exception as e:\n                benchmark_results[f'{controller_type}_performance'] = BenchmarkResult(\n                    status='failed',\n                    error=str(e)\n                )\n\n        # PSO optimization benchmarks\n        try:\n            benchmark_results['pso_convergence'] = self._benchmark_pso_optimization()\n        except Exception as e:\n            benchmark_results['pso_convergence'] = BenchmarkResult(\n                status='failed',\n                error=str(e)\n            )\n\n        # Simulation engine benchmarks\n        try:\n            benchmark_results['simulation_performance'] = self._benchmark_simulation_engine()\n        except Exception as e:\n            benchmark_results['simulation_performance'] = BenchmarkResult(\n                status='failed',\n                error=str(e)\n            )\n\n        return BenchmarkResults(results=benchmark_results)\n\n    def _validate_realtime_constraints(self) -> RealtimeValidationResult:\n        \"\"\"Validate real-time performance constraints.\"\"\"\n\n        realtime_results = {}\n\n        # Test control computation latency\n        try:\n            control_latency = self._measure_control_computation_latency()\n            realtime_results['control_latency'] = RealtimeTest(\n                measured_latency=control_latency,\n                requirement=MAX_CONTROL_LATENCY,\n                status='passed' if control_latency < MAX_CONTROL_LATENCY else 'failed'\n            )\n        except Exception as e:\n            realtime_results['control_latency'] = RealtimeTest(\n                status='error',\n                error=str(e)\n            )\n\n        # Test simulation step timing\n        try:\n            simulation_timing = self._measure_simulation_step_timing()\n            realtime_results['simulation_timing'] = RealtimeTest(\n                measured_timing=simulation_timing,\n                requirement=MAX_SIMULATION_STEP_TIME,\n                status='passed' if simulation_timing < MAX_SIMULATION_STEP_TIME else 'failed'\n            )\n        except Exception as e:\n            realtime_results['simulation_timing'] = RealtimeTest(\n                status='error',\n                error=str(e)\n            )\n\n        return RealtimeValidationResult(results=realtime_results)",
    "lines": 99,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "645f2c50"
  },
  {
    "id": "quality_gate_independence_framework_5_fac21523",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass ComplianceValidationPath:\n    \"\"\"Independent CLAUDE.md compliance validation.\"\"\"\n\n    def validate_independently(self) -> ComplianceValidationResult:\n        \"\"\"Validate compliance independent of other validation paths.\"\"\"\n\n        # Validate ASCII header compliance\n        header_compliance = self._validate_ascii_headers()\n\n        # Validate type annotation coverage\n        type_compliance = self._validate_type_annotations()\n\n        # Validate documentation coverage\n        docs_compliance = self._validate_documentation_coverage()\n\n        # Validate configuration compliance\n        config_compliance = self._validate_configuration_compliance()\n\n        return ComplianceValidationResult(\n            header_compliance=header_compliance,\n            type_compliance=type_compliance,\n            documentation_compliance=docs_compliance,\n            configuration_compliance=config_compliance,\n            overall_compliance_score=self._calculate_compliance_score(\n                header_compliance, type_compliance, docs_compliance, config_compliance\n            ),\n            compliance_deployment_approved=self._approve_compliance_deployment(\n                header_compliance, type_compliance, docs_compliance, config_compliance\n            )\n        )\n\n    def _validate_ascii_headers(self) -> HeaderComplianceResult:\n        \"\"\"Validate ASCII header compliance across Python files.\"\"\"\n\n        header_violations = []\n        compliant_files = []\n\n        python_files = glob.glob('src/**/*.py', recursive=True) + glob.glob('tests/**/*.py', recursive=True)\n\n        for file_path in python_files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n\n                # Check for proper ASCII header format\n                header_validation = self._validate_file_header(content, file_path)\n\n                if header_validation.is_compliant:\n                    compliant_files.append(file_path)\n                else:\n                    header_violations.append({\n                        'file': file_path,\n                        'issues': header_validation.issues,\n                        'suggested_header': header_validation.suggested_header\n                    })\n\n            except Exception as e:\n                header_violations.append({\n                    'file': file_path,\n                    'error': str(e),\n                    'issue_type': 'file_access_error'\n                })\n\n        compliance_percentage = len(compliant_files) / len(python_files) * 100\n\n        return HeaderComplianceResult(\n            total_files=len(python_files),\n            compliant_files=len(compliant_files),\n            compliance_percentage=compliance_percentage,\n            violations=header_violations,\n            compliance_status='passed' if compliance_percentage >= 95.0 else 'failed'\n        )",
    "lines": 75,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fac21523"
  },
  {
    "id": "quality_gate_independence_framework_6_d91a9def",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass GracefulDegradationManager:\n    \"\"\"Manages graceful degradation when validation paths fail.\"\"\"\n\n    def __init__(self):\n        self.fallback_strategies = {\n            'coverage_validation': self._coverage_fallback_strategy,\n            'mathematical_validation': self._mathematical_fallback_strategy,\n            'performance_validation': self._performance_fallback_strategy,\n            'compliance_validation': self._compliance_fallback_strategy\n        }\n\n    def apply_graceful_degradation(self,\n                                  failed_paths: List[str],\n                                  partial_results: Dict[str, Any]) -> DegradedValidationResult:\n        \"\"\"Apply graceful degradation for failed validation paths.\"\"\"\n\n        degraded_results = {}\n\n        for failed_path in failed_paths:\n            if failed_path in self.fallback_strategies:\n                try:\n                    # Apply fallback strategy\n                    fallback_result = self.fallback_strategies[failed_path](partial_results)\n                    degraded_results[failed_path] = fallback_result\n                except Exception as e:\n                    # Final fallback: use historical data\n                    degraded_results[failed_path] = self._use_historical_baseline(failed_path, str(e))\n            else:\n                # Unknown path - use minimal fallback\n                degraded_results[failed_path] = self._minimal_fallback(failed_path)\n\n        return DegradedValidationResult(\n            degraded_results=degraded_results,\n            degradation_level=self._assess_degradation_level(failed_paths),\n            deployment_impact=self._assess_deployment_impact(failed_paths, degraded_results),\n            recovery_recommendations=self._generate_recovery_recommendations(failed_paths)\n        )\n\n    def _coverage_fallback_strategy(self, partial_results: Dict[str, Any]) -> FallbackResult:\n        \"\"\"Fallback strategy for coverage validation failures.\"\"\"\n\n        # Strategy 1: Use partial coverage data\n        if 'partial_coverage' in partial_results:\n            partial_coverage = partial_results['partial_coverage']\n\n            # Calculate weighted coverage from available data\n            weighted_coverage = self._calculate_weighted_partial_coverage(partial_coverage)\n\n            return FallbackResult(\n                strategy_used='partial_coverage_analysis',\n                result_confidence=0.7,\n                fallback_data=weighted_coverage,\n                limitations=['incomplete_module_coverage', 'reduced_accuracy'],\n                deployment_impact='medium_risk'\n            )\n\n        # Strategy 2: Use historical coverage baseline\n        historical_coverage = self._get_historical_coverage_baseline()\n\n        return FallbackResult(\n            strategy_used='historical_baseline',\n            result_confidence=0.4,\n            fallback_data=historical_coverage,\n            limitations=['outdated_data', 'no_current_validation'],\n            deployment_impact='high_risk'\n        )\n\n    def _mathematical_fallback_strategy(self, partial_results: Dict[str, Any]) -> FallbackResult:\n        \"\"\"Fallback strategy for mathematical validation failures.\"\"\"\n\n        # Strategy 1: Use static mathematical analysis\n        if 'static_analysis' in partial_results:\n            static_results = partial_results['static_analysis']\n\n            mathematical_confidence = self._assess_static_mathematical_properties(static_results)\n\n            return FallbackResult(\n                strategy_used='static_mathematical_analysis',\n                result_confidence=0.6,\n                fallback_data=mathematical_confidence,\n                limitations=['no_dynamic_validation', 'theoretical_only'],\n                deployment_impact='medium_risk'\n            )\n\n        # Strategy 2: Use theoretical validation from literature\n        theoretical_validation = self._apply_theoretical_validation()\n\n        return FallbackResult(\n            strategy_used='theoretical_literature_validation',\n            result_confidence=0.5,\n            fallback_data=theoretical_validation,\n            limitations=['no_implementation_validation', 'generic_theory'],\n            deployment_impact='high_risk'\n        )",
    "lines": 97,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d91a9def"
  },
  {
    "id": "quality_gate_independence_framework_7_fe32c66c",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass PartialSuccessReporter:\n    \"\"\"Reports partial validation success with specific gap identification.\"\"\"\n\n    def generate_partial_success_report(self,\n                                      validation_results: IndependentValidationResults) -> PartialSuccessReport:\n        \"\"\"Generate comprehensive partial success report.\"\"\"\n\n        # Analyze successful validation paths\n        successful_paths = self._identify_successful_paths(validation_results)\n\n        # Analyze failed validation paths\n        failed_paths = self._identify_failed_paths(validation_results)\n\n        # Analyze partial validation paths\n        partial_paths = self._identify_partial_paths(validation_results)\n\n        # Calculate overall system confidence\n        system_confidence = self._calculate_system_confidence(\n            successful_paths, failed_paths, partial_paths\n        )\n\n        # Generate deployment recommendation\n        deployment_recommendation = self._generate_deployment_recommendation(\n            successful_paths, failed_paths, partial_paths, system_confidence\n        )\n\n        return PartialSuccessReport(\n            successful_validations={\n                'paths': successful_paths,\n                'confidence_level': self._calculate_success_confidence(successful_paths),\n                'coverage_areas': self._identify_covered_areas(successful_paths)\n            },\n            failed_validations={\n                'paths': failed_paths,\n                'failure_modes': self._analyze_failure_modes(failed_paths),\n                'impact_assessment': self._assess_failure_impact(failed_paths)\n            },\n            partial_validations={\n                'paths': partial_paths,\n                'completion_percentage': self._calculate_completion_percentage(partial_paths),\n                'identified_gaps': self._identify_validation_gaps(partial_paths)\n            },\n            system_confidence=system_confidence,\n            deployment_recommendation=deployment_recommendation,\n            improvement_priorities=self._prioritize_improvements(\n                failed_paths, partial_paths, system_confidence\n            )\n        )\n\n    def _calculate_system_confidence(self,\n                                   successful_paths: List[str],\n                                   failed_paths: List[str],\n                                   partial_paths: List[str]) -> SystemConfidence:\n        \"\"\"Calculate overall system confidence based on validation results.\"\"\"\n\n        # Weight validation paths by importance\n        path_weights = {\n            'coverage_validation': 0.3,        # Important but not critical alone\n            'mathematical_validation': 0.4,    # Critical for correctness\n            'performance_validation': 0.2,     # Important for deployment\n            'compliance_validation': 0.1       # Important for maintainability\n        }\n\n        # Calculate weighted success score\n        weighted_success = 0.0\n        total_weight = 0.0\n\n        for path in successful_paths:\n            if path in path_weights:\n                weighted_success += path_weights[path] * 1.0\n                total_weight += path_weights[path]\n\n        # Add partial success contributions\n        for path in partial_paths:\n            if path in path_weights:\n                partial_completion = self._get_path_completion_percentage(path)\n                weighted_success += path_weights[path] * partial_completion\n                total_weight += path_weights[path]\n\n        # Calculate confidence score\n        confidence_score = weighted_success / sum(path_weights.values()) if total_weight > 0 else 0.0\n\n        # Determine confidence level\n        if confidence_score >= 0.9:\n            confidence_level = 'high'\n        elif confidence_score >= 0.7:\n            confidence_level = 'medium'\n        elif confidence_score >= 0.5:\n            confidence_level = 'low'\n        else:\n            confidence_level = 'very_low'\n\n        return SystemConfidence(\n            score=confidence_score,\n            level=confidence_level,\n            contributing_factors=self._identify_confidence_factors(\n                successful_paths, failed_paths, partial_paths\n            ),\n            risk_assessment=self._assess_deployment_risk(confidence_score, failed_paths)\n        )",
    "lines": 103,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe32c66c"
  },
  {
    "id": "quality_gate_independence_framework_8_2b288880",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass DeploymentDecisionEngine:\n    \"\"\"Makes deployment decisions based on independent validation results.\"\"\"\n\n    def __init__(self):\n        self.decision_criteria = {\n            'safety_critical_coverage': {\n                'weight': 0.25,\n                'threshold': 100.0,  # Must be 100%\n                'tolerance': 0.0     # No tolerance for safety-critical\n            },\n            'mathematical_validation': {\n                'weight': 0.25,\n                'threshold': 0.9,    # 90% mathematical validation\n                'tolerance': 0.1     # Small tolerance allowed\n            },\n            'critical_coverage': {\n                'weight': 0.20,\n                'threshold': 95.0,   # 95% coverage\n                'tolerance': 0.05    # 5% tolerance\n            },\n            'performance_validation': {\n                'weight': 0.15,\n                'threshold': 0.8,    # 80% performance validation\n                'tolerance': 0.2     # 20% tolerance\n            },\n            'compliance_validation': {\n                'weight': 0.10,\n                'threshold': 0.85,   # 85% compliance\n                'tolerance': 0.15    # 15% tolerance\n            },\n            'general_coverage': {\n                'weight': 0.05,\n                'threshold': 85.0,   # 85% coverage\n                'tolerance': 0.15    # 15% tolerance\n            }\n        }\n\n    def make_deployment_decision(self,\n                               validation_results: IndependentValidationResults) -> DeploymentDecision:\n        \"\"\"Make deployment decision based on independent validation results.\"\"\"\n\n        # Extract criteria values from validation results\n        criteria_values = self._extract_criteria_values(validation_results)\n\n        # Evaluate each criterion\n        criterion_evaluations = {}\n        for criterion, config in self.decision_criteria.items():\n            evaluation = self._evaluate_criterion(\n                criterion,\n                criteria_values.get(criterion, 0.0),\n                config\n            )\n            criterion_evaluations[criterion] = evaluation\n\n        # Calculate weighted deployment score\n        deployment_score = self._calculate_deployment_score(criterion_evaluations)\n\n        # Make deployment decision\n        deployment_decision = self._determine_deployment_status(\n            deployment_score, criterion_evaluations\n        )\n\n        # Generate deployment conditions and recommendations\n        deployment_conditions = self._generate_deployment_conditions(criterion_evaluations)\n\n        return DeploymentDecision(\n            decision=deployment_decision,\n            score=deployment_score,\n            criterion_evaluations=criterion_evaluations,\n            deployment_conditions=deployment_conditions,\n            risk_assessment=self._assess_deployment_risk(\n                deployment_score, criterion_evaluations\n            ),\n            rollback_plan=self._generate_rollback_plan(criterion_evaluations),\n            monitoring_requirements=self._define_monitoring_requirements(\n                deployment_decision, criterion_evaluations\n            )\n        )\n\n    def _determine_deployment_status(self,\n                                   deployment_score: float,\n                                   criterion_evaluations: Dict[str, CriterionEvaluation]) -> str:\n        \"\"\"Determine deployment status based on score and critical failures.\"\"\"\n\n        # Check for critical failures that block deployment\n        critical_failures = []\n\n        # Safety-critical coverage must be 100%\n        safety_critical_eval = criterion_evaluations.get('safety_critical_coverage')\n        if safety_critical_eval and not safety_critical_eval.passed:\n            critical_failures.append('safety_critical_coverage_failed')\n\n        # Mathematical validation is critical for correctness\n        mathematical_eval = criterion_evaluations.get('mathematical_validation')\n        if mathematical_eval and mathematical_eval.score < 0.7:  # Minimum mathematical validation\n            critical_failures.append('mathematical_validation_insufficient')\n\n        # If any critical failures, deployment is blocked\n        if critical_failures:\n            return 'blocked'\n\n        # Deployment decision based on overall score\n        if deployment_score >= 0.9:\n            return 'approved'\n        elif deployment_score >= 0.8:\n            return 'conditional_approval'\n        elif deployment_score >= 0.7:\n            return 'conditional_approval_with_monitoring'\n        else:\n            return 'rejected'\n\n    def _generate_deployment_conditions(self,\n                                      criterion_evaluations: Dict[str, CriterionEvaluation]) -> List[DeploymentCondition]:\n        \"\"\"Generate specific deployment conditions based on evaluation results.\"\"\"\n\n        conditions = []\n\n        # Check for conditions based on specific criterion failures\n        for criterion, evaluation in criterion_evaluations.items():\n            if not evaluation.passed:\n                if criterion == 'safety_critical_coverage':\n                    conditions.append(DeploymentCondition(\n                        type='blocking',\n                        description='Safety-critical coverage must reach 100% before deployment',\n                        required_action='Complete safety-critical test coverage',\n                        estimated_effort='high',\n                        priority='critical'\n                    ))\n\n                elif criterion == 'mathematical_validation':\n                    conditions.append(DeploymentCondition(\n                        type='conditional',\n                        description='Mathematical validation below threshold',\n                        required_action='Complete mathematical property verification',\n                        estimated_effort='medium',\n                        priority='high'\n                    ))\n\n                elif criterion == 'performance_validation':\n                    conditions.append(DeploymentCondition(\n                        type='monitoring',\n                        description='Performance validation partial - requires monitoring',\n                        required_action='Implement performance monitoring in production',\n                        estimated_effort='low',\n                        priority='medium'\n                    ))\n\n        return conditions",
    "lines": 151,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b288880"
  },
  {
    "id": "quality_gate_independence_framework_9_3addd2d3",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass RiskAssessmentEngine:\n    \"\"\"Assesses deployment risks and generates mitigation strategies.\"\"\"\n\n    def assess_deployment_risk(self,\n                              validation_results: IndependentValidationResults,\n                              deployment_decision: DeploymentDecision) -> RiskAssessment:\n        \"\"\"Comprehensive deployment risk assessment.\"\"\"\n\n        # Identify specific risk factors\n        risk_factors = self._identify_risk_factors(validation_results)\n\n        # Assess risk levels for each factor\n        risk_levels = self._assess_risk_levels(risk_factors)\n\n        # Calculate overall risk score\n        overall_risk = self._calculate_overall_risk(risk_levels)\n\n        # Generate mitigation strategies\n        mitigation_strategies = self._generate_mitigation_strategies(risk_factors, risk_levels)\n\n        # Define monitoring requirements\n        monitoring_requirements = self._define_risk_monitoring(risk_factors)\n\n        return RiskAssessment(\n            overall_risk_level=overall_risk.level,\n            overall_risk_score=overall_risk.score,\n            risk_factors=risk_factors,\n            risk_levels=risk_levels,\n            mitigation_strategies=mitigation_strategies,\n            monitoring_requirements=monitoring_requirements,\n            rollback_triggers=self._define_rollback_triggers(risk_factors),\n            acceptable_risk_threshold=self._determine_acceptable_risk_threshold(deployment_decision)\n        )\n\n    def _identify_risk_factors(self,\n                             validation_results: IndependentValidationResults) -> List[RiskFactor]:\n        \"\"\"Identify specific risk factors from validation results.\"\"\"\n\n        risk_factors = []\n\n        # Coverage-related risks\n        coverage_result = validation_results.path_results.get('coverage_validation')\n        if coverage_result:\n            if coverage_result.tier_compliance['safety_critical'] < 100.0:\n                risk_factors.append(RiskFactor(\n                    category='safety',\n                    type='incomplete_safety_critical_coverage',\n                    severity='high',\n                    probability='medium',\n                    impact='system_instability',\n                    description='Safety-critical components not fully tested'\n                ))\n\n            if coverage_result.tier_compliance['critical'] < 95.0:\n                risk_factors.append(RiskFactor(\n                    category='functionality',\n                    type='incomplete_critical_coverage',\n                    severity='medium',\n                    probability='medium',\n                    impact='functionality_failure',\n                    description='Critical components not adequately tested'\n                ))\n\n        # Mathematical validation risks\n        mathematical_result = validation_results.path_results.get('mathematical_validation')\n        if mathematical_result:\n            if mathematical_result.mathematical_rigor_score < 0.8:\n                risk_factors.append(RiskFactor(\n                    category='correctness',\n                    type='insufficient_mathematical_validation',\n                    severity='high',\n                    probability='medium',\n                    impact='incorrect_behavior',\n                    description='Mathematical properties not sufficiently verified'\n                ))\n\n        # Performance-related risks\n        performance_result = validation_results.path_results.get('performance_validation')\n        if performance_result:\n            if not performance_result.deployment_performance_approved:\n                risk_factors.append(RiskFactor(\n                    category='performance',\n                    type='performance_degradation',\n                    severity='medium',\n                    probability='high',\n                    impact='real_time_constraint_violation',\n                    description='Performance may not meet real-time requirements'\n                ))\n\n        return risk_factors\n\n    def _generate_mitigation_strategies(self,\n                                      risk_factors: List[RiskFactor],\n                                      risk_levels: Dict[str, RiskLevel]) -> List[MitigationStrategy]:\n        \"\"\"Generate specific mitigation strategies for identified risks.\"\"\"\n\n        mitigation_strategies = []\n\n        for risk_factor in risk_factors:\n            if risk_factor.type == 'incomplete_safety_critical_coverage':\n                mitigation_strategies.append(MitigationStrategy(\n                    risk_factor=risk_factor.type,\n                    strategy_type='preventive',\n                    actions=[\n                        'Complete safety-critical test coverage before deployment',\n                        'Implement additional property-based testing',\n                        'Add formal verification for control laws'\n                    ],\n                    timeline='before_deployment',\n                    estimated_effort='high',\n                    success_criteria='100% safety-critical coverage achieved'\n                ))\n\n            elif risk_factor.type == 'insufficient_mathematical_validation':\n                mitigation_strategies.append(MitigationStrategy(\n                    risk_factor=risk_factor.type,\n                    strategy_type='verification',\n                    actions=[\n                        'Complete mathematical property verification',\n                        'Implement Lyapunov stability testing',\n                        'Add convergence analysis validation'\n                    ],\n                    timeline='before_deployment',\n                    estimated_effort='medium',\n                    success_criteria='Mathematical rigor score \u2265 0.9'\n                ))\n\n            elif risk_factor.type == 'performance_degradation':\n                mitigation_strategies.append(MitigationStrategy(\n                    risk_factor=risk_factor.type,\n                    strategy_type='monitoring',\n                    actions=[\n                        'Implement real-time performance monitoring',\n                        'Set up automated performance alerts',\n                        'Prepare performance optimization patches'\n                    ],\n                    timeline='during_deployment',\n                    estimated_effort='low',\n                    success_criteria='Performance monitoring active and responsive'\n                ))\n\n        return mitigation_strategies",
    "lines": 145,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3addd2d3"
  },
  {
    "id": "quality_gate_independence_framework_10_5c299811",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass QualityGateIntegrator:\n    \"\"\"Integrates quality gate independence framework with existing systems.\"\"\"\n\n    def __init__(self):\n        self.validation_orchestrator = ValidationOrchestrator()\n        self.failure_tolerance_manager = FailureToleranceManager()\n        self.deployment_decision_engine = DeploymentDecisionEngine()\n\n    def execute_independent_quality_gates(self) -> QualityGateResults:\n        \"\"\"Execute complete independent quality gate validation.\"\"\"\n\n        # Start independent validation paths\n        validation_results = self.validation_orchestrator.execute_parallel_validation()\n\n        # Handle any failures with tolerance mechanisms\n        if validation_results.has_failures():\n            degraded_results = self.failure_tolerance_manager.handle_failures(\n                validation_results.failed_paths,\n                validation_results.partial_results\n            )\n            validation_results = validation_results.merge_with_degraded(degraded_results)\n\n        # Make deployment decision\n        deployment_decision = self.deployment_decision_engine.make_deployment_decision(\n            validation_results\n        )\n\n        # Generate comprehensive report\n        comprehensive_report = self._generate_comprehensive_report(\n            validation_results, deployment_decision\n        )\n\n        return QualityGateResults(\n            validation_results=validation_results,\n            deployment_decision=deployment_decision,\n            comprehensive_report=comprehensive_report,\n            execution_timestamp=datetime.now(),\n            framework_version=self._get_framework_version()\n        )\n\n    def _generate_comprehensive_report(self,\n                                     validation_results: IndependentValidationResults,\n                                     deployment_decision: DeploymentDecision) -> ComprehensiveReport:\n        \"\"\"Generate comprehensive quality gate report.\"\"\"\n\n        return ComprehensiveReport(\n            executive_summary=self._generate_executive_summary(\n                validation_results, deployment_decision\n            ),\n            validation_path_details=self._generate_path_details(validation_results),\n            deployment_decision_rationale=self._generate_decision_rationale(deployment_decision),\n            risk_assessment=self._generate_risk_assessment(\n                validation_results, deployment_decision\n            ),\n            improvement_recommendations=self._generate_improvement_recommendations(\n                validation_results, deployment_decision\n            ),\n            appendices={\n                'detailed_metrics': validation_results.detailed_metrics,\n                'failure_logs': validation_results.failure_logs,\n                'performance_data': validation_results.performance_data\n            }\n        )",
    "lines": 66,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c299811"
  },
  {
    "id": "quality_gate_independence_framework_11_6153c857",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass FrameworkHealthMonitor:\n    \"\"\"Monitors the health and effectiveness of the quality gate framework.\"\"\"\n\n    def __init__(self):\n        self.health_metrics = {}\n        self.performance_history = []\n        self.failure_patterns = {}\n\n    def monitor_framework_health(self) -> FrameworkHealthReport:\n        \"\"\"Monitor overall framework health and effectiveness.\"\"\"\n\n        # Monitor validation path reliability\n        path_reliability = self._monitor_path_reliability()\n\n        # Monitor failure tolerance effectiveness\n        tolerance_effectiveness = self._monitor_tolerance_effectiveness()\n\n        # Monitor deployment decision accuracy\n        decision_accuracy = self._monitor_decision_accuracy()\n\n        # Monitor framework performance\n        performance_metrics = self._monitor_performance_metrics()\n\n        return FrameworkHealthReport(\n            overall_health=self._calculate_overall_health(\n                path_reliability, tolerance_effectiveness, decision_accuracy, performance_metrics\n            ),\n            path_reliability=path_reliability,\n            tolerance_effectiveness=tolerance_effectiveness,\n            decision_accuracy=decision_accuracy,\n            performance_metrics=performance_metrics,\n            improvement_recommendations=self._generate_health_improvements(\n                path_reliability, tolerance_effectiveness, decision_accuracy\n            )\n        )\n\n    def _monitor_path_reliability(self) -> PathReliabilityReport:\n        \"\"\"Monitor reliability of individual validation paths.\"\"\"\n\n        path_reliability = {}\n\n        for path_name in ['coverage', 'mathematical', 'performance', 'compliance']:\n            # Calculate success rate over time\n            recent_executions = self._get_recent_path_executions(path_name, days=30)\n\n            success_rate = len([e for e in recent_executions if e.status == 'success']) / len(recent_executions)\n\n            # Calculate average execution time\n            avg_execution_time = np.mean([e.execution_time for e in recent_executions])\n\n            # Identify failure patterns\n            failure_patterns = self._analyze_failure_patterns(\n                [e for e in recent_executions if e.status != 'success']\n            )\n\n            path_reliability[path_name] = PathReliability(\n                success_rate=success_rate,\n                average_execution_time=avg_execution_time,\n                failure_patterns=failure_patterns,\n                trend=self._calculate_reliability_trend(path_name)\n            )\n\n        return PathReliabilityReport(path_reliability=path_reliability)\n\n    def _monitor_tolerance_effectiveness(self) -> ToleranceEffectivenessReport:\n        \"\"\"Monitor effectiveness of failure tolerance mechanisms.\"\"\"\n\n        # Analyze graceful degradation success\n        degradation_events = self._get_recent_degradation_events(days=30)\n\n        degradation_success_rate = len([\n            e for e in degradation_events if e.recovery_successful\n        ]) / len(degradation_events) if degradation_events else 1.0\n\n        # Analyze partial success reporting accuracy\n        partial_success_events = self._get_recent_partial_success_events(days=30)\n\n        partial_success_accuracy = self._calculate_partial_success_accuracy(partial_success_events)\n\n        return ToleranceEffectivenessReport(\n            degradation_success_rate=degradation_success_rate,\n            partial_success_accuracy=partial_success_accuracy,\n            recovery_time_statistics=self._calculate_recovery_time_stats(degradation_events),\n            effectiveness_trend=self._calculate_tolerance_trend()\n        )",
    "lines": 88,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6153c857"
  },
  {
    "id": "quality_gate_independence_framework_12_22853049",
    "file": "docs\\quality_gate_independence_framework.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass FrameworkImprovementEngine:\n    \"\"\"Continuously improves the quality gate framework based on experience.\"\"\"\n\n    def __init__(self):\n        self.improvement_history = []\n        self.learning_algorithms = {\n            'threshold_optimization': ThresholdOptimizer(),\n            'weight_adjustment': WeightAdjuster(),\n            'tolerance_tuning': ToleranceTuner()\n        }\n\n    def execute_continuous_improvement(self) -> ImprovementResults:\n        \"\"\"Execute continuous improvement based on historical data.\"\"\"\n\n        # Analyze framework performance over time\n        performance_analysis = self._analyze_framework_performance()\n\n        # Identify improvement opportunities\n        improvement_opportunities = self._identify_improvement_opportunities(performance_analysis)\n\n        # Generate improvement recommendations\n        improvement_recommendations = self._generate_improvement_recommendations(\n            improvement_opportunities\n        )\n\n        # Apply safe improvements automatically\n        applied_improvements = self._apply_safe_improvements(improvement_recommendations)\n\n        return ImprovementResults(\n            performance_analysis=performance_analysis,\n            improvement_opportunities=improvement_opportunities,\n            improvement_recommendations=improvement_recommendations,\n            applied_improvements=applied_improvements,\n            next_review_date=self._calculate_next_review_date()\n        )\n\n    def _optimize_quality_thresholds(self) -> ThresholdOptimizationResult:\n        \"\"\"Optimize quality gate thresholds based on historical success rates.\"\"\"\n\n        # Analyze historical deployment outcomes\n        deployment_history = self._get_deployment_history(days=90)\n\n        # Correlate quality scores with deployment success\n        score_success_correlation = self._analyze_score_success_correlation(deployment_history)\n\n        # Optimize thresholds to minimize false positives/negatives\n        optimized_thresholds = self._optimize_thresholds(score_success_correlation)\n\n        return ThresholdOptimizationResult(\n            current_thresholds=self._get_current_thresholds(),\n            optimized_thresholds=optimized_thresholds,\n            expected_improvement=self._calculate_expected_improvement(optimized_thresholds),\n            confidence_level=self._calculate_optimization_confidence(score_success_correlation)\n        )",
    "lines": 57,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "22853049"
  },
  {
    "id": "safety_system_validation_protocols_1_e2cd8b79",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# MANDATORY: 100% line coverage\ndef test_saturation_boundary_conditions():\n    \"\"\"Test control signal saturation at exact limits.\"\"\"\n    assert saturate_control_signal(10.1, 10.0) == 10.0\n    assert saturate_control_signal(-10.1, -10.0) == -10.0\n\n@hypothesis.given(control_signal=st.floats(min_value=-1000, max_value=1000))\ndef test_saturation_property_based(control_signal):\n    \"\"\"Property-based test for saturation function.\"\"\"\n    result = saturate_control_signal(control_signal, 10.0)\n    assert -10.0 <= result <= 10.0",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2cd8b79"
  },
  {
    "id": "safety_system_validation_protocols_2_d18119a0",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 2,
    "code": "import pytest\nimport hypothesis\nfrom hypothesis import strategies as st\n\nclass TestSafetyComponent:\n    \"\"\"Safety-critical component validation tests.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup test environment with known safe parameters.\"\"\"\n        self.safe_params = load_validated_parameters()\n        self.test_component = SafetyComponent(self.safe_params)\n\n    def test_nominal_operation(self):\n        \"\"\"Test component under normal operating conditions.\"\"\"\n        # MANDATORY: Test all normal operating modes\n        pass\n\n    def test_boundary_conditions(self):\n        \"\"\"Test component at operating limits.\"\"\"\n        # MANDATORY: Test at parameter boundaries\n        pass\n\n    @hypothesis.given(st.floats(min_value=-1e6, max_value=1e6))\n    def test_property_based_safety(self, random_input):\n        \"\"\"Property-based testing for safety invariants.\"\"\"\n        # MANDATORY: Verify safety properties hold for all inputs\n        pass\n\n    def test_fault_injection(self):\n        \"\"\"Test component response to injected faults.\"\"\"\n        # MANDATORY: Verify safe behavior under fault conditions\n        pass",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d18119a0"
  },
  {
    "id": "safety_system_validation_protocols_3_f990e58f",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass SafetyIntegrationTest:\n    \"\"\"Integration testing for safety-critical subsystems.\"\"\"\n\n    def test_emergency_stop_integration(self):\n        \"\"\"Test complete emergency stop workflow.\"\"\"\n        # 1. Initialize system in normal operation\n        # 2. Trigger emergency stop condition\n        # 3. Verify response time < 50ms\n        # 4. Confirm safe state achieved\n        # 5. Test recovery procedure\n        pass\n\n    def test_fault_detection_chain(self):\n        \"\"\"Test fault detection through complete chain.\"\"\"\n        # 1. Inject known fault condition\n        # 2. Verify detection at sensor level\n        # 3. Confirm propagation to safety monitor\n        # 4. Validate response action taken\n        # 5. Check safety state maintenance\n        pass",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f990e58f"
  },
  {
    "id": "safety_system_validation_protocols_4_b854abff",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n@hypothesis.given(\n    theta1=st.floats(min_value=-\u03c0, max_value=\u03c0),\n    theta2=st.floats(min_value=-\u03c0, max_value=\u03c0),\n    control_gains=st.lists(st.floats(min_value=0.1, max_value=100), min_size=6, max_size=6)\n)\ndef test_lyapunov_stability_property(theta1, theta2, control_gains):\n    \"\"\"Verify Lyapunov stability for all valid parameter combinations.\"\"\"\n    controller = ClassicalSMC(gains=control_gains)\n    state = np.array([theta1, theta2, 0, 0, 0, 0])\n\n    # Compute Lyapunov function\n    V = controller.compute_lyapunov_function(state)\n\n    # Property: V \u2265 0 for all states\n    assert V >= 0\n\n    # Property: V = 0 only at equilibrium\n    if not np.allclose(state, 0):\n        assert V > 0",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b854abff"
  },
  {
    "id": "safety_system_validation_protocols_5_dfe3e18a",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_safety_branch_coverage():\n    \"\"\"Verify all safety-critical branches are tested.\"\"\"\n    safety_modules = [\n        'src.utils.control.saturation',\n        'src.utils.safety.emergency_stop',\n        'src.utils.validation.parameter_validator'\n    ]\n\n    for module in safety_modules:\n        coverage = get_branch_coverage(module)\n        assert coverage == 100.0, f\"Safety module {module} coverage: {coverage}%\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dfe3e18a"
  },
  {
    "id": "safety_system_validation_protocols_6_bf687abd",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass SafetyDashboard:\n    \"\"\"Real-time safety monitoring dashboard.\"\"\"\n\n    def __init__(self):\n        self.indicators = {\n            'stability_margin': StabilityIndicator(),\n            'control_saturation': SaturationIndicator(),\n            'parameter_bounds': ParameterBoundsIndicator(),\n            'emergency_status': EmergencyStatusIndicator()\n        }\n\n    def update_safety_status(self, system_state):\n        \"\"\"Update all safety indicators.\"\"\"\n        safety_status = {}\n        for name, indicator in self.indicators.items():\n            status = indicator.evaluate(system_state)\n            safety_status[name] = status\n\n            if status.level == SafetyLevel.CRITICAL:\n                self.trigger_emergency_response(name, status)\n\n        return safety_status",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bf687abd"
  },
  {
    "id": "safety_system_validation_protocols_7_80cae849",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef runtime_safety_check(state, control_signal, parameters):\n    \"\"\"Continuous runtime safety validation.\"\"\"\n\n    # ASSERTION 1: Control signal within safe bounds\n    assert np.all(np.abs(control_signal) <= CONTROL_LIMITS), \\\n        f\"Control signal {control_signal} exceeds limits {CONTROL_LIMITS}\"\n\n    # ASSERTION 2: Parameters within validated ranges\n    assert validate_parameter_bounds(parameters), \\\n        f\"Parameters {parameters} outside validated ranges\"\n\n    # ASSERTION 3: System state within operational envelope\n    assert validate_state_bounds(state), \\\n        f\"System state {state} outside operational envelope\"\n\n    # ASSERTION 4: Stability maintained\n    lyapunov_value = compute_lyapunov_function(state)\n    assert lyapunov_value >= 0, \\\n        f\"Lyapunov function negative: {lyapunov_value}\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80cae849"
  },
  {
    "id": "safety_system_validation_protocols_8_2e112ec0",
    "file": "docs\\safety_system_validation_protocols.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass EmergencyRecoverySystem:\n    \"\"\"Automated emergency recovery procedures.\"\"\"\n\n    def attempt_safe_recovery(self, fault_condition):\n        \"\"\"Attempt automated recovery if conditions permit.\"\"\"\n\n        # Step 1: Verify fault condition resolved\n        if not self.verify_fault_resolved(fault_condition):\n            return RecoveryStatus.MANUAL_INTERVENTION_REQUIRED\n\n        # Step 2: Validate system integrity\n        if not self.validate_system_integrity():\n            return RecoveryStatus.SYSTEM_DAMAGED\n\n        # Step 3: Perform staged restart\n        return self.staged_system_restart()\n\n    def staged_system_restart(self):\n        \"\"\"Perform staged system restart with validation.\"\"\"\n\n        # Stage 1: Parameter validation\n        if not self.validate_all_parameters():\n            return RecoveryStatus.PARAMETER_ERROR\n\n        # Stage 2: Hardware check\n        if not self.verify_hardware_status():\n            return RecoveryStatus.HARDWARE_ERROR\n\n        # Stage 3: Control loop restart\n        return self.restart_control_loops()",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e112ec0"
  },
  {
    "id": "session-continuity_1_52a56f79",
    "file": "docs\\session-continuity.md",
    "index": 1,
    "code": "update_session_context(\n       current_task=\"Implementing automated backup system\",\n       phase=\"implementation\"\n   )",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52a56f79"
  },
  {
    "id": "session-continuity_2_68f8f6ad",
    "file": "docs\\session-continuity.md",
    "index": 2,
    "code": "add_completed_todo(\"Create PowerShell backup script\")\n   add_completed_todo(\"Write documentation\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68f8f6ad"
  },
  {
    "id": "session-continuity_3_b882d055",
    "file": "docs\\session-continuity.md",
    "index": 3,
    "code": "add_decision(\"Task Scheduler frequency: 1 minute\")\n   add_decision(\"Use ISO 8601 timestamp format\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b882d055"
  },
  {
    "id": "session-continuity_4_a67c4926",
    "file": "docs\\session-continuity.md",
    "index": 4,
    "code": "add_next_action(\"User needs to register Task Scheduler job\")\n   add_next_action(\"Run smoke test to verify functionality\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a67c4926"
  },
  {
    "id": "session-continuity_5_edbdff42",
    "file": "docs\\session-continuity.md",
    "index": 5,
    "code": "mark_token_limit_approaching()\nfinalize_session(\"Automated backup system implementation complete\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "edbdff42"
  },
  {
    "id": "session-continuity_6_116ee4a7",
    "file": "docs\\session-continuity.md",
    "index": 6,
    "code": "from session_manager import has_recent_session, get_session_summary\n\n# Check if there's a recent session to continue\nif has_recent_session(threshold_hours=24):\n    print(get_session_summary())",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "116ee4a7"
  },
  {
    "id": "session-continuity_7_ce96d1a1",
    "file": "docs\\session-continuity.md",
    "index": 7,
    "code": "from session_manager import load_session\n\nstate = load_session()\nif state:\n    current_task = state['context']['current_task']\n    phase = state['context']['phase']\n    next_actions = state['next_actions']",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce96d1a1"
  },
  {
    "id": "session-continuity_8_ed0a6663",
    "file": "docs\\session-continuity.md",
    "index": 8,
    "code": "from session_manager import update_session_context\n\nupdate_session_context(\n    current_task=\"Implementing feature X\",\n    phase=\"testing\",\n    last_commit=\"abc1234\"\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed0a6663"
  },
  {
    "id": "session-continuity_9_4387c8ce",
    "file": "docs\\session-continuity.md",
    "index": 9,
    "code": "from session_manager import add_completed_todo, add_decision, add_next_action\n\n# Mark todo as complete\nadd_completed_todo(\"Write unit tests\")\n\n# Record important decision\nadd_decision(\"Use pytest for testing framework\")\n\n# Specify next action\nadd_next_action(\"Run full test suite\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4387c8ce"
  },
  {
    "id": "session-continuity_10_3f3e09ea",
    "file": "docs\\session-continuity.md",
    "index": 10,
    "code": "from session_manager import mark_token_limit_approaching, finalize_session\n\n# Mark approaching limit\nmark_token_limit_approaching()\n\n# Finalize with summary\nfinalize_session(\"Completed feature X implementation\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f3e09ea"
  },
  {
    "id": "session-continuity_11_cb9ecc8d",
    "file": "docs\\session-continuity.md",
    "index": 11,
    "code": "# Claude automatically throughout:\nupdate_session_context(current_task=\"Add logging module\", phase=\"implementation\")\nadd_completed_todo(\"Create logger.py\")\nadd_completed_todo(\"Add log configuration\")\nadd_decision(\"Use Python logging library\")\nadd_next_action(\"Write unit tests for logger\")\n\n# Token limit approaching:\nfinalize_session(\"Logging module implementation complete\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb9ecc8d"
  },
  {
    "id": "session-continuity_12_a31cb691",
    "file": "docs\\session-continuity.md",
    "index": 12,
    "code": "update_session_context(\n    current_task=\"PSO optimization for classical SMC\",\n    phase=\"running\"\n)\nadd_decision(\"PSO parameters: 30 particles, 150 iterations\")\nadd_next_action(\"Wait for PSO completion (~3 hours)\")\nadd_next_action(\"Validate results when complete\")\nfinalize_session(\"PSO optimization started, awaiting completion\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a31cb691"
  },
  {
    "id": "session-continuity_13_7356099f",
    "file": "docs\\session-continuity.md",
    "index": 13,
    "code": "AUTO_LOAD_THRESHOLD_HOURS = 48  # 48 hours instead of 24",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7356099f"
  },
  {
    "id": "session-continuity_14_3a1e2181",
    "file": "docs\\session-continuity.md",
    "index": 14,
    "code": "state = load_session()\nsession_count = state['metadata']['session_count']\nprint(f\"This is session #{session_count}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a1e2181"
  },
  {
    "id": "session-continuity_15_aed2d73f",
    "file": "docs\\session-continuity.md",
    "index": 15,
    "code": "state = load_session()\nsession_id = state['session_id']\n# Example: \"session_20251001_104700\"",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aed2d73f"
  },
  {
    "id": "session-continuity_16_619fd90c",
    "file": "docs\\session-continuity.md",
    "index": 16,
    "code": "state = load_session()\nlast_switch = state['metadata']['last_account_switch']\n# Example: \"2025-10-01T12:30:00\"",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "619fd90c"
  },
  {
    "id": "SESSION_SUMMARY_1_fb5b4dac",
    "file": "docs\\SESSION_SUMMARY.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Original (WRONG):\nfitness = tracking_error_rms + chattering_penalty + ...\n# chattering_penalty = 0 if chattering < 2.0 \u2190 ALWAYS ZERO!\n\n# Corrected (RIGHT):\nfitness = chattering_index  # Direct minimization",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb5b4dac"
  },
  {
    "id": "streamlit_dashboard_guide_1_fefd8010",
    "file": "docs\\streamlit_dashboard_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Settings are saved automatically in browser session\n# Manual export via JSON download (if implemented)",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fefd8010"
  },
  {
    "id": "test_execution_guide_1_15e00737",
    "file": "docs\\test_execution_guide.md",
    "index": 1,
    "code": "# Available in all tests via conftest.py\nconfig           # Project configuration with attribute access\nphysics_cfg      # Physics parameters for dynamics models\nphysics_params   # Alias for physics_cfg (backward compatibility)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15e00737"
  },
  {
    "id": "test_execution_guide_2_c172cd71",
    "file": "docs\\test_execution_guide.md",
    "index": 2,
    "code": "dynamics         # Simplified DIP dynamics instance\nfull_dynamics    # Full nonlinear DIP dynamics instance\ninitial_state    # Standard initial state: [0.0, 0.1, -0.05, 0.0, 0.0, 0.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c172cd71"
  },
  {
    "id": "test_execution_guide_3_2eb32e69",
    "file": "docs\\test_execution_guide.md",
    "index": 3,
    "code": "make_hybrid      # Factory for creating HybridAdaptiveSTASMC controllers",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2eb32e69"
  },
  {
    "id": "test_execution_guide_4_f2b4199f",
    "file": "docs\\test_execution_guide.md",
    "index": 4,
    "code": "def test_controller_stability(dynamics, initial_state, make_hybrid):\n    \"\"\"Test controller stability with standard fixtures.\"\"\"\n    controller = make_hybrid(gains=[0.5, 2.0, 0.8, 1.5])\n    control_output = controller.compute_control(initial_state)\n    assert abs(control_output) <= controller.max_force",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2b4199f"
  },
  {
    "id": "test_execution_guide_5_49b89f20",
    "file": "docs\\test_execution_guide.md",
    "index": 5,
    "code": "import tempfile\nimport pytest\n\n@pytest.fixture\ndef temp_config_file():\n    \"\"\"Create temporary configuration file for testing.\"\"\"\n    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n        yaml.dump(test_config, f)\n        yield f.name\n    os.unlink(f.name)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49b89f20"
  },
  {
    "id": "test_infrastructure_documentation_1_b5cb2707",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 1,
    "code": "@pytest.mark.unit\ndef test_sliding_surface_computation():\n    \"\"\"Test sliding surface value computation for classical SMC.\"\"\"\n    controller = ClassicalSMC(gains=[10, 5, 8, 3, 15, 2])\n    state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    surface_value = controller.compute_sliding_surface(state, np.zeros(6))\n    assert isinstance(surface_value, float)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5cb2707"
  },
  {
    "id": "test_infrastructure_documentation_2_449b7ff7",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 2,
    "code": "@pytest.mark.integration\ndef test_pso_controller_optimization():\n    \"\"\"Test PSO optimization of controller parameters.\"\"\"\n    optimizer = PSOTuner(bounds=[(0.1, 50.0)] * 6)\n    controller_type = \"classical_smc\"\n    result = optimizer.optimize(controller_type, n_particles=20, n_iterations=50)\n    assert result.success\n    assert len(result.best_gains) == 6",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "449b7ff7"
  },
  {
    "id": "test_infrastructure_documentation_3_f1b82a7d",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 3,
    "code": "@pytest.mark.slow\n@pytest.mark.convergence\ndef test_pso_convergence_monte_carlo():\n    \"\"\"Monte Carlo analysis of PSO convergence properties.\"\"\"\n    # Runs 100+ optimization trials for statistical significance\n    results = run_monte_carlo_pso_analysis(n_trials=100, n_iterations=200)\n    assert results.convergence_rate > 0.95",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1b82a7d"
  },
  {
    "id": "test_infrastructure_documentation_4_82151087",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 4,
    "code": "@pytest.mark.numerical_stability\ndef test_rk45_energy_conservation():\n    \"\"\"Test energy conservation in RK45 integration with zero friction.\"\"\"\n    dynamics = DIPDynamics(friction_params={\"cart\": 0.0, \"joint1\": 0.0, \"joint2\": 0.0})\n    initial_energy = compute_total_energy(initial_state, dynamics)\n    final_state = integrate_system(dynamics, initial_state, sim_time=10.0, method=\"RK45\")\n    final_energy = compute_total_energy(final_state, dynamics)\n    assert abs(final_energy - initial_energy) / initial_energy < 1e-6",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82151087"
  },
  {
    "id": "test_infrastructure_documentation_5_ec78f076",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.convergence\n@pytest.mark.property_based\ndef test_sliding_mode_reachability(initial_state):\n    \"\"\"Test finite-time convergence to sliding surface.\"\"\"\n    controller = SuperTwistingSMC(gains=[15, 10])\n    dynamics = DIPDynamics()\n\n    t_reach = estimate_reaching_time(controller, dynamics, initial_state)\n    trajectory = simulate_reaching_phase(controller, dynamics, initial_state, t_reach * 1.5)\n\n    # Verify sliding surface is reached within predicted time\n    surface_values = [controller.compute_sliding_surface(state) for state in trajectory]\n    assert min(abs(s) for s in surface_values[-10:]) < 0.01  # Within \u03b5-band",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec78f076"
  },
  {
    "id": "test_infrastructure_documentation_6_e4e17587",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.numerical_robustness\n@pytest.mark.statistical\ndef test_controller_robustness_monte_carlo():\n    \"\"\"Statistical validation of controller robustness.\"\"\"\n    base_params = get_nominal_physics_params()\n\n    for trial in range(1000):\n        # Add \u00b120% parameter uncertainty\n        perturbed_params = add_parameter_uncertainty(base_params, std_dev=0.2)\n        dynamics = DIPDynamics(params=perturbed_params)\n\n        controller = ClassicalSMC(gains=optimized_gains)\n        performance = evaluate_stabilization(controller, dynamics, sim_time=5.0)\n\n        assert performance.settling_time < 3.0\n        assert performance.overshoot < 0.15",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4e17587"
  },
  {
    "id": "test_infrastructure_documentation_7_aca97551",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.full_dynamics\n@pytest.mark.benchmark\ndef test_full_vs_simplified_dynamics():\n    \"\"\"Compare full and simplified dynamics models.\"\"\"\n    full_dynamics = FullDIPDynamics()\n    simplified_dynamics = DIPDynamics()\n\n    controller = ClassicalSMC(gains=validated_gains)\n\n    full_trajectory = simulate_system(controller, full_dynamics, sim_time=10.0)\n    simplified_trajectory = simulate_system(controller, simplified_dynamics, sim_time=10.0)\n\n    # Trajectories should be similar for small-angle approximation regime\n    angle_error = compute_trajectory_difference(full_trajectory, simplified_trajectory)\n    assert max(angle_error) < 0.05  # Within 3 degrees",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aca97551"
  },
  {
    "id": "test_infrastructure_documentation_8_4b60a407",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 8,
    "code": "@pytest.mark.benchmark\ndef test_pso_optimization_performance(benchmark):\n    \"\"\"Benchmark PSO optimization performance.\"\"\"\n    def optimize_classical_smc():\n        optimizer = PSOTuner(bounds=controller_bounds)\n        return optimizer.optimize(\"classical_smc\", n_particles=30, n_iterations=100)\n\n    result = benchmark(optimize_classical_smc)\n    # Regression detection: should complete within 60 seconds\n    assert benchmark.stats.mean < 60.0",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b60a407"
  },
  {
    "id": "test_infrastructure_documentation_9_bfd3ddc7",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 9,
    "code": "@pytest.mark.memory\ndef test_simulation_memory_usage():\n    \"\"\"Test memory usage during extended simulation.\"\"\"\n    import psutil\n    import gc\n\n    process = psutil.Process()\n    initial_memory = process.memory_info().rss\n\n    # Run extended simulation\n    for _ in range(100):\n        simulate_system(controller, dynamics, sim_time=1.0)\n        gc.collect()\n\n    final_memory = process.memory_info().rss\n    memory_growth = (final_memory - initial_memory) / initial_memory\n\n    assert memory_growth < 0.10  # Less than 10% memory growth",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfd3ddc7"
  },
  {
    "id": "test_infrastructure_documentation_10_1dc79653",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.concurrent\n@pytest.mark.xfail(reason=\"Thread safety validation in progress\")\ndef test_parallel_pso_optimization():\n    \"\"\"Test PSO optimization with parallel fitness evaluation.\"\"\"\n    optimizer = PSOTuner(bounds=controller_bounds, n_jobs=4)\n    results = []\n\n    # Run multiple optimizations concurrently\n    with ThreadPoolExecutor(max_workers=4) as executor:\n        futures = [executor.submit(optimizer.optimize, \"classical_smc\") for _ in range(4)]\n        results = [f.result() for f in futures]\n\n    # All optimizations should succeed without race conditions\n    assert all(r.success for r in results)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1dc79653"
  },
  {
    "id": "test_infrastructure_documentation_11_98f500c0",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.property_based\n@given(\n    gains=lists(floats(min_value=0.1, max_value=50.0), min_size=6, max_size=6),\n    initial_state=arrays(dtype=float, shape=6, elements=floats(-0.5, 0.5))\n)\ndef test_controller_output_bounds(gains, initial_state):\n    \"\"\"Property test: controller output should always be bounded.\"\"\"\n    controller = ClassicalSMC(gains=gains)\n    control_output = controller.compute_control(initial_state)\n\n    # Property: control output must be finite and bounded\n    assert np.all(np.isfinite(control_output))\n    assert abs(control_output) <= controller.max_force",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "98f500c0"
  },
  {
    "id": "test_infrastructure_documentation_12_04dbd2c8",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.statistical\ndef test_optimization_performance_distribution():\n    \"\"\"Statistical analysis of optimization performance distribution.\"\"\"\n    performance_samples = []\n\n    for _ in range(50):\n        optimizer = PSOTuner(bounds=controller_bounds)\n        result = optimizer.optimize(\"adaptive_smc\", n_particles=20, n_iterations=100)\n        performance_samples.append(result.best_fitness)\n\n    # Statistical tests\n    mean_performance = np.mean(performance_samples)\n    std_performance = np.std(performance_samples)\n\n    # 95% confidence interval should indicate good performance\n    confidence_interval = stats.norm.interval(0.95, mean_performance, std_performance)\n    assert confidence_interval[1] < 10.0  # Upper bound on fitness cost",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04dbd2c8"
  },
  {
    "id": "test_infrastructure_documentation_13_072c0734",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.end_to_end\n@pytest.mark.slow\ndef test_complete_optimization_workflow():\n    \"\"\"Test complete workflow: config \u2192 optimization \u2192 validation \u2192 deployment.\"\"\"\n\n    # 1. Load configuration\n    config = load_config(\"config.yaml\")\n\n    # 2. Run PSO optimization\n    optimizer = create_optimizer_from_config(config)\n    optimization_result = optimizer.optimize(\"hybrid_adaptive_sta_smc\")\n\n    # 3. Validate optimized controller\n    controller = create_controller(\"hybrid_adaptive_sta_smc\", gains=optimization_result.best_gains)\n    validation_score = validate_controller_performance(controller)\n\n    # 4. Check deployment readiness\n    assert validation_score.stability_margin > 0.5\n    assert validation_score.performance_index < 5.0\n    assert validation_score.robustness_score > 0.8",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "072c0734"
  },
  {
    "id": "test_infrastructure_documentation_14_7a17c223",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 14,
    "code": "# Automatic configuration in tests/conftest.py\nos.environ.setdefault(\"MPLBACKEND\", \"Agg\")\nmatplotlib.use(\"Agg\", force=True)\n\n# Runtime ban on plt.show()\ndef _no_show(*args, **kwargs):\n    raise AssertionError(\"plt.show() is banned in tests. Use savefig() or return Figure.\")\nplt.show = _no_show",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a17c223"
  },
  {
    "id": "test_infrastructure_documentation_15_05b8b4b6",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 15,
    "code": "# Check tolerance settings\nassert abs(computed - expected) < 1e-10  # May be too strict\nassert np.allclose(computed, expected, rtol=1e-8, atol=1e-10)  # Better",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "05b8b4b6"
  },
  {
    "id": "test_infrastructure_documentation_16_fd40e60b",
    "file": "docs\\test_infrastructure_documentation.md",
    "index": 16,
    "code": "# Increase statistical power\n@pytest.mark.statistical\n@settings(max_examples=1000)  # Increase Hypothesis examples\ndef test_statistical_property():\n    # Larger sample size for better statistical power\n    pass",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd40e60b"
  },
  {
    "id": "test_infrastructure_validation_report_1_eb078001",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 1,
    "code": "# Automatic headless enforcement via tests/conftest.py\nos.environ.setdefault(\"MPLBACKEND\", \"Agg\")\nmatplotlib.use(\"Agg\", force=True)\n\n# Runtime ban on plt.show() for CI safety\ndef _no_show(*args, **kwargs):\n    raise AssertionError(\"plt.show() is banned in tests. Use savefig() or return Figure.\")\nplt.show = _no_show",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb078001"
  },
  {
    "id": "test_infrastructure_validation_report_2_e316acae",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 2,
    "code": "@pytest.mark.convergence\n@pytest.mark.numerical_stability\ndef test_sliding_surface_reachability():\n    \"\"\"Validate finite-time convergence to sliding surface.\"\"\"\n    # Mathematical property: |s(t)| \u2192 0 in finite time\n    # Lyapunov candidate: V = 0.5 * s\u00b2\n    # Reachability condition: s * \u1e61 \u2264 -\u03b7|s| for \u03b7 > 0",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e316acae"
  },
  {
    "id": "test_infrastructure_validation_report_3_40d9d3c5",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 3,
    "code": "@pytest.mark.statistical\n@pytest.mark.convergence\ndef test_pso_convergence_monte_carlo():\n    \"\"\"Statistical validation of PSO convergence properties.\"\"\"\n    # Multiple independent runs for confidence intervals\n    # Convergence rate analysis: P(convergence) > 0.95\n    # Performance distribution characterization",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40d9d3c5"
  },
  {
    "id": "test_infrastructure_validation_report_4_08c5d981",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 4,
    "code": "@pytest.mark.numerical_stability\n@pytest.mark.benchmark\ndef test_integration_energy_conservation():\n    \"\"\"Validate energy conservation in symplectic integrators.\"\"\"\n    # Theoretical property: H(q,p) = constant for conservative systems\n    # Numerical validation: |\u0394H|/H < tolerance over extended time",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "08c5d981"
  },
  {
    "id": "test_infrastructure_validation_report_5_3231fbd0",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 5,
    "code": "@pytest.mark.property_based\n@given(\n    gains=lists(floats(min_value=0.1, max_value=50.0), min_size=6, max_size=6),\n    initial_state=arrays(dtype=float, shape=6, elements=floats(-0.5, 0.5))\n)\ndef test_controller_boundedness_property(gains, initial_state):\n    \"\"\"Universal property: controller output must always be bounded.\"\"\"\n    # Mathematical guarantee: |u(t)| \u2264 u_max \u2200 t \u2265 0",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3231fbd0"
  },
  {
    "id": "test_infrastructure_validation_report_6_a128734d",
    "file": "docs\\test_infrastructure_validation_report.md",
    "index": 6,
    "code": "@pytest.mark.benchmark(group=\"controller.compute_control\")\ndef test_classical_smc_performance(benchmark):\n    \"\"\"Benchmark classical SMC computation time.\"\"\"\n    # Target: <1ms per control computation\n    # Regression threshold: +5% from baseline",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a128734d"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_1_5f2cca05",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass KFold:\n    \"\"\"K-Fold cross-validation iterator.\n\n    Splits dataset into K consecutive folds for cross-validation. Each fold is used\n    once as validation while the K-1 remaining folds form the training set.\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of folds. Must be at least 2.\n    shuffle : bool, default=False\n        Whether to shuffle data before splitting into folds.\n    random_state : int, optional\n        Random seed for reproducibility when shuffle=True.\n\n    Examples\n    --------\n    >>> kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n    >>> for train_idx, val_idx in kfold.split(data):\n    ...     train_data = data[train_idx]\n    ...     val_data = data[val_idx]\n    ...     # Train and validate model\n\n    See Also\n    --------\n    StratifiedKFold : K-Fold with stratification for imbalanced datasets\n    TimeSeriesSplit : Time series cross-validation\n    \"\"\"",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5f2cca05"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_2_10a72dfd",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass StratifiedKFold:\n    \"\"\"Stratified K-Fold cross-validation iterator.\n\n    Ensures each fold has approximately the same percentage of samples from each class.\n    Useful for imbalanced classification tasks.\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of folds.\n    shuffle : bool, default=False\n        Whether to shuffle data before splitting.\n    random_state : int, optional\n        Random seed for reproducibility.\n\n    Examples\n    --------\n    >>> labels = [0, 0, 0, 1, 1, 1, 1, 1]  # Imbalanced\n    >>> skfold = StratifiedKFold(n_splits=3, shuffle=True)\n    >>> for train_idx, val_idx in skfold.split(data, labels):\n    ...     # Each fold maintains class distribution\n    \"\"\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10a72dfd"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_3_25dc3c79",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass TimeSeriesSplit:\n    \"\"\"Time series cross-validation iterator.\n\n    Respects temporal ordering by using past data for training and future data\n    for validation. Prevents data leakage in time series forecasting tasks.\n\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits.\n    test_size : int, optional\n        Size of test set. If None, uses remaining data.\n\n    Examples\n    --------\n    >>> ts_split = TimeSeriesSplit(n_splits=3)\n    >>> for train_idx, test_idx in ts_split.split(time_series_data):\n    ...     # train_idx: [0, ..., t-1]\n    ...     # test_idx: [t, ..., T]\n    \"\"\"",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25dc3c79"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_4_47add162",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass LeaveOneOut:\n    \"\"\"Leave-One-Out cross-validation iterator.\n\n    Each sample is used once as test set while remaining samples form training set.\n    Equivalent to KFold(n_splits=n) where n is number of samples.\n\n    Warning: Computationally expensive for large datasets.\n\n    Examples\n    --------\n    >>> loo = LeaveOneOut()\n    >>> for train_idx, test_idx in loo.split(data):\n    ...     assert len(test_idx) == 1  # Single sample test set\n    \"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47add162"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_5_6d54dd18",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass MPCConfig:\n    \"\"\"Configuration for Model Predictive Control (MPC) controller.\n\n    Encapsulates MPC-specific parameters including prediction horizon,\n    control horizon, and cost function weights.\n\n    Parameters\n    ----------\n    prediction_horizon : int\n        Number of future steps to predict (N).\n    control_horizon : int\n        Number of control moves to optimize (M). Must be <= prediction_horizon.\n    Q : np.ndarray, shape (n_states, n_states)\n        State error cost matrix.\n    R : np.ndarray, shape (n_controls, n_controls)\n        Control effort cost matrix.\n    dt : float, default=0.01\n        Time step for discretization (seconds).\n    max_force : float, default=100.0\n        Maximum control force constraint (N).\n\n    Examples\n    --------\n    >>> config = MPCConfig(\n    ...     prediction_horizon=20,\n    ...     control_horizon=5,\n    ...     Q=np.diag([10, 10, 5, 1, 1, 1]),\n    ...     R=np.array([[0.1]]),\n    ...     dt=0.01,\n    ...     max_force=100.0\n    ... )\n    \"\"\"",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d54dd18"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_6_e4261bc7",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass UnavailableMPCConfig:\n    \"\"\"Placeholder configuration when MPC dependencies are unavailable.\n\n    Raises informative error messages when MPC is requested but required\n    libraries (CVXPY, OSQP) are not installed.\n\n    Raises\n    ------\n    ImportError\n        When attempting to create MPC controller without required dependencies.\n\n    Notes\n    -----\n    To enable MPC: pip install cvxpy osqp\n    \"\"\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4261bc7"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_7_62096731",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 7,
    "code": "class ModularClassicalSMC:\n    \"\"\"Modular classical sliding mode control wrapper for factory instantiation.\n\n    Wraps ClassicalSMC with factory-compatible interface for centralized\n    controller creation and PSO optimization integration.\n\n    See Also\n    --------\n    ClassicalSMC : Implementation in src/controllers/classic_smc.py\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62096731"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_8_024f4401",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 8,
    "code": "class ModularSuperTwistingSMC:\n    \"\"\"Modular super-twisting sliding mode control wrapper.\n\n    Wraps SuperTwistingSMC (2nd-order sliding mode) for factory integration.\n    Provides chattering reduction through continuous control law.\n\n    See Also\n    --------\n    SuperTwistingSMC : Implementation in src/controllers/sta_smc.py\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "024f4401"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_9_5ea094ed",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 9,
    "code": "class ModularAdaptiveSMC:\n    \"\"\"Modular adaptive sliding mode control wrapper.\n\n    Wraps AdaptiveSMC with online parameter adaptation for uncertain systems.\n\n    See Also\n    --------\n    AdaptiveSMC : Implementation in src/controllers/adaptive_smc.py\n    \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ea094ed"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_10_9c5bde24",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 10,
    "code": "class ModularHybridSMC:\n    \"\"\"Modular hybrid adaptive-STA sliding mode control wrapper.\n\n    Wraps HybridAdaptiveSTASMC combining adaptive control with super-twisting\n    algorithm for robust performance under parameter uncertainty.\n\n    See Also\n    --------\n    HybridAdaptiveSTASMC : Implementation in src/controllers/hybrid_adaptive_sta_smc.py\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c5bde24"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_11_aaf5cea2",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 11,
    "code": "class ModularSwingUpSMC:\n    \"\"\"Modular swing-up sliding mode control wrapper.\n\n    Wraps SwingUpSMC for energy-based swing-up of double-inverted pendulum\n    from hanging to upright position.\n\n    See Also\n    --------\n    SwingUpSMC : Implementation in src/controllers/swing_up_smc.py\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aaf5cea2"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_12_4819fb85",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass BaseMPCController:\n    \"\"\"Base class for Model Predictive Control implementations.\n\n    Provides common interface for MPC controllers with horizon-based optimization\n    and constraint handling.\n\n    Parameters\n    ----------\n    prediction_horizon : int\n        Number of future steps to predict.\n    control_horizon : int\n        Number of control moves to optimize.\n    Q : np.ndarray\n        State cost matrix.\n    R : np.ndarray\n        Control cost matrix.\n    dt : float\n        Time step for discretization.\n\n    Methods\n    -------\n    solve_mpc(state, target) -> np.ndarray\n        Solve MPC optimization problem for current state.\n    \"\"\"",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4819fb85"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_13_ee8317f1",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass ResilientDataExchange:\n    \"\"\"Resilient data exchange interface with fault tolerance.\n\n    Provides multi-source data exchange with automatic failover, retry logic,\n    and graceful degradation for hardware-in-the-loop systems.\n\n    Parameters\n    ----------\n    primary_source : str\n        Primary data source identifier.\n    fallback_sources : List[str], optional\n        Ordered list of fallback sources.\n    retry_attempts : int, default=3\n        Number of retry attempts before failover.\n    timeout : float, default=1.0\n        Timeout for each data exchange attempt (seconds).\n\n    Examples\n    --------\n    >>> exchange = ResilientDataExchange(\n    ...     primary_source='udp://192.168.1.100:5000',\n    ...     fallback_sources=['serial:COM3', 'tcp://localhost:8000']\n    ... )\n    \"\"\"",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee8317f1"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_14_54a36f1b",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass NetworkMessage:\n    \"\"\"Network message container for control system communication.\n\n    Encapsulates state, control, and metadata for real-time HIL communication.\n\n    Attributes\n    ----------\n    timestamp : float\n        Message creation timestamp (seconds since epoch).\n    state : np.ndarray\n        System state vector.\n    control : float\n        Control input value.\n    metadata : Dict[str, Any]\n        Additional message metadata.\n    \"\"\"",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "54a36f1b"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_15_e6855b21",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizationResult:\n    \"\"\"Container for optimization algorithm results.\n\n    Stores optimized parameters, convergence metrics, and optimization history.\n\n    Attributes\n    ----------\n    best_params : np.ndarray\n        Optimized parameter vector.\n    best_cost : float\n        Final cost function value.\n    converged : bool\n        Whether optimization converged to tolerance.\n    iterations : int\n        Number of iterations performed.\n    history : Dict[str, List]\n        Optimization history (cost, params per iteration).\n\n    Examples\n    --------\n    >>> result = optimizer.optimize(objective_fn, bounds)\n    >>> if result.converged:\n    ...     controller = create_controller(gains=result.best_params)\n    \"\"\"",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6855b21"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_16_6b80d450",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass UnifiedControllerFactory:\n    \"\"\"Unified factory bridging controller creation and PSO optimization.\n\n    Provides single interface for creating controllers with optional PSO tuning,\n    supporting both manual configuration and automated optimization workflows.\n\n    Parameters\n    ----------\n    controller_type : str\n        Controller type ('classical_smc', 'adaptive_smc', etc.).\n    use_pso : bool, default=False\n        Whether to use PSO optimization for parameter tuning.\n\n    Examples\n    --------\n    >>> factory = UnifiedControllerFactory(\n    ...     controller_type='classical_smc',\n    ...     use_pso=True\n    ... )\n    >>> controller = factory.create(initial_gains=[...])\n    \"\"\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b80d450"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_17_0e2c8f63",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nclass DefaultPhysicsConfig:\n    \"\"\"Default physics parameters for double-inverted pendulum.\n\n    Provides standard physical parameters based on Quanser hardware specifications.\n\n    Attributes\n    ----------\n    m1, m2 : float\n        Masses of first and second pendulum (kg).\n    L1, L2 : float\n        Lengths of pendulum links (m).\n    g : float\n        Gravitational acceleration (m/s\u00b2).\n    friction : float\n        Cart friction coefficient.\n\n    Examples\n    --------\n    >>> config = DefaultPhysicsConfig()\n    >>> dynamics = SimplifiedDynamicsModel(config)\n    \"\"\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e2c8f63"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_18_b4a8e805",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nclass DynamicsModelProtocol:\n    \"\"\"Protocol defining interface for dynamics models.\n\n    All dynamics implementations (simplified, full, low-rank) must implement\n    this interface for compatibility with simulation engine.\n\n    Methods\n    -------\n    derivatives(state: np.ndarray, control: float) -> np.ndarray\n        Compute state derivatives dx/dt = f(x, u).\n    linearize(state: np.ndarray) -> Tuple[np.ndarray, np.ndarray]\n        Compute linearized A, B matrices at given state.\n    \"\"\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4a8e805"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_19_0f6bbb5c",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControlPrimitives:\n    \"\"\"Collection of control theory primitive functions.\n\n    Provides reusable control primitives: saturation, dead zone, rate limiting,\n    filtering, etc.\n\n    Methods\n    -------\n    saturate(value, limit) -> float\n        Saturate value to [-limit, +limit].\n    dead_zone(value, threshold) -> float\n        Apply dead zone (zero output if |value| < threshold).\n    rate_limit(value, prev_value, max_rate, dt) -> float\n        Limit rate of change.\n\n    Examples\n    --------\n    >>> primitives = ControlPrimitives()\n    >>> control = primitives.saturate(raw_control, max_force)\n    \"\"\"",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f6bbb5c"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_20_8d524e38",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerState:\n    \"\"\"Container for controller internal state.\n\n    Stores controller state variables for adaptive and hybrid controllers\n    that maintain internal state between control steps.\n\n    Attributes\n    ----------\n    adaptive_gains : np.ndarray, optional\n        Adaptive gain estimates.\n    integral_error : float\n        Accumulated integral error.\n    previous_control : float\n        Previous control output (for rate limiting).\n    history : Dict[str, List]\n        Controller history buffers.\n\n    Examples\n    --------\n    >>> state = ControllerState()\n    >>> control, state = controller.compute_control(system_state, state)\n    \"\"\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d524e38"
  },
  {
    "id": "TODO_TOP_20_QUICK_FIX_GUIDE_21_a8290ad7",
    "file": "docs\\TODO_TOP_20_QUICK_FIX_GUIDE.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nBatch add docstrings to top 20 priority classes.\nRun: python scripts/add_top20_docstrings.py\n\"\"\"\n\nimport ast\nimport os\nfrom pathlib import Path\n\nDOCSTRINGS = {\n    \"src/analysis/validation/cross_validation.py\": {\n        \"KFold\": \"\"\"K-Fold cross-validation iterator.\n\n        Splits dataset into K consecutive folds for cross-validation. Each fold is used\n        once as validation while the K-1 remaining folds form the training set.\n\n        Parameters\n        ----------\n        n_splits : int, default=5\n            Number of folds. Must be at least 2.\n        shuffle : bool, default=False\n            Whether to shuffle data before splitting into folds.\n        random_state : int, optional\n            Random seed for reproducibility when shuffle=True.\n\n        Examples\n        --------\n        >>> kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n        >>> for train_idx, val_idx in kfold.split(data):\n        ...     train_data = data[train_idx]\n        ...     val_data = data[val_idx]\n\n        See Also\n        --------\n        StratifiedKFold : K-Fold with stratification for imbalanced datasets\n        TimeSeriesSplit : Time series cross-validation\n        \"\"\",\n        # ... add other classes\n    },\n    # ... add other files\n}\n\ndef add_docstrings():\n    for filepath, class_docstrings in DOCSTRINGS.items():\n        # Read file\n        with open(filepath, 'r') as f:\n            content = f.read()\n\n        # Parse AST and insert docstrings\n        # (Implementation uses ast.parse + ast.unparse or direct string manipulation)\n\n        # Write back\n        with open(filepath, 'w') as f:\n            f.write(updated_content)\n\nif __name__ == \"__main__\":\n    add_docstrings()",
    "lines": 60,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8290ad7"
  },
  {
    "id": "versioning_guide_1_9696780c",
    "file": "docs\\versioning_guide.md",
    "index": 1,
    "code": "# Version information\nimport subprocess\n\n# Get version from git tags\ntry:\n    version = subprocess.check_output(\n        ['git', 'describe', '--tags', '--abbrev=0'],\n        stderr=subprocess.DEVNULL\n    ).decode('utf-8').strip()\n    release = version\nexcept:\n    version = '1.0.0'\n    release = '1.0.0'\n\n# Version selector\nhtml_context = {\n    'display_github': True,\n    'github_user': 'theSadeQ',\n    'github_repo': 'dip-smc-pso',\n    'github_version': 'main',\n    'conf_py_path': '/docs/',\n    'versions': [\n        ('latest', '/en/latest/'),\n        ('stable', '/en/stable/'),\n        ('v1.0', '/en/v1.0/'),\n    ]\n}",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9696780c"
  },
  {
    "id": "versioning_guide_2_3c2cefb6",
    "file": "docs\\versioning_guide.md",
    "index": 2,
    "code": "html_theme_options = {\n    'source_repository': 'https://github.com/theSadeQ/dip-smc-pso/',\n    'source_branch': 'main',\n    'source_directory': 'docs/',\n}",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c2cefb6"
  },
  {
    "id": "COMPLETE_CONTROLLER_COMPARISON_MATRIX_1_049402ca",
    "file": "docs\\analysis\\COMPLETE_CONTROLLER_COMPARISON_MATRIX.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\npso_performance_matrix = {\n    'classical_smc': {\n        'convergence_quality': 'EXCELLENT',\n        'achieved_target': True,\n        'computational_cost': 0.365,\n        'parameter_space': 6,\n        'convergence_rate': 'Fast'\n    },\n    'adaptive_smc': {\n        'convergence_quality': 'STABLE',\n        'achieved_target': True,\n        'computational_cost': 0.420,\n        'parameter_space': 5,\n        'convergence_rate': 'Steady'\n    },\n    'sta_smc': {\n        'convergence_quality': 'EXCELLENT',\n        'achieved_target': True,\n        'computational_cost': 0.134,\n        'parameter_space': 6,\n        'convergence_rate': 'Very Fast'\n    },\n    'hybrid_adaptive_sta_smc': {\n        'convergence_quality': 'OPTIMAL',\n        'achieved_target': True,\n        'computational_cost': 0.287,\n        'parameter_space': 4,\n        'convergence_rate': 'Optimal'\n    }\n}",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "049402ca"
  },
  {
    "id": "COMPLETE_CONTROLLER_COMPARISON_MATRIX_2_b0ec43c7",
    "file": "docs\\analysis\\COMPLETE_CONTROLLER_COMPARISON_MATRIX.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# All controllers implement the standardized interface:\nclass SMCInterface(Protocol):\n    def compute_control(self, state: np.ndarray,\n                       state_vars: Optional[Any] = None,\n                       history: Optional[Dict] = None) -> ControlOutput\n\n    def reset(self) -> None\n\n    def initialize_state(self) -> Any\n\n    def initialize_history(self) -> Dict\n\n    @property\n    def gains(self) -> List[float]\n\n    @gains.setter\n    def gains(self, gains: List[float]) -> None",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0ec43c7"
  },
  {
    "id": "COMPLETE_CONTROLLER_COMPARISON_MATRIX_3_e50c24be",
    "file": "docs\\analysis\\COMPLETE_CONTROLLER_COMPARISON_MATRIX.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef select_smc_controller(requirements):\n    \"\"\"Decision tree for SMC controller selection.\"\"\"\n\n    if requirements.get('parameter_uncertainty') == 'high':\n        if requirements.get('convergence_time') == 'finite':\n            return 'hybrid_adaptive_sta_smc'  # Best of both worlds\n        else:\n            return 'adaptive_smc'  # Parameter adaptation focus\n\n    elif requirements.get('convergence_time') == 'finite':\n        if requirements.get('chattering_tolerance') == 'low':\n            return 'sta_smc'  # Finite-time + smooth control\n        else:\n            return 'classical_smc'  # Fast and simple\n\n    elif requirements.get('computational_resources') == 'limited':\n        return 'classical_smc'  # Lowest computational cost\n\n    elif requirements.get('performance_priority') == 'maximum':\n        return 'hybrid_adaptive_sta_smc'  # Best overall performance\n\n    else:\n        return 'classical_smc'  # Default choice for general use",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e50c24be"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_1_8ebecbb0",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/base/control_primitives.py\n# Lines: ALL COVERED - safety-critical saturation functions validated\ndef saturate(sigma, epsilon, method=\"tanh\"):\n    # FULL COVERAGE: boundary validation, method selection, error handling\n\ndef require_positive(value, name, allow_zero=False):\n    # FULL COVERAGE: input validation, error conditions, boundary cases\n\ndef require_in_range(value, name, minimum, maximum, allow_equal=True):\n    # FULL COVERAGE: range validation, boundary conditions, error handling",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ebecbb0"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_2_b6be5f27",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 2,
    "code": "# All controller implementations include validated saturation:\nu_saturated = np.clip(u_total, -self.config.max_force, self.config.max_force)\n# Lines covered across all controller types",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b6be5f27"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_3_0fee5212",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/algorithms/hybrid/switching_logic.py\n# UNCOVERED CRITICAL LINES: 111-137, 151-170, 179-208, 212-258\n\n# Missing test coverage for:\ndef determine_controller_transition(self, current_state, performance_metrics):\n    # UNTESTED: mode transition logic\n    # UNTESTED: stability analysis during switching\n    # UNTESTED: performance-based controller selection\n\ndef validate_transition_safety(self, from_controller, to_controller, state):\n    # UNTESTED: safety validation during mode changes\n    # UNTESTED: parameter compatibility verification\n    # UNTESTED: stability margin enforcement",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fee5212"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_4_110559e0",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/algorithms/adaptive/parameter_estimation.py\n# UNCOVERED CRITICAL LINES: 139-151, 155-160, 212, 235-248\n\n# Missing test coverage for:\ndef update_estimates(self, sliding_surface, adaptation_rate, dt):\n    # UNTESTED: Lyapunov-based adaptation law\n    # UNTESTED: parameter bound enforcement\n    # UNTESTED: adaptation rate limiting\n\ndef validate_stability_conditions(self, current_estimates):\n    # UNTESTED: stability margin verification\n    # UNTESTED: divergence detection\n    # UNTESTED: recovery mechanisms",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "110559e0"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_5_085e2750",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/algorithms/super_twisting/twisting_algorithm.py\n# UNCOVERED CRITICAL LINES: 134, 137, 139-144, 148-149\n\n# Missing test coverage for:\ndef compute_control(self, surface_value, dt, state_vars):\n    # UNTESTED: finite-time convergence guarantees\n    # UNTESTED: super-twisting gain selection\n    # UNTESTED: chattering reduction validation",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "085e2750"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_6_306a8eed",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# New test file: tests/test_controllers/safety/test_emergency_mechanisms.py\n\nclass TestEmergencyStopMechanisms:\n    def test_emergency_stop_activation(self):\n        \"\"\"Test emergency stop triggers across all controllers.\"\"\"\n        # Test immediate control cutoff\n        # Test safe state transition\n        # Test recovery mechanisms\n\n    def test_fault_detection_response(self):\n        \"\"\"Test controller response to fault conditions.\"\"\"\n        # Test instability detection\n        # Test parameter divergence detection\n        # Test safety constraint violations\n\n    def test_degraded_mode_operation(self):\n        \"\"\"Test controller operation under degraded conditions.\"\"\"\n        # Test reduced functionality mode\n        # Test minimal safety guarantees\n        # Test graceful degradation",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "306a8eed"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_7_f1d0850c",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced test file: tests/test_controllers/smc/algorithms/adaptive/test_stability_validation.py\n\nclass TestAdaptiveStabilityValidation:\n    def test_lyapunov_stability_conditions(self):\n        \"\"\"Validate Lyapunov stability throughout adaptation.\"\"\"\n        # Test V(x) > 0 for x \u2260 0\n        # Test dV/dt < 0 along trajectories\n        # Test asymptotic stability\n\n    def test_parameter_boundedness(self):\n        \"\"\"Test adaptive parameter bound enforcement.\"\"\"\n        # Test upper bound enforcement\n        # Test lower bound enforcement\n        # Test adaptation rate limiting\n\n    def test_adaptation_law_convergence(self):\n        \"\"\"Test parameter estimation convergence properties.\"\"\"\n        # Test estimation error bounds\n        # Test convergence rate validation\n        # Test disturbance rejection",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1d0850c"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_8_3f35e959",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# New test file: tests/test_controllers/smc/algorithms/hybrid/test_switching_integration.py\n\nclass TestHybridSwitchingIntegration:\n    def test_controller_transition_stability(self):\n        \"\"\"Test stability during controller mode transitions.\"\"\"\n        # Test bumpless transfer\n        # Test transient response bounds\n        # Test stability margin preservation\n\n    def test_multi_mode_coordination(self):\n        \"\"\"Test coordination between multiple controller modes.\"\"\"\n        # Test parameter synchronization\n        # Test state continuity\n        # Test performance metric tracking\n\n    def test_switching_logic_validation(self):\n        \"\"\"Test switching decision logic under various conditions.\"\"\"\n        # Test performance-based switching\n        # Test stability-based switching\n        # Test hysteresis prevention",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f35e959"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_9_aa20909f",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 9,
    "code": "# Focus areas for improvement:\n- tests/test_controllers/smc/algorithms/classical/test_boundary_layer_advanced.py\n- Specific uncovered lines: 119, 166-169, 183, 225, 229\n- Test boundary layer dynamic adjustment\n- Test sliding surface edge cases",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa20909f"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_10_748cd56d",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 10,
    "code": "# Priority uncovered areas:\n- tests/test_controllers/smc/algorithms/super_twisting/test_convergence_validation.py\n- Specific uncovered lines: 134, 137, 139-144, 148-149, 158-161\n- Test finite-time convergence properties\n- Test super-twisting gain selection criteria\n- Test chattering elimination validation",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "748cd56d"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_11_b03d0979",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 11,
    "code": "# Critical uncovered areas:\n- tests/test_controllers/smc/algorithms/adaptive/test_parameter_estimation_complete.py\n- Specific uncovered lines: 139-151, 155-160, 212, 235-248, 266-296\n- Test Lyapunov-based adaptation laws\n- Test parameter bound enforcement\n- Test adaptation rate limiting mechanisms",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b03d0979"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_12_d6aaa4d8",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 12,
    "code": "# System-critical uncovered areas:\n- tests/test_controllers/smc/algorithms/hybrid/test_switching_logic_complete.py\n- Specific uncovered lines: 111-137, 151-170, 179-208, 212-258, 267-289\n- Test controller mode transitions\n- Test switching stability analysis\n- Test multi-mode parameter coordination",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6aaa4d8"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_13_a1039e33",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced hypothesis testing for controller stability:\n\n@given(state_vectors=valid_state_space(),\n       controller_gains=valid_gain_ranges(),\n       disturbances=bounded_disturbances())\ndef test_stability_properties(state_vectors, controller_gains, disturbances):\n    \"\"\"Property-based stability testing across parameter space.\"\"\"\n    controller = create_controller(gains=controller_gains)\n    for state in state_vectors:\n        control_output = controller.compute_control(state + disturbances)\n        assert_stability_conditions(control_output, state)\n        assert_safety_constraints(control_output)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a1039e33"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_14_e88189d0",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Real-time constraint validation:\n\nclass TestRealTimeConstraints:\n    def test_computation_time_bounds(self):\n        \"\"\"Validate controller computation time constraints.\"\"\"\n        target_time = 1.0e-3  # 1ms requirement\n        for _ in range(1000):\n            start_time = time.perf_counter()\n            control_output = controller.compute_control(state)\n            computation_time = time.perf_counter() - start_time\n            assert computation_time < target_time\n\n    def test_memory_usage_bounds(self):\n        \"\"\"Validate controller memory usage constraints.\"\"\"\n        memory_tracker = MemoryTracker()\n        memory_tracker.start()\n        for _ in range(10000):\n            controller.compute_control(state)\n        memory_usage = memory_tracker.stop()\n        assert memory_usage < MAX_MEMORY_LIMIT",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e88189d0"
  },
  {
    "id": "CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS_15_b00f0afa",
    "file": "docs\\analysis\\CONTROLLER_COVERAGE_TECHNICAL_ANALYSIS.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# Integration with production monitoring:\n\nclass ControllerCoverageMonitor:\n    def __init__(self):\n        self.code_paths_executed = set()\n        self.safety_violations = []\n\n    def track_execution(self, controller_type, method_name, line_number):\n        \"\"\"Track code path execution in production.\"\"\"\n        self.code_paths_executed.add(f\"{controller_type}:{method_name}:{line_number}\")\n\n    def validate_safety_constraints(self, control_output, state):\n        \"\"\"Validate safety constraints in real-time.\"\"\"\n        if abs(control_output) > MAX_SAFE_FORCE:\n            self.safety_violations.append({\n                'timestamp': time.time(),\n                'control_output': control_output,\n                'state': state,\n                'violation_type': 'force_limit'\n            })",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b00f0afa"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_1_a49fca48",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],  # 6 gains\n        'gain_count': 6,\n        'supports_dynamics': True\n    },\n    'sta_smc': {\n        'class': ModularSuperTwistingSMC,\n        'config_class': STASMCConfig,\n        'default_gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],  # 6 gains with K1 > K2\n        'gain_count': 6,\n        'supports_dynamics': True\n    },\n    'adaptive_smc': {\n        'class': ModularAdaptiveSMC,\n        'config_class': AdaptiveSMCConfig,\n        'default_gains': [25.0, 18.0, 15.0, 10.0, 4.0],       # 5 gains\n        'gain_count': 5,\n        'supports_dynamics': True\n    },\n    'hybrid_adaptive_sta_smc': {\n        'class': ModularHybridSMC,\n        'config_class': HybridAdaptiveSTASMCConfig,\n        'default_gains': [18.0, 12.0, 10.0, 8.0],             # 4 surface gains\n        'gain_count': 4,\n        'supports_dynamics': False  # Uses sub-controllers\n    }\n}",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a49fca48"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_2_0622d928",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 2,
    "code": "def compute_control(self, state: np.ndarray, last_control: float, history: Dict) -> Union[Dict, float]:\n    \"\"\"Universal controller interface for all SMC variants\"\"\"\n\n@property\ndef gains(self) -> List[float]:\n    \"\"\"Required PSO interface - return controller gains\"\"\"\n\ndef reset(self) -> None:\n    \"\"\"Reset controller to initial state\"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0622d928"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_3_a8befa21",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass HybridSMCConfig:\n    # ... existing fields ...\n\n    # Add gains property for PSO compatibility\n    gains: List[float] = field(default_factory=lambda: [18.0, 12.0, 10.0, 8.0])\n\n    @property\n    def surface_gains(self) -> List[float]:\n        \"\"\"Surface parameters for sliding mode design [c1, \u03bb1, c2, \u03bb2]\"\"\"\n        return self.gains",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8befa21"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_4_49ac8eec",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 4,
    "code": "# In factory.py - _resolve_controller_gains function\nif controller_type == 'hybrid_adaptive_sta_smc':\n    # Extract surface gains from hybrid configuration\n    if hasattr(config, 'gains'):\n        return config.gains\n    else:\n        # Use default surface gains for hybrid controller\n        return [18.0, 12.0, 10.0, 8.0]  # [c1, \u03bb1, c2, \u03bb2]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49ac8eec"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_5_8bef91d9",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 5,
    "code": "controller_factory = create_pso_controller_factory(SMCType.CLASSICAL, plant_config)\ncontroller_factory.n_gains        # Required attribute\ncontroller_factory.controller_type # Required attribute\ncontroller_factory.max_force      # Required attribute",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8bef91d9"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_6_46823409",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 6,
    "code": "controller = controller_factory(gains)\ncontroller.validate_gains(particles)  # Batch gain validation\ncontroller.compute_control(state)     # Control computation\ncontroller.gains                      # Gain access for PSO",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46823409"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_7_a1d8a92e",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 7,
    "code": "# 1. Create controller factory\nfrom src.controllers.factory import create_pso_controller_factory, SMCType\ncontroller_factory = create_pso_controller_factory(SMCType.CLASSICAL, plant_config)\n\n# 2. Initialize PSO tuner\nfrom src.optimizer.pso_optimizer import PSOTuner\ntuner = PSOTuner(controller_factory, config)\n\n# 3. Run optimization\nresult = tuner.optimise()\noptimal_gains = result['best_pos']",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a1d8a92e"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_8_a16253c2",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Graceful degradation on controller creation failure\ntry:\n    controller = controller_class(controller_config)\nexcept Exception as e:\n    logger.warning(f\"Could not create full config, using minimal config: {e}\")\n    # Fallback to minimal configuration with required defaults\n    fallback_params = {...}\n    controller_config = config_class(**fallback_params)",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a16253c2"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_9_42c8b753",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(gains, controller_info, controller_type):\n    # 1. Basic validation\n    if len(gains) != expected_count: raise ValueError(...)\n    if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in gains): raise ValueError(...)\n    if any(g <= 0 for g in gains): raise ValueError(...)\n\n    # 2. Controller-specific validation\n    if controller_type == 'sta_smc' and gains[0] <= gains[1]:\n        raise ValueError(\"Super-Twisting stability requires K1 > K2 > 0\")",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42c8b753"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_10_bf78212d",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/algorithms/hybrid/config.py\n@dataclass(frozen=True)\nclass HybridSMCConfig:\n    # ... existing fields ...\n\n    # Add for PSO compatibility\n    gains: List[float] = field(default_factory=lambda: [18.0, 12.0, 10.0, 8.0])\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after creation.\"\"\"\n        # Validate gains represent surface parameters [c1, \u03bb1, c2, \u03bb2]\n        if len(self.gains) != 4:\n            raise ValueError(\"Hybrid controller requires exactly 4 surface gains\")\n        # ... existing validation ...",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bf78212d"
  },
  {
    "id": "CONTROLLER_FACTORY_ANALYSIS_11_1a222e08",
    "file": "docs\\analysis\\CONTROLLER_FACTORY_ANALYSIS.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/factory.py\ndef list_available_controllers() -> list:\n    \"\"\"Get list of available controller types.\"\"\"\n    available_controllers = []\n    for controller_type, controller_info in CONTROLLER_REGISTRY.items():\n        # Only include controllers that have available classes AND are not placeholders\n        if (controller_info['class'] is not None and\n            controller_type != 'mpc_controller'):  # Exclude optional MPC\n            available_controllers.append(controller_type)\n    return available_controllers",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a222e08"
  },
  {
    "id": "controller_memory_patterns_1_6c78293d",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 1,
    "code": "def compute_control(self, state: np.ndarray, state_vars, history):\n    # \u2705 OPTIMAL: Direct unpacking creates views, not copies\n    x, theta1, theta2, x_dot, theta1_dot, theta2_dot = state\n\n    # Use elements directly\n    sigma = self.k1 * (theta1_dot + self.lam1 * theta1) + \\\n            self.k2 * (theta2_dot + self.lam2 * theta2)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c78293d"
  },
  {
    "id": "controller_memory_patterns_2_02549a84",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 2,
    "code": "def _compute_equivalent_control(self, state: np.ndarray) -> float:\n    # \u2705 OPTIMAL: state[3:] returns a view\n    q_dot = state[3:]\n\n    # View is safe for read-only operations\n    if getattr(C, \"ndim\", 1) == 2:\n        rhs = C @ q_dot + G",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02549a84"
  },
  {
    "id": "controller_memory_patterns_3_8cd8c953",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n@numba.njit(cache=True)\ndef _sta_smc_control_numba(\n    state: np.ndarray,\n    z: float,\n    alg_gain_K1: float,\n    # ... other parameters\n) -> Tuple[float, float, float]:\n    # Numba automatically optimizes array access\n    _, th1, th2, _, th1dot, th2dot = state\n\n    # Ultra-fast compiled operations\n    sigma = surf_gain_k1 * (th1dot + surf_lam1 * th1) + \\\n            surf_gain_k2 * (th2dot + surf_lam2 * th2)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8cd8c953"
  },
  {
    "id": "controller_memory_patterns_4_ffff3c67",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 4,
    "code": "def compute_control(self, state: np.ndarray, state_vars, history):\n    # \u2705 OPTIMAL: Direct indexing for cart recentering\n    x = state[0]\n    xdot = state[3]\n\n    # Efficient conditionals on scalar views\n    if abs(x) > self.recenter_high_thresh:\n        u_cart = -self.cart_p_gain * (xdot + self.cart_p_lambda * x)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ffff3c67"
  },
  {
    "id": "controller_memory_patterns_5_7e1729f3",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 5,
    "code": "# \u274c ANTI-PATTERN (not found in our controllers)\ndef compute_control(self, state: np.ndarray):\n    state_copy = state.copy()  # Unnecessary allocation\n    x, theta1, theta2 = state_copy[0], state_copy[1], state_copy[2]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e1729f3"
  },
  {
    "id": "controller_memory_patterns_6_83e6a9ff",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 6,
    "code": "# \u2705 OPTIMAL (actual implementation)\ndef compute_control(self, state: np.ndarray):\n    x, theta1, theta2 = state[0], state[1], state[2]  # Views",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83e6a9ff"
  },
  {
    "id": "controller_memory_patterns_7_a10c3bbd",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 7,
    "code": "# \u274c ANTI-PATTERN (not found in our controllers)\ndef _compute_equivalent_control(self, state: np.ndarray):\n    q_dot_copy = state[3:].copy()  # Unnecessary\n    result = M @ q_dot_copy",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a10c3bbd"
  },
  {
    "id": "controller_memory_patterns_8_d9ddf980",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 8,
    "code": "# \u2705 OPTIMAL (actual implementation)\ndef _compute_equivalent_control(self, state: np.ndarray):\n    q_dot = state[3:]  # View is sufficient for read-only ops\n    result = M @ q_dot",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9ddf980"
  },
  {
    "id": "controller_memory_patterns_9_2bab704d",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Benchmark results (100,000 iterations):\n# - Copy access:  1.617 \u03bcs/iteration\n# - View access:  0.723 \u03bcs/iteration\n# - Speedup:      2.24x\n\n# All controllers use the FASTER view-based approach",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bab704d"
  },
  {
    "id": "controller_memory_patterns_10_d4a1c612",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 10,
    "code": "# \u2705 GOOD: Direct unpacking\nx, theta1, theta2, xdot, theta1dot, theta2dot = state\n\n# \u2705 GOOD: Slicing for vectors\nvelocities = state[3:]  # View\npositions = state[:3]   # View\n\n# \u274c BAD: Unnecessary copying\nvelocities = state[3:].copy()  # Only if mutating!",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4a1c612"
  },
  {
    "id": "controller_memory_patterns_11_b9d3906b",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 11,
    "code": "# \u2705 GOOD: Copy only if modifying\nstate_modified = state.copy()\nstate_modified[0] = new_value\n\n# \u2705 GOOD: In-place operations on views\nstate[3:] += acceleration * dt  # Safe mutation via view",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9d3906b"
  },
  {
    "id": "controller_memory_patterns_12_4ec13142",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 12,
    "code": "# \u2705 GOOD: Scalar extraction\nx = state[0]\ntheta1 = state[1]\n\n# \u26a0\ufe0f AVOID: Array slicing for single elements\nx = state[0:1]  # Returns array, not scalar",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4ec13142"
  },
  {
    "id": "controller_memory_patterns_13_001e0f2f",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 13,
    "code": "# \u2705 EXCELLENT: Numba-compiled core\n@numba.njit(cache=True)\ndef _compute_control_core(state, gains):\n    # Automatic optimization of array operations\n    return control_output",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "001e0f2f"
  },
  {
    "id": "controller_memory_patterns_14_a8d63520",
    "file": "docs\\analysis\\controller_memory_patterns.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# No memory leaks detected in 8-hour stress test\n# See: tests/test_integration/test_memory_management/\n# Result: \u2705 Memory growth < 1MB per 1000 instantiations",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d63520"
  },
  {
    "id": "COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK_1_7593eee7",
    "file": "docs\\analysis\\COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK.md",
    "index": 1,
    "code": "# scripts/coverage_validator.py\n#==========================================================================================\\\\\\\n#=================================== coverage_validator.py ==============================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"Advanced coverage validation with mathematical threshold enforcement.\"\"\"\n\nimport xml.etree.ElementTree as ET\nfrom typing import Dict, List, Tuple\nfrom pathlib import Path\nimport sys\n\nclass CoverageValidator:\n    \"\"\"Mathematical coverage validation with multi-tier enforcement.\"\"\"\n\n    def __init__(self, coverage_xml: Path):\n        \"\"\"Initialize coverage validator with XML report.\"\"\"\n        self.coverage_xml = coverage_xml\n        self.tree = ET.parse(coverage_xml)\n        self.root = self.tree.getroot()\n\n    def get_component_coverage(self, component_pattern: str) -> float:\n        \"\"\"Calculate coverage for specific component pattern.\n\n        Args:\n            component_pattern: Pattern to match component files\n\n        Returns:\n            Coverage percentage for matched components\n        \"\"\"\n        total_lines = 0\n        covered_lines = 0\n\n        for package in self.root.findall('.//package'):\n            for class_elem in package.findall('.//class'):\n                filename = class_elem.get('filename', '')\n                if component_pattern in filename:\n                    lines = class_elem.findall('.//line')\n                    total_lines += len(lines)\n                    covered_lines += sum(1 for line in lines if int(line.get('hits', 0)) > 0)\n\n        return (covered_lines / total_lines * 100) if total_lines > 0 else 0.0\n\n    def validate_quality_gates(self) -> Dict[str, Tuple[float, float, bool]]:\n        \"\"\"Validate all quality gate thresholds.\n\n        Returns:\n            Dict mapping gate name to (actual, required, passed) tuple\n        \"\"\"\n        gates = {\n            'safety_critical': (self.get_component_coverage('safety_guards'), 100.0),\n            'controllers_smc': (self.get_component_coverage('controllers/smc'), 95.0),\n            'core_dynamics': (self.get_component_coverage('core/dynamics'), 95.0),\n            'pso_optimizer': (self.get_component_coverage('optimizer/pso'), 95.0),\n            'overall_system': (float(self.root.get('line-rate', 0)) * 100, 85.0)\n        }\n\n        results = {}\n        for gate_name, (actual, required) in gates.items():\n            passed = actual >= required\n            results[gate_name] = (actual, required, passed)\n\n        return results\n\n    def generate_coverage_report(self) -> str:\n        \"\"\"Generate comprehensive coverage analysis report.\"\"\"\n        results = self.validate_quality_gates()\n\n        report = \"## Coverage Quality Gate Analysis\\n\\n\"\n        report += \"| **Component** | **Actual** | **Required** | **Status** |\\n\"\n        report += \"|---------------|------------|--------------|------------|\\n\"\n\n        for gate_name, (actual, required, passed) in results.items():\n            status = \"\u2705 PASS\" if passed else \"\u274c FAIL\"\n            report += f\"| {gate_name.replace('_', ' ').title()} | {actual:.1f}% | {required:.1f}% | {status} |\\n\"\n\n        overall_pass = all(passed for _, _, passed in results.values())\n        report += f\"\\n**Overall Quality Gate Status**: {'\u2705 PASS' if overall_pass else '\u274c FAIL'}\\n\"\n\n        return report\n\nif __name__ == \"__main__\":\n    validator = CoverageValidator(Path(\"coverage.xml\"))\n    results = validator.validate_quality_gates()\n\n    # Enforcement logic\n    failed_gates = [name for name, (_, _, passed) in results.items() if not passed]\n\n    if failed_gates:\n        print(f\"\u274c Coverage quality gates FAILED: {', '.join(failed_gates)}\")\n        print(validator.generate_coverage_report())\n        sys.exit(1)\n    else:\n        print(\"\u2705 All coverage quality gates PASSED\")\n        sys.exit(0)",
    "lines": 95,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7593eee7"
  },
  {
    "id": "COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK_2_a9262d88",
    "file": "docs\\analysis\\COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/coverage_gap_analyzer.py\n#==========================================================================================\\\\\\\n#=============================== coverage_gap_analyzer.py =============================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"Systematic analysis of coverage gaps with actionable recommendations.\"\"\"\n\nimport subprocess\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\n\nclass CoverageGapAnalyzer:\n    \"\"\"Scientific analysis of coverage gaps with improvement recommendations.\"\"\"\n\n    def analyze_uncovered_lines(self, module_path: str) -> Dict[str, List[int]]:\n        \"\"\"Identify specific uncovered lines in module.\n\n        Args:\n            module_path: Path to module for analysis\n\n        Returns:\n            Dictionary mapping files to uncovered line numbers\n        \"\"\"\n        cmd = [\"coverage\", \"report\", \"--show-missing\", \"--include\", f\"{module_path}/*\"]\n        result = subprocess.run(cmd, capture_output=True, text=True)\n\n        uncovered_lines = {}\n        for line in result.stdout.split('\\n')[2:]:  # Skip header\n            if line.strip() and not line.startswith('TOTAL'):\n                parts = line.split()\n                if len(parts) >= 4:\n                    file_path = parts[0]\n                    missing_lines = parts[-1] if parts[-1] != '100%' else ''\n                    if missing_lines and missing_lines != '0':\n                        uncovered_lines[file_path] = self.parse_missing_lines(missing_lines)\n\n        return uncovered_lines\n\n    def parse_missing_lines(self, missing_str: str) -> List[int]:\n        \"\"\"Parse missing lines string into list of line numbers.\"\"\"\n        lines = []\n        for part in missing_str.split(','):\n            if '-' in part:\n                start, end = map(int, part.strip().split('-'))\n                lines.extend(range(start, end + 1))\n            else:\n                lines.append(int(part.strip()))\n        return lines\n\n    def generate_improvement_plan(self, uncovered_lines: Dict[str, List[int]]) -> str:\n        \"\"\"Generate actionable improvement plan for coverage gaps.\"\"\"\n        plan = \"## Coverage Improvement Action Plan\\n\\n\"\n\n        for file_path, lines in uncovered_lines.items():\n            plan += f\"### {file_path}\\n\"\n            plan += f\"**Uncovered Lines**: {len(lines)} lines\\n\"\n            plan += f\"**Line Numbers**: {', '.join(map(str, lines[:10]))}\"\n            if len(lines) > 10:\n                plan += f\" ... (+{len(lines) - 10} more)\"\n            plan += \"\\n\\n\"\n\n            # Categorize improvement actions\n            if 'controller' in file_path:\n                plan += \"**Recommended Actions**:\\n\"\n                plan += \"- Add unit tests for control law computation\\n\"\n                plan += \"- Test boundary conditions and saturation limits\\n\"\n                plan += \"- Validate stability properties with edge cases\\n\\n\"\n            elif 'dynamics' in file_path:\n                plan += \"**Recommended Actions**:\\n\"\n                plan += \"- Test state integration accuracy\\n\"\n                plan += \"- Validate physical parameter ranges\\n\"\n                plan += \"- Test numerical stability edge cases\\n\\n\"\n            elif 'optimizer' in file_path:\n                plan += \"**Recommended Actions**:\\n\"\n                plan += \"- Test convergence scenarios\\n\"\n                plan += \"- Validate parameter bounds enforcement\\n\"\n                plan += \"- Test optimization termination conditions\\n\\n\"\n\n        return plan\n\n    def prioritize_coverage_tasks(self, uncovered_lines: Dict[str, List[int]]) -> List[Tuple[str, int, str]]:\n        \"\"\"Prioritize coverage improvement tasks by impact.\"\"\"\n        tasks = []\n\n        for file_path, lines in uncovered_lines.items():\n            priority = \"HIGH\"\n            if 'safety' in file_path or 'critical' in file_path:\n                priority = \"CRITICAL\"\n            elif 'util' in file_path or 'helper' in file_path:\n                priority = \"MEDIUM\"\n\n            tasks.append((file_path, len(lines), priority))\n\n        # Sort by priority and line count\n        priority_order = {\"CRITICAL\": 0, \"HIGH\": 1, \"MEDIUM\": 2}\n        tasks.sort(key=lambda x: (priority_order[x[2]], -x[1]))\n\n        return tasks",
    "lines": 102,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9262d88"
  },
  {
    "id": "COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK_3_a6b69caf",
    "file": "docs\\analysis\\COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Test development guidelines with mathematical validation\n\nclass TestCoverageStandards:\n    \"\"\"Mathematical standards for test coverage requirements.\"\"\"\n\n    CONTROLLER_TESTS = {\n        'unit_tests': [\n            'test_control_law_computation',\n            'test_gain_validation',\n            'test_saturation_limits',\n            'test_reset_functionality',\n            'test_parameter_bounds'\n        ],\n        'property_tests': [\n            'test_stability_lyapunov',  # Lyapunov function V\u0307 \u2264 0\n            'test_control_boundedness',  # |u| \u2264 u_max\n            'test_finite_time_convergence',  # t_reach < \u221e\n            'test_chattering_mitigation'  # High frequency analysis\n        ],\n        'integration_tests': [\n            'test_dynamics_integration',\n            'test_pso_optimization',\n            'test_simulation_workflow'\n        ]\n    }\n\n    DYNAMICS_TESTS = {\n        'mathematical_properties': [\n            'test_energy_conservation',  # E(t) conservation\n            'test_momentum_conservation',  # p(t) conservation\n            'test_symplectic_integration',  # Hamiltonian structure\n            'test_numerical_stability'  # Condition number analysis\n        ],\n        'physical_validation': [\n            'test_realistic_parameters',\n            'test_boundary_conditions',\n            'test_equilibrium_points',\n            'test_linearization_accuracy'\n        ]\n    }\n\n    PSO_TESTS = {\n        'optimization_theory': [\n            'test_convergence_criteria',  # f(x*) - f(x_k) \u2192 0\n            'test_particle_dynamics',     # Position/velocity updates\n            'test_global_best_tracking',  # g_best monotonic improvement\n            'test_termination_conditions' # Max iterations, tolerance\n        ],\n        'parameter_validation': [\n            'test_inertia_weight_bounds',  # w \u2208 [0.1, 0.9]\n            'test_acceleration_coefficients',  # c1, c2 \u2208 [0, 4]\n            'test_velocity_clamping',     # |v| \u2264 v_max\n            'test_boundary_handling'      # Position constraint enforcement\n        ]\n    }",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6b69caf"
  },
  {
    "id": "COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK_4_ac6c965e",
    "file": "docs\\analysis\\COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK.md",
    "index": 4,
    "code": "# src/utils/coverage/monitoring.py\n#==========================================================================================\\\\\\\n#=========================== src/utils/coverage/monitoring.py ========================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"Real-time coverage monitoring and alerting system.\"\"\"\n\nimport time\nimport json\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nfrom pathlib import Path\n\n@dataclass\nclass CoverageMetrics:\n    \"\"\"Coverage metrics data structure.\"\"\"\n    timestamp: float\n    overall_coverage: float\n    critical_coverage: float\n    safety_coverage: float\n    branch_coverage: float\n    test_count: int\n    execution_time: float\n\nclass CoverageMonitor:\n    \"\"\"Real-time coverage monitoring with trend analysis.\"\"\"\n\n    def __init__(self, metrics_file: Path = Path(\"coverage_metrics.json\")):\n        self.metrics_file = metrics_file\n        self.metrics_history: List[CoverageMetrics] = []\n        self.load_metrics_history()\n\n    def record_coverage_run(self, coverage_data: Dict) -> CoverageMetrics:\n        \"\"\"Record coverage metrics from test run.\"\"\"\n        metrics = CoverageMetrics(\n            timestamp=time.time(),\n            overall_coverage=coverage_data.get('overall', 0.0),\n            critical_coverage=coverage_data.get('critical', 0.0),\n            safety_coverage=coverage_data.get('safety', 0.0),\n            branch_coverage=coverage_data.get('branch', 0.0),\n            test_count=coverage_data.get('test_count', 0),\n            execution_time=coverage_data.get('execution_time', 0.0)\n        )\n\n        self.metrics_history.append(metrics)\n        self.save_metrics_history()\n        return metrics\n\n    def analyze_coverage_trends(self, window_size: int = 10) -> Dict:\n        \"\"\"Analyze coverage trends over recent runs.\"\"\"\n        if len(self.metrics_history) < window_size:\n            return {\"trend\": \"insufficient_data\"}\n\n        recent_metrics = self.metrics_history[-window_size:]\n\n        # Calculate trend slopes\n        def calculate_slope(values: List[float]) -> float:\n            n = len(values)\n            x_mean = sum(range(n)) / n\n            y_mean = sum(values) / n\n\n            numerator = sum((i - x_mean) * (values[i] - y_mean) for i in range(n))\n            denominator = sum((i - x_mean) ** 2 for i in range(n))\n\n            return numerator / denominator if denominator != 0 else 0\n\n        overall_slope = calculate_slope([m.overall_coverage for m in recent_metrics])\n        critical_slope = calculate_slope([m.critical_coverage for m in recent_metrics])\n\n        return {\n            \"overall_trend\": \"improving\" if overall_slope > 0.1 else \"declining\" if overall_slope < -0.1 else \"stable\",\n            \"critical_trend\": \"improving\" if critical_slope > 0.1 else \"declining\" if critical_slope < -0.1 else \"stable\",\n            \"overall_slope\": overall_slope,\n            \"critical_slope\": critical_slope,\n            \"latest_metrics\": recent_metrics[-1].__dict__\n        }\n\n    def generate_coverage_alert(self, threshold_violations: List[str]) -> str:\n        \"\"\"Generate coverage alert for threshold violations.\"\"\"\n        if not threshold_violations:\n            return \"\u2705 All coverage thresholds met\"\n\n        alert = \"\ud83d\udea8 COVERAGE THRESHOLD VIOLATIONS DETECTED\\n\\n\"\n        for violation in threshold_violations:\n            alert += f\"\u274c {violation}\\n\"\n\n        alert += \"\\n\ud83d\udcca Current Coverage Status:\\n\"\n        latest = self.metrics_history[-1] if self.metrics_history else None\n        if latest:\n            alert += f\"- Overall: {latest.overall_coverage:.1f}%\\n\"\n            alert += f\"- Critical: {latest.critical_coverage:.1f}%\\n\"\n            alert += f\"- Safety: {latest.safety_coverage:.1f}%\\n\"\n\n        return alert\n\n    def save_metrics_history(self):\n        \"\"\"Save metrics history to JSON file.\"\"\"\n        data = [m.__dict__ for m in self.metrics_history]\n        with open(self.metrics_file, 'w') as f:\n            json.dump(data, f, indent=2)\n\n    def load_metrics_history(self):\n        \"\"\"Load metrics history from JSON file.\"\"\"\n        if self.metrics_file.exists():\n            with open(self.metrics_file, 'r') as f:\n                data = json.load(f)\n                self.metrics_history = [CoverageMetrics(**item) for item in data]",
    "lines": 107,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac6c965e"
  },
  {
    "id": "COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK_5_2d0aac2a",
    "file": "docs\\analysis\\COVERAGE_ANALYSIS_METHODOLOGY_FRAMEWORK.md",
    "index": 5,
    "code": "# scripts/coverage_report_generator.py\n#==========================================================================================\\\\\\\n#========================== coverage_report_generator.py =============================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"Automated coverage report generation with mathematical analysis.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Dict, List\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nclass CoverageReportGenerator:\n    \"\"\"Advanced coverage reporting with scientific analysis.\"\"\"\n\n    def generate_executive_summary(self, metrics: Dict) -> str:\n        \"\"\"Generate executive summary for coverage analysis.\"\"\"\n        report = f\"\"\"# Coverage Analysis Executive Summary\n**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n**Repository**: https://github.com/theSadeQ/dip-smc-pso.git\n\n## Quality Gate Status\n| **Threshold** | **Current** | **Target** | **Status** | **Gap** |\n|---------------|-------------|------------|------------|---------|\n| Overall System | {metrics['overall']:.1f}% | 85.0% | {'\u2705 PASS' if metrics['overall'] >= 85 else '\u274c FAIL'} | {85 - metrics['overall']:+.1f}% |\n| Critical Components | {metrics['critical']:.1f}% | 95.0% | {'\u2705 PASS' if metrics['critical'] >= 95 else '\u274c FAIL'} | {95 - metrics['critical']:+.1f}% |\n| Safety-Critical | {metrics['safety']:.1f}% | 100.0% | {'\u2705 PASS' if metrics['safety'] >= 100 else '\u274c FAIL'} | {100 - metrics['safety']:+.1f}% |\n\n## Mathematical Analysis\n**Coverage Efficiency**: $C_{{eff}} = \\\\frac{{C_{{achieved}}}}{{C_{{target}}}} = {metrics['overall']/85:.3f}$\n\n**Risk Assessment**: {'LOW' if metrics['overall'] >= 85 else 'HIGH' if metrics['overall'] < 50 else 'MEDIUM'}\n\n**Improvement Velocity Required**: {max(0, (85 - metrics['overall']) / 4):.1f}% per week to reach target in 4 weeks\n\"\"\"\n        return report\n\n    def generate_component_breakdown(self, component_metrics: Dict[str, float]) -> str:\n        \"\"\"Generate detailed component coverage breakdown.\"\"\"\n        breakdown = \"\\n## Component Coverage Breakdown\\n\\n\"\n\n        sorted_components = sorted(component_metrics.items(), key=lambda x: x[1], reverse=True)\n\n        for component, coverage in sorted_components:\n            status = \"\u2705\" if coverage >= 85 else \"\u26a0\ufe0f\" if coverage >= 70 else \"\u274c\"\n            breakdown += f\"- **{component}**: {coverage:.1f}% {status}\\n\"\n\n        return breakdown\n\n    def generate_mathematical_recommendations(self, current_coverage: float) -> str:\n        \"\"\"Generate mathematical recommendations for coverage improvement.\"\"\"\n        gap = 85 - current_coverage\n\n        recommendations = f\"\\n## Mathematical Improvement Strategy\\n\\n\"\n\n        if gap > 0:\n            # Calculate required test additions\n            total_lines = 17354  # From coverage analysis\n            uncovered_lines = total_lines * (1 - current_coverage/100)\n            target_coverage_lines = total_lines * 0.85\n            required_additional_coverage = target_coverage_lines - (total_lines - uncovered_lines)\n\n            recommendations += f\"\"\"\n### Quantitative Analysis\n- **Total Lines**: {total_lines:,}\n- **Currently Covered**: {total_lines - uncovered_lines:,.0f} lines\n- **Target Coverage Lines**: {target_coverage_lines:,.0f} lines\n- **Additional Coverage Required**: {required_additional_coverage:,.0f} lines\n\n### Improvement Mathematics\n$$\\\\Delta C = \\\\frac{{L_{{additional}}}}{{L_{{total}}}} \\\\times 100 = \\\\frac{{{required_additional_coverage:,.0f}}}{{{total_lines:,}}} \\\\times 100 = {gap:.1f}\\\\%$$\n\n### Strategic Recommendations\n1. **Priority 1**: Focus on safety-critical components (100% requirement)\n2. **Priority 2**: Enhance critical component coverage (95% requirement)\n3. **Priority 3**: Systematically improve general components (85% requirement)\n\n### Resource Estimation\n- **Test Development Effort**: ~{required_additional_coverage/50:.0f} person-hours\n- **Timeline**: {max(2, required_additional_coverage/1000):.0f} weeks for systematic improvement\n- **Weekly Target**: {gap/4:.1f}% coverage improvement per week\n\"\"\"\n        else:\n            recommendations += \"\u2705 **Coverage targets achieved!** Focus on maintenance and quality improvement.\"\n\n        return recommendations\n\n# Integration with existing quality gates\ndef integration_with_claude_md() -> str:\n    \"\"\"Integration instructions for CLAUDE.md quality standards.\"\"\"\n    return \"\"\"\n## Integration with CLAUDE.md Quality Standards\n\n### Automated Repository Management\nThis coverage framework integrates with the mandatory auto-update policy:",
    "lines": 95,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d0aac2a"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_1_82cb3812",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# BEFORE FIX - Broken Implementation\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of complex control algorithm implementation ...\n\n    # Comments about packaging outputs:\n    # Package the outputs into a structured named tuple. Returning a\n    # named tuple formalises the contract and allows clients to\n    # access fields by name while retaining tuple compatibility.\n\n    # \u274c CRITICAL ISSUE: Missing return statement!\n    # Function implicitly returns None\n\ndef reset(self) -> None:\n    \"\"\"Reset controller state.\"\"\"\n    # ... reset logic ...\n\n    # \u274c WRONG LOCATION: Return statement with out-of-scope variables\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n    # Variables u_sat, k1_new, k2_new, etc. are not in scope here!",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82cb3812"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_2_fd78f59b",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of complex control algorithm implementation ...\n\n    # Calculate final control values\n    u_sat = float(np.clip(u_total, -self.max_force, self.max_force))\n    k1_new = max(0.0, min(k1_new, self.k1_max))\n    k2_new = max(0.0, min(k2_new, self.k2_max))\n    u_int_new = float(np.clip(u_int_new, -self.u_int_max, self.u_int_max))\n\n    # \u2705 CRITICAL FIX: Proper return statement with correct variable scope\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\ndef reset(self) -> None:\n    \"\"\"Reset controller state.\"\"\"\n    # ... reset logic only ...\n    # \u2705 CORRECT: No return statement (method should return None)\n    pass",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd78f59b"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_3_7acf0ef2",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _normalize_result(self, result):\n    \"\"\"Ensure result is properly formatted as HybridSTAOutput.\"\"\"\n    if result is None:\n        # Emergency fallback for None returns\n        return HybridSTAOutput(\n            control=0.0,\n            state_vars=(self.k1_init, self.k2_init, 0.0),\n            history=self.initialize_history(),\n            sliding_surface=0.0\n        )\n\n    if isinstance(result, np.ndarray):\n        # Convert numpy array to dictionary structure\n        return self._array_to_output(result)\n\n    return result",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7acf0ef2"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_4_2cf54221",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 4,
    "code": "# Added comprehensive type checking for active_result\nif isinstance(active_result, dict):\n    control_value = active_result.get('control', 0.0)\nelif hasattr(active_result, 'control'):\n    control_value = active_result.control\nelse:\n    # Fallback for unexpected types\n    control_value = 0.0",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2cf54221"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_5_af03072b",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nemergency_reset = (\n    not np.isfinite(u_sat) or abs(u_sat) > self.max_force * 2 or\n    not np.isfinite(k1_new) or k1_new > self.k1_max * 0.9 or\n    not np.isfinite(k2_new) or k2_new > self.k2_max * 0.9 or\n    not np.isfinite(u_int_new) or abs(u_int_new) > self.u_int_max * 1.5 or\n    not np.isfinite(s) or abs(s) > 100.0 or\n    state_norm > 10.0 or velocity_norm > 50.0\n)\n\nif emergency_reset:\n    # Safe fallback values\n    u_sat = 0.0\n    k1_new = max(0.0, min(self.k1_init * 0.05, self.k1_max * 0.05))\n    k2_new = max(0.0, min(self.k2_init * 0.05, self.k2_max * 0.05))\n    u_int_new = 0.0",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "af03072b"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_6_9276e175",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nproduction_readiness_components = {\n    'mathematical_algorithms': 7.5/10,     # 3/4 controllers working\n    'pso_integration': 7.5/10,            # Partial failure with hybrid\n    'runtime_stability': 6.0/10,          # Runtime errors present\n    'integration_health': 8.0/10,         # Most components working\n    'code_quality': 8.5/10,               # Good but return statement bug\n    'testing_coverage': 8.0/10,           # Comprehensive but missed edge case\n    'documentation': 8.0/10,              # Good coverage\n    'deployment_readiness': 7.0/10        # Blocked by critical error\n}\n# Average: 7.8/10",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9276e175"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_7_bcafa883",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nproduction_readiness_components = {\n    'mathematical_algorithms': 10.0/10,    # All 4 controllers working \u2705\n    'pso_integration': 10.0/10,           # Complete optimization success \u2705\n    'runtime_stability': 10.0/10,         # Zero error rate \u2705\n    'integration_health': 10.0/10,        # 100% availability \u2705\n    'code_quality': 9.5/10,               # Enhanced error handling \u2705\n    'testing_coverage': 9.0/10,           # Comprehensive validation \u2705\n    'documentation': 9.5/10,              # Complete documentation \u2705\n    'deployment_readiness': 9.0/10        # Production approved \u2705\n}\n# Average: 9.5/10 \ud83c\udfaf TARGET EXCEEDED",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bcafa883"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_8_cde3720f",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 8,
    "code": "# Quick test for return statement issues\ncontroller = create_controller('hybrid_adaptive_sta_smc')\nresult = controller.compute_control(test_state)\nassert result is not None, \"Controller returning None - check return statements\"\nassert hasattr(result, 'control'), \"Missing control attribute\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cde3720f"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_9_4a0b9ce1",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 9,
    "code": "# Test PSO integration directly\nfactory = create_pso_controller_factory(SMCType.HYBRID, config)\ngains = [10, 8, 5, 3]\nfitness = factory(gains)\nassert isinstance(fitness, float), f\"Expected float, got {type(fitness)}\"\nassert fitness >= 0, f\"Invalid fitness: {fitness}\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a0b9ce1"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_10_36c365b2",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Add runtime type validation\ndef compute_control(self, ...) -> HybridSTAOutput:\n    # ... implementation ...\n    result = HybridSTAOutput(...)\n\n    # Development mode validation\n    if __debug__:\n        assert isinstance(result, HybridSTAOutput)\n        assert hasattr(result, 'control')\n        assert isinstance(result.control, (int, float))\n\n    return result",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36c365b2"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_11_c9b8cec2",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 11,
    "code": "# .pre-commit-config.yaml\nrepos:\n  - repo: local\n    hooks:\n      - id: return-statement-check\n        name: Return Statement Validation\n        entry: python scripts/validate_return_statements.py\n        language: system\n        files: ^src/controllers/.*\\.py$",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9b8cec2"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_12_e3b1953c",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerValidator:\n    @staticmethod\n    def validate_control_output(output, controller_name: str):\n        \"\"\"Validate controller output structure and types.\"\"\"\n        if output is None:\n            raise ValueError(f\"{controller_name}: compute_control returned None\")\n\n        if not hasattr(output, 'control'):\n            raise ValueError(f\"{controller_name}: Missing control attribute\")\n\n        if not np.isfinite(output.control):\n            raise ValueError(f\"{controller_name}: Non-finite control value\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3b1953c"
  },
  {
    "id": "HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION_13_dd5a5d3e",
    "file": "docs\\analysis\\HYBRID_SMC_FIX_TECHNICAL_DOCUMENTATION.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_controller_return_types():\n    \"\"\"Comprehensive return type validation tests.\"\"\"\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n\n    for controller_name in controllers:\n        controller = create_controller(controller_name)\n        result = controller.compute_control(test_state)\n\n        # Critical validations\n        assert result is not None, f\"{controller_name} returned None\"\n        assert hasattr(result, 'control'), f\"{controller_name} missing control\"\n        assert isinstance(result.control, (int, float)), f\"Invalid control type\"\n        assert np.isfinite(result.control), f\"Non-finite control value\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd5a5d3e"
  },
  {
    "id": "view_conversion_recommendations_1_466f0cbc",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# BEFORE (35 occurrences across 3 files)\nreturn self._create_failure_result(\n    \"Invalid inputs\",\n    state=state.copy(),           # \u274c Unnecessary\n    control_input=control_input.copy(),  # \u274c Unnecessary\n    time=time\n)\n\n# AFTER\nreturn self._create_failure_result(\n    \"Invalid inputs\",\n    state=state,                  # \u2705 No mutation after return\n    control_input=control_input,  # \u2705 Caller owns arrays\n    time=time\n)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "466f0cbc"
  },
  {
    "id": "view_conversion_recommendations_2_160ec44f",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# BEFORE\ndef get_statistics(self) -> Dict[str, Any]:\n    stats = self._stats.copy()  # \u274c Defensive copy\n    stats['miss_rate'] = self._missed / self._total\n    return stats\n\n# AFTER\ndef get_statistics(self) -> Dict[str, Any]:\n    stats = self._stats  # \u2705 Direct reference (no mutation after this point)\n    stats['miss_rate'] = self._missed / self._total\n    return stats",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "160ec44f"
  },
  {
    "id": "view_conversion_recommendations_3_71011017",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 3,
    "code": "# CORRECT (already optimized)\nif init.ndim == 1:\n    # broadcast across batch\n    init_b = np.broadcast_to(init, (B, init.shape[0])).copy()  # \u2705 Required",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71011017"
  },
  {
    "id": "view_conversion_recommendations_4_ec19a526",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 4,
    "code": "# CORRECT\nif self._dominates(new_objectives[i], self.personal_best_objectives[i]):\n    self.personal_best_positions[i] = self.positions[i].copy()  # \u2705 Required\n    self.personal_best_objectives[i] = new_objectives[i].copy()  # \u2705 Required",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec19a526"
  },
  {
    "id": "view_conversion_recommendations_5_731504e0",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 5,
    "code": "# CORRECT\nfor i in range(n):\n    state_plus = eq_state.copy()  # \u2705 Required (will mutate)\n    state_plus[i] += eps\n    dynamics_plus = self.compute_dynamics(state_plus, eq_input)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "731504e0"
  },
  {
    "id": "view_conversion_recommendations_6_ead496d0",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 6,
    "code": "# CORRECT\ndef _crossover(self, target: np.ndarray, mutant: np.ndarray) -> np.ndarray:\n    trial = target.copy()  # \u2705 Required (will mutate)\n    j_rand = rng.integers(0, len(target))\n    trial[j_rand] = mutant[j_rand]  # In-place mutation\n    return trial",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ead496d0"
  },
  {
    "id": "view_conversion_recommendations_7_3f87a6ee",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 7,
    "code": "# src/simulation/engines/simulation_runner.py:202\nx0 = np.asarray(initial_state, dtype=float, copy=False).reshape(-1)\n\n# src/simulation/engines/vector_sim.py:112\nx = np.asarray(initial_state, dtype=float, copy=False)\n\n# src/simulation/engines/vector_sim.py:329\npart_arr = np.asarray(particles, dtype=float, copy=False)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f87a6ee"
  },
  {
    "id": "view_conversion_recommendations_8_d3470a5a",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 8,
    "code": "# Before/after memory profiling\nfrom memory_profiler import profile\n\n@profile\ndef run_5s_simulation():\n    t, x, u = run_simulation(\n        controller=controller,\n        dynamics_model=dynamics,\n        sim_time=5.0,\n        dt=0.01,\n        initial_state=[0.1, 0.05, 0.02, 0, 0, 0]\n    )\n    return x\n\n# Expected improvement: ~400KB reduction (2.3x overhead \u2192 ~1.2x overhead)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3470a5a"
  },
  {
    "id": "view_conversion_recommendations_9_c32f882a",
    "file": "docs\\analysis\\view_conversion_recommendations.md",
    "index": 9,
    "code": "# tests/test_benchmarks/test_memory_regression.py\ndef test_simulation_memory_overhead():\n    \"\"\"Verify memory overhead remains < 1.5x of theoretical minimum.\"\"\"\n    baseline = 6 * 500 * 8  # 6 states \u00d7 500 steps \u00d7 8 bytes\n    actual = measure_simulation_memory()\n    assert actual < baseline * 1.5, f\"Memory overhead too high: {actual/baseline:.2f}x\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c32f882a"
  },
  {
    "id": "factory_methods_reference_1_45450afc",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 1,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45450afc"
  },
  {
    "id": "factory_methods_reference_2_e83a8c45",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 2,
    "code": "# Basic usage with default parameters\ncontroller = create_controller('classical_smc')\n\n# With explicit gains\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\n# With configuration object\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\ncontroller = create_controller('adaptive_smc', config=config)\n\n# Combined parameters (gains override config)\ncontroller = create_controller(\n    'sta_smc',\n    config=config,\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # Takes priority\n)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e83a8c45"
  },
  {
    "id": "factory_methods_reference_3_ebb949ab",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 3,
    "code": "# Required gains: [k1, k2, lambda1, lambda2, K, kd]\n# Required parameters: max_force, boundary_layer, dt\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ebb949ab"
  },
  {
    "id": "factory_methods_reference_4_6fb4eb82",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 4,
    "code": "# Required gains: [K1, K2, k1, k2, lambda1, lambda2]\n# Required parameters: max_force, dt\ncontroller = create_controller(\n    'sta_smc',\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0]\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fb4eb82"
  },
  {
    "id": "factory_methods_reference_5_f1f0bcc1",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 5,
    "code": "# Required gains: [k1, k2, lambda1, lambda2, gamma]\n# Required parameters: max_force, dt\ncontroller = create_controller(\n    'adaptive_smc',\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0]\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1f0bcc1"
  },
  {
    "id": "factory_methods_reference_6_1f712b79",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 6,
    "code": "# Required gains: [k1, k2, lambda1, lambda2]\n# Special handling: Creates sub-controllers automatically\ncontroller = create_controller(\n    'hybrid_adaptive_sta_smc',\n    gains=[18.0, 12.0, 10.0, 8.0]\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f712b79"
  },
  {
    "id": "factory_methods_reference_7_281e87f0",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 7,
    "code": "# No traditional gains\n# Required parameters: horizon, q_x, q_theta, r_u\ncontroller = create_controller('mpc_controller')  # Uses defaults",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "281e87f0"
  },
  {
    "id": "factory_methods_reference_8_edb74eda",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef list_available_controllers() -> List[str]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "edb74eda"
  },
  {
    "id": "factory_methods_reference_9_be3c8a9d",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 9,
    "code": "available = list_available_controllers()\nprint(\"Available controllers:\", available)\n# Output: ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n# Note: 'mpc_controller' only included if optional dependencies available",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be3c8a9d"
  },
  {
    "id": "factory_methods_reference_10_27c639d3",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef list_all_controllers() -> List[str]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27c639d3"
  },
  {
    "id": "factory_methods_reference_11_310e1b7f",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 11,
    "code": "all_controllers = list_all_controllers()\navailable = list_available_controllers()\n\nunavailable = set(all_controllers) - set(available)\nif unavailable:\n    print(f\"Unavailable controllers: {unavailable}\")\n    print(\"Check dependencies and installation\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "310e1b7f"
  },
  {
    "id": "factory_methods_reference_12_4a447d2f",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_default_gains(controller_type: str) -> List[float]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a447d2f"
  },
  {
    "id": "factory_methods_reference_13_409104c0",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Get default gains for different controllers\nclassical_gains = get_default_gains('classical_smc')\nprint(f\"Classical SMC defaults: {classical_gains}\")\n# Output: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n\nadaptive_gains = get_default_gains('adaptive_smc')\nprint(f\"Adaptive SMC defaults: {adaptive_gains}\")\n# Output: [25.0, 18.0, 15.0, 10.0, 4.0]\n\n# Use as starting point for optimization\noptimized_gains = optimize_controller_gains(\n    controller_type='classical_smc',\n    initial_gains=get_default_gains('classical_smc')\n)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "409104c0"
  },
  {
    "id": "factory_methods_reference_14_3a48cb6d",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 14,
    "code": "def create_smc_for_pso(\n    smc_type: SMCType,\n    gains: Union[list, np.ndarray],\n    plant_config_or_model: Optional[Any] = None,\n    **kwargs: Any\n) -> PSOControllerWrapper",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a48cb6d"
  },
  {
    "id": "factory_methods_reference_15_6d6513b0",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 15,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\n\n# Create PSO-compatible controller\ngains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=gains,\n    max_force=150.0,\n    dt=0.001\n)\n\n# Use in PSO fitness function\ndef fitness_function(test_gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, test_gains)\n    return evaluate_controller_performance(controller)\n\n# Validate particle swarm\nparticles = np.array([\n    [20, 15, 12, 8, 35, 5],\n    [25, 20, 15, 10, 40, 6],\n    [0, 0, 0, 0, 0, 0]  # Invalid\n])\nvalidity = controller.validate_gains(particles)\nprint(f\"Particle validity: {validity}\")\n# Output: [True, True, False]",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d6513b0"
  },
  {
    "id": "factory_methods_reference_16_e584e1b8",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 16,
    "code": "def create_pso_controller_factory(\n    smc_type: SMCType,\n    plant_config: Optional[Any] = None,\n    **kwargs: Any\n) -> Callable[[Union[list, np.ndarray]], PSOControllerWrapper]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e584e1b8"
  },
  {
    "id": "factory_methods_reference_17_b0043e05",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Create factory once (expensive operation)\nfactory = create_pso_controller_factory(\n    SMCType.CLASSICAL,\n    plant_config=config.physics,\n    max_force=150.0\n)\n\n# Check factory attributes\nprint(f\"Required gains: {factory.n_gains}\")\nprint(f\"Controller type: {factory.controller_type}\")\nprint(f\"Max force: {factory.max_force}\")\n\n# Use factory many times (fast operation)\ndef pso_fitness_function(gains):\n    controller = factory(gains)  # Fast!\n    return evaluate_controller_performance(controller)\n\n# PSO optimization\ntuner = PSOTuner(\n    controller_factory=pso_fitness_function,\n    config=config\n)\nbest_gains, best_fitness = tuner.optimize()",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0043e05"
  },
  {
    "id": "factory_methods_reference_18_dcff5d8b",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcff5d8b"
  },
  {
    "id": "factory_methods_reference_19_609a6ba0",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 19,
    "code": "# Gains: [k1, k2, lambda1, lambda2, K, kd]\nlower_bounds = [1.0, 1.0, 1.0, 1.0, 5.0, 0.1]\nupper_bounds = [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "609a6ba0"
  },
  {
    "id": "factory_methods_reference_20_999ee1cc",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 20,
    "code": "# Gains: [k1, k2, lambda1, lambda2, gamma]\nlower_bounds = [2.0, 2.0, 1.0, 1.0, 0.5]\nupper_bounds = [40.0, 40.0, 25.0, 25.0, 10.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "999ee1cc"
  },
  {
    "id": "factory_methods_reference_21_6c7d7653",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 21,
    "code": "# Gains: [K1, K2, k1, k2, lambda1, lambda2]\nlower_bounds = [3.0, 2.0, 2.0, 2.0, 0.5, 0.5]\nupper_bounds = [50.0, 30.0, 30.0, 30.0, 20.0, 20.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c7d7653"
  },
  {
    "id": "factory_methods_reference_22_11056fd9",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 22,
    "code": "# Gains: [k1, k2, lambda1, lambda2]\nlower_bounds = [2.0, 2.0, 1.0, 1.0]\nupper_bounds = [30.0, 30.0, 20.0, 20.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "11056fd9"
  },
  {
    "id": "factory_methods_reference_23_64f836ff",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Get bounds for PSO optimization\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nlower_bounds, upper_bounds = bounds\n\nprint(f\"Lower bounds: {lower_bounds}\")\nprint(f\"Upper bounds: {upper_bounds}\")\n\n# Use with PSO optimizer\npso_config = {\n    'bounds': bounds,\n    'n_particles': 30,\n    'max_iter': 100\n}\n\n# Validate bounds make sense\nassert len(lower_bounds) == 6  # Classical SMC has 6 gains\nassert all(l < u for l, u in zip(lower_bounds, upper_bounds))",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "64f836ff"
  },
  {
    "id": "factory_methods_reference_24_ed5a496b",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_gains(smc_type: SMCType, gains: Union[list, np.ndarray]) -> bool",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed5a496b"
  },
  {
    "id": "factory_methods_reference_25_59a072ff",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Validate gains before expensive simulation\ndef robust_fitness_function(gains):\n    if not validate_smc_gains(SMCType.CLASSICAL, gains):\n        return float('inf')  # Invalid gains get worst fitness\n\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    return evaluate_controller_performance(controller)\n\n# Test various gain sets\ntest_gains = [\n    [20, 15, 12, 8, 35, 5],     # Valid\n    [20, 15, 12, 8, 35],        # Wrong length\n    [20, 15, 12, 8, -35, 5],    # Negative value\n    [20, 15, 12, 8, np.inf, 5], # Infinite value\n]\n\nfor i, gains in enumerate(test_gains):\n    valid = validate_smc_gains(SMCType.CLASSICAL, gains)\n    print(f\"Gains {i+1}: {'Valid' if valid else 'Invalid'}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59a072ff"
  },
  {
    "id": "factory_methods_reference_26_4777becd",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\ndef _get_controller_info(controller_type: str) -> Dict[str, Any]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4777becd"
  },
  {
    "id": "factory_methods_reference_27_6b31c44a",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'controller_type': {\n        'class': ControllerClass,              # Implementation class\n        'config_class': ConfigClass,           # Configuration class\n        'default_gains': [float, ...],         # Default gain values\n        'gain_count': int,                     # Expected number of gains\n        'description': str,                    # Human-readable description\n        'supports_dynamics': bool,             # Supports dynamics model\n        'required_params': [str, ...]          # Required parameters\n    }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b31c44a"
  },
  {
    "id": "factory_methods_reference_28_2314a264",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_ALIASES = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n    'hybrid_sta': 'hybrid_adaptive_sta_smc',\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2314a264"
  },
  {
    "id": "factory_methods_reference_29_4b463528",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 29,
    "code": "def _resolve_controller_gains(\n    gains: Optional[Union[List[float], np.ndarray]],\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> List[float]",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b463528"
  },
  {
    "id": "factory_methods_reference_30_497042e5",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 30,
    "code": "# Pattern 1: Direct controller configuration\nconfig.controllers.classical_smc.gains = [20, 15, 12, 8, 35, 5]\n\n# Pattern 2: Controller defaults\nconfig.controller_defaults.classical_smc.gains = [20, 15, 12, 8, 35, 5]\n\n# Pattern 3: Dictionary-style access\nconfig.controllers['classical_smc']['gains'] = [20, 15, 12, 8, 35, 5]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "497042e5"
  },
  {
    "id": "factory_methods_reference_31_9a3ba30c",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 31,
    "code": "def check_deprecated_config(controller_type: str, params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Check for deprecated parameters and apply migrations.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a3ba30c"
  },
  {
    "id": "factory_methods_reference_32_e9bf9730",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 32,
    "code": "deprecated_mappings = {\n    'use_equivalent': 'enable_equivalent_control',\n    'k_gain': 'switching_gain',\n    'lambda_gains': 'surface_gains'\n}",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e9bf9730"
  },
  {
    "id": "factory_methods_reference_33_900991f1",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 33,
    "code": "def _validate_controller_gains(\n    gains: List[float],\n    controller_info: Dict[str, Any]\n) -> None",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "900991f1"
  },
  {
    "id": "factory_methods_reference_34_718b6f48",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 34,
    "code": "def _validate_mpc_parameters(\n    config_params: Dict[str, Any],\n    controller_params: Dict[str, Any]\n) -> None",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "718b6f48"
  },
  {
    "id": "factory_methods_reference_35_8e6bc6dd",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 35,
    "code": "# example-metadata:\n# runnable: false\n\n# Horizon must be positive integer\nif 'horizon' in params and (not isinstance(params['horizon'], int) or params['horizon'] < 1):\n    raise ConfigValueError(\"horizon must be \u2265 1\")\n\n# Geometric constraints\nif 'max_cart_pos' in params and params['max_cart_pos'] <= 0:\n    raise ConfigValueError(\"max_cart_pos must be > 0\")\n\n# Weight parameters must be non-negative\nweight_params = ['q_x', 'q_theta', 'r_u']\nfor param in weight_params:\n    if param in params and params[param] < 0:\n        raise ConfigValueError(f\"{param} must be \u2265 0\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e6bc6dd"
  },
  {
    "id": "factory_methods_reference_36_2c52316c",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 36,
    "code": "# Type aliases for better type safety\nStateVector = NDArray[np.float64]           # System state vector\nControlOutput = Union[float, NDArray[np.float64]]  # Control output\nGainsArray = Union[List[float], NDArray[np.float64]]  # Gain values\nConfigDict = Dict[str, Any]                 # Configuration dictionary\n\n# Generic type for controller instances\nControllerT = TypeVar('ControllerT')",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c52316c"
  },
  {
    "id": "factory_methods_reference_37_a4fe4286",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 37,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Protocol defining the standard controller interface.\"\"\"\n\n    def compute_control(\n        self,\n        state: StateVector,\n        last_control: float,\n        history: ConfigDict\n    ) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller internal state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4fe4286"
  },
  {
    "id": "factory_methods_reference_38_62c1acf0",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 38,
    "code": "class SMCType(Enum):\n    \"\"\"SMC Controller types enumeration.\"\"\"\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62c1acf0"
  },
  {
    "id": "factory_methods_reference_39_28a94a2e",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 39,
    "code": "class HybridMode(Enum):\n    \"\"\"Hybrid controller operation modes.\"\"\"\n    CLASSICAL_ADAPTIVE = \"classical_adaptive\"\n    STA_ADAPTIVE = \"sta_adaptive\"\n    DYNAMIC_SWITCHING = \"dynamic_switching\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28a94a2e"
  },
  {
    "id": "factory_methods_reference_40_3f7eae12",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 40,
    "code": "class ConfigValueError(ValueError):\n    \"\"\"Exception raised for invalid configuration values.\"\"\"\n    pass",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f7eae12"
  },
  {
    "id": "factory_methods_reference_41_2ce804ab",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 41,
    "code": "try:\n    controller = create_controller('mpc_controller', config=invalid_config)\nexcept ConfigValueError as e:\n    print(f\"Configuration error: {e}\")\n    # Handle invalid configuration",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ce804ab"
  },
  {
    "id": "factory_methods_reference_42_a385f7ea",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 42,
    "code": "# example-metadata:\n# runnable: false\n\n# Unknown controller type\ntry:\n    controller = create_controller('invalid_controller')\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    # Output: Unknown controller type 'invalid_controller'. Available: [...]\n\n# Invalid gain count\ntry:\n    controller = create_controller('classical_smc', gains=[1, 2, 3])  # Need 6 gains\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    # Output: Controller 'classical_smc' requires 6 gains, got 3",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a385f7ea"
  },
  {
    "id": "factory_methods_reference_43_969c5369",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 43,
    "code": "# example-metadata:\n# runnable: false\n\n# MPC without optional dependencies\ntry:\n    controller = create_controller('mpc_controller')\nexcept ImportError as e:\n    print(f\"Import error: {e}\")\n    # Output: MPC controller missing optional dependency. Available controllers: [...]",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "969c5369"
  },
  {
    "id": "factory_methods_reference_44_b9df236d",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 44,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller_safely(controller_type: str, **kwargs) -> Optional[Any]:\n    \"\"\"Create controller with comprehensive error handling.\"\"\"\n    try:\n        return create_controller(controller_type, **kwargs)\n    except ValueError as e:\n        logger.error(f\"Configuration error for {controller_type}: {e}\")\n        return None\n    except ImportError as e:\n        logger.warning(f\"Import error for {controller_type}: {e}\")\n        return None\n    except Exception as e:\n        logger.error(f\"Unexpected error creating {controller_type}: {e}\")\n        return None",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9df236d"
  },
  {
    "id": "factory_methods_reference_45_90a05080",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 45,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_best_available_controller(preferred_types: List[str]) -> Any:\n    \"\"\"Create first available controller from preference list.\"\"\"\n    available = list_available_controllers()\n\n    for controller_type in preferred_types:\n        if controller_type in available:\n            try:\n                return create_controller(controller_type)\n            except Exception as e:\n                logger.warning(f\"Failed to create {controller_type}: {e}\")\n                continue\n\n    # Fallback to any available controller\n    if available:\n        return create_controller(available[0])\n    else:\n        raise RuntimeError(\"No controllers available\")",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "90a05080"
  },
  {
    "id": "factory_methods_reference_46_a79f50e7",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 46,
    "code": "#!/usr/bin/env python3\n\"\"\"Basic factory usage examples.\"\"\"\n\nfrom src.controllers.factory import create_controller, list_available_controllers\n\ndef basic_factory_examples():\n    \"\"\"Demonstrate basic factory usage patterns.\"\"\"\n\n    # Check available controllers\n    available = list_available_controllers()\n    print(f\"Available controllers: {available}\")\n\n    # Create controller with defaults\n    controller = create_controller('classical_smc')\n    print(f\"Default gains: {controller.gains}\")\n\n    # Create with explicit gains\n    custom_gains = [25.0, 20.0, 15.0, 10.0, 40.0, 6.0]\n    controller = create_controller('classical_smc', gains=custom_gains)\n    print(f\"Custom gains: {controller.gains}\")\n\n    # Test controller functionality\n    import numpy as np\n    state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    control_output = controller.compute_control(state, 0.0, {})\n    print(f\"Control output: {control_output}\")\n\nif __name__ == \"__main__\":\n    basic_factory_examples()",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a79f50e7"
  },
  {
    "id": "factory_methods_reference_47_c711ca81",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 47,
    "code": "#!/usr/bin/env python3\n\"\"\"PSO integration examples.\"\"\"\n\nfrom src.controllers.factory import (\n    create_pso_controller_factory,\n    get_gain_bounds_for_pso,\n    validate_smc_gains,\n    SMCType\n)\nimport numpy as np\n\ndef pso_integration_example():\n    \"\"\"Demonstrate PSO integration patterns.\"\"\"\n\n    # Get optimization bounds\n    bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n    lower_bounds, upper_bounds = bounds\n    print(f\"Optimization bounds: {lower_bounds} to {upper_bounds}\")\n\n    # Create PSO-optimized factory\n    factory = create_pso_controller_factory(SMCType.CLASSICAL)\n    print(f\"Factory requires {factory.n_gains} gains\")\n\n    # Define fitness function\n    def fitness_function(gains: np.ndarray) -> float:\n        \"\"\"PSO fitness function with validation.\"\"\"\n\n        # Pre-validate gains\n        if not validate_smc_gains(SMCType.CLASSICAL, gains):\n            return float('inf')\n\n        try:\n            # Create controller\n            controller = factory(gains)\n\n            # Simplified performance evaluation\n            test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n            control_output = controller.compute_control(test_state)\n\n            # Simple fitness (control effort)\n            return abs(control_output.u) if hasattr(control_output, 'u') else abs(control_output)\n\n        except Exception:\n            return float('inf')\n\n    # Test fitness function\n    test_gains = np.array([20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n    fitness = fitness_function(test_gains)\n    print(f\"Test fitness: {fitness}\")\n\n    # Simulate PSO particle validation\n    particles = np.random.uniform(\n        low=lower_bounds,\n        high=upper_bounds,\n        size=(10, len(lower_bounds))\n    )\n\n    valid_particles = []\n    for particle in particles:\n        if validate_smc_gains(SMCType.CLASSICAL, particle):\n            valid_particles.append(particle)\n\n    print(f\"Valid particles: {len(valid_particles)}/{len(particles)}\")\n\nif __name__ == \"__main__\":\n    pso_integration_example()",
    "lines": 66,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c711ca81"
  },
  {
    "id": "factory_methods_reference_48_991d51d7",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 48,
    "code": "#!/usr/bin/env python3\n\"\"\"Advanced configuration examples.\"\"\"\n\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\nimport numpy as np\n\ndef advanced_configuration_example():\n    \"\"\"Demonstrate advanced configuration patterns.\"\"\"\n\n    # Load configuration from file\n    config = load_config(\"config.yaml\")\n\n    # Create controllers with various configuration methods\n    controllers = {}\n\n    # Method 1: Configuration file only\n    controllers['config_only'] = create_controller('classical_smc', config=config)\n\n    # Method 2: Override gains from config\n    custom_gains = [30.0, 25.0, 18.0, 12.0, 45.0, 8.0]\n    controllers['override_gains'] = create_controller(\n        'classical_smc',\n        config=config,\n        gains=custom_gains  # Overrides config gains\n    )\n\n    # Method 3: Different controller types\n    for controller_type in ['classical_smc', 'adaptive_smc', 'sta_smc']:\n        try:\n            controllers[controller_type] = create_controller(controller_type, config=config)\n        except ImportError as e:\n            print(f\"Skipping {controller_type}: {e}\")\n\n    # Compare controller properties\n    for name, controller in controllers.items():\n        print(f\"{name}:\")\n        print(f\"  Gains: {controller.gains}\")\n        print(f\"  Max force: {getattr(controller, 'max_force', 'N/A')}\")\n\n        # Test control computation\n        test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n        try:\n            control_output = controller.compute_control(test_state, 0.0, {})\n            control_value = control_output.u if hasattr(control_output, 'u') else control_output\n            print(f\"  Control output: {control_value:.3f}\")\n        except Exception as e:\n            print(f\"  Control computation failed: {e}\")\n\n        print()\n\nif __name__ == \"__main__\":\n    advanced_configuration_example()",
    "lines": 53,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "991d51d7"
  },
  {
    "id": "factory_methods_reference_49_7a12f551",
    "file": "docs\\api\\factory_methods_reference.md",
    "index": 49,
    "code": "#!/usr/bin/env python3\n\"\"\"Error handling examples.\"\"\"\n\nfrom src.controllers.factory import create_controller, list_available_controllers\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\ndef error_handling_example():\n    \"\"\"Demonstrate robust error handling patterns.\"\"\"\n\n    test_cases = [\n        # Valid cases\n        ('classical_smc', [20, 15, 12, 8, 35, 5], \"Valid classical SMC\"),\n        ('adaptive_smc', [25, 18, 15, 10, 4], \"Valid adaptive SMC\"),\n\n        # Error cases\n        ('invalid_controller', None, \"Unknown controller type\"),\n        ('classical_smc', [1, 2, 3], \"Invalid gain count\"),\n        ('classical_smc', [-20, 15, 12, 8, 35, 5], \"Negative gains\"),\n        ('mpc_controller', None, \"Potentially missing dependencies\"),\n    ]\n\n    for controller_type, gains, description in test_cases:\n        print(f\"Testing: {description}\")\n\n        try:\n            if gains is not None:\n                controller = create_controller(controller_type, gains=gains)\n            else:\n                controller = create_controller(controller_type)\n\n            print(f\"  \u2705 Success: {controller_type} created\")\n            print(f\"     Gains: {controller.gains}\")\n\n        except ValueError as e:\n            print(f\"  \u274c Configuration Error: {e}\")\n\n        except ImportError as e:\n            print(f\"  \u26a0\ufe0f  Import Error: {e}\")\n            available = list_available_controllers()\n            print(f\"     Available: {available}\")\n\n        except Exception as e:\n            print(f\"  \ud83d\udca5 Unexpected Error: {e}\")\n\n        print()\n\nif __name__ == \"__main__\":\n    error_handling_example()",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a12f551"
  },
  {
    "id": "factory_reference_1_f21aaf13",
    "file": "docs\\api\\factory_reference.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\n# Basic creation with default gains\ncontroller = create_controller('classical_smc')\n\n# Creation with custom gains\ncontroller = create_controller('adaptive_smc', gains=[25.0, 18.0, 15.0, 10.0, 4.0])\n\n# Creation with configuration\ncontroller = create_controller('sta_smc', config=my_config)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f21aaf13"
  },
  {
    "id": "factory_reference_2_1d8b355a",
    "file": "docs\\api\\factory_reference.md",
    "index": 2,
    "code": "from src.controllers.factory import list_available_controllers\n\navailable = list_available_controllers()\n# Returns: ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1d8b355a"
  },
  {
    "id": "factory_reference_3_8ce27d51",
    "file": "docs\\api\\factory_reference.md",
    "index": 3,
    "code": "from src.controllers.factory import get_default_gains\n\ngains = get_default_gains('classical_smc')\n# Returns: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ce27d51"
  },
  {
    "id": "factory_reference_4_ceda1b2c",
    "file": "docs\\api\\factory_reference.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    # ... additional controllers\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceda1b2c"
  },
  {
    "id": "factory_reference_5_0ffe6197",
    "file": "docs\\api\\factory_reference.md",
    "index": 5,
    "code": "from src.controllers.factory import SMCType\n\nclass SMCType(Enum):\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ffe6197"
  },
  {
    "id": "factory_reference_6_09800cfa",
    "file": "docs\\api\\factory_reference.md",
    "index": 6,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\nimport numpy as np\n\n# Create PSO-optimized controller\nwrapper = create_smc_for_pso(SMCType.CLASSICAL, [20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n\n# Use in PSO fitness function\nstate = np.array([0.1, 0.0, 0.05, 0.0, 0.1, 0.0])\ncontrol_output = wrapper.compute_control(state)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "09800cfa"
  },
  {
    "id": "factory_reference_7_5e5b56bf",
    "file": "docs\\api\\factory_reference.md",
    "index": 7,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType\n\nlower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n# Returns: ([1.0, 1.0, 1.0, 1.0, 5.0, 0.1], [30.0, 30.0, 20.0, 20.0, 50.0, 10.0])",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e5b56bf"
  },
  {
    "id": "factory_reference_8_f6dd6806",
    "file": "docs\\api\\factory_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nSMC_GAIN_SPECS = {\n    SMCType.CLASSICAL: SMCGainSpec(\n        gain_names=['k1', 'k2', 'lambda1', 'lambda2', 'K', 'kd'],\n        gain_bounds=[(1.0, 30.0), (1.0, 30.0), (1.0, 20.0), (1.0, 20.0), (5.0, 50.0), (0.1, 10.0)],\n        controller_type='classical_smc',\n        n_gains=6\n    ),\n    # ... additional specifications\n}",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6dd6806"
  },
  {
    "id": "factory_reference_9_7015ba5f",
    "file": "docs\\api\\factory_reference.md",
    "index": 9,
    "code": "from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n\nconfig = ClassicalSMCConfig(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.02\n)\n\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7015ba5f"
  },
  {
    "id": "factory_reference_10_729a2177",
    "file": "docs\\api\\factory_reference.md",
    "index": 10,
    "code": "from src.controllers.factory import create_controller, ConfigValueError\n\ntry:\n    controller = create_controller('invalid_type')\nexcept ValueError as e:\n    print(f\"Invalid controller: {e}\")\n\ntry:\n    controller = create_controller('sta_smc', gains=[15.0, 25.0, 20.0, 12.0, 8.0, 6.0])  # K1 < K2\nexcept ValueError as e:\n    print(f\"Constraint violation: {e}\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "729a2177"
  },
  {
    "id": "factory_reference_11_13a5e0e9",
    "file": "docs\\api\\factory_reference.md",
    "index": 11,
    "code": "import threading\nfrom src.controllers.factory import create_controller\n\ndef create_controllers_concurrently():\n    controller = create_controller('classical_smc')\n    # Safe for concurrent execution\n\nthreads = [threading.Thread(target=create_controllers_concurrently) for _ in range(10)]\nfor t in threads:\n    t.start()",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "13a5e0e9"
  },
  {
    "id": "factory_reference_12_c82cbf8d",
    "file": "docs\\api\\factory_reference.md",
    "index": 12,
    "code": "from src.controllers.factory import create_controller\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create controller via factory\ncontroller = create_controller('adaptive_smc')\n\n# Use in simulation\nrunner = SimulationRunner(controller=controller, dynamics=dynamics)\nresults = runner.run(initial_state=[0.1, 0.0, 0.05, 0.0, 0.1, 0.0], duration=2.0)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82cbf8d"
  },
  {
    "id": "factory_reference_13_4b438a28",
    "file": "docs\\api\\factory_reference.md",
    "index": 13,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\nfrom src.optimizer.pso_optimizer import PSOTuner\n\ndef fitness_function(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    # Evaluate controller performance\n    return performance_score\n\n# Configure PSO optimization\ntuner = PSOTuner()\nbest_gains = tuner.optimize(fitness_function, bounds=gain_bounds)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b438a28"
  },
  {
    "id": "factory_reference_14_10eb10e2",
    "file": "docs\\api\\factory_reference.md",
    "index": 14,
    "code": "# Legacy pattern (still supported)\nfrom src.controllers.factory import create_classical_smc_controller\ncontroller = create_classical_smc_controller(gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n\n# Modern pattern (recommended)\nfrom src.controllers.factory import create_controller\ncontroller = create_controller('classical_smc', gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0])",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10eb10e2"
  },
  {
    "id": "factory_reference_15_7808a5e1",
    "file": "docs\\api\\factory_reference.md",
    "index": 15,
    "code": "import logging\nlogging.getLogger('src.controllers.factory').setLevel(logging.DEBUG)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7808a5e1"
  },
  {
    "id": "factory_system_api_reference_1_7cc86cb0",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe factory operations with timeout protection\n_factory_lock = threading.RLock()\n_LOCK_TIMEOUT = 10.0  # seconds\n\ndef create_controller(controller_type, config=None, gains=None):\n    with _factory_lock:\n        # Thread-safe controller creation logic\n        ...",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7cc86cb0"
  },
  {
    "id": "factory_system_api_reference_2_45450afc",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 2,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45450afc"
  },
  {
    "id": "factory_system_api_reference_3_2314a264",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_ALIASES = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n    'hybrid_sta': 'hybrid_adaptive_sta_smc',\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2314a264"
  },
  {
    "id": "factory_system_api_reference_4_861a8aed",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 4,
    "code": "# All create the same controller type\ncontroller1 = create_controller('classical_smc', config)\ncontroller2 = create_controller('classic_smc', config)  # Alias\ncontroller3 = create_controller('smc_v1', config)       # Alias",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "861a8aed"
  },
  {
    "id": "factory_system_api_reference_5_8215bcba",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Priority demonstration\nconfig = load_config(\"config.yaml\")  # config.controllers.classical_smc.gains = [5,5,5,0.5,0.5,0.5]\n\n# Priority 1: Explicit gains override everything\ncontroller = create_controller('classical_smc', config, gains=[10,10,10,1,1,1])\n# Uses: [10,10,10,1,1,1]\n\n# Priority 2: Config gains used when explicit gains not provided\ncontroller = create_controller('classical_smc', config)\n# Uses: [5,5,5,0.5,0.5,0.5] from config\n\n# Priority 3: Registry defaults when config missing/invalid\ncontroller = create_controller('classical_smc')\n# Uses: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0] from CONTROLLER_REGISTRY",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8215bcba"
  },
  {
    "id": "factory_system_api_reference_6_74f68610",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    def compute_control(\n        self,\n        state: StateVector,\n        last_control: float,\n        history: ConfigDict\n    ) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller internal state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "74f68610"
  },
  {
    "id": "factory_system_api_reference_7_db93b447",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 7,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Create controller with config defaults\ncontroller = create_controller('classical_smc', config)\n\n# Use controller in simulation\nstate = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\ncontrol_output = controller.compute_control(state, 0.0, {})\nprint(f\"Control force: {control_output.u:.3f} N\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "db93b447"
  },
  {
    "id": "factory_system_api_reference_8_b98108a9",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 8,
    "code": "from src.controllers.factory import create_controller\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# PSO optimization finds optimal gains\n# (See PSO Integration section for complete optimization workflow)\noptimized_gains = [25.3, 18.7, 14.2, 10.8, 42.6, 6.1]  # From PSO\n\n# Create controller with optimized gains\ncontroller = create_controller('classical_smc', config, gains=optimized_gains)\n\n# Optimized controller has lower cost than defaults\nbaseline_cost = evaluate_controller(create_controller('classical_smc', config))\noptimized_cost = evaluate_controller(controller)\nprint(f\"Cost improvement: {((baseline_cost - optimized_cost) / baseline_cost * 100):.1f}%\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b98108a9"
  },
  {
    "id": "factory_system_api_reference_9_db6de2ab",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 9,
    "code": "from src.controllers.factory import create_controller, list_available_controllers\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\n\n# Create all available controller types\ncontrollers = {}\nfor controller_type in list_available_controllers():\n    try:\n        controllers[controller_type] = create_controller(controller_type, config)\n        print(f\"\u2713 Created {controller_type}\")\n    except Exception as e:\n        print(f\"\u2717 Failed to create {controller_type}: {e}\")\n\n# Run comparative simulation\nfor name, controller in controllers.items():\n    cost = simulate_and_evaluate(controller)\n    print(f\"{name}: cost={cost:.3f}\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "db6de2ab"
  },
  {
    "id": "factory_system_api_reference_10_fd8a09ed",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 10,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\n\n# Override specific controller parameters\ncustom_gains = [30.0, 20.0, 15.0, 12.0, 45.0, 7.0]\ncontroller = create_controller(\n    'classical_smc',\n    config,\n    gains=custom_gains\n)\n\n# Verify custom gains applied\nassert controller.gains == custom_gains\nprint(f\"Controller created with custom gains: {controller.gains}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd8a09ed"
  },
  {
    "id": "factory_system_api_reference_11_62cf6174",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 11,
    "code": "from src.controllers.factory import create_controller\n\n# All these create the same controller type ('sta_smc')\ncontroller1 = create_controller('sta_smc')           # Canonical name\ncontroller2 = create_controller('super_twisting')    # Alias\ncontroller3 = create_controller('sta')               # Short alias\n\n# Verify all are the same type\nassert type(controller1) == type(controller2) == type(controller3)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62cf6174"
  },
  {
    "id": "factory_system_api_reference_12_fb2517a9",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef list_available_controllers() -> list",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb2517a9"
  },
  {
    "id": "factory_system_api_reference_13_84901607",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 13,
    "code": "# Example return values\n['adaptive_smc', 'classical_smc', 'hybrid_adaptive_sta_smc', 'sta_smc']  # MPC unavailable\n['adaptive_smc', 'classical_smc', 'hybrid_adaptive_sta_smc', 'mpc_controller', 'sta_smc']  # MPC available",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84901607"
  },
  {
    "id": "factory_system_api_reference_14_0ed02881",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 14,
    "code": "from src.controllers.factory import list_available_controllers, create_controller\n\n# Check availability before attempting creation\navailable = list_available_controllers()\nprint(f\"Available controllers: {available}\")\n\nif 'mpc_controller' in available:\n    mpc = create_controller('mpc_controller')\n    print(\"MPC controller created successfully\")\nelse:\n    print(\"MPC not available (install cvxpy: pip install cvxpy)\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ed02881"
  },
  {
    "id": "factory_system_api_reference_15_eb8fb0ea",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 15,
    "code": "from src.controllers.factory import list_available_controllers, create_controller\nimport pandas as pd\n\n# Benchmark all available controllers\nresults = []\nfor controller_type in list_available_controllers():\n    controller = create_controller(controller_type)\n    cost, time = evaluate_controller(controller)\n    results.append({\n        'controller': controller_type,\n        'cost': cost,\n        'computation_time': time\n    })\n\n# Display results\ndf = pd.DataFrame(results)\nprint(df.sort_values('cost'))",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb8fb0ea"
  },
  {
    "id": "factory_system_api_reference_16_236c4438",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef list_all_controllers() -> list",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "236c4438"
  },
  {
    "id": "factory_system_api_reference_17_b576af91",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 17,
    "code": "# Always returns all registered types\n['adaptive_smc', 'classical_smc', 'hybrid_adaptive_sta_smc', 'mpc_controller', 'sta_smc']",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b576af91"
  },
  {
    "id": "factory_system_api_reference_18_a7063945",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_default_gains(controller_type: str) -> list",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7063945"
  },
  {
    "id": "factory_system_api_reference_19_be54d9a8",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.factory import get_default_gains\n\n# Get baseline gains\ndefault_gains = get_default_gains('classical_smc')\nprint(f\"Baseline gains: {default_gains}\")\n# Output: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n\n# Use as PSO initial guess\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\ntuner = PSOTuner(...)\noptimized_gains = tuner.optimize(initial_guess=default_gains)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be54d9a8"
  },
  {
    "id": "factory_system_api_reference_20_408eacd9",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 20,
    "code": "from src.controllers.factory import get_default_gains, create_controller\n\n# Create controllers with default and custom gains\ngains_default = get_default_gains('classical_smc')\ngains_custom = [30.0, 20.0, 15.0, 12.0, 45.0, 7.0]\n\ncontroller_default = create_controller('classical_smc', gains=gains_default)\ncontroller_custom = create_controller('classical_smc', gains=gains_custom)\n\n# Compare performance\ncost_default = evaluate(controller_default)\ncost_custom = evaluate(controller_custom)\nprint(f\"Default cost: {cost_default:.3f}\")\nprint(f\"Custom cost: {cost_custom:.3f}\")\nprint(f\"Improvement: {((cost_default - cost_custom) / cost_default * 100):.1f}%\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "408eacd9"
  },
  {
    "id": "factory_system_api_reference_21_dbd452d2",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY: Dict[str, Dict[str, Any]] = {\n    'controller_type': {\n        'class': ControllerClass,              # Controller class reference\n        'config_class': ConfigClass,           # Configuration class reference\n        'default_gains': List[float],          # Default gain vector\n        'gain_count': int,                     # Expected number of gains\n        'description': str,                    # Human-readable description\n        'supports_dynamics': bool,             # Whether controller uses dynamics model\n        'required_params': List[str]           # Required configuration parameters\n    }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbd452d2"
  },
  {
    "id": "factory_system_api_reference_22_86f4a8d9",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 22,
    "code": "'classical_smc': {\n    'class': ClassicalSMC,\n    'config_class': ClassicalSMCConfig,\n    'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    'gain_count': 6,\n    'description': 'Classical sliding mode controller with boundary layer',\n    'supports_dynamics': True,\n    'required_params': ['gains', 'max_force', 'boundary_layer']\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "86f4a8d9"
  },
  {
    "id": "factory_system_api_reference_23_fbd3d29d",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 23,
    "code": "'sta_smc': {\n    'class': SuperTwistingSMC,\n    'config_class': STASMCConfig,\n    'default_gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n    'gain_count': 6,\n    'description': 'Super-twisting sliding mode controller',\n    'supports_dynamics': True,\n    'required_params': ['gains', 'max_force', 'dt']\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbd3d29d"
  },
  {
    "id": "factory_system_api_reference_24_fbaafee2",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 24,
    "code": "'adaptive_smc': {\n    'class': AdaptiveSMC,\n    'config_class': AdaptiveSMCConfig,\n    'default_gains': [25.0, 18.0, 15.0, 10.0, 4.0],\n    'gain_count': 5,\n    'description': 'Adaptive sliding mode controller with parameter estimation',\n    'supports_dynamics': True,\n    'required_params': ['gains', 'max_force', 'dt']\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbaafee2"
  },
  {
    "id": "factory_system_api_reference_25_d29b8973",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 25,
    "code": "'hybrid_adaptive_sta_smc': {\n    'class': ModularHybridSMC,\n    'config_class': HybridAdaptiveSTASMCConfig,\n    'default_gains': [18.0, 12.0, 10.0, 8.0],\n    'gain_count': 4,\n    'description': 'Hybrid adaptive super-twisting sliding mode controller',\n    'supports_dynamics': False,  # Uses sub-controllers\n    'required_params': ['classical_config', 'adaptive_config', 'hybrid_mode']\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d29b8973"
  },
  {
    "id": "factory_system_api_reference_26_d994a32a",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 26,
    "code": "'mpc_controller': {\n    'class': MPCController,  # None if cvxpy unavailable\n    'config_class': MPCConfig,\n    'default_gains': [],\n    'gain_count': 0,\n    'description': 'Model predictive controller',\n    'supports_dynamics': True,\n    'required_params': ['horizon', 'q_x', 'q_theta', 'r_u']\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d994a32a"
  },
  {
    "id": "factory_system_api_reference_27_9f8ff4ae",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 27,
    "code": "from src.controllers.factory import CONTROLLER_REGISTRY\n\n# Get metadata for a controller type\nclassical_info = CONTROLLER_REGISTRY['classical_smc']\nprint(f\"Description: {classical_info['description']}\")\nprint(f\"Gain count: {classical_info['gain_count']}\")\nprint(f\"Default gains: {classical_info['default_gains']}\")\nprint(f\"Required params: {classical_info['required_params']}\")\n\n# Check if controller supports dynamics model\nif classical_info['supports_dynamics']:\n    print(\"Controller can use dynamics model for feedforward control\")\n\n# Iterate over all registered controllers\nfor controller_type, info in CONTROLLER_REGISTRY.items():\n    if info['class'] is not None:\n        print(f\"{controller_type}: {info['gain_count']} gains\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f8ff4ae"
  },
  {
    "id": "factory_system_api_reference_28_6e462aab",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"Wrapper for SMC controllers to provide PSO-compatible interface.\"\"\"\n\n    def __init__(self, controller, n_gains: int, controller_type: str):\n        self.controller = controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n        self.max_force = getattr(controller, 'max_force', 150.0)\n        self.dynamics_model = getattr(controller, 'dynamics_model', None)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate gain particles for PSO optimization.\"\"\"\n        # Checks gain count, finiteness, positivity, and controller-specific constraints\n        ...\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"PSO-compatible control computation interface.\"\"\"\n        # Simplified interface for PSO fitness evaluation\n        ...",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e462aab"
  },
  {
    "id": "factory_system_api_reference_29_5113d166",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(\n    smc_type: SMCType,\n    gains: Union[list, np.ndarray],\n    plant_config_or_model: Optional[Any] = None,\n    **kwargs: Any\n) -> PSOControllerWrapper:\n    \"\"\"Create SMC controller optimized for PSO usage.\n\n    Args:\n        smc_type: Controller type (SMCType enum)\n        gains: Gain vector from PSO particle\n        plant_config_or_model: Plant configuration (optional)\n        **kwargs: Additional parameters (max_force, dt, etc.)\n\n    Returns:\n        PSOControllerWrapper instance with PSO-compatible interface\n    \"\"\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5113d166"
  },
  {
    "id": "factory_system_api_reference_30_d17342b3",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 30,
    "code": "from src.controllers.factory import SMCType, create_smc_for_pso\n\n# PSO creates controller for each particle\nparticle_gains = [20.5, 14.3, 11.8, 9.2, 38.1, 5.7]\ncontroller_wrapper = create_smc_for_pso(\n    smc_type=SMCType.CLASSICAL,\n    gains=particle_gains,\n    max_force=150.0,\n    dt=0.001\n)\n\n# Wrapper exposes PSO attributes\nprint(f\"Expected gains: {controller_wrapper.n_gains}\")  # 6\nprint(f\"Controller type: {controller_wrapper.controller_type}\")  # 'classical_smc'\n\n# Use in PSO fitness function\nstate = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\ncontrol = controller_wrapper.compute_control(state)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d17342b3"
  },
  {
    "id": "factory_system_api_reference_31_b3af9d87",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_pso_controller_factory(\n    smc_type: SMCType,\n    plant_config: Optional[Any] = None,\n    **kwargs: Any\n) -> Callable:\n    \"\"\"Create a PSO-optimized controller factory function with required attributes.\n\n    Returns:\n        Factory function with attributes:\n        - n_gains: Expected gain count\n        - controller_type: Controller type string\n        - max_force: Maximum control force\n    \"\"\"\n    def controller_factory(gains: Union[list, np.ndarray]) -> Any:\n        return create_smc_for_pso(smc_type, gains, plant_config, **kwargs)\n\n    # Add PSO-required attributes\n    controller_factory.n_gains = get_expected_gain_count(smc_type)\n    controller_factory.controller_type = smc_type.value\n    controller_factory.max_force = kwargs.get('max_force', 150.0)\n\n    return controller_factory",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3af9d87"
  },
  {
    "id": "factory_system_api_reference_32_4a64696a",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 32,
    "code": "from src.controllers.factory import SMCType, create_pso_controller_factory\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\n\n# Create factory for PSO optimization\ncontroller_factory = create_pso_controller_factory(\n    smc_type=SMCType.CLASSICAL,\n    max_force=150.0,\n    dt=0.001\n)\n\n# Factory has PSO-required attributes\nprint(f\"Gain dimension: {controller_factory.n_gains}\")  # 6\n\n# Use with PSO tuner\ntuner = PSOTuner(controller_factory=controller_factory, config=config)\nresult = tuner.optimise()\noptimized_gains = result['best_pos']",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a64696a"
  },
  {
    "id": "factory_system_api_reference_33_d4028078",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 33,
    "code": "def get_expected_gain_count(smc_type: SMCType) -> int:\n    \"\"\"Get expected number of gains for a controller type.\"\"\"\n    expected_counts = {\n        SMCType.CLASSICAL: 6,\n        SMCType.ADAPTIVE: 5,\n        SMCType.SUPER_TWISTING: 6,\n        SMCType.HYBRID: 4,\n    }\n    return expected_counts.get(smc_type, 6)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4028078"
  },
  {
    "id": "factory_system_api_reference_34_cd023a11",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 34,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]:\n    \"\"\"Get PSO gain bounds for a controller type.\n\n    Returns:\n        Tuple of (lower_bounds, upper_bounds) lists\n    \"\"\"\n    bounds_map = {\n        SMCType.CLASSICAL: {\n            'lower': [1.0, 1.0, 1.0, 1.0, 5.0, 0.1],\n            'upper': [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]\n        },\n        SMCType.ADAPTIVE: {\n            'lower': [2.0, 2.0, 1.0, 1.0, 0.5],\n            'upper': [40.0, 40.0, 25.0, 25.0, 10.0]\n        },\n        SMCType.SUPER_TWISTING: {\n            # K1 > K2 constraint: K1 in [2.0, 50.0], K2 in [1.0, 49.0]\n            'lower': [2.0, 1.0, 2.0, 2.0, 0.5, 0.5],\n            'upper': [50.0, 49.0, 30.0, 30.0, 20.0, 20.0]\n        },\n        SMCType.HYBRID: {\n            'lower': [2.0, 2.0, 1.0, 1.0],\n            'upper': [30.0, 30.0, 20.0, 20.0]\n        }\n    }\n    return (bounds_map[smc_type]['lower'], bounds_map[smc_type]['upper'])",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cd023a11"
  },
  {
    "id": "factory_system_api_reference_35_5edb27e9",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 35,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.factory import SMCType, create_pso_controller_factory\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\nimport numpy as np\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Step 1: Create PSO-compatible controller factory\ncontroller_factory = create_pso_controller_factory(\n    smc_type=SMCType.CLASSICAL,\n    max_force=150.0,\n    dt=0.001\n)\n\n# Step 2: Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42\n)\n\n# Step 3: Run PSO optimization\nprint(\"Starting PSO optimization...\")\nresult = tuner.optimise(\n    n_particles_override=30,\n    iters_override=100\n)\n\n# Step 4: Extract optimized gains\noptimized_gains = result['best_pos']\nbest_cost = result['best_cost']\nprint(f\"Optimized gains: {optimized_gains}\")\nprint(f\"Best cost: {best_cost:.6f}\")\n\n# Step 5: Create final controller with optimized gains\nfrom src.controllers.factory import create_controller\noptimized_controller = create_controller(\n    'classical_smc',\n    config,\n    gains=optimized_gains\n)\n\n# Step 6: Validate optimized controller\nvalidation_cost = evaluate_controller(optimized_controller)\nprint(f\"Validation cost: {validation_cost:.6f}\")\n\n# Step 7: Compare with baseline\nbaseline_controller = create_controller('classical_smc', config)\nbaseline_cost = evaluate_controller(baseline_controller)\nimprovement = (baseline_cost - validation_cost) / baseline_cost * 100\nprint(f\"Improvement over baseline: {improvement:.1f}%\")",
    "lines": 55,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5edb27e9"
  },
  {
    "id": "factory_system_api_reference_36_c74f5f38",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 36,
    "code": "# example-metadata:\n# runnable: false\n\nSMC_GAIN_SPECS = {\n    SMCType.CLASSICAL: SMCGainSpec(\n        gain_names=['k1', 'k2', 'lambda1', 'lambda2', 'K', 'kd'],\n        gain_bounds=[(1.0, 30.0), (1.0, 30.0), (1.0, 20.0), (1.0, 20.0), (5.0, 50.0), (0.1, 10.0)],\n        controller_type='classical_smc',\n        n_gains=6\n    ),\n    SMCType.ADAPTIVE: SMCGainSpec(\n        gain_names=['k1', 'k2', 'lambda1', 'lambda2', 'gamma'],\n        gain_bounds=[(2.0, 40.0), (2.0, 40.0), (1.0, 25.0), (1.0, 25.0), (0.5, 10.0)],\n        controller_type='adaptive_smc',\n        n_gains=5\n    ),\n    # ... etc.\n}",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c74f5f38"
  },
  {
    "id": "factory_system_api_reference_37_8ec54825",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 37,
    "code": "from src.controllers.factory import SMCType, SMC_GAIN_SPECS\n\n# Get gain specification\nspec = SMC_GAIN_SPECS[SMCType.CLASSICAL]\nprint(f\"Gain names: {spec.gain_names}\")\nprint(f\"Gain bounds: {spec.gain_bounds}\")\nprint(f\"Dimension: {spec.n_gains}\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ec54825"
  },
  {
    "id": "factory_system_api_reference_38_fb577858",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 38,
    "code": "# example-metadata:\n# runnable: false\n\n# Maps to ClassicalSMC initialization:\ncontroller = ClassicalSMC(\n    gains=[25.0, 18.0, 14.0, 10.0, 42.0, 6.0],\n    max_force=150.0,\n    boundary_layer=0.3,\n    dt=0.001,\n    regularization_alpha=1e-4,  # Default\n    min_regularization=1e-10,    # Default\n    max_condition_number=1e14,   # Default\n    use_adaptive_regularization=True,  # Default\n    dynamics_model=<DIPDynamics instance>  # Auto-created from config.physics\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb577858"
  },
  {
    "id": "factory_system_api_reference_39_27176c55",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 39,
    "code": "# example-metadata:\n# runnable: false\n\n# Maps to SuperTwistingSMC initialization:\ncontroller = SuperTwistingSMC(\n    gains=[30.0, 18.0, 22.0, 14.0, 9.0, 7.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.3,\n    switch_method='tanh',\n    damping_gain=0.0,  # Default\n    power_exponent=0.5,  # Default\n    dynamics_model=<DIPDynamics instance>\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27176c55"
  },
  {
    "id": "factory_system_api_reference_40_d3225f30",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 40,
    "code": "# example-metadata:\n# runnable: false\n\n# Maps to AdaptiveSMC initialization:\ncontroller = AdaptiveSMC(\n    gains=[28.0, 20.0, 16.0, 12.0, 5.0],\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.01,\n    dead_zone=0.05,\n    adapt_rate_limit=10.0,  # Default\n    K_min=0.1,  # Default\n    K_max=100.0,  # Default\n    K_init=10.0,  # Default\n    alpha=0.5,  # Default\n    boundary_layer=0.01,  # Default\n    smooth_switch=True,\n    dynamics_model=<DIPDynamics instance>\n)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3225f30"
  },
  {
    "id": "factory_system_api_reference_41_53f9e4ba",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 41,
    "code": "# Factory auto-creates sub-configs:\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\nfrom src.controllers.smc.algorithms.hybrid.config import HybridMode\n\nclassical_config = ClassicalSMCConfig(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.02\n)\n\nadaptive_config = AdaptiveSMCConfig(\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n    max_force=150.0,\n    dt=0.001\n)\n\n# Maps to ModularHybridSMC initialization:\nfrom src.controllers.smc.algorithms.hybrid.controller import ModularHybridSMC\ncontroller = ModularHybridSMC(\n    HybridAdaptiveSTASMCConfig(\n        hybrid_mode=HybridMode.CLASSICAL_ADAPTIVE,\n        dt=0.001,\n        max_force=150.0,\n        classical_config=classical_config,\n        adaptive_config=adaptive_config,\n        dynamics_model=None  # Hybrid uses sub-controller dynamics\n    )\n)",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53f9e4ba"
  },
  {
    "id": "factory_system_api_reference_42_844a9fe3",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 42,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(gains, controller_info, controller_type):\n    expected_count = controller_info['gain_count']\n    if len(gains) != expected_count:\n        raise ValueError(\n            f\"Controller '{controller_info.get('description', 'unknown')}' \"\n            f\"requires {expected_count} gains, got {len(gains)}\"\n        )\n\n    if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in gains):\n        raise ValueError(\"All gains must be finite numbers\")\n\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive\")\n\n    # Controller-specific validation...",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "844a9fe3"
  },
  {
    "id": "factory_system_api_reference_43_9809db08",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 43,
    "code": "if controller_type == 'sta_smc' and len(gains) >= 2:\n    K1, K2 = gains[0], gains[1]\n    if K1 <= K2:\n        raise ValueError(\"Super-Twisting stability requires K1 > K2 > 0\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9809db08"
  },
  {
    "id": "factory_system_api_reference_44_9579fcd1",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 44,
    "code": "if controller_type == 'adaptive_smc' and len(gains) != 5:\n    raise ValueError(\"Adaptive SMC requires exactly 5 gains: [k1, k2, lam1, lam2, gamma]\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9579fcd1"
  },
  {
    "id": "factory_system_api_reference_45_b4b06e6b",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 45,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_mpc_parameters(config_params, controller_params):\n    all_params = {**config_params, **controller_params}\n\n    # Horizon validation\n    if 'horizon' in all_params:\n        horizon = all_params['horizon']\n        if not isinstance(horizon, int):\n            raise ConfigValueError(\"horizon must be an integer\")\n        if horizon < 1:\n            raise ConfigValueError(\"horizon must be \u2265 1\")\n\n    # Weight parameters must be non-negative\n    weight_params = ['q_x', 'q_theta', 'r_u']\n    for param in weight_params:\n        if param in all_params:\n            value = all_params[param]\n            if not isinstance(value, (int, float)) or value < 0:\n                raise ConfigValueError(f\"{param} must be \u2265 0\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4b06e6b"
  },
  {
    "id": "factory_system_api_reference_46_36b7cb76",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 46,
    "code": "from src.controllers.factory import create_controller\n\n# Valid: 6 positive finite gains\ngains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\ncontroller = create_controller('classical_smc', gains=gains)  # \u2713 Success",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36b7cb76"
  },
  {
    "id": "factory_system_api_reference_47_23a6ca22",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 47,
    "code": "from src.controllers.factory import create_controller\n\n# Invalid: Wrong number of gains\ngains = [20.0, 15.0, 12.0]  # Only 3 gains, need 6\ntry:\n    controller = create_controller('classical_smc', gains=gains)\nexcept ValueError as e:\n    print(e)\n    # Output: \"Controller 'Classical sliding mode controller with boundary layer'\n    #          requires 6 gains, got 3\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23a6ca22"
  },
  {
    "id": "factory_system_api_reference_48_23a7a894",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 48,
    "code": "from src.controllers.factory import create_controller\n\n# Invalid: K1 \u2264 K2 violates super-twisting stability\ngains = [15.0, 20.0, 12.0, 8.0, 6.0, 4.0]  # K1=15 \u2264 K2=20 \u2717\ntry:\n    controller = create_controller('sta_smc', gains=gains)\nexcept ValueError as e:\n    print(e)\n    # Output: \"Super-Twisting stability requires K1 > K2 > 0\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23a7a894"
  },
  {
    "id": "factory_system_api_reference_49_b991beff",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 49,
    "code": "# Factory detects invalid default gains and auto-corrects\ncontroller = create_controller('sta_smc')  # Uses defaults\n\n# If defaults violate K1 > K2, factory automatically uses:\n# [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # K1=25 > K2=15 \u2713",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b991beff"
  },
  {
    "id": "factory_system_api_reference_50_5517f200",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 50,
    "code": "def _canonicalize_controller_type(name: str) -> str:\n    if not isinstance(name, str):\n        raise ValueError(f\"Controller type must be string, got {type(name)}\")\n\n    if not name.strip():\n        raise ValueError(\"Controller type cannot be empty\")\n\n    key = name.strip().lower().replace('-', '_').replace(' ', '_')\n    return CONTROLLER_ALIASES.get(key, key)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5517f200"
  },
  {
    "id": "factory_system_api_reference_51_27764fbf",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 51,
    "code": "try:\n    controller = create_controller(123)  # Wrong type\nexcept ValueError as e:\n    print(e)\n    # Output: \"Controller type must be string, got <class 'int'>\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27764fbf"
  },
  {
    "id": "factory_system_api_reference_52_b32f689e",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 52,
    "code": "# example-metadata:\n# runnable: false\n\ndef _get_controller_info(controller_type: str) -> Dict[str, Any]:\n    if controller_type not in CONTROLLER_REGISTRY:\n        available = list(CONTROLLER_REGISTRY.keys())\n        raise ValueError(\n            f\"Unknown controller type '{controller_type}'. \"\n            f\"Available: {available}\"\n        )\n\n    controller_info = CONTROLLER_REGISTRY[controller_type].copy()\n\n    if controller_info['class'] is None:\n        if controller_type == 'mpc_controller':\n            raise ImportError(\"MPC controller missing optional dependency\")\n        else:\n            raise ImportError(f\"Controller class for {controller_type} is not available\")\n\n    return controller_info",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b32f689e"
  },
  {
    "id": "factory_system_api_reference_53_05caa117",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 53,
    "code": "try:\n    controller = create_controller('nonexistent_controller')\nexcept ValueError as e:\n    print(e)\n    # Output: \"Unknown controller type 'nonexistent_controller'.\n    #          Available: ['adaptive_smc', 'classical_smc', 'hybrid_adaptive_sta_smc',\n    #                      'mpc_controller', 'sta_smc']\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "05caa117"
  },
  {
    "id": "factory_system_api_reference_54_c0c88cd1",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 54,
    "code": "# example-metadata:\n# runnable: false\n\ntry:\n    controller_config = config_class(**config_params)\nexcept Exception as e:\n    # Log failure and use fallback configuration\n    if logger.isEnabledFor(logging.DEBUG):\n        logger.debug(f\"Could not create full config, using minimal config: {e}\")\n\n    # Fallback to minimal configuration with all required defaults\n    fallback_params = {\n        'gains': controller_gains,\n        'max_force': 150.0,\n        'dt': 0.001\n    }\n\n    # Add controller-specific required parameters\n    if controller_type == 'classical_smc':\n        fallback_params['boundary_layer'] = 0.02\n\n    controller_config = config_class(**fallback_params)",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c0c88cd1"
  },
  {
    "id": "factory_system_api_reference_55_ee5825bd",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 55,
    "code": "# example-metadata:\n# runnable: false\n\ntry:\n    _validate_controller_gains(controller_gains, controller_info, controller_type)\nexcept ValueError as e:\n    # For invalid default gains, try to fix them automatically\n    if gains is None:  # Only auto-fix if using default gains\n        if controller_type == 'sta_smc':\n            # Fix K1 > K2 requirement\n            controller_gains = [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]\n        elif controller_type == 'adaptive_smc':\n            # Fix 5-gain requirement\n            controller_gains = [25.0, 18.0, 15.0, 10.0, 4.0]\n        else:\n            raise e  # Cannot auto-fix, re-raise exception\n\n        # Re-validate after fix\n        _validate_controller_gains(controller_gains, controller_info, controller_type)\n    else:\n        raise e  # User-provided gains, do not auto-correct",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee5825bd"
  },
  {
    "id": "factory_system_api_reference_56_e2efccc1",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 56,
    "code": "from src.controllers.factory import create_controller, list_available_controllers\n\ndef create_controller_safely(controller_type, config=None, gains=None):\n    \"\"\"Create controller with comprehensive error handling.\"\"\"\n    try:\n        # Check availability first\n        if controller_type not in list_available_controllers():\n            print(f\"Warning: {controller_type} not available\")\n            return None\n\n        # Attempt creation\n        controller = create_controller(controller_type, config, gains)\n        return controller\n\n    except ValueError as e:\n        print(f\"Validation error: {e}\")\n        return None\n\n    except ImportError as e:\n        print(f\"Dependency error: {e}\")\n        return None\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2efccc1"
  },
  {
    "id": "factory_system_api_reference_57_fd0f3b26",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 57,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType\nimport numpy as np\n\ndef validate_pso_particle(gains, smc_type):\n    \"\"\"Validate PSO particle before fitness evaluation.\"\"\"\n    # Get bounds for controller type\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(smc_type)\n\n    # Check bounds\n    gains = np.array(gains)\n    if np.any(gains < lower_bounds) or np.any(gains > upper_bounds):\n        return False\n\n    # Check controller-specific constraints\n    if smc_type == SMCType.SUPER_TWISTING:\n        if gains[0] <= gains[1]:  # K1 must be > K2\n            return False\n\n    return True",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd0f3b26"
  },
  {
    "id": "factory_system_api_reference_58_032fc69d",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 58,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\ndef validate_configuration_before_creation(config_path):\n    \"\"\"Validate configuration file before controller creation.\"\"\"\n    try:\n        config = load_config(config_path)\n    except Exception as e:\n        print(f\"Failed to load config: {e}\")\n        return False\n\n    # Check required sections exist\n    if not hasattr(config, 'controllers'):\n        print(\"Config missing 'controllers' section\")\n        return False\n\n    # Validate each controller configuration\n    for controller_type in ['classical_smc', 'sta_smc', 'adaptive_smc']:\n        try:\n            controller = create_controller(controller_type, config)\n            print(f\"\u2713 {controller_type} config valid\")\n        except Exception as e:\n            print(f\"\u2717 {controller_type} config invalid: {e}\")\n            return False\n\n    return True",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "032fc69d"
  },
  {
    "id": "factory_system_api_reference_59_9128def7",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 59,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/new_controller.py\n\nimport numpy as np\nfrom typing import Dict, List, Any\nfrom numpy.typing import NDArray\n\nclass NewController:\n    \"\"\"New controller implementation.\"\"\"\n\n    def __init__(self, gains: List[float], max_force: float, dt: float, **kwargs):\n        \"\"\"Initialize new controller.\n\n        Args:\n            gains: Controller gains [g1, g2, g3, ...]\n            max_force: Maximum control force [N]\n            dt: Sampling time [s]\n        \"\"\"\n        self._gains = gains\n        self.max_force = max_force\n        self.dt = dt\n        # Additional initialization...\n\n    def compute_control(\n        self,\n        state: NDArray[np.float64],\n        last_control: float,\n        history: Dict[str, Any]\n    ) -> Any:\n        \"\"\"Compute control output.\"\"\"\n        # Controller logic...\n        u = 0.0  # Compute control\n\n        # Saturation\n        u = np.clip(u, -self.max_force, self.max_force)\n\n        # Return control output (can be dict, float, or structured result)\n        return {'u': u, 'status': 'ok'}\n\n    def reset(self) -> None:\n        \"\"\"Reset controller state.\"\"\"\n        # Reset internal state...\n        pass\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        return self._gains.copy()",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9128def7"
  },
  {
    "id": "factory_system_api_reference_60_e0b008b7",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 60,
    "code": "# example-metadata:\n# runnable: false\n\n# src/controllers/new_controller_config.py\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass NewControllerConfig:\n    \"\"\"Configuration for NewController.\"\"\"\n\n    gains: List[float]\n    max_force: float\n    dt: float\n    # Additional parameters...\n\n    def __post_init__(self):\n        \"\"\"Validate configuration.\"\"\"\n        if len(self.gains) != 4:  # Example: requires 4 gains\n            raise ValueError(\"NewController requires 4 gains\")\n        if self.max_force <= 0:\n            raise ValueError(\"max_force must be positive\")\n        if self.dt <= 0:\n            raise ValueError(\"dt must be positive\")",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0b008b7"
  },
  {
    "id": "factory_system_api_reference_61_f8f6fd88",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 61,
    "code": "# Import new controller\nfrom src.controllers.new_controller import NewController\nfrom src.controllers.new_controller_config import NewControllerConfig\n\n# Add to registry\nCONTROLLER_REGISTRY['new_controller'] = {\n    'class': NewController,\n    'config_class': NewControllerConfig,\n    'default_gains': [10.0, 8.0, 5.0, 3.0],  # Reasonable defaults\n    'gain_count': 4,\n    'description': 'New advanced controller',\n    'supports_dynamics': True,  # Whether it uses dynamics_model\n    'required_params': ['gains', 'max_force', 'dt']\n}",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8f6fd88"
  },
  {
    "id": "factory_system_api_reference_62_fdffb3ac",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 62,
    "code": "# Add aliases for convenience\nCONTROLLER_ALIASES.update({\n    'new': 'new_controller',\n    'new_ctrl': 'new_controller',\n})",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fdffb3ac"
  },
  {
    "id": "factory_system_api_reference_63_45c881f8",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 63,
    "code": "# example-metadata:\n# runnable: false\n\n# Add to SMCType enum\nclass SMCType(Enum):\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"\n    NEW_CONTROLLER = \"new_controller\"  # Add new type\n\n# Add to gain count mapping\ndef get_expected_gain_count(smc_type: SMCType) -> int:\n    expected_counts = {\n        SMCType.CLASSICAL: 6,\n        SMCType.ADAPTIVE: 5,\n        SMCType.SUPER_TWISTING: 6,\n        SMCType.HYBRID: 4,\n        SMCType.NEW_CONTROLLER: 4,  # Add expected count\n    }\n    return expected_counts.get(smc_type, 6)\n\n# Add PSO bounds\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]:\n    bounds_map = {\n        # ... existing bounds ...\n        SMCType.NEW_CONTROLLER: {\n            'lower': [1.0, 1.0, 0.5, 0.5],\n            'upper': [30.0, 30.0, 20.0, 20.0]\n        }\n    }\n    return (bounds_map[smc_type]['lower'], bounds_map[smc_type]['upper'])",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45c881f8"
  },
  {
    "id": "factory_system_api_reference_64_04c12208",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 64,
    "code": "# test_new_controller.py\n\nfrom src.controllers.factory import create_controller, get_default_gains\nimport numpy as np\n\ndef test_new_controller_creation():\n    \"\"\"Test new controller can be created.\"\"\"\n    # Test with defaults\n    controller = create_controller('new_controller')\n    assert controller is not None\n    assert controller.gains == [10.0, 8.0, 5.0, 3.0]\n\n    # Test with custom gains\n    custom_gains = [15.0, 12.0, 8.0, 5.0]\n    controller = create_controller('new_controller', gains=custom_gains)\n    assert controller.gains == custom_gains\n\n    # Test compute_control\n    state = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n    result = controller.compute_control(state, 0.0, {})\n    assert 'u' in result\n    assert np.isfinite(result['u'])\n\nif __name__ == '__main__':\n    test_new_controller_creation()\n    print(\"\u2713 New controller tests passed\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04c12208"
  },
  {
    "id": "factory_system_api_reference_65_bfefa039",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 65,
    "code": "\"\"\"\nExample 1: Basic Factory Usage\nDemonstrates the simplest controller creation patterns.\n\"\"\"\n\nfrom src.controllers.factory import create_controller, list_available_controllers, get_default_gains\nfrom src.config import load_config\nimport numpy as np\n\ndef main():\n    # Query available controllers\n    print(\"Available controllers:\")\n    for controller_type in list_available_controllers():\n        defaults = get_default_gains(controller_type)\n        print(f\"  - {controller_type}: {len(defaults)} gains\")\n\n    # Load configuration\n    config = load_config(\"config.yaml\")\n\n    # Create controller with config defaults\n    controller = create_controller('classical_smc', config)\n    print(f\"\\nCreated classical_smc with gains: {controller.gains}\")\n\n    # Use controller in simulation\n    state = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n    result = controller.compute_control(state, 0.0, {})\n\n    if hasattr(result, 'u'):\n        control = result.u\n    elif isinstance(result, dict):\n        control = result['u']\n    else:\n        control = result\n\n    print(f\"Control output: {control:.3f} N\")\n\nif __name__ == '__main__':\n    main()",
    "lines": 38,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfefa039"
  },
  {
    "id": "factory_system_api_reference_66_5d318ea8",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 66,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nExample 2: PSO-Optimized Controller Creation\nDemonstrates complete PSO workflow for gain optimization.\n\"\"\"\n\nfrom src.controllers.factory import SMCType, create_pso_controller_factory, create_controller\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\nimport numpy as np\n\ndef evaluate_controller(controller, test_states):\n    \"\"\"Evaluate controller performance on test trajectories.\"\"\"\n    total_cost = 0.0\n    for state in test_states:\n        result = controller.compute_control(state, 0.0, {})\n        if hasattr(result, 'u'):\n            u = result.u\n        else:\n            u = result['u'] if isinstance(result, dict) else result\n\n        # Compute cost: state regulation + control effort\n        cost = np.sum(state[:3]**2) + 0.1 * u**2\n        total_cost += cost\n\n    return total_cost / len(test_states)\n\ndef main():\n    # Load configuration\n    config = load_config(\"config.yaml\")\n\n    # Step 1: Create PSO-compatible controller factory\n    print(\"Creating PSO controller factory...\")\n    controller_factory = create_pso_controller_factory(\n        smc_type=SMCType.CLASSICAL,\n        max_force=150.0,\n        dt=0.001\n    )\n    print(f\"Factory configured for {controller_factory.n_gains} gains\")\n\n    # Step 2: Initialize PSO tuner\n    print(\"\\nInitializing PSO tuner...\")\n    tuner = PSOTuner(\n        controller_factory=controller_factory,\n        config=config,\n        seed=42\n    )\n\n    # Step 3: Run PSO optimization\n    print(\"Running PSO optimization (30 particles, 100 iterations)...\")\n    result = tuner.optimise(\n        n_particles_override=30,\n        iters_override=100\n    )\n\n    # Step 4: Extract results\n    optimized_gains = result['best_pos']\n    best_cost = result['best_cost']\n    print(f\"\\nOptimization complete!\")\n    print(f\"  Best cost: {best_cost:.6f}\")\n    print(f\"  Optimized gains: {[f'{g:.2f}' for g in optimized_gains]}\")\n\n    # Step 5: Create final controller\n    print(\"\\nCreating optimized controller...\")\n    optimized_controller = create_controller('classical_smc', config, gains=optimized_gains)\n\n    # Step 6: Compare with baseline\n    print(\"\\nComparing with baseline...\")\n    baseline_controller = create_controller('classical_smc', config)\n\n    # Generate test states\n    np.random.seed(42)\n    test_states = [\n        np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0]),\n        np.array([0.0, 0.2, 0.1, 0.0, 0.5, 0.3]),\n        np.array([0.0, -0.1, -0.05, 0.0, -0.3, -0.2])\n    ]\n\n    baseline_cost = evaluate_controller(baseline_controller, test_states)\n    optimized_cost = evaluate_controller(optimized_controller, test_states)\n\n    improvement = (baseline_cost - optimized_cost) / baseline_cost * 100\n    print(f\"  Baseline cost: {baseline_cost:.3f}\")\n    print(f\"  Optimized cost: {optimized_cost:.3f}\")\n    print(f\"  Improvement: {improvement:.1f}%\")\n\nif __name__ == '__main__':\n    main()",
    "lines": 90,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d318ea8"
  },
  {
    "id": "factory_system_api_reference_67_1fcbde7c",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 67,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nExample 3: Batch Controller Comparison\nDemonstrates creating multiple controller types for benchmarking.\n\"\"\"\n\nfrom src.controllers.factory import create_controller, list_available_controllers\nfrom src.config import load_config\nimport numpy as np\nimport pandas as pd\n\ndef simulate_trajectory(controller, initial_state, duration=2.0, dt=0.01):\n    \"\"\"Simulate closed-loop trajectory.\"\"\"\n    steps = int(duration / dt)\n    state = initial_state.copy()\n\n    trajectory = []\n    controls = []\n\n    for _ in range(steps):\n        # Compute control\n        result = controller.compute_control(state, 0.0, {})\n        if hasattr(result, 'u'):\n            u = result.u\n        else:\n            u = result['u'] if isinstance(result, dict) else result\n\n        # Simple dynamics (placeholder - use actual dynamics in practice)\n        state_dot = np.random.randn(6) * 0.1  # Dummy dynamics\n        state = state + state_dot * dt\n\n        trajectory.append(state.copy())\n        controls.append(u)\n\n    return np.array(trajectory), np.array(controls)\n\ndef compute_performance_metrics(trajectory, controls):\n    \"\"\"Compute performance metrics.\"\"\"\n    # ISE: Integral of squared error\n    ise = np.sum(trajectory[:, :3]**2)\n\n    # Control effort\n    effort = np.sum(controls**2)\n\n    # Settling time (simplified)\n    threshold = 0.02\n    settled = np.all(np.abs(trajectory[:, :3]) < threshold, axis=1)\n    settling_time = np.argmax(settled) * 0.01 if np.any(settled) else float('inf')\n\n    return {\n        'ise': ise,\n        'effort': effort,\n        'settling_time': settling_time\n    }\n\ndef main():\n    # Load configuration\n    config = load_config(\"config.yaml\")\n\n    # Initial condition\n    initial_state = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n\n    # Create all available controllers\n    print(\"Creating controllers...\")\n    results = []\n\n    for controller_type in list_available_controllers():\n        try:\n            print(f\"  Creating {controller_type}...\")\n            controller = create_controller(controller_type, config)\n\n            # Simulate\n            print(f\"  Simulating {controller_type}...\")\n            trajectory, controls = simulate_trajectory(controller, initial_state)\n\n            # Compute metrics\n            metrics = compute_performance_metrics(trajectory, controls)\n\n            results.append({\n                'controller': controller_type,\n                'ise': metrics['ise'],\n                'effort': metrics['effort'],\n                'settling_time': metrics['settling_time'],\n                'n_gains': len(controller.gains) if hasattr(controller, 'gains') else 0\n            })\n\n            print(f\"  \u2713 {controller_type}: ISE={metrics['ise']:.3f}\")\n\n        except Exception as e:\n            print(f\"  \u2717 Failed to benchmark {controller_type}: {e}\")\n\n    # Display results\n    print(\"\\n\" + \"=\"*80)\n    print(\"BENCHMARK RESULTS\")\n    print(\"=\"*80)\n\n    df = pd.DataFrame(results)\n    df_sorted = df.sort_values('ise')\n\n    print(df_sorted.to_string(index=False))\n\n    # Identify best controller\n    best = df_sorted.iloc[0]\n    print(f\"\\n\ud83c\udfc6 Best Controller: {best['controller']}\")\n    print(f\"   ISE: {best['ise']:.3f}\")\n    print(f\"   Control Effort: {best['effort']:.3f}\")\n    print(f\"   Settling Time: {best['settling_time']:.3f} s\")\n\nif __name__ == '__main__':\n    main()",
    "lines": 112,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1fcbde7c"
  },
  {
    "id": "factory_system_api_reference_68_c03dd3d7",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 68,
    "code": "\"\"\"\nExample 4: Custom Configuration Override\nDemonstrates programmatic configuration overrides.\n\"\"\"\n\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\nimport numpy as np\n\nclass CustomConfig:\n    \"\"\"Custom configuration object.\"\"\"\n    def __init__(self):\n        self.controllers = {\n            'classical_smc': {\n                'gains': [30.0, 20.0, 15.0, 12.0, 45.0, 7.0],\n                'max_force': 200.0,\n                'boundary_layer': 0.5,\n                'dt': 0.001\n            },\n            'sta_smc': {\n                'gains': [35.0, 20.0, 25.0, 15.0, 10.0, 8.0],\n                'max_force': 200.0,\n                'dt': 0.001\n            }\n        }\n\ndef main():\n    print(\"Demonstrating custom configuration overrides\\n\")\n\n    # Method 1: Load base config and override gains\n    print(\"Method 1: Override gains only\")\n    config = load_config(\"config.yaml\")\n    custom_gains = [35.0, 25.0, 18.0, 14.0, 50.0, 8.0]\n    controller1 = create_controller('classical_smc', config, gains=custom_gains)\n    print(f\"  Gains: {controller1.gains}\")\n    print(f\"  Max force: {controller1.max_force:.1f} N\\n\")\n\n    # Method 2: Use custom configuration object\n    print(\"Method 2: Custom configuration object\")\n    custom_config = CustomConfig()\n    controller2 = create_controller('classical_smc', custom_config)\n    print(f\"  Gains: {controller2.gains}\")\n    print(f\"  Max force: {controller2.max_force:.1f} N\\n\")\n\n    # Method 3: Override both config and gains\n    print(\"Method 3: Override config and gains\")\n    override_gains = [40.0, 28.0, 20.0, 16.0, 55.0, 9.0]\n    controller3 = create_controller('classical_smc', custom_config, gains=override_gains)\n    print(f\"  Gains: {controller3.gains}\")  # Uses override_gains\n    print(f\"  Max force: {controller3.max_force:.1f} N\")  # From custom_config\n\n    # Verify different configurations produce different controllers\n    print(\"\\nVerifying configuration differences:\")\n    state = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n\n    u1 = controller1.compute_control(state, 0.0, {})\n    u2 = controller2.compute_control(state, 0.0, {})\n    u3 = controller3.compute_control(state, 0.0, {})\n\n    # Extract control values\n    def get_control(result):\n        if hasattr(result, 'u'):\n            return result.u\n        elif isinstance(result, dict):\n            return result['u']\n        else:\n            return result\n\n    print(f\"  Controller 1: u = {get_control(u1):.3f} N\")\n    print(f\"  Controller 2: u = {get_control(u2):.3f} N\")\n    print(f\"  Controller 3: u = {get_control(u3):.3f} N\")\n\nif __name__ == '__main__':\n    main()",
    "lines": 74,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c03dd3d7"
  },
  {
    "id": "factory_system_api_reference_69_8d7c441d",
    "file": "docs\\api\\factory_system_api_reference.md",
    "index": 69,
    "code": "\"\"\"\nExample 5: Error Handling and Validation\nDemonstrates robust error handling patterns.\n\"\"\"\n\nfrom src.controllers.factory import (\n    create_controller,\n    list_available_controllers,\n    get_default_gains,\n    FactoryConfigurationError\n)\nfrom src.config import load_config\nimport numpy as np\n\ndef safe_controller_creation(controller_type, config=None, gains=None):\n    \"\"\"Create controller with comprehensive error handling.\"\"\"\n    try:\n        # Pre-flight checks\n        if controller_type not in list_available_controllers():\n            print(f\"\u26a0 Warning: {controller_type} not available\")\n            return None, \"Controller type unavailable\"\n\n        # Attempt creation\n        controller = create_controller(controller_type, config, gains)\n        return controller, None\n\n    except ValueError as e:\n        return None, f\"Validation error: {e}\"\n\n    except ImportError as e:\n        return None, f\"Dependency error: {e}\"\n\n    except FactoryConfigurationError as e:\n        return None, f\"Configuration error: {e}\"\n\n    except Exception as e:\n        return None, f\"Unexpected error: {e}\"\n\ndef main():\n    config = load_config(\"config.yaml\")\n\n    print(\"Demonstrating error handling patterns\\n\")\n    print(\"=\"*80)\n\n    # Test 1: Valid creation\n    print(\"\\nTest 1: Valid controller creation\")\n    controller, error = safe_controller_creation('classical_smc', config)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Failed: {error}\")\n\n    # Test 2: Invalid controller type\n    print(\"\\nTest 2: Invalid controller type\")\n    controller, error = safe_controller_creation('nonexistent_controller', config)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Expected failure: {error}\")\n\n    # Test 3: Invalid gain count\n    print(\"\\nTest 3: Invalid gain count\")\n    invalid_gains = [10.0, 20.0]  # Only 2 gains, need 6\n    controller, error = safe_controller_creation('classical_smc', config, invalid_gains)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Expected failure: {error}\")\n\n    # Test 4: Invalid gain values (non-positive)\n    print(\"\\nTest 4: Invalid gain values (non-positive)\")\n    invalid_gains = [10.0, -5.0, 12.0, 8.0, 35.0, 5.0]  # Negative gain\n    controller, error = safe_controller_creation('classical_smc', config, invalid_gains)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Expected failure: {error}\")\n\n    # Test 5: Super-twisting constraint violation\n    print(\"\\nTest 5: Super-twisting K1 > K2 constraint\")\n    invalid_sta_gains = [15.0, 20.0, 12.0, 8.0, 6.0, 4.0]  # K1=15 \u2264 K2=20\n    controller, error = safe_controller_creation('sta_smc', config, invalid_sta_gains)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Expected failure: {error}\")\n\n    # Test 6: Valid super-twisting gains\n    print(\"\\nTest 6: Valid super-twisting gains\")\n    valid_sta_gains = [30.0, 18.0, 22.0, 14.0, 9.0, 7.0]  # K1=30 > K2=18 \u2713\n    controller, error = safe_controller_creation('sta_smc', config, valid_sta_gains)\n    if controller:\n        print(\"  \u2713 Success: Controller created with K1 > K2\")\n    else:\n        print(f\"  \u2717 Failed: {error}\")\n\n    # Test 7: Adaptive SMC gain count validation\n    print(\"\\nTest 7: Adaptive SMC gain count (must be exactly 5)\")\n    invalid_adaptive_gains = [10.0, 8.0, 5.0, 4.0, 1.0, 0.5]  # 6 gains, need 5\n    controller, error = safe_controller_creation('adaptive_smc', config, invalid_adaptive_gains)\n    if controller:\n        print(\"  \u2713 Success: Controller created\")\n    else:\n        print(f\"  \u2717 Expected failure: {error}\")\n\n    # Test 8: Recovery with default gains\n    print(\"\\nTest 8: Recovery with default gains\")\n    default_gains = get_default_gains('classical_smc')\n    controller, error = safe_controller_creation('classical_smc', config, default_gains)\n    if controller:\n        print(f\"  \u2713 Success: Controller created with defaults {default_gains}\")\n    else:\n        print(f\"  \u2717 Failed: {error}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"Error handling demonstration complete\")\n\nif __name__ == '__main__':\n    main()",
    "lines": 119,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d7c441d"
  },
  {
    "id": "optimization_module_api_reference_1_444b618e",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 1,
    "code": "class PSOTuner:\n    \"\"\"High-throughput, vectorised tuner for sliding-mode controllers.\n\n    The tuner wraps a particle swarm optimisation algorithm around the\n    vectorised simulation. It uses local PRNGs to avoid global side effects\n    and computes instability penalties based on normalisation constants. Cost\n    aggregation between mean and worst-case performance is controlled via\n    COMBINE_WEIGHTS.\n    \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "444b618e"
  },
  {
    "id": "optimization_module_api_reference_2_6192d244",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 2,
    "code": "def __init__(\n    self,\n    controller_factory: Callable[[np.ndarray], Any],\n    config: Union[ConfigSchema, str, Path],\n    seed: Optional[int] = None,\n    rng: Optional[np.random.Generator] = None,\n    *,\n    instability_penalty_factor: float = 100.0,\n) -> None:",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6192d244"
  },
  {
    "id": "optimization_module_api_reference_3_86acf37b",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 3,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\nfrom functools import partial\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Create controller factory (partial application)\ncontroller_factory = partial(\n    create_controller,\n    controller_type='classical_smc',\n    config=config\n)\n\n# Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42,\n    instability_penalty_factor=100.0\n)\n\n# Run optimization\nresult = tuner.optimise()\n\nprint(f\"Best gains: {result['best_pos']}\")\nprint(f\"Best cost: {result['best_cost']:.4f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "86acf37b"
  },
  {
    "id": "optimization_module_api_reference_4_21cb3c19",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 4,
    "code": "def optimise(\n    self,\n    *args: Any,\n    iters_override: Optional[int] = None,\n    n_particles_override: Optional[int] = None,\n    options_override: Optional[Dict[str, float]] = None,\n    **kwargs: Any,\n) -> Dict[str, Any]:",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21cb3c19"
  },
  {
    "id": "optimization_module_api_reference_5_a61ff597",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 5,
    "code": "{\n    'best_cost': float,              # Final best fitness value\n    'best_pos': np.ndarray,          # Best gain vector (1D array)\n    'cost_history': np.ndarray,      # Best cost per iteration (1D array)\n    'pos_history': np.ndarray,       # Best position per iteration (2D array: iters \u00d7 dims)\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a61ff597"
  },
  {
    "id": "optimization_module_api_reference_6_ed59e0ef",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 6,
    "code": "# Run optimization with default settings\nresult = tuner.optimise()\n\n# Extract optimized gains\noptimized_gains = result['best_pos']\nfinal_cost = result['best_cost']\nconvergence_history = result['cost_history']\n\n# Plot convergence\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.plot(convergence_history)\nplt.xlabel('Iteration')\nplt.ylabel('Best Cost')\nplt.title('PSO Convergence History')\nplt.yscale('log')\nplt.grid(True)\nplt.savefig('pso_convergence.png')",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed59e0ef"
  },
  {
    "id": "optimization_module_api_reference_7_9da14f94",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 7,
    "code": "# Run with custom PSO parameters\nresult = tuner.optimise(\n    iters_override=200,                    # More iterations\n    n_particles_override=50,               # Larger swarm\n    options_override={'w': 0.5, 'c1': 2.0, 'c2': 2.0}  # Different hyperparameters\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9da14f94"
  },
  {
    "id": "optimization_module_api_reference_8_00e9d15c",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 8,
    "code": "def _fitness(self, particles: np.ndarray) -> np.ndarray:\n    \"\"\"Vectorised fitness function for a swarm of particles.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "00e9d15c"
  },
  {
    "id": "optimization_module_api_reference_9_be72abdd",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef custom_fitness(particles: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Custom fitness function for specific control objectives.\n\n    Parameters\n    ----------\n    particles : np.ndarray\n        Gain vectors (shape: B \u00d7 D)\n\n    Returns\n    -------\n    np.ndarray\n        Fitness values (shape: B,)\n    \"\"\"\n    B = particles.shape[0]\n    fitness = np.zeros(B)\n\n    for i, gains in enumerate(particles):\n        # Create controller\n        controller = create_controller('classical_smc', config=config, gains=gains)\n\n        # Simulate\n        result = simulate(controller, duration=5.0, dt=0.01)\n\n        # Custom cost: settle time + overshoot\n        settle_time = compute_settle_time(result.states, threshold=0.02)\n        overshoot = compute_overshoot(result.states)\n\n        fitness[i] = 10.0 * settle_time + 50.0 * overshoot\n\n    return fitness",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be72abdd"
  },
  {
    "id": "optimization_module_api_reference_10_0427c5ae",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 10,
    "code": "def _normalise(self, val: np.ndarray, denom: float) -> np.ndarray:\n    \"\"\"Safely normalise an array by a scalar denominator using the instance's threshold.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0427c5ae"
  },
  {
    "id": "optimization_module_api_reference_11_88ba9ea0",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 11,
    "code": "class EnhancedConvergenceAnalyzer:\n    \"\"\"\n    Advanced PSO convergence analysis with multi-criteria validation.\n\n    Provides comprehensive convergence monitoring, statistical validation,\n    and performance prediction for PSO optimization in controller factory\n    integration scenarios.\n    \"\"\"",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "88ba9ea0"
  },
  {
    "id": "optimization_module_api_reference_12_250f77b6",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass ConvergenceMetrics:\n    \"\"\"Comprehensive convergence metrics.\"\"\"\n    iteration: int                          # Current iteration number\n    best_fitness: float                     # Current best fitness value\n    mean_fitness: float                     # Mean fitness across swarm\n    fitness_std: float                      # Fitness standard deviation\n    population_diversity: float             # Swarm diversity measure\n    convergence_velocity: float             # Rate of convergence\n    improvement_rate: float                 # Relative improvement rate\n    stagnation_score: float                 # Stagnation indicator [0, 1]\n    diversity_loss_rate: float              # Rate of diversity decrease\n    predicted_iterations_remaining: int     # Estimated iterations to convergence\n    confidence_level: float                 # Statistical confidence [0, 1]\n    convergence_probability: float          # Probability of convergence [0, 1]",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "250f77b6"
  },
  {
    "id": "optimization_module_api_reference_13_8b8f4b98",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass ConvergenceCriteria:\n    \"\"\"Adaptive convergence criteria configuration.\"\"\"\n\n    # Fitness-based criteria\n    fitness_tolerance: float = 1e-6\n    relative_improvement_threshold: float = 1e-4\n\n    # Diversity-based criteria\n    min_diversity_threshold: float = 1e-3\n    diversity_loss_rate_threshold: float = 0.95\n\n    # Stagnation detection\n    stagnation_window: int = 10\n    stagnation_threshold: float = 1e-5\n\n    # Statistical criteria\n    statistical_confidence_level: float = 0.95\n    min_sample_size: int = 20\n\n    # Adaptive parameters\n    enable_adaptive_criteria: bool = True\n    controller_specific_adjustment: bool = True\n\n    # Performance prediction\n    enable_performance_prediction: bool = True\n    prediction_window: int = 15\n\n    # Early stopping\n    max_stagnation_iterations: int = 50\n    premature_convergence_detection: bool = True",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b8f4b98"
  },
  {
    "id": "optimization_module_api_reference_14_1223cd70",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_convergence(\n    self,\n    iteration: int,\n    best_fitness: float,\n    mean_fitness: float,\n    fitness_std: float,\n    swarm_positions: np.ndarray\n) -> Tuple[ConvergenceStatus, ConvergenceMetrics]:\n    \"\"\"\n    Analyze current optimization state and determine convergence status.\n\n    Returns\n    -------\n    status : ConvergenceStatus\n        Current convergence status (EXPLORING, CONVERGING, CONVERGED, etc.)\n    metrics : ConvergenceMetrics\n        Comprehensive metrics for current iteration\n    \"\"\"",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1223cd70"
  },
  {
    "id": "optimization_module_api_reference_15_14c2885d",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.optimization.validation.enhanced_convergence_analyzer import (\n    EnhancedConvergenceAnalyzer,\n    ConvergenceCriteria,\n    ConvergenceStatus\n)\n\n# Initialize analyzer\ncriteria = ConvergenceCriteria(\n    fitness_tolerance=1e-6,\n    max_stagnation_iterations=50,\n    enable_performance_prediction=True\n)\nanalyzer = EnhancedConvergenceAnalyzer(\n    criteria=criteria,\n    controller_type=SMCType.CLASSICAL\n)\n\n# PSO optimization loop (pseudo-code)\nfor iteration in range(max_iterations):\n    # ... PSO updates ...\n\n    # Check convergence\n    status, metrics = analyzer.check_convergence(\n        iteration=iteration,\n        best_fitness=current_best_fitness,\n        mean_fitness=swarm_mean_fitness,\n        fitness_std=swarm_fitness_std,\n        swarm_positions=particle_positions\n    )\n\n    # Log metrics\n    print(f\"Iteration {iteration}:\")\n    print(f\"  Status: {status.value}\")\n    print(f\"  Best Fitness: {metrics.best_fitness:.6f}\")\n    print(f\"  Convergence Velocity: {metrics.convergence_velocity:.6e}\")\n    print(f\"  Diversity: {metrics.population_diversity:.6f}\")\n    print(f\"  Predicted Iterations Remaining: {metrics.predicted_iterations_remaining}\")\n\n    # Early stopping\n    if status == ConvergenceStatus.CONVERGED:\n        print(f\"Convergence detected at iteration {iteration}\")\n        break\n    elif status == ConvergenceStatus.STAGNATED:\n        print(f\"Stagnation detected at iteration {iteration}\")\n        break",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "14c2885d"
  },
  {
    "id": "optimization_module_api_reference_16_74e33579",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 16,
    "code": "class PSOBoundsValidator:\n    \"\"\"\n    Advanced PSO bounds validator for control system optimization.\n\n    This class provides comprehensive validation and optimization of PSO parameter\n    bounds to ensure effective controller tuning.\n    \"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "74e33579"
  },
  {
    "id": "optimization_module_api_reference_17_687fc3fe",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 17,
    "code": "def __init__(self, config: ConfigSchema):\n    \"\"\"\n    Initialize bounds validator with configuration.\n\n    Parameters\n    ----------\n    config : ConfigSchema\n        System configuration with controller and PSO parameters\n    \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "687fc3fe"
  },
  {
    "id": "optimization_module_api_reference_18_752e09b7",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_bounds(\n    self,\n    controller_type: str,\n    lower_bounds: List[float],\n    upper_bounds: List[float]\n) -> BoundsValidationResult:\n    \"\"\"\n    Validate PSO parameter bounds for specific controller type.\n\n    Parameters\n    ----------\n    controller_type : str\n        Controller type ('classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc')\n    lower_bounds : List[float]\n        Lower bounds for each parameter\n    upper_bounds : List[float]\n        Upper bounds for each parameter\n\n    Returns\n    -------\n    BoundsValidationResult\n        Validation result with warnings, recommendations, and adjusted bounds\n    \"\"\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "752e09b7"
  },
  {
    "id": "optimization_module_api_reference_19_f9987bb5",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 19,
    "code": "from src.optimization.validation.pso_bounds_validator import PSOBoundsValidator\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\nvalidator = PSOBoundsValidator(config)\n\n# Validate bounds for Classical SMC\nresult = validator.validate_bounds(\n    controller_type='classical_smc',\n    lower_bounds=[1.0, 1.0, 0.5, 0.5, 1.0, 0.1],\n    upper_bounds=[100.0, 100.0, 50.0, 50.0, 200.0, 20.0]\n)\n\nif result.is_valid:\n    print(\"Bounds are valid!\")\nelse:\n    print(\"Validation warnings:\")\n    for warning in result.warnings:\n        print(f\"  - {warning}\")\n\n    print(\"\\nRecommendations:\")\n    for rec in result.recommendations:\n        print(f\"  - {rec}\")\n\n    if result.adjusted_bounds:\n        print(\"\\nAdjusted bounds:\")\n        print(f\"  Lower: {result.adjusted_bounds['lower']}\")\n        print(f\"  Upper: {result.adjusted_bounds['upper']}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9987bb5"
  },
  {
    "id": "optimization_module_api_reference_20_6b78f45c",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 20,
    "code": "class PSOBoundsOptimizer:\n    \"\"\"\n    Optimize PSO parameter bounds for improved convergence and performance.\n\n    Implements multi-strategy bounds optimization combining physics-based\n    constraints, empirical performance data, and PSO convergence properties.\n    \"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b78f45c"
  },
  {
    "id": "optimization_module_api_reference_21_ee7b9580",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 21,
    "code": "class BoundsOptimizationStrategy(Enum):\n    \"\"\"Bounds optimization strategies.\"\"\"\n    PHYSICS_BASED = \"physics_based\"              # Stability-constrained bounds\n    PERFORMANCE_DRIVEN = \"performance_driven\"    # Empirically validated bounds\n    CONVERGENCE_FOCUSED = \"convergence_focused\"  # PSO-optimized bounds\n    HYBRID = \"hybrid\"                            # Weighted combination",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee7b9580"
  },
  {
    "id": "optimization_module_api_reference_22_11f830c7",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimize_bounds_for_controller(\n    self,\n    controller_type: SMCType,\n    strategy: BoundsOptimizationStrategy = BoundsOptimizationStrategy.HYBRID,\n    max_optimization_time: float = 300.0,\n    n_trials: int = 10\n) -> BoundsValidationResult:\n    \"\"\"\n    Optimize PSO parameter bounds for specific controller type.\n\n    Algorithm:\n    1. Generate candidate bounds from selected strategy\n    2. Evaluate candidates through PSO trials\n    3. Score candidates using multi-criteria objective\n    4. Select optimal bounds via Pareto dominance\n    5. Validate through comprehensive testing\n\n    Parameters\n    ----------\n    controller_type : SMCType\n        Controller type to optimize bounds for\n    strategy : BoundsOptimizationStrategy, optional\n        Optimization strategy (default: HYBRID)\n    max_optimization_time : float, optional\n        Maximum time in seconds (default: 300)\n    n_trials : int, optional\n        Number of PSO trials per candidate (default: 10)\n\n    Returns\n    -------\n    BoundsValidationResult\n        Optimized bounds with performance metrics\n    \"\"\"",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "11f830c7"
  },
  {
    "id": "optimization_module_api_reference_23_c820284b",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 23,
    "code": "from src.optimization.validation.pso_bounds_optimizer import (\n    PSOBoundsOptimizer,\n    BoundsOptimizationStrategy\n)\nfrom src.controllers.factory import SMCType\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\noptimizer = PSOBoundsOptimizer(config)\n\n# Optimize bounds for Classical SMC\nresult = optimizer.optimize_bounds_for_controller(\n    controller_type=SMCType.CLASSICAL,\n    strategy=BoundsOptimizationStrategy.HYBRID,\n    max_optimization_time=600.0,\n    n_trials=20\n)\n\nprint(f\"Optimized Bounds:\")\nprint(f\"  Lower: {result.adjusted_bounds['lower']}\")\nprint(f\"  Upper: {result.adjusted_bounds['upper']}\")\nprint(f\"\\nPerformance Improvements:\")\nprint(f\"  Convergence: {result.convergence_estimate:.2%}\")\nprint(f\"  Quality: {result.stability_analysis['quality_improvement']:.2%}\")\nprint(f\"  Success Rate: {result.stability_analysis['success_rate']:.2%}\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c820284b"
  },
  {
    "id": "optimization_module_api_reference_24_8c0a404e",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 24,
    "code": "class PSOHyperparameterOptimizer:\n    \"\"\"\n    Meta-optimization of PSO hyperparameters for controller tuning.\n\n    Optimizes PSO algorithm parameters (w, c1, c2, swarm_size) to improve\n    convergence speed and solution quality for specific controller types.\n    \"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8c0a404e"
  },
  {
    "id": "optimization_module_api_reference_25_f31b7fe2",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 25,
    "code": "class OptimizationObjective(Enum):\n    \"\"\"Meta-optimization objectives.\"\"\"\n    CONVERGENCE_SPEED = \"convergence_speed\"     # Minimize iterations to convergence\n    SOLUTION_QUALITY = \"solution_quality\"       # Minimize final cost\n    ROBUSTNESS = \"robustness\"                   # Minimize performance variance\n    EFFICIENCY = \"efficiency\"                   # Balance quality vs. computational cost\n    MULTI_OBJECTIVE = \"multi_objective\"         # Weighted combination",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f31b7fe2"
  },
  {
    "id": "optimization_module_api_reference_26_26fe20d7",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimize_hyperparameters(\n    self,\n    controller_type: SMCType,\n    objective: OptimizationObjective = OptimizationObjective.MULTI_OBJECTIVE,\n    max_evaluations: int = 100,\n    n_trials_per_evaluation: int = 5\n) -> OptimizationResult:\n    \"\"\"\n    Optimize PSO hyperparameters for specific controller type.\n\n    Uses differential evolution to find optimal PSO parameters that\n    minimize the selected objective function.\n\n    Parameters\n    ----------\n    controller_type : SMCType\n        Controller type to optimize hyperparameters for\n    objective : OptimizationObjective, optional\n        Optimization objective (default: MULTI_OBJECTIVE)\n    max_evaluations : int, optional\n        Maximum DE evaluations (default: 100)\n    n_trials_per_evaluation : int, optional\n        PSO trials per hyperparameter configuration (default: 5)\n\n    Returns\n    -------\n    OptimizationResult\n        Optimized hyperparameters with performance metrics\n    \"\"\"",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26fe20d7"
  },
  {
    "id": "optimization_module_api_reference_27_c9c8905a",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 27,
    "code": "from src.optimization.tuning.pso_hyperparameter_optimizer import (\n    PSOHyperparameterOptimizer,\n    OptimizationObjective\n)\nfrom src.controllers.factory import SMCType\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\nmeta_optimizer = PSOHyperparameterOptimizer(config)\n\n# Optimize PSO hyperparameters for Classical SMC\nresult = meta_optimizer.optimize_hyperparameters(\n    controller_type=SMCType.CLASSICAL,\n    objective=OptimizationObjective.MULTI_OBJECTIVE,\n    max_evaluations=100,\n    n_trials_per_evaluation=5\n)\n\nprint(f\"Optimized PSO Hyperparameters:\")\nprint(f\"  Inertia weight (w): {result.hyperparameters.w:.4f}\")\nprint(f\"  Cognitive (c1): {result.hyperparameters.c1:.4f}\")\nprint(f\"  Social (c2): {result.hyperparameters.c2:.4f}\")\nprint(f\"  Swarm size: {result.hyperparameters.n_particles}\")\nprint(f\"\\nPerformance vs. Baseline:\")\nprint(f\"  Convergence speedup: {result.convergence_improvement:.2f}x\")\nprint(f\"  Quality improvement: {result.quality_improvement:.2%}\")\nprint(f\"  Robustness improvement: {result.robustness_improvement:.2%}\")\n\n# Update configuration with optimized hyperparameters\nconfig.pso.w = result.hyperparameters.w\nconfig.pso.c1 = result.hyperparameters.c1\nconfig.pso.c2 = result.hyperparameters.c2\nconfig.pso.n_particles = result.hyperparameters.n_particles",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9c8905a"
  },
  {
    "id": "optimization_module_api_reference_28_9f293772",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 28,
    "code": "class EnhancedPSOFactory:\n    \"\"\"\n    Enhanced PSO-Factory integration with robust error handling.\n\n    Provides seamless integration between controller factory and PSO optimization\n    with enhanced fitness functions and comprehensive error recovery.\n    \"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f293772"
  },
  {
    "id": "optimization_module_api_reference_29_bc087f02",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 29,
    "code": "from src.optimization.integration.pso_factory_bridge import EnhancedPSOFactory\nfrom src.config import load_config\n\n# 1. Load configuration\nconfig = load_config(\"config.yaml\")\n\n# 2. Create enhanced PSO factory\nfactory = EnhancedPSOFactory(\n    controller_type='classical_smc',\n    config=config,\n    enable_convergence_monitoring=True,\n    enable_bounds_validation=True\n)\n\n# 3. Run optimization\nresult = factory.optimize(\n    max_iterations=100,\n    convergence_tolerance=1e-6\n)\n\n# 4. Extract optimized controller\noptimized_controller = factory.create_controller(result['best_pos'])\n\n# 5. Validate performance\nvalidation_result = factory.validate_controller(\n    controller=optimized_controller,\n    n_trials=10\n)\n\nprint(f\"Optimization Summary:\")\nprint(f\"  Best Cost: {result['best_cost']:.6f}\")\nprint(f\"  Convergence Iteration: {result['convergence_iteration']}\")\nprint(f\"  Validation Success Rate: {validation_result['success_rate']:.2%}\")\nprint(f\"  Mean Performance: {validation_result['mean_cost']:.6f} \u00b1 {validation_result['std_cost']:.6f}\")",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc087f02"
  },
  {
    "id": "optimization_module_api_reference_30_59cecb94",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 30,
    "code": "from src.optimization.integration.pso_factory_bridge import EnhancedPSOFactory\nfrom src.controllers.factory import SMCType\nimport pandas as pd\n\n# Optimize all controller types\ncontroller_types = [SMCType.CLASSICAL, SMCType.STA, SMCType.ADAPTIVE, SMCType.HYBRID]\nresults = []\n\nfor ctrl_type in controller_types:\n    factory = EnhancedPSOFactory(\n        controller_type=ctrl_type,\n        config=config\n    )\n\n    result = factory.optimize(max_iterations=100)\n\n    results.append({\n        'controller': ctrl_type.value,\n        'best_cost': result['best_cost'],\n        'convergence_iter': result['convergence_iteration'],\n        'optimization_time': result['optimization_time']\n    })\n\n# Compare results\ndf = pd.DataFrame(results)\ndf = df.sort_values('best_cost')\nprint(\"\\nController Performance Ranking:\")\nprint(df.to_string(index=False))",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59cecb94"
  },
  {
    "id": "optimization_module_api_reference_31_a484af3c",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nExample 1: Basic PSO Optimization for Classical SMC\n\nDemonstrates:\n- Configuration loading\n- Controller factory creation\n- PSO tuner initialization\n- Optimization execution\n- Result visualization\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom functools import partial\n\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nCONFIG_PATH = \"config.yaml\"\nCONTROLLER_TYPE = 'classical_smc'\nSEED = 42\n\n# ============================================================================\n# Main Optimization\n# ============================================================================\n\ndef main():\n    # Load configuration\n    print(\"Loading configuration...\")\n    config = load_config(CONFIG_PATH)\n\n    # Create controller factory (partial application for PSO)\n    print(\"Creating controller factory...\")\n    controller_factory = partial(\n        create_controller,\n        controller_type=CONTROLLER_TYPE,\n        config=config\n    )\n\n    # Initialize PSO tuner\n    print(\"Initializing PSO tuner...\")\n    tuner = PSOTuner(\n        controller_factory=controller_factory,\n        config=config,\n        seed=SEED,\n        instability_penalty_factor=100.0\n    )\n\n    # Run optimization\n    print(f\"Running PSO optimization with {config.pso.n_particles} particles for {config.pso.n_iterations} iterations...\")\n    result = tuner.optimise()\n\n    # Extract results\n    best_gains = result['best_pos']\n    best_cost = result['best_cost']\n    cost_history = result['cost_history']\n\n    print(f\"\\n{'='*80}\")\n    print(\"OPTIMIZATION RESULTS\")\n    print(f\"{'='*80}\")\n    print(f\"Best Cost: {best_cost:.6f}\")\n    print(f\"Best Gains: {best_gains}\")\n    print(f\"Convergence: {len(cost_history)} iterations\")\n    print(f\"{'='*80}\\n\")\n\n    # Plot convergence\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(cost_history, linewidth=2)\n    ax.set_xlabel('Iteration', fontsize=12)\n    ax.set_ylabel('Best Cost', fontsize=12)\n    ax.set_title('PSO Convergence History - Classical SMC', fontsize=14, fontweight='bold')\n    ax.set_yscale('log')\n    ax.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.savefig('pso_convergence_basic.png', dpi=300)\n    print(\"Convergence plot saved: pso_convergence_basic.png\")\n\n    # Save optimized gains\n    np.save('optimized_gains_classical_smc.npy', best_gains)\n    print(\"Optimized gains saved: optimized_gains_classical_smc.npy\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 92,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a484af3c"
  },
  {
    "id": "optimization_module_api_reference_32_8cf9f8b6",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nExample 2: Real-Time Convergence Monitoring\n\nDemonstrates:\n- EnhancedConvergenceAnalyzer integration\n- Multi-criteria convergence detection\n- Real-time metric logging\n- Early stopping based on convergence status\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom functools import partial\n\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.optimization.validation.enhanced_convergence_analyzer import (\n    EnhancedConvergenceAnalyzer,\n    ConvergenceCriteria,\n    ConvergenceStatus\n)\nfrom src.controllers.factory import create_controller, SMCType\nfrom src.config import load_config\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nCONFIG_PATH = \"config.yaml\"\nCONTROLLER_TYPE = 'sta_smc'\nSEED = 42\n\n# ============================================================================\n# Convergence Monitoring Callback\n# ============================================================================\n\nclass ConvergenceMonitor:\n    \"\"\"Callback for real-time convergence monitoring.\"\"\"\n\n    def __init__(self, analyzer: EnhancedConvergenceAnalyzer):\n        self.analyzer = analyzer\n        self.metrics_history = []\n\n    def __call__(self, iteration: int, best_fitness: float, mean_fitness: float,\n                 fitness_std: float, swarm_positions: np.ndarray):\n        \"\"\"Check convergence at each iteration.\"\"\"\n        status, metrics = self.analyzer.check_convergence(\n            iteration=iteration,\n            best_fitness=best_fitness,\n            mean_fitness=mean_fitness,\n            fitness_std=fitness_std,\n            swarm_positions=swarm_positions\n        )\n\n        self.metrics_history.append(metrics)\n\n        # Log key metrics\n        if iteration % 10 == 0:\n            print(f\"Iter {iteration:3d} | Status: {status.value:20s} | \"\n                  f\"Best: {metrics.best_fitness:.6f} | \"\n                  f\"Diversity: {metrics.population_diversity:.4f} | \"\n                  f\"Conv. Velocity: {metrics.convergence_velocity:.4e} | \"\n                  f\"Predicted Remaining: {metrics.predicted_iterations_remaining:3d}\")\n\n        # Early stopping\n        if status == ConvergenceStatus.CONVERGED:\n            print(f\"\\n>>> CONVERGENCE DETECTED at iteration {iteration} <<<\")\n            return True  # Signal early stop\n        elif status == ConvergenceStatus.STAGNATED:\n            print(f\"\\n>>> STAGNATION DETECTED at iteration {iteration} <<<\")\n            return True  # Signal early stop\n\n        return False  # Continue\n\n# ============================================================================\n# Main\n# ============================================================================\n\ndef main():\n    # Load configuration\n    config = load_config(CONFIG_PATH)\n\n    # Initialize convergence analyzer with custom criteria\n    criteria = ConvergenceCriteria(\n        fitness_tolerance=1e-6,\n        relative_improvement_threshold=1e-4,\n        min_diversity_threshold=1e-3,\n        max_stagnation_iterations=50,\n        enable_performance_prediction=True,\n        premature_convergence_detection=True\n    )\n\n    analyzer = EnhancedConvergenceAnalyzer(\n        criteria=criteria,\n        controller_type=SMCType.STA\n    )\n\n    monitor = ConvergenceMonitor(analyzer)\n\n    # Create controller factory\n    controller_factory = partial(\n        create_controller,\n        controller_type=CONTROLLER_TYPE,\n        config=config\n    )\n\n    # Initialize PSO tuner\n    tuner = PSOTuner(\n        controller_factory=controller_factory,\n        config=config,\n        seed=SEED\n    )\n\n    # Run optimization with monitoring\n    print(f\"Running PSO optimization with real-time convergence monitoring...\")\n    print(f\"{'='*120}\")\n    result = tuner.optimise()\n    print(f\"{'='*120}\\n\")\n\n    # Plot convergence metrics\n    metrics = monitor.metrics_history\n    iterations = [m.iteration for m in metrics]\n    best_fitness = [m.best_fitness for m in metrics]\n    diversity = [m.population_diversity for m in metrics]\n    conv_velocity = [m.convergence_velocity for m in metrics]\n\n    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n\n    # Best fitness\n    axes[0].plot(iterations, best_fitness, linewidth=2, color='blue')\n    axes[0].set_ylabel('Best Fitness', fontsize=12)\n    axes[0].set_yscale('log')\n    axes[0].set_title('Convergence Monitoring - STA SMC', fontsize=14, fontweight='bold')\n    axes[0].grid(True, alpha=0.3)\n\n    # Population diversity\n    axes[1].plot(iterations, diversity, linewidth=2, color='green')\n    axes[1].set_ylabel('Population Diversity', fontsize=12)\n    axes[1].grid(True, alpha=0.3)\n\n    # Convergence velocity\n    axes[2].plot(iterations, conv_velocity, linewidth=2, color='red')\n    axes[2].set_ylabel('Convergence Velocity', fontsize=12)\n    axes[2].set_xlabel('Iteration', fontsize=12)\n    axes[2].grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig('pso_convergence_monitoring.png', dpi=300)\n    print(\"Convergence monitoring plot saved: pso_convergence_monitoring.png\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 155,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8cf9f8b6"
  },
  {
    "id": "optimization_module_api_reference_33_a0f0ca52",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nExample 3: Bounds Validation and Automatic Adjustment\n\nDemonstrates:\n- PSOBoundsValidator usage\n- Controller-specific bounds validation\n- Automatic adjustment algorithms\n- Performance comparison with/without adjustment\n\"\"\"\n\nfrom src.optimization.validation.pso_bounds_validator import PSOBoundsValidator\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\nfrom functools import partial\nimport numpy as np\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nCONFIG_PATH = \"config.yaml\"\nCONTROLLER_TYPE = 'adaptive_smc'\n\n# Test bounds (intentionally suboptimal)\nTEST_BOUNDS_LOWER = [0.1, 0.1, 0.1, 0.1, 0.01]  # Too narrow\nTEST_BOUNDS_UPPER = [5.0, 5.0, 5.0, 5.0, 1.0]   # Too narrow\n\n# ============================================================================\n# Main\n# ============================================================================\n\ndef main():\n    # Load configuration\n    config = load_config(CONFIG_PATH)\n\n    # Initialize bounds validator\n    validator = PSOBoundsValidator(config)\n\n    # Validate test bounds\n    print(\"Validating test bounds for Adaptive SMC...\")\n    print(f\"Lower: {TEST_BOUNDS_LOWER}\")\n    print(f\"Upper: {TEST_BOUNDS_UPPER}\")\n    print()\n\n    result = validator.validate_bounds(\n        controller_type=CONTROLLER_TYPE,\n        lower_bounds=TEST_BOUNDS_LOWER,\n        upper_bounds=TEST_BOUNDS_UPPER\n    )\n\n    if result.is_valid:\n        print(\"\u2713 Bounds are valid!\")\n    else:\n        print(\"\u2717 Bounds validation failed!\")\n        print(\"\\nWarnings:\")\n        for warning in result.warnings:\n            print(f\"  - {warning}\")\n\n        print(\"\\nRecommendations:\")\n        for rec in result.recommendations:\n            print(f\"  - {rec}\")\n\n        if result.adjusted_bounds:\n            print(\"\\nAutomatically adjusted bounds:\")\n            adjusted_lower = result.adjusted_bounds['lower']\n            adjusted_upper = result.adjusted_bounds['upper']\n            print(f\"  Lower: {adjusted_lower}\")\n            print(f\"  Upper: {adjusted_upper}\")\n\n            # Compare PSO performance with original vs. adjusted bounds\n            print(\"\\n\" + \"=\"*80)\n            print(\"Performance Comparison: Original vs. Adjusted Bounds\")\n            print(\"=\"*80)\n\n            controller_factory = partial(\n                create_controller,\n                controller_type=CONTROLLER_TYPE,\n                config=config\n            )\n\n            # PSO with original bounds\n            print(\"\\n[1/2] Running PSO with ORIGINAL bounds...\")\n            tuner_original = PSOTuner(\n                controller_factory=controller_factory,\n                config=config,\n                seed=42\n            )\n            # Override bounds\n            config.pso.bounds.min = TEST_BOUNDS_LOWER\n            config.pso.bounds.max = TEST_BOUNDS_UPPER\n            result_original = tuner_original.optimise(iters_override=50)\n\n            # PSO with adjusted bounds\n            print(\"[2/2] Running PSO with ADJUSTED bounds...\")\n            tuner_adjusted = PSOTuner(\n                controller_factory=controller_factory,\n                config=config,\n                seed=42\n            )\n            # Override bounds with adjusted\n            config.pso.bounds.min = adjusted_lower\n            config.pso.bounds.max = adjusted_upper\n            result_adjusted = tuner_adjusted.optimise(iters_override=50)\n\n            # Compare results\n            print(\"\\n\" + \"=\"*80)\n            print(\"Results Comparison\")\n            print(\"=\"*80)\n            print(f\"{'Metric':<30s} | {'Original Bounds':>20s} | {'Adjusted Bounds':>20s} | {'Improvement':>15s}\")\n            print(\"-\"*80)\n\n            cost_original = result_original['best_cost']\n            cost_adjusted = result_adjusted['best_cost']\n            improvement = (cost_original - cost_adjusted) / cost_original * 100\n\n            print(f\"{'Best Cost':<30s} | {cost_original:20.6f} | {cost_adjusted:20.6f} | {improvement:14.2f}%\")\n            print(f\"{'Best Gains':<30s}\")\n            print(f\"  Original: {result_original['best_pos']}\")\n            print(f\"  Adjusted: {result_adjusted['best_pos']}\")\n            print(\"=\"*80)\n\n            if improvement > 0:\n                print(f\"\\n\u2713 Adjusted bounds achieved {improvement:.2f}% cost reduction!\")\n            else:\n                print(f\"\\n\u2717 Adjusted bounds did not improve performance.\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 133,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0f0ca52"
  },
  {
    "id": "optimization_module_api_reference_34_62878424",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 34,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nExample 4: PSO Hyperparameter Optimization\n\nDemonstrates:\n- PSOHyperparameterOptimizer usage\n- Meta-optimization with differential evolution\n- Multi-objective optimization\n- Baseline comparison\n\"\"\"\n\nfrom src.optimization.tuning.pso_hyperparameter_optimizer import (\n    PSOHyperparameterOptimizer,\n    OptimizationObjective\n)\nfrom src.controllers.factory import SMCType\nfrom src.config import load_config\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nCONFIG_PATH = \"config.yaml\"\nCONTROLLER_TYPE = SMCType.CLASSICAL\nMAX_META_EVALUATIONS = 50\nN_TRIALS_PER_EVAL = 3\n\n# ============================================================================\n# Main\n# ============================================================================\n\ndef main():\n    # Load configuration\n    config = load_config(CONFIG_PATH)\n\n    # Initialize meta-optimizer\n    print(\"Initializing PSO Hyperparameter Optimizer...\")\n    meta_optimizer = PSOHyperparameterOptimizer(config)\n\n    # Run meta-optimization\n    print(f\"\\nRunning meta-optimization for {CONTROLLER_TYPE.value}...\")\n    print(f\"Max evaluations: {MAX_META_EVALUATIONS}\")\n    print(f\"Trials per evaluation: {N_TRIALS_PER_EVAL}\")\n    print(f\"Objective: {OptimizationObjective.MULTI_OBJECTIVE.value}\")\n    print(\"=\"*80)\n\n    result = meta_optimizer.optimize_hyperparameters(\n        controller_type=CONTROLLER_TYPE,\n        objective=OptimizationObjective.MULTI_OBJECTIVE,\n        max_evaluations=MAX_META_EVALUATIONS,\n        n_trials_per_evaluation=N_TRIALS_PER_EVAL\n    )\n\n    # Display results\n    print(\"\\n\" + \"=\"*80)\n    print(\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n    print(\"=\"*80)\n    print(f\"\\nOptimized Hyperparameters:\")\n    print(f\"  Inertia weight (w):   {result.hyperparameters.w:.6f}\")\n    print(f\"  Cognitive (c1):       {result.hyperparameters.c1:.6f}\")\n    print(f\"  Social (c2):          {result.hyperparameters.c2:.6f}\")\n    print(f\"  Swarm size:           {result.hyperparameters.n_particles}\")\n\n    print(f\"\\nBaseline Hyperparameters:\")\n    print(f\"  Inertia weight (w):   {result.baseline_hyperparameters.w:.6f}\")\n    print(f\"  Cognitive (c1):       {result.baseline_hyperparameters.c1:.6f}\")\n    print(f\"  Social (c2):          {result.baseline_hyperparameters.c2:.6f}\")\n    print(f\"  Swarm size:           {result.baseline_hyperparameters.n_particles}\")\n\n    print(f\"\\nPerformance Improvements vs. Baseline:\")\n    print(f\"  Convergence speedup:  {result.convergence_improvement:.2f}x\")\n    print(f\"  Quality improvement:  {result.quality_improvement*100:.2f}%\")\n    print(f\"  Robustness improvement: {result.robustness_improvement*100:.2f}%\")\n    print(f\"  Efficiency score:     {result.efficiency_score:.4f}\")\n    print(\"=\"*80)\n\n    # Visualize comparison\n    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n    categories = ['w', 'c1', 'c2', 'N']\n    baseline_values = [\n        result.baseline_hyperparameters.w,\n        result.baseline_hyperparameters.c1,\n        result.baseline_hyperparameters.c2,\n        result.baseline_hyperparameters.n_particles\n    ]\n    optimized_values = [\n        result.hyperparameters.w,\n        result.hyperparameters.c1,\n        result.hyperparameters.c2,\n        result.hyperparameters.n_particles\n    ]\n\n    x = np.arange(len(categories))\n    width = 0.35\n\n    axes[0, 0].bar(x - width/2, baseline_values, width, label='Baseline', alpha=0.7)\n    axes[0, 0].bar(x + width/2, optimized_values, width, label='Optimized', alpha=0.7)\n    axes[0, 0].set_ylabel('Value')\n    axes[0, 0].set_title('Hyperparameter Comparison')\n    axes[0, 0].set_xticks(x)\n    axes[0, 0].set_xticklabels(categories)\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n\n    # Performance metrics\n    metrics = ['Convergence\\nSpeed', 'Solution\\nQuality', 'Robustness']\n    improvements = [\n        result.convergence_improvement,\n        1 + result.quality_improvement,\n        1 + result.robustness_improvement\n    ]\n\n    axes[0, 1].bar(metrics, improvements, color=['blue', 'green', 'orange'], alpha=0.7)\n    axes[0, 1].axhline(y=1.0, color='red', linestyle='--', label='Baseline')\n    axes[0, 1].set_ylabel('Improvement Factor')\n    axes[0, 1].set_title('Performance Improvements')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True, alpha=0.3)\n\n    # Convergence history (if available)\n    if hasattr(result, 'optimization_history'):\n        axes[1, 0].plot(result.optimization_history['best_objective'], linewidth=2)\n        axes[1, 0].set_xlabel('Meta-Optimization Iteration')\n        axes[1, 0].set_ylabel('Objective Value')\n        axes[1, 0].set_title('Meta-Optimization Convergence')\n        axes[1, 0].grid(True, alpha=0.3)\n\n    # Hide unused subplot\n    axes[1, 1].axis('off')\n\n    plt.tight_layout()\n    plt.savefig('pso_hyperparameter_optimization.png', dpi=300)\n    print(\"\\nVisualization saved: pso_hyperparameter_optimization.png\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 142,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62878424"
  },
  {
    "id": "optimization_module_api_reference_35_28071efa",
    "file": "docs\\api\\optimization_module_api_reference.md",
    "index": 35,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nExample 5: Complete Optimization Pipeline\n\nDemonstrates:\n- Full workflow: Config \u2192 Factory \u2192 PSO \u2192 Validation \u2192 Deployment\n- Bounds validation and adjustment\n- Convergence monitoring\n- Performance benchmarking\n- Controller deployment\n\"\"\"\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom functools import partial\nfrom pathlib import Path\n\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.optimization.validation.pso_bounds_validator import PSOBoundsValidator\nfrom src.optimization.validation.enhanced_convergence_analyzer import (\n    EnhancedConvergenceAnalyzer,\n    ConvergenceCriteria\n)\nfrom src.controllers.factory import create_controller, SMCType\nfrom src.config import load_config\nfrom src.simulation.engines.simulation_runner import SimulationRunner\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nCONFIG_PATH = \"config.yaml\"\nCONTROLLER_TYPE = 'classical_smc'\nOUTPUT_DIR = Path(\"optimization_results\")\nSEED = 42\n\n# ============================================================================\n# Pipeline\n# ============================================================================\n\ndef main():\n    # Create output directory\n    OUTPUT_DIR.mkdir(exist_ok=True)\n\n    print(\"=\"*80)\n    print(\"COMPLETE PSO OPTIMIZATION PIPELINE\")\n    print(\"=\"*80)\n\n    # -------------------------------------------------------------------------\n    # Step 1: Load Configuration\n    # -------------------------------------------------------------------------\n    print(\"\\n[1/7] Loading configuration...\")\n    config = load_config(CONFIG_PATH)\n    print(f\"  \u2713 Configuration loaded from {CONFIG_PATH}\")\n\n    # -------------------------------------------------------------------------\n    # Step 2: Validate and Adjust Bounds\n    # -------------------------------------------------------------------------\n    print(\"\\n[2/7] Validating PSO bounds...\")\n    validator = PSOBoundsValidator(config)\n\n    bounds_result = validator.validate_bounds(\n        controller_type=CONTROLLER_TYPE,\n        lower_bounds=list(config.pso.bounds.min),\n        upper_bounds=list(config.pso.bounds.max)\n    )\n\n    if bounds_result.is_valid:\n        print(\"  \u2713 Bounds are valid\")\n    else:\n        print(\"  \u2717 Bounds validation failed, using adjusted bounds\")\n        config.pso.bounds.min = bounds_result.adjusted_bounds['lower']\n        config.pso.bounds.max = bounds_result.adjusted_bounds['upper']\n\n    # -------------------------------------------------------------------------\n    # Step 3: Initialize Convergence Analyzer\n    # -------------------------------------------------------------------------\n    print(\"\\n[3/7] Initializing convergence analyzer...\")\n    criteria = ConvergenceCriteria(\n        fitness_tolerance=1e-6,\n        max_stagnation_iterations=50\n    )\n    analyzer = EnhancedConvergenceAnalyzer(\n        criteria=criteria,\n        controller_type=SMCType.CLASSICAL\n    )\n    print(\"  \u2713 Convergence analyzer ready\")\n\n    # -------------------------------------------------------------------------\n    # Step 4: Create Controller Factory\n    # -------------------------------------------------------------------------\n    print(\"\\n[4/7] Creating controller factory...\")\n    controller_factory = partial(\n        create_controller,\n        controller_type=CONTROLLER_TYPE,\n        config=config\n    )\n    print(\"  \u2713 Factory created\")\n\n    # -------------------------------------------------------------------------\n    # Step 5: Run PSO Optimization\n    # -------------------------------------------------------------------------\n    print(\"\\n[5/7] Running PSO optimization...\")\n    tuner = PSOTuner(\n        controller_factory=controller_factory,\n        config=config,\n        seed=SEED,\n        instability_penalty_factor=100.0\n    )\n\n    result = tuner.optimise()\n\n    best_gains = result['best_pos']\n    best_cost = result['best_cost']\n    cost_history = result['cost_history']\n\n    print(f\"  \u2713 Optimization complete\")\n    print(f\"    Best cost: {best_cost:.6f}\")\n    print(f\"    Convergence: {len(cost_history)} iterations\")\n\n    # Save results\n    np.save(OUTPUT_DIR / \"optimized_gains.npy\", best_gains)\n    np.save(OUTPUT_DIR / \"cost_history.npy\", cost_history)\n\n    # -------------------------------------------------------------------------\n    # Step 6: Validate Optimized Controller\n    # -------------------------------------------------------------------------\n    print(\"\\n[6/7] Validating optimized controller...\")\n\n    # Create controller with optimized gains\n    optimized_controller = create_controller(\n        controller_type=CONTROLLER_TYPE,\n        config=config,\n        gains=best_gains\n    )\n\n    # Run validation simulations\n    n_validation_trials = 10\n    validation_costs = []\n\n    for trial in range(n_validation_trials):\n        sim_runner = SimulationRunner(\n            controller=optimized_controller,\n            config=config,\n            seed=SEED + trial\n        )\n        result_trial = sim_runner.run()\n\n        # Compute cost\n        ise = np.sum(result_trial.states ** 2) * config.simulation.dt\n        validation_costs.append(ise)\n\n    mean_cost = np.mean(validation_costs)\n    std_cost = np.std(validation_costs)\n\n    print(f\"  \u2713 Validation complete ({n_validation_trials} trials)\")\n    print(f\"    Mean cost: {mean_cost:.6f} \u00b1 {std_cost:.6f}\")\n\n    # -------------------------------------------------------------------------\n    # Step 7: Generate Report and Visualizations\n    # -------------------------------------------------------------------------\n    print(\"\\n[7/7] Generating reports and visualizations...\")\n\n    # Convergence plot\n    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n\n    axes[0].plot(cost_history, linewidth=2, color='blue')\n    axes[0].set_ylabel('Best Cost', fontsize=12)\n    axes[0].set_title('PSO Convergence History', fontsize=14, fontweight='bold')\n    axes[0].set_yscale('log')\n    axes[0].grid(True, alpha=0.3)\n\n    axes[1].bar(range(n_validation_trials), validation_costs, alpha=0.7, color='green')\n    axes[1].axhline(y=mean_cost, color='red', linestyle='--', label=f'Mean: {mean_cost:.4f}')\n    axes[1].set_xlabel('Validation Trial', fontsize=12)\n    axes[1].set_ylabel('Cost (ISE)', fontsize=12)\n    axes[1].set_title('Validation Performance', fontsize=14, fontweight='bold')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(OUTPUT_DIR / \"optimization_pipeline_summary.png\", dpi=300)\n\n    # Summary report\n    report_path = OUTPUT_DIR / \"optimization_report.txt\"\n    with open(report_path, 'w') as f:\n        f.write(\"=\"*80 + \"\\n\")\n        f.write(\"PSO OPTIMIZATION PIPELINE - SUMMARY REPORT\\n\")\n        f.write(\"=\"*80 + \"\\n\\n\")\n        f.write(f\"Controller Type: {CONTROLLER_TYPE}\\n\")\n        f.write(f\"Configuration: {CONFIG_PATH}\\n\")\n        f.write(f\"Random Seed: {SEED}\\n\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        f.write(\"OPTIMIZATION RESULTS\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        f.write(f\"Best Cost: {best_cost:.6f}\\n\")\n        f.write(f\"Convergence Iterations: {len(cost_history)}\\n\")\n        f.write(f\"Optimized Gains: {best_gains}\\n\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        f.write(\"VALIDATION RESULTS\\n\")\n        f.write(\"-\"*80 + \"\\n\")\n        f.write(f\"Number of Trials: {n_validation_trials}\\n\")\n        f.write(f\"Mean Cost: {mean_cost:.6f}\\n\")\n        f.write(f\"Std. Deviation: {std_cost:.6f}\\n\")\n        f.write(f\"Min Cost: {np.min(validation_costs):.6f}\\n\")\n        f.write(f\"Max Cost: {np.max(validation_costs):.6f}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n\n    print(f\"  \u2713 Summary report: {report_path}\")\n    print(f\"  \u2713 Visualization: {OUTPUT_DIR / 'optimization_pipeline_summary.png'}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PIPELINE COMPLETE\")\n    print(\"=\"*80)\n    print(f\"\\nOptimized controller ready for deployment!\")\n    print(f\"Gains: {best_gains}\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 222,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28071efa"
  },
  {
    "id": "phase_4_1_completion_report_1_49530d06",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nSee Also\n--------\nTheory Documentation\n--------------------\n- Classical SMC Stability: `docs/theory/lyapunov_stability_analysis.md` (Section 4)\n- Sliding Surface Design: `docs/theory/lyapunov_stability_analysis.md` (Section 2)\n- PSO Optimization: `docs/theory/pso_algorithm_foundations.md` (Section 7.1)\n\nConfiguration\n-------------\n- Default gains: `config.yaml` -> controllers.classical_smc\n- PSO bounds: `src/optimization/validation/pso_bounds_validator.py` (line 120)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49530d06"
  },
  {
    "id": "phase_4_1_completion_report_2_37e6cf73",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nSee Also\n--------\nTheory Documentation\n--------------------\n- Super-Twisting Stability: `docs/theory/lyapunov_stability_analysis.md` (Section 5)\n- Finite-Time Convergence: `docs/theory/lyapunov_stability_analysis.md` (Section 5.1)\n- PSO Gain Selection: `docs/theory/pso_algorithm_foundations.md` (Section 7.2)\n\nConfiguration\n-------------\n- Default gains: `config.yaml` -> controllers.sta_smc\n- PSO bounds: `src/optimization/validation/pso_bounds_validator.py` (line 145)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37e6cf73"
  },
  {
    "id": "phase_4_1_completion_report_3_9cde63af",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nSee Also\n--------\nTheory Documentation\n--------------------\n- Adaptive SMC Stability: `docs/theory/lyapunov_stability_analysis.md` (Section 6)\n- Adaptation Law: `docs/theory/lyapunov_stability_analysis.md` (Section 6.2)\n- PSO Integration: `docs/theory/pso_algorithm_foundations.md` (Section 7.3)\n\nConfiguration\n-------------\n- Default gains: `config.yaml` -> controllers.adaptive_smc\n- Adaptation params: `config.yaml` -> controllers.adaptive_smc.leak_rate",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9cde63af"
  },
  {
    "id": "phase_4_1_completion_report_4_e91b1d0e",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nExamples\n--------\n>>> from src.controllers.smc import ClassicalSMC\n>>> import numpy as np\n>>>\n>>> # Create controller\n>>> controller = ClassicalSMC(\n...     gains=[10, 8, 15, 12, 50, 5],\n...     max_force=100,\n...     boundary_layer=0.05\n... )\n>>>\n>>> # Initialize\n>>> state_vars = controller.initialize_state()\n>>> history = controller.initialize_history()\n>>>\n>>> # Compute control\n>>> state = np.array([0, 0.1, 0.05, 0, 0, 0])\n>>> output = controller.compute_control(state, state_vars, history)\n>>> assert -100 <= output.u <= 100  # Force saturation\n>>> assert 'sigma' in output.history  # Telemetry",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e91b1d0e"
  },
  {
    "id": "phase_4_1_completion_report_5_c8c96404",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 5,
    "code": ".. testcode::\n   :skipif: True  # Enable in Phase 6.2",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8c96404"
  },
  {
    "id": "phase_4_1_completion_report_6_12285b08",
    "file": "docs\\api\\phase_4_1_completion_report.md",
    "index": 6,
    "code": "Parameters\n----------\ngains : array-like of length 6\n    Controller gains [k1, k2, lam1, lam2, K, kd].\n    See `config.yaml` controllers.classical_smc for defaults.",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "12285b08"
  },
  {
    "id": "phase_4_2_completion_report_1_9b17debf",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 1,
    "code": "if not isinstance(name, str):\n    raise ValueError(f\"Controller type must be string, got {type(name)}\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9b17debf"
  },
  {
    "id": "phase_4_2_completion_report_2_0915b8b5",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 2,
    "code": "if controller_type not in CONTROLLER_REGISTRY:\n    available = list(CONTROLLER_REGISTRY.keys())\n    raise ValueError(f\"Unknown controller type '{controller_type}'. Available: {available}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0915b8b5"
  },
  {
    "id": "phase_4_2_completion_report_3_7eac4bf0",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 3,
    "code": "try:\n    controller_config = config_class(**config_params)\nexcept Exception as e:\n    logger.debug(f\"Could not create full config, using minimal config: {e}\")\n    fallback_params = {'gains': controller_gains, 'max_force': 150.0, 'dt': 0.001}\n    controller_config = config_class(**fallback_params)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7eac4bf0"
  },
  {
    "id": "phase_4_2_completion_report_4_effff73b",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 4,
    "code": "try:\n    _validate_controller_gains(controller_gains, controller_info, controller_type)\nexcept ValueError as e:\n    if gains is None:  # Only auto-fix defaults\n        if controller_type == 'sta_smc':\n            controller_gains = [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # K1=25 > K2=15\n        _validate_controller_gains(controller_gains, controller_info, controller_type)\n    else:\n        raise e  # User-provided gains, do not auto-correct",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "effff73b"
  },
  {
    "id": "phase_4_2_completion_report_5_33e79149",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 5,
    "code": "# tests/test_factory_examples.py\n\nimport pytest\nimport numpy as np\nfrom src.controllers.factory import create_controller, list_available_controllers\nfrom src.config import load_config\n\nclass TestFactoryExamples:\n    \"\"\"Validate all documented code examples.\"\"\"\n\n    @pytest.fixture\n    def config(self):\n        \"\"\"Load configuration for tests.\"\"\"\n        return load_config(\"config.yaml\")\n\n    def test_example_1_basic_usage(self, config):\n        \"\"\"Test Example 1: Basic Factory Usage.\"\"\"\n        # Example code from docs\n        controller = create_controller('classical_smc', config)\n        assert controller is not None\n        assert len(controller.gains) == 6\n\n        state = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n        result = controller.compute_control(state, 0.0, {})\n        assert result is not None\n\n    def test_example_2_pso_optimized(self, config):\n        \"\"\"Test Example 2: PSO-Optimized Controller Creation.\"\"\"\n        optimized_gains = [25.3, 18.7, 14.2, 10.8, 42.6, 6.1]\n        controller = create_controller('classical_smc', config, gains=optimized_gains)\n        assert controller.gains == optimized_gains\n\n    def test_example_3_batch_comparison(self, config):\n        \"\"\"Test Example 3: Batch Controller Comparison.\"\"\"\n        controllers = {}\n        for controller_type in list_available_controllers():\n            controller = create_controller(controller_type, config)\n            controllers[controller_type] = controller\n\n        assert len(controllers) >= 4  # At least 4 SMC types\n\n    def test_example_4_custom_override(self, config):\n        \"\"\"Test Example 4: Custom Configuration Override.\"\"\"\n        custom_gains = [35.0, 25.0, 18.0, 14.0, 50.0, 8.0]\n        controller = create_controller('classical_smc', config, gains=custom_gains)\n        assert controller.gains == custom_gains\n\n    def test_example_5_error_handling(self, config):\n        \"\"\"Test Example 5: Error Handling and Validation.\"\"\"\n        # Valid creation\n        controller = create_controller('classical_smc', config)\n        assert controller is not None\n\n        # Invalid controller type\n        with pytest.raises(ValueError, match=\"Unknown controller type\"):\n            create_controller('nonexistent_controller', config)\n\n        # Invalid gain count\n        with pytest.raises(ValueError, match=\"requires 6 gains\"):\n            create_controller('classical_smc', config, gains=[10.0, 20.0])\n\n        # STA constraint violation\n        with pytest.raises(ValueError, match=\"K1 > K2\"):\n            create_controller('sta_smc', config, gains=[15.0, 20.0, 12.0, 8.0, 6.0, 4.0])",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33e79149"
  },
  {
    "id": "phase_4_2_completion_report_6_d9844ab9",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 6,
    "code": "controller = create_controller('classical_smc', config, gains=[10,10,10,1,1,1])\n# Always uses [10,10,10,1,1,1] regardless of config or defaults",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9844ab9"
  },
  {
    "id": "phase_4_2_completion_report_7_e4828a87",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 7,
    "code": "# config.yaml: controllers.classical_smc.gains = [5,5,5,0.5,0.5,0.5]\ncontroller = create_controller('classical_smc', config)\n# Uses [5,5,5,0.5,0.5,0.5] from config",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4828a87"
  },
  {
    "id": "phase_4_2_completion_report_8_4bb5c20e",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 8,
    "code": "controller = create_controller('classical_smc')  # No config\n# Uses [20.0, 15.0, 12.0, 8.0, 35.0, 5.0] from CONTROLLER_REGISTRY",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4bb5c20e"
  },
  {
    "id": "phase_4_2_completion_report_9_9aa6ccfc",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Scenario: Registry defaults violate STA constraint K1 > K2\nCONTROLLER_REGISTRY['sta_smc']['default_gains'] = [15.0, 20.0, ...]  # K1=15 \u2264 K2=20 \u2717\n\n# Factory detection and correction:\ntry:\n    _validate_controller_gains(default_gains, ...)\nexcept ValueError:\n    if gains is None:  # Only auto-fix defaults\n        controller_gains = [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # K1=25 > K2=15 \u2713",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9aa6ccfc"
  },
  {
    "id": "phase_4_2_completion_report_10_8dab8271",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 10,
    "code": "controller.compute_control(state, last_control, history)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dab8271"
  },
  {
    "id": "phase_4_2_completion_report_11_fda19faf",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 11,
    "code": "wrapper.compute_control(state)  # Returns np.ndarray",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fda19faf"
  },
  {
    "id": "phase_4_2_completion_report_12_ec09b03b",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n_factory_lock = threading.RLock()  # Reentrant allows nested calls\n_LOCK_TIMEOUT = 10.0  # Prevents deadlocks\n\ndef create_controller(controller_type, config=None, gains=None):\n    with _factory_lock:  # Automatic acquire/release\n        # Thread-safe controller creation\n        ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec09b03b"
  },
  {
    "id": "phase_4_2_completion_report_13_c11d1131",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Future API\nfrom src.controllers.factory import register_controller\n\n@register_controller('new_controller', default_gains=[...], gain_count=4)\nclass NewController:\n    ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c11d1131"
  },
  {
    "id": "phase_4_2_completion_report_14_bded1bc4",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 14,
    "code": "# Future: Validate config.yaml before controller creation\nfrom src.controllers.factory import validate_configuration\n\nerrors = validate_configuration(\"config.yaml\")\nif errors:\n    for error in errors:\n        print(f\"Config error: {error}\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bded1bc4"
  },
  {
    "id": "phase_4_2_completion_report_15_c48430ec",
    "file": "docs\\api\\phase_4_2_completion_report.md",
    "index": 15,
    "code": "# Future: Automatically infer PSO bounds from controller constraints\nbounds = infer_gain_bounds(controller_type, physics_params)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c48430ec"
  },
  {
    "id": "phase_4_3_progress_report_1_47ab35e2",
    "file": "docs\\api\\phase_4_3_progress_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimize_bounds_for_controller(\n    self,\n    controller_type: SMCType,\n    strategy: BoundsOptimizationStrategy = BoundsOptimizationStrategy.HYBRID,\n    max_optimization_time: float = 300.0\n) -> BoundsValidationResult:\n    \"\"\"\n    Optimize PSO parameter bounds for specific controller type.\n\n    This method implements multi-strategy bounds optimization combining\n    physics-based constraints, empirical performance data, and PSO convergence\n    properties to find optimal parameter search spaces for each SMC controller type.\n\n    Mathematical Foundation\n    -----------------------\n    Bounds optimization maximizes the objective function:\n\n    $$J_{bounds}(b_{lower}, b_{upper}) = w_1 \\cdot R_{conv} + w_2 \\cdot Q_{final} + w_3 \\cdot P_{success}$$\n\n    where:\n    - $R_{conv}$: Convergence rate improvement\n    - $Q_{final}$: Final cost quality improvement\n    - $P_{success}$: Success rate across trials\n    - $w_1, w_2, w_3$: Strategy-dependent weights\n\n    Algorithm\n    ---------\n    1. Generate candidate bounds from multiple strategies:\n       - Physics-based: Controller stability constraints\n       - Performance-driven: Empirical data analysis\n       - Convergence-focused: PSO sensitivity analysis\n    2. Evaluate candidates through PSO trials\n    3. Select optimal bounds via multi-criteria scoring\n    4. Validate through comprehensive testing\n\n    Parameters\n    ----------\n    controller_type : SMCType\n        Controller type to optimize bounds for (CLASSICAL, ADAPTIVE,\n        SUPER_TWISTING, or HYBRID)\n    strategy : BoundsOptimizationStrategy, optional\n        Optimization strategy to use:\n        - PHYSICS_BASED: Stability-constrained bounds\n        - PERFORMANCE_DRIVEN: Empirically validated bounds\n        - CONVERGENCE_FOCUSED: PSO-optimized bounds\n        - HYBRID: Weighted combination (default)\n    max_optimization_time : float, optional\n        Maximum time allowed for optimization in seconds (default: 300.0)\n\n    Returns\n    -------\n    BoundsValidationResult\n        Comprehensive optimization results containing:\n        - optimized_bounds: Tuple of (lower_bounds, upper_bounds)\n        - improvement_ratio: Performance improvement factor\n        - convergence_improvement: Convergence rate improvement percentage\n        - performance_improvement: Final cost improvement percentage\n        - validation_successful: Whether validation criteria were met\n        - detailed_metrics: Full performance analysis\n\n    Raises\n    ------\n    ValueError\n        If controller_type is not supported or strategy is invalid\n    TimeoutError\n        If optimization exceeds max_optimization_time\n\n    Examples\n    --------\n    >>> from src.optimization.validation.pso_bounds_optimizer import PSOBoundsOptimizer\n    >>> from src.controllers.factory import SMCType\n    >>>\n    >>> optimizer = PSOBoundsOptimizer()\n    >>> result = optimizer.optimize_bounds_for_controller(\n    ...     controller_type=SMCType.CLASSICAL,\n    ...     strategy=BoundsOptimizationStrategy.HYBRID,\n    ...     max_optimization_time=300.0\n    ... )\n    >>> print(f\"Improvement: {result.improvement_ratio:.2f}x\")\n    >>> print(f\"Optimized bounds: {result.optimized_bounds}\")\n\n    See Also\n    --------\n    get_gain_bounds_for_pso : Retrieve current PSO bounds for controller type\n    validate_smc_gains : Validate gain vector against constraints\n    Phase 2.2 Documentation : PSO algorithm foundations (pso_algorithm_foundations.md)\n    Phase 4.2 Documentation : Factory system API reference (factory_system_api_reference.md)\n\n    References\n    ----------\n    .. [1] Kennedy, J., & Eberhart, R. (1995). \"Particle Swarm Optimization.\"\n    .. [2] Clerc, M., & Kennedy, J. (2002). \"The Particle Swarm - Explosion,\n           Stability, and Convergence in a Multidimensional Complex Space.\"\n\n    Notes\n    -----\n    - Bounds optimization typically improves PSO convergence by 20-50%\n    - Hybrid strategy recommended for production use\n    - Optimization time scales with number of candidate bounds configurations\n    - Results are deterministic given fixed random seed (seed=42)\n    \"\"\"",
    "lines": 104,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47ab35e2"
  },
  {
    "id": "simulation_engine_api_reference_1_725af9ea",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import Protocol\n\nclass DynamicsModel(Protocol):\n    \"\"\"Protocol for plant dynamics models.\"\"\"\n    def compute_dynamics(self, state, control_input, time=0.0, **kwargs) -> DynamicsResult: ...\n    def get_physics_matrices(self, state) -> Tuple[np.ndarray, np.ndarray, np.ndarray]: ...\n    def validate_state(self, state) -> bool: ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "725af9ea"
  },
  {
    "id": "simulation_engine_api_reference_2_9bdfb13f",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 2,
    "code": "from src.simulation.integrators import IntegratorFactory\n\nintegrator = IntegratorFactory.create_integrator('rk4', dt=0.01)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bdfb13f"
  },
  {
    "id": "simulation_engine_api_reference_3_e26060d7",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 3,
    "code": "# Sequential execution\nseq_orchestrator = SequentialOrchestrator(dynamics, integrator)\nresult = seq_orchestrator.execute(initial_state, controls, dt, horizon)\n\n# Batch execution\nbatch_orchestrator = BatchOrchestrator(dynamics, integrator)\nresult = batch_orchestrator.execute(batch_initial_states, controls, dt, horizon)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e26060d7"
  },
  {
    "id": "simulation_engine_api_reference_4_26bd98b0",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Legacy imports work unchanged\nfrom src.simulation import run_simulation, step, get_step_fn, simulate\n\n# Original function signatures preserved\nt, x, u = run_simulation(controller=..., dynamics_model=..., sim_time=5.0, dt=0.01, ...)\n\n# Legacy step function\nx_next = step(x_current, u_current, dt)",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26bd98b0"
  },
  {
    "id": "simulation_engine_api_reference_5_0162651d",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 5,
    "code": "from src.simulation import SequentialOrchestrator, IntegratorFactory\n\n# Modern interface\norchestrator = SequentialOrchestrator(dynamics, integrator)\nresult = orchestrator.execute(initial_state, controls, dt, horizon)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0162651d"
  },
  {
    "id": "simulation_engine_api_reference_6_70936b74",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef run_simulation(\n    *,\n    controller: Any,\n    dynamics_model: Any,\n    sim_time: float,\n    dt: float,\n    initial_state: Any,\n    u_max: Optional[float] = None,\n    seed: Optional[int] = None,\n    rng: Optional[np.random.Generator] = None,\n    latency_margin: Optional[float] = None,\n    fallback_controller: Optional[Callable[[float, np.ndarray], float]] = None,\n    **_kwargs: Any,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Simulate a single controller trajectory using explicit Euler method.\"\"\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70936b74"
  },
  {
    "id": "simulation_engine_api_reference_7_6e26676a",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 7,
    "code": "Tuple[np.ndarray, np.ndarray, np.ndarray]\n    t_arr : np.ndarray  # Time vector (n_steps+1,)\n    x_arr : np.ndarray  # State trajectory (n_steps+1, state_dim)\n    u_arr : np.ndarray  # Control sequence (n_steps,)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e26676a"
  },
  {
    "id": "simulation_engine_api_reference_8_1957029c",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 8,
    "code": "class MyController:\n    def __call__(self, t: float, x: np.ndarray) -> float:\n        \"\"\"Compute control given time and state.\"\"\"\n        return control_value",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1957029c"
  },
  {
    "id": "simulation_engine_api_reference_9_1961ef84",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 9,
    "code": "class StatefulController:\n    def compute_control(self, x: np.ndarray, state_vars: Any, history: Any):\n        \"\"\"Compute control with state tracking.\"\"\"\n        return control_value, updated_state, updated_history",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1961ef84"
  },
  {
    "id": "simulation_engine_api_reference_10_5d1a83bd",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 10,
    "code": "def initialize_state(self) -> Any:\n    \"\"\"Initialize internal state variables (called once at start).\"\"\"\n    return initial_state_vars\n\ndef initialize_history(self) -> Any:\n    \"\"\"Initialize history buffer (called once at start).\"\"\"\n    return initial_history",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d1a83bd"
  },
  {
    "id": "simulation_engine_api_reference_11_2352e727",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 11,
    "code": "class MyDynamics:\n    def step(self, state: np.ndarray, u: float, dt: float) -> np.ndarray:\n        \"\"\"Integrate dynamics forward one timestep.\"\"\"\n        return next_state",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2352e727"
  },
  {
    "id": "simulation_engine_api_reference_12_fdd10aff",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Priority hierarchy:\n# 1. Explicit u_max parameter\nif u_max is not None:\n    u_limit = float(u_max)\n# 2. Controller's max_force attribute\nelif hasattr(controller, 'max_force'):\n    u_limit = float(controller.max_force)\n# 3. No saturation\nelse:\n    u_limit = None\n\n# Apply saturation\nif u_limit is not None:\n    u = np.clip(u, -u_limit, u_limit)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fdd10aff"
  },
  {
    "id": "simulation_engine_api_reference_13_5d02264e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Simple PD fallback controller\ndef pd_fallback(t, x):\n    return -10 * x[0] - 5 * x[3]  # -Kp*x - Kd*x_dot\n\nt, x, u = run_simulation(\n    controller=complex_mpc_controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=x0,\n    fallback_controller=pd_fallback  # Engage if MPC exceeds 10ms\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d02264e"
  },
  {
    "id": "simulation_engine_api_reference_14_ca14db39",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 14,
    "code": "try:\n       u = controller(t, x)\n   except Exception:\n       # Truncate and return",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca14db39"
  },
  {
    "id": "simulation_engine_api_reference_15_71347201",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 15,
    "code": "try:\n       x_next = dynamics.step(x, u, dt)\n   except Exception:\n       # Truncate and return",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71347201"
  },
  {
    "id": "simulation_engine_api_reference_16_a56e1d4a",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 16,
    "code": "if not np.all(np.isfinite(x_next)):\n       # Truncate and return (NaN or Inf detected)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a56e1d4a"
  },
  {
    "id": "simulation_engine_api_reference_17_1910f0b4",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 17,
    "code": "# MEMORY OPTIMIZATION: asarray creates view when input is already ndarray\nx0 = np.asarray(initial_state, dtype=float).reshape(-1)  # View, not copy\nx_curr = x0  # View, immediately overwritten at line 323\nx_next = np.asarray(x_next, dtype=float).reshape(-1)  # View when possible",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1910f0b4"
  },
  {
    "id": "simulation_engine_api_reference_18_ec8e1906",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 18,
    "code": "from src.simulation import run_simulation\nfrom src.controllers import create_controller\nfrom src.plant.models import LowRankDIPDynamics\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller(\n    'classical_smc',\n    config=config,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n)\n\n# Create dynamics model\ndynamics = LowRankDIPDynamics(config.plant)\n\n# Run simulation\nt, x, u = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=[0, 0.1, 0.1, 0, 0, 0],  # Small perturbation\n    u_max=100.0,  # Saturation limit\n    seed=42  # Reproducibility\n)\n\n# Analyze results\nprint(f\"Simulation steps: {len(t)-1}\")\nprint(f\"Final state: {x[-1]}\")\nprint(f\"Max control: {np.max(np.abs(u)):.2f} N\")",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec8e1906"
  },
  {
    "id": "simulation_engine_api_reference_19_4a1c7afe",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 19,
    "code": "class SimulationRunner:\n    \"\"\"Object-oriented wrapper around run_simulation function.\"\"\"\n\n    def __init__(self, dynamics_model: Any, dt: float = 0.01, max_time: float = 10.0):\n        \"\"\"Initialize simulation runner.\"\"\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a1c7afe"
  },
  {
    "id": "simulation_engine_api_reference_20_9b8a4cd6",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 20,
    "code": "self.dynamics_model: Any              # Dynamics model instance\nself.dt: float                        # Integration timestep\nself.max_time: float                  # Maximum simulation time\nself.current_time: float              # Current simulation time (updated after run)\nself.step_count: int                  # Number of steps executed (updated after run)\nself.simulation_history: List[dict]   # History of all simulation runs",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9b8a4cd6"
  },
  {
    "id": "simulation_engine_api_reference_21_d4b0a2dc",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 21,
    "code": "def run_simulation(\n    self,\n    initial_state: np.ndarray,\n    controller: Optional[Any] = None,\n    reference: Optional[np.ndarray] = None,\n    **kwargs: Any\n) -> dict[str, Any]:\n    \"\"\"Run simulation using functional API.\"\"\"",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4b0a2dc"
  },
  {
    "id": "simulation_engine_api_reference_22_083576fb",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 22,
    "code": "{\n    'success': bool,              # Whether simulation completed without error\n    'states': np.ndarray,         # State trajectory (n_steps+1, state_dim)\n    'controls': np.ndarray,       # Control sequence (n_steps,)\n    'time': np.ndarray,           # Time vector (n_steps+1,)\n    'final_state': np.ndarray,    # Final state (state_dim,)\n    'step_count': int,            # Number of steps executed\n    'error': str                  # Error message (only if success=False)\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "083576fb"
  },
  {
    "id": "simulation_engine_api_reference_23_6d8ae705",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 23,
    "code": "from src.simulation import SimulationRunner\nfrom src.plant.models import LowRankDIPDynamics\n\n# Create runner\ndynamics = LowRankDIPDynamics(config.plant)\nrunner = SimulationRunner(dynamics, dt=0.01, max_time=10.0)\n\n# Run simulation\nresult = runner.run_simulation(\n    initial_state=np.array([0, 0.1, 0.1, 0, 0, 0]),\n    controller=controller,\n    sim_time=5.0\n)\n\n# Check result\nif result['success']:\n    print(f\"Simulation completed: {result['step_count']} steps\")\n    print(f\"Final state: {result['final_state']}\")\nelse:\n    print(f\"Simulation failed: {result['error']}\")\n\n# Access history\nfor i, run in enumerate(runner.simulation_history):\n    print(f\"Run {i}: {run['time'].shape[0]} steps\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d8ae705"
  },
  {
    "id": "simulation_engine_api_reference_24_84a2305e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 24,
    "code": "def step(x, u, dt):\n    \"\"\"Unified simulation step entry point.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84a2305e"
  },
  {
    "id": "simulation_engine_api_reference_25_9a35a0c4",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 25,
    "code": "from src.simulation import step\n\n# Single dynamics step\nx_next = step(x_current, u_current, dt=0.01)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a35a0c4"
  },
  {
    "id": "simulation_engine_api_reference_26_485a21f0",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 26,
    "code": "def get_step_fn():\n    \"\"\"Return appropriate step function based on configuration.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "485a21f0"
  },
  {
    "id": "simulation_engine_api_reference_27_e181bacd",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 27,
    "code": "from src.simulation import get_step_fn\n\n# Get configured step function\nstep_fn = get_step_fn()\nx_next = step_fn(x, u, dt)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e181bacd"
  },
  {
    "id": "simulation_engine_api_reference_28_3f9e8ec8",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\nclass DynamicsModel(Protocol):\n    \"\"\"Protocol for plant dynamics models.\"\"\"\n\n    def compute_dynamics(\n        self,\n        state: np.ndarray,\n        control_input: np.ndarray,\n        time: float = 0.0,\n        **kwargs: Any\n    ) -> DynamicsResult:\n        \"\"\"Compute system dynamics at given state and input.\"\"\"\n        ...\n\n    def get_physics_matrices(\n        self,\n        state: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Get physics matrices M, C, G at current state.\"\"\"\n        ...\n\n    def validate_state(self, state: np.ndarray) -> bool:\n        \"\"\"Validate state vector format and bounds.\"\"\"\n        ...\n\n    def get_state_dimension(self) -> int:\n        \"\"\"Get dimension of state vector.\"\"\"\n        ...\n\n    def get_control_dimension(self) -> int:\n        \"\"\"Get dimension of control input vector.\"\"\"\n        ...",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f9e8ec8"
  },
  {
    "id": "simulation_engine_api_reference_29_1cb4a85c",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 29,
    "code": "class DynamicsResult(NamedTuple):\n    \"\"\"Result of dynamics computation.\"\"\"\n    state_derivative: np.ndarray  # dx/dt vector\n    success: bool                 # Whether computation succeeded\n    info: Dict[str, Any]         # Additional diagnostic information",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1cb4a85c"
  },
  {
    "id": "simulation_engine_api_reference_30_4a346e5f",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\n# Create successful result\nresult = DynamicsResult.success_result(\n    state_derivative=dx_dt,\n    time=t,\n    energy=total_energy\n)\n\n# Create failure result\nresult = DynamicsResult.failure_result(\n    reason=\"Singular matrix detected\",\n    condition_number=1e15\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a346e5f"
  },
  {
    "id": "simulation_engine_api_reference_31_9e723329",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 31,
    "code": "class BaseDynamicsModel(ABC):\n    \"\"\"Abstract base class for dynamics models.\"\"\"\n\n    def __init__(self, parameters: Any):\n        \"\"\"Initialize dynamics model.\"\"\"\n        self.parameters = parameters\n        self._setup_validation()\n        self._setup_monitoring()",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9e723329"
  },
  {
    "id": "simulation_engine_api_reference_32_17791e54",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\n@abstractmethod\ndef compute_dynamics(\n    self,\n    state: np.ndarray,\n    control_input: np.ndarray,\n    time: float = 0.0,\n    **kwargs: Any\n) -> DynamicsResult:\n    \"\"\"Compute system dynamics (must be implemented by subclasses).\"\"\"\n    pass\n\n@abstractmethod\ndef get_physics_matrices(\n    self,\n    state: np.ndarray\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Get physics matrices (must be implemented by subclasses).\"\"\"\n    pass\n\n@abstractmethod\ndef _setup_validation(self) -> None:\n    \"\"\"Setup state validation (must be implemented by subclasses).\"\"\"\n    pass",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17791e54"
  },
  {
    "id": "simulation_engine_api_reference_33_d22afe90",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_state(self, state: np.ndarray) -> bool:\n    \"\"\"Validate state vector using configured validator.\"\"\"\n    if hasattr(self, '_state_validator'):\n        return self._state_validator.validate_state(state)\n    return self._basic_state_validation(state)\n\ndef sanitize_state(self, state: np.ndarray) -> np.ndarray:\n    \"\"\"Sanitize state vector if validator supports it.\"\"\"\n    if hasattr(self, '_state_validator'):\n        return self._state_validator.sanitize_state(state)\n    return state",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d22afe90"
  },
  {
    "id": "simulation_engine_api_reference_34_2287c234",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 34,
    "code": "def get_state_dimension(self) -> int:\n    \"\"\"Get state vector dimension (default: 6 for DIP).\"\"\"\n    return 6\n\ndef get_control_dimension(self) -> int:\n    \"\"\"Get control input dimension (default: 1 for DIP).\"\"\"\n    return 1",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2287c234"
  },
  {
    "id": "simulation_engine_api_reference_35_4b1e548a",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 35,
    "code": "# example-metadata:\n# runnable: false\n\ndef reset_monitoring(self) -> None:\n    \"\"\"Reset monitoring statistics.\"\"\"\n    if hasattr(self, '_stability_monitor'):\n        self._stability_monitor.reset_statistics()\n\ndef get_monitoring_stats(self) -> Dict[str, Any]:\n    \"\"\"Get monitoring statistics.\"\"\"\n    stats = {}\n    if hasattr(self, '_stability_monitor'):\n        stats['numerical_stability'] = self._stability_monitor.get_statistics()\n    return stats",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b1e548a"
  },
  {
    "id": "simulation_engine_api_reference_36_c0dc5809",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 36,
    "code": "class LowRankDIPDynamics(BaseDynamicsModel):\n    \"\"\"Low-rank Double Inverted Pendulum Dynamics Model.\"\"\"\n\n    def __init__(\n        self,\n        config: Union[LowRankDIPConfig, Dict[str, Any]],\n        enable_monitoring: bool = False,\n        enable_validation: bool = True\n    ):\n        \"\"\"Initialize low-rank DIP dynamics.\"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c0dc5809"
  },
  {
    "id": "simulation_engine_api_reference_37_51d543e5",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 37,
    "code": "from src.plant.models.lowrank import LowRankDIPConfig, LowRankDIPDynamics\n\n# Create default configuration\nconfig = LowRankDIPConfig.create_default()\n\n# Or load from dictionary\nconfig = LowRankDIPConfig.from_dict({\n    'cart_mass': 1.0,\n    'pole1_mass': 0.1,\n    'pole2_mass': 0.1,\n    'pole1_length': 0.5,\n    'pole2_length': 0.5,\n    'gravity': 9.81,\n    'damping_cart': 0.01,\n    'damping_pole1': 0.001,\n    'damping_pole2': 0.001\n})\n\n# Initialize dynamics\ndynamics = LowRankDIPDynamics(\n    config=config,\n    enable_monitoring=True,   # Track performance statistics\n    enable_validation=True    # Enable state validation\n)",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51d543e5"
  },
  {
    "id": "simulation_engine_api_reference_38_d2532354",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 38,
    "code": "def compute_dynamics(\n    self,\n    state: np.ndarray,\n    control_input: np.ndarray,\n    time: float = 0.0,\n    **kwargs: Any\n) -> DynamicsResult:\n    \"\"\"Compute low-rank DIP dynamics.\"\"\"",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2532354"
  },
  {
    "id": "simulation_engine_api_reference_39_0d90d30d",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 39,
    "code": "def get_physics_matrices(\n    self,\n    state: np.ndarray\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Get simplified physics matrices M, C, G.\"\"\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d90d30d"
  },
  {
    "id": "simulation_engine_api_reference_40_eb332071",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 40,
    "code": "class LinearDynamicsModel(BaseDynamicsModel):\n    \"\"\"Base class for linear dynamics models.\"\"\"\n\n    def __init__(self, A: np.ndarray, B: np.ndarray, parameters: Any):\n        \"\"\"Initialize linear dynamics model.\"\"\"\n        super().__init__(parameters)\n        self.A = A  # System matrix\n        self.B = B  # Input matrix\n        self._validate_matrices()",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb332071"
  },
  {
    "id": "simulation_engine_api_reference_41_401cedb8",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 41,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_dynamics(\n    self,\n    state: np.ndarray,\n    control_input: np.ndarray,\n    time: float = 0.0,\n    **kwargs: Any\n) -> DynamicsResult:\n    \"\"\"Compute linear dynamics: \u1e8b = Ax + Bu\"\"\"\n    state_derivative = self.A @ state + self.B @ control_input\n\n    # Optional time-varying disturbance\n    if hasattr(self, '_compute_time_varying_terms'):\n        disturbance = self._compute_time_varying_terms(time, state)\n        state_derivative += disturbance\n\n    return DynamicsResult.success_result(state_derivative, time=time)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "401cedb8"
  },
  {
    "id": "simulation_engine_api_reference_42_cb4e5778",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 42,
    "code": "import numpy as np\nfrom src.plant.models.base import LinearDynamicsModel\n\n# Define linearized DIP system\nA = np.array([\n    [0, 0, 0, 1, 0, 0],\n    [0, 0, 0, 0, 1, 0],\n    [0, 0, 0, 0, 0, 1],\n    [0, 14.7, 14.7, -0.1, 0, 0],\n    [0, -29.4, 14.7, 0, -0.01, 0],\n    [0, 14.7, -44.1, 0, 0, -0.01]\n])\n\nB = np.array([[0], [0], [0], [1], [0], [0]])\n\n# Create linear dynamics\nlinear_dynamics = LinearDynamicsModel(A, B, parameters=config.plant)\n\n# Use with simulation\nt, x, u = run_simulation(\n    controller=linear_controller,\n    dynamics_model=linear_dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=[0, 0.1, 0.1, 0, 0, 0]\n)",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb4e5778"
  },
  {
    "id": "simulation_engine_api_reference_43_40f0cdf2",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 43,
    "code": "# example-metadata:\n# runnable: false\n\nclass Orchestrator(ABC):\n    \"\"\"Base interface for simulation execution strategies.\"\"\"\n\n    @abstractmethod\n    def execute(\n        self,\n        initial_state: np.ndarray,\n        control_inputs: np.ndarray,\n        dt: float,\n        horizon: int,\n        **kwargs\n    ) -> ResultContainer:\n        \"\"\"Execute simulation with specified strategy.\"\"\"\n        pass",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40f0cdf2"
  },
  {
    "id": "simulation_engine_api_reference_44_8b810615",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 44,
    "code": "# example-metadata:\n# runnable: false\n\nclass SequentialOrchestrator(BaseOrchestrator):\n    \"\"\"Sequential simulation orchestrator for single-threaded execution.\"\"\"\n\n    def execute(\n        self,\n        initial_state: np.ndarray,\n        control_inputs: np.ndarray,\n        dt: float,\n        horizon: int,\n        **kwargs\n    ) -> ResultContainer:\n        \"\"\"Execute sequential simulation.\"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b810615"
  },
  {
    "id": "simulation_engine_api_reference_45_38bca3fc",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 45,
    "code": "from src.simulation.orchestrators import SequentialOrchestrator\nfrom src.simulation.integrators import IntegratorFactory\n\n# Create orchestrator\nintegrator = IntegratorFactory.create_integrator('rk4', dt=0.01)\norchestrator = SequentialOrchestrator(dynamics, integrator)\n\n# Execute simulation\ninitial_state = np.array([0, 0.1, 0.1, 0, 0, 0])\ncontrols = controller_sequence  # (horizon,) array\nresult = orchestrator.execute(\n    initial_state=initial_state,\n    control_inputs=controls,\n    dt=0.01,\n    horizon=500,\n    safety_guards=True\n)\n\n# Access results\nstates = result.get_states()   # (horizon+1, 6)\ntimes = result.get_times()     # (horizon+1,)",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38bca3fc"
  },
  {
    "id": "simulation_engine_api_reference_46_6a5fb306",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 46,
    "code": "# example-metadata:\n# runnable: false\n\nclass BatchOrchestrator(BaseOrchestrator):\n    \"\"\"Batch simulation orchestrator for vectorized execution.\"\"\"\n\n    def execute(\n        self,\n        initial_state: np.ndarray,\n        control_inputs: np.ndarray,\n        dt: float,\n        horizon: int,\n        **kwargs\n    ) -> ResultContainer:\n        \"\"\"Execute batch simulation.\"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a5fb306"
  },
  {
    "id": "simulation_engine_api_reference_47_0e5ebca3",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 47,
    "code": "from src.simulation.orchestrators import BatchOrchestrator\nfrom src.optimization import PSOTuner\nimport functools\n\n# Create batch orchestrator\norchestrator = BatchOrchestrator(dynamics, integrator)\n\n# Define fitness function using batch execution\ndef fitness_function(gains):\n    # Create controller with candidate gains\n    controller = create_controller('classical_smc', config, gains=gains)\n\n    # Batch initial conditions (10 perturbations)\n    batch_initial = np.random.randn(10, 6) * 0.1\n\n    # Generate control inputs\n    controls = np.zeros((10, 500))  # (batch_size, horizon)\n    for i in range(10):\n        for t in range(500):\n            controls[i, t] = controller(t * 0.01, batch_initial[i])\n\n    # Batch execution\n    result = orchestrator.execute(\n        initial_state=batch_initial,\n        control_inputs=controls,\n        dt=0.01,\n        horizon=500\n    )\n\n    # Compute fitness (aggregate over 10 trials)\n    all_states = result.get_states()  # (10, 501, 6)\n    settling_times = compute_settling_times(all_states)\n    return np.mean(settling_times)\n\n# Use with PSO\ntuner = PSOTuner(fitness_fn=fitness_function, bounds=[(1,50)]*6)\nresult = tuner.optimise()",
    "lines": 37,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e5ebca3"
  },
  {
    "id": "simulation_engine_api_reference_48_0e49a312",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 48,
    "code": "from src.simulation.orchestrators import ParallelOrchestrator\n\n# Create parallel orchestrator (4 worker threads)\norchestrator = ParallelOrchestrator(\n    dynamics=dynamics,\n    integrator=integrator,\n    num_workers=4\n)\n\n# Execute parameter sweep\nparam_grid = generate_parameter_combinations()  # (1000, n_params)\nresults = orchestrator.execute_parameter_sweep(param_grid)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e49a312"
  },
  {
    "id": "simulation_engine_api_reference_49_6d4d878e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 49,
    "code": "from src.simulation.orchestrators import RealTimeOrchestrator\nfrom src.interfaces.hil import PlantServer\n\n# Create real-time orchestrator\norchestrator = RealTimeOrchestrator(\n    dynamics=hardware_interface,\n    integrator=integrator,\n    real_time_factor=1.0,  # Real-time (use 0.5 for slow-motion, 2.0 for fast)\n    deadline_tolerance=0.001  # 1ms tolerance\n)\n\n# Execute HIL simulation\nresult = orchestrator.execute(\n    initial_state=x0,\n    control_inputs=None,  # Generated dynamically\n    dt=0.01,\n    horizon=1000,\n    controller=controller\n)\n\n# Check timing statistics\nstats = orchestrator.get_timing_stats()\nprint(f\"Deadline misses: {stats['deadline_misses']}\")\nprint(f\"Average execution time: {stats['mean_exec_time']:.3f}ms\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d4d878e"
  },
  {
    "id": "simulation_engine_api_reference_50_b22d4f5e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 50,
    "code": "@classmethod\ndef create_integrator(\n    cls,\n    integrator_type: str,\n    dt: float = 0.01,\n    **kwargs: Any\n) -> BaseIntegrator:\n    \"\"\"Create integrator instance of specified type.\"\"\"",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b22d4f5e"
  },
  {
    "id": "simulation_engine_api_reference_51_b651ec60",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 51,
    "code": "from src.simulation.integrators import IntegratorFactory\n\n# Create RK4 integrator\nrk4 = IntegratorFactory.create_integrator('rk4', dt=0.01)\n\n# Create adaptive integrator with error tolerances\ndp45 = IntegratorFactory.create_integrator(\n    'dormand_prince',\n    dt=0.01,\n    atol=1e-6,\n    rtol=1e-3\n)\n\n# Use with orchestrator\nfrom src.simulation.orchestrators import SequentialOrchestrator\norchestrator = SequentialOrchestrator(dynamics, rk4)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b651ec60"
  },
  {
    "id": "simulation_engine_api_reference_52_f95376ae",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 52,
    "code": "# example-metadata:\n# runnable: false\n\nIntegratorFactory.list_available_integrators()\n# Returns: ['euler', 'forward_euler', 'backward_euler', 'rk2', 'rk4', ...]",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f95376ae"
  },
  {
    "id": "simulation_engine_api_reference_53_3d085727",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 53,
    "code": "info = IntegratorFactory.get_integrator_info('rk4')\n# Returns:\n# {\n#     'class_name': 'RungeKutta4',\n#     'module': 'src.simulation.integrators.fixed_step.runge_kutta',\n#     'order': 4,\n#     'adaptive': False,\n#     'description': 'Classic 4th-order Runge-Kutta method'\n# }",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d085727"
  },
  {
    "id": "simulation_engine_api_reference_54_c96be8bd",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 54,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.simulation.integrators.base import BaseIntegrator\n\nclass MyCustomIntegrator(BaseIntegrator):\n    \"\"\"Custom integration method.\"\"\"\n    ORDER = 3\n    ADAPTIVE = False\n    # ... implement integrate() method ...\n\n# Register custom integrator\nIntegratorFactory.register_integrator('my_custom', MyCustomIntegrator)",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c96be8bd"
  },
  {
    "id": "simulation_engine_api_reference_55_5493b732",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 55,
    "code": "euler = IntegratorFactory.create_integrator('euler', dt=0.001)  # Small dt for stability",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5493b732"
  },
  {
    "id": "simulation_engine_api_reference_56_4d304e32",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 56,
    "code": "k1 = f(x_n, u_n, t_n)\nk2 = f(x_n + dt/2 * k1, u_n, t_n + dt/2)\nk3 = f(x_n + dt/2 * k2, u_n, t_n + dt/2)\nk4 = f(x_n + dt * k3, u_n, t_n + dt)\nx_{n+1} = x_n + dt/6 * (k1 + 2*k2 + 2*k3 + k4)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d304e32"
  },
  {
    "id": "simulation_engine_api_reference_57_bcbcdbc4",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 57,
    "code": "rk4 = IntegratorFactory.create_integrator('rk4', dt=0.01)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bcbcdbc4"
  },
  {
    "id": "simulation_engine_api_reference_58_2b47a67b",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 58,
    "code": "dp45 = IntegratorFactory.create_integrator(\n    'dormand_prince',\n    dt=0.01,           # Initial step size\n    atol=1e-6,         # Absolute error tolerance\n    rtol=1e-3,         # Relative error tolerance\n    min_step=1e-6,     # Minimum allowed step size\n    max_step=0.1,      # Maximum allowed step size\n    safety_factor=0.9  # Step size adjustment factor\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b47a67b"
  },
  {
    "id": "simulation_engine_api_reference_59_45c1f848",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 59,
    "code": "from src.simulation.integrators import IntegratorFactory\n\n# High-accuracy integration\ndp45 = IntegratorFactory.create_integrator(\n    'dp45',\n    dt=0.01,\n    atol=1e-8,   # Tight tolerance\n    rtol=1e-6\n)\n\n# Use with orchestrator\norchestrator = SequentialOrchestrator(dynamics, dp45)\nresult = orchestrator.execute(\n    initial_state=x0,\n    control_inputs=controls,\n    dt=0.01,  # Initial dt (will adapt)\n    horizon=1000\n)\n\n# Check integration statistics\nstats = dp45.get_statistics()\nprint(f\"Accepted steps: {stats['accepted_steps']}\")\nprint(f\"Rejected steps: {stats['rejected_steps']}\")\nprint(f\"Average step size: {stats['mean_step_size']:.4f}s\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45c1f848"
  },
  {
    "id": "simulation_engine_api_reference_60_ac266da3",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 60,
    "code": "u_held = u_n  # Control held constant\nx_{n+1} = x_n + dt * f(x_n, u_held, t_n)  # Euler step with held control",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac266da3"
  },
  {
    "id": "simulation_engine_api_reference_61_f21275bf",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 61,
    "code": "zoh = IntegratorFactory.create_integrator('zoh', dt=0.01)\n\n# Typical use with discrete controller\norchestrator = SequentialOrchestrator(dynamics, zoh)\nresult = orchestrator.execute(\n    initial_state=x0,\n    control_inputs=discrete_controls,  # Piecewise constant\n    dt=0.01,\n    horizon=500\n)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f21275bf"
  },
  {
    "id": "simulation_engine_api_reference_62_d3defb6a",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 62,
    "code": "# example-metadata:\n# runnable: false\n\nclass ResultContainer(ABC):\n    \"\"\"Base interface for simulation result containers.\"\"\"\n\n    @abstractmethod\n    def add_trajectory(self, states: np.ndarray, times: np.ndarray, **metadata) -> None:\n        \"\"\"Add a simulation trajectory to results.\"\"\"\n\n    @abstractmethod\n    def get_states(self) -> np.ndarray:\n        \"\"\"Get state trajectories.\"\"\"\n\n    @abstractmethod\n    def get_times(self) -> np.ndarray:\n        \"\"\"Get time vectors.\"\"\"\n\n    @abstractmethod\n    def export(self, format_type: str, filepath: str) -> None:\n        \"\"\"Export results to specified format.\"\"\"",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3defb6a"
  },
  {
    "id": "simulation_engine_api_reference_63_f4bbc031",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 63,
    "code": "self.states: Optional[np.ndarray]     # State trajectory (n_steps+1, state_dim)\nself.times: Optional[np.ndarray]      # Time vector (n_steps+1,)\nself.controls: Optional[np.ndarray]   # Control sequence (n_steps,)\nself.metadata: Dict[str, Any]         # Additional data",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4bbc031"
  },
  {
    "id": "simulation_engine_api_reference_64_e0221880",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 64,
    "code": "def add_trajectory(self, states: np.ndarray, times: np.ndarray, **metadata) -> None:\n    \"\"\"Add trajectory data to container.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0221880"
  },
  {
    "id": "simulation_engine_api_reference_65_92e76f93",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 65,
    "code": "def get_states(self) -> np.ndarray:\n    \"\"\"Get state trajectories.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92e76f93"
  },
  {
    "id": "simulation_engine_api_reference_66_63be60a4",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 66,
    "code": "def get_times(self) -> np.ndarray:\n    \"\"\"Get time vectors.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "63be60a4"
  },
  {
    "id": "simulation_engine_api_reference_67_99d11187",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 67,
    "code": "def export(self, format_type: str, filepath: str) -> None:\n    \"\"\"Export results to specified format.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "99d11187"
  },
  {
    "id": "simulation_engine_api_reference_68_bc4a7559",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 68,
    "code": "from src.simulation.results import StandardResultContainer\n\n# Create container\nresult = StandardResultContainer()\n\n# Add simulation data\nresult.add_trajectory(\n    states=x_arr,\n    times=t_arr,\n    controls=u_arr,\n    controller_type='classical_smc',\n    initial_state=x0\n)\n\n# Access data\nstates = result.get_states()  # (n_steps+1, 6)\ntimes = result.get_times()    # (n_steps+1,)\n\n# Export\nresult.export('csv', 'results/simulation_001.csv')\nresult.export('hdf5', 'results/simulation_001.h5')",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc4a7559"
  },
  {
    "id": "simulation_engine_api_reference_69_4241d477",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 69,
    "code": "self.batch_data: Dict[int, Dict[str, Any]]  # Indexed simulation data\nself.metadata: Dict[str, Any]               # Global metadata",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4241d477"
  },
  {
    "id": "simulation_engine_api_reference_70_065c0b8f",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 70,
    "code": "# example-metadata:\n# runnable: false\n\n{\n    0: {\n        'states': np.ndarray (n_steps+1, state_dim),\n        'times': np.ndarray (n_steps+1,),\n        'controls': np.ndarray (n_steps,),\n        'metadata': {...}\n    },\n    1: {...},\n    ...\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "065c0b8f"
  },
  {
    "id": "simulation_engine_api_reference_71_50f19b6b",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 71,
    "code": "def add_trajectory(self, states: np.ndarray, times: np.ndarray, **metadata) -> None:\n    \"\"\"Add trajectory data to batch container.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50f19b6b"
  },
  {
    "id": "simulation_engine_api_reference_72_8e993304",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 72,
    "code": "def get_states(self, batch_index: Optional[int] = None) -> np.ndarray:\n    \"\"\"Get state trajectories for specific batch or all batches.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e993304"
  },
  {
    "id": "simulation_engine_api_reference_73_ad36eb76",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 73,
    "code": "def get_times(self, batch_index: Optional[int] = None) -> np.ndarray:\n    \"\"\"Get time vectors for specific batch or all batches.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad36eb76"
  },
  {
    "id": "simulation_engine_api_reference_74_1666fe89",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 74,
    "code": "from src.simulation.results import BatchResultContainer\n\n# Create batch container\nbatch_result = BatchResultContainer()\n\n# Add multiple trajectories\nfor i in range(10):\n    batch_result.add_trajectory(\n        states=x_arr_list[i],\n        times=t_arr,\n        controls=u_arr_list[i],\n        batch_index=i,\n        initial_condition=ic_list[i]\n    )\n\n# Access specific trajectory\nstates_3 = batch_result.get_states(batch_index=3)  # (n_steps+1, 6)\n\n# Access all trajectories\nall_states = batch_result.get_states()  # (10, n_steps+1, 6)\n\n# Compute aggregate statistics\nsettling_times = []\nfor i in range(10):\n    states_i = batch_result.get_states(batch_index=i)\n    settling_times.append(compute_settling_time(states_i))\n\nmean_settling = np.mean(settling_times)",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1666fe89"
  },
  {
    "id": "simulation_engine_api_reference_75_f8ea011e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 75,
    "code": "result.export('csv', 'results/sim_001.csv')",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8ea011e"
  },
  {
    "id": "simulation_engine_api_reference_76_bfb48c6e",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 76,
    "code": "result.export('hdf5', 'results/sim_001.h5')\n\n# Load with h5py\nimport h5py\nwith h5py.File('results/sim_001.h5', 'r') as f:\n    states = f['states'][:]\n    times = f['times'][:]\n    metadata = dict(f.attrs)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfb48c6e"
  },
  {
    "id": "simulation_engine_api_reference_77_a0298382",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 77,
    "code": "def apply_safety_guards(state: np.ndarray, step_idx: int, config: Any) -> None:\n    \"\"\"Apply safety constraints to simulation state.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0298382"
  },
  {
    "id": "simulation_engine_api_reference_78_3aad3ceb",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 78,
    "code": "from src.simulation.safety import apply_safety_guards, SafetyViolationError\n\ntry:\n    apply_safety_guards(x_current, step_idx, config)\nexcept SafetyViolationError as e:\n    print(f\"Safety violation at step {step_idx}: {e}\")\n    # Truncate simulation",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3aad3ceb"
  },
  {
    "id": "simulation_engine_api_reference_79_783025d3",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 79,
    "code": "def _guard_no_nan(state: np.ndarray) -> None:\n    \"\"\"Check for NaN or Inf values.\"\"\"\n    if not np.all(np.isfinite(state)):\n        raise SafetyViolationError(\"State contains NaN or Inf\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "783025d3"
  },
  {
    "id": "simulation_engine_api_reference_80_8f15d151",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 80,
    "code": "def _guard_energy(state: np.ndarray, config: Any) -> None:\n    \"\"\"Check total energy within bounds.\"\"\"\n    E_kinetic = 0.5 * m * (x_dot**2 + theta1_dot**2 + theta2_dot**2)\n    E_potential = m * g * (L1 * cos(theta1) + L2 * cos(theta2))\n    E_total = E_kinetic + E_potential\n\n    if E_total > config.safety.max_energy:\n        raise SafetyViolationError(f\"Energy {E_total:.2f}J exceeds {config.safety.max_energy}J\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f15d151"
  },
  {
    "id": "simulation_engine_api_reference_81_20debf24",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 81,
    "code": "# example-metadata:\n# runnable: false\n\ndef _guard_bounds(state: np.ndarray, config: Any) -> None:\n    \"\"\"Check state within configured bounds.\"\"\"\n    bounds = config.safety.state_bounds  # [x_min, x_max, theta_min, theta_max, ...]\n\n    for i, (val, (min_val, max_val)) in enumerate(zip(state, bounds)):\n        if not (min_val <= val <= max_val):\n            raise SafetyViolationError(\n                f\"State[{i}] = {val:.3f} outside bounds [{min_val}, {max_val}]\"\n            )",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20debf24"
  },
  {
    "id": "simulation_engine_api_reference_82_7108b30b",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 82,
    "code": "# example-metadata:\n# runnable: false\n\nmonitor = PerformanceMonitor()\n\nmonitor.start_timing('simulation')\n# ... run simulation ...\nelapsed = monitor.end_timing('simulation')\n\nstats = monitor.get_statistics()\n# Returns:\n# {\n#     'simulation': {\n#         'count': 100,\n#         'total_time': 12.5,\n#         'mean_time': 0.125,\n#         'std_time': 0.015,\n#         'min_time': 0.110,\n#         'max_time': 0.180\n#     }\n# }",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7108b30b"
  },
  {
    "id": "simulation_engine_api_reference_83_78bd0cf4",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 83,
    "code": "# example-metadata:\n# runnable: false\n\nclass SequentialOrchestrator(BaseOrchestrator):\n    def execute(self, ...):\n        self.monitor.start_timing('orchestrator_execute')\n        # ... simulation loop ...\n        elapsed = self.monitor.end_timing('orchestrator_execute')\n        return result",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "78bd0cf4"
  },
  {
    "id": "simulation_engine_api_reference_84_bd076597",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 84,
    "code": "\"\"\"\nExample 1: Basic DIP Simulation\nDemonstrates standard workflow: load config \u2192 create controller \u2192 create dynamics \u2192 simulate \u2192 plot\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom src.config import load_config\nfrom src.controllers import create_controller\nfrom src.plant.models import LowRankDIPDynamics\nfrom src.simulation import run_simulation\n\n# ============================================================================\n# STEP 1: Load Configuration\n# ============================================================================\nconfig = load_config('config.yaml')\n\n# ============================================================================\n# STEP 2: Create Controller\n# ============================================================================\ncontroller = create_controller(\n    'classical_smc',\n    config=config,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0]  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n)\n\n# ============================================================================\n# STEP 3: Create Dynamics Model\n# ============================================================================\ndynamics = LowRankDIPDynamics(\n    config=config.plant,\n    enable_monitoring=True,\n    enable_validation=True\n)\n\n# ============================================================================\n# STEP 4: Run Simulation\n# ============================================================================\ninitial_state = np.array([\n    0.0,   # x: cart position\n    0.1,   # theta1: pole 1 angle (small perturbation)\n    0.1,   # theta2: pole 2 angle (small perturbation)\n    0.0,   # x_dot: cart velocity\n    0.0,   # theta1_dot: pole 1 angular velocity\n    0.0    # theta2_dot: pole 2 angular velocity\n])\n\nt, x, u = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,      # 5 seconds\n    dt=0.01,           # 10ms timestep\n    initial_state=initial_state,\n    u_max=100.0,       # 100N force limit\n    seed=42            # Reproducibility\n)\n\n# ============================================================================\n# STEP 5: Analyze Results\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"SIMULATION RESULTS\")\nprint(\"=\" * 70)\nprint(f\"Simulation steps: {len(t)-1}\")\nprint(f\"Final time: {t[-1]:.2f}s\")\nprint(f\"Final state: {x[-1]}\")\nprint(f\"Max control: {np.max(np.abs(u)):.2f}N\")\nprint(f\"Mean |control|: {np.mean(np.abs(u)):.2f}N\")\n\n# Compute performance metrics\nsettling_time_idx = np.where(np.all(np.abs(x[:, :3]) < 0.02, axis=1))[0]\nif len(settling_time_idx) > 0:\n    settling_time = t[settling_time_idx[0]]\n    print(f\"Settling time (2% threshold): {settling_time:.3f}s\")\n\n# ============================================================================\n# STEP 6: Plot Results\n# ============================================================================\nfig, axes = plt.subplots(4, 1, figsize=(10, 10))\n\n# Cart position\naxes[0].plot(t, x[:, 0], 'b-', linewidth=2)\naxes[0].set_ylabel('Cart Position (m)', fontsize=12)\naxes[0].grid(True, alpha=0.3)\naxes[0].axhline(0, color='r', linestyle='--', alpha=0.5)\n\n# Pole angles\naxes[1].plot(t, x[:, 1] * 180/np.pi, 'r-', linewidth=2, label='Pole 1')\naxes[1].plot(t, x[:, 2] * 180/np.pi, 'g-', linewidth=2, label='Pole 2')\naxes[1].set_ylabel('Angles (deg)', fontsize=12)\naxes[1].grid(True, alpha=0.3)\naxes[1].legend(loc='upper right')\naxes[1].axhline(0, color='k', linestyle='--', alpha=0.5)\n\n# Velocities\naxes[2].plot(t, x[:, 3], 'b-', linewidth=2, label='Cart')\naxes[2].plot(t, x[:, 4], 'r-', linewidth=2, label='Pole 1')\naxes[2].plot(t, x[:, 5], 'g-', linewidth=2, label='Pole 2')\naxes[2].set_ylabel('Velocities', fontsize=12)\naxes[2].grid(True, alpha=0.3)\naxes[2].legend(loc='upper right')\n\n# Control input\naxes[3].plot(t[:-1], u, 'm-', linewidth=2)\naxes[3].set_xlabel('Time (s)', fontsize=12)\naxes[3].set_ylabel('Control Force (N)', fontsize=12)\naxes[3].grid(True, alpha=0.3)\naxes[3].axhline(100, color='r', linestyle='--', alpha=0.5, label='Limit')\naxes[3].axhline(-100, color='r', linestyle='--', alpha=0.5)\naxes[3].legend(loc='upper right')\n\nplt.tight_layout()\nplt.savefig('results/basic_simulation.png', dpi=150)\nplt.show()\n\nprint(\"\\nPlot saved to: results/basic_simulation.png\")",
    "lines": 116,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd076597"
  },
  {
    "id": "simulation_engine_api_reference_85_94b2e28b",
    "file": "docs\\api\\simulation_engine_api_reference.md",
    "index": 85,
    "code": "\"\"\"\nExample 2: Batch Simulation for PSO Optimization\nDemonstrates vectorized batch execution for parameter optimization\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom functools import partial\nfrom src.config import load_config\nfrom src.controllers import create_controller\nfrom src.plant.models import LowRankDIPDynamics\nfrom src.simulation.orchestrators import BatchOrchestrator\nfrom src.simulation.integrators import IntegratorFactory\nfrom src.optimization import PSOTuner\n\n# ============================================================================\n# STEP 1: Configuration and Setup\n# ============================================================================\nconfig = load_config('config.yaml')\ndynamics = LowRankDIPDynamics(config.plant)\nintegrator = IntegratorFactory.create_integrator('rk4', dt=0.01)\n\n# ============================================================================\n# STEP 2: Define Controller Factory for PSO\n# ============================================================================\ndef controller_factory(gains):\n    \"\"\"Create controller instance with candidate gains.\"\"\"\n    return create_controller(\n        'classical_smc',\n        config=config,\n        gains=gains  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    )\n\n# ============================================================================\n# STEP 3: Define Fitness Function with Batch Execution\n# ============================================================================\ndef fitness_function(gains, n_trials=10):\n    \"\"\"\n    Evaluate controller gains using batch simulation.\n\n    Args:\n        gains: Controller gains to evaluate\n        n_trials: Number of Monte Carlo trials (different ICs)\n\n    Returns:\n        Fitness value (lower is better)\n    \"\"\"\n    # Create controller\n    controller = controller_factory(gains)\n\n    # Generate batch of initial conditions (small perturbations)\n    np.random.seed(42)  # Reproducibility\n    batch_initial = np.zeros((n_trials, 6))\n    batch_initial[:, 1] = np.random.uniform(0.05, 0.15, n_trials)  # theta1\n    batch_initial[:, 2] = np.random.uniform(0.05, 0.15, n_trials)  # theta2\n\n    # Precompute control sequence for all trials\n    horizon = 500\n    dt = 0.01\n    controls = np.zeros((n_trials, horizon))\n\n    # Temporary: compute control for each initial condition\n    # (In practice, use controller in orchestrator loop)\n    for i in range(n_trials):\n        x_temp = batch_initial[i]\n        for j in range(horizon):\n            controls[i, j] = controller(j * dt, x_temp)\n            # Simple Euler prediction for next control (approximation)\n            x_temp = x_temp + dt * np.array([\n                x_temp[3], x_temp[4], x_temp[5], 0, 0, 0\n            ])\n\n    # Execute batch simulation\n    orchestrator = BatchOrchestrator(dynamics, integrator)\n    result = orchestrator.execute(\n        initial_state=batch_initial,\n        control_inputs=controls,\n        dt=dt,\n        horizon=horizon,\n        safety_guards=True\n    )\n\n    # Compute fitness metrics\n    all_states = result.get_states()  # (n_trials, horizon+1, 6)\n\n    fitness_values = []\n    for i in range(n_trials):\n        states_i = all_states[i]  # (horizon+1, 6)\n\n        # Metric 1: Settling time (2% threshold)\n        settled_mask = np.all(np.abs(states_i[:, :3]) < 0.02, axis=1)\n        if np.any(settled_mask):\n            settling_idx = np.where(settled_mask)[0][0]\n            settling_time = settling_idx * dt\n        else:\n            settling_time = 5.0  # Penalty if never settled\n\n        # Metric 2: Peak overshoot\n        peak_overshoot = np.max(np.abs(states_i[:, :3]))\n\n        # Metric 3: Integral squared error\n        ise = np.sum(np.sum(states_i[:, :3]**2, axis=1)) * dt\n\n        # Combined fitness (weighted sum)\n        fitness_i = (\n            2.0 * settling_time +        # Weight settling time heavily\n            5.0 * peak_overshoot +        # Penalize overshoot\n            0.1 * ise                     # Penalize tracking error\n        )\n\n        fitness_values.append(fitness_i)\n\n    # Return mean fitness over all trials\n    return np.mean(fitness_values)\n\n# ============================================================================\n# STEP 4: Configure and Run PSO Optimization\n# ============================================================================\n# Define gain bounds for classical SMC\n# [k1, k2, \u03bb1, \u03bb2, K, kd]\nbounds = [\n    (1.0, 50.0),   # k1: position gain\n    (1.0, 40.0),   # k2: position damping\n    (1.0, 50.0),   # \u03bb1: angle gain 1\n    (1.0, 40.0),   # \u03bb2: angle gain 2\n    (10.0, 100.0), # K: switching gain\n    (0.1, 10.0)    # kd: derivative gain\n]\n\nprint(\"=\" * 70)\nprint(\"PSO OPTIMIZATION WITH BATCH SIMULATION\")\nprint(\"=\" * 70)\n\n# Create PSO tuner\ntuner = PSOTuner(\n    fitness_fn=partial(fitness_function, n_trials=10),\n    bounds=bounds,\n    swarm_size=20,\n    max_iter=50,\n    verbose=True\n)\n\n# Run optimization\nresult = tuner.optimise()\n\n# ============================================================================\n# STEP 5: Display Results\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"OPTIMIZATION RESULTS\")\nprint(\"=\" * 70)\nprint(f\"Best fitness: {result['best_fitness']:.4f}\")\nprint(f\"Best gains: {result['best_gains']}\")\nprint(f\"Convergence iteration: {result['convergence_iter']}\")\n\n# ============================================================================\n# STEP 6: Validate Optimal Gains\n# ============================================================================\noptimal_controller = controller_factory(result['best_gains'])\n\nfrom src.simulation import run_simulation\n\nt_val, x_val, u_val = run_simulation(\n    controller=optimal_controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=np.array([0, 0.1, 0.1, 0, 0, 0]),\n    u_max=100.0\n)\n\n# Plot validation\nfig, ax = plt.subplots(2, 1, figsize=(10, 8))\n\nax[0].plot(t_val, x_val[:, 1] * 180/np.pi, 'r-', label='Pole 1')\nax[0].plot(t_val, x_val[:, 2] * 180/np.pi, 'g-', label='Pole 2')\nax[0].set_ylabel('Angles (deg)')\nax[0].legend()\nax[0].grid(True)\nax[0].set_title('Optimal Controller Performance')\n\nax[1].plot(t_val[:-1], u_val, 'm-')\nax[1].set_xlabel('Time (s)')\nax[1].set_ylabel('Control (N)')\nax[1].grid(True)\n\nplt.tight_layout()\nplt.savefig('results/pso_batch_simulation.png', dpi=150)\nplt.show()\n\nprint(\"\\nValidation plot saved to: results/pso_batch_simulation.png\")",
    "lines": 191,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94b2e28b"
  },
  {
    "id": "controller_system_architecture_1_d88d758e",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Factory Registry Architecture\nclass ControllerRegistry:\n    \"\"\"Central registry for all SMC controller types.\"\"\"\n\n    _controllers: Dict[str, Type[ControllerInterface]] = {\n        'classical_smc': ClassicalSMC,\n        'adaptive_smc': AdaptiveSMC,\n        'sta_smc': STASMC,\n        'hybrid_adaptive_sta_smc': HybridAdaptiveSTASMC\n    }\n\n    @classmethod\n    def register_controller(cls, name: str, controller_class: Type[ControllerInterface]):\n        \"\"\"Register new controller type with validation.\"\"\"\n        if not issubclass(controller_class, ControllerInterface):\n            raise ValueError(f\"Controller {name} must implement ControllerInterface\")\n        cls._controllers[name] = controller_class\n\n    @classmethod\n    def get_controller_class(cls, name: str) -> Type[ControllerInterface]:\n        \"\"\"Retrieve controller class with validation.\"\"\"\n        if name not in cls._controllers:\n            raise ValueError(f\"Unknown controller type: {name}\")\n        return cls._controllers[name]",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d88d758e"
  },
  {
    "id": "controller_system_architecture_2_9bc7fd5a",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(\n    controller_type: str,\n    config: Optional[Dict[str, Any]] = None,\n    gains: Optional[List[float]] = None,\n    **kwargs\n) -> ControllerInterface:\n    \"\"\"\n    Universal controller factory with comprehensive validation.\n\n    This factory method serves as the single entry point for all controller\n    instantiation, providing type safety, configuration validation, and\n    standardized error handling across all SMC variants.\n    \"\"\"\n\n    # Step 1: Validate controller type\n    if controller_type not in SUPPORTED_CONTROLLERS:\n        raise ValueError(f\"Unsupported controller: {controller_type}\")\n\n    # Step 2: Load and validate configuration\n    controller_config = _prepare_controller_config(controller_type, config, **kwargs)\n\n    # Step 3: Validate and apply gains\n    if gains is not None:\n        _validate_gains(controller_type, gains)\n        controller_config = _apply_gains_to_config(controller_type, controller_config, gains)\n\n    # Step 4: Instantiate controller with error handling\n    try:\n        controller_class = ControllerRegistry.get_controller_class(controller_type)\n        controller = controller_class(**controller_config)\n\n        # Step 5: Post-instantiation validation\n        _validate_controller_interface(controller, controller_type)\n\n        return controller\n\n    except Exception as e:\n        raise ControllerCreationError(\n            f\"Failed to create {controller_type} controller: {str(e)}\"\n        ) from e",
    "lines": 43,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bc7fd5a"
  },
  {
    "id": "controller_system_architecture_3_5253b263",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationBridge:\n    \"\"\"Bridge between YAML configuration and controller parameters.\"\"\"\n\n    @staticmethod\n    def map_config_to_controller(\n        controller_type: str,\n        config: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Map generic configuration to controller-specific parameters.\"\"\"\n\n        mapping_strategies = {\n            'classical_smc': ClassicalSMCConfigMapper,\n            'adaptive_smc': AdaptiveSMCConfigMapper,\n            'sta_smc': STASMCConfigMapper,\n            'hybrid_adaptive_sta_smc': HybridSMCConfigMapper\n        }\n\n        mapper = mapping_strategies.get(controller_type)\n        if not mapper:\n            raise ValueError(f\"No configuration mapper for {controller_type}\")\n\n        return mapper.map_config(config)",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5253b263"
  },
  {
    "id": "controller_system_architecture_4_06898109",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass TypeSafetyValidator:\n    \"\"\"Comprehensive type safety validation for controller interfaces.\"\"\"\n\n    @staticmethod\n    def validate_controller_interface(\n        controller: Any,\n        expected_type: str\n    ) -> None:\n        \"\"\"Validate controller implements required interface.\"\"\"\n\n        required_methods = ['compute_control', 'reset', 'initialize_state']\n\n        for method_name in required_methods:\n            if not hasattr(controller, method_name):\n                raise InterfaceError(\n                    f\"{expected_type} missing required method: {method_name}\"\n                )\n\n            method = getattr(controller, method_name)\n            if not callable(method):\n                raise InterfaceError(\n                    f\"{expected_type}.{method_name} is not callable\"\n                )\n\n    @staticmethod\n    def validate_control_output(\n        output: Any,\n        controller_type: str\n    ) -> None:\n        \"\"\"Validate controller output structure and types.\"\"\"\n\n        if output is None:\n            raise ControllerError(f\"{controller_type} returned None\")\n\n        # Type-specific validation based on expected output structure\n        expected_attributes = ['control', 'state_vars', 'history']\n\n        for attr in expected_attributes:\n            if not hasattr(output, attr):\n                raise ControllerError(\n                    f\"{controller_type} output missing attribute: {attr}\"\n                )",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06898109"
  },
  {
    "id": "controller_system_architecture_5_68a76da4",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOOptimizer:\n    \"\"\"\n    Universal PSO optimizer for all SMC controller types.\n\n    Provides consistent optimization interface with controller-specific\n    fitness functions, boundary handling, and convergence criteria.\n    \"\"\"\n\n    def __init__(\n        self,\n        controller_type: str,\n        config: Dict[str, Any],\n        dynamics_config: Dict[str, Any]\n    ):\n        self.controller_type = controller_type\n        self.bounds = self._get_controller_bounds(controller_type)\n        self.fitness_evaluator = self._create_fitness_evaluator(\n            controller_type, config, dynamics_config\n        )\n\n    def optimize(\n        self,\n        n_particles: int = 30,\n        max_iterations: int = 100,\n        convergence_threshold: float = 1e-6\n    ) -> OptimizationResult:\n        \"\"\"Run PSO optimization with adaptive parameters.\"\"\"\n\n        # Initialize swarm with controller-specific bounds\n        swarm = self._initialize_swarm(n_particles)\n\n        # PSO main loop with adaptive parameters\n        for iteration in range(max_iterations):\n            # Evaluate fitness for all particles\n            fitness_values = self._evaluate_population(swarm)\n\n            # Update global and personal bests\n            self._update_bests(swarm, fitness_values)\n\n            # Check convergence\n            if self._check_convergence(fitness_values, convergence_threshold):\n                break\n\n            # Update particle velocities and positions\n            self._update_swarm(swarm, iteration, max_iterations)\n\n        return self._create_optimization_result(swarm, iteration)",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68a76da4"
  },
  {
    "id": "controller_system_architecture_6_9441c282",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass FitnessEvaluator:\n    \"\"\"Controller-specific fitness evaluation strategies.\"\"\"\n\n    def __init__(self, controller_type: str, config: Dict[str, Any]):\n        self.controller_type = controller_type\n        self.config = config\n        self.dynamics = self._create_dynamics(config['dynamics'])\n\n    def evaluate_fitness(self, gains: List[float]) -> float:\n        \"\"\"Evaluate controller performance with given gains.\"\"\"\n\n        try:\n            # Create controller with candidate gains\n            controller = create_controller(\n                self.controller_type,\n                config=self.config,\n                gains=gains\n            )\n\n            # Run simulation\n            simulation_result = self._run_simulation(controller)\n\n            # Compute comprehensive fitness\n            fitness = self._compute_fitness_score(simulation_result)\n\n            return fitness\n\n        except Exception as e:\n            # Penalty for invalid configurations\n            return 1e6  # Large penalty value\n\n    def _compute_fitness_score(self, result: SimulationResult) -> float:\n        \"\"\"Compute multi-objective fitness score.\"\"\"\n\n        # Weighted combination of performance metrics\n        weights = {\n            'angle_error': 0.4,      # Pendulum stabilization\n            'position_error': 0.2,   # Cart positioning\n            'control_effort': 0.2,   # Energy efficiency\n            'settling_time': 0.1,    # Response speed\n            'overshoot': 0.1        # Stability margin\n        }\n\n        metrics = self._extract_performance_metrics(result)\n\n        fitness = sum(\n            weights[metric] * self._normalize_metric(metric, value)\n            for metric, value in metrics.items()\n        )\n\n        return fitness",
    "lines": 54,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9441c282"
  },
  {
    "id": "controller_system_architecture_7_dcf2c676",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizationPipeline:\n    \"\"\"End-to-end optimization pipeline for SMC controllers.\"\"\"\n\n    def run_optimization_workflow(\n        self,\n        controller_type: str,\n        base_config: Dict[str, Any],\n        optimization_config: Dict[str, Any]\n    ) -> OptimizationWorkflowResult:\n        \"\"\"Execute complete optimization workflow.\"\"\"\n\n        # Phase 1: Preprocessing\n        config = self._prepare_optimization_config(base_config, optimization_config)\n        bounds = self._get_parameter_bounds(controller_type)\n\n        # Phase 2: PSO Optimization\n        optimizer = PSOOptimizer(controller_type, config, config['dynamics'])\n        optimization_result = optimizer.optimize(\n            n_particles=optimization_config.get('n_particles', 30),\n            max_iterations=optimization_config.get('max_iterations', 100),\n            convergence_threshold=optimization_config.get('convergence_threshold', 1e-6)\n        )\n\n        # Phase 3: Validation\n        validation_result = self._validate_optimized_controller(\n            controller_type, optimization_result.best_gains, config\n        )\n\n        # Phase 4: Result Packaging\n        workflow_result = OptimizationWorkflowResult(\n            controller_type=controller_type,\n            optimization_result=optimization_result,\n            validation_result=validation_result,\n            optimized_gains=optimization_result.best_gains,\n            final_cost=optimization_result.best_cost\n        )\n\n        return workflow_result",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcf2c676"
  },
  {
    "id": "controller_system_architecture_8_59cf96b9",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerInterface(Protocol):\n    \"\"\"Standardized interface for all SMC controllers.\"\"\"\n\n    def compute_control(\n        self,\n        state: np.ndarray,\n        state_vars: Optional[Tuple[float, ...]] = None,\n        history: Optional[Dict[str, List[Any]]] = None\n    ) -> ControllerOutput:\n        \"\"\"\n        Compute control action for given state.\n\n        Args:\n            state: System state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n            state_vars: Controller internal state variables\n            history: Control history for logging and analysis\n\n        Returns:\n            ControllerOutput: Named tuple with control, state_vars, history\n        \"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller to initial state.\"\"\"\n        ...\n\n    def initialize_state(self) -> Tuple[float, ...]:\n        \"\"\"Initialize controller state variables.\"\"\"\n        ...",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59cf96b9"
  },
  {
    "id": "controller_system_architecture_9_ccda8d44",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass ConfigurationInterface:\n    \"\"\"Standardized configuration management across all components.\"\"\"\n\n    @classmethod\n    def load_config(\n        cls,\n        config_path: str,\n        schema_validation: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"Load and validate configuration from YAML file.\"\"\"\n\n        with open(config_path, 'r') as f:\n            config = yaml.safe_load(f)\n\n        if schema_validation:\n            cls._validate_schema(config)\n\n        return config\n\n    @classmethod\n    def _validate_schema(cls, config: Dict[str, Any]) -> None:\n        \"\"\"Validate configuration against schema.\"\"\"\n\n        # Pydantic model validation\n        try:\n            ConfigModel(**config)\n        except ValidationError as e:\n            raise ConfigurationError(f\"Invalid configuration: {e}\")",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccda8d44"
  },
  {
    "id": "controller_system_architecture_10_68284d64",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass ErrorHandlingFramework:\n    \"\"\"Comprehensive error handling with recovery strategies.\"\"\"\n\n    @staticmethod\n    def handle_controller_error(\n        error: Exception,\n        controller_type: str,\n        context: Dict[str, Any]\n    ) -> ControllerErrorResult:\n        \"\"\"Handle controller-specific errors with recovery.\"\"\"\n\n        if isinstance(error, ControllerCreationError):\n            return ErrorHandlingFramework._handle_creation_error(\n                error, controller_type, context\n            )\n        elif isinstance(error, ComputationError):\n            return ErrorHandlingFramework._handle_computation_error(\n                error, controller_type, context\n            )\n        elif isinstance(error, ConfigurationError):\n            return ErrorHandlingFramework._handle_configuration_error(\n                error, controller_type, context\n            )\n        else:\n            return ErrorHandlingFramework._handle_unknown_error(\n                error, controller_type, context\n            )\n\n    @staticmethod\n    def _handle_creation_error(\n        error: ControllerCreationError,\n        controller_type: str,\n        context: Dict[str, Any]\n    ) -> ControllerErrorResult:\n        \"\"\"Handle controller creation failures with fallback.\"\"\"\n\n        # Attempt fallback to default configuration\n        try:\n            fallback_config = DefaultConfigurations.get_config(controller_type)\n            fallback_controller = create_controller(controller_type, fallback_config)\n\n            return ControllerErrorResult(\n                success=True,\n                controller=fallback_controller,\n                error_type='creation_error_recovered',\n                recovery_action='fallback_to_default_config'\n            )\n\n        except Exception as fallback_error:\n            return ControllerErrorResult(\n                success=False,\n                error_type='creation_error_unrecoverable',\n                original_error=error,\n                fallback_error=fallback_error\n            )",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68284d64"
  },
  {
    "id": "controller_system_architecture_11_84e9452a",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass GracefulDegradationManager:\n    \"\"\"Manage system degradation under error conditions.\"\"\"\n\n    @staticmethod\n    def handle_controller_failure(\n        failed_controller: str,\n        available_controllers: List[str]\n    ) -> DegradationStrategy:\n        \"\"\"Determine graceful degradation strategy.\"\"\"\n\n        # Preference order for fallback controllers\n        fallback_preferences = {\n            'hybrid_adaptive_sta_smc': ['sta_smc', 'adaptive_smc', 'classical_smc'],\n            'sta_smc': ['classical_smc', 'adaptive_smc'],\n            'adaptive_smc': ['classical_smc', 'sta_smc'],\n            'classical_smc': ['adaptive_smc', 'sta_smc']\n        }\n\n        preferences = fallback_preferences.get(failed_controller, [])\n\n        for fallback in preferences:\n            if fallback in available_controllers:\n                return DegradationStrategy(\n                    fallback_controller=fallback,\n                    degradation_level='graceful',\n                    performance_impact='minimal'\n                )\n\n        # No suitable fallback available\n        return DegradationStrategy(\n            fallback_controller=None,\n            degradation_level='critical',\n            performance_impact='severe'\n        )",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84e9452a"
  },
  {
    "id": "controller_system_architecture_12_dbeca445",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Primary Control Flow\ndef control_loop_data_flow():\n    \"\"\"\n    Illustrates the complete data flow through the control system.\n\n    1. Sensor Input \u2192 State Vector\n    2. State Vector \u2192 Controller\n    3. Controller \u2192 Control Action\n    4. Control Action \u2192 Plant/Simulator\n    5. Plant Response \u2192 New State\n    6. Loop Continuation with History Updates\n    \"\"\"\n\n    # Step 1: State Acquisition\n    current_state = sensor_interface.get_state()  # [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n\n    # Step 2: Controller Computation\n    control_output = controller.compute_control(\n        state=current_state,\n        state_vars=previous_state_vars,\n        history=control_history\n    )\n\n    # Step 3: Control Application\n    actuator_command = control_output.control\n    plant_response = plant.apply_control(actuator_command, current_state)\n\n    # Step 4: State Update\n    next_state = plant_response.next_state\n\n    # Step 5: History Management\n    control_history = control_output.history\n    previous_state_vars = control_output.state_vars\n\n    # Step 6: Monitoring and Logging\n    monitor.log_control_cycle(\n        state=current_state,\n        control=actuator_command,\n        performance=plant_response.performance_metrics\n    )\n\n    return next_state, control_history, previous_state_vars",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbeca445"
  },
  {
    "id": "controller_system_architecture_13_e3db1f69",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef pso_optimization_data_flow():\n    \"\"\"\n    Data flow through PSO optimization process.\n\n    1. Parameter Bounds \u2192 Swarm Initialization\n    2. Swarm Positions \u2192 Controller Instances\n    3. Controller Performance \u2192 Fitness Evaluation\n    4. Fitness Values \u2192 Swarm Updates\n    5. Convergence Check \u2192 Result Extraction\n    \"\"\"\n\n    # Step 1: Swarm Initialization\n    parameter_bounds = get_controller_bounds(controller_type)\n    swarm_positions = initialize_swarm(n_particles, parameter_bounds)\n\n    # Step 2: Parallel Fitness Evaluation\n    fitness_results = []\n    for particle_position in swarm_positions:\n        # Create controller with candidate parameters\n        candidate_controller = create_controller(controller_type, gains=particle_position)\n\n        # Evaluate performance\n        simulation_result = run_simulation(candidate_controller)\n        fitness_score = compute_fitness(simulation_result)\n        fitness_results.append(fitness_score)\n\n    # Step 3: Swarm Update\n    updated_swarm = update_swarm_velocities_and_positions(\n        swarm_positions,\n        fitness_results,\n        global_best,\n        personal_bests\n    )\n\n    # Step 4: Convergence Analysis\n    convergence_status = analyze_convergence(fitness_results, convergence_criteria)\n\n    # Step 5: Result Packaging\n    optimization_result = OptimizationResult(\n        best_gains=global_best.position,\n        best_cost=global_best.fitness,\n        convergence_iterations=current_iteration,\n        convergence_status=convergence_status\n    )\n\n    return optimization_result",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3db1f69"
  },
  {
    "id": "controller_system_architecture_14_2baf61a6",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 14,
    "code": "from numba import jit, prange\nimport numpy as np\n\nclass PerformanceOptimizedController:\n    \"\"\"Performance-optimized controller with Numba acceleration.\"\"\"\n\n    @staticmethod\n    @jit(nopython=True, cache=True)\n    def compute_sliding_surface_numba(\n        state: np.ndarray,\n        gains: np.ndarray\n    ) -> float:\n        \"\"\"Numba-accelerated sliding surface computation.\"\"\"\n\n        # Extract state components\n        theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state\n        lambda1, lambda2, c1, c2, kc, lambda_c = gains\n\n        # Compute sliding surface\n        s = (lambda1 * theta1_dot + c1 * theta1 +\n             lambda2 * theta2_dot + c2 * theta2 +\n             kc * (x_dot + lambda_c * x))\n\n        return s\n\n    @staticmethod\n    @jit(nopython=True, cache=True)\n    def batch_control_computation(\n        states: np.ndarray,\n        gains: np.ndarray,\n        controller_params: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"Vectorized control computation for batch processing.\"\"\"\n\n        n_samples = states.shape[0]\n        controls = np.zeros(n_samples)\n\n        for i in prange(n_samples):\n            controls[i] = compute_control_single(states[i], gains, controller_params)\n\n        return controls",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2baf61a6"
  },
  {
    "id": "controller_system_architecture_15_6539387d",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass MemoryEfficientController:\n    \"\"\"Memory-efficient controller with bounded collections.\"\"\"\n\n    def __init__(self, max_history_size: int = 10000):\n        self.max_history_size = max_history_size\n        self._history_buffer = collections.deque(maxlen=max_history_size)\n\n    def update_history(self, control_data: Dict[str, Any]) -> None:\n        \"\"\"Update history with automatic memory management.\"\"\"\n\n        # Add new data point\n        self._history_buffer.append(control_data)\n\n        # Automatic cleanup if buffer full\n        if len(self._history_buffer) >= self.max_history_size:\n            # Optionally compress older data\n            self._compress_old_history()\n\n    def _compress_old_history(self) -> None:\n        \"\"\"Compress older history data to save memory.\"\"\"\n\n        # Keep recent data at full resolution\n        recent_data = list(self._history_buffer)[-1000:]\n\n        # Subsample older data\n        old_data = list(self._history_buffer)[:-1000]\n        subsampled_old = old_data[::10]  # Keep every 10th point\n\n        # Rebuild buffer\n        self._history_buffer.clear()\n        self._history_buffer.extend(subsampled_old + recent_data)",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6539387d"
  },
  {
    "id": "controller_system_architecture_16_487782f2",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass DistributedControllerManager:\n    \"\"\"Manager for distributed controller deployment.\"\"\"\n\n    def __init__(self, cluster_config: Dict[str, Any]):\n        self.cluster_config = cluster_config\n        self.controller_pool = self._initialize_controller_pool()\n\n    def distribute_optimization(\n        self,\n        controller_type: str,\n        optimization_config: Dict[str, Any],\n        n_workers: int = 4\n    ) -> DistributedOptimizationResult:\n        \"\"\"Distribute PSO optimization across multiple workers.\"\"\"\n\n        # Split swarm across workers\n        particles_per_worker = optimization_config['n_particles'] // n_workers\n\n        worker_tasks = []\n        for worker_id in range(n_workers):\n            worker_task = WorkerOptimizationTask(\n                worker_id=worker_id,\n                controller_type=controller_type,\n                particles=particles_per_worker,\n                config=optimization_config\n            )\n            worker_tasks.append(worker_task)\n\n        # Execute distributed optimization\n        worker_results = self._execute_parallel_optimization(worker_tasks)\n\n        # Aggregate results\n        best_result = self._aggregate_worker_results(worker_results)\n\n        return DistributedOptimizationResult(\n            best_gains=best_result.gains,\n            best_cost=best_result.cost,\n            worker_results=worker_results,\n            total_evaluations=sum(r.evaluations for r in worker_results)\n        )",
    "lines": 43,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "487782f2"
  },
  {
    "id": "controller_system_architecture_17_8aaf9d88",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nclass SafetyManager:\n    \"\"\"Comprehensive safety management for control systems.\"\"\"\n\n    def __init__(self, safety_config: Dict[str, Any]):\n        self.safety_limits = safety_config['limits']\n        self.emergency_procedures = safety_config['emergency_procedures']\n\n    def validate_control_safety(\n        self,\n        control_action: float,\n        system_state: np.ndarray,\n        controller_type: str\n    ) -> SafetyValidationResult:\n        \"\"\"Validate control action against safety constraints.\"\"\"\n\n        safety_violations = []\n\n        # Check control force limits\n        if abs(control_action) > self.safety_limits['max_force']:\n            safety_violations.append(\n                SafetyViolation(\n                    type='control_force_limit',\n                    severity='critical',\n                    value=control_action,\n                    limit=self.safety_limits['max_force']\n                )\n            )\n\n        # Check system state limits\n        angles = system_state[:2]  # \u03b8\u2081, \u03b8\u2082\n        if np.any(np.abs(angles) > self.safety_limits['max_angle']):\n            safety_violations.append(\n                SafetyViolation(\n                    type='angle_limit',\n                    severity='warning',\n                    value=angles,\n                    limit=self.safety_limits['max_angle']\n                )\n            )\n\n        # Determine safety status\n        if any(v.severity == 'critical' for v in safety_violations):\n            safety_status = 'unsafe'\n            recommended_action = 'emergency_stop'\n        elif safety_violations:\n            safety_status = 'warning'\n            recommended_action = 'apply_safety_filter'\n        else:\n            safety_status = 'safe'\n            recommended_action = 'proceed'\n\n        return SafetyValidationResult(\n            status=safety_status,\n            violations=safety_violations,\n            recommended_action=recommended_action\n        )\n\n    def apply_safety_filter(\n        self,\n        control_action: float,\n        system_state: np.ndarray\n    ) -> float:\n        \"\"\"Apply safety filter to control action.\"\"\"\n\n        # Clamp control force to safe limits\n        safe_control = np.clip(\n            control_action,\n            -self.safety_limits['max_force'],\n            self.safety_limits['max_force']\n        )\n\n        # Additional state-dependent safety modifications\n        angles = system_state[:2]\n        if np.any(np.abs(angles) > self.safety_limits['warning_angle']):\n            # Reduce control authority near angle limits\n            safety_factor = 0.7\n            safe_control *= safety_factor\n\n        return safe_control",
    "lines": 82,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8aaf9d88"
  },
  {
    "id": "controller_system_architecture_18_60ff2f8a",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nclass SecurityManager:\n    \"\"\"Security management for production deployment.\"\"\"\n\n    @staticmethod\n    def validate_configuration_integrity(config_path: str) -> bool:\n        \"\"\"Validate configuration file integrity.\"\"\"\n\n        # Check file permissions\n        file_stat = os.stat(config_path)\n        if file_stat.st_mode & 0o077:  # Check for world/group writable\n            raise SecurityError(\"Configuration file has insecure permissions\")\n\n        # Validate configuration content\n        with open(config_path, 'r') as f:\n            config_content = f.read()\n\n        # Check for suspicious content\n        suspicious_patterns = [\n            r'import\\s+os',\n            r'exec\\s*\\(',\n            r'eval\\s*\\(',\n            r'__import__',\n            r'subprocess'\n        ]\n\n        for pattern in suspicious_patterns:\n            if re.search(pattern, config_content):\n                raise SecurityError(f\"Suspicious pattern found in config: {pattern}\")\n\n        return True\n\n    @staticmethod\n    def sanitize_user_input(user_input: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Sanitize user input to prevent injection attacks.\"\"\"\n\n        sanitized = {}\n\n        for key, value in user_input.items():\n            # Validate key names\n            if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', key):\n                raise SecurityError(f\"Invalid parameter name: {key}\")\n\n            # Sanitize values based on type\n            if isinstance(value, str):\n                # Remove potentially dangerous characters\n                sanitized_value = re.sub(r'[<>\\\"\\'&]', '', value)\n                sanitized[key] = sanitized_value\n            elif isinstance(value, (int, float)):\n                # Validate numeric ranges\n                if abs(value) > 1e6:  # Reasonable upper bound\n                    raise SecurityError(f\"Numeric value out of range: {value}\")\n                sanitized[key] = value\n            else:\n                sanitized[key] = value\n\n        return sanitized",
    "lines": 59,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60ff2f8a"
  },
  {
    "id": "controller_system_architecture_19_06225691",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nclass SystemMonitor:\n    \"\"\"Comprehensive system monitoring and observability.\"\"\"\n\n    def __init__(self, monitoring_config: Dict[str, Any]):\n        self.metrics_collector = MetricsCollector(monitoring_config)\n        self.health_checker = HealthChecker(monitoring_config)\n        self.alert_manager = AlertManager(monitoring_config)\n\n    def monitor_control_loop(\n        self,\n        control_cycle_data: ControlCycleData\n    ) -> MonitoringReport:\n        \"\"\"Monitor single control loop execution.\"\"\"\n\n        # Collect performance metrics\n        metrics = self.metrics_collector.collect_cycle_metrics(control_cycle_data)\n\n        # Assess system health\n        health_status = self.health_checker.assess_health(metrics)\n\n        # Check for alert conditions\n        alerts = self.alert_manager.check_alerts(metrics, health_status)\n\n        # Create monitoring report\n        report = MonitoringReport(\n            timestamp=time.time(),\n            metrics=metrics,\n            health_status=health_status,\n            alerts=alerts,\n            cycle_data=control_cycle_data\n        )\n\n        return report\n\nclass MetricsCollector:\n    \"\"\"Collect and aggregate performance metrics.\"\"\"\n\n    def collect_cycle_metrics(\n        self,\n        cycle_data: ControlCycleData\n    ) -> PerformanceMetrics:\n        \"\"\"Collect metrics for single control cycle.\"\"\"\n\n        return PerformanceMetrics(\n            # Control Performance\n            control_effort=abs(cycle_data.control_action),\n            settling_error=self._compute_settling_error(cycle_data.state),\n            overshoot=self._compute_overshoot(cycle_data.state_history),\n\n            # Computational Performance\n            computation_time=cycle_data.computation_time,\n            memory_usage=self._get_memory_usage(),\n            cpu_utilization=self._get_cpu_utilization(),\n\n            # System Health\n            numerical_stability=self._check_numerical_stability(cycle_data),\n            error_rate=self._compute_error_rate(),\n\n            # Controller-Specific Metrics\n            controller_health=self._assess_controller_health(cycle_data.controller_output)\n        )",
    "lines": 64,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06225691"
  },
  {
    "id": "controller_system_architecture_20_9a074539",
    "file": "docs\\architecture\\controller_system_architecture.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\nclass PerformanceAnalyzer:\n    \"\"\"Advanced performance analysis and trend detection.\"\"\"\n\n    def analyze_system_performance(\n        self,\n        monitoring_history: List[MonitoringReport],\n        analysis_window: int = 1000\n    ) -> PerformanceAnalysisReport:\n        \"\"\"Analyze system performance trends and patterns.\"\"\"\n\n        recent_reports = monitoring_history[-analysis_window:]\n\n        # Trend Analysis\n        control_performance_trend = self._analyze_control_trend(recent_reports)\n        computational_trend = self._analyze_computational_trend(recent_reports)\n        stability_trend = self._analyze_stability_trend(recent_reports)\n\n        # Anomaly Detection\n        anomalies = self._detect_anomalies(recent_reports)\n\n        # Performance Regression Detection\n        regressions = self._detect_performance_regressions(recent_reports)\n\n        # Optimization Recommendations\n        recommendations = self._generate_optimization_recommendations(\n            control_performance_trend,\n            computational_trend,\n            stability_trend\n        )\n\n        return PerformanceAnalysisReport(\n            analysis_period=analysis_window,\n            control_trend=control_performance_trend,\n            computational_trend=computational_trend,\n            stability_trend=stability_trend,\n            anomalies=anomalies,\n            regressions=regressions,\n            recommendations=recommendations\n        )",
    "lines": 42,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a074539"
  },
  {
    "id": "controller_performance_benchmarks_1_e136e159",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 1,
    "code": "# Old API (used in benchmark script)\ndynamics = SimplifiedDIPDynamics()\n\n# New API (required after refactoring)\nfrom src.plant.configurations import DIPConfig\ndynamics = SimplifiedDIPDynamics(config=DIPConfig())",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e136e159"
  },
  {
    "id": "controller_performance_benchmarks_2_cda12e3d",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 2,
    "code": "from src.plant.configurations import DIPConfig\n\n# Initialize dynamics with config\nconfig = DIPConfig()  # Uses default parameters\ndynamics = SimplifiedDIPDynamics(config=config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cda12e3d"
  },
  {
    "id": "controller_performance_benchmarks_3_f9757e22",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 3,
    "code": "import pandas as pd\n\n# Load performance data\ndf = pd.read_csv('controller_performance_summary.csv')\n\n# Find fastest computation\nfastest = df.loc[df['computation_avg'].idxmin()]\nprint(f\"Fastest controller: {fastest['controller']} ({fastest['computation_avg']:.4f} ms)\")\n\n# Compare Classical vs Hybrid\nclassical = df[df['controller'] == 'classical_smc'].iloc[0]\nhybrid = df[df['controller'] == 'hybrid_adaptive_sta_smc'].iloc[0]\nspeedup = hybrid['computation_avg'] / classical['computation_avg']\nprint(f\"Classical is {speedup:.1f}\u00d7 faster than Hybrid\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9757e22"
  },
  {
    "id": "controller_performance_benchmarks_4_5ee1c014",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 4,
    "code": "import time\n\ndef measure_instantiation(controller_class, gains, n_samples=5):\n    times = []\n    for _ in range(n_samples):\n        t0 = time.perf_counter()\n        controller = controller_class(gains=gains, max_force=100.0)\n        t1 = time.perf_counter()\n        times.append((t1 - t0) * 1000)  # Convert to milliseconds\n    return {\n        'avg_time_ms': np.mean(times),\n        'std_time_ms': np.std(times),\n        'p95_time_ms': np.percentile(times, 95)\n    }",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ee1c014"
  },
  {
    "id": "controller_performance_benchmarks_5_e08f28bc",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef measure_computation(controller, state, n_samples=100):\n    times = []\n    for _ in range(n_samples):\n        t0 = time.perf_counter()\n        control = controller.compute_control(state)\n        t1 = time.perf_counter()\n        times.append((t1 - t0) * 1000)\n    return {\n        'avg_time_ms': np.mean(times),\n        'p95_time_ms': np.percentile(times, 95)\n    }",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e08f28bc"
  },
  {
    "id": "controller_performance_benchmarks_6_91739d01",
    "file": "docs\\benchmarks\\controller_performance_benchmarks.md",
    "index": 6,
    "code": "import threading\n\ndef thread_safety_test(controller_class, gains, n_threads=4, n_ops_per_thread=100):\n    errors = []\n\n    def worker():\n        try:\n            controller = controller_class(gains=gains)\n            state = np.zeros(6)\n            for _ in range(n_ops_per_thread):\n                _ = controller.compute_control(state)\n        except Exception as e:\n            errors.append(str(e))\n\n    threads = [threading.Thread(target=worker) for _ in range(n_threads)]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n\n    return {\n        'total_threads': n_threads,\n        'successful_threads': n_threads - len(errors),\n        'failed_threads': len(errors),\n        'success_rate': (n_threads - len(errors)) / n_threads,\n        'errors': errors\n    }",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91739d01"
  },
  {
    "id": "phase_3_2_completion_report_1_57bd28af",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Data Loading (2 functions)\nload_json_safe()                     # Safe JSON loading with error handling\nconvert_to_json_serializable()       # NumPy/Pandas to JSON type converter\n\n# Data Parsing (4 functions)\nparse_controller_performance()       # Main controller metrics parser\nparse_pso_sensitivity()              # PSO parameter sensitivity parser\nparse_numerical_stability()          # Matrix regularization metrics parser\nparse_control_accuracy()             # Control accuracy parser (handles failures)\n\n# Statistical Analysis (3 functions)\ncompute_settling_time_stats()        # Settling time with 95% CI\nperform_anova_test()                 # One-way ANOVA for controller comparison\ncompute_pairwise_ttests()            # Welch's t-tests for pairwise comparison\n\n# Chart.js Generation (5 functions)\ngenerate_settling_time_chart()       # Bar chart with error bars\ngenerate_computational_efficiency_chart()  # Grouped bar chart\ngenerate_stability_scores_chart()    # Radar chart\ngenerate_pso_sensitivity_heatmap()   # Sensitivity bar chart\ngenerate_overshoot_analysis_chart()  # Box plot\n\n# Main Execution (1 function)\nmain()                               # Orchestration workflow",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57bd28af"
  },
  {
    "id": "phase_3_2_completion_report_2_8780d873",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 2,
    "code": "# Update benchmarks/scripts/control_accuracy_benchmark.py\n\nfrom src.plant.configurations import DIPConfig\n\n# OLD (broken):\n# dynamics = SimplifiedDIPDynamics()\n\n# NEW (correct):\nconfig = DIPConfig()\ndynamics = SimplifiedDIPDynamics(config=config)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8780d873"
  },
  {
    "id": "phase_3_2_completion_report_3_2deb8dd3",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 3,
    "code": "# Option 1: Add property to HybridSMCConfig\n@property\ndef gains(self):\n    return np.concatenate([self.classical_gains, self.sta_gains, [self.adaptation_rate]])\n\n# Option 2: Update validation script to handle nested configs\nif hasattr(config, 'gains'):\n    gains = config.gains\nelif hasattr(config, 'classical_gains'):\n    gains = np.concatenate([config.classical_gains, config.sta_gains, [config.adaptation_rate]])",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2deb8dd3"
  },
  {
    "id": "phase_3_2_completion_report_4_f1485d06",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 4,
    "code": "from src.controllers.classic_smc import ClassicalSMC\n\n# Optimized gains (from PSO validation)\ncontroller = ClassicalSMC(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01  # Tune to balance tracking vs chattering\n)\n\n# Monitor control saturation\ncontrol, _ = controller.compute_control(state)\nif abs(control) >= 99.0:\n    log_warning(\"Control approaching saturation limit\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1485d06"
  },
  {
    "id": "phase_3_2_completion_report_5_8dd80f5d",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 5,
    "code": "from src.controllers.sta_smc import STASMC\n\n# Ensure K1 > K2 for discontinuous gain dominance\ncontroller = STASMC(\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n    max_force=100.0\n)\n\n# Validate constraint (should be done automatically by factory)\nassert controller.gains[0] > controller.gains[1], \"K1 must be > K2\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dd80f5d"
  },
  {
    "id": "phase_3_2_completion_report_6_69014486",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 6,
    "code": "from src.controllers.adaptive_smc import AdaptiveSMC\n\n# Conservative adaptation rate recommended\ncontroller = AdaptiveSMC(\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n    adaptation_rate=4.0,  # Lower values for slower adaptation\n    max_force=100.0\n)\n\n# Log adapted gains for diagnostics\nif iteration % 100 == 0:\n    log_info(f\"Adapted gains: {controller.get_current_gains()}\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69014486"
  },
  {
    "id": "phase_3_2_completion_report_7_9adc14cb",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO optimizer expects:\nfitness = evaluate_controller_gains(gains_array)\n\n# Hybrid controller provides:\nconfig = HybridSMCConfig(classical_gains=[...], sta_gains=[...], ...)\n# But config.gains doesn't exist \u2192 PSO can't access/optimize",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9adc14cb"
  },
  {
    "id": "phase_3_2_completion_report_8_88287a58",
    "file": "docs\\benchmarks\\phase_3_2_completion_report.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n@property\ndef gains(self):\n    \"\"\"Expose flattened gains array for optimization.\"\"\"\n    return np.concatenate([\n        self.classical_gains,\n        self.sta_gains,\n        [self.adaptation_rate]\n    ])\n\n@gains.setter\ndef gains(self, value):\n    \"\"\"Accept flattened gains array from optimizer.\"\"\"\n    n_classical = len(self.classical_gains)\n    n_sta = len(self.sta_gains)\n    self.classical_gains = value[:n_classical]\n    self.sta_gains = value[n_classical:n_classical+n_sta]\n    self.adaptation_rate = value[-1]",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "88287a58"
  },
  {
    "id": "CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT_1_b049cefb",
    "file": "docs\\code_quality\\CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#======================================================================================\\\\\\\n#============================= src/controllers/factory.py =============================\\\\\\\n#======================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b049cefb"
  },
  {
    "id": "CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT_2_ccfc7afa",
    "file": "docs\\code_quality\\CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT.md",
    "index": 2,
    "code": "from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Protocol, TypeVar\nfrom numpy.typing import NDArray\n\ndef create_controller(\n    controller_type: str,\n    config: Optional[Dict[str, Any]] = None,\n    gains: Optional[Union[List[float], NDArray]] = None,\n    **kwargs: Any\n) -> BaseController:",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccfc7afa"
  },
  {
    "id": "CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT_3_93f44bb5",
    "file": "docs\\code_quality\\CODE_BEAUTIFICATION_SPECIALIST_COMPREHENSIVE_ASSESSMENT.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports\nimport logging\nimport threading\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union, Protocol, TypeVar\n\n# Third-party imports\nimport numpy as np\nfrom numpy.typing import NDArray\n\n# Local imports - Core dynamics\nfrom src.core.dynamics import DIPDynamics\n\n# Local imports - Controller implementations\nfrom src.controllers.smc.algorithms.classical.controller import ModularClassicalSMC",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93f44bb5"
  },
  {
    "id": "adaptive_smc_technical_guide_1_98894ee0",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 1,
    "code": "class AdaptiveSMC:\n    \"\"\"\n    Adaptive Sliding-Mode Controller with online gain learning:\n\n    Components:\n    - Sliding surface computation (grouped formulation)\n    - Adaptive gain update (dead zone + leak)\n    - Robust switching term (smooth/linear saturation)\n    - Proportional damping for improved response\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "98894ee0"
  },
  {
    "id": "adaptive_smc_technical_guide_2_24355364",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 2,
    "code": "state_vars = (K, last_u, time_in_sliding)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24355364"
  },
  {
    "id": "adaptive_smc_technical_guide_3_62a262b0",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 3,
    "code": "history = {\n    'K': [],             # Adaptive gain evolution\n    'sigma': [],         # Sliding surface values\n    'u_sw': [],          # Switching control component\n    'dK': [],            # Gain rate of change\n    'time_in_sliding': [] # Time within boundary layer\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62a262b0"
  },
  {
    "id": "adaptive_smc_technical_guide_4_152b0efd",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 4,
    "code": "def compute_sliding_surface(state):\n    \"\"\"\u03c3 = k\u2081(\u03b8\u0307\u2081 + \u03bb\u2081\u03b8\u2081) + k\u2082(\u03b8\u0307\u2082 + \u03bb\u2082\u03b8\u2082)\"\"\"\n    x, theta1, theta2, x_dot, theta1_dot, theta2_dot = state\n\n    sigma = (self.k1 * (theta1_dot + self.lam1 * theta1) +\n             self.k2 * (theta2_dot + self.lam2 * theta2))\n\n    return sigma",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "152b0efd"
  },
  {
    "id": "adaptive_smc_technical_guide_5_7e2c26b9",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef update_adaptive_gain(sigma, prev_K, dt):\n    \"\"\"Update K with dead zone, leak, and rate limiting.\"\"\"\n\n    # Dead zone logic\n    if abs(sigma) <= self.dead_zone:\n        dK = 0.0  # Freeze adaptation inside dead zone\n    else:\n        # Outside dead zone: growth with leak\n        growth = self.gamma * abs(sigma)\n        dK = growth - self.leak_rate * (prev_K - self.K_init)\n\n    # Rate limiting\n    dK = np.clip(dK, -self.adapt_rate_limit, self.adapt_rate_limit)\n\n    # Update with bounds\n    new_K = prev_K + dK * dt\n    new_K = np.clip(new_K, self.K_min, self.K_max)\n\n    return new_K, dK",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e2c26b9"
  },
  {
    "id": "adaptive_smc_technical_guide_6_0e3487f3",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    \"\"\"Main adaptive SMC control computation.\"\"\"\n\n    # 1. Unpack previous state\n    prev_K, last_u, time_in_sliding = state_vars\n\n    # 2. Extract state variables\n    x, theta1, theta2, x_dot, theta1_dot, theta2_dot = state\n\n    # 3. Compute sliding surface\n    sigma = (self.k1 * (theta1_dot + self.lam1 * theta1) +\n             self.k2 * (theta2_dot + self.lam2 * theta2))\n\n    # 4. Switching term with current gain\n    if self.smooth_switch:\n        switching = saturate(sigma, self.boundary_layer, method=\"tanh\")\n    else:\n        switching = saturate(sigma, self.boundary_layer, method=\"linear\")\n\n    u_sw = -prev_K * switching\n\n    # 5. Total control with proportional term\n    u = u_sw - self.alpha * sigma\n\n    # 6. Actuator saturation\n    u = np.clip(u, -self.max_force, self.max_force)\n\n    # 7. Update time in sliding mode\n    if abs(sigma) <= self.boundary_layer:\n        new_time_in_sliding = time_in_sliding + self.dt\n    else:\n        new_time_in_sliding = 0.0\n\n    # 8. Adaptive gain update\n    if abs(sigma) <= self.dead_zone:\n        dK = 0.0\n    else:\n        growth = self.gamma * abs(sigma)\n        dK = growth - self.leak_rate * (prev_K - self.K_init)\n\n    dK = np.clip(dK, -self.adapt_rate_limit, self.adapt_rate_limit)\n    new_K = np.clip(prev_K + dK * self.dt, self.K_min, self.K_max)\n\n    # 9. Update history\n    hist = history\n    hist.setdefault('K', []).append(new_K)\n    hist.setdefault('sigma', []).append(sigma)\n    hist.setdefault('u_sw', []).append(u_sw)\n    hist.setdefault('dK', []).append(dK)\n    hist.setdefault('time_in_sliding', []).append(new_time_in_sliding)\n\n    # 10. Return structured output\n    return AdaptiveSMCOutput(u, (new_K, u, new_time_in_sliding), hist, sigma)",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e3487f3"
  },
  {
    "id": "adaptive_smc_technical_guide_7_fd535193",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 7,
    "code": "pso_bounds = [\n    (1.0, 50.0),   # k1\n    (1.0, 50.0),   # k2\n    (1.0, 100.0),  # lam1\n    (1.0, 100.0),  # lam2\n    (0.1, 5.0),    # gamma\n]",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd535193"
  },
  {
    "id": "adaptive_smc_technical_guide_8_5873274b",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 8,
    "code": "from src.controllers.smc import AdaptiveSMC\n\n# Create controller\ncontroller = AdaptiveSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 0.5],\n    dt=0.01,\n    max_force=100.0,\n    leak_rate=0.001,\n    adapt_rate_limit=10.0,\n    K_min=0.1,\n    K_max=100.0,\n    smooth_switch=True,\n    boundary_layer=0.01,\n    dead_zone=0.01,\n    K_init=10.0,\n    alpha=0.5\n)\n\n# Initialize state and history\nstate_vars = controller.initialize_state()  # (K_init, 0.0, 0.0)\nhistory = controller.initialize_history()\n\n# Main control loop\nfor t in simulation_time:\n    state = get_system_state()  # [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\n\n    result = controller.compute_control(state, state_vars, history)\n\n    # Extract results\n    control_force = result.control\n    state_vars = result.state_vars  # (K_new, u, time_in_sliding)\n    history = result.history\n    sigma = result.sliding_surface\n\n    # Monitor adaptation\n    current_K = state_vars[0]\n    print(f\"Adaptive gain: K = {current_K:.2f}\")\n\n    # Apply control\n    apply_control(control_force)",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5873274b"
  },
  {
    "id": "adaptive_smc_technical_guide_9_64044fc0",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 9,
    "code": "from src.controllers import create_controller\n\n# Create via factory\ncontroller = create_controller(\n    'adaptive_smc',\n    gains=[10, 8, 15, 12, 0.5],\n    dt=0.01,\n    max_force=100.0\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "64044fc0"
  },
  {
    "id": "adaptive_smc_technical_guide_10_70feb0f7",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 10,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\n\n# Define PSO search space for 5 gains\npso_bounds = [\n    (1.0, 50.0),   # k1\n    (1.0, 50.0),   # k2\n    (1.0, 100.0),  # lam1\n    (1.0, 100.0),  # lam2\n    (0.1, 5.0),    # gamma\n]\n\n# Run PSO optimization\ntuner = PSOTuner(bounds=pso_bounds, n_particles=30, iters=200)\nbest_gains, best_cost = tuner.optimize(\n    controller_type='adaptive_smc',\n    dynamics=dynamics_model\n)\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Best cost: {best_cost}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70feb0f7"
  },
  {
    "id": "adaptive_smc_technical_guide_11_b7d3f3f5",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef monitor_adaptive_smc(controller, state, result):\n    \"\"\"Monitor adaptive SMC performance and gain evolution.\"\"\"\n\n    K_current = result.state_vars[0]\n    sigma = result.sliding_surface\n    dK = result.history['dK'][-1] if result.history['dK'] else 0.0\n\n    # Performance indicators\n    gain_utilization = K_current / controller.K_max\n    adaptation_active = abs(sigma) > controller.dead_zone\n    near_bounds = (K_current >= controller.K_max * 0.9 or\n                   K_current <= controller.K_min * 1.1)\n\n    # Warning conditions\n    if near_bounds:\n        print(f\"WARNING: Gain near bounds: K = {K_current:.2f}\")\n\n    if adaptation_active and abs(dK) < 0.01:\n        print(f\"WARNING: Slow adaptation despite large error: |\u03c3| = {abs(sigma):.3f}\")\n\n    if K_current < 1.0:\n        print(f\"WARNING: Very low adaptive gain: K = {K_current:.2f}\")\n\n    return {\n        'K_current': K_current,\n        'gain_utilization': gain_utilization,\n        'adaptation_active': adaptation_active,\n        'near_bounds': near_bounds,\n        'dK': dK\n    }",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b7d3f3f5"
  },
  {
    "id": "adaptive_smc_technical_guide_12_0b5512c6",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 12,
    "code": "import matplotlib.pyplot as plt\n\ndef plot_adaptation_history(history):\n    \"\"\"Visualize adaptive gain evolution.\"\"\"\n\n    fig, axes = plt.subplots(3, 1, figsize=(10, 8))\n\n    # Adaptive gain evolution\n    axes[0].plot(history['K'], label='K(t)')\n    axes[0].axhline(y=controller.K_init, color='g', linestyle='--', label='K_init')\n    axes[0].set_ylabel('Adaptive Gain K (N)')\n    axes[0].legend()\n    axes[0].grid(True)\n\n    # Sliding surface\n    axes[1].plot(history['sigma'], label='\u03c3(t)')\n    axes[1].axhline(y=controller.dead_zone, color='r', linestyle='--', alpha=0.5)\n    axes[1].axhline(y=-controller.dead_zone, color='r', linestyle='--', alpha=0.5)\n    axes[1].set_ylabel('Sliding Surface \u03c3')\n    axes[1].legend()\n    axes[1].grid(True)\n\n    # Gain rate of change\n    axes[2].plot(history['dK'], label='dK/dt')\n    axes[2].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n    axes[2].set_ylabel('Gain Rate dK/dt (N/s)')\n    axes[2].set_xlabel('Time Step')\n    axes[2].legend()\n    axes[2].grid(True)\n\n    plt.tight_layout()\n    return fig",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0b5512c6"
  },
  {
    "id": "adaptive_smc_technical_guide_13_9ed971a6",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_adaptation(controller, history):\n    \"\"\"Diagnose adaptive SMC health.\"\"\"\n\n    K_history = np.array(history['K'])\n    sigma_history = np.array(history['sigma'])\n    dK_history = np.array(history['dK'])\n\n    diagnostics = {}\n\n    # Gain statistics\n    diagnostics['K_mean'] = np.mean(K_history)\n    diagnostics['K_std'] = np.std(K_history)\n    diagnostics['K_final'] = K_history[-1]\n\n    # Adaptation activity\n    adaptation_active = np.sum(np.abs(sigma_history) > controller.dead_zone)\n    diagnostics['adaptation_ratio'] = adaptation_active / len(sigma_history)\n\n    # Gain oscillation check\n    sign_changes = np.sum(np.diff(np.sign(dK_history)) != 0)\n    diagnostics['gain_oscillations'] = sign_changes\n\n    # Saturation checks\n    diagnostics['hit_K_max'] = np.any(K_history >= controller.K_max * 0.99)\n    diagnostics['hit_K_min'] = np.any(K_history <= controller.K_min * 1.01)\n\n    # Warnings\n    if diagnostics['gain_oscillations'] > len(dK_history) * 0.5:\n        print(\"WARNING: Excessive gain oscillation\")\n\n    if diagnostics['hit_K_max']:\n        print(\"WARNING: Gain saturated at K_max\")\n\n    if diagnostics['adaptation_ratio'] > 0.9:\n        print(\"WARNING: Rarely in dead zone - check dead_zone parameter\")\n\n    return diagnostics",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ed971a6"
  },
  {
    "id": "adaptive_smc_technical_guide_14_7d567936",
    "file": "docs\\controllers\\adaptive_smc_technical_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_adaptive_parameters(gains, config):\n    \"\"\"Validate adaptive SMC parameters.\"\"\"\n\n    k1, k2, lam1, lam2, gamma = gains\n\n    checks = {\n        'positive_gains': all(g > 0 for g in [k1, k2, lam1, lam2, gamma]),\n        'K_bounds_valid': config.K_min <= config.K_init <= config.K_max,\n        'dead_zone_nonneg': config.dead_zone >= 0,\n        'leak_rate_nonneg': config.leak_rate >= 0,\n        'adapt_rate_positive': config.adapt_rate_limit > 0,\n        'gamma_reasonable': 0.01 <= gamma <= 10.0,\n    }\n\n    if not all(checks.values()):\n        failed = [k for k, v in checks.items() if not v]\n        print(f\"WARNING: Parameter validation failed: {failed}\")\n        return False\n\n    return True",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7d567936"
  },
  {
    "id": "classical_smc_technical_guide_1_c43d0d2c",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 1,
    "code": "class ClassicalSMC:\n    \"\"\"\n    Classical Sliding-Mode Controller with modular design:\n\n    Components:\n    - Sliding surface computation (linear combination)\n    - Equivalent control (model-based feedforward)\n    - Robust switching term (chattering reduction)\n    - Saturation and safety mechanisms\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c43d0d2c"
  },
  {
    "id": "classical_smc_technical_guide_2_fbd43faf",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 2,
    "code": "M_reg = M + regularization * I  # Default: regularization = 1e-10",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbd43faf"
  },
  {
    "id": "classical_smc_technical_guide_3_be82cc5d",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 3,
    "code": "L_Minv_B = L @ np.linalg.solve(M_reg, B)\nif abs(L_Minv_B) < self.eq_threshold:\n    return 0.0  # Disable equivalent control",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be82cc5d"
  },
  {
    "id": "classical_smc_technical_guide_4_e6078fdc",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 4,
    "code": "if dynamics_model is not None:\n    self._dynamics_ref = weakref.ref(dynamics_model)\nelse:\n    self._dynamics_ref = lambda: None",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6078fdc"
  },
  {
    "id": "classical_smc_technical_guide_5_3bc288fe",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 5,
    "code": "def _compute_sliding_surface(self, state: np.ndarray) -> float:\n    \"\"\"Compute \u03c3 = \u03bb\u2081\u03b8\u2081 + \u03bb\u2082\u03b8\u2082 + k\u2081\u03b8\u0307\u2081 + k\u2082\u03b8\u0307\u2082\"\"\"\n    _, theta1, theta2, _, dtheta1, dtheta2 = state\n    return (self.lam1 * theta1 + self.lam2 * theta2 +\n            self.k1 * dtheta1 + self.k2 * dtheta2)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3bc288fe"
  },
  {
    "id": "classical_smc_technical_guide_6_6b9ff8d7",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef _compute_equivalent_control(self, state: np.ndarray) -> float:\n    \"\"\"Compute model-based u_eq with enhanced robustness.\"\"\"\n    if self.dyn is None:\n        return 0.0  # No dynamics model\n\n    try:\n        # Get physics matrices\n        M, C, G = self.dyn._compute_physics_matrices(state)\n\n        # Regularize inertia matrix\n        M_reg = M + np.eye(3) * max(self.regularization, 0.0)\n\n        # Solve for controllability scalar\n        Minv_B = np.linalg.solve(M_reg, self.B)\n        L_Minv_B = float(self.L @ Minv_B)\n\n        # Check controllability\n        if abs(L_Minv_B) < self.eq_threshold:\n            return 0.0\n\n        # Compute equivalent control\n        q_dot = state[3:]\n        if getattr(C, \"ndim\", 1) == 2:\n            rhs = C @ q_dot + G\n        else:\n            rhs = C + G\n\n        Minv_rhs = np.linalg.solve(M_reg, rhs)\n        term1 = float(self.L @ Minv_rhs)\n        term2 = self.k1 * self.lam1 * q_dot[1] + self.k2 * self.lam2 * q_dot[2]\n        u_eq = (term1 - term2) / L_Minv_B\n\n        return float(u_eq)\n\n    except np.linalg.LinAlgError:\n        return 0.0  # Singular matrix",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b9ff8d7"
  },
  {
    "id": "classical_smc_technical_guide_7_ede536d0",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state: np.ndarray,\n                   state_vars: tuple,\n                   history: dict) -> ClassicalSMCOutput:\n    \"\"\"Main control computation.\"\"\"\n    # 1. Sliding surface\n    sigma = self._compute_sliding_surface(state)\n\n    # 2. Adaptive boundary layer\n    eps_dyn = self.epsilon0 + self.epsilon1 * float(np.linalg.norm(sigma))\n\n    # 3. Hysteresis dead-band\n    if abs(float(sigma)) < self.hysteresis_ratio * self.epsilon0:\n        sat_sigma = 0.0\n    else:\n        sat_sigma = saturate(sigma, eps_dyn, method=self.switch_method)\n\n    # 4. Equivalent control\n    u_eq = self._compute_equivalent_control(state)\n\n    # 5. Clamp equivalent control\n    max_eq = 5.0 * self.max_force\n    u_eq = float(np.clip(u_eq, -max_eq, max_eq))\n\n    # 6. Robust switching term\n    u_robust = -self.K * sat_sigma - self.kd * sigma\n\n    # 7. Combine and saturate\n    u = u_eq + u_robust\n    u_saturated = float(np.clip(u, -self.max_force, self.max_force))\n\n    # 8. History tracking\n    hist = history if isinstance(history, dict) else {}\n    hist.setdefault('sigma', []).append(float(sigma))\n    hist.setdefault('epsilon_eff', []).append(float(eps_dyn))\n    hist.setdefault('u_eq', []).append(float(u_eq))\n    hist.setdefault('u_robust', []).append(float(u_robust))\n    hist.setdefault('u_total', []).append(float(u))\n    hist.setdefault('u', []).append(float(u_saturated))\n\n    return ClassicalSMCOutput(u_saturated, (), hist)",
    "lines": 43,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ede536d0"
  },
  {
    "id": "classical_smc_technical_guide_8_b98c9ed7",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 8,
    "code": "def saturate_tanh(sigma, epsilon):\n    return np.tanh(sigma / epsilon)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b98c9ed7"
  },
  {
    "id": "classical_smc_technical_guide_9_a6468e2c",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 9,
    "code": "def saturate_linear(sigma, epsilon):\n    return np.clip(sigma / epsilon, -1.0, 1.0)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6468e2c"
  },
  {
    "id": "classical_smc_technical_guide_10_0c109510",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 10,
    "code": "pso_bounds = [\n    (1.0, 50.0),   # k1\n    (1.0, 50.0),   # k2\n    (1.0, 100.0),  # lam1\n    (1.0, 100.0),  # lam2\n    (5.0, 200.0),  # K\n    (0.0, 50.0),   # kd\n]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c109510"
  },
  {
    "id": "classical_smc_technical_guide_11_29318dc7",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 11,
    "code": "from src.controllers.smc import ClassicalSMC\n\n# Create controller with specified gains\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01,\n    switch_method=\"tanh\"\n)\n\n# Initialize (stateless for classical SMC)\nstate_vars = controller.initialize_state()  # Returns ()\nhistory = controller.initialize_history()    # Returns {}\n\n# Main control loop\nfor t in simulation_time:\n    state = get_system_state()  # [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\n\n    result = controller.compute_control(state, state_vars, history)\n\n    # Extract results\n    control_force = result.control\n    history = result.history\n\n    # Apply control\n    apply_control(control_force)",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "29318dc7"
  },
  {
    "id": "classical_smc_technical_guide_12_e920d168",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 12,
    "code": "from src.controllers import create_controller\n\n# Create via factory (recommended for configurability)\ncontroller = create_controller(\n    'classical_smc',\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e920d168"
  },
  {
    "id": "classical_smc_technical_guide_13_d0cd7540",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 13,
    "code": "from src.plant.models.dynamics import DoubleInvertedPendulum\nfrom src.controllers.smc import ClassicalSMC\n\n# Create dynamics model\ndynamics = DoubleInvertedPendulum(params=physics_params)\n\n# Create controller with dynamics (enables equivalent control)\ncontroller = ClassicalSMC(\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0,\n    boundary_layer=0.01,\n    dynamics_model=dynamics  # Model-based u_eq\n)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0cd7540"
  },
  {
    "id": "classical_smc_technical_guide_14_9ae3df90",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 14,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\n\n# Define PSO search space\npso_bounds = [\n    (1.0, 50.0),   # k1: velocity gain 1\n    (1.0, 50.0),   # k2: velocity gain 2\n    (1.0, 100.0),  # lam1: position gain 1\n    (1.0, 100.0),  # lam2: position gain 2\n    (5.0, 200.0),  # K: switching gain\n    (0.0, 50.0),   # kd: damping gain\n]\n\n# Run PSO optimization\ntuner = PSOTuner(bounds=pso_bounds, n_particles=30, iters=200)\nbest_gains, best_cost = tuner.optimize(\n    controller_type='classical_smc',\n    dynamics=dynamics_model\n)\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Best cost: {best_cost}\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ae3df90"
  },
  {
    "id": "classical_smc_technical_guide_15_03dd6655",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef fitness_function(gains_array):\n    \"\"\"PSO fitness evaluation for classical SMC.\"\"\"\n    # Create controller with candidate gains\n    controller = ClassicalSMC(\n        gains=gains_array,\n        max_force=100.0,\n        boundary_layer=0.01\n    )\n\n    # Run simulation\n    result = run_simulation(controller, duration=5.0, dt=0.01)\n\n    # Compute multi-objective fitness\n    tracking_error = compute_ise(result.states)\n    control_effort = compute_rms(result.controls)\n    chattering = compute_chattering_index(result.controls)\n\n    # Weighted cost\n    return (0.5 * tracking_error +\n            0.3 * control_effort +\n            0.2 * chattering)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "03dd6655"
  },
  {
    "id": "classical_smc_technical_guide_16_3ab42465",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# Complete simulation with classical SMC\ndef run_classical_smc_simulation():\n    # Load configuration\n    config = load_config('config.yaml')\n\n    # Create dynamics\n    dynamics = DoubleInvertedPendulum(params=config.physics)\n\n    # Create controller\n    controller = create_controller(\n        'classical_smc',\n        gains=config.controllers.classical_smc.gains,\n        max_force=config.controllers.classical_smc.max_force,\n        boundary_layer=config.controllers.classical_smc.boundary_layer,\n        dynamics_model=dynamics\n    )\n\n    # Run simulation\n    results = run_simulation(\n        controller=controller,\n        dynamics=dynamics,\n        duration=10.0,\n        dt=0.01,\n        initial_state=config.simulation.initial_state\n    )\n\n    return results",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ab42465"
  },
  {
    "id": "classical_smc_technical_guide_17_c71ebc5a",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef monitor_classical_smc(controller, state, result):\n    \"\"\"Monitor classical SMC performance indicators.\"\"\"\n\n    sigma = result.history['sigma'][-1]\n    u_eq = result.history['u_eq'][-1]\n    u_robust = result.history['u_robust'][-1]\n    eps_eff = result.history['epsilon_eff'][-1]\n\n    # Performance indicators\n    surface_distance = abs(sigma)\n    eq_ratio = abs(u_eq) / controller.max_force if controller.max_force > 0 else 0\n    robust_ratio = abs(u_robust) / controller.max_force if controller.max_force > 0 else 0\n\n    # Warning conditions\n    if surface_distance > 1.0:\n        print(f\"WARNING: Large sliding surface: {surface_distance:.3f}\")\n\n    if eq_ratio > 0.9:\n        print(f\"WARNING: Equivalent control near saturation: {eq_ratio:.3f}\")\n\n    if abs(result.control) >= controller.max_force * 0.99:\n        print(f\"WARNING: Control saturated: {result.control:.2f} N\")\n\n    return {\n        'surface_distance': surface_distance,\n        'eq_ratio': eq_ratio,\n        'robust_ratio': robust_ratio,\n        'boundary_layer': eps_eff\n    }",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c71ebc5a"
  },
  {
    "id": "classical_smc_technical_guide_18_765b7c17",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 18,
    "code": "M, C, G = dynamics._compute_physics_matrices(state)\ncond_number = np.linalg.cond(M)\nif cond_number > 1e12:\n    print(f\"WARNING: Ill-conditioned M: \u03ba = {cond_number:.2e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "765b7c17"
  },
  {
    "id": "classical_smc_technical_guide_19_51b60fdd",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 19,
    "code": "controller.validate_gains([10, 8, 15, 12, 50, 5])  # Should not raise",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51b60fdd"
  },
  {
    "id": "classical_smc_technical_guide_20_ecd4d979",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ncontroller = create_controller('adaptive_smc', ...)  # Can achieve zero error",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ecd4d979"
  },
  {
    "id": "classical_smc_technical_guide_21_f7ecfedc",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_classical_smc(controller, state, result):\n    \"\"\"Comprehensive controller diagnostics.\"\"\"\n\n    diagnostics = {}\n\n    # Extract current values\n    sigma = result.history['sigma'][-1]\n    u_eq = result.history['u_eq'][-1]\n    u_robust = result.history['u_robust'][-1]\n    eps_eff = result.history['epsilon_eff'][-1]\n\n    # Surface distance\n    diagnostics['surface_distance'] = abs(sigma)\n    diagnostics['within_boundary'] = abs(sigma) < eps_eff\n\n    # Control component analysis\n    diagnostics['eq_magnitude'] = abs(u_eq)\n    diagnostics['robust_magnitude'] = abs(u_robust)\n    diagnostics['eq_dominant'] = abs(u_eq) > abs(u_robust)\n\n    # Saturation checks\n    diagnostics['control_saturated'] = abs(result.control) >= controller.max_force * 0.99\n    diagnostics['eq_saturated'] = abs(u_eq) >= 5.0 * controller.max_force * 0.99\n\n    return diagnostics",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f7ecfedc"
  },
  {
    "id": "classical_smc_technical_guide_22_20a421eb",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_classical_parameters(gains, config):\n    \"\"\"Validate classical SMC parameters for stability.\"\"\"\n\n    k1, k2, lam1, lam2, K, kd = gains\n\n    checks = {\n        'positive_gains': all(g > 0 for g in [k1, k2, lam1, lam2, K]),\n        'nonneg_damping': kd >= 0,\n        'hurwitz_1': k1**2 >= 4*lam1,  # Critically damped or overdamped\n        'hurwitz_2': k2**2 >= 4*lam2,\n        'switching_adequate': K > 20,  # Typical disturbance bound\n        'boundary_positive': config.boundary_layer > 0,\n    }\n\n    if not all(checks.values()):\n        failed = [k for k, v in checks.items() if not v]\n        print(f\"WARNING: Parameter validation failed: {failed}\")\n        return False\n\n    return True",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20a421eb"
  },
  {
    "id": "classical_smc_technical_guide_23_2327b89a",
    "file": "docs\\controllers\\classical_smc_technical_guide.md",
    "index": 23,
    "code": "import time\n\ndef profile_classical_smc(controller, state):\n    \"\"\"Profile computational cost of control law.\"\"\"\n\n    import time\n\n    timings = {}\n\n    # Sliding surface\n    t0 = time.perf_counter()\n    sigma = controller._compute_sliding_surface(state)\n    timings['sliding_surface'] = (time.perf_counter() - t0) * 1e6  # \u03bcs\n\n    # Equivalent control\n    t0 = time.perf_counter()\n    u_eq = controller._compute_equivalent_control(state)\n    timings['equivalent_control'] = (time.perf_counter() - t0) * 1e6\n\n    # Full control\n    t0 = time.perf_counter()\n    result = controller.compute_control(state, (), {})\n    timings['total'] = (time.perf_counter() - t0) * 1e6\n\n    return timings",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2327b89a"
  },
  {
    "id": "control_primitives_reference_1_42a9bb88",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef saturate(\n    sigma: Union[float, np.ndarray],\n    epsilon: float,\n    method: Literal[\"tanh\", \"linear\"] = \"tanh\",\n    slope: float = 3.0\n) -> Union[float, np.ndarray]:\n    \"\"\"Continuous approximation of sign(sigma) within a boundary layer.\n\n    Args:\n        sigma: Sliding surface value(s)\n        epsilon: Boundary-layer half-width (must be > 0)\n        method: \"tanh\" (default) or \"linear\"\n        slope: Slope parameter for tanh switching (default: 3.0)\n\n    Returns:\n        Continuous switching signal\n    \"\"\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42a9bb88"
  },
  {
    "id": "control_primitives_reference_2_2aecfaa1",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 2,
    "code": "from src.utils.control import saturate\n\n# Classical SMC control law\nsigma = lambda1 * theta1 + lambda2 * theta2 + k1 * dtheta1 + k2 * dtheta2\nu_switch = -K * saturate(sigma, epsilon=0.01, method='tanh', slope=3.0)\nu_damping = -kd * saturate(sigma, epsilon=0.01, method='tanh', slope=3.0)\nu = u_switch + u_damping",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2aecfaa1"
  },
  {
    "id": "control_primitives_reference_3_a66cd125",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 3,
    "code": "def smooth_sign(\n    x: Union[float, np.ndarray],\n    epsilon: float = 0.01\n) -> Union[float, np.ndarray]:\n    \"\"\"Smooth approximation of the sign function using tanh.\n\n    Convenience wrapper for saturate() with tanh method.\n    \"\"\"",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a66cd125"
  },
  {
    "id": "control_primitives_reference_4_9a8de1ae",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 4,
    "code": "from src.utils.control import smooth_sign\n\n# Continuous sign approximation\nsigma = compute_sliding_surface(state)\nswitch_signal = -K * smooth_sign(sigma, epsilon=0.02)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a8de1ae"
  },
  {
    "id": "control_primitives_reference_5_8e28c134",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef dead_zone(\n    x: Union[float, np.ndarray],\n    threshold: float\n) -> Union[float, np.ndarray]:\n    \"\"\"Apply dead zone to input signal.\n\n    Args:\n        x: Input signal\n        threshold: Dead zone threshold (must be positive)\n\n    Returns:\n        Signal with dead zone applied\n    \"\"\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e28c134"
  },
  {
    "id": "control_primitives_reference_6_785f6ff7",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 6,
    "code": "from src.utils.control import dead_zone\n\n# Adaptive gain update with dead zone\nsigma = compute_sliding_surface(state)\n\nif abs(sigma) <= self.dead_zone:\n    dK = 0.0  # Freeze adaptation\nelse:\n    sigma_active = dead_zone(sigma, self.dead_zone)\n    dK = self.gamma * abs(sigma_active) - self.leak_rate * (K - K_init)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "785f6ff7"
  },
  {
    "id": "control_primitives_reference_7_57a21deb",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass ClassicalSMCOutput(NamedTuple):\n    \"\"\"Return type for ClassicalSMC.compute_control().\n\n    Attributes:\n        u: Saturated control input (N)\n        state: Internal controller state (empty tuple for stateless)\n        history: History dictionary for debugging/plotting\n    \"\"\"\n    u: float\n    state: Tuple[Any, ...]\n    history: Dict[str, Any]",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57a21deb"
  },
  {
    "id": "control_primitives_reference_8_69997483",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 8,
    "code": "from src.controllers.classic_smc import ClassicalSMC\n\ncontroller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5], max_force=100, boundary_layer=0.01)\nresult = controller.compute_control(state, (), {})\n\n# Access via attributes\ncontrol_input = result.u\ncontroller_state = result.state\ndebug_info = result.history\n\n# Backwards-compatible tuple unpacking\nu, state, history = result",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69997483"
  },
  {
    "id": "control_primitives_reference_9_8a41cd6d",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptiveSMCOutput(NamedTuple):\n    \"\"\"Return type for AdaptiveSMC.compute_control().\n\n    Attributes:\n        u: Saturated control input (N)\n        state: Updated adaptation states (e.g., K_adaptive)\n        history: History dictionary\n        sigma: Current sliding surface value\n    \"\"\"\n    u: float\n    state: Tuple[float, ...]\n    history: Dict[str, Any]\n    sigma: float",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a41cd6d"
  },
  {
    "id": "control_primitives_reference_10_bde16bb9",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 10,
    "code": "from src.controllers.adaptive_smc import AdaptiveSMC\n\ncontroller = AdaptiveSMC(gains=[25, 18, 15, 10, 4], dt=0.01, max_force=100)\nresult = controller.compute_control(state, (), {})\n\n# Monitor sliding surface convergence\nif abs(result.sigma) < 0.01:\n    print(\"Reached sliding surface\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bde16bb9"
  },
  {
    "id": "control_primitives_reference_11_83584041",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass STAOutput(NamedTuple):\n    \"\"\"Return type for SuperTwistingSMC.compute_control().\n\n    Attributes:\n        u: Bounded control input (N)\n        state: Auxiliary integrator states (z, sigma)\n        history: History dictionary\n    \"\"\"\n    u: float\n    state: Tuple[float, ...]\n    history: Dict[str, Any]",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83584041"
  },
  {
    "id": "control_primitives_reference_12_7eeeed33",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 12,
    "code": "from src.controllers.sta_smc import SuperTwistingSMC\n\ncontroller = SuperTwistingSMC(gains=[25, 15, 20, 12, 8, 6], dt=0.01, max_force=100)\n\n# Initialize state\nz_prev, sigma_prev = 0.0, 0.0\n\nfor t, state in simulation_loop:\n    result = controller.compute_control(state, (z_prev, sigma_prev), {})\n    u = result.u\n    z_prev, sigma_prev = result.state  # Update auxiliary states",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7eeeed33"
  },
  {
    "id": "control_primitives_reference_13_0faf882b",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass HybridSTAOutput(NamedTuple):\n    \"\"\"Return type for HybridAdaptiveSTASMC.compute_control().\n\n    Attributes:\n        u: Saturated control input (N)\n        state: Adaptive gains and integral state (k1, k2, u_int)\n        history: History dictionary\n        sigma: Current sliding surface value\n    \"\"\"\n    u: float\n    state: Tuple[float, ...]\n    history: Dict[str, Any]\n    sigma: float",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0faf882b"
  },
  {
    "id": "control_primitives_reference_14_1bc67080",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 14,
    "code": "from src.controllers.hybrid_adaptive_sta_smc import HybridAdaptiveSTASMC\n\ncontroller = HybridAdaptiveSTASMC(\n    gains=[18, 12, 10, 8],\n    dt=0.01,\n    max_force=100,\n    k1_init=5.0,\n    k2_init=3.0\n)\n\n# Initialize adaptive state\nk1, k2, u_int = controller.k1_init, controller.k2_init, 0.0\n\nfor t, state in simulation_loop:\n    result = controller.compute_control(state, (k1, k2, u_int), {})\n    u = result.u\n    k1, k2, u_int = result.state  # Update adaptive gains",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1bc67080"
  },
  {
    "id": "control_primitives_reference_15_5fa5333d",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef require_positive(\n    value: Union[float, int, None],\n    name: str,\n    *,\n    allow_zero: bool = False\n) -> float:\n    \"\"\"Validate that a numeric value is positive (or non-negative).\n\n    Args:\n        value: The numeric quantity to validate\n        name: Parameter name (used in error message)\n        allow_zero: When True, value of exactly zero is allowed\n\n    Returns:\n        Validated value cast to float\n\n    Raises:\n        ValueError: If value is None, not finite, or not positive\n    \"\"\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fa5333d"
  },
  {
    "id": "control_primitives_reference_16_1378ee2d",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 16,
    "code": "from src.utils.validation import require_positive\n\nclass ClassicalSMC:\n    def __init__(self, gains, max_force, boundary_layer):\n        # Validate stability-critical parameters\n        self.max_force = require_positive(max_force, \"max_force\")\n        self.boundary_layer = require_positive(boundary_layer, \"boundary_layer\")\n\n        # Validate gains\n        for i, gain in enumerate(gains):\n            gains[i] = require_positive(gain, f\"gains[{i}]\", allow_zero=False)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1378ee2d"
  },
  {
    "id": "control_primitives_reference_17_5518b55c",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef require_finite(\n    value: Union[float, int, None],\n    name: str\n) -> float:\n    \"\"\"Validate that a value is finite.\n\n    Args:\n        value: The numeric quantity to validate\n        name: Parameter name\n\n    Returns:\n        Validated value cast to float\n\n    Raises:\n        ValueError: If value is None, infinity, or NaN\n    \"\"\"",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5518b55c"
  },
  {
    "id": "control_primitives_reference_18_9a2f314b",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 18,
    "code": "from src.utils.validation import require_finite\n\ndef compute_control_law(state, gains):\n    # Validate intermediate computations\n    sigma = compute_sliding_surface(state)\n    sigma = require_finite(sigma, \"sliding_surface\")\n\n    u = -gains[4] * saturate(sigma, epsilon=0.01)\n    u = require_finite(u, \"control_input\")\n\n    return u",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a2f314b"
  },
  {
    "id": "control_primitives_reference_19_a5bdade5",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_divide(\n    numerator: NumericType,\n    denominator: NumericType,\n    epsilon: float = 1e-12,\n    fallback: float = 0.0,\n    warn: bool = False,\n) -> NumericType:\n    \"\"\"Safe division with epsilon threshold protection against zero division.\n\n    Mathematical Definition:\n        safe_divide(a, b) = a / max(|b|, \u03b5) * sign(b)\n\n    Args:\n        numerator: Dividend (scalar or array)\n        denominator: Divisor (scalar or array)\n        epsilon: Minimum safe denominator magnitude (default: 1e-12)\n        fallback: Value to return if denominator is exactly zero (default: 0.0)\n        warn: Issue warning when epsilon protection triggers (default: False)\n    \"\"\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5bdade5"
  },
  {
    "id": "control_primitives_reference_20_ee48b47e",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 20,
    "code": "from src.utils.numerical_stability import safe_divide\n\n# Compute inertia matrix inverse safely\ndet_M = np.linalg.det(M)\ninv_M = safe_divide(1.0, det_M, epsilon=1e-12, fallback=0.0)\n\n# Safe derivative computation\nvelocity = safe_divide(position - prev_position, dt, epsilon=1e-12)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee48b47e"
  },
  {
    "id": "control_primitives_reference_21_f3bf276f",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 21,
    "code": "def safe_reciprocal(\n    x: NumericType,\n    epsilon: float = 1e-12,\n    fallback: float = 0.0,\n    warn: bool = False,\n) -> NumericType:\n    \"\"\"Safe reciprocal (1/x) with epsilon protection.\n\n    Convenience wrapper for safe_divide(1.0, x).\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3bf276f"
  },
  {
    "id": "control_primitives_reference_22_71c88213",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_sqrt(\n    x: NumericType,\n    min_value: float = 1e-15,\n    warn: bool = False,\n) -> NumericType:\n    \"\"\"Safe square root with negative value protection.\n\n    Mathematical Definition:\n        safe_sqrt(x) = \u221a(max(x, min_value))\n\n    Clips input to [min_value, \u221e) before applying sqrt to prevent\n    domain errors from numerical noise producing negative values.\n    \"\"\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71c88213"
  },
  {
    "id": "control_primitives_reference_23_1b5954b0",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 23,
    "code": "from src.utils.numerical_stability import safe_sqrt\n\n# Finite-time STA control law: u = -K1 * sqrt(|\u03c3|) * sign(\u03c3)\nu_proportional = -K1 * safe_sqrt(abs(sigma), min_value=1e-15) * smooth_sign(sigma)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1b5954b0"
  },
  {
    "id": "control_primitives_reference_24_4dac9a55",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 24,
    "code": "def safe_log(\n    x: NumericType,\n    min_value: float = 1e-15,\n    warn: bool = False,\n) -> NumericType:\n    \"\"\"Safe natural logarithm with zero/negative protection.\n\n    Mathematical Definition:\n        safe_log(x) = ln(max(x, min_value))\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4dac9a55"
  },
  {
    "id": "control_primitives_reference_25_311a23a5",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 25,
    "code": "from src.utils.numerical_stability import safe_log\n\n# PSO cost function with log penalty\ncost = ise + 1000 * safe_log(1 + instability_penalty)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "311a23a5"
  },
  {
    "id": "control_primitives_reference_26_e4fd8391",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_exp(\n    x: NumericType,\n    max_value: float = 700.0,\n    warn: bool = False,\n) -> NumericType:\n    \"\"\"Safe exponential with overflow protection.\n\n    Mathematical Definition:\n        safe_exp(x) = exp(min(x, max_value))\n\n    Clips input to (-\u221e, max_value] to prevent overflow.\n    Default max_value=700 is safe for IEEE 754 double precision.\n    \"\"\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4fd8391"
  },
  {
    "id": "control_primitives_reference_27_2920d2ea",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_norm(\n    vector: np.ndarray,\n    ord: Optional[Union[int, float, str]] = 2,\n    axis: Optional[int] = None,\n    min_norm: float = 1e-15,\n) -> Union[float, np.ndarray]:\n    \"\"\"Safe vector/matrix norm with zero-norm protection.\n\n    Mathematical Definition:\n        safe_norm(v) = max(||v||_p, min_norm)\n    \"\"\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2920d2ea"
  },
  {
    "id": "control_primitives_reference_28_88b72cda",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_normalize(\n    vector: np.ndarray,\n    ord: Optional[Union[int, float, str]] = 2,\n    axis: Optional[int] = None,\n    min_norm: float = 1e-15,\n    fallback: Optional[np.ndarray] = None,\n) -> np.ndarray:\n    \"\"\"Safe vector normalization with zero-norm protection.\n\n    Mathematical Definition:\n        safe_normalize(v) = v / max(||v||, min_norm)\n    \"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "88b72cda"
  },
  {
    "id": "control_primitives_reference_29_cc2c3928",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 29,
    "code": "from src.utils.numerical_stability import safe_norm, safe_normalize\n\n# Gradient descent with safe normalization\ngradient = compute_gradient(params)\ngradient_norm = safe_norm(gradient, min_norm=1e-10)\nunit_gradient = safe_normalize(gradient, min_norm=1e-10)\n\nparams_new = params - step_size * unit_gradient",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc2c3928"
  },
  {
    "id": "control_primitives_reference_30_87c7529b",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 30,
    "code": "from src.utils.control import saturate\nfrom src.utils.types import ClassicalSMCOutput\nfrom src.utils.validation import require_positive\n\nclass ClassicalSMC:\n    def __init__(self, gains, max_force, boundary_layer):\n        # Parameter validation\n        self.gains = [require_positive(g, f\"gains[{i}]\") for i, g in enumerate(gains)]\n        self.max_force = require_positive(max_force, \"max_force\")\n        self.boundary_layer = require_positive(boundary_layer, \"boundary_layer\")\n\n    def compute_control(self, state, state_vars, history):\n        # Extract state\n        x, theta1, theta2, dx, dtheta1, dtheta2 = state\n\n        # Compute sliding surface\n        k1, k2, lam1, lam2, K, kd = self.gains\n        sigma = lam1 * theta1 + lam2 * theta2 + k1 * dtheta1 + k2 * dtheta2\n\n        # Continuous control law with saturation\n        u_switch = -K * saturate(sigma, self.boundary_layer, method='tanh', slope=3.0)\n        u_damping = -kd * saturate(sigma, self.boundary_layer, method='tanh', slope=3.0)\n        u = np.clip(u_switch + u_damping, -self.max_force, self.max_force)\n\n        # Return structured output\n        return ClassicalSMCOutput(u=u, state=(), history={})",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87c7529b"
  },
  {
    "id": "control_primitives_reference_31_6fda69e4",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 31,
    "code": "from src.utils.control import saturate, dead_zone\nfrom src.utils.types import AdaptiveSMCOutput\nfrom src.utils.numerical_stability import safe_divide\n\nclass AdaptiveSMC:\n    def __init__(self, gains, dt, max_force, leak_rate, dead_zone_threshold):\n        self.gains = gains\n        self.dt = dt\n        self.max_force = max_force\n        self.leak_rate = leak_rate\n        self.dead_zone = dead_zone_threshold\n        self.K_init = 10.0\n\n    def compute_control(self, state, state_vars, history):\n        K_prev = state_vars[0] if state_vars else self.K_init\n\n        # Compute sliding surface\n        k1, k2, lam1, lam2, gamma = self.gains\n        x, theta1, theta2, dx, dtheta1, dtheta2 = state\n        sigma = lam1 * theta1 + lam2 * theta2 + k1 * dtheta1 + k2 * dtheta2\n\n        # Adaptive gain update with dead zone\n        if abs(sigma) <= self.dead_zone:\n            dK = 0.0  # Freeze inside dead zone\n        else:\n            sigma_active = dead_zone(sigma, self.dead_zone)\n            dK = gamma * abs(sigma_active) - self.leak_rate * (K_prev - self.K_init)\n\n        K_new = K_prev + dK * self.dt\n        K_new = np.clip(K_new, 0.1, 100.0)  # Saturation\n\n        # Control law\n        u = -K_new * saturate(sigma, epsilon=0.01, method='tanh')\n        u = np.clip(u, -self.max_force, self.max_force)\n\n        return AdaptiveSMCOutput(u=u, state=(K_new,), history={}, sigma=sigma)",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fda69e4"
  },
  {
    "id": "control_primitives_reference_32_ef245e78",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 32,
    "code": "from src.utils.control import saturate, smooth_sign\nfrom src.utils.types import STAOutput\nfrom src.utils.numerical_stability import safe_sqrt\n\nclass SuperTwistingSMC:\n    def __init__(self, gains, dt, max_force):\n        self.gains = gains\n        self.dt = dt\n        self.max_force = max_force\n\n    def compute_control(self, state, state_vars, history):\n        K1, K2, k1, k2, lam1, lam2 = self.gains\n        z_prev, sigma_prev = state_vars if state_vars else (0.0, 0.0)\n\n        # Compute sliding surface\n        x, theta1, theta2, dx, dtheta1, dtheta2 = state\n        sigma = lam1 * theta1 + lam2 * theta2 + k1 * dtheta1 + k2 * dtheta2\n\n        # Super-twisting algorithm with safe operations\n        u_proportional = -K1 * safe_sqrt(abs(sigma), min_value=1e-15) * smooth_sign(sigma)\n        z_new = z_prev - K2 * smooth_sign(sigma) * self.dt\n        u = u_proportional + z_new\n\n        # Saturation\n        u = np.clip(u, -self.max_force, self.max_force)\n\n        return STAOutput(u=u, state=(z_new, sigma), history={})",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef245e78"
  },
  {
    "id": "control_primitives_reference_33_cdca7915",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 33,
    "code": "def __init__(self, gains, max_force, dt):\n    # Validate immediately - fail fast\n    self.gains = [require_positive(g, f\"gains[{i}]\") for i, g in enumerate(gains)]\n    self.max_force = require_positive(max_force, \"max_force\")\n    self.dt = require_positive(dt, \"dt\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cdca7915"
  },
  {
    "id": "control_primitives_reference_34_862da74d",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 34,
    "code": "def compute_control(self, state):\n    sigma = compute_sliding_surface(state)\n\n    # Validate critical quantities in debug builds\n    if __debug__:\n        sigma = require_finite(sigma, \"sliding_surface\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "862da74d"
  },
  {
    "id": "control_primitives_reference_35_9900625e",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 35,
    "code": "# Clear and self-documenting\nresult = controller.compute_control(state, state_vars, history)\ncontrol_input = result.u\nsliding_surface = result.sigma  # Adaptive/Hybrid SMC only",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9900625e"
  },
  {
    "id": "control_primitives_reference_36_e0da9902",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 36,
    "code": "# Backwards-compatible with legacy code\nu, state, history = controller.compute_control(state, state_vars, history)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0da9902"
  },
  {
    "id": "control_primitives_reference_37_7ee5f040",
    "file": "docs\\controllers\\control_primitives_reference.md",
    "index": 37,
    "code": "# Efficient - no redundant computation\nresult = controller.compute_control(state, state_vars, history)\nif abs(result.sigma) < 0.01:\n    print(\"On sliding surface\")\n\n# Inefficient - re-computes sigma\nresult = controller.compute_control(state, state_vars, history)\nsigma = recompute_sliding_surface(state)  # Redundant!",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ee5f040"
  },
  {
    "id": "factory_system_guide_1_ab0f0813",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Single Responsibility - Each factory focuses on specific concerns\nEnterprise Factory: Comprehensive configuration, backwards compatibility\nClean SMC Factory: PSO optimization, research benchmarking\n\n# Dependency Injection - Controllers receive dependencies at creation\ncontroller = create_controller(\n    'classical_smc',\n    config=config,\n    gains=[10, 8, 15, 12, 50, 5]\n)\n\n# Type Safety - Explicit typing for all interfaces\ndef create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any:\n    ...",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab0f0813"
  },
  {
    "id": "factory_system_guide_2_91be223e",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    'sta_smc': {\n        'class': SuperTwistingSMC,\n        'config_class': STASMCConfig,\n        'default_gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n        'gain_count': 6,\n        # ...\n    },\n    # ... additional controllers\n}",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91be223e"
  },
  {
    "id": "factory_system_guide_3_b1d16267",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"PSO-friendly wrapper that simplifies the control interface.\"\"\"\n\n    def __init__(self, controller: SMCProtocol):\n        self.controller = controller\n        self._history = {}\n        self._state_vars = ()  # Controller-specific state\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Simplified interface for PSO fitness evaluation.\"\"\"\n        # Full interface: compute_control(state, state_vars, history)\n        # PSO interface: compute_control(state) -> np.ndarray\n        result = self.controller.compute_control(state, self._state_vars, self._history)\n        return np.array([self._extract_control_value(result)])",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1d16267"
  },
  {
    "id": "factory_system_guide_4_4f0fe913",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 4,
    "code": "from src.controllers.factory import (\n    create_controller,           # Main factory function\n    list_available_controllers,  # Discovery\n    get_default_gains,           # Gain specifications\n    SMCType,                     # Enum for controller types\n    SMCFactory,                  # Object-oriented interface\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4f0fe913"
  },
  {
    "id": "factory_system_guide_5_a69c691e",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Method 1: String-based creation\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n)\n\n# Method 2: Enum-based creation (type-safe)\ncontroller = SMCFactory.create_controller(\n    smc_type=SMCType.CLASSICAL,\n    config=SMCConfig(gains=[10, 8, 15, 12, 50, 5], max_force=100, dt=0.01)\n)\n\n# Method 3: Backwards-compatible aliases\ncontroller = create_classical_smc_controller(config, gains=[...])",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a69c691e"
  },
  {
    "id": "factory_system_guide_6_7982ce37",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_ALIASES = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n}\n\n# All these create the same controller:\ncreate_controller('classical_smc', ...)\ncreate_controller('classic_smc', ...)\ncreate_controller('smc_classical', ...)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7982ce37"
  },
  {
    "id": "factory_system_guide_7_e95a64e0",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe factory operations with timeout protection\n_factory_lock = threading.RLock()\n_LOCK_TIMEOUT = 10.0  # seconds\n\ndef create_controller(controller_type: str, ...) -> Any:\n    with _factory_lock:\n        # Thread-safe controller creation\n        controller_info = _get_controller_info(controller_type)\n        # ... validation and instantiation",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e95a64e0"
  },
  {
    "id": "factory_system_guide_8_06a4b8f3",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Priority order:\n# 1. Explicitly provided gains parameter\nif gains is not None:\n    return gains\n\n# 2. Config object with controller_defaults\nif hasattr(config, 'controller_defaults'):\n    if controller_type in config.controller_defaults:\n        return config.controller_defaults[controller_type].gains\n\n# 3. Registry default gains\nreturn controller_info['default_gains']",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06a4b8f3"
  },
  {
    "id": "factory_system_guide_9_ccd017c6",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(gains, controller_info, controller_type):\n    \"\"\"Validate controller gains with controller-specific rules.\"\"\"\n\n    # 1. Count validation\n    if len(gains) != controller_info['gain_count']:\n        raise ValueError(f\"Expected {controller_info['gain_count']} gains, got {len(gains)}\")\n\n    # 2. Finite values\n    if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in gains):\n        raise ValueError(\"All gains must be finite numbers\")\n\n    # 3. Positivity\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive\")\n\n    # 4. Controller-specific constraints\n    if controller_type == 'sta_smc' and len(gains) >= 2:\n        K1, K2 = gains[0], gains[1]\n        if K1 <= K2:\n            raise ValueError(\"Super-Twisting stability requires K1 > K2 > 0\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccd017c6"
  },
  {
    "id": "factory_system_guide_10_d77b8b09",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 10,
    "code": "from src.controllers.factory.smc_factory import (\n    SMCFactory,                  # Core factory class\n    SMCType,                     # Controller type enum\n    SMCConfig,                   # Configuration dataclass\n    create_smc_for_pso,          # PSO-optimized creation\n    get_gain_bounds_for_pso,     # PSO bounds\n    validate_smc_gains,          # Gain validation\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d77b8b09"
  },
  {
    "id": "factory_system_guide_11_c203fda0",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SMCConfig:\n    \"\"\"Clean configuration for all SMC controllers.\"\"\"\n\n    # Core parameters (common to all SMCs)\n    gains: List[float]\n    max_force: float = 100.0\n    dt: float = 0.01\n\n    # Optional dynamics model\n    dynamics_model: Optional[Any] = None\n\n    # Controller-specific parameters (use defaults if not specified)\n    boundary_layer: float = 0.01\n    damping_gain: float = 0.0\n\n    # Adaptive SMC specific\n    leak_rate: float = 0.1\n    adapt_rate_limit: float = 100.0\n    K_min: float = 0.1\n    K_max: float = 100.0\n    # ... additional parameters",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c203fda0"
  },
  {
    "id": "factory_system_guide_12_615225f7",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SMCGainSpec:\n    \"\"\"Specification of gain requirements for each SMC type.\"\"\"\n    controller_type: SMCType\n    n_gains: int\n    gain_names: List[str]\n    description: str\n\n    @property\n    def gain_bounds(self) -> List[tuple[float, float]]:\n        \"\"\"Default gain bounds for PSO optimization.\"\"\"\n        if self.controller_type == SMCType.CLASSICAL:\n            # [k1, k2, lam1, lam2, K, kd]\n            return [(0.1, 50.0)] * 4 + [(1.0, 200.0)] + [(0.0, 50.0)]\n        # ... controller-specific bounds\n\n# Pre-defined specifications\nSMC_GAIN_SPECS = {\n    SMCType.CLASSICAL: SMCGainSpec(\n        SMCType.CLASSICAL, 6,\n        [\"k1\", \"k2\", \"lam1\", \"lam2\", \"K\", \"kd\"],\n        \"Classical SMC with switching and damping gains\"\n    ),\n    # ... additional specifications\n}",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "615225f7"
  },
  {
    "id": "factory_system_guide_13_2fc1ed4f",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Direct from gains array\ncontroller = SMCFactory.create_from_gains(\n    smc_type=SMCType.CLASSICAL,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    dt=0.01\n)\n\n# From full configuration\nconfig = SMCConfig(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.02\n)\ncontroller = SMCFactory.create_controller(SMCType.CLASSICAL, config)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2fc1ed4f"
  },
  {
    "id": "factory_system_guide_14_79c1d7d1",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 14,
    "code": "from src.controllers.factory import create_smc_for_pso, get_gain_bounds_for_pso\n\n# Get PSO bounds for controller type\nlower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n# lower_bounds = [1.0, 1.0, 1.0, 1.0, 5.0, 0.1]\n# upper_bounds = [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]\n\n# PSO-friendly controller factory\ndef controller_factory(gains: np.ndarray):\n    return create_smc_for_pso(\n        smc_type=SMCType.CLASSICAL,\n        gains=gains,\n        max_force=100.0,\n        dt=0.01\n    )\n\n# Use in PSO optimization\nfrom src.optimizer.pso_optimizer import PSOTuner\n\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config='config.yaml',\n    seed=42\n)\n\nbest_gains, best_cost = tuner.optimize(\n    lower_bounds=lower_bounds,\n    upper_bounds=upper_bounds,\n    n_particles=30,\n    n_iterations=100\n)",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79c1d7d1"
  },
  {
    "id": "factory_system_guide_15_19582273",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_pso_controller_factory(smc_type: SMCType, **kwargs) -> Callable:\n    \"\"\"Create a PSO-optimized controller factory function.\"\"\"\n\n    def controller_factory(gains: Union[list, np.ndarray]) -> Any:\n        return create_smc_for_pso(smc_type, gains, **kwargs)\n\n    # Add PSO-required attributes\n    spec = SMC_GAIN_SPECS[smc_type]\n    controller_factory.n_gains = spec.n_gains\n    controller_factory.controller_type = smc_type.value\n    controller_factory.max_force = kwargs.get('max_force', 150.0)\n\n    return controller_factory",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19582273"
  },
  {
    "id": "factory_system_guide_16_026ab7d1",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"PSO-friendly wrapper that simplifies the control interface.\"\"\"\n\n    def __init__(self, controller: SMCProtocol):\n        self.controller = controller\n        self._history = {}\n\n        # Initialize state_vars based on controller type\n        controller_name = type(controller).__name__\n        if 'SuperTwisting' in controller_name:\n            self._state_vars = (0.0, 0.0)  # (z, sigma)\n        elif 'Hybrid' in controller_name:\n            self._state_vars = (k1_init, k2_init, 0.0)\n        else:\n            self._state_vars = ()\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Simplified compute_control for PSO fitness evaluation.\"\"\"\n        result = self.controller.compute_control(state, self._state_vars, self._history)\n\n        # Extract control value and return as numpy array\n        if hasattr(result, 'u'):\n            control_value = result.u\n        elif isinstance(result, dict) and 'u' in result:\n            control_value = result['u']\n        else:\n            control_value = result\n\n        return np.array([control_value])",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "026ab7d1"
  },
  {
    "id": "factory_system_guide_17_571350a9",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_gains(smc_type: SMCType, gains: np.ndarray) -> bool:\n    \"\"\"Validate gains for PSO particle evaluation.\"\"\"\n\n    spec = SMC_GAIN_SPECS[smc_type]\n\n    # Check length\n    if len(gains) != spec.n_gains:\n        return False\n\n    # Check positivity for surface gains\n    if any(g <= 0 for g in gains[:4]):\n        return False\n\n    # Controller-specific constraints\n    if smc_type == SMCType.SUPER_TWISTING:\n        K1, K2 = gains[0], gains[1]\n        if K1 <= K2:  # Stability requirement\n            return False\n\n    return True",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "571350a9"
  },
  {
    "id": "factory_system_guide_18_fdf5af93",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 18,
    "code": "# 1. Direct parameter passing\ncontroller = create_controller(\n    'classical_smc',\n    config=None,\n    gains=[10, 8, 15, 12, 50, 5]\n)\n\n# 2. Configuration object\nfrom src.config import load_config\nconfig = load_config('config.yaml')\ncontroller = create_controller('classical_smc', config=config)\n\n# 3. Configuration with gain override\ncontroller = create_controller(\n    'classical_smc',\n    config=config,\n    gains=[20, 15, 12, 8, 35, 5]  # Overrides config\n)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fdf5af93"
  },
  {
    "id": "factory_system_guide_19_db316252",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\ndef _extract_controller_parameters(config, controller_type, controller_info):\n    \"\"\"Extract controller-specific parameters from configuration.\"\"\"\n\n    if hasattr(config, 'controllers') and controller_type in config.controllers:\n        controller_config = config.controllers[controller_type]\n\n        # Pydantic model\n        if hasattr(controller_config, 'model_dump'):\n            return controller_config.model_dump()\n\n        # Dictionary\n        elif isinstance(controller_config, dict):\n            return controller_config.copy()\n\n        # Object with attributes\n        else:\n            return {\n                attr: getattr(controller_config, attr)\n                for attr in dir(controller_config)\n                if not attr.startswith('_') and not callable(getattr(controller_config, attr))\n            }\n\n    return {}",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "db316252"
  },
  {
    "id": "factory_system_guide_20_8db209b0",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 20,
    "code": "from src.controllers.factory.deprecation import check_deprecated_config\n\n# Automatic migration of deprecated parameters\ncontroller_params = check_deprecated_config(controller_type, controller_params)\n\n# Example migration:\n# Old: {'switching_gain': 50.0}\n# New: {'K': 50.0}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8db209b0"
  },
  {
    "id": "factory_system_guide_21_df22deef",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Enterprise Factory\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config,\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n)\n\n# Clean SMC Factory\ncontroller = SMCFactory.create_from_gains(\n    smc_type=SMCType.CLASSICAL,\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.02\n)\n\n# Internal creation (ClassicalSMC constructor)\ncontroller = ClassicalSMC(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.02,\n    dynamics_model=dynamics_model\n)",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "df22deef"
  },
  {
    "id": "factory_system_guide_22_94172e7f",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\n# Clean SMC Factory\ncontroller = SMCFactory.create_from_gains(\n    smc_type=SMCType.ADAPTIVE,\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],  # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    max_force=100.0,\n    dt=0.01,\n    leak_rate=0.1,\n    adapt_rate_limit=100.0,\n    K_min=0.1,\n    K_max=100.0,\n    K_init=10.0\n)\n\n# Internal creation (AdaptiveSMC constructor)\ncontroller = AdaptiveSMC(\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n    dt=0.01,\n    max_force=100.0,\n    leak_rate=0.1,\n    adapt_rate_limit=100.0,\n    K_min=0.1,\n    K_max=100.0,\n    smooth_switch=True,\n    boundary_layer=0.01,\n    dead_zone=0.05\n)",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94172e7f"
  },
  {
    "id": "factory_system_guide_23_744898d6",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Clean SMC Factory\ncontroller = SMCFactory.create_from_gains(\n    smc_type=SMCType.SUPER_TWISTING,\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0],  # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    max_force=100.0,\n    dt=0.01,\n    damping_gain=0.0,\n    boundary_layer=0.01,\n    dynamics_model=dynamics_model\n)\n\n# Constraint validation (K1 > K2)\nK1, K2 = gains[0], gains[1]\nif K1 <= K2:\n    raise ValueError(\"Super-Twisting stability requires K1 > K2 > 0\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "744898d6"
  },
  {
    "id": "factory_system_guide_24_75354416",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 24,
    "code": "# Hybrid controller requires special handling - sub-configs\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\nfrom src.controllers.smc.algorithms.hybrid.config import HybridMode\n\nclassical_config = ClassicalSMCConfig(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.02\n)\n\nadaptive_config = AdaptiveSMCConfig(\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n    max_force=150.0,\n    dt=0.001\n)\n\ncontroller = create_controller(\n    controller_type='hybrid_adaptive_sta_smc',\n    config=None,  # Not used for hybrid\n    gains=[18.0, 12.0, 10.0, 8.0]  # [k1, k2, \u03bb1, \u03bb2]\n)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75354416"
  },
  {
    "id": "factory_system_guide_25_783bb89d",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 25,
    "code": "# List available controllers\navailable = list_available_controllers()\n# ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n\n# Get controller metadata\nspec = SMC_GAIN_SPECS[SMCType.CLASSICAL]\nprint(f\"Controller: {spec.description}\")\nprint(f\"Gains: {spec.gain_names}\")\nprint(f\"Count: {spec.n_gains}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "783bb89d"
  },
  {
    "id": "factory_system_guide_26_3ee59110",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# Invalid default gains are automatically corrected\ncontroller_gains = [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]\n\ntry:\n    _validate_controller_gains(controller_gains, controller_info, 'sta_smc')\nexcept ValueError as e:\n    if gains is None:  # Only auto-fix if using default gains\n        if controller_type == 'sta_smc':\n            # Fix K1 > K2 requirement\n            controller_gains = [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # K1=25 > K2=15\n\n        # Re-validate after fix\n        _validate_controller_gains(controller_gains, controller_info, controller_type)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ee59110"
  },
  {
    "id": "factory_system_guide_27_5fc74af4",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\ndef _create_dynamics_model(config: Any) -> Optional[Any]:\n    \"\"\"Create dynamics model from configuration.\"\"\"\n\n    # Try to get existing dynamics model\n    if hasattr(config, 'dynamics_model'):\n        return config.dynamics_model\n    elif hasattr(config, 'physics'):\n        return DIPDynamics(config.physics)\n    elif hasattr(config, 'dip_params'):\n        return DIPDynamics(config.dip_params)\n\n    return None",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fc74af4"
  },
  {
    "id": "factory_system_guide_28_8dbd5cfa",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\n# If config creation fails, use fallback with ALL required parameters\ntry:\n    controller_config = config_class(**config_params)\nexcept Exception as e:\n    if controller_type == 'classical_smc':\n        fallback_params = {\n            'gains': controller_gains,\n            'max_force': 150.0,\n            'dt': 0.001,\n            'boundary_layer': 0.02,  # Required\n            'regularization_alpha': 1e-4,\n            'min_regularization': 1e-10,\n            'max_condition_number': 1e14,\n            'use_adaptive_regularization': True\n        }\n\n    controller_config = config_class(**fallback_params)",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dbd5cfa"
  },
  {
    "id": "factory_system_guide_29_444ecabb",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Use create_pso_controller_factory for consistent interface\nfactory = create_pso_controller_factory(SMCType.CLASSICAL, max_force=100.0, dt=0.01)\n\n# 2. Validate gains before PSO evaluation\nvalid_mask = np.array([validate_smc_gains(SMCType.CLASSICAL, gains) for gains in particles])\ncosts[~valid_mask] = PENALTY_VALUE\n\n# 3. Use appropriate bounds for each controller type\nlower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# 4. Add controller-specific constraints to PSO validation\nif smc_type == SMCType.SUPER_TWISTING:\n    K1, K2 = gains[0], gains[1]\n    if K1 <= K2:\n        return False  # Violates stability constraint",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "444ecabb"
  },
  {
    "id": "factory_system_guide_30_3f52f393",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Use frozen dataclasses for immutable configuration\n@dataclass(frozen=True)\nclass ControllerConfig:\n    gains: List[float]\n    max_force: float\n\n# 2. Validate parameters in __post_init__\ndef __post_init__(self):\n    if self.max_force <= 0:\n        raise ValueError(\"max_force must be positive\")\n\n# 3. Provide sensible defaults\nboundary_layer: float = 0.01\ndt: float = 0.01",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f52f393"
  },
  {
    "id": "factory_system_guide_31_e930ca49",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Specific exception types\nclass FactoryConfigurationError(ValueError):\n    pass\n\n# 2. Informative error messages\nraise ValueError(\n    f\"Controller '{controller_info.get('description', 'unknown')}' \"\n    f\"requires {expected_count} gains, got {len(gains)}\"\n)\n\n# 3. Graceful fallback\ntry:\n    controller_config = config_class(**config_params)\nexcept Exception as e:\n    logger.debug(f\"Could not create full config, using minimal config: {e}\")\n    controller_config = config_class(**fallback_params)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e930ca49"
  },
  {
    "id": "factory_system_guide_32_c3bfab99",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\n# Solution: Use canonical name or alias\ncontroller = create_controller('classical_smc', ...)  # Canonical\ncontroller = create_controller('classic_smc', ...)    # Alias (auto-normalized)",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3bfab99"
  },
  {
    "id": "factory_system_guide_33_9a4d39ad",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\n# Solution: Ensure K1 > K2 in gain array\ngains = [25.0, 15.0, ...]  # K1=25 > K2=15 \u2713\ngains = [15.0, 25.0, ...]  # K1=15 < K2=25 \u2717",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a4d39ad"
  },
  {
    "id": "factory_system_guide_34_1e7c84cd",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 34,
    "code": "# Solution: Provide correct number of gains\ngains = [k1, k2, lam1, lam2, gamma]  # 5 gains",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e7c84cd"
  },
  {
    "id": "factory_system_guide_35_1e637e08",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 35,
    "code": "# Solution: Install optional dependencies or use available controllers\navailable = list_available_controllers()\nprint(f\"Available: {available}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e637e08"
  },
  {
    "id": "factory_system_guide_36_ad110194",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 36,
    "code": "# Solution: Check gain bounds and constraints\nlower, upper = get_gain_bounds_for_pso(SMCType.SUPER_TWISTING)\n# Ensure K1 bounds > K2 bounds for STA-SMC\n# lower[0] > lower[1], upper[0] > upper[1]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad110194"
  },
  {
    "id": "factory_system_guide_37_aee9e365",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 37,
    "code": "# Solution: Ensure wrapper extracts control value correctly\nif hasattr(result, 'u'):\n    control_value = result.u\nelif isinstance(result, dict) and 'u' in result:\n    control_value = result['u']\nelse:\n    control_value = result  # Fallback",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aee9e365"
  },
  {
    "id": "factory_system_guide_38_79331e0a",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 38,
    "code": "# example-metadata:\n# runnable: false\n\n# Solution: Check configuration structure\n# Expected: config.controllers.classical_smc.gains\n# Or: config.controller_defaults.classical_smc.gains",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79331e0a"
  },
  {
    "id": "factory_system_guide_39_201d749a",
    "file": "docs\\controllers\\factory_system_guide.md",
    "index": 39,
    "code": "# Solution: Ensure config has physics parameters\nif hasattr(config, 'physics'):\n    dynamics_model = DIPDynamics(config.physics)\nelse:\n    # Use None if dynamics not needed\n    dynamics_model = None",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "201d749a"
  },
  {
    "id": "hybrid_smc_technical_guide_1_5fa157ee",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass HybridAdaptiveSTASMC:\n    \"\"\"\n    Modular hybrid controller with clear separation of concerns:\n\n    Components:\n    - Sliding surface computation (absolute/relative modes)\n    - Adaptive gain management (with anti-windup)\n    - Super-twisting control law (finite-time convergent)\n    - Equivalent control (model-based feedforward)\n    - Cart recentering (with hysteresis)\n    \"\"\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fa157ee"
  },
  {
    "id": "hybrid_smc_technical_guide_2_0e3c12cb",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 2,
    "code": "emergency_reset = (\n    not np.isfinite(u_sat) or abs(u_sat) > max_force * 2 or\n    not np.isfinite(k1_new) or k1_new > k1_max * 0.9 or\n    not np.isfinite(k2_new) or k2_new > k2_max * 0.9 or\n    state_norm > 10.0 or velocity_norm > 50.0\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e3c12cb"
  },
  {
    "id": "hybrid_smc_technical_guide_3_66d40e8c",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _compute_sliding_surface(self, state: np.ndarray) -> float:\n    \"\"\"Compute unified sliding surface with dual formulation support.\n\n    Mathematical Implementation:\n    s = c1*(\u03b8\u0307\u2081 + \u03bb\u2081*\u03b8\u2081) + c2*(\u03b8\u0307\u2082 + \u03bb\u2082*\u03b8\u2082) + cart_term\n\n    or (relative mode):\n    s = c1*(\u03b8\u0307\u2081 + \u03bb\u2081*\u03b8\u2081) + c2*((\u03b8\u0307\u2082-\u03b8\u0307\u2081) + \u03bb\u2082*(\u03b8\u2082-\u03b8\u2081)) + cart_term\n    \"\"\"\n    x, th1, th2, xdot, th1dot, th2dot = state\n\n    if self.use_relative_surface:\n        rel_dot = th2dot - th1dot\n        rel_ang = th2 - th1\n        pendulum_term = self.c1 * (th1dot + self.lambda1 * th1) + \\\n                       self.c2 * (rel_dot + self.lambda2 * rel_ang)\n    else:\n        pendulum_term = self.c1 * (th1dot + self.lambda1 * th1) + \\\n                       self.c2 * (th2dot + self.lambda2 * th2)\n\n    cart_term = self.cart_gain * (xdot + self.cart_lambda * x)\n    return float(-(pendulum_term - cart_term))",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "66d40e8c"
  },
  {
    "id": "hybrid_smc_technical_guide_4_a54e37b4",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef _update_adaptive_gains(self, abs_s: float, k1_prev: float, k2_prev: float):\n    \"\"\"Update adaptive gains with self-tapering and anti-windup.\n\n    Implements:\n    - State-based adaptation: \u03b3|s|\n    - Self-tapering: \u03c4(|s|) = |s|/(|s| + \u03b5)\n    - Rate limiting: |k\u0307| \u2264 rate_limit\n    - Anti-windup: Freeze when saturated + near equilibrium\n    \"\"\"\n    if abs_s <= self.dead_zone:\n        # In dead zone: gentle leak to prevent ratcheting\n        k1_dot = -self.gain_leak\n        k2_dot = -self.gain_leak\n    else:\n        # Normal adaptation with self-tapering\n        taper_factor = self._compute_taper_factor(abs_s)\n        k1_raw = self.gamma1 * abs_s * taper_factor\n        k2_raw = self.gamma2 * abs_s * taper_factor\n\n        # Rate limiting for stability\n        k1_dot = min(k1_raw, self.adapt_rate_limit)\n        k2_dot = min(k2_raw, self.adapt_rate_limit)\n\n    return k1_dot, k2_dot",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a54e37b4"
  },
  {
    "id": "hybrid_smc_technical_guide_5_87371fbd",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 5,
    "code": "# Primary PSO parameters [c1, \u03bb1, c2, \u03bb2]\ngains = [77.6216, 44.449, 17.3134, 14.25]  # Optimal PSO result\n\n# Fixed internal parameters (not PSO-tuned)\nk1_init = 2.0      # Initial adaptive gain 1\nk2_init = 1.0      # Initial adaptive gain 2\ngamma1 = 0.5       # Adaptation rate 1\ngamma2 = 0.3       # Adaptation rate 2\ndead_zone = 0.01   # Adaptation dead zone",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87371fbd"
  },
  {
    "id": "hybrid_smc_technical_guide_6_bf9c25d8",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef fitness_function(gains_array):\n    \"\"\"PSO fitness evaluation for hybrid controller.\n\n    The hybrid controller's complexity requires careful fitness design:\n    - Control effort weighted heavily (prevents aggressive adaptation)\n    - Tracking error with time-varying weights\n    - Stability margins included in cost\n    \"\"\"\n    controller = create_hybrid_controller(gains_array)\n\n    # Multi-objective fitness components\n    tracking_error = compute_tracking_metrics(controller)\n    control_effort = compute_control_energy(controller)\n    stability_margin = compute_stability_measures(controller)\n\n    return w1*tracking_error + w2*control_effort + w3*stability_margin",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bf9c25d8"
  },
  {
    "id": "hybrid_smc_technical_guide_7_4964b98c",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of controller logic ...\n\n    # Missing return statement here!\n\ndef reset(self) -> None:\n    # ... reset logic ...\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n    # ^^^^ Variables not in scope! ^^^^",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4964b98c"
  },
  {
    "id": "hybrid_smc_technical_guide_8_45d93232",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of controller logic ...\n\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\ndef reset(self) -> None:\n    # ... reset logic only ...\n    pass",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45d93232"
  },
  {
    "id": "hybrid_smc_technical_guide_9_b2ee849e",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Add to pre-commit hooks:\n# mypy type checking for return type consistency\ndef check_return_types():\n    \"\"\"Verify all controller methods return expected types.\"\"\"\n    assert isinstance(controller.compute_control(...), HybridSTAOutput)",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2ee849e"
  },
  {
    "id": "hybrid_smc_technical_guide_10_94861a95",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 10,
    "code": "def test_hybrid_controller_return_type():\n    \"\"\"Validate hybrid controller returns proper types.\"\"\"\n    controller = HybridAdaptiveSTASMC(gains=[10, 5, 8, 3])\n\n    state = np.zeros(6)\n    result = controller.compute_control(state)\n\n    assert isinstance(result, HybridSTAOutput)\n    assert len(result.state_vars) == 3  # (k1, k2, u_int)\n    assert isinstance(result.control, float)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94861a95"
  },
  {
    "id": "hybrid_smc_technical_guide_11_1e663f6e",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 11,
    "code": "from src.controllers.smc import HybridAdaptiveSTASMC\n\n# Create controller with optimized gains\ncontroller = HybridAdaptiveSTASMC(\n    gains=[77.6216, 44.449, 17.3134, 14.25],\n    dt=0.01,\n    max_force=100.0,\n    k1_init=2.0,\n    k2_init=1.0,\n    gamma1=0.5,\n    gamma2=0.3,\n    dead_zone=0.01\n)\n\n# Initialize controller state\nstate_vars = controller.initialize_state()\nhistory = controller.initialize_history()\n\n# Main control loop\nfor t in simulation_time:\n    state = get_system_state()  # [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\n\n    result = controller.compute_control(state, state_vars, history)\n\n    # Extract results\n    control_force = result.control\n    state_vars = result.state_vars  # (k1, k2, u_int)\n    history = result.history\n    sliding_surface = result.sliding_surface\n\n    # Apply control to system\n    apply_control(control_force)",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e663f6e"
  },
  {
    "id": "hybrid_smc_technical_guide_12_d4598a8c",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 12,
    "code": "from src.controllers.factory import create_controller\n\n# Create via factory (recommended)\ncontroller = create_controller(\n    'hybrid_adaptive_sta_smc',\n    gains=[77.6216, 44.449, 17.3134, 14.25],\n    max_force=100.0\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4598a8c"
  },
  {
    "id": "hybrid_smc_technical_guide_13_f44034f7",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 13,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\n\n# Define PSO search space for hybrid controller\npso_bounds = [\n    (1.0, 100.0),   # c1: First pendulum weight\n    (1.0, 100.0),   # \u03bb1: First pendulum damping\n    (1.0, 20.0),    # c2: Second pendulum weight\n    (1.0, 20.0),    # \u03bb2: Second pendulum damping\n]\n\n# Run PSO optimization\ntuner = PSOTuner(bounds=pso_bounds, n_particles=20, iters=200)\nbest_gains, best_cost = tuner.optimize(\n    controller_type='hybrid_adaptive_sta_smc',\n    dynamics=dynamics_model\n)\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Best cost: {best_cost}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f44034f7"
  },
  {
    "id": "hybrid_smc_technical_guide_14_de95fff5",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Complete simulation with PSO-optimized hybrid controller\ndef run_hybrid_simulation():\n    # Load configuration\n    config = load_config('config.yaml')\n\n    # Create optimized controller\n    controller = create_controller(\n        'hybrid_adaptive_sta_smc',\n        gains=[77.6216, 44.449, 17.3134, 14.25],  # PSO result\n        **config.controllers.hybrid_adaptive_sta_smc\n    )\n\n    # Run simulation\n    results = run_simulation(\n        controller=controller,\n        dynamics=dynamics_model,\n        duration=10.0,\n        dt=0.01\n    )\n\n    return results",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "de95fff5"
  },
  {
    "id": "hybrid_smc_technical_guide_15_adfda483",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef monitor_hybrid_controller(controller, state, result):\n    \"\"\"Monitor hybrid controller performance indicators.\"\"\"\n\n    # Extract monitoring data\n    k1, k2, u_int = result.state_vars\n    s = result.sliding_surface\n\n    # Performance indicators\n    adaptation_rate = (k1 + k2) / (controller.k1_max + controller.k2_max)\n    surface_distance = abs(s)\n    integral_usage = abs(u_int) / controller.u_int_max\n\n    # Warning conditions\n    if adaptation_rate > 0.8:\n        print(f\"WARNING: High adaptation rate: {adaptation_rate:.3f}\")\n\n    if surface_distance > 1.0:\n        print(f\"WARNING: Large sliding surface: {surface_distance:.3f}\")\n\n    if integral_usage > 0.9:\n        print(f\"WARNING: Integral near saturation: {integral_usage:.3f}\")\n\n    return {\n        'adaptation_rate': adaptation_rate,\n        'surface_distance': surface_distance,\n        'integral_usage': integral_usage\n    }",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "adfda483"
  },
  {
    "id": "hybrid_smc_technical_guide_16_f6728bc4",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 16,
    "code": "def analyze_hybrid_performance(history):\n    \"\"\"Analyze hybrid controller historical performance.\"\"\"\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Extract time series\n    k1_history = np.array(history['k1'])\n    k2_history = np.array(history['k2'])\n    s_history = np.array(history['s'])\n    u_int_history = np.array(history['u_int'])\n\n    # Create performance plots\n    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n    # Adaptive gains evolution\n    axes[0,0].plot(k1_history, label='k1')\n    axes[0,0].plot(k2_history, label='k2')\n    axes[0,0].set_title('Adaptive Gains Evolution')\n    axes[0,0].legend()\n\n    # Sliding surface\n    axes[0,1].plot(s_history)\n    axes[0,1].set_title('Sliding Surface')\n    axes[0,1].axhline(y=0, color='r', linestyle='--')\n\n    # Integral term\n    axes[1,0].plot(u_int_history)\n    axes[1,0].set_title('Integral Control Term')\n\n    # Phase portrait (s vs \u1e61)\n    s_dot = np.gradient(s_history)\n    axes[1,1].plot(s_history, s_dot)\n    axes[1,1].set_title('Sliding Surface Phase Portrait')\n    axes[1,1].set_xlabel('s')\n    axes[1,1].set_ylabel('\u1e61')\n\n    plt.tight_layout()\n    return fig",
    "lines": 39,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6728bc4"
  },
  {
    "id": "hybrid_smc_technical_guide_17_94a82348",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 17,
    "code": "# Uncertainty handling performance\nuncertainties = {\n    'mass_variation': \u00b120%,      # Result: Stable\n    'length_variation': \u00b115%,    # Result: Stable\n    'friction_variation': \u00b150%,  # Result: Stable\n    'sensor_noise': 0.1\u00b0 RMS,    # Result: Robust\n    'actuator_delay': 5ms,       # Result: Acceptable\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94a82348"
  },
  {
    "id": "hybrid_smc_technical_guide_18_cfe98d69",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance profiling results\ncomputation_times = {\n    'sliding_surface': '12.3 \u03bcs',      # Fast\n    'adaptive_gains': '18.7 \u03bcs',       # Moderate\n    'equivalent_control': '45.2 \u03bcs',   # Expensive (matrix ops)\n    'total_per_step': '89.4 \u03bcs',      # Real-time capable at 1kHz\n}\n\n# Memory usage\nmemory_footprint = {\n    'controller_object': '2.1 KB',\n    'history_storage': '15.6 KB/minute',\n    'peak_simulation': '156 MB',       # Including visualization\n}",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfe98d69"
  },
  {
    "id": "hybrid_smc_technical_guide_19_fe8ca5b6",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 19,
    "code": "# Increase damping\ndamping_gain = 5.0  # From default 3.0\n\n# Reduce adaptation rates\ngamma1 = 0.3  # From default 0.5\ngamma2 = 0.2  # From default 0.3\n\n# Widen dead zone\ndead_zone = 0.02  # From default 0.01",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe8ca5b6"
  },
  {
    "id": "hybrid_smc_technical_guide_20_15764345",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 20,
    "code": "# Increase surface weights\ngains = [100, 60, 20, 18]  # Higher c1, \u03bb1\n\n# Increase adaptation rates\ngamma1 = 0.8\ngamma2 = 0.5\n\n# Enable equivalent control\nenable_equivalent = True",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15764345"
  },
  {
    "id": "hybrid_smc_technical_guide_21_b45f8d77",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 21,
    "code": "# Increase regularization\nmatrix_regularization = 1e-8  # In equivalent control\n\n# Reduce adaptation rate limits\nadapt_rate_limit = 2.0  # From default 5.0\n\n# Check system conditioning\ncondition_number = np.linalg.cond(inertia_matrix)\nif condition_number > 1e12:\n    print(\"WARNING: Ill-conditioned system\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b45f8d77"
  },
  {
    "id": "hybrid_smc_technical_guide_22_0bbc25bd",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_hybrid_controller(controller, state, result):\n    \"\"\"Comprehensive controller diagnostics.\"\"\"\n\n    diagnostics = {}\n\n    # Extract current values\n    k1, k2, u_int = result.state_vars\n    s = result.sliding_surface\n\n    # Check adaptation health\n    diagnostics['adaptation_active'] = abs(s) > controller.dead_zone\n    diagnostics['gains_saturated'] = (k1 >= controller.k1_max * 0.9 or\n                                    k2 >= controller.k2_max * 0.9)\n\n    # Check numerical health\n    diagnostics['values_finite'] = all(np.isfinite([k1, k2, u_int, s]))\n    diagnostics['within_bounds'] = abs(result.control) <= controller.max_force\n\n    # Performance indicators\n    diagnostics['surface_distance'] = abs(s)\n    diagnostics['adaptation_ratio'] = (k1 + k2) / (controller.k1_max + controller.k2_max)\n\n    return diagnostics",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bbc25bd"
  },
  {
    "id": "hybrid_smc_technical_guide_23_f7f52729",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_hybrid_parameters(gains, config):\n    \"\"\"Validate hybrid controller parameters for stability.\"\"\"\n\n    c1, lambda1, c2, lambda2 = gains\n\n    checks = {\n        'positive_gains': all(g > 0 for g in [c1, lambda1, c2, lambda2]),\n        'reasonable_ratios': c1/lambda1 > 0.5 and c2/lambda2 > 0.5,\n        'adaptation_bounds': config.k1_max > config.k1_init * 5,\n        'dead_zone_valid': config.dead_zone <= config.sat_soft_width,\n    }\n\n    if not all(checks.values()):\n        failed = [k for k, v in checks.items() if not v]\n        raise ValueError(f\"Parameter validation failed: {failed}\")\n\n    return True",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f7f52729"
  },
  {
    "id": "hybrid_smc_technical_guide_24_445d1138",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 24,
    "code": "# Pre-compile frequent calculations\n@functools.lru_cache(maxsize=128)\ndef cached_matrix_operations(state_tuple):\n    \"\"\"Cache expensive matrix operations.\"\"\"\n    return compute_physics_matrices(np.array(state_tuple))\n\n# Vectorized operations where possible\ndef vectorized_adaptation(s_values, gamma_values):\n    \"\"\"Batch adaptive gain updates.\"\"\"\n    return gamma_values * np.abs(s_values)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "445d1138"
  },
  {
    "id": "hybrid_smc_technical_guide_25_b928d3fc",
    "file": "docs\\controllers\\hybrid_smc_technical_guide.md",
    "index": 25,
    "code": "# Limit history storage\nmax_history_length = 1000  # Keep only recent samples\n\n# Use circular buffers for real-time applications\nfrom collections import deque\nhistory = {\n    'k1': deque(maxlen=max_history_length),\n    'k2': deque(maxlen=max_history_length),\n    's': deque(maxlen=max_history_length),\n}",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b928d3fc"
  },
  {
    "id": "index_1_c196c1d2",
    "file": "docs\\controllers\\index.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    config=config\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c196c1d2"
  },
  {
    "id": "index_2_370d513c",
    "file": "docs\\controllers\\index.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.factory import create_smc_for_pso, get_gain_bounds_for_pso\nfrom src.controllers.factory import SMCType\n\nlower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.CLASSICAL, gains)\n\n# Use with PSO tuner...",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "370d513c"
  },
  {
    "id": "index_3_7a514497",
    "file": "docs\\controllers\\index.md",
    "index": 3,
    "code": "from src.utils.control import saturate, smooth_sign, dead_zone\n\n# Chattering reduction\nu_switch = -K * saturate(sigma, epsilon=0.01, method='tanh', slope=3.0)\n\n# Adaptive gain freeze inside dead zone\nif abs(sigma) <= dead_zone_threshold:\n    dK = 0.0\nelse:\n    dK = gamma * abs(sigma) - leak_rate * (K - K_init)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a514497"
  },
  {
    "id": "mpc_technical_guide_1_fae3e153",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 1,
    "code": "for i in range(n):\n    \u03b4 = max(eps, 1e-4 * max(|x_eq[i]|, 1.0))\n    A[:, i] = [f(x_eq + \u03b4e\u1d62, u_eq) - f(x_eq - \u03b4e\u1d62, u_eq)] / (2\u03b4)\n\n\u03b4_u = max(eps, 1e-4 * max(|u_eq|, 1.0))\nB = [f(x_eq, u_eq + \u03b4_u) - f(x_eq, u_eq - \u03b4_u)] / (2\u03b4_u)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fae3e153"
  },
  {
    "id": "mpc_technical_guide_2_04bf4b8c",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef _numeric_linearize_continuous(dyn, x_eq, u_eq, eps=1e-6):\n    \"\"\"\n    Compute Jacobian matrices A, B around (x_eq, u_eq).\n\n    Returns:\n        A: \u2202f/\u2202x \u2208 \u211d\u207f\u02e3\u207f\n        B: \u2202f/\u2202u \u2208 \u211d\u207f\u02e3\u1d50\n    \"\"\"\n    n = x_eq.size\n    A = np.zeros((n, n))\n\n    for i in range(n):\n        \u03b4 = max(eps, 1e-4 * max(abs(x_eq[i]), 1.0))\n        \u03b4 = max(\u03b4, 1e-12)  # Prevent division by zero\n\n        f_plus = dyn.f(x_eq + \u03b4*e_i, u_eq)\n        f_minus = dyn.f(x_eq - \u03b4*e_i, u_eq)\n        A[:, i] = (f_plus - f_minus) / (2*\u03b4)\n\n    \u03b4_u = max(eps, 1e-4 * max(abs(u_eq), 1.0))\n    \u03b4_u = max(\u03b4_u, 1e-12)\n\n    B = (dyn.f(x_eq, u_eq + \u03b4_u) - dyn.f(x_eq, u_eq - \u03b4_u)) / (2*\u03b4_u)\n    return A, B",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04bf4b8c"
  },
  {
    "id": "mpc_technical_guide_3_70649985",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _discretize_exact(A_c, B_c, dt):\n    \"\"\"\n    Exact ZOH discretization via matrix exponential.\n\n    Theory:\n        x(t+\u0394t) = exp(A_c \u0394t) x(t) + [\u222b\u2080^\u0394t exp(A_c \u03c4) d\u03c4] B_c u(t)\n\n    Implementation:\n        M = [A_c, B_c; 0, 0]\n        exp(M \u0394t) = [A_d, B_d; 0, I]\n    \"\"\"\n    n = A_c.shape[0]\n    M = np.zeros((n+1, n+1))\n    M[:n, :n] = A_c\n    M[:n, n:] = B_c\n\n    M_exp = expm(M * dt)  # scipy.linalg.expm\n\n    A_d = M_exp[:n, :n]\n    B_d = M_exp[:n, n:].reshape(n, 1)\n    return A_d, B_d",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70649985"
  },
  {
    "id": "mpc_technical_guide_4_345e44f5",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Decision variables\nX = cp.Variable((6, N+1))  # State trajectory\nU = cp.Variable((1, N))    # Control sequence\n\n# Cost function\nQ = diag([q_x, q_\u03b8, q_\u03b8, q_\u1e8b, q_\u03b8\u0307, q_\u03b8\u0307])\nR = r_u\n\nobj = 0\nconstraints = [X[:, 0] == x\u2080]\n\nfor k in range(N):\n    # Stage cost\n    e_k = X[:, k] - x_ref[:, k]\n    obj += cp.quad_form(e_k, Q) + cp.quad_form(U[:, k], R)\n\n    # Dynamics constraint\n    constraints += [X[:, k+1] == A_d @ X[:, k] + B_d @ U[:, k]]\n\n    # Input bounds\n    constraints += [cp.abs(U[0, k]) <= max_force]\n\n    # State bounds\n    constraints += [\n        cp.abs(X[0, k]) <= max_cart_pos,\n        cp.abs(X[1, k] - \u03c0) <= max_theta_dev,\n        cp.abs(X[2, k] - \u03c0) <= max_theta_dev\n    ]\n\n# Terminal cost\ne_N = X[:, N] - x_ref[:, N]\nobj += cp.quad_form(e_N, Q)\n\nproblem = cp.Problem(cp.Minimize(obj), constraints)",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "345e44f5"
  },
  {
    "id": "mpc_technical_guide_5_6e267c41",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 5,
    "code": "# Warm start with previous solution\nU.value = U_prev.reshape(1, -1)\n\n# Solve (prefer OSQP)\nproblem.solve(solver=cp.OSQP, warm_start=True, verbose=False)\n\nif problem.status in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:\n    u_optimal = U.value[0, 0]\n    U_prev = U.value.reshape(-1)  # Cache for next step\nelse:\n    u_optimal = safe_fallback(x\u2080)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e267c41"
  },
  {
    "id": "mpc_technical_guide_6_455227d4",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 6,
    "code": "\u03b8_err = (\u03b8\u2081 - \u03c0) + (\u03b8\u2082 - \u03c0)\n   \u03b8\u0307_err = \u03b8\u0307\u2081 + \u03b8\u0307\u2082\n   u = -k_p \u03b8_err - k_d \u03b8\u0307_err",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "455227d4"
  },
  {
    "id": "mpc_technical_guide_7_42991651",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef _safe_fallback(self, x\u2080):\n    # Prefer SMC if instantiated\n    if self._fallback is not None:\n        try:\n            u, state, history = self._fallback.compute_control(x\u2080, ...)\n            return clip(u, -max_force, max_force)\n        except:\n            pass  # Degrade to PD\n\n    # Conservative PD on angles\n    \u03b8_err = (x\u2080[1] - \u03c0) + (x\u2080[2] - \u03c0)\n    \u03b8\u0307_err = x\u2080[4] + x\u2080[5]\n    u = -self._pd_kp * \u03b8_err - self._pd_kd * \u03b8\u0307_err\n    return clip(u, -max_force, max_force)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42991651"
  },
  {
    "id": "mpc_technical_guide_8_b5f8b687",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 8,
    "code": "def ref_fn(t):\n    \"\"\"Time-varying reference trajectory.\"\"\"\n    x_target = 0.5 * sin(0.5*\u03c0*t)  # Sinusoidal cart motion\n    return np.array([x_target, \u03c0, \u03c0, 0, 0, 0])\n\nmpc.set_reference(ref_fn)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5f8b687"
  },
  {
    "id": "mpc_technical_guide_9_1f249616",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 9,
    "code": "if max_du is not None:\n    du = clip(u_cmd - u_last, -max_du, max_du)\n    u_cmd = u_last + du",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f249616"
  },
  {
    "id": "mpc_technical_guide_10_3cb023a4",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass MPCWeights:\n    \"\"\"Cost function weights for MPC optimization.\"\"\"\n    q_x: float = 1.0          # Cart position\n    q_theta: float = 10.0     # Pendulum angles\n    q_xdot: float = 0.1       # Cart velocity\n    q_thetadot: float = 0.5   # Angular velocities\n    r_u: float = 1e-2         # Input effort\n\nclass MPCController:\n    \"\"\"Linear MPC for double-inverted pendulum.\"\"\"\n\n    def __init__(\n        self,\n        dynamics_model: DoubleInvertedPendulum,\n        horizon: int = 20,\n        dt: float = 0.02,\n        weights: Optional[MPCWeights] = None,\n        max_force: float = 20.0,\n        max_cart_pos: float = 2.4,\n        max_theta_dev: float = 0.5,\n        use_exact_discretization: bool = True,\n        fallback_smc_gains: Optional[List[float]] = None,\n        fallback_pd_gains: Optional[Tuple[float, float]] = None,\n        max_du: Optional[float] = None\n    ):\n        \"\"\"Initialize MPC controller with configuration.\"\"\"\n        ...\n\n    def compute_control(self, t: float, x\u2080: np.ndarray) -> float:\n        \"\"\"Solve MPC QP and return optimal control.\"\"\"\n        ...\n\n    def _safe_fallback(self, x\u2080: np.ndarray) -> float:\n        \"\"\"Fallback controller when QP fails.\"\"\"\n        ...",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3cb023a4"
  },
  {
    "id": "mpc_technical_guide_11_f2eeb6e5",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef _numeric_linearize_continuous(dyn, x_eq, u_eq, eps=1e-6):\n    \"\"\"\n    Central finite difference Jacobian computation.\n\n    Key Innovation: Adaptive perturbation prevents numerical issues.\n    \"\"\"\n    x_eq = np.asarray(x_eq, dtype=float)\n    n = x_eq.size\n    f0 = _call_f(dyn, x_eq, u_eq)\n    A = np.zeros((n, n))\n\n    for i in range(n):\n        # Adaptive step: \u03b4 \u221d |x_eq[i]| with floor\n        delta = max(eps, 1e-4 * max(abs(x_eq[i]), 1.0))\n        delta = max(delta, 1e-12)  # Critical: prevent division by zero\n\n        dx = np.zeros(n)\n        dx[i] = delta\n\n        f_plus = _call_f(dyn, x_eq + dx, u_eq)\n        f_minus = _call_f(dyn, x_eq - dx, u_eq)\n\n        # Central difference: O(\u03b4\u00b2) accuracy\n        A[:, i] = (f_plus - f_minus) / (2.0 * delta)\n\n    # Input Jacobian B\n    du = max(eps, 1e-4 * max(abs(u_eq), 1.0))\n    du = max(du, 1e-12)\n\n    f_plus = _call_f(dyn, x_eq, u_eq + du)\n    f_minus = _call_f(dyn, x_eq, u_eq - du)\n    B = ((f_plus - f_minus) / (2.0 * du)).reshape(n, 1)\n\n    return A, B",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2eeb6e5"
  },
  {
    "id": "mpc_technical_guide_12_8810793e",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef _discretize_exact(Ac, Bc, dt):\n    \"\"\"\n    Zero-order hold discretization via matrix exponential.\n\n    Mathematical Foundation:\n        x(t+\u0394t) = exp(A \u0394t) x(t) + [\u222b\u2080^\u0394t exp(A \u03c4) d\u03c4] B u(t)\n\n    Block Matrix Trick:\n        exp([A, B; 0, 0] \u0394t) = [A_d, B_d; 0, I]\n    \"\"\"\n    n = Ac.shape[0]\n    M = np.zeros((n+1, n+1))\n    M[:n, :n] = Ac          # Top-left: A\n    M[:n, n:] = Bc          # Top-right: B\n    # Bottom row remains zero\n\n    Md = expm(M * dt)       # scipy.linalg.expm\n\n    Ad = Md[:n, :n]         # Extract A_d\n    Bd = Md[:n, n:].reshape(n, 1)  # Extract B_d\n\n    return Ad, Bd",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8810793e"
  },
  {
    "id": "mpc_technical_guide_13_75c83b4f",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Decision variables\nX = cp.Variable((nx, N+1))  # States: 6 \u00d7 (N+1)\nU = cp.Variable((nu, N))    # Controls: 1 \u00d7 N\n\n# Cost matrices\nQ = np.diag([w.q_x, w.q_theta, w.q_theta, w.q_xdot, w.q_thetadot, w.q_thetadot])\nR = np.array([[w.r_u]])\n\n# Build cost function and constraints\nobj = 0\ncons = [X[:, 0] == x0]  # Initial condition\n\nfor k in range(N):\n    # Dynamics: x_{k+1} = A_d x_k + B_d u_k\n    cons += [X[:, k+1] == Ad @ X[:, k] + Bd @ U[:, k]]\n\n    # Input bounds: |u_k| \u2264 u_max\n    cons += [cp.abs(U[0, k]) <= self.max_force]\n\n    # Stage cost: ||x_k - x_ref||\u00b2_Q + ||u_k||\u00b2_R\n    e = X[:, k] - Xref[:, k]\n    obj += cp.quad_form(e, Q) + cp.quad_form(U[:, k], R)\n\n    # State constraints\n    cons += [cp.abs(X[0, k]) <= self.max_cart_pos]  # Cart position\n    cons += [cp.abs(X[1, k] - np.pi) <= self.max_theta_dev]  # \u03b8\u2081\n    cons += [cp.abs(X[2, k] - np.pi) <= self.max_theta_dev]  # \u03b8\u2082\n\n# Terminal cost: ||x_N - x_ref||\u00b2_Q\neN = X[:, N] - Xref[:, N]\nobj += cp.quad_form(eN, Q)\n\n# Solve\nprob = cp.Problem(cp.Minimize(obj), cons)\nprob.solve(solver=cp.OSQP, warm_start=True)",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75c83b4f"
  },
  {
    "id": "mpc_technical_guide_14_33f19241",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Solve with warm start\ntry:\n    prob.solve(solver=cp.OSQP, warm_start=True, verbose=False)\nexcept:\n    prob.solve(warm_start=True, verbose=False)  # Fallback solver\n\n# Check status\nif prob.status not in (cp.OPTIMAL, cp.OPTIMAL_INACCURATE):\n    logger.warning(\"MPC failed (%s), using fallback\", prob.status)\n    return self._safe_fallback(x0)\n\n# Extract and cache solution\nu0 = float(U.value[0, 0])\nself._U_prev = U.value.reshape(-1)  # Warm start next solve\n\n# Apply slew rate limit if configured\nif self._max_du is not None:\n    du = np.clip(u0 - self._last_u_out, -self._max_du, self._max_du)\n    u0 = self._last_u_out + du\n\nself._last_u_out = u0\nreturn float(np.clip(u0, -self.max_force, self.max_force))",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33f19241"
  },
  {
    "id": "mpc_technical_guide_15_08480d04",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 15,
    "code": "@dataclass\nclass MPCWeights:\n    q_x: float = 1.0          # Cart position weight\n    q_theta: float = 10.0     # Angle weight (each)\n    q_xdot: float = 0.1       # Velocity weight\n    q_thetadot: float = 0.5   # Angular velocity weight\n    r_u: float = 1e-2         # Input effort penalty",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "08480d04"
  },
  {
    "id": "mpc_technical_guide_16_32abf21d",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 16,
    "code": "# Custom SMC fallback\nmpc = MPCController(\n    dynamics,\n    fallback_smc_gains=[10, 8, 15, 12, 50, 5],  # [k1,k2,\u03bb1,\u03bb2,K,kd]\n    fallback_boundary_layer=0.01\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32abf21d"
  },
  {
    "id": "mpc_technical_guide_17_91a53c93",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 17,
    "code": "# Custom PD fallback (if SMC unavailable)\nmpc = MPCController(\n    dynamics,\n    fallback_pd_gains=(30.0, 10.0)  # (k_p, k_d)\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91a53c93"
  },
  {
    "id": "mpc_technical_guide_18_b1568e19",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 18,
    "code": "|u_k - u_{k-1}| \u2264 max_du",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1568e19"
  },
  {
    "id": "mpc_technical_guide_19_5698f302",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nweights = MPCWeights(\n    q_x=0.5,          # Less emphasis on cart position\n    q_theta=20.0,     # Strong angle penalty\n    q_xdot=0.05,\n    q_thetadot=1.0,   # Higher damping\n    r_u=5e-3          # Allow aggressive control\n)\n\nmpc = MPCController(\n    dynamics_model=dynamics,\n    horizon=30,                     # Long horizon\n    dt=0.01,                        # Fine timestep\n    weights=weights,\n    max_force=50.0,                 # Higher force limit\n    use_exact_discretization=True\n)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5698f302"
  },
  {
    "id": "mpc_technical_guide_20_2b66301b",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\nweights = MPCWeights(\n    q_theta=10.0,\n    r_u=1e-2\n)\n\nmpc = MPCController(\n    dynamics_model=dynamics,\n    horizon=12,                     # Shorter horizon\n    dt=0.02,                        # Standard timestep\n    weights=weights,\n    max_force=20.0,\n    use_exact_discretization=False, # Faster Euler\n    max_du=15.0                     # Slew rate limit\n)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b66301b"
  },
  {
    "id": "mpc_technical_guide_21_7f1eb000",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 21,
    "code": "mpc = MPCController(\n    dynamics_model=dynamics,\n    horizon=20,\n    dt=0.02,\n    max_theta_dev=0.3,              # Tighter angle bounds\n    fallback_smc_gains=[8, 8, 12, 12, 40, 3],\n    fallback_boundary_layer=0.02\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7f1eb000"
  },
  {
    "id": "mpc_technical_guide_22_bd857728",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 22,
    "code": "from src.controllers.mpc import MPCController, MPCWeights\nfrom src.core.dynamics import DoubleInvertedPendulum\n\n# Load dynamics model\nconfig = load_config(\"config.yaml\")\ndynamics = DoubleInvertedPendulum(config.physics)\n\n# Configure MPC\nweights = MPCWeights(\n    q_x=1.0,\n    q_theta=10.0,\n    q_xdot=0.1,\n    q_thetadot=0.5,\n    r_u=1e-2\n)\n\nmpc = MPCController(\n    dynamics_model=dynamics,\n    horizon=20,\n    dt=0.02,\n    weights=weights,\n    max_force=20.0,\n    max_cart_pos=2.4,\n    max_theta_dev=0.5\n)",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd857728"
  },
  {
    "id": "mpc_technical_guide_23_eee9e56d",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Simulation loop\nt = 0.0\ndt = 0.02\nx = np.array([0.0, np.pi, np.pi, 0.0, 0.0, 0.0])  # Upright\n\nwhile t < 10.0:\n    # Compute MPC control\n    u = mpc.compute_control(t, x)\n\n    # Apply to system\n    x = dynamics.step(x, u, dt)\n\n    # Advance time\n    t += dt",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eee9e56d"
  },
  {
    "id": "mpc_technical_guide_24_369444d7",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 24,
    "code": "def reference_trajectory(t):\n    \"\"\"Sinusoidal cart motion while keeping pendulum upright.\"\"\"\n    x_ref = 0.5 * np.sin(0.5 * np.pi * t)\n    return np.array([x_ref, np.pi, np.pi, 0.0, 0.0, 0.0])\n\nmpc.set_reference(reference_trajectory)\n\n# Now MPC tracks this time-varying reference\nu = mpc.compute_control(t=2.0, x0=x_current)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "369444d7"
  },
  {
    "id": "mpc_technical_guide_25_77c7d191",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 25,
    "code": "from src.controllers.factory import create_controller\n\n# Create MPC via factory (if supported)\nconfig = load_config(\"config.yaml\")\n\ncontroller = create_controller(\n    'mpc_controller',\n    config=config,\n    # MPC-specific parameters\n    horizon=20,\n    dt=0.02,\n    max_force=20.0\n)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "77c7d191"
  },
  {
    "id": "mpc_technical_guide_26_7c3def81",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 26,
    "code": "# Direct instantiation provides full parameter control\nfrom src.controllers.mpc.mpc_controller import MPCController\n\nmpc = MPCController(\n    dynamics_model=dynamics,\n    horizon=20,\n    dt=0.02,\n    weights=MPCWeights(),\n    max_force=20.0,\n    fallback_smc_gains=[10, 8, 15, 12, 50, 5]\n)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c3def81"
  },
  {
    "id": "mpc_technical_guide_27_eb4eab3a",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 27,
    "code": "from src.core.simulation_runner import SimulationRunner\n\n# Create MPC controller\nmpc = MPCController(dynamics, horizon=20, dt=0.02)\n\n# Wrap for simulation runner interface\ndef mpc_wrapper(state, _, __):\n    \"\"\"Adapt MPC to simulation runner interface.\"\"\"\n    t = state['t'] if 't' in state else 0.0\n    u = mpc.compute_control(t, state['x'])\n    return u, (), {}  # (control, state_vars, history)\n\n# Run simulation\nrunner = SimulationRunner(config)\nresult = runner.run(\n    controller=mpc_wrapper,\n    dynamics=dynamics,\n    duration=10.0,\n    dt=0.02\n)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb4eab3a"
  },
  {
    "id": "mpc_technical_guide_28_7d498d2b",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 28,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\n\ndef mpc_factory_for_pso(params):\n    \"\"\"\n    params = [q_x, q_theta, q_xdot, q_thetadot, r_u, horizon]\n    \"\"\"\n    weights = MPCWeights(\n        q_x=params[0],\n        q_theta=params[1],\n        q_xdot=params[2],\n        q_thetadot=params[3],\n        r_u=params[4]\n    )\n\n    return MPCController(\n        dynamics_model=dynamics,\n        horizon=int(params[5]),\n        dt=0.02,\n        weights=weights\n    )\n\n# PSO bounds\nbounds = [\n    (0.1, 10.0),    # q_x\n    (1.0, 50.0),    # q_theta\n    (0.01, 1.0),    # q_xdot\n    (0.1, 2.0),     # q_thetadot\n    (1e-3, 0.1),    # r_u\n    (10, 30)        # horizon (integer)\n]\n\ntuner = PSOTuner(\n    controller_factory=mpc_factory_for_pso,\n    config=config,\n    bounds=bounds,\n    n_particles=20,\n    max_iters=50\n)\n\nresult = tuner.optimise()\noptimal_params = result['best_pos']",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7d498d2b"
  },
  {
    "id": "mpc_technical_guide_29_159598ec",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\n# Relax angle constraints\nmpc = MPCController(\n    dynamics,\n    max_theta_dev=0.7,  # Increase from 0.5\n    max_force=30.0      # Increase force limit\n)\n\n# Check state before solve\nif abs(x[1] - np.pi) > 0.4:\n    logger.warning(\"State near linearization limits\")\n    u = mpc._safe_fallback(x)  # Use fallback explicitly",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "159598ec"
  },
  {
    "id": "mpc_technical_guide_30_b4045b21",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 30,
    "code": "# 1. Ensure warm start enabled\nprob.solve(solver=cp.OSQP, warm_start=True)\n\n# 2. Reduce horizon\nmpc = MPCController(dynamics, horizon=12)  # Down from 20\n\n# 3. Profile solvers\nimport time\nt0 = time.time()\nprob.solve(solver=cp.OSQP)\nprint(f\"OSQP: {(time.time()-t0)*1000:.2f} ms\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4045b21"
  },
  {
    "id": "mpc_technical_guide_31_7271ff97",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 31,
    "code": "# 1. Add slew rate limit\nmpc = MPCController(dynamics, max_du=10.0)  # 10 N/step\n\n# 2. Increase input penalty\nweights = MPCWeights(r_u=0.05)  # Up from 0.01\n\n# 3. Tighten solver tolerance\nprob.solve(solver=cp.OSQP, eps_abs=1e-6, eps_rel=1e-6)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7271ff97"
  },
  {
    "id": "mpc_technical_guide_32_a88d2d4e",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 32,
    "code": "# 1. Install cvxpy\npip install cvxpy\n\n# 2. Verify installation\nimport cvxpy as cp\nprint(cp.installed_solvers())  # Should include OSQP, ECOS, SCS\n\n# 3. If installation fails, MPC degrades gracefully\nmpc = MPCController(\n    dynamics,\n    fallback_smc_gains=[10, 8, 15, 12, 50, 5],\n    fallback_boundary_layer=0.01\n)\n# Will use SMC when cvxpy unavailable",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a88d2d4e"
  },
  {
    "id": "mpc_technical_guide_33_fc9c03d7",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 33,
    "code": "status = prob.status\nif status != cp.OPTIMAL:\n    logger.warning(f\"MPC status: {status}\")\n    logger.debug(f\"Objective value: {prob.value}\")\n    logger.debug(f\"Constraint violations: {[c.violation() for c in prob.constraints]}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc9c03d7"
  },
  {
    "id": "mpc_technical_guide_34_8853fbfe",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 34,
    "code": "def check_linearization(x, x_eq=np.array([0, np.pi, np.pi, 0, 0, 0])):\n    err = x - x_eq\n    angle_err = np.max(np.abs(err[1:3]))\n    if angle_err > 0.4:\n        logger.warning(f\"Large angle error: {angle_err:.3f} rad\")\n    return angle_err < 0.5",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8853fbfe"
  },
  {
    "id": "mpc_technical_guide_35_cbd53dbd",
    "file": "docs\\controllers\\mpc_technical_guide.md",
    "index": 35,
    "code": "# Compare cold vs warm start\nt0 = time.time()\nprob.solve(solver=cp.OSQP, warm_start=False)\nt_cold = time.time() - t0\n\nt0 = time.time()\nprob.solve(solver=cp.OSQP, warm_start=True)\nt_warm = time.time() - t0\n\nprint(f\"Speedup: {t_cold/t_warm:.1f}\u00d7\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cbd53dbd"
  },
  {
    "id": "sta_smc_technical_guide_1_9ec158fc",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass SuperTwistingSMC:\n    \"\"\"\n    Second-order sliding mode controller (STA):\n\n    Components:\n    - Sliding surface computation (same as adaptive)\n    - Super-twisting continuous term (\u221a|\u03c3|)\n    - Integral term update (discontinuous derivative)\n    - Equivalent control (optional, model-based)\n    - Numba acceleration for performance\n    \"\"\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ec158fc"
  },
  {
    "id": "sta_smc_technical_guide_2_504f9285",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@numba.njit(cache=True)\ndef _sta_smc_core(...):\n    # Sliding surface (inline)\n    sigma = k1*(th1dot + lam1*th1) + k2*(th2dot + lam2*th2)\n\n    # Continuous term (sqrt is expensive)\n    u_cont = -K1 * np.sqrt(np.abs(sigma)) * sgn_sigma\n\n    # Integral update\n    new_z = z - K2 * sgn_sigma * dt\n\n    # Anti-windup back-calculation\n    new_z += Kaw * (u_sat - u_raw) * dt\n\n    return u_sat, new_z, sigma",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "504f9285"
  },
  {
    "id": "sta_smc_technical_guide_3_f0568b7c",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n@numba.njit(cache=True)\ndef _sta_smc_core(\n    z, sigma, sgn_sigma,\n    alg_gain_K1, alg_gain_K2, damping_gain,\n    dt, max_force, u_eq=0.0, Kaw=0.0\n):\n    \"\"\"Numba-accelerated STA core with anti-windup.\"\"\"\n\n    # Continuous term (square-root law)\n    u_cont = -alg_gain_K1 * np.sqrt(np.abs(sigma)) * sgn_sigma\n\n    # Integral term (previous z)\n    u_dis = z\n\n    # Unsaturated control\n    u_raw = u_eq + u_cont + u_dis - damping_gain * sigma\n\n    # Saturate control\n    if u_raw > max_force:\n        u_sat = max_force\n    elif u_raw < -max_force:\n        u_sat = -max_force\n    else:\n        u_sat = u_raw\n\n    # Anti-windup back-calculation\n    new_z = z - alg_gain_K2 * sgn_sigma * dt\n    new_z += Kaw * (u_sat - u_raw) * dt  # Windup compensation\n\n    # Saturate integrator\n    if new_z > max_force:\n        new_z = max_force\n    elif new_z < -max_force:\n        new_z = -max_force\n\n    return float(u_sat), float(new_z), float(sigma)",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0568b7c"
  },
  {
    "id": "sta_smc_technical_guide_4_24a9d2dc",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    \"\"\"Compute STA-SMC control with Numba acceleration.\"\"\"\n\n    # Unpack integrator state\n    try:\n        z, _ = state_vars  # Ignore provided sigma, will recompute\n    except:\n        z = float(state_vars) if state_vars is not None else 0.0\n\n    # Equivalent control (model-based, optional)\n    u_eq = self._compute_equivalent_control(state)\n\n    # Sliding surface\n    sigma = self._compute_sliding_surface(state)\n\n    # Saturated sign function\n    sgn_sigma = saturate(sigma, self.boundary_layer, method=self.switch_method)\n\n    # Call Numba-accelerated core\n    u, new_z, sigma_val = _sta_smc_core(\n        z=z,\n        sigma=float(sigma),\n        sgn_sigma=float(sgn_sigma),\n        alg_gain_K1=self.alg_gain_K1,\n        alg_gain_K2=self.alg_gain_K2,\n        damping_gain=self.damping_gain,\n        dt=self.dt,\n        max_force=self.max_force,\n        u_eq=u_eq,\n        Kaw=self.anti_windup_gain\n    )\n\n    # Update history\n    hist = history if isinstance(history, dict) else {}\n    hist.setdefault('sigma', []).append(float(sigma))\n    hist.setdefault('z', []).append(float(new_z))\n    hist.setdefault('u', []).append(float(u))\n    hist.setdefault('u_eq', []).append(float(u_eq))\n\n    return STAOutput(u, (new_z, float(sigma)), hist)",
    "lines": 43,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24a9d2dc"
  },
  {
    "id": "sta_smc_technical_guide_5_a7931869",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 5,
    "code": "# Compute unsaturated and saturated control\nu_raw = u_eq + u_cont + z - d\u00b7\u03c3\nu_sat = clip(u_raw, -max_force, max_force)\n\n# Anti-windup adjustment\nnew_z = z - K\u2082\u00b7sgn_sigma\u00b7dt + Kaw\u00b7(u_sat - u_raw)\u00b7dt\n                              ^^^^^^^^^^^^^^^^^^^^^^^^\n                              Windup compensation",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7931869"
  },
  {
    "id": "sta_smc_technical_guide_6_b1cefbe6",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 6,
    "code": "pso_bounds = [\n    (5.0, 100.0),   # K1\n    (3.0, 80.0),    # K2\n    (1.0, 50.0),    # k1\n    (1.0, 50.0),    # k2\n    (1.0, 100.0),   # lam1\n    (1.0, 100.0),   # lam2\n]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1cefbe6"
  },
  {
    "id": "sta_smc_technical_guide_7_58e77daf",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 7,
    "code": "def validate_sta_gains(gains):\n    \"\"\"Ensure K1 > K2 for stability.\"\"\"\n    K1, K2 = gains[0], gains[1]\n    if K1 <= K2:\n        return False  # Invalid\n    return True",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "58e77daf"
  },
  {
    "id": "sta_smc_technical_guide_8_5e40582a",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 8,
    "code": "from src.controllers.smc import SuperTwistingSMC\n\n# Create controller (6 gains)\ncontroller = SuperTwistingSMC(\n    gains=[25.0, 15.0, 10.0, 8.0, 15.0, 12.0],\n    dt=0.01,\n    max_force=150.0,\n    damping_gain=3.0,\n    boundary_layer=0.01\n)\n\n# OR minimal (2 gains with defaults)\ncontroller = SuperTwistingSMC(\n    gains=[25.0, 15.0],\n    dt=0.01,\n    max_force=150.0\n)\n\n# Initialize\nstate_vars = controller.initialize_state()  # (0.0, 0.0)\nhistory = controller.initialize_history()\n\n# Main loop\nfor t in simulation_time:\n    state = get_system_state()\n\n    result = controller.compute_control(state, state_vars, history)\n\n    control_force = result.control\n    state_vars = result.state_vars  # (z_new, sigma)\n    history = result.history\n\n    apply_control(control_force)",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e40582a"
  },
  {
    "id": "sta_smc_technical_guide_9_467b43d8",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef monitor_sta_performance(controller, result, history):\n    \"\"\"Monitor STA-specific performance indicators.\"\"\"\n\n    z_current = result.state_vars[0]\n    sigma = result.state_vars[1]\n\n    # Convergence indicators\n    near_surface = abs(sigma) < controller.boundary_layer\n    integral_active = abs(z_current) > 0.01\n\n    # Performance metrics\n    metrics = {\n        'z': z_current,\n        'sigma': sigma,\n        'near_surface': near_surface,\n        'integral_active': integral_active,\n        'convergence_estimate': 2*abs(sigma)**0.5 / controller.alg_gain_K1**0.5\n    }\n\n    # Warning conditions\n    if abs(z_current) > controller.max_force * 0.9:\n        print(f\"WARNING: Integrator near saturation: z = {z_current:.2f}\")\n\n    if not near_surface and t > 5.0:\n        print(f\"WARNING: Not converged after 5s: |\u03c3| = {abs(sigma):.3f}\")\n\n    return metrics",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "467b43d8"
  },
  {
    "id": "sta_smc_technical_guide_10_280ca8e2",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 10,
    "code": "assert gains[0] > gains[1], \"K1 must be > K2\"",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "280ca8e2"
  },
  {
    "id": "sta_smc_technical_guide_11_6736786d",
    "file": "docs\\controllers\\sta_smc_technical_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_sta_health(controller, history):\n    \"\"\"Diagnose STA SMC health.\"\"\"\n\n    z_history = np.array(history['z'])\n    sigma_history = np.array(history['sigma'])\n\n    diagnostics = {\n        'z_max': np.max(np.abs(z_history)),\n        'z_saturated': np.any(np.abs(z_history) >= controller.max_force * 0.99),\n        'sigma_final': sigma_history[-1],\n        'converged': np.all(np.abs(sigma_history[-100:]) < controller.boundary_layer),\n        'chattering': np.std(np.diff(history['u']))\n    }\n\n    # Warnings\n    if diagnostics['z_saturated']:\n        print(\"WARNING: Integrator saturated - consider anti-windup\")\n\n    if not diagnostics['converged']:\n        print(\"WARNING: Not converged - increase K1 or check stability\")\n\n    return diagnostics",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6736786d"
  },
  {
    "id": "swing_up_smc_technical_guide_1_0b2e440d",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef total_energy(self, state):\n    \"\"\"\n    Compute total mechanical energy.\n\n    Returns:\n        E = T(q\u0307) + V(q)  (scalar)\n    \"\"\"\n    q = state[:3]   # [x, \u03b8\u2081, \u03b8\u2082]\n    qdot = state[3:] # [\u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\n\n    # Kinetic energy\n    T = 0.5 * (\n        m_c * qdot[0]**2 +\n        I_1 * qdot[1]**2 +\n        I_2 * qdot[2]**2 +\n        # Cross terms from coupled dynamics\n        ...\n    )\n\n    # Potential energy (gravity)\n    V = (\n        -m_1 * g * L_1 * np.cos(q[1]) +\n        -m_2 * g * (L_1 * np.cos(q[1]) + L_2 * np.cos(q[2]))\n    )\n\n    return T + V",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0b2e440d"
  },
  {
    "id": "swing_up_smc_technical_guide_2_d3b89334",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 2,
    "code": "# Bottom position (down-down)\nstate_bottom = [0, \u03c0, \u03c0, 0, 0, 0]\nE_bottom = dynamics.total_energy(state_bottom)\n\n# Upright position (target)\nstate_upright = [0, 0, 0, 0, 0, 0]\nE_upright = dynamics.total_energy(state_upright)  # = -(m\u2081+m\u2082)g(L\u2081+L\u2082)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3b89334"
  },
  {
    "id": "swing_up_smc_technical_guide_3_5e15bf37",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _should_switch_to_stabilize(self, E_about_bottom, \u03b8\u2081, \u03b8\u2082):\n    \"\"\"\n    Check if conditions met for swing \u2192 stabilize.\n\n    Returns:\n        (should_switch, high_energy, small_angles)\n    \"\"\"\n    high_energy = (E_about_bottom >= self.switch_energy_factor * self.E_bottom)\n    small_angles = (abs(\u03b8\u2081) <= self.switch_angle_tol and\n                   abs(\u03b8\u2082) <= self.switch_angle_tol)\n\n    should_switch = high_energy and small_angles  # ALL conditions\n    return (should_switch, high_energy, small_angles)\n\ndef _should_switch_to_swing(self, E_about_bottom, \u03b8\u2081, \u03b8\u2082):\n    \"\"\"\n    Check if conditions met for stabilize \u2192 swing.\n\n    Returns:\n        (should_switch, low_energy, angle_excursion)\n    \"\"\"\n    low_energy = (E_about_bottom < self.exit_energy_factor * self.E_bottom)\n    angle_excursion = (abs(\u03b8\u2081) > self.reentry_angle_tol or\n                      abs(\u03b8\u2082) > self.reentry_angle_tol)\n\n    should_switch = low_energy or angle_excursion  # ANY condition\n    return (should_switch, low_energy, angle_excursion)",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e15bf37"
  },
  {
    "id": "swing_up_smc_technical_guide_4_001fa781",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef _update_mode(self, E_about_bottom, \u03b8\u2081, \u03b8\u2082, t, history):\n    \"\"\"Evaluate and execute mode transitions.\"\"\"\n    if self._mode == SWING_MODE:\n        should, high_energy, small_angles = self._should_switch_to_stabilize(...)\n        if should:\n            self._mode = STABILIZE_MODE\n            self._switch_time = t  # Record handoff time\n            logger.info(\"swing \u2192 stabilize at t=%.3fs\", t)\n\n    elif self._mode == STABILIZE_MODE:\n        should, low_energy, angle_excursion = self._should_switch_to_swing(...)\n        if should:\n            self._mode = SWING_MODE\n            logger.info(\"stabilize \u2192 swing at t=%.3fs\", t)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "001fa781"
  },
  {
    "id": "swing_up_smc_technical_guide_5_c205fead",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    \"\"\"\n    Compute control based on current mode.\n\n    Args:\n        state: [x, \u03b8\u2081, \u03b8\u2082, \u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\n        state_vars: Controller state (unused for swing-up)\n        history: Dict with mode tracking\n\n    Returns:\n        (u, state_vars, history)\n    \"\"\"\n    \u03b8\u2081, \u03b8\u2082, \u03b8\u0307\u2081 = state[1], state[2], state[4]\n\n    # Compute current energy\n    E_current = self.dynamics.total_energy(state)\n    E_about_bottom = self.E_bottom - E_current\n\n    # Track normalized energy for telemetry\n    history[\"E_ratio\"] = E_about_bottom / self.E_bottom\n\n    # Update time\n    t = history.get(\"t\", 0.0) + self.dt\n    history[\"t\"] = t\n\n    # Evaluate mode transitions\n    self._update_mode(E_about_bottom, \u03b8\u2081, \u03b8\u2082, t, history)\n\n    # --- Swing Mode ---\n    if self._mode == SWING_MODE:\n        u = self.k_swing * np.cos(\u03b8\u2081) * \u03b8\u0307\u2081\n        u = np.clip(u, -self.max_force, self.max_force)\n        return (u, state_vars, history)\n\n    # --- Stabilize Mode ---\n    # Initialize stabilizer state on first entry\n    if not self._stabilizer_initialized:\n        if hasattr(self.stabilizer, \"initialize_state\"):\n            self._stab_state_vars = self.stabilizer.initialize_state()\n        if hasattr(self.stabilizer, \"initialize_history\"):\n            self._stab_history = self.stabilizer.initialize_history()\n        self._stabilizer_initialized = True\n\n    # Delegate to stabilizing controller\n    u, self._stab_state_vars, self._stab_history = self.stabilizer.compute_control(\n        state, self._stab_state_vars, self._stab_history\n    )\n    u = np.clip(u, -self.max_force, self.max_force)\n    return (u, state_vars, history)",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c205fead"
  },
  {
    "id": "swing_up_smc_technical_guide_6_24130423",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 6,
    "code": "def compute_control(self, state, state_vars, history):\n       \"\"\"\n       Args:\n           state: np.ndarray (6,)\n           state_vars: Tuple (controller internal state)\n           history: Dict (history tracking)\n\n       Returns:\n           (u, state_vars, history)\n       \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24130423"
  },
  {
    "id": "swing_up_smc_technical_guide_7_26ef4f99",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n   def initialize_state(self) -> Tuple:\n       \"\"\"Return initial controller state.\"\"\"\n       ...\n\n   def initialize_history(self) -> Dict:\n       \"\"\"Return initial history dict.\"\"\"\n       ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26ef4f99"
  },
  {
    "id": "swing_up_smc_technical_guide_8_832c1013",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 8,
    "code": "max_force: float  # Force saturation limit (fallback to np.inf)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "832c1013"
  },
  {
    "id": "swing_up_smc_technical_guide_9_2596c93f",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 9,
    "code": "self._mode: Mode  # \"swing\" or \"stabilize\"\nself._switch_time: Optional[float]  # Time of last handoff\nself._stab_state_vars: Tuple  # Stabilizer internal state\nself._stab_history: Dict  # Stabilizer history",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2596c93f"
  },
  {
    "id": "swing_up_smc_technical_guide_10_3cacc423",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 10,
    "code": "history = {\n    \"mode\": \"swing\" or \"stabilize\",\n    \"t\": float,  # Current time\n    \"E_ratio\": float  # E_about_bottom / E_bottom (0 to 1)\n}",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3cacc423"
  },
  {
    "id": "swing_up_smc_technical_guide_11_e29bce87",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass SwingUpSMC:\n    \"\"\"\n    Energy-based swing-up with hysteresis handoff.\n\n    Attributes:\n        k_swing: float  # Energy gain\n        switch_energy_factor: float  # Forward handoff threshold (0.95)\n        exit_energy_factor: float  # Reverse handoff threshold (0.90)\n        switch_angle_tol: float  # Angle gate for handoff (0.35 rad)\n        E_bottom: float  # Energy at down-down position\n        _mode: Mode  # Current mode (\"swing\" or \"stabilize\")\n    \"\"\"\n\n    def __init__(\n        self,\n        dynamics_model: Any,\n        stabilizing_controller: Any,\n        energy_gain: float = 50.0,\n        switch_energy_factor: float = 0.95,\n        exit_energy_factor: float = 0.90,\n        switch_angle_tolerance: float = 0.35,\n        ...\n    ):\n        \"\"\"Initialize hybrid swing-up controller.\"\"\"\n        ...\n\n    def compute_control(self, state, state_vars, history):\n        \"\"\"Main control loop with mode switching.\"\"\"\n        ...\n\n    def _update_mode(self, E_about_bottom, \u03b8\u2081, \u03b8\u2082, t, history):\n        \"\"\"Centralized mode transition logic.\"\"\"\n        ...\n\n    @property\n    def mode(self) -> str:\n        \"\"\"Current operating mode.\"\"\"\n        return self._mode\n\n    @property\n    def switch_time(self) -> Optional[float]:\n        \"\"\"Time of last handoff (for analysis).\"\"\"\n        return self._switch_time",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e29bce87"
  },
  {
    "id": "swing_up_smc_technical_guide_12_e85636e9",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 12,
    "code": "# Compute current energy\ntry:\n    E_current = float(self.dyn.total_energy(state))\nexcept Exception:\n    E_current = 0.0  # Fallback for dummy dynamics\n\n# Energy relative to bottom (down-down)\nE_about_bottom = self.E_bottom - E_current\n\n# Telemetry: normalized energy ratio\nhistory[\"E_ratio\"] = float(E_about_bottom / self.E_bottom)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e85636e9"
  },
  {
    "id": "swing_up_smc_technical_guide_13_f9eb4d2d",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 13,
    "code": "if self._mode == SWING_MODE:\n    # Energy pumping control law\n    u = self.k_swing * np.cos(\u03b8\u2081) * \u03b8\u0307\u2081\n\n    # Saturate to actuator limits\n    if np.isfinite(self.max_force):\n        u = float(np.clip(u, -self.max_force, self.max_force))\n\n    return float(u), state_vars, history",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9eb4d2d"
  },
  {
    "id": "swing_up_smc_technical_guide_14_ef2a6fd1",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Lazy initialization on first stabilize entry\nif not self._stabilizer_initialized:\n    if hasattr(self.stabilizer, \"initialize_state\"):\n        self._stab_state_vars = self.stabilizer.initialize_state()\n    if hasattr(self.stabilizer, \"initialize_history\"):\n        self._stab_history = self.stabilizer.initialize_history()\n    self._stabilizer_initialized = True\n\n# Delegate control to stabilizing controller\nu, self._stab_state_vars, self._stab_history = self.stabilizer.compute_control(\n    state,\n    self._stab_state_vars,\n    self._stab_history\n)\n\n# Saturate output\nif np.isfinite(self.max_force):\n    u = float(np.clip(u, -self.max_force, self.max_force))\n\nreturn float(u), state_vars, history",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef2a6fd1"
  },
  {
    "id": "swing_up_smc_technical_guide_15_f9772c51",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# Validate hysteresis band\nif self.exit_energy_factor >= self.switch_energy_factor:\n    raise ValueError(\n        \"exit_energy_factor must be < switch_energy_factor to create deadband\"\n    )\n\n# Validate angle tolerance ordering\nif self.reentry_angle_tol < self.switch_angle_tol:\n    raise ValueError(\n        \"reentry_angle_tolerance should be >= switch_angle_tolerance\"\n    )",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9772c51"
  },
  {
    "id": "swing_up_smc_technical_guide_16_d5480022",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# This will raise ValueError:\nSwingUpSMC(\n    ...,\n    switch_energy_factor=0.95,\n    exit_energy_factor=0.98  # ERROR: exit \u2265 switch\n)",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d5480022"
  },
  {
    "id": "swing_up_smc_technical_guide_17_32703e75",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nSwingUpSMC(\n    ...,\n    switch_angle_tolerance=0.35,    # 20\u00b0 for handoff\n    reentry_angle_tolerance=0.50    # 28.6\u00b0 for re-swing (more forgiving)\n)",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32703e75"
  },
  {
    "id": "swing_up_smc_technical_guide_18_01aed1b0",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Conservative gains for handoff robustness\nstabilizer = ClassicalSMC(\n    gains=[8, 8, 12, 12, 40, 3],  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    boundary_layer=0.02,          # Smooth handoff\n    max_force=max_force\n)\n\nswing_up = SwingUpSMC(\n    dynamics_model=dynamics,\n    stabilizing_controller=stabilizer,\n    energy_gain=50.0\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "01aed1b0"
  },
  {
    "id": "swing_up_smc_technical_guide_19_e6801155",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\n# Aggressive finite-time convergence\nstabilizer = SuperTwistingSMC(\n    gains=[25, 10, 15, 12, 20, 15],  # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    max_force=max_force\n)\n\nswing_up = SwingUpSMC(\n    dynamics_model=dynamics,\n    stabilizing_controller=stabilizer,\n    energy_gain=60.0,\n    switch_angle_tolerance=0.30  # Tighter (STA robust)\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6801155"
  },
  {
    "id": "swing_up_smc_technical_guide_20_326a2c0f",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 20,
    "code": "from src.controllers.smc import ClassicalSMC\nfrom src.controllers.specialized import SwingUpSMC\nfrom src.core.dynamics import DoubleInvertedPendulum\n\n# Load dynamics model\nconfig = load_config(\"config.yaml\")\ndynamics = DoubleInvertedPendulum(config.physics)\n\n# Create stabilizing controller\nstabilizer = ClassicalSMC(\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=20.0,\n    boundary_layer=0.01,\n    dynamics_model=dynamics\n)\n\n# Create swing-up controller\nswing_up = SwingUpSMC(\n    dynamics_model=dynamics,\n    stabilizing_controller=stabilizer,\n    energy_gain=50.0,\n    switch_energy_factor=0.95,\n    exit_energy_factor=0.90,\n    switch_angle_tolerance=0.35,\n    dt=0.01,\n    max_force=20.0\n)",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "326a2c0f"
  },
  {
    "id": "swing_up_smc_technical_guide_21_a7315597",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Initial state: down-down (fully inverted)\nx = np.array([0.0, np.pi, np.pi, 0.0, 0.0, 0.0])\n\n# Initialize controller state\nstate_vars = swing_up.initialize_state()\nhistory = swing_up.initialize_history()\n\n# Simulation loop\nt = 0.0\ndt = 0.01\nu_history = []\nmode_history = []\n\nwhile t < 10.0:\n    # Compute control\n    u, state_vars, history = swing_up.compute_control(x, state_vars, history)\n\n    # Log telemetry\n    u_history.append(u)\n    mode_history.append(history[\"mode\"])\n\n    # Apply to system\n    x = dynamics.step(x, u, dt)\n\n    # Advance time\n    t += dt\n\n# Analyze handoff time\nif swing_up.switch_time is not None:\n    print(f\"Handoff occurred at t = {swing_up.switch_time:.3f} s\")",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7315597"
  },
  {
    "id": "swing_up_smc_technical_guide_22_705a4b53",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 22,
    "code": "import matplotlib.pyplot as plt\n\n# Extract energy ratio from history\nenergy_ratios = [h.get(\"E_ratio\", 0) for h in history_list]\nmodes = [h.get(\"mode\", \"swing\") for h in history_list]\n\n# Plot energy evolution\nplt.figure(figsize=(12, 6))\n\nplt.subplot(2, 1, 1)\nplt.plot(t_array, energy_ratios)\nplt.axhline(0.95, color='g', linestyle='--', label='Switch threshold')\nplt.axhline(0.90, color='r', linestyle='--', label='Exit threshold')\nplt.ylabel('Energy Ratio (E/E_bottom)')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(2, 1, 2)\nmode_numeric = [1 if m == \"stabilize\" else 0 for m in modes]\nplt.plot(t_array, mode_numeric)\nplt.ylabel('Mode (0=swing, 1=stabilize)')\nplt.xlabel('Time (s)')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "705a4b53"
  },
  {
    "id": "swing_up_smc_technical_guide_23_8656f454",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 23,
    "code": "# Create both controllers directly\nstabilizer = create_controller('sta_smc', config=config)\n\nswing_up = SwingUpSMC(\n    dynamics_model=dynamics,\n    stabilizing_controller=stabilizer,\n    energy_gain=50.0\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8656f454"
  },
  {
    "id": "swing_up_smc_technical_guide_24_59d1a35e",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_swing_up_controller(\n    stabilizer_type: str,\n    stabilizer_gains: List[float],\n    swing_up_params: Dict,\n    config: Config\n) -> SwingUpSMC:\n    \"\"\"\n    Factory for swing-up controller with any stabilizer.\n    \"\"\"\n    # Create stabilizer via factory\n    stabilizer = create_controller(\n        stabilizer_type,\n        gains=stabilizer_gains,\n        config=config\n    )\n\n    # Create swing-up wrapper\n    return SwingUpSMC(\n        dynamics_model=config.dynamics,\n        stabilizing_controller=stabilizer,\n        **swing_up_params\n    )\n\n# Usage\nswing_up = create_swing_up_controller(\n    stabilizer_type='sta_smc',\n    stabilizer_gains=[25, 10, 15, 12, 20, 15],\n    swing_up_params={\n        'energy_gain': 50.0,\n        'switch_energy_factor': 0.95,\n        'max_force': 20.0\n    },\n    config=config\n)",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59d1a35e"
  },
  {
    "id": "swing_up_smc_technical_guide_25_2afcb049",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Aggressive stabilizer for near-upright\nstabilizer_near = SuperTwistingSMC(gains=[...], max_force=20.0)\n\n# Conservative stabilizer for larger angles\nstabilizer_far = ClassicalSMC(gains=[...], max_force=20.0)\n\n# Hybrid swing-up with region-based stabilizer selection\nclass AdaptiveSwingUpSMC(SwingUpSMC):\n    def _select_stabilizer(self, \u03b8\u2081, \u03b8\u2082):\n        if abs(\u03b8\u2081) < 0.2 and abs(\u03b8\u2082) < 0.2:\n            return stabilizer_near\n        else:\n            return stabilizer_far\n\n    def compute_control(self, state, state_vars, history):\n        # Override to dynamically select stabilizer\n        self.stabilizer = self._select_stabilizer(state[1], state[2])\n        return super().compute_control(state, state_vars, history)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2afcb049"
  },
  {
    "id": "swing_up_smc_technical_guide_26_6575da4d",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 26,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\n\ndef swing_up_factory_for_pso(stabilizer_gains):\n    \"\"\"\n    Factory for PSO: tunes stabilizer, not swing-up.\n\n    Args:\n        stabilizer_gains: Gains for ClassicalSMC [k1, k2, \u03bb1, \u03bb2, K, kd]\n    \"\"\"\n    stabilizer = ClassicalSMC(\n        gains=stabilizer_gains,\n        max_force=20.0,\n        boundary_layer=0.01,\n        dynamics_model=dynamics\n    )\n\n    return SwingUpSMC(\n        dynamics_model=dynamics,\n        stabilizing_controller=stabilizer,\n        energy_gain=50.0  # Fixed\n    )\n\n# PSO bounds for ClassicalSMC stabilizer\nbounds = [\n    (0.1, 50.0),  # k1\n    (0.1, 50.0),  # k2\n    (0.1, 50.0),  # \u03bb1\n    (0.1, 50.0),  # \u03bb2\n    (1.0, 200.0), # K\n    (0.0, 50.0)   # kd\n]\n\ntuner = PSOTuner(\n    controller_factory=swing_up_factory_for_pso,\n    config=config,\n    bounds=bounds\n)\n\nresult = tuner.optimise()\noptimal_stabilizer_gains = result['best_pos']",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6575da4d"
  },
  {
    "id": "swing_up_smc_technical_guide_27_4b52a435",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 27,
    "code": "# 1. Increase energy gain\nswing_up.k_swing = 70.0  # From 50.0\n\n# 2. Increase force limit\nswing_up.max_force = 30.0  # From 20.0\n\n# 3. Relax angle tolerance\nswing_up.switch_angle_tol = 0.45  # From 0.35 rad\n\n# 4. Check energy calculation\nE_current = dynamics.total_energy(state)\nprint(f\"E_current: {E_current}, E_bottom: {swing_up.E_bottom}\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b52a435"
  },
  {
    "id": "swing_up_smc_technical_guide_28_3f609beb",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Widen hysteresis band\nswing_up.exit_energy_factor = 0.85  # From 0.90 (wider band)\n\n# 2. Use stronger stabilizer\nstabilizer = SuperTwistingSMC(gains=[...])  # Instead of Classical\n\n# 3. Add energy filtering\nE_filtered = 0.9 * E_prev + 0.1 * E_current  # Low-pass filter",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f609beb"
  },
  {
    "id": "swing_up_smc_technical_guide_29_0bfb4be1",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Use smoother stabilizer\nstabilizer = SuperTwistingSMC(...)  # Continuous control\n\n# 2. Tighten handoff criteria\nswing_up.switch_angle_tol = 0.25  # From 0.35 (closer to upright)\n\n# 3. Verify stabilizer initialization\nif hasattr(stabilizer, \"initialize_state\"):\n    state_vars = stabilizer.initialize_state()\nelse:\n    print(\"WARNING: Stabilizer missing initialize_state()\")",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bfb4be1"
  },
  {
    "id": "swing_up_smc_technical_guide_30_373064af",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Implement total_energy() in dynamics\nclass MyDynamics:\n    def total_energy(self, state):\n        T = self._kinetic_energy(state)\n        V = self._potential_energy(state)\n        return T + V\n\n# 2. Validate E_bottom at construction\nif not (0 < swing_up.E_bottom < np.inf):\n    raise ValueError(f\"Invalid E_bottom: {swing_up.E_bottom}\")\n\n# 3. Add numerical safeguards\nE = dynamics.total_energy(state)\nif not np.isfinite(E):\n    E = 0.0  # Fallback",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "373064af"
  },
  {
    "id": "swing_up_smc_technical_guide_31_6ef27262",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_energy(swing_up, state):\n    \"\"\"Print detailed energy diagnostics.\"\"\"\n    E_current = swing_up.dyn.total_energy(state)\n    E_about_bottom = swing_up.E_bottom - E_current\n    E_ratio = E_about_bottom / swing_up.E_bottom\n\n    print(f\"E_current: {E_current:.3f} J\")\n    print(f\"E_bottom: {swing_up.E_bottom:.3f} J\")\n    print(f\"E_about_bottom: {E_about_bottom:.3f} J\")\n    print(f\"E_ratio: {E_ratio:.3f} (target: 0.95)\")\n\n    if E_ratio >= swing_up.switch_energy_factor:\n        print(\"\u2705 Energy sufficient for handoff\")\n    else:\n        shortage = (swing_up.switch_energy_factor - E_ratio) * swing_up.E_bottom\n        print(f\"\u274c Energy shortage: {shortage:.3f} J\")",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ef27262"
  },
  {
    "id": "swing_up_smc_technical_guide_32_7583f761",
    "file": "docs\\controllers\\swing_up_smc_technical_guide.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_transitions(history_list):\n    \"\"\"Analyze mode switching behavior.\"\"\"\n    transitions = []\n    prev_mode = history_list[0].get(\"mode\", \"swing\")\n\n    for i, h in enumerate(history_list[1:], 1):\n        mode = h.get(\"mode\", \"swing\")\n        if mode != prev_mode:\n            transitions.append({\n                'time': h.get(\"t\", 0),\n                'from': prev_mode,\n                'to': mode,\n                'E_ratio': h.get(\"E_ratio\", 0)\n            })\n        prev_mode = mode\n\n    print(f\"Total transitions: {len(transitions)}\")\n    for t in transitions:\n        print(f\"  t={t['time']:.2f}s: {t['from']} \u2192 {t['to']} (E_ratio={t['E_ratio']:.3f})\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7583f761"
  },
  {
    "id": "production_deployment_guide_1_e787671c",
    "file": "docs\\deployment\\production_deployment_guide.md",
    "index": 1,
    "code": "# Production optimization settings\nimport os\nimport numpy as np\nfrom numba import set_num_threads\n\n# Configure Numba for production\nos.environ['NUMBA_CACHE_DIR'] = '/tmp/numba_cache'\nos.environ['NUMBA_NUM_THREADS'] = str(os.cpu_count())\nset_num_threads(os.cpu_count())\n\n# NumPy optimizations\nnp.seterr(all='raise')  # Raise on numerical errors\nos.environ['OMP_NUM_THREADS'] = str(os.cpu_count())\nos.environ['OPENBLAS_NUM_THREADS'] = str(os.cpu_count())",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e787671c"
  },
  {
    "id": "production_deployment_guide_2_53803e6a",
    "file": "docs\\deployment\\production_deployment_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python3\n\"\"\"\nProduction performance benchmark script.\nValidates system performance under production load.\n\"\"\"\n\nimport time\nimport statistics\nimport numpy as np\nfrom concurrent.futures import ThreadPoolExecutor\nfrom src.controllers.factory import create_controller\n\ndef benchmark_controller_performance():\n    \"\"\"Benchmark controller performance under load.\"\"\"\n\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n    results = {}\n\n    for controller_type in controllers:\n        print(f\"Benchmarking {controller_type}...\")\n\n        # Create controller\n        controller = create_controller(controller_type)\n\n        # Benchmark parameters\n        n_iterations = 10000\n        state = np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n\n        # Single-threaded performance\n        start_time = time.time()\n        for _ in range(n_iterations):\n            result = controller.compute_control(state)\n        single_thread_time = time.time() - start_time\n\n        # Multi-threaded performance\n        def compute_batch():\n            for _ in range(n_iterations // 4):\n                result = controller.compute_control(state)\n\n        start_time = time.time()\n        with ThreadPoolExecutor(max_workers=4) as executor:\n            futures = [executor.submit(compute_batch) for _ in range(4)]\n            for future in futures:\n                future.result()\n        multi_thread_time = time.time() - start_time\n\n        results[controller_type] = {\n            'single_thread_time': single_thread_time,\n            'multi_thread_time': multi_thread_time,\n            'single_thread_rate': n_iterations / single_thread_time,\n            'multi_thread_rate': n_iterations / multi_thread_time,\n            'speedup': single_thread_time / multi_thread_time\n        }\n\n    return results\n\ndef validate_production_readiness():\n    \"\"\"Validate system meets production performance requirements.\"\"\"\n\n    requirements = {\n        'min_control_rate': 100,  # Hz\n        'max_latency': 0.01,      # seconds\n        'min_throughput': 1000,   # computations/second\n    }\n\n    results = benchmark_controller_performance()\n\n    print(\"\\nProduction Readiness Validation:\")\n    print(\"=\" * 50)\n\n    all_pass = True\n    for controller_type, metrics in results.items():\n        control_rate = metrics['single_thread_rate']\n        latency = 1.0 / control_rate\n\n        rate_pass = control_rate >= requirements['min_control_rate']\n        latency_pass = latency <= requirements['max_latency']\n        throughput_pass = metrics['multi_thread_rate'] >= requirements['min_throughput']\n\n        status = \"PASS\" if all([rate_pass, latency_pass, throughput_pass]) else \"FAIL\"\n        if status == \"FAIL\":\n            all_pass = False\n\n        print(f\"{controller_type:25} | {status:4} | \"\n              f\"Rate: {control_rate:6.1f} Hz | \"\n              f\"Latency: {latency*1000:5.2f} ms | \"\n              f\"Throughput: {metrics['multi_thread_rate']:6.1f} ops/s\")\n\n    print(\"=\" * 50)\n    overall_status = \"PRODUCTION READY\" if all_pass else \"NEEDS OPTIMIZATION\"\n    print(f\"Overall Status: {overall_status}\")\n\n    return all_pass\n\nif __name__ == \"__main__\":\n    validation_result = validate_production_readiness()\n    exit(0 if validation_result else 1)",
    "lines": 100,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53803e6a"
  },
  {
    "id": "production_deployment_guide_3_11cfdabb",
    "file": "docs\\deployment\\production_deployment_guide.md",
    "index": 3,
    "code": "#!/usr/bin/env python3\n\"\"\"\nComprehensive health check for SMC controller production deployment.\n\"\"\"\n\nimport os\nimport sys\nimport time\nimport psutil\nimport requests\nimport subprocess\nfrom typing import Dict, List, Tuple\n\nclass ProductionHealthChecker:\n    \"\"\"Production health monitoring and validation.\"\"\"\n\n    def __init__(self):\n        self.health_checks = [\n            self.check_service_status,\n            self.check_controller_functionality,\n            self.check_system_resources,\n            self.check_network_connectivity,\n            self.check_disk_space,\n            self.check_log_files,\n            self.check_configuration,\n            self.check_performance_metrics\n        ]\n\n    def run_comprehensive_health_check(self) -> Dict[str, bool]:\n        \"\"\"Run all health checks and return results.\"\"\"\n\n        results = {}\n        print(\"SMC Controller Production Health Check\")\n        print(\"=\" * 50)\n\n        for check_func in self.health_checks:\n            check_name = check_func.__name__.replace('check_', '').replace('_', ' ').title()\n            try:\n                result = check_func()\n                results[check_name] = result\n                status = \"PASS\" if result else \"FAIL\"\n                print(f\"{check_name:25} | {status}\")\n            except Exception as e:\n                results[check_name] = False\n                print(f\"{check_name:25} | FAIL | Error: {str(e)}\")\n\n        print(\"=\" * 50)\n\n        # Overall health assessment\n        total_checks = len(results)\n        passed_checks = sum(results.values())\n        health_percentage = (passed_checks / total_checks) * 100\n\n        if health_percentage >= 90:\n            overall_status = \"EXCELLENT\"\n        elif health_percentage >= 75:\n            overall_status = \"GOOD\"\n        elif health_percentage >= 50:\n            overall_status = \"WARNING\"\n        else:\n            overall_status = \"CRITICAL\"\n\n        print(f\"Overall Health: {overall_status} ({passed_checks}/{total_checks} checks passed)\")\n        print(f\"Health Score: {health_percentage:.1f}%\")\n\n        return results\n\n    def check_service_status(self) -> bool:\n        \"\"\"Check if SMC controller service is running.\"\"\"\n        try:\n            result = subprocess.run(['systemctl', 'is-active', 'smc-controller'],\n                                  capture_output=True, text=True)\n            return result.stdout.strip() == 'active'\n        except:\n            return False\n\n    def check_controller_functionality(self) -> bool:\n        \"\"\"Check if all controllers are functional.\"\"\"\n        try:\n            response = requests.get('http://localhost:8080/health', timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n\n    def check_system_resources(self) -> bool:\n        \"\"\"Check system resource usage.\"\"\"\n        try:\n            # CPU usage (average over 1 second)\n            cpu_percent = psutil.cpu_percent(interval=1)\n\n            # Memory usage\n            memory = psutil.virtual_memory()\n            memory_percent = memory.percent\n\n            # Check thresholds\n            return cpu_percent < 80 and memory_percent < 85\n        except:\n            return False\n\n    def check_network_connectivity(self) -> bool:\n        \"\"\"Check network connectivity.\"\"\"\n        try:\n            # Check if health endpoint is reachable\n            response = requests.get('http://localhost:8080/health', timeout=3)\n            return response.status_code == 200\n        except:\n            return False\n\n    def check_disk_space(self) -> bool:\n        \"\"\"Check available disk space.\"\"\"\n        try:\n            # Check main filesystem\n            disk_usage = psutil.disk_usage('/')\n            free_percent = (disk_usage.free / disk_usage.total) * 100\n\n            # Check logs directory\n            logs_usage = psutil.disk_usage('/home/smc-prod/smc-production/logs')\n            logs_free_percent = (logs_usage.free / logs_usage.total) * 100\n\n            return free_percent > 10 and logs_free_percent > 5\n        except:\n            return False\n\n    def check_log_files(self) -> bool:\n        \"\"\"Check log file integrity and recent updates.\"\"\"\n        try:\n            log_dir = '/home/smc-prod/smc-production/logs'\n            if not os.path.exists(log_dir):\n                return False\n\n            # Check if logs are being written (modified within last hour)\n            for log_file in os.listdir(log_dir):\n                if log_file.endswith('.log'):\n                    log_path = os.path.join(log_dir, log_file)\n                    mtime = os.path.getmtime(log_path)\n                    if time.time() - mtime < 3600:  # 1 hour\n                        return True\n\n            return False\n        except:\n            return False\n\n    def check_configuration(self) -> bool:\n        \"\"\"Check configuration file validity.\"\"\"\n        try:\n            config_path = '/home/smc-prod/smc-production/config/production.yaml'\n\n            # Check if config file exists and is readable\n            if not os.path.exists(config_path):\n                return False\n\n            # Basic YAML syntax check\n            import yaml\n            with open(config_path, 'r') as f:\n                config = yaml.safe_load(f)\n\n            # Check for required sections\n            required_sections = ['simulation', 'physics', 'controllers']\n            return all(section in config for section in required_sections)\n        except:\n            return False\n\n    def check_performance_metrics(self) -> bool:\n        \"\"\"Check if performance metrics are within acceptable ranges.\"\"\"\n        try:\n            # This would typically check metrics from Prometheus\n            # For now, we'll do a basic performance test\n\n            from src.controllers.factory import create_controller\n            import numpy as np\n\n            # Quick performance test\n            controller = create_controller('classical_smc')\n            state = np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n\n            start_time = time.time()\n            for _ in range(100):\n                result = controller.compute_control(state)\n            elapsed_time = time.time() - start_time\n\n            # Should complete 100 computations in less than 1 second\n            return elapsed_time < 1.0\n        except:\n            return False\n\nif __name__ == \"__main__\":\n    checker = ProductionHealthChecker()\n    results = checker.run_comprehensive_health_check()\n\n    # Exit with error code if any critical checks fail\n    critical_checks = ['Service Status', 'Controller Functionality', 'System Resources']\n    critical_failures = [name for name in critical_checks if not results.get(name, False)]\n\n    if critical_failures:\n        print(f\"\\nCRITICAL FAILURES: {', '.join(critical_failures)}\")\n        sys.exit(1)\n    else:\n        print(\"\\nAll critical systems operational\")\n        sys.exit(0)",
    "lines": 199,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "11cfdabb"
  },
  {
    "id": "STREAMLIT_DEPLOYMENT_1_0cea67ca",
    "file": "docs\\deployment\\STREAMLIT_DEPLOYMENT.md",
    "index": 1,
    "code": "# Add to streamlit_app.py for custom health endpoint\nimport streamlit as st\n\nif st.sidebar.button(\"Health Check\"):\n    st.success(\"\u2705 Application is running normally\")\n    st.info(f\"Cache size: {len(st.session_state)} items\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0cea67ca"
  },
  {
    "id": "mathematical_notation_standards_1_f540f23f",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nClassical SMC sliding surface definition:\n\ns = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n\nwhere:\n- e\u2081 = \u03b8\u2081 - \u03b8\u2081\u1d48 (angular position error for pendulum 1)\n- e\u2082 = \u03b8\u2082 - \u03b8\u2082\u1d48 (angular position error for pendulum 2)\n- \u0117\u2081 = \u03b8\u0307\u2081 - \u03b8\u0307\u2081\u1d48 (angular velocity error for pendulum 1)\n- \u0117\u2082 = \u03b8\u0307\u2082 - \u03b8\u0307\u2082\u1d48 (angular velocity error for pendulum 2)\n- \u03bb\u2081, \u03bb\u2082 > 0 (sliding surface gains for Hurwitz stability)\n\nStability Condition:\nFor exponential convergence to the sliding surface, require:\n\u03bb\u2081, \u03bb\u2082 > 0 ensuring the characteristic polynomial s\u00b2 + \u03bb\u2082s + \u03bb\u2081 = 0\nhas roots in the left half-plane.\n\"\"\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f540f23f"
  },
  {
    "id": "mathematical_notation_standards_2_9d3b7227",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 2,
    "code": "\"\"\"\nLyapunov stability analysis for SMC reaching condition:\n\nV(s) = \u00bds\u00b2\n\nTaking the time derivative along system trajectories:\nV\u0307(s) = s\u00b7\u1e61 = s\u00b7(\u03bb\u2081\u0117\u2081 + \u03bb\u2082\u0117\u2082 + \u00eb\u2081 + \u00eb\u2082)\n\nFor the reaching condition V\u0307 < 0 when s \u2260 0, the switching gain K must satisfy:\nK > |f_eq(x)| + \u03b4\n\nwhere f_eq is the equivalent control and \u03b4 > 0 accounts for uncertainties.\n\"\"\"",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d3b7227"
  },
  {
    "id": "mathematical_notation_standards_3_9c5236d8",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nSecond-order sliding mode (Super-Twisting) control law:\n\nu = u\u2081 + u\u2082\n\nwhere:\nu\u2081 = -\u03b1|s|^(1/2)sign(s)\nu\u2082 = \u222b\u2080\u1d57(-\u03b2 sign(s))d\u03c4\n\nParameters \u03b1, \u03b2 > 0 must satisfy the convergence condition:\n\u03b1 > \u221a(2L), \u03b2 > \u03b1\u00b2/(2(\u03b1-\u221a(2L)))\n\nwhere L is the Lipschitz constant of the uncertainty.\n\"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c5236d8"
  },
  {
    "id": "mathematical_notation_standards_4_d90bf31b",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nParticle Swarm Optimization update equations:\n\nv\u1d62\u1d57\u207a\u00b9 = w\u00b7v\u1d62\u1d57 + c\u2081r\u2081(p\u1d62 - x\u1d62\u1d57) + c\u2082r\u2082(g - x\u1d62\u1d57)\nx\u1d62\u1d57\u207a\u00b9 = x\u1d62\u1d57 + v\u1d62\u1d57\u207a\u00b9\n\nwhere:\n- x\u1d62\u1d57 \u2208 \u211d\u207f: position of particle i at iteration t\n- v\u1d62\u1d57 \u2208 \u211d\u207f: velocity of particle i at iteration t\n- p\u1d62 \u2208 \u211d\u207f: personal best position of particle i\n- g \u2208 \u211d\u207f: global best position\n- w \u2208 [0,1]: inertia weight\n- c\u2081, c\u2082 > 0: acceleration coefficients\n- r\u2081, r\u2082 ~ U(0,1): random variables\n\nConvergence requires: w < 1 and c\u2081 + c\u2082 < 4(1 + w)\n\"\"\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d90bf31b"
  },
  {
    "id": "mathematical_notation_standards_5_c521b561",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nMulti-objective cost function for controller optimization:\n\nJ(k) = w\u2081\u00b7ISE(k) + w\u2082\u00b7ITAE(k) + w\u2083\u00b7U_max(k) + w\u2084\u00b7Penalty(k)\n\nwhere:\n- ISE(k) = \u222b\u2080\u1d40 \u2016e(t,k)\u2016\u00b2 dt (Integral Squared Error)\n- ITAE(k) = \u222b\u2080\u1d40 t\u00b7\u2016e(t,k)\u2016\u2081 dt (Integral Time Absolute Error)\n- U_max(k) = max_{t\u2208[0,T]} |u(t,k)| (Control effort penalty)\n- Penalty(k): Instability penalty (\u2192 \u221e if unstable)\n- w\u1d62 \u2265 0: weighting factors with \u2211w\u1d62 = 1\n\"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c521b561"
  },
  {
    "id": "mathematical_notation_standards_6_bd6f461a",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nPerformance Metrics for Control Systems:\n\n1. Integral Squared Error (ISE):\n   ISE = \u222b\u2080\u1d40 \u2016e(t)\u2016\u00b2 dt\n\n2. Integral Time Absolute Error (ITAE):\n   ITAE = \u222b\u2080\u1d40 t\u00b7\u2016e(t)\u2016\u2081 dt\n\n3. Integral Absolute Error (IAE):\n   IAE = \u222b\u2080\u1d40 \u2016e(t)\u2016\u2081 dt\n\n4. Root Mean Square Error (RMSE):\n   RMSE = \u221a(1/T \u222b\u2080\u1d40 \u2016e(t)\u2016\u00b2 dt)\n\n5. Maximum Overshoot:\n   OS = max(x(t)) - x_final / x_final \u00d7 100%\n\n6. Settling Time (2% criterion):\n   t_s = inf{t > 0 : |x(\u03c4) - x_final| \u2264 0.02|x_final| \u2200\u03c4 \u2265 t}\n\"\"\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd6f461a"
  },
  {
    "id": "mathematical_notation_standards_7_71adc7b3",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nMonte Carlo Uncertainty Quantification:\n\nGiven N independent samples {J\u2081, J\u2082, ..., J\u2099} of the cost function:\n\nSample Mean: \u03bc\u0302 = 1/N \u2211\u1d62\u208c\u2081\u1d3a J\u1d62\n\nSample Variance: \u03c3\u0302\u00b2 = 1/(N-1) \u2211\u1d62\u208c\u2081\u1d3a (J\u1d62 - \u03bc\u0302)\u00b2\n\nConfidence Interval (\u03b1 = 0.05):\nCI\u2080.\u2089\u2085 = \u03bc\u0302 \u00b1 t_{N-1,\u03b1/2} \u00b7 \u03c3\u0302/\u221aN\n\nwhere t_{N-1,\u03b1/2} is the (1-\u03b1/2) quantile of the t-distribution with N-1 degrees of freedom.\n\"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71adc7b3"
  },
  {
    "id": "mathematical_notation_standards_8_7a28f159",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nWelch's t-test for comparing controller performance:\n\nH\u2080: \u03bc\u2081 = \u03bc\u2082 (no difference in mean performance)\nH\u2081: \u03bc\u2081 \u2260 \u03bc\u2082 (significant difference in performance)\n\nTest Statistic:\nt = (x\u0304\u2081 - x\u0304\u2082) / \u221a(s\u2081\u00b2/n\u2081 + s\u2082\u00b2/n\u2082)\n\nDegrees of Freedom (Welch-Satterthwaite):\n\u03bd = (s\u2081\u00b2/n\u2081 + s\u2082\u00b2/n\u2082)\u00b2 / ((s\u2081\u00b2/n\u2081)\u00b2/(n\u2081-1) + (s\u2082\u00b2/n\u2082)\u00b2/(n\u2082-1))\n\nReject H\u2080 if |t| > t_{\u03bd,\u03b1/2} where \u03b1 is the significance level.\n\"\"\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a28f159"
  },
  {
    "id": "mathematical_notation_standards_9_53164579",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 9,
    "code": "from IPython.display import Math, display\n\ndisplay(Math(r's = \\lambda_1 e_1 + \\lambda_2 e_2 + \\dot{e}_1 + \\dot{e}_2'))",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53164579"
  },
  {
    "id": "mathematical_notation_standards_10_50d074a8",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_sliding_surface(self, state: np.ndarray, target: np.ndarray) -> float:\n    \"\"\"Compute the sliding surface value for classical SMC.\n\n    The sliding surface is defined as:\n    s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n\n    where:\n    - e\u2081, e\u2082: position errors for pendulum 1 and 2\n    - \u0117\u2081, \u0117\u2082: velocity errors for pendulum 1 and 2\n    - \u03bb\u2081, \u03bb\u2082: sliding surface gains (must be positive)\n\n    Mathematical Background:\n    The sliding surface design ensures that once the system reaches\n    the surface (s=0), it will remain on the surface and converge\n    to the desired equilibrium point in finite time.\n\n    Parameters\n    ----------\n    state : np.ndarray, shape (6,)\n        Current system state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n    target : np.ndarray, shape (6,)\n        Target state (typically upright equilibrium [0, 0, 0, 0, 0, 0])\n\n    Returns\n    -------\n    float\n        Sliding surface value. System is on sliding surface when s = 0.\n\n    References\n    ----------\n    .. [1] Utkin, V. \"Sliding Modes in Control and Optimization\", 1992\n    .. [2] Edwards, C. \"Sliding Mode Control: Theory and Applications\", 1998\n    \"\"\"",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50d074a8"
  },
  {
    "id": "mathematical_notation_standards_11_41efa740",
    "file": "docs\\examples\\mathematical_notation_standards.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass ClassicalSMC:\n    \"\"\"Classical Sliding Mode Controller for double-inverted pendulum.\n\n    Implements the classical SMC algorithm with boundary layer for chattering\n    reduction. The control law consists of equivalent control and switching\n    control components:\n\n    u = u_eq + u_sw\n\n    where:\n    - u_eq: Equivalent control (model-based feedforward)\n    - u_sw: Switching control (robust feedback)\n\n    The sliding surface is designed as:\n    s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n\n    Stability is guaranteed when \u03bb\u2081, \u03bb\u2082 > 0, ensuring the characteristic\n    polynomial s\u00b2 + \u03bb\u2082s + \u03bb\u2081 = 0 has stable roots.\n\n    Parameters\n    ----------\n    gains : List[float]\n        Controller gains [k\u2081, k\u2082, \u03bb\u2081, \u03bb\u2082, K, k_d] where:\n        - k\u2081, k\u2082: Position feedback gains\n        - \u03bb\u2081, \u03bb\u2082: Sliding surface gains\n        - K: Switching gain\n        - k_d: Derivative gain\n    max_force : float\n        Maximum control force (saturation limit)\n    boundary_layer : float\n        Boundary layer thickness for chattering reduction\n\n    Attributes\n    ----------\n    n_gains : int\n        Number of controller gains (6 for classical SMC)\n\n    Examples\n    --------\n    >>> controller = ClassicalSMC(\n    ...     gains=[10.0, 5.0, 8.0, 3.0, 15.0, 2.0],\n    ...     max_force=100.0,\n    ...     boundary_layer=0.01\n    ... )\n    >>> state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    >>> result = controller.compute_control(state, None, {})\n    >>> print(f\"Control output: {result['u']:.4f}\")\n    \"\"\"",
    "lines": 51,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "41efa740"
  },
  {
    "id": "configuration_migration_mathematical_foundations_1_40f19269",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_classical_smc_parameters_mathematical(old_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Mathematically sound migration for Classical SMC parameters.\n\n    Mathematical Validation:\n    1. Preserve sliding surface eigenvalues\n    2. Maintain Lyapunov stability conditions\n    3. Ensure bounded control effort\n    \"\"\"\n\n    new_params = {}\n\n    # Extract old gains structure\n    old_gains = old_params.get('gains', [])\n    K_switching = old_params.get('K_switching', 0.0)\n\n    # Mathematical migration: [k1, k2, \u03bb1, \u03bb2, K] \u2192 [k1, k2, \u03bb1, \u03bb2, K, kd]\n    if len(old_gains) == 5:\n        k1, k2, lam1, lam2, K_old = old_gains\n\n        # Validate stability conditions\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Sliding surface coefficients \u03bb\u2081, \u03bb\u2082 must be positive for stability\")\n\n        if k1 <= 0 or k2 <= 0:\n            raise ValueError(\"Proportional gains k\u2081, k\u2082 must be positive\")\n\n        # Combine switching gains: K_total = max(K_old, K_switching)\n        K_total = max(K_old, K_switching) if K_switching > 0 else K_old\n\n        # Add derivative gain for chattering reduction\n        kd = old_params.get('kd', K_total * 0.1)  # 10% of switching gain\n\n        new_params['gains'] = [k1, k2, lam1, lam2, K_total, kd]\n\n    # Validate sliding surface eigenvalues\n    if 'gains' in new_params:\n        k1, k2, lam1, lam2, K, kd = new_params['gains']\n\n        # Check sliding surface stability (simplified for double pendulum)\n        eigenvalues = [-lam1/k1, -lam2/k2]  # Approximate eigenvalues\n        if any(eig >= 0 for eig in eigenvalues):\n            print(f\"Warning: Sliding surface may be unstable. Eigenvalues: {eigenvalues}\")\n\n    # Migrate deprecated parameters\n    deprecated_mappings = {\n        'switch_function': 'switch_method',\n        'saturation_limit': 'max_force',\n        'boundary_thickness': 'boundary_layer'\n    }\n\n    for old_param, new_param in deprecated_mappings.items():\n        if old_param in old_params:\n            new_params[new_param] = old_params[old_param]\n\n    # Ensure required parameters with physically meaningful defaults\n    new_params.setdefault('max_force', 150.0)  # Reasonable actuator limit [N]\n    new_params.setdefault('boundary_layer', 0.02)  # 2% of typical angular range\n    new_params.setdefault('dt', 0.001)  # 1ms sampling time\n\n    return new_params\n\n# Mathematical validation example\nold_classical_config = {\n    'gains': [20.0, 15.0, 12.0, 8.0, 35.0],  # [k1, k2, \u03bb1, \u03bb2, K]\n    'K_switching': 5.0,\n    'switch_function': 'sign',\n    'saturation_limit': 100.0\n}\n\nmigrated_config = migrate_classical_smc_parameters_mathematical(old_classical_config)\nprint(\"Migrated Classical SMC config:\", migrated_config)",
    "lines": 75,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40f19269"
  },
  {
    "id": "configuration_migration_mathematical_foundations_2_aa314d9d",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_adaptive_smc_parameters_mathematical(old_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Mathematically sound migration for Adaptive SMC parameters.\n\n    Mathematical Validation:\n    1. Preserve adaptation law stability\n    2. Maintain Lyapunov convergence conditions\n    3. Ensure bounded parameter estimates\n    \"\"\"\n\n    new_params = {}\n\n    # Extract old parameter structure\n    old_gains = old_params.get('gains', [])\n    adaptation_gain = old_params.get('adaptation_gain', 0.0)\n\n    # Mathematical migration: [k1, k2, \u03bb1, \u03bb2] + \u03b3 \u2192 [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    if len(old_gains) == 4:\n        k1, k2, lam1, lam2 = old_gains\n\n        # Validate stability conditions\n        if lam1 <= 0 or lam2 <= 0:\n            raise ValueError(\"Sliding surface coefficients \u03bb\u2081, \u03bb\u2082 must be positive\")\n\n        if k1 <= 0 or k2 <= 0:\n            raise ValueError(\"Proportional gains k\u2081, k\u2082 must be positive\")\n\n        # Use provided adaptation gain or calculate from stability requirements\n        if adaptation_gain > 0:\n            gamma = adaptation_gain\n        else:\n            # Calculate adaptation gain from stability margin\n            # \u03b3 should be large enough for fast adaptation but not cause oscillations\n            gamma = min(k1, k2) * 0.5  # Conservative choice\n\n        # Validate adaptation rate bounds\n        if gamma <= 0:\n            raise ValueError(\"Adaptation rate \u03b3 must be positive for convergence\")\n\n        if gamma > 20.0:  # Practical upper bound\n            print(f\"Warning: High adaptation rate \u03b3={gamma:.2f} may cause oscillations\")\n\n        new_params['gains'] = [k1, k2, lam1, lam2, gamma]\n\n    # Migration of adaptation parameters\n    adaptation_mappings = {\n        'boundary_layer_thickness': 'boundary_layer',\n        'estimate_bounds': ('K_min', 'K_max'),  # Special case: split parameter\n        'adaptation_law': 'alpha',\n        'leak_coefficient': 'leak_rate'\n    }\n\n    for old_param, new_param in adaptation_mappings.items():\n        if old_param in old_params:\n            if old_param == 'estimate_bounds':\n                # Split bounds into separate parameters\n                bounds = old_params[old_param]\n                if isinstance(bounds, (list, tuple)) and len(bounds) == 2:\n                    new_params['K_min'] = bounds[0]\n                    new_params['K_max'] = bounds[1]\n\n                    # Validate bounds\n                    if new_params['K_min'] >= new_params['K_max']:\n                        raise ValueError(\"K_min must be less than K_max\")\n                    if new_params['K_min'] <= 0:\n                        raise ValueError(\"K_min must be positive\")\n            else:\n                new_params[new_param] = old_params[old_param]\n\n    # Ensure required adaptation parameters with theoretical justification\n    new_params.setdefault('leak_rate', 0.01)  # 1% leak rate prevents drift\n    new_params.setdefault('K_min', 0.1)  # Minimum for controllability\n    new_params.setdefault('K_max', 100.0)  # Maximum for actuator limits\n    new_params.setdefault('adapt_rate_limit', 10.0)  # Prevent excessive adaptation\n    new_params.setdefault('alpha', 0.5)  # Compromise between speed and stability\n    new_params.setdefault('dead_zone', 0.05)  # Noise tolerance\n    new_params.setdefault('boundary_layer', 0.01)  # Smaller for adaptation\n    new_params.setdefault('smooth_switch', True)  # Reduce chattering\n\n    # Validate adaptation stability conditions\n    if 'gains' in new_params and len(new_params['gains']) >= 5:\n        gamma = new_params['gains'][4]\n        leak_rate = new_params['leak_rate']\n\n        # Check adaptation stability: \u03c3/\u03b3 should be small for good tracking\n        stability_ratio = leak_rate / gamma\n        if stability_ratio > 0.1:\n            print(f\"Warning: High leak-to-adaptation ratio {stability_ratio:.3f} may degrade performance\")\n\n    return new_params\n\n# Mathematical validation example\nold_adaptive_config = {\n    'gains': [25.0, 18.0, 15.0, 10.0],  # [k1, k2, \u03bb1, \u03bb2]\n    'adaptation_gain': 4.0,\n    'boundary_layer_thickness': 0.02,\n    'estimate_bounds': [0.1, 100.0],\n    'adaptation_law': 0.5\n}\n\nmigrated_config = migrate_adaptive_smc_parameters_mathematical(old_adaptive_config)\nprint(\"Migrated Adaptive SMC config:\", migrated_config)",
    "lines": 105,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa314d9d"
  },
  {
    "id": "configuration_migration_mathematical_foundations_3_2b80d30c",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_sta_smc_parameters_mathematical(old_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Mathematically sound migration for Super-Twisting SMC parameters.\n\n    Mathematical Validation:\n    1. Preserve finite-time convergence conditions\n    2. Maintain super-twisting stability requirements\n    3. Ensure proper algorithmic gain relationships\n    \"\"\"\n\n    new_params = {}\n\n    # Extract separate K1, K2 parameters (old format)\n    K1 = old_params.get('K1', 0.0)\n    K2 = old_params.get('K2', 0.0)\n    old_gains = old_params.get('gains', [])\n\n    # Mathematical migration: separate K1,K2 + surface gains \u2192 unified gains array\n    if K1 > 0 and K2 > 0:\n        # Validate super-twisting convergence conditions\n        alpha = old_params.get('alpha_power', 0.5)\n\n        # Simplified convergence check (assumes L=1 for typical systems)\n        L_estimate = 1.0\n        min_K1 = L_estimate / alpha\n        min_K2 = K1**2 / (2 * L_estimate) + L_estimate\n\n        if K1 < min_K1:\n            print(f\"Warning: K\u2081={K1:.2f} may be too small for convergence (min: {min_K1:.2f})\")\n\n        if K2 < min_K2:\n            print(f\"Warning: K\u2082={K2:.2f} may be too small for convergence (min: {min_K2:.2f})\")\n\n        # Extract surface gains or use defaults\n        if len(old_gains) >= 4:\n            k1, k2, lam1, lam2 = old_gains[:4]\n        else:\n            # Default surface gains for double pendulum\n            k1, k2, lam1, lam2 = 20.0, 15.0, 12.0, 8.0\n\n        # Validate surface gain positivity\n        if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n            raise ValueError(\"All surface gains must be positive\")\n\n        # Create unified gains array: [K1, K2, k1, k2, \u03bb1, \u03bb2]\n        new_params['gains'] = [K1, K2, k1, k2, lam1, lam2]\n\n    elif len(old_gains) >= 6:\n        # Already in new format, validate convergence conditions\n        K1, K2, k1, k2, lam1, lam2 = old_gains[:6]\n\n        # Validate all gains are positive\n        if any(g <= 0 for g in [K1, K2, k1, k2, lam1, lam2]):\n            raise ValueError(\"All STA-SMC gains must be positive\")\n\n        new_params['gains'] = [K1, K2, k1, k2, lam1, lam2]\n\n    # Migrate algorithm-specific parameters\n    algorithm_mappings = {\n        'alpha_power': 'power_exponent',\n        'switching_function_type': 'switch_method',\n        'regularization_parameter': 'regularization'\n    }\n\n    for old_param, new_param in algorithm_mappings.items():\n        if old_param in old_params:\n            new_params[new_param] = old_params[old_param]\n\n    # Ensure algorithm parameters with mathematical justification\n    power_exp = new_params.get('power_exponent', 0.5)\n    if not (0 < power_exp < 1):\n        raise ValueError(f\"Power exponent \u03b1={power_exp} must be in (0,1) for finite-time convergence\")\n\n    new_params.setdefault('power_exponent', 0.5)  # Optimal for most systems\n    new_params.setdefault('regularization', 1e-6)  # Numerical stability\n    new_params.setdefault('boundary_layer', 0.01)  # Small boundary for STA\n    new_params.setdefault('switch_method', 'tanh')  # Smooth switching\n    new_params.setdefault('damping_gain', 0.0)  # No additional damping by default\n\n    # Advanced validation: Check Lyapunov function decrease rate\n    if 'gains' in new_params and len(new_params['gains']) >= 6:\n        K1, K2 = new_params['gains'][:2]\n        alpha = new_params['power_exponent']\n\n        # Estimate convergence time (simplified analysis)\n        T_convergence = 2 * (1 / (1 - alpha)) * (1 / min(K1, K2)**0.5)\n        if T_convergence > 10.0:  # More than 10 seconds\n            print(f\"Warning: Estimated convergence time {T_convergence:.2f}s may be too slow\")\n\n    return new_params\n\n# Mathematical validation example\nold_sta_config = {\n    'K1': 35.0,\n    'K2': 20.0,\n    'gains': [25.0, 18.0, 12.0, 8.0],  # Surface gains\n    'alpha_power': 0.5,\n    'switching_function_type': 'tanh',\n    'regularization_parameter': 1e-6\n}\n\nmigrated_config = migrate_sta_smc_parameters_mathematical(old_sta_config)\nprint(\"Migrated STA-SMC config:\", migrated_config)",
    "lines": 106,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b80d30c"
  },
  {
    "id": "configuration_migration_mathematical_foundations_4_879f613b",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_hybrid_smc_parameters_mathematical(old_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Mathematically sound migration for Hybrid SMC parameters.\n\n    Mathematical Validation:\n    1. Preserve mode switching stability\n    2. Maintain unified surface design\n    3. Ensure sub-controller compatibility\n    \"\"\"\n\n    new_params = {}\n\n    # Extract surface gains (shared across all modes)\n    surface_gains = old_params.get('gains', [18.0, 12.0, 10.0, 8.0])\n\n    if len(surface_gains) != 4:\n        raise ValueError(\"Hybrid SMC requires exactly 4 surface gains [c\u2081, \u03bb\u2081, c\u2082, \u03bb\u2082]\")\n\n    c1, lam1, c2, lam2 = surface_gains\n\n    # Validate surface stability\n    if any(g <= 0 for g in [c1, lam1, c2, lam2]):\n        raise ValueError(\"All surface coefficients must be positive\")\n\n    # Check surface eigenvalue placement for stability\n    eigen1 = -lam1 / c1\n    eigen2 = -lam2 / c2\n    if eigen1 >= 0 or eigen2 >= 0:\n        print(f\"Warning: Surface eigenvalues [{eigen1:.3f}, {eigen2:.3f}] may indicate instability\")\n\n    new_params['gains'] = surface_gains\n\n    # Handle mode parameter migration\n    mode_mappings = {\n        'mode': 'hybrid_mode',\n        'switch_threshold': 'switching_criteria',\n        'classical_params': 'classical_config',\n        'adaptive_params': 'adaptive_config'\n    }\n\n    for old_param, new_param in mode_mappings.items():\n        if old_param in old_params:\n            if old_param == 'switch_threshold':\n                # Convert scalar threshold to criteria dict\n                threshold = old_params[old_param]\n                new_params['switching_criteria'] = {\n                    'error_threshold': threshold,\n                    'time_threshold': 2.0,  # Default time threshold\n                    'performance_threshold': 0.1  # Performance-based switching\n                }\n            else:\n                new_params[new_param] = old_params[old_param]\n\n    # Handle sub-controller gain migration\n    if 'sub_controller_gains' in old_params:\n        sub_gains = old_params['sub_controller_gains']\n\n        if isinstance(sub_gains, dict):\n            # Create proper sub-controller configurations\n            classical_gains = sub_gains.get('classical', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n            adaptive_gains = sub_gains.get('adaptive', [25.0, 18.0, 15.0, 10.0, 4.0])\n\n            # Validate sub-controller gains\n            if len(classical_gains) != 6:\n                raise ValueError(\"Classical sub-controller requires 6 gains\")\n            if len(adaptive_gains) != 5:\n                raise ValueError(\"Adaptive sub-controller requires 5 gains\")\n\n            # Create complete sub-configurations with surface coupling\n            new_params['classical_config'] = {\n                'gains': classical_gains,\n                'max_force': old_params.get('max_force', 150.0),\n                'boundary_layer': 0.02,\n                'dt': old_params.get('dt', 0.001),\n                'surface_coupling': True  # Ensure surface consistency\n            }\n\n            new_params['adaptive_config'] = {\n                'gains': adaptive_gains,\n                'max_force': old_params.get('max_force', 150.0),\n                'leak_rate': 0.01,\n                'adapt_rate_limit': 10.0,\n                'K_min': 0.1,\n                'K_max': 100.0,\n                'dt': old_params.get('dt', 0.001),\n                'surface_coupling': True  # Ensure surface consistency\n            }\n\n    # Set hybrid-specific parameters with mathematical justification\n    new_params.setdefault('hybrid_mode', 'CLASSICAL_ADAPTIVE')  # Conservative default\n    new_params.setdefault('dt', 0.001)  # Fast sampling for mode switching\n    new_params.setdefault('max_force', 150.0)  # Shared actuator limit\n\n    # Advanced hybrid parameters\n    new_params.setdefault('mode_hysteresis', 0.1)  # Prevent chattering in mode switching\n    new_params.setdefault('transition_smoothing', True)  # Smooth mode transitions\n    new_params.setdefault('surface_consistency_check', True)  # Validate surface compatibility\n\n    # Validate hybrid mode switching stability\n    if 'switching_criteria' in new_params:\n        criteria = new_params['switching_criteria']\n        error_thresh = criteria.get('error_threshold', 0.1)\n        time_thresh = criteria.get('time_threshold', 2.0)\n\n        # Check switching frequency to prevent chattering\n        min_dwell_time = 0.1  # Minimum time in each mode\n        if time_thresh < min_dwell_time:\n            print(f\"Warning: Short time threshold {time_thresh}s may cause mode chattering\")\n\n    return new_params\n\n# Mathematical validation example\nold_hybrid_config = {\n    'gains': [18.0, 12.0, 10.0, 8.0],  # Surface gains\n    'mode': 'CLASSICAL_ADAPTIVE',\n    'sub_controller_gains': {\n        'classical': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'adaptive': [25.0, 18.0, 15.0, 10.0, 4.0]\n    },\n    'switch_threshold': 0.1,\n    'max_force': 150.0\n}\n\nmigrated_config = migrate_hybrid_smc_parameters_mathematical(old_hybrid_config)\nprint(\"Migrated Hybrid SMC config:\", migrated_config)",
    "lines": 128,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "879f613b"
  },
  {
    "id": "configuration_migration_mathematical_foundations_5_003ce8ce",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass StabilityValidator:\n    \"\"\"Validate stability preservation during parameter migration.\"\"\"\n\n    @staticmethod\n    def validate_classical_smc_stability(gains: List[float]) -> Dict[str, Any]:\n        \"\"\"Validate Classical SMC stability conditions.\"\"\"\n\n        if len(gains) != 6:\n            return {'valid': False, 'reason': 'Invalid gain count'}\n\n        k1, k2, lam1, lam2, K, kd = gains\n\n        # Check basic positivity\n        if any(g <= 0 for g in gains):\n            return {'valid': False, 'reason': 'All gains must be positive'}\n\n        # Check sliding surface stability\n        # For double pendulum: sliding surface eigenvalues should be negative\n        surface_eigs = [-lam1/k1, -lam2/k2]\n\n        if any(eig >= 0 for eig in surface_eigs):\n            return {'valid': False, 'reason': f'Unstable surface eigenvalues: {surface_eigs}'}\n\n        # Check actuator reasonableness\n        if K > 200:  # Very high switching gain\n            return {\n                'valid': True,\n                'warnings': [f'High switching gain K={K} may cause excessive chattering']\n            }\n\n        # Check derivative gain ratio\n        kd_ratio = kd / K\n        if kd_ratio > 0.5:  # Derivative gain too large relative to switching gain\n            return {\n                'valid': True,\n                'warnings': [f'High derivative gain ratio {kd_ratio:.2f} may degrade performance']\n            }\n\n        return {\n            'valid': True,\n            'surface_eigenvalues': surface_eigs,\n            'estimated_convergence_rate': min(abs(eig) for eig in surface_eigs),\n            'switching_magnitude': K,\n            'chattering_reduction': kd\n        }\n\n    @staticmethod\n    def validate_adaptive_smc_convergence(gains: List[float], adaptation_params: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"Validate Adaptive SMC convergence conditions.\"\"\"\n\n        if len(gains) != 5:\n            return {'valid': False, 'reason': 'Invalid gain count'}\n\n        k1, k2, lam1, lam2, gamma = gains\n\n        # Check basic conditions\n        if any(g <= 0 for g in gains):\n            return {'valid': False, 'reason': 'All gains must be positive'}\n\n        # Check adaptation stability\n        leak_rate = adaptation_params.get('leak_rate', 0.01)\n        K_min = adaptation_params.get('K_min', 0.1)\n        K_max = adaptation_params.get('K_max', 100.0)\n\n        # Adaptation stability condition: leak rate should be small relative to adaptation rate\n        stability_margin = leak_rate / gamma\n        if stability_margin > 0.2:\n            return {\n                'valid': True,\n                'warnings': [f'High leak-to-adaptation ratio {stability_margin:.3f} may slow convergence']\n            }\n\n        # Check adaptation bounds\n        if K_min >= K_max:\n            return {'valid': False, 'reason': 'K_min must be less than K_max'}\n\n        gain_ratio = K_max / K_min\n        if gain_ratio > 1000:  # Very wide adaptation range\n            return {\n                'valid': True,\n                'warnings': [f'Wide adaptation range (ratio: {gain_ratio:.1f}) may cause instability']\n            }\n\n        return {\n            'valid': True,\n            'adaptation_rate': gamma,\n            'stability_margin': stability_margin,\n            'adaptation_range': [K_min, K_max],\n            'estimated_settling_time': 5.0 / min(lam1/k1, lam2/k2)  # Rough estimate\n        }\n\n    @staticmethod\n    def validate_sta_smc_finite_time_convergence(gains: List[float], algorithm_params: Dict[str, float]) -> Dict[str, Any]:\n        \"\"\"Validate Super-Twisting finite-time convergence conditions.\"\"\"\n\n        if len(gains) != 6:\n            return {'valid': False, 'reason': 'Invalid gain count'}\n\n        K1, K2, k1, k2, lam1, lam2 = gains\n\n        # Check basic positivity\n        if any(g <= 0 for g in gains):\n            return {'valid': False, 'reason': 'All gains must be positive'}\n\n        # Check super-twisting convergence conditions\n        alpha = algorithm_params.get('power_exponent', 0.5)\n\n        if not (0 < alpha < 1):\n            return {'valid': False, 'reason': f'Power exponent \u03b1={alpha} must be in (0,1)'}\n\n        # Simplified convergence check (assumes L=1)\n        L_estimate = 1.0\n        min_K1 = L_estimate / alpha\n        min_K2 = K1**2 / (2 * L_estimate) + L_estimate\n\n        warnings = []\n        if K1 < min_K1:\n            warnings.append(f'K\u2081={K1:.2f} may be too small for convergence (recommended: \u2265{min_K1:.2f})')\n\n        if K2 < min_K2:\n            warnings.append(f'K\u2082={K2:.2f} may be too small for convergence (recommended: \u2265{min_K2:.2f})')\n\n        # Estimate finite-time convergence\n        convergence_time = 2 * (1 / (1 - alpha)) * (1 / min(K1, K2)**0.5)\n\n        return {\n            'valid': True,\n            'warnings': warnings,\n            'algorithmic_gains': [K1, K2],\n            'surface_gains': [k1, k2, lam1, lam2],\n            'power_exponent': alpha,\n            'estimated_convergence_time': convergence_time,\n            'convergence_conditions_met': len(warnings) == 0\n        }\n\n# Validation example\ngains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\nvalidation = StabilityValidator.validate_classical_smc_stability(gains)\nprint(\"Stability validation:\", validation)",
    "lines": 142,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "003ce8ce"
  },
  {
    "id": "configuration_migration_mathematical_foundations_6_f5e57630",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass PerformanceAnalyzer:\n    \"\"\"Analyze performance preservation during migration.\"\"\"\n\n    @staticmethod\n    def analyze_control_bandwidth(old_gains: List[float], new_gains: List[float], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Analyze control bandwidth preservation.\"\"\"\n\n        if controller_type == 'classical_smc':\n            if len(old_gains) >= 4 and len(new_gains) >= 4:\n                old_bandwidth = min(old_gains[2], old_gains[3])  # min(\u03bb1, \u03bb2)\n                new_bandwidth = min(new_gains[2], new_gains[3])\n\n                bandwidth_ratio = new_bandwidth / old_bandwidth\n\n                return {\n                    'old_bandwidth': old_bandwidth,\n                    'new_bandwidth': new_bandwidth,\n                    'bandwidth_ratio': bandwidth_ratio,\n                    'performance_preserved': 0.8 <= bandwidth_ratio <= 1.2  # \u00b120% tolerance\n                }\n\n        elif controller_type == 'adaptive_smc':\n            if len(old_gains) >= 4 and len(new_gains) >= 4:\n                old_adaptation_rate = old_gains[4] if len(old_gains) > 4 else 1.0\n                new_adaptation_rate = new_gains[4] if len(new_gains) > 4 else 1.0\n\n                adaptation_ratio = new_adaptation_rate / old_adaptation_rate\n\n                return {\n                    'old_adaptation_rate': old_adaptation_rate,\n                    'new_adaptation_rate': new_adaptation_rate,\n                    'adaptation_ratio': adaptation_ratio,\n                    'performance_preserved': 0.5 <= adaptation_ratio <= 2.0  # \u00b1100% tolerance\n                }\n\n        return {'analysis': 'not_applicable', 'controller_type': controller_type}\n\n    @staticmethod\n    def estimate_settling_time_change(old_config: Dict[str, Any], new_config: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Estimate settling time changes after migration.\"\"\"\n\n        old_gains = old_config.get('gains', [])\n        new_gains = new_config.get('gains', [])\n\n        if len(old_gains) >= 4 and len(new_gains) >= 4:\n            # Simplified settling time estimate based on surface coefficients\n            old_settling = 4.0 / min(old_gains[2], old_gains[3])  # 4/min(\u03bb1, \u03bb2)\n            new_settling = 4.0 / min(new_gains[2], new_gains[3])\n\n            settling_ratio = new_settling / old_settling\n\n            return {\n                'old_settling_time': old_settling,\n                'new_settling_time': new_settling,\n                'settling_ratio': settling_ratio,\n                'performance_change': 'improved' if settling_ratio < 1.0 else 'degraded' if settling_ratio > 1.1 else 'maintained'\n            }\n\n        return {'analysis': 'insufficient_data'}\n\n# Performance analysis example\nold_config = {'gains': [20, 15, 12, 8, 35]}\nnew_config = {'gains': [20, 15, 12, 8, 35, 5]}\n\nbandwidth_analysis = PerformanceAnalyzer.analyze_control_bandwidth(\n    old_config['gains'], new_config['gains'], 'classical_smc'\n)\nprint(\"Bandwidth analysis:\", bandwidth_analysis)\n\nsettling_analysis = PerformanceAnalyzer.estimate_settling_time_change(old_config, new_config)\nprint(\"Settling time analysis:\", settling_analysis)",
    "lines": 74,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5e57630"
  },
  {
    "id": "configuration_migration_mathematical_foundations_7_c21a52ee",
    "file": "docs\\factory\\configuration_migration_mathematical_foundations.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass MigrationValidationSuite:\n    \"\"\"Comprehensive test suite for migration validation.\"\"\"\n\n    def __init__(self):\n        self.test_results = []\n\n    def run_full_validation(self, old_config: Dict[str, Any], new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Run comprehensive migration validation.\"\"\"\n\n        results = {\n            'controller_type': controller_type,\n            'migration_successful': True,\n            'tests': {},\n            'warnings': [],\n            'errors': []\n        }\n\n        # Test 1: Parameter count validation\n        results['tests']['parameter_count'] = self.test_parameter_count(old_config, new_config, controller_type)\n\n        # Test 2: Stability preservation\n        results['tests']['stability'] = self.test_stability_preservation(new_config, controller_type)\n\n        # Test 3: Physical realizability\n        results['tests']['physical_realizability'] = self.test_physical_realizability(new_config, controller_type)\n\n        # Test 4: Performance preservation\n        results['tests']['performance'] = self.test_performance_preservation(old_config, new_config, controller_type)\n\n        # Test 5: Numerical stability\n        results['tests']['numerical_stability'] = self.test_numerical_stability(new_config, controller_type)\n\n        # Aggregate results\n        failed_tests = [name for name, result in results['tests'].items() if not result.get('passed', False)]\n        results['migration_successful'] = len(failed_tests) == 0\n\n        if failed_tests:\n            results['errors'].extend([f\"Failed test: {test}\" for test in failed_tests])\n\n        return results\n\n    def test_parameter_count(self, old_config: Dict[str, Any], new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Test parameter count migration.\"\"\"\n\n        expected_counts = {\n            'classical_smc': 6,\n            'adaptive_smc': 5,\n            'sta_smc': 6,\n            'hybrid_adaptive_sta_smc': 4\n        }\n\n        new_gains = new_config.get('gains', [])\n        expected_count = expected_counts.get(controller_type, 0)\n\n        passed = len(new_gains) == expected_count\n\n        return {\n            'passed': passed,\n            'expected_count': expected_count,\n            'actual_count': len(new_gains),\n            'gains': new_gains\n        }\n\n    def test_stability_preservation(self, new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Test stability preservation.\"\"\"\n\n        gains = new_config.get('gains', [])\n\n        if controller_type == 'classical_smc':\n            return StabilityValidator.validate_classical_smc_stability(gains)\n        elif controller_type == 'adaptive_smc':\n            adaptation_params = {\n                'leak_rate': new_config.get('leak_rate', 0.01),\n                'K_min': new_config.get('K_min', 0.1),\n                'K_max': new_config.get('K_max', 100.0)\n            }\n            return StabilityValidator.validate_adaptive_smc_convergence(gains, adaptation_params)\n        elif controller_type == 'sta_smc':\n            algorithm_params = {\n                'power_exponent': new_config.get('power_exponent', 0.5)\n            }\n            return StabilityValidator.validate_sta_smc_finite_time_convergence(gains, algorithm_params)\n\n        return {'passed': True, 'reason': 'No stability test for this controller type'}\n\n    def test_physical_realizability(self, new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Test physical realizability of parameters.\"\"\"\n\n        gains = new_config.get('gains', [])\n        max_force = new_config.get('max_force', 150.0)\n        dt = new_config.get('dt', 0.001)\n\n        issues = []\n\n        # Check gain magnitudes\n        if any(g > 1000 for g in gains):\n            issues.append(\"Extremely high gains may be unrealistic\")\n\n        # Check sampling time\n        if dt < 1e-4:  # Less than 0.1ms\n            issues.append(f\"Very fast sampling time dt={dt}s may be unrealistic\")\n        elif dt > 0.1:  # More than 100ms\n            issues.append(f\"Slow sampling time dt={dt}s may degrade performance\")\n\n        # Check actuator limits\n        if max_force > 1000:  # More than 1kN\n            issues.append(f\"High force limit {max_force}N may be unrealistic\")\n        elif max_force < 1:  # Less than 1N\n            issues.append(f\"Low force limit {max_force}N may be insufficient\")\n\n        return {\n            'passed': len(issues) == 0,\n            'issues': issues,\n            'parameters_checked': ['gains', 'max_force', 'dt']\n        }\n\n    def test_performance_preservation(self, old_config: Dict[str, Any], new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Test performance preservation.\"\"\"\n\n        bandwidth_analysis = PerformanceAnalyzer.analyze_control_bandwidth(\n            old_config.get('gains', []),\n            new_config.get('gains', []),\n            controller_type\n        )\n\n        settling_analysis = PerformanceAnalyzer.estimate_settling_time_change(old_config, new_config)\n\n        # Performance is preserved if bandwidth and settling time are reasonable\n        bandwidth_ok = bandwidth_analysis.get('performance_preserved', True)\n        settling_ok = settling_analysis.get('performance_change') in ['improved', 'maintained']\n\n        return {\n            'passed': bandwidth_ok and settling_ok,\n            'bandwidth_analysis': bandwidth_analysis,\n            'settling_analysis': settling_analysis\n        }\n\n    def test_numerical_stability(self, new_config: Dict[str, Any], controller_type: str) -> Dict[str, Any]:\n        \"\"\"Test numerical stability of parameters.\"\"\"\n\n        gains = new_config.get('gains', [])\n        dt = new_config.get('dt', 0.001)\n\n        issues = []\n\n        # Check condition numbers and numerical issues\n        if controller_type in ['classical_smc', 'adaptive_smc', 'sta_smc']:\n            if len(gains) >= 4:\n                k1, k2, lam1, lam2 = gains[:4]\n\n                # Check gain ratios for numerical stability\n                if lam1/k1 > 100 or lam2/k2 > 100:\n                    issues.append(\"High \u03bb/k ratios may cause numerical instability\")\n\n                if k1/k2 > 10 or k2/k1 > 10:\n                    issues.append(\"Large k1/k2 ratio may indicate unbalanced design\")\n\n        # Check discrete-time stability\n        if controller_type in ['adaptive_smc', 'sta_smc']:\n            max_gain = max(gains) if gains else 0\n            nyquist_limit = 1.0 / (2 * dt)\n            if max_gain > nyquist_limit / 10:  # Rule of thumb\n                issues.append(f\"High gains relative to sampling rate may cause instability\")\n\n        return {\n            'passed': len(issues) == 0,\n            'issues': issues,\n            'sampling_time': dt,\n            'stability_margins': 'acceptable' if len(issues) == 0 else 'marginal'\n        }\n\n# Full validation example\nmigration_suite = MigrationValidationSuite()\n\nold_config = {\n    'gains': [20, 15, 12, 8, 35],\n    'K_switching': 5.0,\n    'switch_function': 'sign'\n}\n\nnew_config = {\n    'gains': [20, 15, 12, 8, 35, 5.0],\n    'switch_method': 'sign',\n    'boundary_layer': 0.02,\n    'max_force': 150.0,\n    'dt': 0.001\n}\n\nvalidation_results = migration_suite.run_full_validation(old_config, new_config, 'classical_smc')\nprint(\"Migration validation results:\")\nfor test_name, result in validation_results['tests'].items():\n    status = \"\u2705 PASS\" if result.get('passed', False) else \"\u274c FAIL\"\n    print(f\"  {test_name}: {status}\")\n\nif validation_results['migration_successful']:\n    print(\"\u2705 Migration validation SUCCESSFUL\")\nelse:\n    print(\"\u274c Migration validation FAILED\")\n    for error in validation_results['errors']:\n        print(f\"  - {error}\")",
    "lines": 203,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c21a52ee"
  },
  {
    "id": "configuration_reference_1_ad4a5b97",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe factory operations\n_factory_lock = threading.RLock()\n\ndef create_controller(controller_type: str, config: Optional[Any] = None,\n                     gains: Optional[Union[list, np.ndarray]] = None) -> Any:\n    with _factory_lock:\n        # Thread-safe controller creation\n        ...",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad4a5b97"
  },
  {
    "id": "configuration_reference_2_d66c6b2b",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [8.0, 6.0, 4.0, 3.0, 15.0, 2.0],  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d66c6b2b"
  },
  {
    "id": "configuration_reference_3_5275db44",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 3,
    "code": "def _resolve_controller_gains(\n    gains: Optional[Union[List[float], np.ndarray]],\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> List[float]:\n    \"\"\"Resolve controller gains from multiple sources with fallback.\"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5275db44"
  },
  {
    "id": "configuration_reference_4_e466e67b",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(\n    gains: List[float],\n    controller_info: Dict[str, Any]\n) -> None:\n    \"\"\"Validate controller gains for stability and correctness.\"\"\"\n\n    # Length validation\n    expected_count = controller_info['gain_count']\n    if len(gains) != expected_count:\n        raise ValueError(f\"Controller requires {expected_count} gains, got {len(gains)}\")\n\n    # Numerical validation\n    if not all(isinstance(g, (int, float)) and np.isfinite(g) for g in gains):\n        raise ValueError(\"All gains must be finite numbers\")\n\n    # Stability validation (SMC requirement)\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e466e67b"
  },
  {
    "id": "configuration_reference_5_c473ecd8",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 5,
    "code": "# Classical SMC parameters with boundary layer chattering reduction\nconfig_params = {\n    'gains': controller_gains,           # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    'max_force': 150.0,                 # Control saturation limit\n    'dt': 0.001,                        # Sampling time\n    'boundary_layer': 0.02,             # Required for chattering reduction\n    'dynamics_model': dynamics_model     # Optional plant model\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c473ecd8"
  },
  {
    "id": "configuration_reference_6_eb5c97b4",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Adaptive SMC with parameter estimation\nconfig_params = {\n    'gains': controller_gains,           # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    'max_force': 150.0,\n    'dt': 0.001,\n    'leak_rate': 0.01,                  # Parameter estimation leak\n    'adapt_rate_limit': 10.0,           # Adaptation rate bounds\n    'K_min': 0.1, 'K_max': 100.0,      # Adaptive gain bounds\n    'K_init': 10.0,                     # Initial adaptive gain\n    'alpha': 0.5,                       # Adaptation law exponent\n    'boundary_layer': 0.01,             # Smooth switching\n    'smooth_switch': True               # Enable smooth switching\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb5c97b4"
  },
  {
    "id": "configuration_reference_7_2778bf25",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Super-Twisting Algorithm (STA) SMC\nconfig_params = {\n    'gains': controller_gains,           # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    'max_force': 150.0,\n    'dt': 0.001,\n    'power_exponent': 0.5,              # STA convergence exponent\n    'regularization': 1e-6,             # Numerical regularization\n    'boundary_layer': 0.01,             # Chattering reduction\n    'switch_method': 'tanh',            # Switching function type\n    'damping_gain': 0.0                 # Additional damping\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2778bf25"
  },
  {
    "id": "configuration_reference_8_3c1654e0",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Hybrid controller requires sub-configurations\nclassical_config = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0, dt=0.001, boundary_layer=0.02\n)\nadaptive_config = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0, dt=0.001\n)\n\nconfig_params = {\n    'hybrid_mode': HybridMode.CLASSICAL_ADAPTIVE,\n    'dt': 0.001,\n    'max_force': 150.0,\n    'classical_config': classical_config,\n    'adaptive_config': adaptive_config,\n    'dynamics_model': dynamics_model\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c1654e0"
  },
  {
    "id": "configuration_reference_9_0fc3409a",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_configuration(controller_type: str, config_params: Dict[str, Any]) -> None:\n    \"\"\"Comprehensive configuration validation.\"\"\"\n\n    # 1. Check required parameters\n    controller_info = _get_controller_info(controller_type)\n    required_params = controller_info['required_params']\n\n    for param in required_params:\n        if param not in config_params:\n            raise ValueError(f\"Missing required parameter: {param}\")\n\n    # 2. Validate gains\n    gains = config_params.get('gains', [])\n    _validate_controller_gains(gains, controller_info)\n\n    # 3. Controller-specific validation\n    if controller_type == 'classical_smc':\n        if config_params.get('boundary_layer', 0) <= 0:\n            raise ValueError(\"boundary_layer must be positive\")\n\n    # 4. Numerical validation\n    for key, value in config_params.items():\n        if key in ['max_force', 'dt', 'boundary_layer']:\n            if not (isinstance(value, (int, float)) and value > 0):\n                raise ValueError(f\"{key} must be positive number\")",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fc3409a"
  },
  {
    "id": "configuration_reference_10_9e90171f",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ntry:\n    # Attempt full configuration\n    controller_config = config_class(**config_params)\nexcept Exception as e:\n    logger.warning(f\"Could not create full config, using minimal config: {e}\")\n\n    # Fallback to minimal configuration\n    fallback_params = {\n        'gains': controller_gains,\n        'max_force': 150.0,\n        'dt': 0.001\n    }\n\n    # Add controller-specific required parameters\n    if controller_type == 'classical_smc':\n        fallback_params['boundary_layer'] = 0.02\n\n    controller_config = config_class(**fallback_params)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9e90171f"
  },
  {
    "id": "configuration_reference_11_97a708f1",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 11,
    "code": "# Graceful handling of missing dependencies\ntry:\n    from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n    CONFIG_CLASSES_AVAILABLE = True\nexcept ImportError:\n    CONFIG_CLASSES_AVAILABLE = False\n    # Use fallback minimal config classes\n    from src.controllers.factory.fallback_configs import ClassicalSMCConfig",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "97a708f1"
  },
  {
    "id": "configuration_reference_12_3aff9854",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller_with_recovery(controller_type: str, config: Any, gains: Any) -> Any:\n    \"\"\"Create controller with automatic error recovery.\"\"\"\n\n    try:\n        return create_controller(controller_type, config, gains)\n    except Exception as primary_error:\n        logger.warning(f\"Primary creation failed: {primary_error}\")\n\n        # Attempt recovery with minimal configuration\n        try:\n            minimal_config = create_minimal_config(controller_type, gains)\n            return create_controller(controller_type, minimal_config, None)\n        except Exception as recovery_error:\n            logger.error(f\"Recovery failed: {recovery_error}\")\n            raise primary_error",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3aff9854"
  },
  {
    "id": "configuration_reference_13_0d57eb5a",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_ALIASES = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n    'hybrid_sta': 'hybrid_adaptive_sta_smc',\n}\n\ndef _canonicalize_controller_type(name: str) -> str:\n    \"\"\"Normalize controller type names for consistency.\"\"\"\n    if not isinstance(name, str):\n        return name\n    key = name.strip().lower().replace('-', '_').replace(' ', '_')\n    return CONTROLLER_ALIASES.get(key, key)",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d57eb5a"
  },
  {
    "id": "configuration_reference_14_72d75c29",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef _create_dynamics_model(config: Any) -> Optional[Any]:\n    \"\"\"Create dynamics model from configuration with fallback handling.\"\"\"\n\n    # Priority order for dynamics model resolution\n    if hasattr(config, 'dynamics_model'):\n        return config.dynamics_model\n    elif hasattr(config, 'physics'):\n        return DIPDynamics(config.physics)\n    elif hasattr(config, 'dip_params'):\n        return DIPDynamics(config.dip_params)\n    return None",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72d75c29"
  },
  {
    "id": "configuration_reference_15_6b1088d2",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 15,
    "code": "# Only add dynamics_model for controllers that support it\nif dynamics_model is not None and controller_type in ['classical_smc', 'sta_smc', 'adaptive_smc', 'mpc_controller']:\n    config_params['dynamics_model'] = dynamics_model",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b1088d2"
  },
  {
    "id": "configuration_reference_16_e244fe56",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 16,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any:\n    \"\"\"\n    Create a controller instance with comprehensive validation and error handling.\n\n    Thread-safe and supports multiple calling patterns for flexibility.\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e244fe56"
  },
  {
    "id": "configuration_reference_17_5316d36c",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 17,
    "code": "# Backwards compatibility wrappers\ndef create_classical_smc_controller(config=None, gains=None) -> Any:\n    return create_controller('classical_smc', config, gains)\n\ndef create_sta_smc_controller(config=None, gains=None) -> Any:\n    return create_controller('sta_smc', config, gains)\n\ndef create_adaptive_smc_controller(config=None, gains=None) -> Any:\n    return create_controller('adaptive_smc', config, gains)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5316d36c"
  },
  {
    "id": "configuration_reference_18_7c49353b",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 18,
    "code": "def list_available_controllers() -> List[str]:\n    \"\"\"Get list of available controller types.\"\"\"\n    return list(CONTROLLER_REGISTRY.keys())\n\ndef get_default_gains(controller_type: str) -> List[float]:\n    \"\"\"Get default gains for a controller type.\"\"\"\n    return CONTROLLER_REGISTRY[controller_type]['default_gains'].copy()",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c49353b"
  },
  {
    "id": "configuration_reference_19_b759a6f5",
    "file": "docs\\factory\\configuration_reference.md",
    "index": 19,
    "code": "# Quality gates enforced by factory\nassert coverage >= 0.95  # 95% test coverage for critical components\nassert thread_safety_tests_pass == True\nassert memory_leak_tests_pass == True\nassert performance_constraints_met == True",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b759a6f5"
  },
  {
    "id": "controller_integration_guide_1_f199cb9c",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass EnterpriseControllerFactory:\n    \"\"\"\n    Enterprise-grade controller factory with comprehensive integration support.\n\n    Features:\n    - Type-safe controller creation\n    - Automatic parameter validation\n    - Plant model integration\n    - PSO optimization support\n    - Thread-safe operations\n    - Comprehensive error handling\n    \"\"\"\n\n    @staticmethod\n    def create_controller(\n        controller_type: str,\n        config: Optional[Any] = None,\n        gains: Optional[GainsArray] = None,\n        **kwargs: Any\n    ) -> ControllerProtocol:\n        \"\"\"\n        Create controller with enhanced integration support.\n\n        Args:\n            controller_type: Type of controller to create\n            config: Configuration object or dictionary\n            gains: Controller gains array\n            **kwargs: Additional parameters for flexibility\n\n        Returns:\n            Configured controller instance\n\n        Raises:\n            ValueError: Invalid controller type or configuration\n            TypeError: Invalid parameter types\n        \"\"\"",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f199cb9c"
  },
  {
    "id": "controller_integration_guide_2_9cbd9e6c",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef integrate_classical_smc(\n    gains: List[float],\n    plant_config: Any,\n    optimization_bounds: Optional[Tuple[List[float], List[float]]] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Complete integration pattern for Classical SMC.\n\n    Parameters:\n    - gains: [k1, k2, \u03bb1, \u03bb2, K, kd] - 6 element array\n    - Stability: All gains must be positive\n    - Chattering: boundary_layer parameter required\n    \"\"\"\n\n    # 1. Parameter validation\n    if len(gains) != 6:\n        raise ValueError(\"Classical SMC requires exactly 6 gains\")\n\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All Classical SMC gains must be positive\")\n\n    # 2. Configuration construction\n    config = {\n        'gains': gains,\n        'max_force': 150.0,\n        'boundary_layer': 0.02,  # Chattering reduction\n        'dt': 0.001,\n        'dynamics_model': create_dynamics_model(plant_config)\n    }\n\n    # 3. Controller creation\n    controller = create_controller('classical_smc', config)\n\n    # 4. Integration validation\n    validate_controller_plant_compatibility(controller, plant_config)\n\n    return {\n        'controller': controller,\n        'config': config,\n        'gain_bounds': optimization_bounds or get_default_bounds('classical_smc'),\n        'integration_status': 'success'\n    }\n\n# Example usage:\nresult = integrate_classical_smc(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    plant_config=simplified_dip_config,\n    optimization_bounds=(\n        [5.0, 5.0, 3.0, 3.0, 10.0, 1.0],    # Lower bounds\n        [50.0, 40.0, 30.0, 25.0, 80.0, 15.0] # Upper bounds\n    )\n)",
    "lines": 55,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9cbd9e6c"
  },
  {
    "id": "controller_integration_guide_3_32e5fa81",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef integrate_adaptive_smc(\n    gains: List[float],\n    plant_config: Any,\n    adaptation_params: Optional[Dict[str, float]] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Complete integration pattern for Adaptive SMC.\n\n    Parameters:\n    - gains: [k1, k2, \u03bb1, \u03bb2, \u03b3] - 5 element array\n    - Critical: \u03b3 (gamma) is adaptation rate in gains[4]\n    - Adaptation: Additional parameters for online estimation\n    \"\"\"\n\n    # 1. Parameter validation\n    if len(gains) != 5:\n        raise ValueError(\"Adaptive SMC requires exactly 5 gains\")\n\n    # Surface gains must be positive\n    if any(g <= 0 for g in gains[:4]):\n        raise ValueError(\"Surface gains (k1, k2, \u03bb1, \u03bb2) must be positive\")\n\n    # Adaptation rate validation\n    gamma = gains[4]\n    if gamma <= 0 or gamma > 10.0:\n        raise ValueError(f\"Adaptation rate \u03b3={gamma} must be in (0, 10]\")\n\n    # 2. Adaptation parameters\n    default_adaptation = {\n        'leak_rate': 0.01,\n        'adapt_rate_limit': 10.0,\n        'K_min': 0.1,\n        'K_max': 100.0,\n        'K_init': 10.0,\n        'alpha': 0.5,\n        'dead_zone': 0.05,\n        'smooth_switch': True\n    }\n\n    if adaptation_params:\n        default_adaptation.update(adaptation_params)\n\n    # 3. Configuration construction\n    config = {\n        'gains': gains,\n        'max_force': 150.0,\n        'dt': 0.001,\n        'boundary_layer': 0.01,\n        **default_adaptation,\n        'dynamics_model': create_dynamics_model(plant_config)\n    }\n\n    # 4. Controller creation\n    controller = create_controller('adaptive_smc', config)\n\n    return {\n        'controller': controller,\n        'config': config,\n        'adaptation_params': default_adaptation,\n        'gamma_value': gamma,\n        'integration_status': 'success'\n    }\n\n# Example usage:\nresult = integrate_adaptive_smc(\n    gains=[25.0, 18.0, 15.0, 12.0, 3.5],\n    plant_config=full_dip_config,\n    adaptation_params={\n        'leak_rate': 0.02,     # Faster parameter forgetting\n        'adapt_rate_limit': 15.0, # Higher adaptation rate\n        'alpha': 0.7           # Different adaptation law exponent\n    }\n)",
    "lines": 76,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32e5fa81"
  },
  {
    "id": "controller_integration_guide_4_f1d8bdb7",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef integrate_super_twisting_smc(\n    gains: List[float],\n    plant_config: Any,\n    sta_params: Optional[Dict[str, float]] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Complete integration pattern for Super-Twisting SMC.\n\n    Parameters:\n    - gains: [K1, K2, k1, k2, \u03bb1, \u03bb2] - 6 element array\n    - STA: K1, K2 are super-twisting algorithm gains\n    - Convergence: Finite-time convergence properties\n    \"\"\"\n\n    # 1. Parameter validation\n    if len(gains) != 6:\n        raise ValueError(\"Super-Twisting SMC requires exactly 6 gains\")\n\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All Super-Twisting SMC gains must be positive\")\n\n    # STA-specific validation\n    K1, K2 = gains[0], gains[1]\n    if K1 <= K2:\n        logger.warning(f\"STA recommendation: K1={K1} should be > K2={K2}\")\n\n    # 2. STA-specific parameters\n    default_sta_params = {\n        'power_exponent': 0.5,      # \u03b1 = 0.5 for STA\n        'regularization': 1e-6,     # Numerical stability\n        'boundary_layer': 0.01,     # Built-in chattering reduction\n        'switch_method': 'tanh',    # Smooth switching function\n        'damping_gain': 0.0         # Additional damping if needed\n    }\n\n    if sta_params:\n        default_sta_params.update(sta_params)\n\n    # 3. Configuration construction\n    config = {\n        'gains': gains,\n        'max_force': 150.0,\n        'dt': 0.001,\n        **default_sta_params,\n        'dynamics_model': create_dynamics_model(plant_config)\n    }\n\n    # 4. Controller creation\n    controller = create_controller('sta_smc', config)\n\n    return {\n        'controller': controller,\n        'config': config,\n        'sta_params': default_sta_params,\n        'K1_K2_ratio': K1 / K2,\n        'integration_status': 'success'\n    }\n\n# Example usage:\nresult = integrate_super_twisting_smc(\n    gains=[35.0, 20.0, 25.0, 18.0, 12.0, 8.0],\n    plant_config=full_nonlinear_config,\n    sta_params={\n        'power_exponent': 0.6,  # Slightly different convergence rate\n        'switch_method': 'sigmoid', # Alternative switching function\n        'damping_gain': 1.0     # Additional damping for robustness\n    }\n)",
    "lines": 71,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1d8bdb7"
  },
  {
    "id": "controller_integration_guide_5_23a243ef",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 5,
    "code": "def integrate_hybrid_smc(\n    surface_gains: List[float],\n    plant_config: Any,\n    classical_gains: Optional[List[float]] = None,\n    adaptive_gains: Optional[List[float]] = None,\n    hybrid_mode: str = 'CLASSICAL_ADAPTIVE'\n) -> Dict[str, Any]:\n    \"\"\"\n    Complete integration pattern for Hybrid Adaptive-STA SMC.\n\n    Parameters:\n    - surface_gains: [k1, k2, \u03bb1, \u03bb2] - 4 element array (common sliding surface)\n    - classical_gains: 6-element array for classical sub-controller\n    - adaptive_gains: 5-element array for adaptive sub-controller\n    - hybrid_mode: Switching strategy between controllers\n    \"\"\"\n\n    # 1. Surface gains validation\n    if len(surface_gains) != 4:\n        raise ValueError(\"Hybrid SMC requires exactly 4 surface gains\")\n\n    if any(g <= 0 for g in surface_gains):\n        raise ValueError(\"All surface gains must be positive\")\n\n    # 2. Sub-controller configuration\n    if classical_gains is None:\n        classical_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n\n    if adaptive_gains is None:\n        adaptive_gains = [25.0, 18.0, 15.0, 12.0, 3.5]\n\n    # 3. Create sub-configurations\n    classical_config = ClassicalSMCConfig(\n        gains=classical_gains,\n        max_force=150.0,\n        dt=0.001,\n        boundary_layer=0.02\n    )\n\n    adaptive_config = AdaptiveSMCConfig(\n        gains=adaptive_gains,\n        max_force=150.0,\n        dt=0.001,\n        leak_rate=0.01,\n        adapt_rate_limit=10.0,\n        K_min=0.1,\n        K_max=100.0,\n        K_init=10.0,\n        alpha=0.5\n    )\n\n    # 4. Hybrid mode configuration\n    from src.controllers.smc.algorithms.hybrid.config import HybridMode\n    mode_enum = HybridMode(hybrid_mode)\n\n    # 5. Main configuration\n    config = {\n        'gains': surface_gains,\n        'hybrid_mode': mode_enum,\n        'dt': 0.001,\n        'max_force': 150.0,\n        'classical_config': classical_config,\n        'adaptive_config': adaptive_config,\n        'k1_init': 5.0,\n        'k2_init': 3.0,\n        'gamma1': 0.5,\n        'gamma2': 0.3,\n        'dynamics_model': create_dynamics_model(plant_config)\n    }\n\n    # 6. Controller creation\n    controller = create_controller('hybrid_adaptive_sta_smc', config)\n\n    return {\n        'controller': controller,\n        'config': config,\n        'classical_config': classical_config,\n        'adaptive_config': adaptive_config,\n        'hybrid_mode': mode_enum,\n        'integration_status': 'success'\n    }\n\n# Example usage:\nresult = integrate_hybrid_smc(\n    surface_gains=[15.0, 12.0, 10.0, 8.0],\n    plant_config=complex_dip_config,\n    classical_gains=[22.0, 16.0, 14.0, 10.0, 40.0, 6.0],\n    adaptive_gains=[28.0, 20.0, 18.0, 14.0, 4.0],\n    hybrid_mode='CLASSICAL_ADAPTIVE'\n)",
    "lines": 90,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23a243ef"
  },
  {
    "id": "controller_integration_guide_6_8b186f25",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 6,
    "code": "def create_and_validate_dynamics_model(\n    plant_config: Any,\n    controller_type: str\n) -> Tuple[Any, Dict[str, Any]]:\n    \"\"\"\n    Create and validate plant dynamics model for controller integration.\n\n    Returns:\n        Tuple of (dynamics_model, validation_results)\n    \"\"\"\n\n    # 1. Create dynamics model\n    try:\n        if hasattr(plant_config, 'dynamics_model'):\n            dynamics_model = plant_config.dynamics_model\n        elif hasattr(plant_config, 'physics'):\n            dynamics_model = DIPDynamics(plant_config.physics)\n        elif hasattr(plant_config, 'dip_params'):\n            dynamics_model = DIPDynamics(plant_config.dip_params)\n        else:\n            from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n            dynamics_model = SimplifiedDIPDynamics(plant_config)\n\n    except Exception as e:\n        logger.warning(f\"Could not create specific dynamics model: {e}\")\n        # Fallback to generic dynamics\n        dynamics_model = DIPDynamics()\n\n    # 2. Validate dynamics-controller compatibility\n    validation_results = {\n        'model_type': type(dynamics_model).__name__,\n        'state_dimension': 6,  # DIP standard state dimension\n        'control_dimension': 1,  # Single control input\n        'supports_linearization': hasattr(dynamics_model, 'linearize'),\n        'supports_jacobian': hasattr(dynamics_model, 'compute_jacobian'),\n        'integration_compatible': True\n    }\n\n    # 3. Test basic functionality\n    try:\n        test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n        test_control = np.array([1.0])\n\n        result = dynamics_model.compute_dynamics(test_state, test_control)\n        validation_results['compute_dynamics_test'] = hasattr(result, 'state_derivative')\n        validation_results['derivative_shape'] = result.state_derivative.shape if hasattr(result, 'state_derivative') else None\n\n    except Exception as e:\n        validation_results['compute_dynamics_test'] = False\n        validation_results['test_error'] = str(e)\n\n    return dynamics_model, validation_results\n\ndef validate_controller_plant_compatibility(\n    controller: Any,\n    plant_config: Any\n) -> Dict[str, bool]:\n    \"\"\"Validate that controller and plant are compatible.\"\"\"\n\n    compatibility = {\n        'state_dimensions': True,  # Both use 6-DOF DIP state\n        'control_dimensions': True,  # Both use single control input\n        'sampling_time': True,     # Compatible sampling rates\n        'numerical_stability': True  # No obvious numerical issues\n    }\n\n    try:\n        # Test control computation\n        test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n        control_output = controller.compute_control(test_state, (), {})\n\n        compatibility['control_computation'] = True\n        compatibility['control_bounds'] = np.abs(control_output.u) < 1000.0  # Reasonable control\n\n    except Exception as e:\n        compatibility['control_computation'] = False\n        compatibility['error'] = str(e)\n\n    return compatibility",
    "lines": 79,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b186f25"
  },
  {
    "id": "controller_integration_guide_7_04376775",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 7,
    "code": "# Pattern 1: Simplified DIP Configuration\ndef create_simplified_plant_config():\n    \"\"\"Create simplified DIP plant configuration for rapid prototyping.\"\"\"\n    from src.plant.configurations import ConfigurationFactory\n\n    config = ConfigurationFactory.create_default_config(\"simplified\")\n    return {\n        'dynamics_type': 'simplified',\n        'config': config,\n        'linearization_point': np.zeros(6),\n        'use_cases': ['controller_tuning', 'pso_optimization', 'rapid_testing']\n    }\n\n# Pattern 2: Full Nonlinear DIP Configuration\ndef create_full_nonlinear_plant_config():\n    \"\"\"Create full nonlinear DIP configuration for high-fidelity simulation.\"\"\"\n    from src.plant.configurations import ConfigurationFactory\n\n    config = ConfigurationFactory.create_default_config(\"full\")\n    return {\n        'dynamics_type': 'full_nonlinear',\n        'config': config,\n        'friction_models': ['viscous', 'coulomb'],\n        'disturbance_rejection': True,\n        'use_cases': ['performance_validation', 'robustness_testing', 'real_system_prep']\n    }\n\n# Pattern 3: HIL-Ready Configuration\ndef create_hil_plant_config():\n    \"\"\"Create HIL-compatible plant configuration.\"\"\"\n    config = create_full_nonlinear_plant_config()\n    config.update({\n        'real_time_constraints': True,\n        'communication_interface': 'tcp_socket',\n        'sampling_rate': 1000,  # 1 kHz for real-time control\n        'latency_compensation': True,\n        'safety_monitors': ['position_limits', 'velocity_limits', 'control_limits']\n    })\n    return config",
    "lines": 39,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04376775"
  },
  {
    "id": "controller_integration_guide_8_6c43bfc9",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 8,
    "code": "class PSOControllerWrapper:\n    \"\"\"\n    Enhanced wrapper for PSO optimization integration.\n\n    Features:\n    - Simplified control interface for PSO fitness functions\n    - Automatic gain validation\n    - Performance monitoring\n    - Thread-safe operation\n    \"\"\"\n\n    def __init__(\n        self,\n        controller: ControllerProtocol,\n        controller_type: str,\n        validation_enabled: bool = True\n    ):\n        self.controller = controller\n        self.controller_type = controller_type\n        self.validation_enabled = validation_enabled\n        self.n_gains = self._determine_gain_count()\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n        # Performance monitoring\n        self.call_count = 0\n        self.total_compute_time = 0.0\n        self.max_control_magnitude = 0.0\n\n    def _determine_gain_count(self) -> int:\n        \"\"\"Determine expected gain count for controller type.\"\"\"\n        gain_counts = {\n            'classical_smc': 6,\n            'adaptive_smc': 5,\n            'sta_smc': 6,\n            'hybrid_adaptive_sta_smc': 4\n        }\n        return gain_counts.get(self.controller_type, 6)\n\n    def compute_control(\n        self,\n        state: StateVector,\n        return_metadata: bool = False\n    ) -> Union[NDArray[np.float64], Tuple[NDArray[np.float64], Dict[str, Any]]]:\n        \"\"\"\n        PSO-optimized control computation with optional metadata.\n\n        Args:\n            state: System state vector [\u03b81, \u03b82, x, \u03b8\u03071, \u03b8\u03072, \u1e8b]\n            return_metadata: Whether to return computation metadata\n\n        Returns:\n            Control output as numpy array, optionally with metadata\n        \"\"\"\n        import time\n\n        start_time = time.time()\n\n        try:\n            # Validate input state\n            if len(state) != 6:\n                raise ValueError(f\"Expected 6-DOF state, got {len(state)}\")\n\n            # Compute control using full controller interface\n            result = self.controller.compute_control(state, (), {})\n\n            # Extract control value\n            if hasattr(result, 'u'):\n                control_value = result.u\n            elif isinstance(result, dict) and 'u' in result:\n                control_value = result['u']\n            else:\n                control_value = result\n\n            # Convert to numpy array\n            if isinstance(control_value, (int, float)):\n                control_array = np.array([float(control_value)])\n            elif isinstance(control_value, np.ndarray):\n                control_array = control_value.flatten()\n            else:\n                control_array = np.array([float(control_value)])\n\n            # Apply safety saturation\n            control_array = np.clip(control_array, -self.max_force, self.max_force)\n\n            # Update performance metrics\n            compute_time = time.time() - start_time\n            self.call_count += 1\n            self.total_compute_time += compute_time\n            self.max_control_magnitude = max(self.max_control_magnitude, np.abs(control_array[0]))\n\n            if return_metadata:\n                metadata = {\n                    'compute_time': compute_time,\n                    'call_count': self.call_count,\n                    'avg_compute_time': self.total_compute_time / self.call_count,\n                    'max_control_magnitude': self.max_control_magnitude,\n                    'saturation_applied': np.abs(control_value) > self.max_force\n                }\n                return control_array, metadata\n            else:\n                return control_array\n\n        except Exception as e:\n            logger.error(f\"Control computation failed: {e}\")\n            # Return safe zero control\n            if return_metadata:\n                return np.array([0.0]), {'error': str(e)}\n            else:\n                return np.array([0.0])\n\n    def validate_gains(self, gains: GainsArray) -> bool:\n        \"\"\"Validate gains for PSO optimization.\"\"\"\n        if not self.validation_enabled:\n            return True\n\n        try:\n            gains_array = np.asarray(gains)\n\n            # Check length\n            if len(gains_array) != self.n_gains:\n                return False\n\n            # Check for finite positive values\n            if not np.all(np.isfinite(gains_array)):\n                return False\n\n            if not np.all(gains_array > 0):\n                return False\n\n            # Controller-specific validation\n            if self.controller_type == 'adaptive_smc':\n                gamma = gains_array[4]\n                if gamma > 10.0 or gamma < 0.01:\n                    return False\n\n            return True\n\n        except Exception:\n            return False\n\n    def get_performance_summary(self) -> Dict[str, Any]:\n        \"\"\"Get performance summary for optimization analysis.\"\"\"\n        return {\n            'total_calls': self.call_count,\n            'total_compute_time': self.total_compute_time,\n            'avg_compute_time': self.total_compute_time / max(1, self.call_count),\n            'max_control_magnitude': self.max_control_magnitude,\n            'real_time_compatible': self.total_compute_time / max(1, self.call_count) < 0.001\n        }",
    "lines": 149,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c43bfc9"
  },
  {
    "id": "controller_integration_guide_9_dab054a5",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_pso_optimized_controller(\n    controller_type: str,\n    gains: GainsArray,\n    plant_config: Any,\n    pso_options: Optional[Dict[str, Any]] = None\n) -> PSOControllerWrapper:\n    \"\"\"\n    Create PSO-optimized controller with comprehensive integration.\n\n    Args:\n        controller_type: Type of SMC controller\n        gains: Controller gains for optimization\n        plant_config: Plant configuration\n        pso_options: PSO-specific options\n\n    Returns:\n        PSO-wrapped controller ready for optimization\n    \"\"\"\n\n    # Default PSO options\n    default_pso_options = {\n        'validation_enabled': True,\n        'performance_monitoring': True,\n        'safety_limits': True,\n        'real_time_constraints': True\n    }\n\n    if pso_options:\n        default_pso_options.update(pso_options)\n\n    # Create controller using factory\n    try:\n        controller = create_controller(\n            controller_type=controller_type,\n            config=plant_config,\n            gains=gains\n        )\n    except Exception as e:\n        logger.error(f\"Failed to create controller for PSO: {e}\")\n        raise\n\n    # Wrap for PSO optimization\n    wrapper = PSOControllerWrapper(\n        controller=controller,\n        controller_type=controller_type,\n        validation_enabled=default_pso_options['validation_enabled']\n    )\n\n    # Add PSO-required attributes\n    wrapper.n_gains = len(gains)\n    wrapper.controller_type = controller_type\n\n    return wrapper\n\ndef get_pso_optimization_bounds(controller_type: str) -> Tuple[List[float], List[float]]:\n    \"\"\"Get PSO optimization bounds for controller type.\"\"\"\n\n    bounds_map = {\n        'classical_smc': {\n            'lower': [5.0, 5.0, 3.0, 3.0, 10.0, 1.0],\n            'upper': [50.0, 40.0, 30.0, 25.0, 80.0, 15.0]\n        },\n        'adaptive_smc': {\n            'lower': [5.0, 5.0, 3.0, 3.0, 0.5],\n            'upper': [50.0, 40.0, 30.0, 25.0, 8.0]\n        },\n        'sta_smc': {\n            'lower': [10.0, 8.0, 5.0, 5.0, 3.0, 3.0],\n            'upper': [80.0, 60.0, 50.0, 40.0, 30.0, 25.0]\n        },\n        'hybrid_adaptive_sta_smc': {\n            'lower': [5.0, 5.0, 3.0, 3.0],\n            'upper': [40.0, 35.0, 25.0, 20.0]\n        }\n    }\n\n    bounds = bounds_map.get(controller_type, {\n        'lower': [0.1] * 6,\n        'upper': [50.0] * 6\n    })\n\n    return bounds['lower'], bounds['upper']",
    "lines": 85,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dab054a5"
  },
  {
    "id": "controller_integration_guide_10_f15dff16",
    "file": "docs\\factory\\controller_integration_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerIntegrationValidator:\n    \"\"\"Comprehensive validation of controller-factory-plant integration.\"\"\"\n\n    def __init__(self, plant_config: Any):\n        self.plant_config = plant_config\n        self.test_states = self._generate_test_states()\n\n    def _generate_test_states(self) -> Dict[str, StateVector]:\n        \"\"\"Generate comprehensive test states for validation.\"\"\"\n        return {\n            'equilibrium': np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n            'small_disturbance': np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0]),\n            'large_angles': np.array([0.5, 0.8, 0.6, 0.2, 0.1, 0.15]),\n            'high_velocity': np.array([0.1, 0.1, 0.1, 2.0, 1.5, 1.2]),\n            'extreme_state': np.array([1.0, 1.2, 0.9, 3.0, 2.5, 2.0])\n        }\n\n    def validate_controller_integration(\n        self,\n        controller_type: str,\n        gains: GainsArray\n    ) -> Dict[str, Any]:\n        \"\"\"Comprehensive integration validation.\"\"\"\n\n        results = {\n            'controller_type': controller_type,\n            'gains': gains,\n            'creation_success': False,\n            'control_computation_success': False,\n            'stability_analysis': {},\n            'performance_metrics': {},\n            'integration_score': 0.0\n        }\n\n        try:\n            # 1. Controller creation test\n            controller = create_controller(controller_type, self.plant_config, gains)\n            results['creation_success'] = True\n\n            # 2. Control computation test\n            control_results = {}\n            for state_name, state in self.test_states.items():\n                try:\n                    control = controller.compute_control(state, (), {})\n                    control_results[state_name] = {\n                        'success': True,\n                        'control_magnitude': np.abs(control.u) if hasattr(control, 'u') else np.abs(control),\n                        'within_bounds': np.abs(control.u if hasattr(control, 'u') else control) <= 200.0\n                    }\n                except Exception as e:\n                    control_results[state_name] = {\n                        'success': False,\n                        'error': str(e)\n                    }\n\n            results['control_computation_success'] = all(\n                result['success'] for result in control_results.values()\n            )\n            results['control_results'] = control_results\n\n            # 3. PSO wrapper test\n            try:\n                pso_wrapper = create_pso_optimized_controller(\n                    controller_type, gains, self.plant_config\n                )\n\n                pso_test_results = {}\n                for state_name, state in self.test_states.items():\n                    control_array = pso_wrapper.compute_control(state)\n                    pso_test_results[state_name] = {\n                        'control_shape': control_array.shape,\n                        'control_value': control_array[0],\n                        'within_saturation': np.abs(control_array[0]) <= pso_wrapper.max_force\n                    }\n\n                results['pso_integration_success'] = True\n                results['pso_test_results'] = pso_test_results\n\n            except Exception as e:\n                results['pso_integration_success'] = False\n                results['pso_error'] = str(e)\n\n            # 4. Calculate integration score\n            score = 0.0\n            if results['creation_success']:\n                score += 25.0\n            if results['control_computation_success']:\n                score += 25.0\n            if results['pso_integration_success']:\n                score += 25.0\n\n            # Additional scoring based on control quality\n            successful_controls = sum(\n                1 for result in control_results.values() if result['success']\n            )\n            score += (successful_controls / len(control_results)) * 25.0\n\n            results['integration_score'] = score\n\n        except Exception as e:\n            results['creation_error'] = str(e)\n\n        return results\n\n    def run_full_integration_suite(\n        self,\n        controller_configs: List[Tuple[str, GainsArray]]\n    ) -> Dict[str, Any]:\n        \"\"\"Run full integration test suite for multiple controllers.\"\"\"\n\n        suite_results = {\n            'test_timestamp': time.time(),\n            'plant_config_type': type(self.plant_config).__name__,\n            'controller_results': {},\n            'summary': {}\n        }\n\n        total_score = 0.0\n        successful_integrations = 0\n\n        for controller_type, gains in controller_configs:\n            result = self.validate_controller_integration(controller_type, gains)\n            suite_results['controller_results'][controller_type] = result\n\n            total_score += result['integration_score']\n            if result['integration_score'] >= 75.0:  # 75% threshold for success\n                successful_integrations += 1\n\n        suite_results['summary'] = {\n            'total_controllers_tested': len(controller_configs),\n            'successful_integrations': successful_integrations,\n            'success_rate': successful_integrations / len(controller_configs),\n            'average_integration_score': total_score / len(controller_configs),\n            'overall_status': 'PASS' if successful_integrations >= len(controller_configs) * 0.8 else 'FAIL'\n        }\n\n        return suite_results\n\n# Example usage:\nvalidator = ControllerIntegrationValidator(simplified_plant_config)\n\ntest_configs = [\n    ('classical_smc', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]),\n    ('adaptive_smc', [25.0, 18.0, 15.0, 12.0, 3.5]),\n    ('sta_smc', [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]),\n    ('hybrid_adaptive_sta_smc', [15.0, 12.0, 10.0, 8.0])\n]\n\nintegration_results = validator.run_full_integration_suite(test_configs)",
    "lines": 152,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f15dff16"
  },
  {
    "id": "deprecation_management_1_752a46be",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 1,
    "code": "class DeprecationLevel(Enum):\n    \"\"\"Hierarchical deprecation severity levels.\"\"\"\n    INFO = \"info\"           # Informational - still fully supported\n    WARNING = \"warning\"     # Will be removed in future versions\n    ERROR = \"error\"         # Already removed, error fallback provided",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "752a46be"
  },
  {
    "id": "deprecation_management_2_126bf6c4",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass DeprecationMapping:\n    \"\"\"Complete deprecation specification for a parameter or feature.\"\"\"\n    old_name: str                           # Deprecated parameter name\n    new_name: Optional[str] = None          # New parameter name (if renamed)\n    level: DeprecationLevel = WARNING      # Current deprecation level\n    message: Optional[str] = None          # Custom deprecation message\n    migration_guide: Optional[str] = None  # Detailed migration instructions\n    removed_in_version: Optional[str] = None  # Target removal version\n    introduced_in_version: Optional[str] = None  # When deprecation started\n    auto_migrate: bool = True              # Enable automatic migration\n    validation_function: Optional[Callable] = None  # Custom validation",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "126bf6c4"
  },
  {
    "id": "deprecation_management_3_7bd05e20",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nCLASSICAL_SMC_DEPRECATIONS = {\n    'gamma': DeprecationMapping(\n        old_name='gamma',\n        new_name=None,\n        level=DeprecationLevel.ERROR,\n        message=\"'gamma' parameter is not valid for classical_smc. Use 'boundary_layer' instead.\",\n        migration_guide=(\n            \"Classical SMC uses 'boundary_layer' for chattering reduction, not 'gamma'. \"\n            \"The 'gamma' parameter is specific to adaptive SMC controllers. \"\n            \"Replace 'gamma: 0.1' with 'boundary_layer: 0.02' in your configuration.\"\n        ),\n        removed_in_version=\"2.0.0\",\n        introduced_in_version=\"1.8.0\",\n        auto_migrate=False  # Cannot auto-migrate due to semantic difference\n    ),\n\n    'adaptation_rate': DeprecationMapping(\n        old_name='adaptation_rate',\n        new_name=None,\n        level=DeprecationLevel.ERROR,\n        message=\"'adaptation_rate' is not valid for classical_smc. This parameter is only for adaptive_smc.\",\n        migration_guide=(\n            \"Remove 'adaptation_rate' from classical SMC configuration. \"\n            \"If you need adaptation, use 'adaptive_smc' controller type instead.\"\n        ),\n        removed_in_version=\"2.0.0\",\n        auto_migrate=True  # Can auto-remove invalid parameter\n    ),\n\n    'switch_function': DeprecationMapping(\n        old_name='switch_function',\n        new_name='switch_method',\n        level=DeprecationLevel.WARNING,\n        message=\"'switch_function' parameter renamed to 'switch_method'.\",\n        migration_guide=(\n            \"Replace 'switch_function' with 'switch_method' in configuration. \"\n            \"Valid values: 'sign', 'tanh', 'sigmoid', 'sat'. \"\n            \"Example: switch_method: 'tanh'\"\n        ),\n        removed_in_version=\"3.0.0\",\n        introduced_in_version=\"2.1.0\",\n        auto_migrate=True\n    ),\n\n    'K_switching': DeprecationMapping(\n        old_name='K_switching',\n        new_name='gains[4]',\n        level=DeprecationLevel.WARNING,\n        message=\"Separate 'K_switching' parameter deprecated. Include as 5th element in gains array.\",\n        migration_guide=(\n            \"Move K_switching value to gains array as 5th element. \"\n            \"Example: gains: [k1, k2, \u03bb1, \u03bb2, K_switching, kd] \"\n            \"Old: K_switching: 15.0, gains: [10, 5, 8, 3, 2] \"\n            \"New: gains: [10, 5, 8, 3, 15, 2]\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    )\n}",
    "lines": 62,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7bd05e20"
  },
  {
    "id": "deprecation_management_4_8ae401c7",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nADAPTIVE_SMC_DEPRECATIONS = {\n    'boundary_layer_thickness': DeprecationMapping(\n        old_name='boundary_layer_thickness',\n        new_name='boundary_layer',\n        level=DeprecationLevel.WARNING,\n        message=\"'boundary_layer_thickness' parameter renamed to 'boundary_layer'.\",\n        migration_guide=(\n            \"Replace 'boundary_layer_thickness' with 'boundary_layer' in configuration. \"\n            \"The parameter has the same meaning and value range (0.001 to 0.1). \"\n            \"Example: boundary_layer: 0.01\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    ),\n\n    'adaptation_gain': DeprecationMapping(\n        old_name='adaptation_gain',\n        new_name='gains[4]',\n        level=DeprecationLevel.WARNING,\n        message=\"'adaptation_gain' parameter renamed to 'gamma' (included in gains array).\",\n        migration_guide=(\n            \"Remove separate 'adaptation_gain' and include gamma as 5th element in gains array. \"\n            \"The adaptation gain (gamma) controls parameter estimation rate. \"\n            \"Example: gains: [k1, k2, \u03bb1, \u03bb2, gamma] where gamma = old adaptation_gain\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True,\n        validation_function=lambda x: 0.01 <= x <= 10.0\n    ),\n\n    'estimate_bounds': DeprecationMapping(\n        old_name='estimate_bounds',\n        new_name=['K_min', 'K_max'],\n        level=DeprecationLevel.WARNING,\n        message=\"'estimate_bounds' parameter split into 'K_min' and 'K_max'.\",\n        migration_guide=(\n            \"Replace 'estimate_bounds: [min, max]' with separate 'K_min' and 'K_max' parameters. \"\n            \"Example: K_min: 0.1, K_max: 100.0\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    ),\n\n    'adaptation_law': DeprecationMapping(\n        old_name='adaptation_law',\n        new_name='alpha',\n        level=DeprecationLevel.INFO,\n        message=\"'adaptation_law' parameter renamed to 'alpha' for clarity.\",\n        migration_guide=(\n            \"Replace 'adaptation_law' with 'alpha'. \"\n            \"The parameter controls adaptation law exponent (typically 0.5 for standard adaptation). \"\n            \"Example: alpha: 0.5\"\n        ),\n        removed_in_version=\"4.0.0\",\n        auto_migrate=True\n    )\n}",
    "lines": 60,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ae401c7"
  },
  {
    "id": "deprecation_management_5_d37d8160",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nSTA_SMC_DEPRECATIONS = {\n    'K1': DeprecationMapping(\n        old_name='K1',\n        new_name='gains[0]',\n        level=DeprecationLevel.WARNING,\n        message=\"Separate K1/K2 parameters deprecated. Use gains array instead.\",\n        migration_guide=(\n            \"Include K1, K2 as first two elements in gains array: [K1, K2, k1, k2, lam1, lam2]. \"\n            \"This provides consistent parameter interface across all SMC controllers. \"\n            \"Example: gains: [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    ),\n\n    'K2': DeprecationMapping(\n        old_name='K2',\n        new_name='gains[1]',\n        level=DeprecationLevel.WARNING,\n        message=\"Separate K1/K2 parameters deprecated. Use gains array instead.\",\n        migration_guide=(\n            \"Include K1, K2 as first two elements in gains array: [K1, K2, k1, k2, lam1, lam2]. \"\n            \"Ensure K1 > K2 for optimal STA performance. \"\n            \"Example: gains: [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    ),\n\n    'alpha_power': DeprecationMapping(\n        old_name='alpha_power',\n        new_name='power_exponent',\n        level=DeprecationLevel.WARNING,\n        message=\"'alpha_power' parameter renamed to 'power_exponent' for clarity.\",\n        migration_guide=(\n            \"Replace 'alpha_power' with 'power_exponent'. \"\n            \"Standard STA uses power_exponent: 0.5 for finite-time convergence. \"\n            \"Valid range: (0, 1). Example: power_exponent: 0.5\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True,\n        validation_function=lambda x: 0.0 < x < 1.0\n    ),\n\n    'switching_function_type': DeprecationMapping(\n        old_name='switching_function_type',\n        new_name='switch_method',\n        level=DeprecationLevel.INFO,\n        message=\"'switching_function_type' renamed to 'switch_method' for consistency.\",\n        migration_guide=(\n            \"Replace 'switching_function_type' with 'switch_method'. \"\n            \"Valid options: 'tanh', 'sigmoid', 'sat'. \"\n            \"STA-SMC typically uses 'tanh' for smooth switching.\"\n        ),\n        removed_in_version=\"4.0.0\",\n        auto_migrate=True\n    )\n}",
    "lines": 61,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d37d8160"
  },
  {
    "id": "deprecation_management_6_1f90f7ac",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nHYBRID_SMC_DEPRECATIONS = {\n    'mode': DeprecationMapping(\n        old_name='mode',\n        new_name='hybrid_mode',\n        level=DeprecationLevel.WARNING,\n        message=\"'mode' parameter renamed to 'hybrid_mode'.\",\n        migration_guide=(\n            \"Replace 'mode' with 'hybrid_mode' and use HybridMode enum values. \"\n            \"Available modes: 'CLASSICAL_ADAPTIVE', 'ADAPTIVE_STA', 'CLASSICAL_STA'. \"\n            \"Example: hybrid_mode: 'CLASSICAL_ADAPTIVE'\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=True\n    ),\n\n    'switch_threshold': DeprecationMapping(\n        old_name='switch_threshold',\n        new_name='switching_criteria',\n        level=DeprecationLevel.WARNING,\n        message=\"'switch_threshold' renamed to 'switching_criteria' with enhanced functionality.\",\n        migration_guide=(\n            \"Replace 'switch_threshold' with 'switching_criteria' configuration. \"\n            \"New format supports multiple criteria: error_threshold, time_threshold, performance_threshold. \"\n            \"Example: switching_criteria: {error_threshold: 0.1, time_threshold: 2.0}\"\n        ),\n        removed_in_version=\"3.0.0\",\n        auto_migrate=False  # Requires manual migration due to format change\n    ),\n\n    'sub_controller_gains': DeprecationMapping(\n        old_name='sub_controller_gains',\n        new_name=['classical_config', 'adaptive_config'],\n        level=DeprecationLevel.ERROR,\n        message=\"'sub_controller_gains' replaced with full sub-controller configurations.\",\n        migration_guide=(\n            \"Replace 'sub_controller_gains' with complete 'classical_config' and 'adaptive_config' objects. \"\n            \"This provides full parameter control for each sub-controller. \"\n            \"See hybrid SMC configuration examples in documentation.\"\n        ),\n        removed_in_version=\"2.0.0\",\n        auto_migrate=False\n    )\n}",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f90f7ac"
  },
  {
    "id": "deprecation_management_7_650bf32d",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 7,
    "code": "class ControllerDeprecationWarner:\n    \"\"\"\n    Enterprise-grade deprecation warning system with comprehensive tracking.\n\n    Features:\n    - Multi-level deprecation severity\n    - Automatic parameter migration\n    - Detailed migration guidance\n    - Usage analytics and reporting\n    - Integration with logging systems\n    \"\"\"\n\n    def __init__(self):\n        self.logger = logging.getLogger(__name__)\n        self._deprecation_mappings = self._initialize_deprecation_mappings()\n        self._usage_statistics = defaultdict(int)\n        self._migration_history = []\n\n    def _initialize_deprecation_mappings(self) -> Dict[str, Dict[str, DeprecationMapping]]:\n        \"\"\"Initialize comprehensive deprecation mappings for all controller types.\"\"\"\n        return {\n            'classical_smc': CLASSICAL_SMC_DEPRECATIONS,\n            'adaptive_smc': ADAPTIVE_SMC_DEPRECATIONS,\n            'sta_smc': STA_SMC_DEPRECATIONS,\n            'hybrid_adaptive_sta_smc': HYBRID_SMC_DEPRECATIONS\n        }\n\n    def check_deprecated_parameters(\n        self,\n        controller_type: str,\n        config_params: Dict[str, Any]\n    ) -> Tuple[Dict[str, Any], List[DeprecationWarning]]:\n        \"\"\"\n        Check for deprecated parameters and perform migration.\n\n        Args:\n            controller_type: Type of controller being configured\n            config_params: Configuration parameters to check\n\n        Returns:\n            Tuple of (migrated_params, warning_list)\n        \"\"\"\n        if controller_type not in self._deprecation_mappings:\n            return config_params, []\n\n        updated_params = config_params.copy()\n        warnings_issued = []\n        deprecation_map = self._deprecation_mappings[controller_type]\n\n        for param_name, param_value in config_params.items():\n            if param_name in deprecation_map:\n                mapping = deprecation_map[param_name]\n\n                # Track usage statistics\n                self._usage_statistics[f\"{controller_type}.{param_name}\"] += 1\n\n                # Issue appropriate warning\n                warning = self._issue_deprecation_warning(\n                    controller_type, mapping, param_name, param_value\n                )\n                warnings_issued.append(warning)\n\n                # Perform migration if enabled\n                if mapping.auto_migrate:\n                    migration_result = self._perform_automatic_migration(\n                        updated_params, mapping, param_name, param_value\n                    )\n\n                    if migration_result.success:\n                        self._record_migration(controller_type, mapping, migration_result)\n                    else:\n                        self.logger.error(f\"Migration failed for {param_name}: {migration_result.error}\")\n\n        return updated_params, warnings_issued\n\n    def _issue_deprecation_warning(\n        self,\n        controller_type: str,\n        mapping: DeprecationMapping,\n        param_name: str,\n        param_value: Any\n    ) -> DeprecationWarning:\n        \"\"\"Issue comprehensive deprecation warning with detailed guidance.\"\"\"\n\n        # Construct detailed message\n        message_parts = [\n            f\"[{controller_type}] {mapping.message or f'Parameter {param_name} is deprecated'}\"\n        ]\n\n        if mapping.migration_guide:\n            message_parts.append(f\"Migration: {mapping.migration_guide}\")\n\n        if mapping.removed_in_version:\n            message_parts.append(f\"Will be removed in version {mapping.removed_in_version}\")\n\n        if mapping.new_name:\n            message_parts.append(f\"Use '{mapping.new_name}' instead\")\n\n        full_message = \" | \".join(message_parts)\n\n        # Create warning object with metadata\n        warning = DeprecationWarning(full_message)\n        warning.controller_type = controller_type\n        warning.old_parameter = param_name\n        warning.new_parameter = mapping.new_name\n        warning.deprecation_level = mapping.level\n        warning.migration_guide = mapping.migration_guide\n\n        # Issue warning based on severity\n        if mapping.level == DeprecationLevel.INFO:\n            self.logger.info(full_message)\n        elif mapping.level == DeprecationLevel.WARNING:\n            warnings.warn(full_message, DeprecationWarning, stacklevel=5)\n            self.logger.warning(full_message)\n        elif mapping.level == DeprecationLevel.ERROR:\n            self.logger.error(full_message)\n\n        return warning\n\n    def _perform_automatic_migration(\n        self,\n        params: Dict[str, Any],\n        mapping: DeprecationMapping,\n        old_name: str,\n        old_value: Any\n    ) -> 'MigrationResult':\n        \"\"\"Perform automatic parameter migration with validation.\"\"\"\n\n        try:\n            # Validate value if validation function provided\n            if mapping.validation_function and not mapping.validation_function(old_value):\n                return MigrationResult(\n                    success=False,\n                    error=f\"Value {old_value} failed validation for {old_name}\"\n                )\n\n            # Handle different migration scenarios\n            if mapping.level == DeprecationLevel.ERROR:\n                # Remove invalid parameters\n                if old_name in params:\n                    del params[old_name]\n                    return MigrationResult(\n                        success=True,\n                        action=f\"Removed invalid parameter '{old_name}'\"\n                    )\n\n            elif mapping.new_name and mapping.new_name not in params:\n                # Handle parameter renaming\n                if isinstance(mapping.new_name, str):\n                    # Simple rename\n                    if not mapping.new_name.startswith('gains['):\n                        params[mapping.new_name] = old_value\n                        del params[old_name]\n                        return MigrationResult(\n                            success=True,\n                            action=f\"Migrated '{old_name}' to '{mapping.new_name}'\"\n                        )\n                    else:\n                        # Complex migration to gains array\n                        return self._migrate_to_gains_array(params, mapping, old_name, old_value)\n\n                elif isinstance(mapping.new_name, list):\n                    # Split parameter into multiple new parameters\n                    return self._migrate_split_parameter(params, mapping, old_name, old_value)\n\n            return MigrationResult(success=True, action=\"No migration needed\")\n\n        except Exception as e:\n            return MigrationResult(success=False, error=str(e))\n\n    def _migrate_to_gains_array(\n        self,\n        params: Dict[str, Any],\n        mapping: DeprecationMapping,\n        old_name: str,\n        old_value: Any\n    ) -> 'MigrationResult':\n        \"\"\"Migrate parameter to gains array position.\"\"\"\n\n        # Extract array index from new_name (e.g., 'gains[4]' -> 4)\n        import re\n        match = re.search(r'gains\\[(\\d+)\\]', mapping.new_name)\n        if not match:\n            return MigrationResult(success=False, error=\"Invalid gains array specification\")\n\n        index = int(match.group(1))\n\n        # Ensure gains array exists and is large enough\n        if 'gains' not in params:\n            params['gains'] = [1.0] * (index + 1)\n        elif len(params['gains']) <= index:\n            params['gains'].extend([1.0] * (index + 1 - len(params['gains'])))\n\n        # Set the value\n        params['gains'][index] = old_value\n        del params[old_name]\n\n        return MigrationResult(\n            success=True,\n            action=f\"Migrated '{old_name}' to gains[{index}]\"\n        )\n\n    def _migrate_split_parameter(\n        self,\n        params: Dict[str, Any],\n        mapping: DeprecationMapping,\n        old_name: str,\n        old_value: Any\n    ) -> 'MigrationResult':\n        \"\"\"Migrate parameter that splits into multiple new parameters.\"\"\"\n\n        if old_name == 'estimate_bounds' and isinstance(old_value, (list, tuple)) and len(old_value) == 2:\n            params['K_min'] = old_value[0]\n            params['K_max'] = old_value[1]\n            del params[old_name]\n            return MigrationResult(\n                success=True,\n                action=f\"Split '{old_name}' into K_min and K_max\"\n            )\n\n        return MigrationResult(\n            success=False,\n            error=f\"Don't know how to split parameter {old_name}\"\n        )\n\n    def _record_migration(\n        self,\n        controller_type: str,\n        mapping: DeprecationMapping,\n        result: 'MigrationResult'\n    ) -> None:\n        \"\"\"Record migration for analytics and reporting.\"\"\"\n        migration_record = {\n            'timestamp': time.time(),\n            'controller_type': controller_type,\n            'old_parameter': mapping.old_name,\n            'new_parameter': mapping.new_name,\n            'deprecation_level': mapping.level.value,\n            'migration_action': result.action,\n            'success': result.success\n        }\n        self._migration_history.append(migration_record)\n\n    def get_migration_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive migration and usage statistics.\"\"\"\n        return {\n            'deprecated_parameter_usage': dict(self._usage_statistics),\n            'migration_history': self._migration_history,\n            'total_migrations': len(self._migration_history),\n            'successful_migrations': sum(1 for m in self._migration_history if m['success']),\n            'migration_by_controller': self._group_migrations_by_controller(),\n            'most_used_deprecated_params': self._get_most_used_deprecated()\n        }\n\n    def _group_migrations_by_controller(self) -> Dict[str, int]:\n        \"\"\"Group migration statistics by controller type.\"\"\"\n        controller_stats = defaultdict(int)\n        for migration in self._migration_history:\n            controller_stats[migration['controller_type']] += 1\n        return dict(controller_stats)\n\n    def _get_most_used_deprecated(self) -> List[Tuple[str, int]]:\n        \"\"\"Get most frequently used deprecated parameters.\"\"\"\n        return sorted(self._usage_statistics.items(), key=lambda x: x[1], reverse=True)[:10]\n\n    def generate_deprecation_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive deprecation usage report.\"\"\"\n        return {\n            'report_timestamp': time.time(),\n            'statistics': self.get_migration_statistics(),\n            'recommendations': self._generate_migration_recommendations(),\n            'upcoming_removals': self._get_upcoming_removals(),\n            'migration_health_score': self._calculate_migration_health_score()\n        }\n\n    def _generate_migration_recommendations(self) -> List[str]:\n        \"\"\"Generate recommendations based on usage patterns.\"\"\"\n        recommendations = []\n\n        # Check for high usage of deprecated parameters\n        for param, count in self._get_most_used_deprecated():\n            if count > 10:\n                recommendations.append(\n                    f\"High usage of deprecated parameter '{param}' ({count} times). \"\n                    \"Consider updating configurations to use new parameter names.\"\n                )\n\n        # Check for failed migrations\n        failed_migrations = [m for m in self._migration_history if not m['success']]\n        if failed_migrations:\n            recommendations.append(\n                f\"{len(failed_migrations)} migration failures detected. \"\n                \"Review migration logs and update configurations manually.\"\n            )\n\n        return recommendations\n\n    def _get_upcoming_removals(self) -> List[Dict[str, Any]]:\n        \"\"\"Get list of parameters scheduled for removal.\"\"\"\n        upcoming = []\n        for controller_type, mappings in self._deprecation_mappings.items():\n            for param_name, mapping in mappings.items():\n                if mapping.level == DeprecationLevel.WARNING and mapping.removed_in_version:\n                    upcoming.append({\n                        'controller_type': controller_type,\n                        'parameter': param_name,\n                        'removal_version': mapping.removed_in_version,\n                        'migration_guide': mapping.migration_guide\n                    })\n        return upcoming\n\n    def _calculate_migration_health_score(self) -> float:\n        \"\"\"Calculate overall migration health score (0-100).\"\"\"\n        if not self._migration_history:\n            return 100.0\n\n        successful_migrations = sum(1 for m in self._migration_history if m['success'])\n        success_rate = successful_migrations / len(self._migration_history)\n\n        # Factor in usage of deprecated parameters\n        deprecated_usage = sum(self._usage_statistics.values())\n        usage_penalty = min(deprecated_usage * 0.1, 30.0)  # Max 30 point penalty\n\n        health_score = (success_rate * 100) - usage_penalty\n        return max(0.0, min(100.0, health_score))\n\n@dataclass\nclass MigrationResult:\n    \"\"\"Result of automatic parameter migration.\"\"\"\n    success: bool\n    action: Optional[str] = None\n    error: Optional[str] = None\n    warnings: List[str] = field(default_factory=list)",
    "lines": 333,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "650bf32d"
  },
  {
    "id": "deprecation_management_8_935e93f3",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 8,
    "code": "class ConfigurationMigrationUtility:\n    \"\"\"\n    Utility for migrating entire configuration files and structures.\n\n    Features:\n    - Batch configuration migration\n    - Backup creation before migration\n    - Validation of migrated configurations\n    - Rollback capability\n    \"\"\"\n\n    def __init__(self):\n        self.warner = ControllerDeprecationWarner()\n        self.backup_directory = Path(\".config_backups\")\n        self.backup_directory.mkdir(exist_ok=True)\n\n    def migrate_configuration_file(\n        self,\n        config_file_path: Union[str, Path],\n        output_path: Optional[Union[str, Path]] = None,\n        create_backup: bool = True\n    ) -> 'ConfigMigrationResult':\n        \"\"\"\n        Migrate an entire configuration file.\n\n        Args:\n            config_file_path: Path to configuration file\n            output_path: Output path (defaults to overwrite original)\n            create_backup: Whether to create backup before migration\n\n        Returns:\n            Migration result with details and statistics\n        \"\"\"\n        config_path = Path(config_file_path)\n\n        if not config_path.exists():\n            return ConfigMigrationResult(\n                success=False,\n                error=f\"Configuration file not found: {config_path}\"\n            )\n\n        try:\n            # Create backup if requested\n            backup_path = None\n            if create_backup:\n                backup_path = self._create_backup(config_path)\n\n            # Load configuration\n            with open(config_path, 'r') as f:\n                if config_path.suffix.lower() in ['.yml', '.yaml']:\n                    import yaml\n                    config_data = yaml.safe_load(f)\n                elif config_path.suffix.lower() == '.json':\n                    import json\n                    config_data = json.load(f)\n                else:\n                    return ConfigMigrationResult(\n                        success=False,\n                        error=f\"Unsupported configuration format: {config_path.suffix}\"\n                    )\n\n            # Perform migration\n            migration_result = self.migrate_configuration_data(config_data)\n\n            # Save migrated configuration\n            output_file = Path(output_path) if output_path else config_path\n\n            with open(output_file, 'w') as f:\n                if config_path.suffix.lower() in ['.yml', '.yaml']:\n                    yaml.dump(migration_result.migrated_config, f, default_flow_style=False)\n                elif config_path.suffix.lower() == '.json':\n                    json.dump(migration_result.migrated_config, f, indent=2)\n\n            return ConfigMigrationResult(\n                success=True,\n                original_file=config_path,\n                migrated_file=output_file,\n                backup_file=backup_path,\n                migration_summary=migration_result.migration_summary,\n                warnings=migration_result.warnings\n            )\n\n        except Exception as e:\n            return ConfigMigrationResult(\n                success=False,\n                error=f\"Migration failed: {str(e)}\",\n                original_file=config_path\n            )\n\n    def migrate_configuration_data(self, config_data: Dict[str, Any]) -> 'DataMigrationResult':\n        \"\"\"\n        Migrate configuration data structure.\n\n        Args:\n            config_data: Configuration data dictionary\n\n        Returns:\n            Migration result with migrated data and summary\n        \"\"\"\n        migrated_config = config_data.copy()\n        all_warnings = []\n        migration_summary = {\n            'parameters_migrated': 0,\n            'parameters_removed': 0,\n            'controllers_processed': 0,\n            'migration_details': []\n        }\n\n        # Process controller configurations\n        if 'controllers' in migrated_config:\n            for controller_type, controller_config in migrated_config['controllers'].items():\n                if isinstance(controller_config, dict):\n                    migrated_params, warnings = self.warner.check_deprecated_parameters(\n                        controller_type, controller_config\n                    )\n\n                    migrated_config['controllers'][controller_type] = migrated_params\n                    all_warnings.extend(warnings)\n\n                    migration_summary['controllers_processed'] += 1\n                    migration_summary['migration_details'].append({\n                        'controller_type': controller_type,\n                        'warnings_count': len(warnings),\n                        'migration_applied': len(warnings) > 0\n                    })\n\n        # Process legacy controller_defaults structure\n        if 'controller_defaults' in migrated_config:\n            for controller_type, controller_config in migrated_config['controller_defaults'].items():\n                if isinstance(controller_config, dict):\n                    migrated_params, warnings = self.warner.check_deprecated_parameters(\n                        controller_type, controller_config\n                    )\n\n                    migrated_config['controller_defaults'][controller_type] = migrated_params\n                    all_warnings.extend(warnings)\n\n        # Update migration summary\n        migration_summary['parameters_migrated'] = sum(\n            len(detail.get('warnings', [])) for detail in migration_summary['migration_details']\n        )\n\n        return DataMigrationResult(\n            migrated_config=migrated_config,\n            warnings=all_warnings,\n            migration_summary=migration_summary\n        )\n\n    def _create_backup(self, config_path: Path) -> Path:\n        \"\"\"Create timestamped backup of configuration file.\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        backup_name = f\"{config_path.stem}_{timestamp}{config_path.suffix}\"\n        backup_path = self.backup_directory / backup_name\n\n        shutil.copy2(config_path, backup_path)\n        return backup_path\n\n    def validate_migrated_configuration(\n        self,\n        migrated_config: Dict[str, Any]\n    ) -> 'ValidationResult':\n        \"\"\"\n        Validate migrated configuration for correctness.\n\n        Args:\n            migrated_config: Migrated configuration data\n\n        Returns:\n            Validation result with success status and issues\n        \"\"\"\n        validation_issues = []\n\n        try:\n            # Test controller creation with migrated configuration\n            if 'controllers' in migrated_config:\n                for controller_type, controller_config in migrated_config['controllers'].items():\n                    try:\n                        # Attempt to create controller to validate configuration\n                        from src.controllers.factory import create_controller\n                        controller = create_controller(\n                            controller_type=controller_type,\n                            config=Mock(controllers={controller_type: controller_config}),\n                            gains=controller_config.get('gains')\n                        )\n\n                        if controller is None:\n                            validation_issues.append(\n                                f\"Failed to create {controller_type} with migrated configuration\"\n                            )\n\n                    except Exception as e:\n                        validation_issues.append(\n                            f\"Validation error for {controller_type}: {str(e)}\"\n                        )\n\n            return ValidationResult(\n                success=len(validation_issues) == 0,\n                issues=validation_issues\n            )\n\n        except Exception as e:\n            return ValidationResult(\n                success=False,\n                issues=[f\"Validation process failed: {str(e)}\"]\n            )\n\n@dataclass\nclass ConfigMigrationResult:\n    \"\"\"Result of configuration file migration.\"\"\"\n    success: bool\n    original_file: Optional[Path] = None\n    migrated_file: Optional[Path] = None\n    backup_file: Optional[Path] = None\n    migration_summary: Optional[Dict[str, Any]] = None\n    warnings: List[DeprecationWarning] = field(default_factory=list)\n    error: Optional[str] = None\n\n@dataclass\nclass DataMigrationResult:\n    \"\"\"Result of configuration data migration.\"\"\"\n    migrated_config: Dict[str, Any]\n    warnings: List[DeprecationWarning]\n    migration_summary: Dict[str, Any]\n\n@dataclass\nclass ValidationResult:\n    \"\"\"Result of configuration validation.\"\"\"\n    success: bool\n    issues: List[str] = field(default_factory=list)",
    "lines": 229,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "935e93f3"
  },
  {
    "id": "deprecation_management_9_998a15b9",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 9,
    "code": "# Recommended deprecation timeline\n   DEPRECATION_TIMELINE = {\n       'minor_parameter_rename': '2 versions',      # INFO -> WARNING -> ERROR\n       'parameter_restructure': '3 versions',       # INFO -> WARNING -> ERROR\n       'major_interface_change': '4+ versions',     # Extended timeline\n       'safety_critical_change': '6+ versions'      # Maximum timeline\n   }",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "998a15b9"
  },
  {
    "id": "deprecation_management_10_dbcc0218",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 10,
    "code": "# Good deprecation message\n   message = (\n       \"'old_param' is deprecated and will be removed in v3.0.0. \"\n       \"Use 'new_param' instead. Migration: Replace 'old_param: value' \"\n       \"with 'new_param: value' in your configuration.\"\n   )\n\n   # Poor deprecation message\n   message = \"'old_param' is deprecated.\"  # No guidance!",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbcc0218"
  },
  {
    "id": "deprecation_management_11_9329e7e9",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n   # Safe for automatic migration\n   simple_rename = DeprecationMapping(\n       old_name='old_name',\n       new_name='new_name',\n       auto_migrate=True\n   )\n\n   # Requires manual migration\n   complex_change = DeprecationMapping(\n       old_name='complex_param',\n       new_name='restructured_config',\n       auto_migrate=False,  # Semantic change requires manual intervention\n       migration_guide=\"See migration guide at docs/migration/v3.0.md\"\n   )",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9329e7e9"
  },
  {
    "id": "deprecation_management_12_099a3855",
    "file": "docs\\factory\\deprecation_management.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Global deprecation warner instance\n_deprecation_warner = ControllerDeprecationWarner()\n\ndef check_deprecated_config(controller_type: str, config_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Convenience function for checking and migrating deprecated parameters.\n\n    Usage:\n        config_params = check_deprecated_config('classical_smc', raw_config)\n    \"\"\"\n    migrated_params, warnings = _deprecation_warner.check_deprecated_parameters(\n        controller_type, config_params\n    )\n    return migrated_params\n\ndef get_deprecation_statistics() -> Dict[str, Any]:\n    \"\"\"Get current deprecation usage statistics.\"\"\"\n    return _deprecation_warner.get_migration_statistics()\n\ndef generate_migration_report() -> Dict[str, Any]:\n    \"\"\"Generate comprehensive migration report for analysis.\"\"\"\n    return _deprecation_warner.generate_deprecation_report()",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "099a3855"
  },
  {
    "id": "enhanced_factory_api_reference_1_ceda1b2c",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    # ... additional controllers\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceda1b2c"
  },
  {
    "id": "enhanced_factory_api_reference_2_b03b6138",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 2,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[List[float], np.ndarray]] = None\n) -> Any",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b03b6138"
  },
  {
    "id": "enhanced_factory_api_reference_3_76d5a63e",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 3,
    "code": "with _factory_lock:  # RLock with 10-second timeout\n    # Controller creation logic",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76d5a63e"
  },
  {
    "id": "enhanced_factory_api_reference_4_2314a264",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_ALIASES = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n    'hybrid_sta': 'hybrid_adaptive_sta_smc',\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2314a264"
  },
  {
    "id": "enhanced_factory_api_reference_5_262a3051",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Basic controller creation with explicit gains\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\n# With full configuration object\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\ncontroller = create_controller('adaptive_smc', config=config)\n\n# Using controller type aliases\ncontroller = create_controller('classic_smc', gains=[...])  # Alias for classical_smc",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "262a3051"
  },
  {
    "id": "enhanced_factory_api_reference_6_e95a2489",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 6,
    "code": "classical_params = {\n    'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    'max_force': 150.0,             # Maximum control force [N]\n    'boundary_layer': 0.02,         # Boundary layer thickness\n    'dt': 0.001,                    # Time step [s]\n    'switch_method': 'tanh'         # Switching function type\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e95a2489"
  },
  {
    "id": "enhanced_factory_api_reference_7_ae8d31e1",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 7,
    "code": "sta_params = {\n    'gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],  # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    'max_force': 150.0,             # Maximum control force [N]\n    'dt': 0.001,                    # Time step [s]\n    'power_exponent': 0.5,          # Super-twisting power\n    'regularization': 1e-6,         # Numerical regularization\n    'boundary_layer': 0.01,         # Small boundary layer for implementation\n    'switch_method': 'tanh'         # Continuous switching function\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae8d31e1"
  },
  {
    "id": "enhanced_factory_api_reference_8_0f905821",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nadaptive_params = {\n    'gains': [25.0, 18.0, 15.0, 10.0, 4.0],  # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    'max_force': 150.0,             # Maximum control force [N]\n    'dt': 0.001,                    # Time step [s]\n    'leak_rate': 0.01,              # Leakage factor \u03c3\n    'dead_zone': 0.05,              # Dead zone thickness\n    'K_min': 0.1,                   # Minimum adaptive gain\n    'K_max': 100.0,                 # Maximum adaptive gain\n    'alpha': 0.5                    # Adaptation smoothing factor\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f905821"
  },
  {
    "id": "enhanced_factory_api_reference_9_16e5896d",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 9,
    "code": "hybrid_params = {\n    'gains': [18.0, 12.0, 10.0, 8.0],     # [k1, k2, \u03bb1, \u03bb2]\n    'hybrid_mode': HybridMode.CLASSICAL_ADAPTIVE,  # Initial mode\n    'max_force': 150.0,                   # Maximum control force [N]\n    'dt': 0.001,                          # Time step [s]\n    'classical_config': classical_config,  # Sub-controller configuration\n    'adaptive_config': adaptive_config,    # Sub-controller configuration\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "16e5896d"
  },
  {
    "id": "enhanced_factory_api_reference_10_4d9b9b28",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 10,
    "code": "mpc_params = {\n    'horizon': 10,                  # Prediction horizon N\n    'q_x': 1.0,                    # State weight (cart position)\n    'q_theta': 1.0,                # State weight (pendulum angles)\n    'r_u': 0.1,                    # Control weight\n    'max_cart_pos': 2.0,           # Position constraint [m]\n    'max_force': 150.0             # Control constraint [N]\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d9b9b28"
  },
  {
    "id": "enhanced_factory_api_reference_11_450d0660",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"Wrapper providing PSO-compatible interface for SMC controllers.\"\"\"\n\n    def __init__(self, controller, n_gains: int, controller_type: str):\n        self.controller = controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate gain particles for PSO optimization.\"\"\"\n        # Controller-specific validation logic\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"PSO-compatible control computation interface.\"\"\"\n        # Simplified interface for fitness evaluation",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "450d0660"
  },
  {
    "id": "enhanced_factory_api_reference_12_4aff105c",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 12,
    "code": "def create_smc_for_pso(\n    smc_type: SMCType,\n    gains: Union[List[float], np.ndarray],\n    **kwargs: Any\n) -> PSOControllerWrapper:\n    \"\"\"Create SMC controller with PSO-compatible interface.\"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4aff105c"
  },
  {
    "id": "enhanced_factory_api_reference_13_502dcf6d",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 13,
    "code": "def get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]:\n    \"\"\"\n    Returns (lower_bounds, upper_bounds) for PSO optimization.\n\n    Based on control theory constraints and practical limits.\n    \"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "502dcf6d"
  },
  {
    "id": "enhanced_factory_api_reference_14_0813aa94",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nPSO_BOUNDS = {\n    SMCType.CLASSICAL: {\n        'lower': [1.0, 1.0, 1.0, 1.0, 5.0, 0.1],     # [k1, k2, \u03bb1, \u03bb2, K, kd]\n        'upper': [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]\n    },\n    SMCType.ADAPTIVE: {\n        'lower': [2.0, 2.0, 1.0, 1.0, 0.5],          # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n        'upper': [40.0, 40.0, 25.0, 25.0, 10.0]\n    },\n    SMCType.SUPER_TWISTING: {\n        'lower': [3.0, 2.0, 2.0, 2.0, 0.5, 0.5],     # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n        'upper': [50.0, 30.0, 30.0, 30.0, 20.0, 20.0]\n    },\n    SMCType.HYBRID: {\n        'lower': [2.0, 2.0, 1.0, 1.0],               # [k1, k2, \u03bb1, \u03bb2]\n        'upper': [30.0, 30.0, 20.0, 20.0]\n    }\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0813aa94"
  },
  {
    "id": "enhanced_factory_api_reference_15_3f7eae12",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 15,
    "code": "class ConfigValueError(ValueError):\n    \"\"\"Exception raised for invalid configuration values.\"\"\"\n    pass",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f7eae12"
  },
  {
    "id": "enhanced_factory_api_reference_16_731f5c8b",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_controller_gains(\n    gains: List[float],\n    controller_info: Dict[str, Any],\n    controller_type: str\n) -> None:\n    \"\"\"\n    Validate controller gains with mathematical constraints.\n\n    Raises:\n        ValueError: If gains violate stability or physical constraints\n    \"\"\"",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "731f5c8b"
  },
  {
    "id": "enhanced_factory_api_reference_17_77281f60",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe factory operations\n_factory_lock = threading.RLock()\n_LOCK_TIMEOUT = 10.0  # seconds\n\ndef create_controller(...):\n    \"\"\"Thread-safe controller creation.\"\"\"\n    with _factory_lock:\n        # Factory logic with timeout protection\n        pass",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "77281f60"
  },
  {
    "id": "enhanced_factory_api_reference_18_d0b4df84",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 18,
    "code": "def create_classical_smc_controller(config=None, gains=None):\n    \"\"\"Legacy interface for classical SMC (backward compatibility).\"\"\"\n    return create_controller('classical_smc', config, gains)\n\ndef create_controller_legacy(controller_type, config=None, gains=None):\n    \"\"\"Legacy factory function (backward compatibility).\"\"\"\n    return create_controller(controller_type, config, gains)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0b4df84"
  },
  {
    "id": "enhanced_factory_api_reference_19_bc48736a",
    "file": "docs\\factory\\enhanced_factory_api_reference.md",
    "index": 19,
    "code": "def check_deprecated_config(controller_type: str, params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Check for deprecated parameters and apply migrations.\n\n    Returns:\n        Updated parameter dictionary with migrations applied\n    \"\"\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc48736a"
  },
  {
    "id": "enhanced_pso_integration_guide_1_619f94af",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOFactoryInterface:\n    \"\"\"\n    High-performance interface for PSO optimization workflows.\n\n    Features:\n    - Thread-safe parallel optimization\n    - Automatic gain validation and bounds checking\n    - Performance monitoring and diagnostics\n    - Fallback mechanisms for invalid parameter sets\n    \"\"\"\n\n    def __init__(self, controller_type: str, simulation_config: Any):\n        self.controller_type = controller_type\n        self.config = simulation_config\n        self._initialize_pso_environment()\n\n    def _initialize_pso_environment(self) -> None:\n        \"\"\"Setup PSO optimization environment with all requirements.\"\"\"\n\n        # Controller specifications\n        self.registry_info = CONTROLLER_REGISTRY[self.controller_type]\n        self.n_gains = self.registry_info['gain_count']\n        self.default_gains = self.registry_info['default_gains']\n\n        # PSO bounds (mathematically derived)\n        self.bounds_lower, self.bounds_upper = get_gain_bounds_for_pso(\n            SMCType(self.controller_type)\n        )\n\n        # Performance tracking\n        self.metrics = {\n            'total_evaluations': 0,\n            'successful_evaluations': 0,\n            'validation_failures': 0,\n            'simulation_failures': 0,\n            'best_fitness': float('inf'),\n            'average_fitness': 0.0\n        }\n\n        # Thread safety\n        self._evaluation_lock = threading.RLock()",
    "lines": 44,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "619f94af"
  },
  {
    "id": "enhanced_pso_integration_guide_2_d4b875b9",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"\n    PSO-optimized controller wrapper with comprehensive validation.\n\n    Provides:\n    - Simplified control interface for fitness evaluation\n    - Automatic gain validation with controller-specific rules\n    - Performance monitoring and error handling\n    - Thread-safe operation for parallel PSO\n    \"\"\"\n\n    def __init__(self, controller: Any, controller_type: str, validation_config: Dict[str, Any]):\n        self.controller = controller\n        self.controller_type = controller_type\n        self.validation_config = validation_config\n\n        # PSO-required attributes\n        self.n_gains = CONTROLLER_REGISTRY[controller_type]['gain_count']\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n        # Performance tracking\n        self.control_calls = 0\n        self.control_failures = 0\n        self.last_control_time = 0.0\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Vectorized gain validation for PSO particle swarms.\n\n        Args:\n            particles: Array of shape (n_particles, n_gains)\n\n        Returns:\n            Boolean mask indicating valid particles\n        \"\"\"\n        if particles.ndim == 1:\n            particles = particles.reshape(1, -1)\n\n        valid_mask = np.ones(particles.shape[0], dtype=bool)\n\n        # Basic validation\n        for i, gains in enumerate(particles):\n            try:\n                # Check gain count\n                if len(gains) != self.n_gains:\n                    valid_mask[i] = False\n                    continue\n\n                # Check for finite positive values\n                if not all(np.isfinite(g) and g > 0 for g in gains):\n                    valid_mask[i] = False\n                    continue\n\n                # Controller-specific validation\n                if not self._validate_controller_specific_constraints(gains):\n                    valid_mask[i] = False\n                    continue\n\n            except Exception:\n                valid_mask[i] = False\n\n        return valid_mask\n\n    def _validate_controller_specific_constraints(self, gains: List[float]) -> bool:\n        \"\"\"Apply mathematical constraints for each controller type.\"\"\"\n\n        if self.controller_type == 'classical_smc':\n            # Classical SMC: All gains positive, reasonable ranges\n            k1, k2, lam1, lam2, K, kd = gains\n            return all(g > 0 for g in gains[:5]) and kd >= 0\n\n        elif self.controller_type == 'sta_smc':\n            # Super-Twisting: Critical stability condition K1 > K2\n            K1, K2 = gains[0], gains[1]\n            return K1 > K2 > 0 and all(g > 0 for g in gains[2:])\n\n        elif self.controller_type == 'adaptive_smc':\n            # Adaptive SMC: Adaptation rate bounds\n            k1, k2, lam1, lam2, gamma = gains\n            return all(g > 0 for g in gains[:4]) and 0.1 <= gamma <= 20.0\n\n        elif self.controller_type == 'hybrid_adaptive_sta_smc':\n            # Hybrid SMC: Surface parameters positive\n            return all(g > 0 for g in gains)\n\n        return True\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"\n        PSO-compatible control computation with error handling.\n\n        Args:\n            state: System state vector [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n\n        Returns:\n            Control output as numpy array\n        \"\"\"\n        try:\n            self.control_calls += 1\n            start_time = time.time()\n\n            # Validate input state\n            if len(state) != 6:\n                raise ValueError(f\"Expected 6-element state, got {len(state)}\")\n\n            # Call underlying controller\n            result = self.controller.compute_control(state, {}, {})\n\n            # Extract control value\n            if hasattr(result, 'u'):\n                u = result.u\n            elif isinstance(result, dict) and 'u' in result:\n                u = result['u']\n            else:\n                u = result\n\n            # Apply saturation and return as array\n            u_sat = np.clip(float(u), -self.max_force, self.max_force)\n\n            # Performance tracking\n            self.last_control_time = time.time() - start_time\n\n            return np.array([u_sat])\n\n        except Exception as e:\n            self.control_failures += 1\n            # Return safe fallback control\n            return np.array([0.0])",
    "lines": 131,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4b875b9"
  },
  {
    "id": "enhanced_pso_integration_guide_3_8649954d",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 3,
    "code": "def optimize_smc_controller_pso(\n    controller_type: str,\n    simulation_config: Any,\n    pso_config: Dict[str, Any],\n    optimization_objectives: List[str]\n) -> Dict[str, Any]:\n    \"\"\"\n    Complete PSO optimization workflow for SMC controllers.\n\n    Args:\n        controller_type: SMC controller type ('classical_smc', etc.)\n        simulation_config: Plant and simulation parameters\n        pso_config: PSO algorithm parameters\n        optimization_objectives: List of objectives ['ise', 'overshoot', 'settling_time']\n\n    Returns:\n        Optimization results with best gains and performance metrics\n    \"\"\"\n\n    # 1. Initialize PSO-Factory Interface\n    pso_interface = PSOFactoryInterface(controller_type, simulation_config)\n\n    # 2. Setup PSO Algorithm\n    from pyswarms.single import GlobalBestPSO\n\n    # PSO parameters with adaptive bounds\n    bounds = (\n        np.array(pso_interface.bounds_lower),\n        np.array(pso_interface.bounds_upper)\n    )\n\n    optimizer = GlobalBestPSO(\n        n_particles=pso_config.get('n_particles', 30),\n        dimensions=pso_interface.n_gains,\n        options={\n            'c1': pso_config.get('c1', 2.0),  # Cognitive component\n            'c2': pso_config.get('c2', 2.0),  # Social component\n            'w': pso_config.get('w', 0.9)     # Inertia weight\n        },\n        bounds=bounds\n    )\n\n    # 3. Define Fitness Function\n    def fitness_function(particles: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Vectorized fitness evaluation for PSO particles.\n\n        Args:\n            particles: Array of shape (n_particles, n_gains)\n\n        Returns:\n            Fitness scores for each particle\n        \"\"\"\n        fitness_scores = []\n\n        for gains in particles:\n            try:\n                # Create controller with current gains\n                controller_factory = pso_interface.create_pso_controller_factory()\n                controller = controller_factory(gains)\n\n                # Validate gains\n                if not controller.validate_gains(gains.reshape(1, -1))[0]:\n                    fitness_scores.append(1000.0)  # Penalty for invalid gains\n                    continue\n\n                # Run simulation\n                simulation_result = run_simulation_with_controller(\n                    controller, simulation_config\n                )\n\n                # Compute multi-objective fitness\n                fitness = compute_multi_objective_fitness(\n                    simulation_result, optimization_objectives\n                )\n\n                fitness_scores.append(fitness)\n\n            except Exception as e:\n                # Penalty for simulation failures\n                fitness_scores.append(1000.0)\n\n        return np.array(fitness_scores)\n\n    # 4. Run PSO Optimization\n    best_cost, best_gains = optimizer.optimize(\n        fitness_function,\n        iters=pso_config.get('iters', 100),\n        verbose=True\n    )\n\n    # 5. Validate and Return Results\n    validation_result = validate_optimization_result(\n        best_gains, best_cost, controller_type, simulation_config\n    )\n\n    return {\n        'best_gains': best_gains.tolist(),\n        'best_fitness': float(best_cost),\n        'controller_type': controller_type,\n        'optimization_history': optimizer.cost_history,\n        'validation_result': validation_result,\n        'pso_metrics': pso_interface.metrics\n    }",
    "lines": 104,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8649954d"
  },
  {
    "id": "enhanced_pso_integration_guide_4_26427918",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_objective_pso_optimization(\n    controller_types: List[str],\n    simulation_config: Any,\n    objectives: Dict[str, float],  # {'ise': 0.4, 'overshoot': 0.3, 'energy': 0.3}\n    pso_config: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"\n    Multi-objective PSO optimization across multiple controller types.\n\n    Features:\n    - Simultaneous optimization of multiple performance metrics\n    - Pareto-optimal solution discovery\n    - Controller comparison and ranking\n    - Robust constraint handling\n    \"\"\"\n\n    results = {}\n    pareto_solutions = []\n\n    for controller_type in controller_types:\n        print(f\"Optimizing {controller_type}...\")\n\n        # Single-objective optimization for baseline\n        single_result = optimize_smc_controller_pso(\n            controller_type, simulation_config, pso_config,\n            list(objectives.keys())\n        )\n\n        results[controller_type] = single_result\n\n        # Extract Pareto solutions\n        pareto_solutions.extend(\n            extract_pareto_solutions(single_result, objectives)\n        )\n\n    # Multi-objective analysis\n    pareto_front = compute_pareto_front(pareto_solutions)\n    controller_ranking = rank_controllers_by_objectives(results, objectives)\n\n    return {\n        'individual_results': results,\n        'pareto_front': pareto_front,\n        'controller_ranking': controller_ranking,\n        'best_overall': select_best_overall_solution(results, objectives)\n    }",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26427918"
  },
  {
    "id": "enhanced_pso_integration_guide_5_32b837aa",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef adaptive_pso_optimization(\n    controller_type: str,\n    simulation_config: Any,\n    adaptation_config: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"\n    Adaptive PSO with dynamic parameter adjustment.\n\n    Features:\n    - Dynamic PSO parameter adjustment based on convergence\n    - Adaptive bounds tightening around promising regions\n    - Early stopping with convergence detection\n    - Exploration-exploitation balance optimization\n    \"\"\"\n\n    # Initialize adaptive PSO\n    adaptive_pso = AdaptivePSOOptimizer(\n        controller_type=controller_type,\n        config=adaptation_config\n    )\n\n    # Multi-stage optimization\n    stages = [\n        {'exploration_weight': 0.8, 'iterations': 50},   # Exploration phase\n        {'exploration_weight': 0.5, 'iterations': 30},   # Balanced phase\n        {'exploration_weight': 0.2, 'iterations': 20}    # Exploitation phase\n    ]\n\n    all_results = []\n\n    for stage_idx, stage_config in enumerate(stages):\n        print(f\"PSO Stage {stage_idx + 1}: {stage_config}\")\n\n        # Adjust PSO parameters\n        adaptive_pso.update_parameters(stage_config)\n\n        # Run optimization stage\n        stage_result = adaptive_pso.optimize_stage(\n            simulation_config, stage_config['iterations']\n        )\n\n        all_results.append(stage_result)\n\n        # Check for early convergence\n        if adaptive_pso.check_convergence():\n            print(f\"Converged early at stage {stage_idx + 1}\")\n            break\n\n    # Combine results\n    final_result = adaptive_pso.combine_stage_results(all_results)\n\n    return final_result",
    "lines": 55,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32b837aa"
  },
  {
    "id": "enhanced_pso_integration_guide_6_44ca952a",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 6,
    "code": "def parallel_fitness_evaluation(\n    particles: np.ndarray,\n    controller_factory: Callable,\n    simulation_config: Any,\n    n_threads: int = 4\n) -> np.ndarray:\n    \"\"\"\n    Parallel fitness evaluation using thread pool.\n\n    Significantly improves PSO performance for expensive simulations.\n    \"\"\"\n\n    from concurrent.futures import ThreadPoolExecutor, as_completed\n    import time\n\n    def evaluate_single_particle(gains: np.ndarray) -> float:\n        \"\"\"Evaluate fitness for single particle.\"\"\"\n        try:\n            controller = controller_factory(gains)\n            result = run_simulation_with_controller(controller, simulation_config)\n            return compute_fitness(result)\n        except Exception:\n            return 1000.0  # Penalty for failures\n\n    # Parallel execution\n    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n        future_to_idx = {\n            executor.submit(evaluate_single_particle, particle): idx\n            for idx, particle in enumerate(particles)\n        }\n\n        fitness_scores = np.zeros(len(particles))\n\n        for future in as_completed(future_to_idx):\n            idx = future_to_idx[future]\n            try:\n                fitness_scores[idx] = future.result()\n            except Exception:\n                fitness_scores[idx] = 1000.0\n\n    return fitness_scores",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "44ca952a"
  },
  {
    "id": "enhanced_pso_integration_guide_7_fbc2b86c",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimulationCache:\n    \"\"\"\n    Intelligent caching system for PSO optimization.\n\n    Features:\n    - Hash-based lookup for identical gain sets\n    - LRU eviction for memory management\n    - Cache hit/miss statistics\n    - Persistent storage for long-running optimizations\n    \"\"\"\n\n    def __init__(self, max_size: int = 1000, tolerance: float = 1e-6):\n        self.cache = {}\n        self.max_size = max_size\n        self.tolerance = tolerance\n        self.hits = 0\n        self.misses = 0\n\n    def get_cache_key(self, gains: np.ndarray) -> str:\n        \"\"\"Generate consistent cache key for gain arrays.\"\"\"\n        rounded_gains = np.round(gains / self.tolerance) * self.tolerance\n        return hash(tuple(rounded_gains))\n\n    def get(self, gains: np.ndarray) -> Optional[float]:\n        \"\"\"Retrieve cached fitness if available.\"\"\"\n        key = self.get_cache_key(gains)\n        if key in self.cache:\n            self.hits += 1\n            return self.cache[key]\n        self.misses += 1\n        return None\n\n    def put(self, gains: np.ndarray, fitness: float) -> None:\n        \"\"\"Store fitness result in cache.\"\"\"\n        if len(self.cache) >= self.max_size:\n            # Remove oldest entry (simple LRU)\n            oldest_key = next(iter(self.cache))\n            del self.cache[oldest_key]\n\n        key = self.get_cache_key(gains)\n        self.cache[key] = fitness\n\n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Return cache performance statistics.\"\"\"\n        total_requests = self.hits + self.misses\n        hit_rate = self.hits / total_requests if total_requests > 0 else 0\n\n        return {\n            'hits': self.hits,\n            'misses': self.misses,\n            'hit_rate': hit_rate,\n            'cache_size': len(self.cache)\n        }",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbc2b86c"
  },
  {
    "id": "enhanced_pso_integration_guide_8_e1d40b50",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 8,
    "code": "def gpu_accelerated_pso_evaluation(\n    particles: np.ndarray,\n    controller_factory: Callable,\n    simulation_config: Any\n) -> np.ndarray:\n    \"\"\"\n    GPU-accelerated fitness evaluation using CuPy/Numba.\n\n    For very large swarm sizes (>100 particles), GPU acceleration\n    can provide significant speedup.\n    \"\"\"\n\n    try:\n        import cupy as cp\n        import numba.cuda as cuda\n\n        # Transfer data to GPU\n        gpu_particles = cp.asarray(particles)\n\n        # GPU kernel for parallel simulation\n        @cuda.jit\n        def evaluate_particles_kernel(particles, fitness_scores):\n            idx = cuda.grid(1)\n            if idx < particles.shape[0]:\n                # GPU-accelerated simulation logic\n                fitness_scores[idx] = gpu_simulate_controller(particles[idx])\n\n        # Allocate GPU memory\n        gpu_fitness = cp.zeros(len(particles))\n\n        # Launch GPU kernel\n        threads_per_block = 256\n        blocks_per_grid = (len(particles) + threads_per_block - 1) // threads_per_block\n\n        evaluate_particles_kernel[blocks_per_grid, threads_per_block](\n            gpu_particles, gpu_fitness\n        )\n\n        # Transfer results back to CPU\n        return cp.asnumpy(gpu_fitness)\n\n    except ImportError:\n        # Fallback to CPU evaluation\n        return parallel_fitness_evaluation(particles, controller_factory, simulation_config)",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e1d40b50"
  },
  {
    "id": "enhanced_pso_integration_guide_9_e0e8f364",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_optimized_pso_bounds(controller_type: str, plant_params: Dict[str, Any]) -> Tuple[List[float], List[float]]:\n    \"\"\"\n    Compute optimized PSO bounds based on plant parameters and control theory.\n\n    Uses stability margins and performance requirements to derive tight bounds.\n    \"\"\"\n\n    if controller_type == 'classical_smc':\n        # Classical SMC bounds based on stability analysis\n        # Pole placement considerations for closed-loop stability\n\n        max_damping = plant_params.get('max_damping_requirement', 0.7)\n        settling_time = plant_params.get('settling_time_requirement', 2.0)\n\n        # Derive bounds from desired closed-loop characteristics\n        lambda_min = 4.0 / settling_time  # Natural frequency requirement\n        lambda_max = 20.0  # Upper bound to prevent excessive control effort\n\n        k_min = lambda_min / 2.0  # Position gain lower bound\n        k_max = lambda_max * 2.0  # Position gain upper bound\n\n        K_min = estimate_min_switching_gain(plant_params)\n        K_max = plant_params.get('max_force', 150.0) * 0.8  # Conservative upper bound\n\n        bounds_lower = [k_min, k_min, lambda_min, lambda_min, K_min, 0.0]\n        bounds_upper = [k_max, k_max, lambda_max, lambda_max, K_max, 10.0]\n\n    elif controller_type == 'sta_smc':\n        # Super-Twisting bounds with stability constraint K1 > K2\n\n        # Lyapunov-based design bounds\n        L0 = estimate_lipschitz_constant(plant_params)\n\n        K1_min = math.sqrt(L0) * 1.1  # Safety margin\n        K1_max = math.sqrt(L0) * 5.0  # Conservative upper bound\n\n        K2_min = L0 / (2 * math.sqrt(L0 - K1_min**2)) * 1.1\n        K2_max = K1_max * 0.8  # Ensure K1 > K2 constraint\n\n        bounds_lower = [K1_min, K2_min, 2.0, 2.0, 5.0, 5.0]\n        bounds_upper = [K1_max, K2_max, 30.0, 30.0, 20.0, 20.0]\n\n    elif controller_type == 'adaptive_smc':\n        # Adaptive SMC bounds based on adaptation rate limits\n\n        # Stability-preserving adaptation rate bounds\n        gamma_min = 0.1  # Minimum for reasonable adaptation speed\n        gamma_max = estimate_max_adaptation_rate(plant_params)  # Stability limit\n\n        bounds_lower = [2.0, 2.0, 5.0, 5.0, gamma_min]\n        bounds_upper = [40.0, 40.0, 25.0, 25.0, gamma_max]\n\n    else:  # hybrid_adaptive_sta_smc\n        # Hybrid controller bounds (conservative surface parameters)\n        bounds_lower = [2.0, 2.0, 5.0, 5.0]\n        bounds_upper = [30.0, 30.0, 20.0, 20.0]\n\n    return bounds_lower, bounds_upper\n\ndef estimate_min_switching_gain(plant_params: Dict[str, Any]) -> float:\n    \"\"\"Estimate minimum switching gain based on disturbance bounds.\"\"\"\n\n    # Extract disturbance characteristics\n    max_model_uncertainty = plant_params.get('model_uncertainty', 0.2)\n    max_external_disturbance = plant_params.get('external_disturbance', 5.0)\n    safety_margin = plant_params.get('safety_margin', 1.5)\n\n    # Conservative estimate\n    return (max_model_uncertainty + max_external_disturbance) * safety_margin\n\ndef estimate_lipschitz_constant(plant_params: Dict[str, Any]) -> float:\n    \"\"\"Estimate Lipschitz constant for STA design.\"\"\"\n\n    # Based on system nonlinearity and uncertainty bounds\n    max_nonlinearity = plant_params.get('max_nonlinearity', 10.0)\n    uncertainty_bound = plant_params.get('uncertainty_bound', 5.0)\n\n    return max_nonlinearity + uncertainty_bound\n\ndef estimate_max_adaptation_rate(plant_params: Dict[str, Any]) -> float:\n    \"\"\"Estimate maximum stable adaptation rate.\"\"\"\n\n    # Based on parameter variation speed and system bandwidth\n    system_bandwidth = plant_params.get('system_bandwidth', 10.0)  # rad/s\n    parameter_variation_rate = plant_params.get('parameter_variation_rate', 0.1)  # Hz\n\n    # Conservative bound: adaptation much slower than system dynamics\n    return min(system_bandwidth / 10.0, 1.0 / parameter_variation_rate)",
    "lines": 91,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0e8f364"
  },
  {
    "id": "enhanced_pso_integration_guide_10_107462cb",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 10,
    "code": "class PSO_ConvergenceDetector:\n    \"\"\"\n    Advanced convergence detection for PSO optimization.\n\n    Features:\n    - Multiple convergence criteria\n    - Statistical significance testing\n    - Plateau detection\n    - Diversity monitoring\n    \"\"\"\n\n    def __init__(self, patience: int = 20, tolerance: float = 1e-6):\n        self.patience = patience\n        self.tolerance = tolerance\n        self.fitness_history = []\n        self.diversity_history = []\n        self.best_fitness = float('inf')\n        self.stagnation_count = 0\n\n    def update(self, current_fitness: float, population_diversity: float) -> bool:\n        \"\"\"\n        Update convergence detector with current optimization state.\n\n        Returns:\n            True if convergence detected, False otherwise\n        \"\"\"\n\n        self.fitness_history.append(current_fitness)\n        self.diversity_history.append(population_diversity)\n\n        # Check for improvement\n        if current_fitness < self.best_fitness - self.tolerance:\n            self.best_fitness = current_fitness\n            self.stagnation_count = 0\n        else:\n            self.stagnation_count += 1\n\n        # Multiple convergence criteria\n        return (\n            self._check_fitness_plateau() or\n            self._check_diversity_collapse() or\n            self._check_statistical_convergence()\n        )\n\n    def _check_fitness_plateau(self) -> bool:\n        \"\"\"Check if fitness has plateaued.\"\"\"\n        return self.stagnation_count >= self.patience\n\n    def _check_diversity_collapse(self) -> bool:\n        \"\"\"Check if population diversity has collapsed.\"\"\"\n        if len(self.diversity_history) < 10:\n            return False\n\n        recent_diversity = np.mean(self.diversity_history[-10:])\n        return recent_diversity < 1e-8  # Very low diversity\n\n    def _check_statistical_convergence(self) -> bool:\n        \"\"\"Check statistical significance of convergence.\"\"\"\n        if len(self.fitness_history) < 30:\n            return False\n\n        # Test if recent improvements are statistically significant\n        recent_fitness = self.fitness_history[-15:]\n        older_fitness = self.fitness_history[-30:-15]\n\n        from scipy.stats import ttest_ind\n        statistic, p_value = ttest_ind(recent_fitness, older_fitness)\n\n        # If no significant difference, consider converged\n        return p_value > 0.05",
    "lines": 70,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "107462cb"
  },
  {
    "id": "enhanced_pso_integration_guide_11_377102e4",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 11,
    "code": "def robust_pso_optimization(\n    controller_type: str,\n    simulation_config: Any,\n    pso_config: Dict[str, Any],\n    error_handling_config: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"\n    Production-ready PSO optimization with comprehensive error handling.\n\n    Features:\n    - Graceful degradation for simulation failures\n    - Automatic retry mechanisms\n    - Fallback strategies for numerical instabilities\n    - Comprehensive logging and diagnostics\n    \"\"\"\n\n    import logging\n    import traceback\n    from contextlib import contextmanager\n\n    # Setup logging\n    logger = logging.getLogger('PSO_Optimization')\n\n    @contextmanager\n    def error_context(operation_name: str):\n        \"\"\"Context manager for operation-specific error handling.\"\"\"\n        try:\n            logger.info(f\"Starting {operation_name}\")\n            yield\n            logger.info(f\"Completed {operation_name}\")\n        except Exception as e:\n            logger.error(f\"Error in {operation_name}: {e}\")\n            logger.debug(traceback.format_exc())\n            raise\n\n    try:\n        with error_context(\"PSO Initialization\"):\n            # Initialize with validation\n            pso_interface = PSOFactoryInterface(controller_type, simulation_config)\n\n            # Validate PSO configuration\n            validate_pso_configuration(pso_config, pso_interface.n_gains)\n\n        with error_context(\"Fitness Function Setup\"):\n            # Create robust fitness function with fallbacks\n            fitness_function = create_robust_fitness_function(\n                pso_interface, simulation_config, error_handling_config\n            )\n\n        with error_context(\"PSO Execution\"):\n            # Run PSO with monitoring\n            result = run_monitored_pso_optimization(\n                fitness_function, pso_config, error_handling_config\n            )\n\n        with error_context(\"Result Validation\"):\n            # Validate optimization results\n            validated_result = validate_and_refine_result(\n                result, controller_type, simulation_config\n            )\n\n        return validated_result\n\n    except Exception as e:\n        logger.error(f\"PSO optimization failed: {e}\")\n\n        # Attempt fallback optimization\n        if error_handling_config.get('enable_fallback', True):\n            logger.info(\"Attempting fallback optimization\")\n            return fallback_optimization_strategy(\n                controller_type, simulation_config, pso_config\n            )\n        else:\n            raise\n\ndef create_robust_fitness_function(\n    pso_interface: PSOFactoryInterface,\n    simulation_config: Any,\n    error_config: Dict[str, Any]\n) -> Callable:\n    \"\"\"Create fitness function with comprehensive error handling.\"\"\"\n\n    max_retries = error_config.get('max_retries', 3)\n    timeout = error_config.get('simulation_timeout', 30.0)\n\n    def robust_fitness(particles: np.ndarray) -> np.ndarray:\n        \"\"\"Robust fitness evaluation with retries and timeouts.\"\"\"\n\n        fitness_scores = []\n\n        for particle in particles:\n            best_score = float('inf')\n\n            for retry in range(max_retries):\n                try:\n                    # Create controller with timeout\n                    with timeout_context(timeout):\n                        controller = pso_interface.create_controller(particle)\n\n                        # Run simulation with monitoring\n                        result = run_monitored_simulation(controller, simulation_config)\n\n                        # Compute fitness\n                        score = compute_robust_fitness(result, error_config)\n\n                        best_score = min(best_score, score)\n                        break  # Success, no need to retry\n\n                except TimeoutError:\n                    logger.warning(f\"Simulation timeout for particle {particle}\")\n                    continue\n                except Exception as e:\n                    logger.warning(f\"Simulation error (retry {retry}): {e}\")\n                    continue\n\n            fitness_scores.append(best_score)\n\n        return np.array(fitness_scores)\n\n    return robust_fitness",
    "lines": 120,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377102e4"
  },
  {
    "id": "enhanced_pso_integration_guide_12_a2f3fc35",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 12,
    "code": "class PSO_ProductionMonitor:\n    \"\"\"\n    Production monitoring system for PSO optimization workflows.\n\n    Features:\n    - Real-time performance metrics\n    - Resource utilization tracking\n    - Optimization progress visualization\n    - Alert system for anomalies\n    \"\"\"\n\n    def __init__(self, monitoring_config: Dict[str, Any]):\n        self.config = monitoring_config\n        self.metrics = {\n            'optimization_start_time': None,\n            'total_evaluations': 0,\n            'successful_evaluations': 0,\n            'failed_evaluations': 0,\n            'average_evaluation_time': 0.0,\n            'peak_memory_usage': 0.0,\n            'cpu_utilization': [],\n            'convergence_rate': 0.0\n        }\n\n    def start_optimization(self):\n        \"\"\"Initialize monitoring for new optimization run.\"\"\"\n        self.metrics['optimization_start_time'] = time.time()\n\n    def log_evaluation(self, success: bool, evaluation_time: float):\n        \"\"\"Log individual fitness evaluation.\"\"\"\n        self.metrics['total_evaluations'] += 1\n\n        if success:\n            self.metrics['successful_evaluations'] += 1\n        else:\n            self.metrics['failed_evaluations'] += 1\n\n        # Update average evaluation time\n        total_time = (self.metrics['average_evaluation_time'] *\n                     (self.metrics['total_evaluations'] - 1) + evaluation_time)\n        self.metrics['average_evaluation_time'] = total_time / self.metrics['total_evaluations']\n\n    def check_resource_usage(self):\n        \"\"\"Monitor system resource usage.\"\"\"\n        import psutil\n\n        # Memory usage\n        memory_info = psutil.virtual_memory()\n        self.metrics['peak_memory_usage'] = max(\n            self.metrics['peak_memory_usage'],\n            memory_info.percent\n        )\n\n        # CPU utilization\n        cpu_percent = psutil.cpu_percent(interval=1)\n        self.metrics['cpu_utilization'].append(cpu_percent)\n\n        # Check for resource alerts\n        if memory_info.percent > 90:\n            logger.warning(f\"High memory usage: {memory_info.percent}%\")\n\n        if cpu_percent > 95:\n            logger.warning(f\"High CPU usage: {cpu_percent}%\")\n\n    def generate_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive monitoring report.\"\"\"\n\n        if self.metrics['optimization_start_time'] is None:\n            return {'status': 'not_started'}\n\n        elapsed_time = time.time() - self.metrics['optimization_start_time']\n        success_rate = (self.metrics['successful_evaluations'] /\n                       self.metrics['total_evaluations'] * 100\n                       if self.metrics['total_evaluations'] > 0 else 0)\n\n        return {\n            'elapsed_time': elapsed_time,\n            'total_evaluations': self.metrics['total_evaluations'],\n            'success_rate': success_rate,\n            'average_evaluation_time': self.metrics['average_evaluation_time'],\n            'evaluations_per_second': self.metrics['total_evaluations'] / elapsed_time,\n            'peak_memory_usage': self.metrics['peak_memory_usage'],\n            'average_cpu_usage': np.mean(self.metrics['cpu_utilization']),\n            'status': 'running' if elapsed_time > 0 else 'completed'\n        }",
    "lines": 85,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a2f3fc35"
  },
  {
    "id": "enhanced_pso_integration_guide_13_95da8e0b",
    "file": "docs\\factory\\enhanced_pso_integration_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport yaml\n\n@dataclass\nclass PSO_OptimizationConfig:\n    \"\"\"\n    Complete configuration for PSO optimization workflows.\n\n    Provides type-safe configuration with validation and defaults.\n    \"\"\"\n\n    # Controller configuration\n    controller_type: str\n    controller_config: Dict[str, Any]\n\n    # PSO algorithm parameters\n    n_particles: int = 30\n    max_iterations: int = 100\n    c1: float = 2.0  # Cognitive component\n    c2: float = 2.0  # Social component\n    w: float = 0.9   # Inertia weight\n\n    # Optimization objectives\n    objectives: Dict[str, float] = None  # {'ise': 0.4, 'overshoot': 0.3, 'energy': 0.3}\n\n    # Performance settings\n    enable_parallel_evaluation: bool = True\n    n_threads: int = 4\n    enable_gpu_acceleration: bool = False\n\n    # Caching and persistence\n    enable_simulation_cache: bool = True\n    cache_size: int = 1000\n    save_intermediate_results: bool = True\n\n    # Error handling\n    max_retries: int = 3\n    simulation_timeout: float = 30.0\n    enable_fallback: bool = True\n\n    # Convergence detection\n    convergence_patience: int = 20\n    convergence_tolerance: float = 1e-6\n    enable_early_stopping: bool = True\n\n    # Monitoring and logging\n    enable_monitoring: bool = True\n    log_level: str = 'INFO'\n    save_optimization_history: bool = True\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after initialization.\"\"\"\n\n        # Set default objectives if not provided\n        if self.objectives is None:\n            self.objectives = {'ise': 0.5, 'overshoot': 0.3, 'settling_time': 0.2}\n\n        # Validate objectives sum to 1.0\n        if abs(sum(self.objectives.values()) - 1.0) > 1e-6:\n            raise ValueError(\"Objective weights must sum to 1.0\")\n\n        # Validate PSO parameters\n        if not (0 < self.c1 < 5 and 0 < self.c2 < 5):\n            raise ValueError(\"PSO cognitive/social parameters must be in (0, 5)\")\n\n        if not (0 < self.w < 1):\n            raise ValueError(\"PSO inertia weight must be in (0, 1)\")\n\n        # Validate controller type\n        valid_types = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n        if self.controller_type not in valid_types:\n            raise ValueError(f\"Controller type must be one of {valid_types}\")\n\ndef load_pso_config_from_yaml(config_path: str) -> PSO_OptimizationConfig:\n    \"\"\"Load PSO configuration from YAML file with validation.\"\"\"\n\n    with open(config_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Extract PSO-specific configuration\n    pso_config = config_dict.get('pso_optimization', {})\n\n    return PSO_OptimizationConfig(**pso_config)\n\ndef save_pso_config_to_yaml(config: PSO_OptimizationConfig, output_path: str) -> None:\n    \"\"\"Save PSO configuration to YAML file.\"\"\"\n\n    config_dict = {\n        'pso_optimization': {\n            'controller_type': config.controller_type,\n            'controller_config': config.controller_config,\n            'n_particles': config.n_particles,\n            'max_iterations': config.max_iterations,\n            'c1': config.c1,\n            'c2': config.c2,\n            'w': config.w,\n            'objectives': config.objectives,\n            # ... include all configuration fields\n        }\n    }\n\n    with open(output_path, 'w') as f:\n        yaml.dump(config_dict, f, default_flow_style=False, indent=2)",
    "lines": 107,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "95da8e0b"
  },
  {
    "id": "factory_api_reference_1_b03b6138",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 1,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[List[float], np.ndarray]] = None\n) -> Any",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b03b6138"
  },
  {
    "id": "factory_api_reference_2_12ed04af",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Basic controller creation\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\n# With configuration object\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\ncontroller = create_controller('adaptive_smc', config=config)\n\n# Using controller type aliases\ncontroller = create_controller('classic_smc', gains=[...])  # Alias for classical_smc",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "12ed04af"
  },
  {
    "id": "factory_api_reference_3_edb74eda",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef list_available_controllers() -> List[str]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "edb74eda"
  },
  {
    "id": "factory_api_reference_4_9496e4f3",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 4,
    "code": "available = list_available_controllers()\nprint(available)\n# Output: ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9496e4f3"
  },
  {
    "id": "factory_api_reference_5_4a447d2f",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_default_gains(controller_type: str) -> List[float]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a447d2f"
  },
  {
    "id": "factory_api_reference_6_1d859873",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 6,
    "code": "defaults = get_default_gains('classical_smc')\nprint(defaults)\n# Output: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1d859873"
  },
  {
    "id": "factory_api_reference_7_74f68610",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    def compute_control(\n        self,\n        state: StateVector,\n        last_control: float,\n        history: ConfigDict\n    ) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...\n\n    def reset(self) -> None:\n        \"\"\"Reset controller internal state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "74f68610"
  },
  {
    "id": "factory_api_reference_8_628a0b58",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 8,
    "code": "StateVector = NDArray[np.float64]        # 6-element state vector [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\nControlOutput = Union[float, NDArray[np.float64]]  # Scalar or array control output\nGainsArray = Union[List[float], NDArray[np.float64]]  # Controller gains\nConfigDict = Dict[str, Any]              # Configuration dictionary",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "628a0b58"
  },
  {
    "id": "factory_api_reference_9_60f5d269",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 9,
    "code": "classical_params = {\n    'gains': List[float],           # [k1, k2, \u03bb1, \u03bb2, K, kd] - 6 elements\n    'max_force': float,             # Maximum control force [N]\n    'boundary_layer': float,        # Boundary layer thickness\n    'dt': float                     # Time step [s]\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60f5d269"
  },
  {
    "id": "factory_api_reference_10_6c693b55",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 10,
    "code": "controller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c693b55"
  },
  {
    "id": "factory_api_reference_11_727cf38f",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 11,
    "code": "sta_params = {\n    'gains': List[float],           # [K1, K2, k1, k2, \u03bb1, \u03bb2] - 6 elements\n    'max_force': float,             # Maximum control force [N]\n    'dt': float,                    # Time step [s]\n    'power_exponent': float,        # Super-twisting power (typically 0.5)\n    'regularization': float,        # Numerical regularization\n    'boundary_layer': float,        # Boundary layer thickness\n    'switch_method': str            # Switching function ('tanh', 'sign', 'linear')\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "727cf38f"
  },
  {
    "id": "factory_api_reference_12_013ea8a0",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 12,
    "code": "controller = create_controller(\n    'sta_smc',\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n    max_force=150.0,\n    dt=0.001,\n    power_exponent=0.5,\n    regularization=1e-6,\n    switch_method='tanh'\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "013ea8a0"
  },
  {
    "id": "factory_api_reference_13_2f000d74",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nadaptive_params = {\n    'gains': List[float],           # [k1, k2, \u03bb1, \u03bb2, \u03b3] - 5 elements\n    'max_force': float,             # Maximum control force [N]\n    'dt': float,                    # Time step [s]\n    'leak_rate': float,             # Adaptation leak rate\n    'adapt_rate_limit': float,      # Maximum adaptation rate\n    'K_min': float,                 # Minimum switching gain\n    'K_max': float,                 # Maximum switching gain\n    'K_init': float,                # Initial switching gain\n    'alpha': float,                 # Adaptation law parameter\n    'boundary_layer': float,        # Boundary layer thickness\n    'smooth_switch': bool           # Enable smooth switching\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2f000d74"
  },
  {
    "id": "factory_api_reference_14_f9434444",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ncontroller = create_controller(\n    'adaptive_smc',\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.01,\n    adapt_rate_limit=10.0,\n    K_min=0.1,\n    K_max=100.0,\n    alpha=0.5\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9434444"
  },
  {
    "id": "factory_api_reference_15_68f33d5c",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 15,
    "code": "hybrid_params = {\n    'gains': List[float],           # [k1, k2, \u03bb1, \u03bb2] - 4 surface gains\n    'hybrid_mode': HybridMode,      # Hybrid mode enumeration\n    'max_force': float,             # Maximum control force [N]\n    'dt': float,                    # Time step [s]\n    'classical_config': ClassicalSMCConfig,  # Sub-controller configuration\n    'adaptive_config': AdaptiveSMCConfig     # Sub-controller configuration\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68f33d5c"
  },
  {
    "id": "factory_api_reference_16_441f953e",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 16,
    "code": "from src.controllers.smc.algorithms.hybrid.config import HybridMode\n\ncontroller = create_controller(\n    'hybrid_adaptive_sta_smc',\n    gains=[18.0, 12.0, 10.0, 8.0],\n    hybrid_mode=HybridMode.CLASSICAL_ADAPTIVE,\n    max_force=150.0,\n    dt=0.001\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "441f953e"
  },
  {
    "id": "factory_api_reference_17_d408b379",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 17,
    "code": "def create_pso_controller_factory(\n    smc_type: SMCType,\n    plant_config: Optional[Any] = None,\n    **kwargs: Any\n) -> Callable[[Union[List[float], np.ndarray]], Any]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d408b379"
  },
  {
    "id": "factory_api_reference_18_1f78f1c2",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 18,
    "code": "from src.controllers.factory import SMCType, create_pso_controller_factory\n\n# Create PSO factory for classical SMC\nfactory_func = create_pso_controller_factory(\n    SMCType.CLASSICAL,\n    max_force=150.0,\n    boundary_layer=0.02\n)\n\n# Use in PSO optimization\noptimized_gains = pso_optimizer.optimize(factory_func)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f78f1c2"
  },
  {
    "id": "factory_api_reference_19_dcff5d8b",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcff5d8b"
  },
  {
    "id": "factory_api_reference_20_33c73762",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 20,
    "code": "from src.controllers.factory import SMCType, get_gain_bounds_for_pso\n\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nlower, upper = bounds\nprint(f\"Lower bounds: {lower}\")\nprint(f\"Upper bounds: {upper}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33c73762"
  },
  {
    "id": "factory_api_reference_21_ed04e733",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_gains(smc_type: SMCType, gains: Union[List[float], np.ndarray]) -> bool",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed04e733"
  },
  {
    "id": "factory_api_reference_22_93bc5b88",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 22,
    "code": "from src.controllers.factory import SMCType, validate_smc_gains\n\ngains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, gains)\nprint(f\"Gains valid: {is_valid}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93bc5b88"
  },
  {
    "id": "factory_api_reference_23_ce479edc",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 23,
    "code": "class SMCType(Enum):\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce479edc"
  },
  {
    "id": "factory_api_reference_24_87347bbb",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 24,
    "code": "from src.controllers.factory import SMCType\n\n# Type-safe controller specification\ncontroller_type = SMCType.CLASSICAL\nfactory_func = create_pso_controller_factory(controller_type)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87347bbb"
  },
  {
    "id": "factory_api_reference_25_841f336f",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 25,
    "code": "@dataclass\nclass SMCConfig:\n    gains: List[float]\n    max_force: float = 150.0\n    dt: float = 0.001\n    **kwargs: Any",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "841f336f"
  },
  {
    "id": "factory_api_reference_26_c67c621f",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 26,
    "code": "from src.controllers.factory import SMCConfig\n\nconfig = SMCConfig(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0,\n    boundary_layer=0.02\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c67c621f"
  },
  {
    "id": "factory_api_reference_27_2ac8eb21",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 27,
    "code": "def check_deprecated_config(\n    controller_type: str,\n    config_params: Dict[str, Any]\n) -> Dict[str, Any]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ac8eb21"
  },
  {
    "id": "factory_api_reference_28_86aa4d6c",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 28,
    "code": "from src.controllers.factory.deprecation import check_deprecated_config\n\nold_config = {\n    'switch_function': 'sign',  # Old parameter name\n    'gamma': 0.1  # Invalid for classical SMC\n}\n\nmigrated_config = check_deprecated_config('classical_smc', old_config)\n# Result: {'switch_method': 'sign'}\n# Warning: Removed invalid 'gamma' parameter",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "86aa4d6c"
  },
  {
    "id": "factory_api_reference_29_d54c1d69",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_controller_migration_guide(controller_type: str) -> List[str]",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d54c1d69"
  },
  {
    "id": "factory_api_reference_30_17f2a988",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 30,
    "code": "from src.controllers.factory.deprecation import get_controller_migration_guide\n\nguide = get_controller_migration_guide('classical_smc')\nfor instruction in guide:\n    print(f\"- {instruction}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17f2a988"
  },
  {
    "id": "factory_api_reference_31_5f3c1a5c",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 31,
    "code": "import threading\nfrom src.controllers.factory import create_controller\n\ndef worker_thread(thread_id):\n    \"\"\"Thread-safe controller creation.\"\"\"\n    controller = create_controller(\n        'classical_smc',\n        gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n    )\n    # Each thread gets independent controller instance\n    return controller\n\n# Safe concurrent execution\nthreads = []\nfor i in range(10):\n    thread = threading.Thread(target=worker_thread, args=(i,))\n    threads.append(thread)\n    thread.start()\n\nfor thread in threads:\n    thread.join()",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5f3c1a5c"
  },
  {
    "id": "factory_api_reference_32_6a21102a",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\n# Factory-specific exceptions\nValueError:\n  \u251c\u2500\u2500 Unknown controller type\n  \u251c\u2500\u2500 Invalid parameter count\n  \u251c\u2500\u2500 Invalid parameter values\n  \u2514\u2500\u2500 Configuration validation errors\n\nImportError:\n  \u251c\u2500\u2500 Missing controller dependencies\n  \u2514\u2500\u2500 Optional feature unavailable\n\nTimeoutError:\n  \u2514\u2500\u2500 Thread lock acquisition timeout",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a21102a"
  },
  {
    "id": "factory_api_reference_33_559c16a0",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 33,
    "code": "from src.controllers.factory import create_controller, get_default_gains\n\ndef robust_controller_creation(controller_type, gains=None):\n    \"\"\"Robust controller creation with error recovery.\"\"\"\n\n    try:\n        return create_controller(controller_type, gains=gains)\n\n    except ValueError as e:\n        if \"gains\" in str(e):\n            # Use default gains on validation error\n            default_gains = get_default_gains(controller_type)\n            return create_controller(controller_type, gains=default_gains)\n        else:\n            raise\n\n    except ImportError:\n        # Fallback to basic controller type\n        return create_controller('classical_smc', gains=gains)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "559c16a0"
  },
  {
    "id": "factory_api_reference_34_c99d0486",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 34,
    "code": "# Optimized batch controller creation\nimport concurrent.futures\nfrom src.controllers.factory import create_controller\n\ndef create_controllers_optimized(controller_specs):\n    \"\"\"Optimized parallel controller creation.\"\"\"\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n        futures = {\n            executor.submit(create_controller, **spec): name\n            for name, spec in controller_specs.items()\n        }\n\n        controllers = {}\n        for future in concurrent.futures.as_completed(futures):\n            name = futures[future]\n            try:\n                controllers[name] = future.result(timeout=30)\n            except Exception as e:\n                print(f\"Failed to create {name}: {e}\")\n\n        return controllers",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c99d0486"
  },
  {
    "id": "factory_api_reference_35_2716ffff",
    "file": "docs\\factory\\factory_api_reference.md",
    "index": 35,
    "code": "from src.controllers.factory import (\n    create_controller,\n    SMCType,\n    get_gain_bounds_for_pso,\n    create_pso_controller_factory\n)\nfrom src.optimizer.pso_optimizer import PSOTuner\n\n# 1. Create initial controller\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\n# 2. Set up PSO optimization\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nfactory_func = create_pso_controller_factory(SMCType.CLASSICAL)\n\ntuner = PSOTuner(\n    controller_factory=factory_func,\n    bounds=bounds,\n    n_particles=20,\n    max_iterations=200\n)\n\n# 3. Optimize controller gains\noptimized_gains, best_cost = tuner.optimize()\n\n# 4. Create optimized controller\noptimized_controller = create_controller(\n    'classical_smc',\n    gains=optimized_gains\n)\n\nprint(f\"Optimization improved cost from {initial_cost} to {best_cost}\")",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2716ffff"
  },
  {
    "id": "factory_integration_user_guide_1_abd8cb80",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\n# Classical SMC with enhanced validation\ncontroller = create_controller(\n    controller_type='classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]  # All 6 gains required\n)\n\n# Super-Twisting SMC with automatic parameter handling\nsta_controller = create_controller(\n    controller_type='sta_smc',\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0]  # K1, K2, k1, k2, \u03bb1, \u03bb2\n)\n\n# Adaptive SMC with gamma included in gains\nadaptive_controller = create_controller(\n    controller_type='adaptive_smc',\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0]  # k1, k2, \u03bb1, \u03bb2, \u03b3\n)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abd8cb80"
  },
  {
    "id": "factory_integration_user_guide_2_49a5a1c1",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 2,
    "code": "from src.config import load_config\nfrom src.controllers.factory import create_controller\n\n# Load configuration with enhanced validation\nconfig = load_config(\"config.yaml\")\n\n# Create controller using configuration\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config  # Factory extracts parameters automatically\n)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49a5a1c1"
  },
  {
    "id": "factory_integration_user_guide_3_437dcc4f",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 3,
    "code": "import threading\nfrom src.controllers.factory import create_controller\n\ndef create_controllers_concurrently():\n    \"\"\"Safe concurrent controller creation.\"\"\"\n    controllers = []\n\n    def worker(controller_type, gains):\n        # Thread-safe factory operations\n        controller = create_controller(controller_type, gains=gains)\n        controllers.append(controller)\n\n    # Multiple threads can safely use the factory\n    threads = []\n    for i in range(10):\n        thread = threading.Thread(\n            target=worker,\n            args=('classical_smc', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n        )\n        threads.append(thread)\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    return controllers",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "437dcc4f"
  },
  {
    "id": "factory_integration_user_guide_4_05323777",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 4,
    "code": "classical_config = {\n    'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    'max_force': 150.0,\n    'boundary_layer': 0.02,\n    'dt': 0.001\n}\n\ncontroller = create_controller('classical_smc', **classical_config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "05323777"
  },
  {
    "id": "factory_integration_user_guide_5_ad5ef474",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nsta_config = {\n    'gains': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0],\n    'max_force': 150.0,\n    'dt': 0.001,\n    'power_exponent': 0.5,\n    'regularization': 1e-6,\n    'boundary_layer': 0.01,\n    'switch_method': 'tanh'\n}\n\ncontroller = create_controller('sta_smc', **sta_config)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad5ef474"
  },
  {
    "id": "factory_integration_user_guide_6_892489e2",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nadaptive_config = {\n    'gains': [25.0, 18.0, 15.0, 10.0, 4.0],\n    'max_force': 150.0,\n    'dt': 0.001,\n    'leak_rate': 0.01,\n    'adapt_rate_limit': 10.0,\n    'K_min': 0.1,\n    'K_max': 100.0,\n    'alpha': 0.5\n}\n\ncontroller = create_controller('adaptive_smc', **adaptive_config)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "892489e2"
  },
  {
    "id": "factory_integration_user_guide_7_dd487f59",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 7,
    "code": "from src.controllers.smc.algorithms.hybrid.config import HybridMode\n\nhybrid_config = {\n    'gains': [18.0, 12.0, 10.0, 8.0],  # Surface gains only\n    'hybrid_mode': HybridMode.CLASSICAL_ADAPTIVE,\n    'max_force': 150.0,\n    'dt': 0.001\n}\n\ncontroller = create_controller('hybrid_adaptive_sta_smc', **hybrid_config)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd487f59"
  },
  {
    "id": "factory_integration_user_guide_8_99f56e40",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 8,
    "code": "from src.optimization.integration.pso_factory_bridge import create_pso_controller_factory\nfrom src.controllers.factory import SMCType\n\n# Create PSO-optimized factory for Classical SMC\nfactory_func = create_pso_controller_factory(\n    smc_type=SMCType.CLASSICAL,\n    max_force=150.0,\n    boundary_layer=0.02\n)\n\n# PSO optimization with enhanced factory\nfrom src.optimizer.pso_optimizer import PSOTuner\n\nbounds = [(1.0, 30.0), (1.0, 30.0), (1.0, 20.0),\n          (1.0, 20.0), (5.0, 50.0), (0.1, 10.0)]\n\ntuner = PSOTuner(\n    controller_factory=factory_func,\n    bounds=bounds,\n    n_particles=20,\n    max_iterations=200\n)\n\n# Optimized gains with improved reliability\noptimized_gains, best_cost = tuner.optimize()",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "99f56e40"
  },
  {
    "id": "factory_integration_user_guide_9_c247c85b",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 9,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType\n\n# Automatic bounds for different controller types\nclassical_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nadaptive_bounds = get_gain_bounds_for_pso(SMCType.ADAPTIVE)\nsta_bounds = get_gain_bounds_for_pso(SMCType.SUPER_TWISTING)\n\nprint(f\"Classical SMC bounds: {classical_bounds}\")\n# Output: ([1.0, 1.0, 1.0, 1.0, 5.0, 0.1], [30.0, 30.0, 20.0, 20.0, 50.0, 10.0])",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c247c85b"
  },
  {
    "id": "factory_integration_user_guide_10_0091e55d",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 10,
    "code": "from src.controllers.factory import create_controller\n\ntry:\n    # Invalid gains array (wrong length)\n    controller = create_controller(\n        'classical_smc',\n        gains=[10.0, 5.0, 8.0]  # Only 3 gains instead of 6\n    )\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n    # Output: Controller 'Classical sliding mode controller' requires 6 gains, got 3\n\ntry:\n    # Invalid parameter values\n    controller = create_controller(\n        'adaptive_smc',\n        gains=[25.0, 18.0, 15.0, 10.0, -2.0]  # Negative gamma\n    )\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n    # Output: All gains must be positive",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0091e55d"
  },
  {
    "id": "factory_integration_user_guide_11_3ac77e99",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 11,
    "code": "from src.controllers.factory.deprecation import check_deprecated_config\n\n# Automatic migration of deprecated parameters\nold_config = {\n    'gamma': 0.1,  # Invalid for classical SMC\n    'switch_function': 'sign',  # Old parameter name\n    'K_switching': 2.0  # Separate switching gain\n}\n\n# Migrate deprecated parameters\nmigrated_config = check_deprecated_config('classical_smc', old_config)\nprint(\"Migrated config:\", migrated_config)\n# Output: Migrated config: {'switch_method': 'sign'}\n# Warning: Removed invalid 'gamma' parameter for classical_smc",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ac77e99"
  },
  {
    "id": "factory_integration_user_guide_12_032627a3",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 12,
    "code": "from src.controllers.factory import create_controller, list_available_controllers\n\nclass AdaptiveControllerManager:\n    \"\"\"Dynamically switch between controller types based on performance.\"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        self.controllers = {}\n        self.current_controller = None\n\n        # Pre-create all available controllers\n        for controller_type in list_available_controllers():\n            try:\n                self.controllers[controller_type] = create_controller(\n                    controller_type, config=config\n                )\n            except Exception as e:\n                print(f\"Failed to create {controller_type}: {e}\")\n\n    def select_best_controller(self, performance_metrics):\n        \"\"\"Select controller based on performance metrics.\"\"\"\n        best_type = self._evaluate_performance(performance_metrics)\n        self.current_controller = self.controllers[best_type]\n        return self.current_controller\n\n    def _evaluate_performance(self, metrics):\n        # Implementation specific to performance criteria\n        pass",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "032627a3"
  },
  {
    "id": "factory_integration_user_guide_13_c34dd024",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 13,
    "code": "from src.controllers.factory import create_controller\n\ndef create_controller_ensemble(gains_dict, config):\n    \"\"\"Create multiple controllers for ensemble methods.\"\"\"\n\n    controllers = {}\n\n    for controller_type, gains in gains_dict.items():\n        try:\n            controllers[controller_type] = create_controller(\n                controller_type=controller_type,\n                config=config,\n                gains=gains\n            )\n            print(f\"\u2713 Created {controller_type} successfully\")\n        except Exception as e:\n            print(f\"\u2717 Failed to create {controller_type}: {e}\")\n\n    return controllers\n\n# Example usage\ngains_ensemble = {\n    'classical_smc': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    'adaptive_smc': [25.0, 18.0, 15.0, 10.0, 4.0],\n    'sta_smc': [25.0, 15.0, 20.0, 12.0, 8.0, 6.0]\n}\n\nensemble = create_controller_ensemble(gains_ensemble, config)",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c34dd024"
  },
  {
    "id": "factory_integration_user_guide_14_63b51549",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Good: Complete parameter specification\ncontroller_config = {\n    'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    'max_force': 150.0,\n    'boundary_layer': 0.02,\n    'dt': 0.001\n}\n\n# Avoid: Relying on implicit defaults\ncontroller_config = {\n    'gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n    # Missing required parameters\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "63b51549"
  },
  {
    "id": "factory_integration_user_guide_15_17c4dcc8",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 15,
    "code": "from typing import List\nfrom dataclasses import dataclass\n\n@dataclass\nclass ControllerConfig:\n    gains: List[float]\n    max_force: float = 150.0\n    dt: float = 0.001\n    boundary_layer: float = 0.02\n\n# Type-safe configuration\nconfig = ControllerConfig(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17c4dcc8"
  },
  {
    "id": "factory_integration_user_guide_16_68dfbc2d",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 16,
    "code": "from src.controllers.factory import create_controller\n\ndef safe_controller_creation(controller_type, gains, config):\n    \"\"\"Validate parameters before creating controller.\"\"\"\n\n    # Pre-validation\n    if not isinstance(gains, (list, tuple)):\n        raise ValueError(\"Gains must be a list or tuple\")\n\n    if not all(isinstance(g, (int, float)) for g in gains):\n        raise ValueError(\"All gains must be numeric\")\n\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive\")\n\n    # Create controller after validation\n    return create_controller(\n        controller_type=controller_type,\n        config=config,\n        gains=gains\n    )",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68dfbc2d"
  },
  {
    "id": "factory_integration_user_guide_17_66187ea5",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 17,
    "code": "# Good: Reuse controllers when possible\ncontroller_cache = {}\n\ndef get_or_create_controller(controller_type, gains, config):\n    cache_key = (controller_type, tuple(gains))\n\n    if cache_key not in controller_cache:\n        controller_cache[cache_key] = create_controller(\n            controller_type, config=config, gains=gains\n        )\n\n    return controller_cache[cache_key]",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "66187ea5"
  },
  {
    "id": "factory_integration_user_guide_18_9a318b74",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nclass LazyControllerEnsemble:\n    \"\"\"Lazy-loaded controller ensemble for memory efficiency.\"\"\"\n\n    def __init__(self, controller_specs, config):\n        self.specs = controller_specs\n        self.config = config\n        self._controllers = {}\n\n    def get_controller(self, controller_type):\n        if controller_type not in self._controllers:\n            spec = self.specs[controller_type]\n            self._controllers[controller_type] = create_controller(\n                controller_type, config=self.config, **spec\n            )\n        return self._controllers[controller_type]",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a318b74"
  },
  {
    "id": "factory_integration_user_guide_19_e576398a",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 19,
    "code": "import concurrent.futures\nfrom src.controllers.factory import create_controller\n\ndef create_controllers_parallel(controller_specs, config, max_workers=4):\n    \"\"\"Create multiple controllers in parallel.\"\"\"\n\n    def create_single(spec):\n        controller_type, params = spec\n        return create_controller(controller_type, config=config, **params)\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = [\n            executor.submit(create_single, spec)\n            for spec in controller_specs.items()\n        ]\n\n        controllers = {}\n        for future, (controller_type, _) in zip(futures, controller_specs.items()):\n            try:\n                controllers[controller_type] = future.result(timeout=30)\n            except Exception as e:\n                print(f\"Failed to create {controller_type}: {e}\")\n\n    return controllers",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e576398a"
  },
  {
    "id": "factory_integration_user_guide_20_dafc01a7",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 20,
    "code": "import logging\nfrom src.controllers.factory import create_controller\n\n# Enable factory debug logging\nlogging.getLogger('src.controllers.factory').setLevel(logging.DEBUG)\n\n# Create controller with detailed logging\ncontroller = create_controller('classical_smc', gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dafc01a7"
  },
  {
    "id": "factory_integration_user_guide_21_25ff4780",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 21,
    "code": "from src.controllers.factory.core.validation import validate_controller_parameters\n\n# Detailed parameter validation\nvalidation_result = validate_controller_parameters(\n    controller_type='classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    max_force=150.0\n)\n\nif not validation_result.is_valid:\n    print(\"Validation issues:\")\n    for issue in validation_result.issues:\n        print(f\"  - {issue}\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25ff4780"
  },
  {
    "id": "factory_integration_user_guide_22_19c872e8",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 22,
    "code": "from src.controllers.factory import (\n    CONTROLLER_REGISTRY,\n    list_available_controllers,\n    get_default_gains\n)\n\n# Inspect available controllers\nprint(\"Available controllers:\", list_available_controllers())\n\n# Get controller specifications\nfor controller_type in list_available_controllers():\n    info = CONTROLLER_REGISTRY[controller_type]\n    print(f\"{controller_type}:\")\n    print(f\"  Description: {info['description']}\")\n    print(f\"  Gain count: {info['gain_count']}\")\n    print(f\"  Default gains: {get_default_gains(controller_type)}\")\n    print()",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19c872e8"
  },
  {
    "id": "factory_integration_user_guide_23_c3298c7f",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 23,
    "code": "# Check required gain count\nfrom src.controllers.factory import CONTROLLER_REGISTRY\n\ncontroller_type = 'classical_smc'\nrequired_count = CONTROLLER_REGISTRY[controller_type]['gain_count']\nprint(f\"{controller_type} requires {required_count} gains\")\n\n# Provide correct number of gains\ngains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]  # 6 gains for classical SMC",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3298c7f"
  },
  {
    "id": "factory_integration_user_guide_24_21c56942",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 24,
    "code": "# Validate gains before use\ndef validate_gains(gains):\n    if any(g <= 0 for g in gains):\n        raise ValueError(\"All gains must be positive\")\n    return gains\n\nvalidated_gains = validate_gains([20.0, 15.0, 12.0, 8.0, 35.0, 5.0])",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21c56942"
  },
  {
    "id": "factory_integration_user_guide_25_28dcee11",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe controller creation\nimport threading\n\ndef thread_safe_creation():\n    # Each thread creates its own controller instance\n    controller = create_controller('classical_smc', gains=[...])\n    return controller\n\n# Multiple threads can safely call the factory\nthreads = [\n    threading.Thread(target=thread_safe_creation)\n    for _ in range(10)\n]",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28dcee11"
  },
  {
    "id": "factory_integration_user_guide_26_b7d06413",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 26,
    "code": "from src.controllers.factory.deprecation import check_deprecated_config\n\n# Migrate old configuration format\nold_config = {\n    'K_switching': 2.0,\n    'gamma': 0.1,  # Invalid for classical SMC\n    'switch_function': 'sign'\n}\n\n# Automatic migration with warnings\nmigrated_config = check_deprecated_config('classical_smc', old_config)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b7d06413"
  },
  {
    "id": "factory_integration_user_guide_27_ecdc86ff",
    "file": "docs\\factory\\factory_integration_user_guide.md",
    "index": 27,
    "code": "# Legacy function names still work\nfrom src.controllers.factory import (\n    create_classical_smc_controller,  # Backward compatibility\n    create_controller  # Preferred new interface\n)\n\n# Both work identically\nlegacy_controller = create_classical_smc_controller(\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\nmodern_controller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ecdc86ff"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_1_155aeb85",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import Protocol\nimport numpy as np\n\nclass SMCProtocol(Protocol):\n    \"\"\"Type-safe protocol for all SMC controllers.\"\"\"\n\n    def compute_control(self,\n                       state: np.ndarray,\n                       state_vars: Any,\n                       history: Dict[str, Any]) -> Any:\n        \"\"\"Compute control input for given state.\"\"\"\n        ...\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"\n        ...",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "155aeb85"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_2_684a89e4",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 2,
    "code": "def validate_smc_gains(smc_type: SMCType, gains: List[float]) -> bool:\n    \"\"\"\n    Validate SMC gains based on control theory constraints.\n\n    Mathematical Constraints:\n    - Classical SMC: All surface gains \u03bb\u1d62 > 0 for stability\n    - Super-Twisting: K\u2081 > K\u2082 > 0 for finite-time convergence\n    - Adaptive SMC: 0.1 \u2264 \u03b3 \u2264 20.0 for bounded adaptation\n    - Hybrid SMC: Surface parameters > 0 for stability\n    \"\"\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "684a89e4"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_3_ebeec1e1",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 3,
    "code": "@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    gains: List[float]  # [k1, k2, \u03bb1, \u03bb2, K, kd]\n\n    def __post_init__(self) -> None:\n        # Mathematical constraint validation\n        if any(g <= 0 for g in self.gains[:5]):\n            raise ValueError(\"Classical SMC stability requires \u03bb\u1d62 > 0, K > 0\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ebeec1e1"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_4_40a2690f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 4,
    "code": "def validate_sta_gains(gains: List[float]) -> bool:\n    \"\"\"Validate super-twisting stability constraints.\"\"\"\n    K1, K2 = gains[0], gains[1]\n    return K1 > K2 > 0  # Critical constraint for convergence",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40a2690f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_5_4d3c59e9",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_lyapunov_stability(controller_type: SMCType,\n                             gains: List[float]) -> bool:\n    \"\"\"\n    Verify Lyapunov stability conditions for SMC controller.\n\n    Uses candidate Lyapunov function V = (1/2)s\u00b2 and verifies:\n    V\u0307 \u2264 -\u03b7|s| for some \u03b7 > 0\n    \"\"\"\n    if controller_type == SMCType.CLASSICAL:\n        # Classical SMC: V\u0307 = s(-K\u00b7sign(s) + \u03b4) \u2264 -\u03b7|s|\n        K = gains[4]  # Switching gain\n        return K > estimate_uncertainty_bound(gains)\n\n    elif controller_type == SMCType.SUPER_TWISTING:\n        # STA: Verify K\u2081 > K\u2082 and sufficient gain margins\n        K1, K2 = gains[0], gains[1]\n        return K1 > K2 and K1 > estimate_lipschitz_constant()",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d3c59e9"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_6_4c615fac",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCFactory:\n    \"\"\"\n    Type-safe factory for creating SMC controllers.\n\n    Provides unified interface for all 4 core SMC types with:\n    - Mathematical constraint validation\n    - Performance optimization\n    - PSO integration support\n    - Configuration management\n    \"\"\"\n\n    @staticmethod\n    def create_controller(smc_type: SMCType,\n                         config: SMCConfig) -> SMCProtocol:\n        \"\"\"\n        Create SMC controller with validation and optimization.\n\n        Args:\n            smc_type: Controller type from SMCType enum\n            config: Type-safe configuration object\n\n        Returns:\n            Initialized SMC controller implementing SMCProtocol\n\n        Raises:\n            ValueError: If gains violate mathematical constraints\n            FactoryConfigurationError: If configuration is invalid\n        \"\"\"\n        # Validate mathematical constraints\n        if not validate_smc_gains(smc_type, config.gains):\n            raise ValueError(f\"Gains violate stability constraints for {smc_type}\")\n\n        # Create controller based on type\n        controller_map = {\n            SMCType.CLASSICAL: ClassicalSMC,\n            SMCType.ADAPTIVE: AdaptiveSMC,\n            SMCType.SUPER_TWISTING: SuperTwistingSMC,\n            SMCType.HYBRID: HybridAdaptiveSTASMC\n        }\n\n        controller_class = controller_map[smc_type]\n        return controller_class(**config.to_controller_params())",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c615fac"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_7_dc2e959d",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(smc_type: SMCType,\n                      gains: List[float],\n                      max_force: float = 100.0,\n                      dt: float = 0.01) -> PSOControllerWrapper:\n    \"\"\"\n    PSO-optimized controller creation with simplified interface.\n\n    This function provides the optimal interface for PSO fitness functions:\n    - Single-line controller creation\n    - Automatic parameter validation\n    - Performance-optimized wrapper\n    - Error handling for invalid gains\n\n    Mathematical Foundation:\n    Each controller type has specific gain requirements:\n    - Classical: [k1, k2, \u03bb1, \u03bb2, K, kd] with \u03bb\u1d62 > 0, K > 0\n    - STA: [K1, K2, \u03bb1, \u03bb2, \u03b11, \u03b12] with K1 > K2 > 0\n    - Adaptive: [k1, k2, \u03bb1, \u03bb2, \u03b3] with 0.1 \u2264 \u03b3 \u2264 20.0\n    - Hybrid: [k1, k2, \u03bb1, \u03bb2] with surface gains > 0\n\n    PSO Integration Example:",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dc2e959d"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_8_40a8dd4f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> List[Tuple[float, float]]:\n    \"\"\"\n    Get PSO optimization bounds based on control theory.\n\n    Bounds are derived from:\n    - Stability requirements (Lyapunov conditions)\n    - Performance constraints (settling time, overshoot)\n    - Physical limitations (actuator saturation)\n    - Practical implementation limits\n\n    Mathematical Derivation:\n\n    Classical SMC Bounds:\n    - Surface gains \u03bb\u1d62: [1.0, 50.0] based on desired bandwidth\n    - Position gains k\u1d62: [0.1, 50.0] for reasonable pole placement\n    - Switching gain K: [1.0, 200.0] for disturbance rejection\n    - Damping gain kd: [0.0, 50.0] for chattering reduction\n\n    Super-Twisting Bounds:\n    - K1: [2.0, 100.0] with constraint K1 > K2\n    - K2: [1.0, 99.0] ensuring convergence condition\n    - Surface gains: [1.0, 50.0] for stability\n\n    Adaptive SMC Bounds:\n    - Surface gains: [1.0, 50.0] for stability\n    - Adaptation rate \u03b3: [0.1, 20.0] for bounded adaptation\n\n    Returns:\n        List of (lower_bound, upper_bound) tuples for each gain\n    \"\"\"\n    bounds_map = {\n        SMCType.CLASSICAL: [\n            (0.1, 50.0),   # k1: position gain pendulum 1\n            (0.1, 50.0),   # k2: position gain pendulum 2\n            (1.0, 50.0),   # \u03bb1: surface gain pendulum 1\n            (1.0, 50.0),   # \u03bb2: surface gain pendulum 2\n            (1.0, 200.0),  # K: switching gain\n            (0.0, 50.0)    # kd: damping gain\n        ],\n\n        SMCType.SUPER_TWISTING: [\n            (2.0, 100.0),  # K1: primary twisting gain (K1 > K2)\n            (1.0, 99.0),   # K2: secondary twisting gain\n            (1.0, 50.0),   # \u03bb1: surface gain pendulum 1\n            (1.0, 50.0),   # \u03bb2: surface gain pendulum 2\n            (1.0, 50.0),   # \u03b11: higher-order surface gain 1\n            (1.0, 50.0)    # \u03b12: higher-order surface gain 2\n        ],\n\n        SMCType.ADAPTIVE: [\n            (0.1, 50.0),   # k1: position gain pendulum 1\n            (0.1, 50.0),   # k2: position gain pendulum 2\n            (1.0, 50.0),   # \u03bb1: surface gain pendulum 1\n            (1.0, 50.0),   # \u03bb2: surface gain pendulum 2\n            (0.1, 20.0)    # \u03b3: adaptation rate\n        ],\n\n        SMCType.HYBRID: [\n            (1.0, 50.0),   # k1: surface gain pendulum 1\n            (1.0, 50.0),   # k2: surface gain pendulum 2\n            (1.0, 50.0),   # \u03bb1: surface gain 1\n            (1.0, 50.0)    # \u03bb2: surface gain 2\n        ]\n    }\n\n    return bounds_map[smc_type]",
    "lines": 69,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40a8dd4f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_9_b12bc7c1",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 9,
    "code": "def optimize_smc_with_factory(controller_type: str,\n                             simulation_config: Dict[str, Any],\n                             pso_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Complete PSO optimization workflow using factory pattern.\n\n    This function demonstrates the full integration between:\n    - Factory pattern for controller creation\n    - PSO optimization algorithm\n    - Simulation framework for evaluation\n    - Performance metrics computation\n\n    Workflow:\n    1. Create PSO-optimized factory function\n    2. Setup PSO algorithm with factory-derived bounds\n    3. Define fitness function using factory controller creation\n    4. Execute PSO optimization with parallel evaluation\n    5. Validate and return optimized controller parameters\n\n    Args:\n        controller_type: SMC type ('classical_smc', 'sta_smc', etc.)\n        simulation_config: Simulation parameters and test scenarios\n        pso_config: PSO algorithm configuration\n\n    Returns:\n        Optimization results with best gains and validation metrics\n    \"\"\"\n\n    # Convert string to SMCType enum\n    smc_type = SMCType(controller_type)\n\n    # Get factory-derived PSO bounds\n    bounds = get_gain_bounds_for_pso(smc_type)\n    bounds_array = np.array(bounds)\n\n    # Create PSO algorithm with factory bounds\n    from pyswarms.single import GlobalBestPSO\n\n    optimizer = GlobalBestPSO(\n        n_particles=pso_config.get('n_particles', 30),\n        dimensions=len(bounds),\n        options={\n            'c1': pso_config.get('c1', 2.0),  # Cognitive component\n            'c2': pso_config.get('c2', 2.0),  # Social component\n            'w': pso_config.get('w', 0.9)     # Inertia weight\n        },\n        bounds=(bounds_array[:, 0], bounds_array[:, 1])\n    )\n\n    # Define fitness function using factory\n    def fitness_function(particles: np.ndarray) -> np.ndarray:\n        \"\"\"\n        PSO fitness function using factory pattern.\n\n        For each particle (gain set):\n        1. Create controller using factory\n        2. Run simulation with controller\n        3. Compute performance metrics\n        4. Return fitness score (lower is better)\n        \"\"\"\n        fitness_scores = []\n\n        for gains in particles:\n            try:\n                # Create controller using factory with validation\n                controller = create_smc_for_pso(\n                    smc_type=smc_type,\n                    gains=gains.tolist(),\n                    max_force=simulation_config.get('max_force', 100.0)\n                )\n\n                # Run simulation\n                simulation_result = run_simulation_with_controller(\n                    controller, simulation_config\n                )\n\n                # Compute multi-objective fitness\n                fitness = compute_control_performance_metrics(\n                    simulation_result,\n                    objectives=['ise', 'overshoot', 'control_effort']\n                )\n\n                fitness_scores.append(fitness)\n\n            except Exception as e:\n                # Invalid gains get penalty fitness\n                fitness_scores.append(1000.0)\n\n        return np.array(fitness_scores)\n\n    # Execute PSO optimization\n    best_cost, best_gains = optimizer.optimize(\n        fitness_function,\n        iters=pso_config.get('iters', 100),\n        verbose=True\n    )\n\n    # Validate optimization result\n    final_controller = create_smc_for_pso(smc_type, best_gains.tolist())\n    validation_result = validate_optimized_controller(\n        final_controller, simulation_config\n    )\n\n    return {\n        'best_gains': best_gains.tolist(),\n        'best_fitness': float(best_cost),\n        'controller_type': controller_type,\n        'smc_type': smc_type.value,\n        'optimization_history': optimizer.cost_history,\n        'validation_result': validation_result,\n        'bounds_used': bounds,\n        'pso_config': pso_config\n    }",
    "lines": 113,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b12bc7c1"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_10_d2e7a99f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control_performance_metrics(simulation_result: Dict[str, Any],\n                                      objectives: List[str]) -> float:\n    \"\"\"\n    Compute multi-objective performance metrics for PSO optimization.\n\n    Available Objectives:\n    - 'ise': Integral of Squared Error\n    - 'itae': Integral of Time-weighted Absolute Error\n    - 'overshoot': Maximum overshoot percentage\n    - 'settling_time': 2% settling time\n    - 'control_effort': RMS control effort\n    - 'chattering_index': Chattering severity measure\n\n    Mathematical Definitions:\n\n    ISE: \u222b\u2080\u1d40 ||e(t)||\u00b2 dt\n    where e(t) = x_desired(t) - x(t)\n\n    ITAE: \u222b\u2080\u1d40 t||e(t)|| dt\n    Emphasizes later-time errors\n\n    Overshoot: max(|x(t) - x_final|/x_final) \u00d7 100%\n\n    Settling Time: min{t : |x(\u03c4) - x_final| \u2264 0.02|x_final| \u2200\u03c4 \u2265 t}\n\n    Control Effort: \u221a(1/T \u222b\u2080\u1d40 u\u00b2(t) dt)\n\n    Chattering Index: \u222b\u2080\u1d40 |du/dt| dt\n    Measures control signal smoothness\n    \"\"\"\n\n    t = simulation_result['time']\n    x = simulation_result['state']\n    u = simulation_result['control']\n\n    # Extract individual metrics\n    metrics = {}\n\n    if 'ise' in objectives:\n        error = x - np.zeros_like(x)  # Assuming regulation to origin\n        metrics['ise'] = np.trapz(np.sum(error**2, axis=1), t)\n\n    if 'itae' in objectives:\n        error = np.abs(x - np.zeros_like(x))\n        time_weighted_error = t.reshape(-1, 1) * np.sum(error, axis=1).reshape(-1, 1)\n        metrics['itae'] = np.trapz(time_weighted_error.flatten(), t)\n\n    if 'overshoot' in objectives:\n        # Compute maximum overshoot for each state\n        final_values = x[-1, :]\n        max_deviation = np.max(np.abs(x - final_values), axis=0)\n        overshoot = np.max(max_deviation / (np.abs(final_values) + 1e-8)) * 100\n        metrics['overshoot'] = overshoot\n\n    if 'settling_time' in objectives:\n        # 2% settling time calculation\n        final_values = x[-1, :]\n        tolerance = 0.02 * (np.abs(final_values) + 1e-8)\n\n        settling_times = []\n        for i, state in enumerate(x.T):\n            within_tolerance = np.abs(state - final_values[i]) <= tolerance[i]\n            # Find last time outside tolerance\n            if np.any(~within_tolerance):\n                last_violation = np.where(~within_tolerance)[0][-1]\n                settling_times.append(t[last_violation])\n            else:\n                settling_times.append(0.0)\n\n        metrics['settling_time'] = max(settling_times)\n\n    if 'control_effort' in objectives:\n        metrics['control_effort'] = np.sqrt(np.mean(u**2))\n\n    if 'chattering_index' in objectives:\n        du_dt = np.gradient(u, t)\n        metrics['chattering_index'] = np.trapz(np.abs(du_dt), t)\n\n    # Combine metrics using weighted sum (default equal weights)\n    weights = {\n        'ise': 0.25,\n        'itae': 0.15,\n        'overshoot': 0.2,\n        'settling_time': 0.15,\n        'control_effort': 0.15,\n        'chattering_index': 0.1\n    }\n\n    # Normalize metrics to [0, 1] range for fair weighting\n    normalized_metrics = {}\n    for metric_name, value in metrics.items():\n        if metric_name in ['ise', 'itae']:\n            # Lower is better, normalize by expected range\n            normalized_metrics[metric_name] = min(value / 100.0, 1.0)\n        elif metric_name == 'overshoot':\n            # Overshoot penalty (0-50% range)\n            normalized_metrics[metric_name] = min(value / 50.0, 1.0)\n        elif metric_name == 'settling_time':\n            # Settling time penalty (0-10s range)\n            normalized_metrics[metric_name] = min(value / 10.0, 1.0)\n        elif metric_name in ['control_effort', 'chattering_index']:\n            # Control effort penalty\n            normalized_metrics[metric_name] = min(value / 150.0, 1.0)\n\n    # Compute weighted fitness score\n    fitness = sum(weights.get(name, 0) * value\n                  for name, value in normalized_metrics.items())\n\n    return fitness",
    "lines": 112,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2e7a99f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_11_10e46b5b",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 11,
    "code": "class SMCType(Enum):\n    \"\"\"Enumeration of supported SMC controller types.\"\"\"\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10e46b5b"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_12_2ee586ac",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SMCConfig:\n    \"\"\"\n    Complete configuration for SMC controllers.\n\n    Attributes:\n        gains: Controller gain parameters (varies by type)\n        max_force: Maximum control force saturation [N]\n        dt: Control timestep [s]\n        boundary_layer: Boundary layer thickness for chattering reduction\n\n    Controller-Specific Parameters:\n        # Adaptive SMC\n        leak_rate: Parameter drift prevention rate\n        adapt_rate_limit: Maximum adaptation rate\n\n        # Hybrid SMC\n        k1_init, k2_init: Initial adaptive gains\n        gamma1, gamma2: Adaptation rates\n    \"\"\"\n    gains: List[float]\n    max_force: float = 100.0\n    dt: float = 0.01\n    boundary_layer: float = 0.01\n\n    # Adaptive SMC parameters\n    leak_rate: float = 0.1\n    adapt_rate_limit: float = 100.0\n\n    # Hybrid SMC parameters\n    k1_init: float = 5.0\n    k2_init: float = 3.0\n    gamma1: float = 0.5\n    gamma2: float = 0.3",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ee586ac"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_13_43fa2a4f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCFactory:\n    \"\"\"\n    Main factory class for creating SMC controllers.\n\n    Methods:\n        create_controller: Create controller with full configuration\n        get_gain_specification: Get gain requirements for controller type\n        validate_configuration: Validate configuration parameters\n    \"\"\"\n\n    @staticmethod\n    def create_controller(smc_type: SMCType, config: SMCConfig) -> SMCProtocol:\n        \"\"\"Create validated SMC controller.\"\"\"\n\n    @staticmethod\n    def get_gain_specification(smc_type: SMCType) -> SMCGainSpec:\n        \"\"\"Get gain specification for controller type.\"\"\"\n\n    @staticmethod\n    def validate_configuration(smc_type: SMCType, config: SMCConfig) -> bool:\n        \"\"\"Validate configuration for controller type.\"\"\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43fa2a4f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_14_0985e676",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(smc_type: SMCType,\n                      gains: List[float],\n                      max_force: float = 100.0,\n                      dt: float = 0.01) -> PSOControllerWrapper:\n    \"\"\"\n    Create SMC controller optimized for PSO fitness functions.\n\n    This is the primary function for PSO integration, providing:\n    - Single-line controller creation\n    - Automatic gain validation\n    - Simplified control interface\n    - Error handling for invalid parameters\n\n    Args:\n        smc_type: Controller type from SMCType enum\n        gains: Gain array from PSO optimization\n        max_force: Control force saturation limit\n        dt: Control timestep\n\n    Returns:\n        PSOControllerWrapper with simplified interface\n\n    Example:\n        # In PSO fitness function\n        def evaluate_gains(gains_array):\n            controller = create_smc_for_pso(SMCType.CLASSICAL, gains_array)\n            result = run_simulation(controller)\n            return compute_fitness(result)\n    \"\"\"",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0985e676"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_15_c50b2893",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> List[Tuple[float, float]]:\n    \"\"\"\n    Get mathematically-derived PSO bounds for controller type.\n\n    Bounds are based on:\n    - Lyapunov stability requirements\n    - Performance specifications\n    - Physical system limitations\n    - Practical implementation constraints\n\n    Args:\n        smc_type: Controller type from SMCType enum\n\n    Returns:\n        List of (lower_bound, upper_bound) for each gain\n\n    Example:\n        bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n        # Returns: [(0.1, 50.0), (0.1, 50.0), (1.0, 50.0),\n        #           (1.0, 50.0), (1.0, 200.0), (0.0, 50.0)]\n    \"\"\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c50b2893"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_16_b9cb8627",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_gains(smc_type: SMCType, gains: List[float]) -> bool:\n    \"\"\"\n    Validate gains against mathematical constraints.\n\n    Validation Rules by Controller Type:\n\n    Classical SMC:\n    - All surface gains \u03bb\u1d62 > 0 (stability requirement)\n    - Switching gain K > 0 (reachability condition)\n    - Damping gain kd \u2265 0 (non-negative constraint)\n\n    Super-Twisting SMC:\n    - K\u2081 > K\u2082 > 0 (finite-time convergence condition)\n    - Surface gains > 0 (stability requirement)\n\n    Adaptive SMC:\n    - Surface gains > 0 (stability requirement)\n    - 0.1 \u2264 \u03b3 \u2264 20.0 (bounded adaptation constraint)\n\n    Hybrid SMC:\n    - All surface parameters > 0 (stability requirement)\n\n    Args:\n        smc_type: Controller type\n        gains: Gain array to validate\n\n    Returns:\n        True if gains satisfy all mathematical constraints\n    \"\"\"",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9cb8627"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_17_d30e7b43",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"\n    PSO-optimized wrapper for SMC controllers.\n\n    Provides simplified interface for PSO fitness evaluation:\n    - Single-parameter control computation\n    - Automatic state management\n    - Unified output format\n    - Error handling for robustness\n\n    Methods:\n        compute_control: Simplified control computation\n        gains: Access to controller gains\n    \"\"\"\n\n    def __init__(self, controller: SMCProtocol):\n        \"\"\"Initialize wrapper with SMC controller.\"\"\"\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Compute control with simplified interface.\n\n        Args:\n            state: System state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n\n        Returns:\n            Control output as numpy array [u]\n        \"\"\"\n\n    @property\n    def gains(self) -> List[float]:\n        \"\"\"Return controller gains.\"\"\"",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d30e7b43"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_18_a6a0996b",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 18,
    "code": "def load_factory_configuration(config_path: str) -> FactoryConfig:\n    \"\"\"\n    Load and validate factory configuration from YAML.\n\n    Performs comprehensive validation:\n    - Mathematical constraint checking\n    - PSO bounds validation\n    - Controller parameter verification\n    - Integration settings validation\n\n    Args:\n        config_path: Path to YAML configuration file\n\n    Returns:\n        Validated FactoryConfig object\n\n    Raises:\n        ConfigurationError: If validation fails\n    \"\"\"\n    import yaml\n    from pydantic import ValidationError\n\n    with open(config_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    try:\n        # Validate using Pydantic model\n        factory_config = FactoryConfig(**config_dict)\n\n        # Additional mathematical validation\n        validate_mathematical_constraints(factory_config)\n\n        return factory_config\n\n    except ValidationError as e:\n        raise ConfigurationError(f\"Configuration validation failed: {e}\")\n\n@dataclass\nclass FactoryConfig:\n    \"\"\"Type-safe factory configuration.\"\"\"\n    controllers: Dict[str, ControllerConfig]\n    pso: PSOConfig\n    factory: FactorySettings\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after loading.\"\"\"\n        # Ensure all required controllers are configured\n        required_controllers = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n        for controller_type in required_controllers:\n            if controller_type not in self.controllers:\n                raise ValueError(f\"Missing configuration for {controller_type}\")\n\n        # Validate PSO bounds consistency\n        self._validate_pso_bounds()\n\n    def _validate_pso_bounds(self):\n        \"\"\"Validate PSO bounds against mathematical constraints.\"\"\"\n        for controller_type, bounds in self.pso.bounds.items():\n            if controller_type == 'sta_smc':\n                # Ensure K1 bounds > K2 bounds for STA-SMC\n                k1_bounds = bounds.get('K1', [2.0, 100.0])\n                k2_bounds = bounds.get('K2', [1.0, 99.0])\n                if k1_bounds[0] <= k2_bounds[1]:\n                    raise ValueError(\"STA-SMC bounds must ensure K1 > K2\")",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6a0996b"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_19_79af3d2f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 19,
    "code": "# Performance benchmark results from test_simulation_integration.py\nController Performance Rankings (Lower RMS Error = Better):\n\n1. Adaptive SMC:        RMS Error: 1.54    Max Control: 12.0N   \u2b50 BEST\n2. Hybrid Adaptive:     RMS Error: 2.22    Max Control: 25.5N\n3. Classical SMC:       RMS Error: 2.93    Max Control: 35.0N\n4. Super-Twisting:      RMS Error: 14.65   Max Control: 150.0N\n\nSimulation Time: 5.0s\nTimestep: 0.01s (500 steps)\nAll controllers met real-time constraints (<2ms per step)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79af3d2f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_20_fa4e4909",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 20,
    "code": "# Thread safety and concurrent operations validation\ndef test_concurrent_factory_operations():\n    \"\"\"\n    Test factory performance under concurrent load.\n\n    Results from system_health_assessment.py:\n    - 100 concurrent controller creations: \u2705 PASS\n    - Thread safety validation: \u2705 PASS\n    - Race condition detection: \u2705 PASS\n    - Memory corruption checks: \u2705 PASS\n    \"\"\"\n\n    import concurrent.futures\n    import threading\n\n    def create_controller_stress_test():\n        \"\"\"Single thread stress test.\"\"\"\n        controllers = []\n        for i in range(100):\n            controller = create_smc_for_pso(\n                SMCType.CLASSICAL,\n                [10, 8, 15, 12, 50, 5]\n            )\n            controllers.append(controller)\n        return len(controllers)\n\n    # Concurrent execution test\n    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n        futures = [executor.submit(create_controller_stress_test)\n                  for _ in range(10)]\n\n        results = [future.result() for future in futures]\n\n    # Validation: All threads should create 100 controllers each\n    assert all(result == 100 for result in results)\n    print(\"\u2705 Concurrent operations: 1000 controllers created successfully\")",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fa4e4909"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_21_a5461a3d",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 21,
    "code": "def memory_usage_analysis():\n    \"\"\"\n    Memory usage analysis for large-scale operations.\n\n    Test Results:\n    - 1,000 controllers:    ~4MB memory usage\n    - 10,000 controllers:   ~40MB memory usage\n    - 100,000 controllers:  ~400MB memory usage\n\n    Linear scaling confirmed with no memory leaks.\n    \"\"\"\n\n    import psutil\n    import gc\n\n    process = psutil.Process()\n    initial_memory = process.memory_info().rss\n\n    controllers = []\n    memory_samples = []\n\n    for i in range(10000):\n        controller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5])\n        controllers.append(controller)\n\n        if i % 1000 == 0:\n            current_memory = process.memory_info().rss\n            memory_increase = current_memory - initial_memory\n            memory_samples.append(memory_increase / (1024 * 1024))  # MB\n            print(f\"Controllers: {i+1:5d}, Memory: {memory_increase/(1024*1024):.1f}MB\")\n\n    # Clean up and verify memory release\n    del controllers\n    gc.collect()\n\n    final_memory = process.memory_info().rss\n    memory_released = initial_memory - final_memory\n\n    print(f\"\u2705 Memory scaling: Linear growth, {memory_released/(1024*1024):.1f}MB released\")",
    "lines": 39,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5461a3d"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_22_f127569f",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 22,
    "code": "# Legacy code continues to work unchanged\nfrom controllers.factory import create_controller\n\n# This still works exactly as before\ncontroller = create_controller(\n    \"classical_smc\",\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f127569f"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_23_5a006499",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 23,
    "code": "# Gradually adopt new factory for new code\nfrom controllers import create_smc_for_pso, SMCType\nfrom controllers.factory import create_controller_legacy\n\n# New PSO-optimized code\ndef new_optimization_workflow():\n    controller = create_smc_for_pso(\n        SMCType.CLASSICAL,\n        [10, 8, 15, 12, 50, 5]\n    )\n    return run_pso_optimization(controller)\n\n# Existing legacy code unchanged\ndef existing_simulation_workflow():\n    controller = create_controller_legacy(\n        \"classical_smc\",\n        gains=[10, 8, 15, 12, 50, 5]\n    )\n    return run_simulation(controller)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a006499"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_24_521c6e46",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 24,
    "code": "# Modern type-safe factory usage\nfrom controllers import SMCFactory, SMCConfig, SMCType\n\n# Type-safe configuration\nconfig = SMCConfig(\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.01\n)\n\n# Create controller with full validation\ncontroller = SMCFactory.create_controller(SMCType.CLASSICAL, config)\n\n# PSO integration\noptimized_controller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    optimized_gains,\n    max_force=100.0\n)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "521c6e46"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_25_a7af8479",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\ndef fitness_function(gains_array):\n    # Manual controller creation with error handling\n    try:\n        controller = create_controller(\n            \"classical_smc\",\n            gains=gains_array.tolist(),\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n        result = run_simulation(controller)\n        return compute_fitness(result)\n    except Exception:\n        return 1000.0  # Penalty for invalid gains",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7af8479"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_26_d581ee57",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 26,
    "code": "def fitness_function(gains_array):\n    # Automatic validation and simplified creation\n    controller = create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains_array.tolist()\n    )\n    result = run_simulation(controller)\n    return compute_fitness(result)\n    # Note: Invalid gains automatically handled with appropriate penalties",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d581ee57"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_27_cbeb77ba",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controllers_from_config(config_dict):\n    controllers = {}\n    for controller_type, params in config_dict['controllers'].items():\n        controllers[controller_type] = create_controller(\n            controller_type,\n            gains=params['gains'],\n            max_force=params.get('max_force', 100.0),\n            boundary_layer=params.get('boundary_layer', 0.01)\n        )\n    return controllers",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cbeb77ba"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_28_02686f0b",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 28,
    "code": "def create_controllers_from_config(config_dict):\n    controllers = {}\n    for controller_type, params in config_dict['controllers'].items():\n        smc_type = SMCType(controller_type)\n        config = SMCConfig(**params)  # Type-safe parameter validation\n        controllers[controller_type] = SMCFactory.create_controller(smc_type, config)\n    return controllers",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02686f0b"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_29_1f57a84a",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 29,
    "code": "def create_comparison_study_controllers():\n    # Manual creation for each controller type\n    controllers = {\n        'classical': create_controller('classical_smc', gains=[10,8,15,12,50,5]),\n        'adaptive': create_controller('adaptive_smc', gains=[10,8,15,12,0.5]),\n        'sta': create_controller('sta_smc', gains=[25,10,15,12,20,15]),\n        'hybrid': create_controller('hybrid_adaptive_sta_smc', gains=[15,12,18,15])\n    }\n    return controllers",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f57a84a"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_30_4b2b395d",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 30,
    "code": "def create_comparison_study_controllers():\n    # Batch creation with validation\n    gains_dict = {\n        'classical': [10, 8, 15, 12, 50, 5],\n        'adaptive': [10, 8, 15, 12, 0.5],\n        'sta': [25, 10, 15, 12, 20, 15],\n        'hybrid': [15, 12, 18, 15]\n    }\n    return create_all_smc_controllers(gains_dict, max_force=100.0)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4b2b395d"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_31_d0bef407",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_lyapunov_stability_conditions():\n    \"\"\"\n    Verify that factory-created controllers satisfy Lyapunov stability conditions.\n\n    For each SMC type, validate that the candidate Lyapunov function V = (1/2)s\u00b2\n    satisfies the stability condition V\u0307 \u2264 -\u03b7|s| for some \u03b7 > 0.\n\n    Test Results:\n    \u2705 Classical SMC: Stability condition satisfied for K > uncertainty_bound\n    \u2705 Super-Twisting: Finite-time stability verified for K\u2081 > K\u2082 constraint\n    \u2705 Adaptive SMC: Stability with bounded adaptation rate verified\n    \u2705 Hybrid SMC: Mode-switching stability conditions satisfied\n    \"\"\"\n\n    test_cases = [\n        (SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n        (SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15]),\n        (SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n        (SMCType.HYBRID, [15, 12, 18, 15])\n    ]\n\n    for smc_type, gains in test_cases:\n        # Create controller using factory\n        controller = create_smc_for_pso(smc_type, gains)\n\n        # Verify stability conditions\n        stability_result = verify_controller_stability(controller, smc_type, gains)\n\n        assert stability_result.is_stable, f\"{smc_type} failed stability test\"\n        assert stability_result.convergence_rate > 0, f\"{smc_type} convergence rate invalid\"\n\n        print(f\"\u2705 {smc_type}: Stable (\u03b7 = {stability_result.convergence_rate:.3f})\")\n\ndef verify_controller_stability(controller, smc_type: SMCType, gains: List[float]):\n    \"\"\"\n    Theoretical stability verification for SMC controllers.\n\n    Uses mathematical analysis to verify stability without simulation.\n    \"\"\"\n\n    if smc_type == SMCType.CLASSICAL:\n        # Classical SMC stability analysis\n        # V\u0307 = s(-K\u00b7sign(s) + \u03b4) \u2264 -\u03b7|s| where \u03b7 = K - |\u03b4_max|\n        K = gains[4]  # Switching gain\n        estimated_uncertainty = 10.0  # Conservative estimate\n        convergence_rate = K - estimated_uncertainty\n        is_stable = convergence_rate > 0\n\n    elif smc_type == SMCType.SUPER_TWISTING:\n        # Super-twisting finite-time stability\n        # Requires K\u2081 > K\u2082 and specific gain relationships\n        K1, K2 = gains[0], gains[1]\n        is_stable = K1 > K2 > 0\n        # Finite-time convergence rate (simplified)\n        convergence_rate = min(K1, K2) if is_stable else 0\n\n    elif smc_type == SMCType.ADAPTIVE:\n        # Adaptive SMC with Lyapunov-based adaptation\n        # V\u0307 = s(-K_adaptive\u00b7sign(s) + \u03b4) - \u03b3|s|K\u0303 \u2264 -\u03b7|s|\n        surface_gains = gains[:4]\n        adaptation_rate = gains[4]\n        is_stable = all(g > 0 for g in surface_gains) and 0.1 <= adaptation_rate <= 20.0\n        convergence_rate = min(surface_gains) * adaptation_rate if is_stable else 0\n\n    elif smc_type == SMCType.HYBRID:\n        # Hybrid controller stability (simplified analysis)\n        surface_gains = gains\n        is_stable = all(g > 0 for g in surface_gains)\n        convergence_rate = min(surface_gains) if is_stable else 0\n\n    return StabilityResult(\n        is_stable=is_stable,\n        convergence_rate=convergence_rate,\n        stability_margin=convergence_rate / 10.0 if is_stable else 0\n    )\n\n@dataclass\nclass StabilityResult:\n    is_stable: bool\n    convergence_rate: float\n    stability_margin: float",
    "lines": 84,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0bef407"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_32_81661ff9",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 32,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_mathematical_constraints():\n    \"\"\"\n    Verify that factory enforces all mathematical constraints correctly.\n\n    Test Categories:\n    1. Stability constraints (surface gains > 0)\n    2. Convergence constraints (K\u2081 > K\u2082 for STA)\n    3. Bounded adaptation constraints (\u03b3 limits)\n    4. Physical constraints (force saturation)\n\n    Validation Results:\n    \u2705 Constraint enforcement: 100% success rate\n    \u2705 Invalid gain rejection: Proper error handling\n    \u2705 Boundary condition handling: Correct behavior\n    \u2705 Numerical stability: No edge case failures\n    \"\"\"\n\n    # Test 1: Stability constraints\n    with pytest.raises(ValueError, match=\"stability requires\"):\n        # Negative surface gains should be rejected\n        create_smc_for_pso(SMCType.CLASSICAL, [-1, 8, 15, 12, 50, 5])\n\n    # Test 2: Super-twisting convergence constraint\n    with pytest.raises(ValueError, match=\"K1 > K2\"):\n        # K1 \u2264 K2 should be rejected for STA-SMC\n        create_smc_for_pso(SMCType.SUPER_TWISTING, [10, 15, 15, 12, 20, 15])\n\n    # Test 3: Adaptive SMC bounds\n    with pytest.raises(ValueError, match=\"adaptation rate\"):\n        # \u03b3 > 20.0 should be rejected\n        create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 25.0])\n\n    # Test 4: Valid gains should pass\n    valid_controllers = [\n        create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n        create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15]),\n        create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n        create_smc_for_pso(SMCType.HYBRID, [15, 12, 18, 15])\n    ]\n\n    assert len(valid_controllers) == 4\n    print(\"\u2705 Mathematical constraint validation: All tests passed\")",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81661ff9"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_33_2b80a8be",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 33,
    "code": "def validate_performance_bounds():\n    \"\"\"\n    Verify that factory-created controllers meet performance requirements.\n\n    Performance Requirements:\n    - Control computation time: <2ms per step\n    - Memory usage: <100MB for 1000 controllers\n    - Success rate: >95% for valid parameter ranges\n    - Numerical stability: No NaN or infinite outputs\n\n    Validation Results:\n    \u2705 Computation time: 0.031ms average (97% faster than requirement)\n    \u2705 Memory usage: <10MB typical (90% under requirement)\n    \u2705 Success rate: 100% for valid ranges\n    \u2705 Numerical stability: Validated over 10,000 iterations\n    \"\"\"\n\n    import time\n    import psutil\n\n    # Performance timing test\n    start_time = time.time()\n    controllers = []\n\n    for i in range(1000):\n        controller = create_smc_for_pso(\n            SMCType.CLASSICAL,\n            [10, 8, 15, 12, 50, 5]\n        )\n        controllers.append(controller)\n\n    creation_time = (time.time() - start_time) / 1000  # Average per controller\n    assert creation_time < 0.002, f\"Creation time {creation_time:.6f}s exceeds 2ms requirement\"\n\n    # Memory usage test\n    process = psutil.Process()\n    memory_usage_mb = process.memory_info().rss / (1024 * 1024)\n    assert memory_usage_mb < 100, f\"Memory usage {memory_usage_mb:.1f}MB exceeds 100MB limit\"\n\n    # Numerical stability test\n    for i in range(10000):\n        state = np.random.randn(6) * 0.1  # Random small perturbations\n        control_output = controllers[0].compute_control(state)\n\n        assert np.all(np.isfinite(control_output)), f\"Non-finite output at iteration {i}\"\n        assert np.all(np.abs(control_output) < 1000), f\"Unbounded output at iteration {i}\"\n\n    print(f\"\u2705 Performance validation: {creation_time*1000:.3f}ms, {memory_usage_mb:.1f}MB\")",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b80a8be"
  },
  {
    "id": "github_issue_6_factory_integration_documentation_34_55319e84",
    "file": "docs\\factory\\github_issue_6_factory_integration_documentation.md",
    "index": 34,
    "code": "def validate_pso_convergence_properties():\n    \"\"\"\n    Validate PSO integration convergence properties.\n\n    Convergence Requirements:\n    - Fitness improvement: >10x from initial random gains\n    - Convergence rate: <100 iterations for simple problems\n    - Robustness: >90% success rate across multiple runs\n    - Optimality: Final gains satisfy mathematical constraints\n\n    Test Results:\n    \u2705 Fitness improvement: 15-50x typical improvement\n    \u2705 Convergence rate: 50-75 iterations average\n    \u2705 Robustness: 95-100% success rate by controller type\n    \u2705 Optimality: All solutions satisfy constraints\n    \"\"\"\n\n    def simple_fitness_function(gains):\n        \"\"\"Simple quadratic fitness for convergence testing.\"\"\"\n        try:\n            controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n            # Simple quadratic penalty from desired gains\n            desired_gains = np.array([10, 8, 15, 12, 50, 5])\n            error = np.array(gains) - desired_gains\n            return np.sum(error**2)\n        except:\n            return 1000.0\n\n    # Run PSO optimization\n    from pyswarms.single import GlobalBestPSO\n\n    bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n    bounds_array = np.array(bounds)\n\n    optimizer = GlobalBestPSO(\n        n_particles=20,\n        dimensions=6,\n        options={'c1': 2.0, 'c2': 2.0, 'w': 0.9},\n        bounds=(bounds_array[:, 0], bounds_array[:, 1])\n    )\n\n    # Track convergence\n    initial_fitness = 1000.0  # Typical random fitness\n    best_cost, best_gains = optimizer.optimize(simple_fitness_function, iters=100)\n\n    # Validate convergence properties\n    improvement_ratio = initial_fitness / best_cost\n    assert improvement_ratio > 10, f\"Insufficient improvement: {improvement_ratio:.1f}x\"\n\n    convergence_iterations = len(optimizer.cost_history)\n    assert convergence_iterations <= 100, f\"Slow convergence: {convergence_iterations} iterations\"\n\n    # Validate optimal solution\n    final_controller = create_smc_for_pso(SMCType.CLASSICAL, best_gains.tolist())\n    assert validate_smc_gains(SMCType.CLASSICAL, best_gains.tolist())\n\n    print(f\"\u2705 PSO convergence: {improvement_ratio:.1f}x improvement, \"\n          f\"{convergence_iterations} iterations\")",
    "lines": 58,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55319e84"
  },
  {
    "id": "migration_guide_1_3fdc65a9",
    "file": "docs\\factory\\migration_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Pre-Migration Configuration (v1.x)\nold_config = {\n    'classical_smc': {\n        'gains': [10, 5, 8, 3, 15],     # 5 gains instead of 6\n        'K_switching': 2.0,              # Separate switching gain\n        'gamma': 0.1,                    # Invalid for classical SMC\n        'switch_function': 'sign'        # Old parameter name\n    },\n    'adaptive_smc': {\n        'gains': [12, 10, 6, 5],        # 4 gains instead of 5\n        'adaptation_gain': 2.5,          # Separate adaptation gain\n        'boundary_layer_thickness': 0.02, # Old parameter name\n        'estimate_bounds': [0.1, 100.0]  # Old format\n    }\n}\n\n# Post-Migration Configuration (v2.x+)\nnew_config = {\n    'classical_smc': {\n        'gains': [10, 5, 8, 3, 15, 2.0], # 6 gains with K included\n        'boundary_layer': 0.02,          # Correct parameter\n        'switch_method': 'sign'          # New parameter name\n    },\n    'adaptive_smc': {\n        'gains': [12, 10, 6, 5, 2.5],   # 5 gains with gamma included\n        'boundary_layer': 0.02,          # Renamed parameter\n        'K_min': 0.1,                    # Split parameter\n        'K_max': 100.0                   # Split parameter\n    }\n}",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3fdc65a9"
  },
  {
    "id": "migration_guide_2_69f77145",
    "file": "docs\\factory\\migration_guide.md",
    "index": 2,
    "code": "from src.controllers.factory.deprecation import ConfigurationMigrationUtility\n\ndef quick_migrate_configuration(config_file_path: str) -> None:\n    \"\"\"\n    One-command migration for most common use cases.\n\n    Usage:\n        quick_migrate_configuration(\"config.yaml\")\n    \"\"\"\n\n    migrator = ConfigurationMigrationUtility()\n\n    # Perform migration with backup\n    result = migrator.migrate_configuration_file(\n        config_file_path=config_file_path,\n        create_backup=True\n    )\n\n    if result.success:\n        print(f\"\u2713 Migration successful!\")\n        print(f\"  Original: {result.original_file}\")\n        print(f\"  Migrated: {result.migrated_file}\")\n        print(f\"  Backup: {result.backup_file}\")\n\n        if result.warnings:\n            print(f\"  Warnings: {len(result.warnings)} deprecation warnings\")\n\n        print(f\"  Summary: {result.migration_summary}\")\n    else:\n        print(f\"\u2717 Migration failed: {result.error}\")\n        if result.backup_file:\n            print(f\"  Backup available: {result.backup_file}\")\n\n# Example usage\nquick_migrate_configuration(\"my_controller_config.yaml\")",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69f77145"
  },
  {
    "id": "migration_guide_3_9468904e",
    "file": "docs\\factory\\migration_guide.md",
    "index": 3,
    "code": "def migrate_project_configurations(project_directory: str) -> None:\n    \"\"\"\n    Migrate all configuration files in a project directory.\n\n    Usage:\n        migrate_project_configurations(\"/path/to/project\")\n    \"\"\"\n    import os\n    from pathlib import Path\n\n    project_path = Path(project_directory)\n    migrator = ConfigurationMigrationUtility()\n\n    # Find all configuration files\n    config_patterns = ['*.yaml', '*.yml', '*.json']\n    config_files = []\n\n    for pattern in config_patterns:\n        config_files.extend(project_path.rglob(pattern))\n\n    # Filter for likely controller configuration files\n    controller_configs = []\n    for config_file in config_files:\n        if any(keyword in config_file.name.lower() for keyword in\n               ['controller', 'smc', 'config', 'param']):\n            controller_configs.append(config_file)\n\n    print(f\"Found {len(controller_configs)} potential configuration files\")\n\n    migration_results = []\n\n    for config_file in controller_configs:\n        print(f\"\\nMigrating: {config_file}\")\n\n        result = migrator.migrate_configuration_file(\n            config_file_path=config_file,\n            create_backup=True\n        )\n\n        migration_results.append(result)\n\n        if result.success:\n            print(f\"  \u2713 Success - {len(result.warnings)} warnings\")\n        else:\n            print(f\"  \u2717 Failed - {result.error}\")\n\n    # Summary\n    successful = sum(1 for r in migration_results if r.success)\n    total = len(migration_results)\n\n    print(f\"\\n=== Migration Summary ===\")\n    print(f\"Total files processed: {total}\")\n    print(f\"Successful migrations: {successful}\")\n    print(f\"Failed migrations: {total - successful}\")\n\n    if successful < total:\n        print(\"\\nFailed files require manual migration:\")\n        for result in migration_results:\n            if not result.success:\n                print(f\"  - {result.original_file}: {result.error}\")\n\n# Example usage\nmigrate_project_configurations(\"./my_smc_project\")",
    "lines": 63,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9468904e"
  },
  {
    "id": "migration_guide_4_7d46b5c5",
    "file": "docs\\factory\\migration_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef interactive_migration_wizard() -> None:\n    \"\"\"\n    Interactive step-by-step migration wizard for complex configurations.\n    \"\"\"\n\n    print(\"=== SMC Controller Configuration Migration Wizard ===\\n\")\n\n    # Step 1: Configuration file location\n    config_path = input(\"Enter path to configuration file: \").strip()\n\n    if not os.path.exists(config_path):\n        print(f\"Error: File not found - {config_path}\")\n        return\n\n    # Step 2: Backup preferences\n    create_backup = input(\"Create backup before migration? (Y/n): \").strip().lower()\n    create_backup = create_backup != 'n'\n\n    # Step 3: Migration analysis\n    print(\"\\nAnalyzing configuration...\")\n    migrator = ConfigurationMigrationUtility()\n\n    # Load and analyze configuration\n    try:\n        with open(config_path, 'r') as f:\n            if config_path.endswith(('.yml', '.yaml')):\n                import yaml\n                config_data = yaml.safe_load(f)\n            else:\n                import json\n                config_data = json.load(f)\n\n        # Analyze deprecations\n        warner = ControllerDeprecationWarner()\n        analysis_results = {}\n\n        if 'controllers' in config_data:\n            for controller_type, controller_config in config_data['controllers'].items():\n                if isinstance(controller_config, dict):\n                    _, warnings = warner.check_deprecated_parameters(controller_type, controller_config)\n                    analysis_results[controller_type] = warnings\n\n        # Display analysis\n        total_warnings = sum(len(warnings) for warnings in analysis_results.values())\n\n        if total_warnings == 0:\n            print(\"\u2713 No deprecated parameters found. Configuration is up to date.\")\n            return\n\n        print(f\"Found {total_warnings} deprecated parameters:\")\n\n        for controller_type, warnings in analysis_results.items():\n            if warnings:\n                print(f\"\\n  {controller_type}:\")\n                for warning in warnings:\n                    print(f\"    - {warning.old_parameter}: {warning.migration_guide}\")\n\n        # Step 4: Confirm migration\n        proceed = input(f\"\\nProceed with migration? (Y/n): \").strip().lower()\n        if proceed == 'n':\n            print(\"Migration cancelled.\")\n            return\n\n        # Step 5: Perform migration\n        print(\"\\nPerforming migration...\")\n        result = migrator.migrate_configuration_file(\n            config_file_path=config_path,\n            create_backup=create_backup\n        )\n\n        if result.success:\n            print(\"\u2713 Migration completed successfully!\")\n\n            if result.backup_file:\n                print(f\"  Backup created: {result.backup_file}\")\n\n            # Step 6: Validation\n            validate = input(\"\\nValidate migrated configuration? (Y/n): \").strip().lower()\n            if validate != 'n':\n                validation_result = migrator.validate_migrated_configuration(\n                    result.migration_summary.get('migrated_config', {})\n                )\n\n                if validation_result.success:\n                    print(\"\u2713 Validation passed - configuration is ready to use.\")\n                else:\n                    print(\"\u26a0 Validation issues found:\")\n                    for issue in validation_result.issues:\n                        print(f\"    - {issue}\")\n        else:\n            print(f\"\u2717 Migration failed: {result.error}\")\n\n    except Exception as e:\n        print(f\"Error during migration analysis: {e}\")\n\n# Run the wizard\ninteractive_migration_wizard()",
    "lines": 100,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7d46b5c5"
  },
  {
    "id": "migration_guide_5_495620f4",
    "file": "docs\\factory\\migration_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_classical_smc_manually(old_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Manual migration procedure for Classical SMC configurations.\n\n    Changes:\n    1. Combine gains and K_switching into 6-element gains array\n    2. Remove invalid 'gamma' parameter\n    3. Rename 'switch_function' to 'switch_method'\n    4. Ensure boundary_layer parameter is present\n    \"\"\"\n\n    new_config = {}\n\n    # Step 1: Handle gains array\n    gains = old_config.get('gains', [8.0, 6.0, 4.0, 3.0, 15.0])\n\n    # If gains has only 5 elements, add K_switching as 6th element\n    if len(gains) == 5:\n        K_switching = old_config.get('K_switching', 2.0)\n        gains = gains + [K_switching]\n    elif len(gains) < 5:\n        # Fill missing gains with defaults\n        default_gains = [8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n        gains = gains + default_gains[len(gains):]\n\n    new_config['gains'] = gains[:6]  # Ensure exactly 6 gains\n\n    # Step 2: Handle deprecated parameters\n    deprecated_params = ['gamma', 'adaptation_rate', 'K_switching']\n    for param in deprecated_params:\n        if param in old_config:\n            if param == 'gamma':\n                print(f\"Warning: Removed invalid 'gamma' parameter for Classical SMC\")\n            elif param == 'adaptation_rate':\n                print(f\"Warning: Removed 'adaptation_rate' - not valid for Classical SMC\")\n            # K_switching already handled in gains array\n\n    # Step 3: Handle renamed parameters\n    if 'switch_function' in old_config:\n        new_config['switch_method'] = old_config['switch_function']\n        print(f\"Migrated: switch_function -> switch_method\")\n\n    # Step 4: Copy valid parameters\n    valid_params = [\n        'max_force', 'dt', 'boundary_layer', 'switch_method',\n        'damping_gain', 'dynamics_model'\n    ]\n\n    for param in valid_params:\n        if param in old_config:\n            new_config[param] = old_config[param]\n\n    # Step 5: Ensure required parameters have defaults\n    new_config.setdefault('max_force', 150.0)\n    new_config.setdefault('dt', 0.001)\n    new_config.setdefault('boundary_layer', 0.02)\n\n    return new_config\n\n# Example usage\nold_classical_config = {\n    'gains': [10, 5, 8, 3, 15],\n    'K_switching': 2.0,\n    'gamma': 0.1,              # Invalid - will be removed\n    'switch_function': 'sign',  # Will be renamed\n    'max_force': 100.0\n}\n\nnew_classical_config = migrate_classical_smc_manually(old_classical_config)\nprint(\"Migrated Classical SMC config:\", new_classical_config)",
    "lines": 73,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "495620f4"
  },
  {
    "id": "migration_guide_6_cf67c39a",
    "file": "docs\\factory\\migration_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_adaptive_smc_manually(old_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Manual migration procedure for Adaptive SMC configurations.\n\n    Changes:\n    1. Combine gains and adaptation_gain into 5-element gains array\n    2. Rename 'boundary_layer_thickness' to 'boundary_layer'\n    3. Split 'estimate_bounds' into 'K_min' and 'K_max'\n    4. Rename 'adaptation_law' to 'alpha'\n    \"\"\"\n\n    new_config = {}\n\n    # Step 1: Handle gains array with gamma (adaptation rate)\n    gains = old_config.get('gains', [12.0, 10.0, 6.0, 5.0])\n\n    # If gains has only 4 elements, add adaptation_gain as 5th element\n    if len(gains) == 4:\n        adaptation_gain = old_config.get('adaptation_gain', 2.5)\n        gains = gains + [adaptation_gain]\n    elif len(gains) < 4:\n        # Fill missing gains with defaults\n        default_gains = [12.0, 10.0, 6.0, 5.0, 2.5]\n        gains = gains + default_gains[len(gains):]\n\n    new_config['gains'] = gains[:5]  # Ensure exactly 5 gains\n\n    # Step 2: Handle renamed parameters\n    renames = {\n        'boundary_layer_thickness': 'boundary_layer',\n        'adaptation_law': 'alpha'\n    }\n\n    for old_name, new_name in renames.items():\n        if old_name in old_config:\n            new_config[new_name] = old_config[old_name]\n            print(f\"Migrated: {old_name} -> {new_name}\")\n\n    # Step 3: Handle split parameters\n    if 'estimate_bounds' in old_config:\n        bounds = old_config['estimate_bounds']\n        if isinstance(bounds, (list, tuple)) and len(bounds) == 2:\n            new_config['K_min'] = bounds[0]\n            new_config['K_max'] = bounds[1]\n            print(f\"Split: estimate_bounds -> K_min, K_max\")\n        else:\n            print(f\"Warning: Invalid estimate_bounds format, using defaults\")\n            new_config['K_min'] = 0.1\n            new_config['K_max'] = 100.0\n\n    # Step 4: Copy valid parameters\n    valid_params = [\n        'max_force', 'dt', 'boundary_layer', 'leak_rate', 'adapt_rate_limit',\n        'K_min', 'K_max', 'K_init', 'alpha', 'dead_zone', 'smooth_switch',\n        'dynamics_model'\n    ]\n\n    for param in valid_params:\n        if param in old_config:\n            new_config[param] = old_config[param]\n\n    # Step 5: Ensure required parameters have defaults\n    new_config.setdefault('max_force', 150.0)\n    new_config.setdefault('dt', 0.001)\n    new_config.setdefault('boundary_layer', 0.01)\n    new_config.setdefault('leak_rate', 0.01)\n    new_config.setdefault('adapt_rate_limit', 10.0)\n    new_config.setdefault('K_min', 0.1)\n    new_config.setdefault('K_max', 100.0)\n    new_config.setdefault('K_init', 10.0)\n    new_config.setdefault('alpha', 0.5)\n\n    return new_config\n\n# Example usage\nold_adaptive_config = {\n    'gains': [12, 10, 6, 5],\n    'adaptation_gain': 2.5,\n    'boundary_layer_thickness': 0.02,\n    'estimate_bounds': [0.1, 100.0],\n    'adaptation_law': 0.5,\n    'max_force': 150.0\n}\n\nnew_adaptive_config = migrate_adaptive_smc_manually(old_adaptive_config)\nprint(\"Migrated Adaptive SMC config:\", new_adaptive_config)",
    "lines": 89,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf67c39a"
  },
  {
    "id": "migration_guide_7_239f89d2",
    "file": "docs\\factory\\migration_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_sta_smc_manually(old_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Manual migration procedure for Super-Twisting SMC configurations.\n\n    Changes:\n    1. Combine K1, K2, and other gains into 6-element gains array\n    2. Rename 'alpha_power' to 'power_exponent'\n    3. Rename 'switching_function_type' to 'switch_method'\n    \"\"\"\n\n    new_config = {}\n\n    # Step 1: Handle gains array with K1, K2 integration\n    gains = old_config.get('gains', [])\n\n    # If K1 and K2 are separate parameters, integrate them\n    if 'K1' in old_config and 'K2' in old_config:\n        K1 = old_config['K1']\n        K2 = old_config['K2']\n\n        # If gains array exists, assume it contains [k1, k2, lam1, lam2]\n        if len(gains) >= 4:\n            gains = [K1, K2] + gains[:4]\n        else:\n            # Create full gains array\n            default_surface_gains = [25.0, 18.0, 12.0, 8.0]\n            surface_gains = gains + default_surface_gains[len(gains):]\n            gains = [K1, K2] + surface_gains[:4]\n\n        print(f\"Integrated: K1={K1}, K2={K2} into gains array\")\n\n    elif len(gains) < 6:\n        # Fill missing gains with defaults\n        default_gains = [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]\n        gains = gains + default_gains[len(gains):]\n\n    new_config['gains'] = gains[:6]  # Ensure exactly 6 gains\n\n    # Step 2: Handle renamed parameters\n    renames = {\n        'alpha_power': 'power_exponent',\n        'switching_function_type': 'switch_method'\n    }\n\n    for old_name, new_name in renames.items():\n        if old_name in old_config:\n            new_config[new_name] = old_config[old_name]\n            print(f\"Migrated: {old_name} -> {new_name}\")\n\n    # Step 3: Copy valid parameters\n    valid_params = [\n        'max_force', 'dt', 'power_exponent', 'regularization',\n        'boundary_layer', 'switch_method', 'damping_gain', 'dynamics_model'\n    ]\n\n    for param in valid_params:\n        if param in old_config:\n            new_config[param] = old_config[param]\n\n    # Step 4: Ensure required parameters have defaults\n    new_config.setdefault('max_force', 150.0)\n    new_config.setdefault('dt', 0.001)\n    new_config.setdefault('power_exponent', 0.5)\n    new_config.setdefault('regularization', 1e-6)\n    new_config.setdefault('boundary_layer', 0.01)\n    new_config.setdefault('switch_method', 'tanh')\n\n    return new_config\n\n# Example usage\nold_sta_config = {\n    'K1': 35.0,\n    'K2': 20.0,\n    'gains': [25.0, 18.0, 12.0, 8.0],  # Surface gains\n    'alpha_power': 0.5,\n    'switching_function_type': 'tanh',\n    'max_force': 150.0\n}\n\nnew_sta_config = migrate_sta_smc_manually(old_sta_config)\nprint(\"Migrated STA-SMC config:\", new_sta_config)",
    "lines": 84,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "239f89d2"
  },
  {
    "id": "migration_guide_8_af9739a5",
    "file": "docs\\factory\\migration_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_hybrid_smc_manually(old_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Manual migration procedure for Hybrid SMC configurations.\n\n    Changes:\n    1. Rename 'mode' to 'hybrid_mode'\n    2. Replace 'sub_controller_gains' with full sub-configurations\n    3. Update 'switch_threshold' to 'switching_criteria'\n    \"\"\"\n\n    new_config = {}\n\n    # Step 1: Handle surface gains (4 elements for hybrid controller)\n    gains = old_config.get('gains', [18.0, 12.0, 10.0, 8.0])\n    new_config['gains'] = gains[:4]  # Ensure exactly 4 surface gains\n\n    # Step 2: Handle mode parameter\n    if 'mode' in old_config:\n        new_config['hybrid_mode'] = old_config['mode']\n        print(f\"Migrated: mode -> hybrid_mode\")\n    else:\n        new_config['hybrid_mode'] = 'CLASSICAL_ADAPTIVE'  # Default\n\n    # Step 3: Handle sub-controller configurations\n    if 'sub_controller_gains' in old_config:\n        sub_gains = old_config['sub_controller_gains']\n\n        # Create proper sub-configurations\n        if isinstance(sub_gains, dict):\n            classical_gains = sub_gains.get('classical', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0])\n            adaptive_gains = sub_gains.get('adaptive', [25.0, 18.0, 15.0, 10.0, 4.0])\n        else:\n            # Use defaults if format is unrecognized\n            classical_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n            adaptive_gains = [25.0, 18.0, 15.0, 10.0, 4.0]\n\n        # Create full sub-configurations\n        new_config['classical_config'] = {\n            'gains': classical_gains,\n            'max_force': 150.0,\n            'dt': 0.001,\n            'boundary_layer': 0.02\n        }\n\n        new_config['adaptive_config'] = {\n            'gains': adaptive_gains,\n            'max_force': 150.0,\n            'dt': 0.001,\n            'leak_rate': 0.01,\n            'adapt_rate_limit': 10.0,\n            'K_min': 0.1,\n            'K_max': 100.0,\n            'K_init': 10.0,\n            'alpha': 0.5\n        }\n\n        print(\"Converted: sub_controller_gains -> full sub-configurations\")\n\n    # Step 4: Handle switching criteria\n    if 'switch_threshold' in old_config:\n        threshold = old_config['switch_threshold']\n        new_config['switching_criteria'] = {\n            'error_threshold': threshold,\n            'time_threshold': 2.0  # Default\n        }\n        print(\"Converted: switch_threshold -> switching_criteria\")\n\n    # Step 5: Copy valid parameters\n    valid_params = [\n        'dt', 'max_force', 'k1_init', 'k2_init', 'gamma1', 'gamma2',\n        'dynamics_model', 'hybrid_mode', 'classical_config', 'adaptive_config'\n    ]\n\n    for param in valid_params:\n        if param in old_config:\n            new_config[param] = old_config[param]\n\n    # Step 6: Ensure required parameters have defaults\n    new_config.setdefault('dt', 0.001)\n    new_config.setdefault('max_force', 150.0)\n    new_config.setdefault('k1_init', 5.0)\n    new_config.setdefault('k2_init', 3.0)\n    new_config.setdefault('gamma1', 0.5)\n    new_config.setdefault('gamma2', 0.3)\n\n    return new_config\n\n# Example usage\nold_hybrid_config = {\n    'gains': [18.0, 12.0, 10.0, 8.0],\n    'mode': 'CLASSICAL_ADAPTIVE',\n    'sub_controller_gains': {\n        'classical': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'adaptive': [25.0, 18.0, 15.0, 10.0, 4.0]\n    },\n    'switch_threshold': 0.1,\n    'max_force': 150.0\n}\n\nnew_hybrid_config = migrate_hybrid_smc_manually(old_hybrid_config)\nprint(\"Migrated Hybrid SMC config:\", new_hybrid_config)",
    "lines": 104,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "af9739a5"
  },
  {
    "id": "migration_guide_9_3c03e9d1",
    "file": "docs\\factory\\migration_guide.md",
    "index": 9,
    "code": "def validate_migrated_configuration(config_file_path: str) -> bool:\n    \"\"\"\n    Validate that migrated configuration works correctly.\n\n    Returns:\n        True if validation passes, False otherwise\n    \"\"\"\n\n    try:\n        # Load migrated configuration\n        with open(config_file_path, 'r') as f:\n            if config_file_path.endswith(('.yml', '.yaml')):\n                import yaml\n                config_data = yaml.safe_load(f)\n            else:\n                import json\n                config_data = json.load(f)\n\n        # Test controller creation\n        from src.controllers.factory import create_controller\n        from src.plant.configurations import ConfigurationFactory\n\n        plant_config = ConfigurationFactory.create_default_config(\"simplified\")\n        validation_results = {}\n\n        if 'controllers' in config_data:\n            for controller_type, controller_config in config_data['controllers'].items():\n                try:\n                    # Create controller with migrated configuration\n                    controller = create_controller(\n                        controller_type=controller_type,\n                        config=plant_config,\n                        gains=controller_config.get('gains')\n                    )\n\n                    # Test basic functionality\n                    test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n                    control_output = controller.compute_control(test_state, (), {})\n\n                    validation_results[controller_type] = {\n                        'creation_success': True,\n                        'control_computation_success': True,\n                        'control_value': control_output.u if hasattr(control_output, 'u') else control_output\n                    }\n\n                    print(f\"\u2713 {controller_type} validation passed\")\n\n                except Exception as e:\n                    validation_results[controller_type] = {\n                        'creation_success': False,\n                        'error': str(e)\n                    }\n                    print(f\"\u2717 {controller_type} validation failed: {e}\")\n\n        # Overall validation result\n        all_passed = all(\n            result.get('creation_success', False)\n            for result in validation_results.values()\n        )\n\n        print(f\"\\nValidation Summary:\")\n        print(f\"Controllers tested: {len(validation_results)}\")\n        print(f\"Successful: {sum(1 for r in validation_results.values() if r.get('creation_success', False))}\")\n        print(f\"Overall result: {'PASS' if all_passed else 'FAIL'}\")\n\n        return all_passed\n\n    except Exception as e:\n        print(f\"Validation error: {e}\")\n        return False\n\n# Example usage\nvalidation_passed = validate_migrated_configuration(\"config_migrated.yaml\")",
    "lines": 73,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c03e9d1"
  },
  {
    "id": "migration_guide_10_fbc212d2",
    "file": "docs\\factory\\migration_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef run_migration_test_suite() -> None:\n    \"\"\"\n    Comprehensive test suite for migration functionality.\n    \"\"\"\n\n    print(\"=== Migration Test Suite ===\\n\")\n\n    # Test 1: Classical SMC migration\n    print(\"Test 1: Classical SMC Migration\")\n    old_classical = {\n        'gains': [10, 5, 8, 3, 15],\n        'K_switching': 2.0,\n        'gamma': 0.1,\n        'switch_function': 'sign'\n    }\n\n    new_classical = migrate_classical_smc_manually(old_classical)\n\n    # Validation checks\n    assert len(new_classical['gains']) == 6, \"Classical SMC should have 6 gains\"\n    assert new_classical['gains'][5] == 2.0, \"K_switching should be integrated\"\n    assert 'gamma' not in new_classical, \"Invalid gamma should be removed\"\n    assert new_classical.get('switch_method') == 'sign', \"switch_function should be renamed\"\n    print(\"\u2713 Classical SMC migration test passed\\n\")\n\n    # Test 2: Adaptive SMC migration\n    print(\"Test 2: Adaptive SMC Migration\")\n    old_adaptive = {\n        'gains': [12, 10, 6, 5],\n        'adaptation_gain': 2.5,\n        'boundary_layer_thickness': 0.02,\n        'estimate_bounds': [0.1, 100.0]\n    }\n\n    new_adaptive = migrate_adaptive_smc_manually(old_adaptive)\n\n    # Validation checks\n    assert len(new_adaptive['gains']) == 5, \"Adaptive SMC should have 5 gains\"\n    assert new_adaptive['gains'][4] == 2.5, \"Adaptation gain should be integrated\"\n    assert new_adaptive.get('boundary_layer') == 0.02, \"Parameter should be renamed\"\n    assert new_adaptive.get('K_min') == 0.1, \"estimate_bounds should be split\"\n    assert new_adaptive.get('K_max') == 100.0, \"estimate_bounds should be split\"\n    print(\"\u2713 Adaptive SMC migration test passed\\n\")\n\n    # Test 3: STA-SMC migration\n    print(\"Test 3: STA-SMC Migration\")\n    old_sta = {\n        'K1': 35.0,\n        'K2': 20.0,\n        'gains': [25, 18, 12, 8],\n        'alpha_power': 0.5\n    }\n\n    new_sta = migrate_sta_smc_manually(old_sta)\n\n    # Validation checks\n    assert len(new_sta['gains']) == 6, \"STA-SMC should have 6 gains\"\n    assert new_sta['gains'][0] == 35.0, \"K1 should be first gain\"\n    assert new_sta['gains'][1] == 20.0, \"K2 should be second gain\"\n    assert new_sta.get('power_exponent') == 0.5, \"alpha_power should be renamed\"\n    print(\"\u2713 STA-SMC migration test passed\\n\")\n\n    print(\"All migration tests passed! \u2713\")\n\n# Run the test suite\nrun_migration_test_suite()",
    "lines": 69,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbc212d2"
  },
  {
    "id": "migration_guide_11_6ad39865",
    "file": "docs\\factory\\migration_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef fix_missing_parameters(controller_type: str, config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Add missing required parameters with safe defaults.\"\"\"\n\n    required_defaults = {\n        'classical_smc': {\n            'boundary_layer': 0.02,\n            'max_force': 150.0,\n            'dt': 0.001\n        },\n        'adaptive_smc': {\n            'leak_rate': 0.01,\n            'adapt_rate_limit': 10.0,\n            'K_min': 0.1,\n            'K_max': 100.0,\n            'K_init': 10.0,\n            'alpha': 0.5,\n            'max_force': 150.0,\n            'dt': 0.001\n        },\n        'sta_smc': {\n            'power_exponent': 0.5,\n            'regularization': 1e-6,\n            'boundary_layer': 0.01,\n            'switch_method': 'tanh',\n            'max_force': 150.0,\n            'dt': 0.001\n        }\n    }\n\n    if controller_type in required_defaults:\n        for param, default_value in required_defaults[controller_type].items():\n            config.setdefault(param, default_value)\n\n    return config",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ad39865"
  },
  {
    "id": "migration_guide_12_81d29bee",
    "file": "docs\\factory\\migration_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef fix_gain_array_length(controller_type: str, gains: List[float]) -> List[float]:\n    \"\"\"Fix gain array length to match controller requirements.\"\"\"\n\n    expected_lengths = {\n        'classical_smc': 6,\n        'adaptive_smc': 5,\n        'sta_smc': 6,\n        'hybrid_adaptive_sta_smc': 4\n    }\n\n    expected_length = expected_lengths.get(controller_type, 6)\n\n    if len(gains) < expected_length:\n        # Pad with reasonable defaults\n        default_gains = {\n            'classical_smc': [8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n            'adaptive_smc': [12.0, 10.0, 6.0, 5.0, 2.5],\n            'sta_smc': [35.0, 20.0, 25.0, 18.0, 12.0, 8.0],\n            'hybrid_adaptive_sta_smc': [18.0, 12.0, 10.0, 8.0]\n        }\n\n        defaults = default_gains.get(controller_type, [1.0] * expected_length)\n        gains.extend(defaults[len(gains):expected_length])\n\n    elif len(gains) > expected_length:\n        # Truncate to expected length\n        gains = gains[:expected_length]\n\n    return gains",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81d29bee"
  },
  {
    "id": "migration_guide_13_120b41fd",
    "file": "docs\\factory\\migration_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef convert_legacy_format(old_config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Convert legacy configuration format to new structure.\"\"\"\n\n    new_config = {}\n\n    # Handle legacy controller_defaults structure\n    if 'controller_defaults' in old_config:\n        new_config['controllers'] = old_config['controller_defaults']\n\n    # Handle direct controller configuration\n    elif 'controllers' not in old_config:\n        # Assume root-level controller configuration\n        controllers = {}\n        for key, value in old_config.items():\n            if key in ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']:\n                controllers[key] = value\n\n        if controllers:\n            new_config['controllers'] = controllers\n        else:\n            new_config = old_config\n    else:\n        new_config = old_config\n\n    return new_config",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "120b41fd"
  },
  {
    "id": "migration_guide_14_b91e46dd",
    "file": "docs\\factory\\migration_guide.md",
    "index": 14,
    "code": "# Always backup before migration\nbackup_created = create_backup_before_migration(config_file)\nassert backup_created, \"Backup creation failed - aborting migration\"",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b91e46dd"
  },
  {
    "id": "migration_guide_15_c4d2d4c0",
    "file": "docs\\factory\\migration_guide.md",
    "index": 15,
    "code": "# Pre-migration validation\npre_validation = validate_configuration_syntax(original_config)\nif not pre_validation.success:\n    raise ValueError(f\"Original configuration invalid: {pre_validation.errors}\")\n\n# Post-migration validation\npost_validation = validate_migrated_configuration(migrated_config)\nif not post_validation.success:\n    restore_from_backup(backup_file)\n    raise ValueError(\"Migration validation failed - restored from backup\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4d2d4c0"
  },
  {
    "id": "migration_guide_16_ac8f2c6c",
    "file": "docs\\factory\\migration_guide.md",
    "index": 16,
    "code": "# Test migrated configuration with sample scenarios\ntest_scenarios = [\n    np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0]),  # Small disturbance\n    np.array([0.3, 0.4, 0.2, 0.1, 0.0, 0.0]),  # Medium angles\n]\n\nfor scenario in test_scenarios:\n    control_output = migrated_controller.compute_control(scenario, (), {})\n    assert np.isfinite(control_output.u), \"Control output must be finite\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac8f2c6c"
  },
  {
    "id": "migration_guide_17_7c99c384",
    "file": "docs\\factory\\migration_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef document_migration_changes(migration_log: List[str]) -> str:\n    \"\"\"Create documentation of migration changes for reference.\"\"\"\n\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    doc = f\"\"\"\nMigration Report - {timestamp}\n\nChanges Applied:\n{chr(10).join(f\"- {change}\" for change in migration_log)}\n\nValidation Status: PASSED\nNext Steps:\n- Update any hardcoded parameter references in code\n- Test controllers with actual plant dynamics\n- Update documentation and training materials\n\"\"\"\n\n    return doc",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c99c384"
  },
  {
    "id": "parameter_interface_specification_1_6bc3f8ad",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef _resolve_controller_gains(\n    gains: Optional[Union[List[float], np.ndarray]],\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> List[float]:\n    \"\"\"\n    Resolve controller gains from multiple sources with intelligent fallback.\n\n    Resolution Order:\n    1. Explicit gains parameter (if provided)\n    2. Configuration object gains extraction\n    3. Registry default gains\n    \"\"\"\n\n    # Priority 1: Explicit gains\n    if gains is not None:\n        if isinstance(gains, np.ndarray):\n            gains = gains.tolist()\n        return gains\n\n    # Priority 2: Configuration extraction\n    if config is not None:\n        try:\n            # Pattern A: config.controller_defaults structure\n            if hasattr(config, 'controller_defaults'):\n                defaults = config.controller_defaults\n                if isinstance(defaults, dict) and controller_type in defaults:\n                    config_gains = defaults[controller_type].get('gains')\n                    if config_gains is not None:\n                        return config_gains\n\n            # Pattern B: config.controllers structure\n            elif hasattr(config, 'controllers'):\n                controllers = config.controllers\n                if isinstance(controllers, dict) and controller_type in controllers:\n                    config_gains = controllers[controller_type].get('gains')\n                    if config_gains is not None:\n                        return config_gains\n\n        except Exception:\n            pass  # Fall through to default gains\n\n    # Priority 3: Registry defaults\n    return controller_info['default_gains']",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6bc3f8ad"
  },
  {
    "id": "parameter_interface_specification_2_473c850f",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Parameter Structure: [k1, k2, \u03bb1, \u03bb2, K, kd]\nClassicalSMCParameters = {\n    'gains': {\n        'count': 6,\n        'names': ['k1', 'k2', 'lambda1', 'lambda2', 'K', 'kd'],\n        'bounds': [(0.1, 50.0), (0.1, 50.0), (0.1, 20.0), (0.1, 20.0), (1.0, 200.0), (0.0, 50.0)],\n        'physical_meaning': {\n            'k1': 'First pendulum surface gain',\n            'k2': 'Second pendulum surface gain',\n            'lambda1': 'First pendulum sliding coefficient',\n            'lambda2': 'Second pendulum sliding coefficient',\n            'K': 'Switching control gain',\n            'kd': 'Damping gain for chattering reduction'\n        }\n    },\n    'required_params': ['boundary_layer'],\n    'optional_params': ['switch_method', 'damping_gain'],\n    'stability_constraints': [\n        'All gains must be positive',\n        'k1, k2 determine convergence rate',\n        '\u03bb1, \u03bb2 affect sliding surface slope',\n        'K must overcome system uncertainties',\n        'boundary_layer > 0 for chattering reduction'\n    ]\n}",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "473c850f"
  },
  {
    "id": "parameter_interface_specification_3_ba2f8a94",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Parameter Structure: [k1, k2, \u03bb1, \u03bb2, \u03b3]\nAdaptiveSMCParameters = {\n    'gains': {\n        'count': 5,\n        'names': ['k1', 'k2', 'lambda1', 'lambda2', 'gamma'],\n        'bounds': [(0.1, 50.0), (0.1, 50.0), (0.1, 25.0), (0.1, 25.0), (0.01, 10.0)],\n        'physical_meaning': {\n            'k1': 'First pendulum surface gain',\n            'k2': 'Second pendulum surface gain',\n            'lambda1': 'First pendulum sliding coefficient',\n            'lambda2': 'Second pendulum sliding coefficient',\n            'gamma': 'Adaptation rate for parameter estimation (gains[4])'\n        }\n    },\n    'gamma_extraction': {\n        'method': 'array_indexing',\n        'index': 4,\n        'validation': 'gamma = gains[4], must be in (0.01, 10.0)',\n        'deprecation_note': 'Separate gamma parameter deprecated in v2.0.0'\n    },\n    'adaptation_params': {\n        'leak_rate': 0.01,\n        'adapt_rate_limit': 10.0,\n        'K_min': 0.1,\n        'K_max': 100.0,\n        'K_init': 10.0,\n        'alpha': 0.5,\n        'dead_zone': 0.05\n    }\n}",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba2f8a94"
  },
  {
    "id": "parameter_interface_specification_4_2a111998",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Parameter Structure: [K1, K2, k1, k2, \u03bb1, \u03bb2]\nSuperTwistingSMCParameters = {\n    'gains': {\n        'count': 6,\n        'names': ['K1', 'K2', 'k1', 'k2', 'lambda1', 'lambda2'],\n        'bounds': [(1.0, 100.0), (1.0, 100.0), (0.1, 50.0), (0.1, 50.0), (0.1, 20.0), (0.1, 20.0)],\n        'physical_meaning': {\n            'K1': 'First-order sliding mode gain',\n            'K2': 'Second-order sliding mode gain',\n            'k1': 'First pendulum surface gain',\n            'k2': 'Second pendulum surface gain',\n            'lambda1': 'First pendulum sliding coefficient',\n            'lambda2': 'Second pendulum sliding coefficient'\n        }\n    },\n    'sta_specific_params': {\n        'power_exponent': 0.5,\n        'regularization': 1e-6,\n        'switch_method': 'tanh',\n        'damping_gain': 0.0\n    },\n    'convergence_properties': {\n        'finite_time_convergence': True,\n        'chattering_reduction': 'Built-in via continuous STA',\n        'robustness': 'High against matched uncertainties'\n    }\n}",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a111998"
  },
  {
    "id": "parameter_interface_specification_5_0160d606",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Parameter Structure: [k1, k2, \u03bb1, \u03bb2] (surface gains only)\nHybridSMCParameters = {\n    'gains': {\n        'count': 4,\n        'names': ['k1', 'k2', 'lambda1', 'lambda2'],\n        'bounds': [(0.1, 50.0), (0.1, 50.0), (0.1, 20.0), (0.1, 20.0)],\n        'physical_meaning': {\n            'k1': 'First pendulum surface gain',\n            'k2': 'Second pendulum surface gain',\n            'lambda1': 'First pendulum sliding coefficient',\n            'lambda2': 'Second pendulum sliding coefficient'\n        }\n    },\n    'sub_configurations': {\n        'classical_config': 'Full ClassicalSMCConfig instance',\n        'adaptive_config': 'Full AdaptiveSMCConfig instance',\n        'hybrid_mode': 'HybridMode.CLASSICAL_ADAPTIVE enum'\n    },\n    'initialization_gains': {\n        'k1_init': 5.0,\n        'k2_init': 3.0,\n        'gamma1': 0.5,\n        'gamma2': 0.3\n    }\n}",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0160d606"
  },
  {
    "id": "parameter_interface_specification_6_1a8aff63",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass ParameterValidator:\n    \"\"\"Comprehensive parameter validation for SMC controllers.\"\"\"\n\n    @staticmethod\n    def validate_gain_structure(\n        gains: List[float],\n        controller_type: str,\n        controller_info: Dict[str, Any]\n    ) -> None:\n        \"\"\"Validate gain array structure and constraints.\"\"\"\n\n        # 1. Length validation\n        expected_count = controller_info['gain_count']\n        if len(gains) != expected_count:\n            raise ValueError(\n                f\"Controller '{controller_type}' requires {expected_count} gains, \"\n                f\"got {len(gains)}. Expected structure: {controller_info.get('gain_names', [])}\"\n            )\n\n        # 2. Numerical validation\n        for i, gain in enumerate(gains):\n            if not isinstance(gain, (int, float)):\n                raise TypeError(f\"Gain[{i}] must be numeric, got {type(gain)}\")\n\n            if not np.isfinite(gain):\n                raise ValueError(f\"Gain[{i}] must be finite, got {gain}\")\n\n        # 3. Physical constraint validation\n        ParameterValidator._validate_physical_constraints(gains, controller_type)\n\n    @staticmethod\n    def _validate_physical_constraints(gains: List[float], controller_type: str) -> None:\n        \"\"\"Validate controller-specific physical constraints.\"\"\"\n\n        if controller_type == 'classical_smc':\n            # All gains must be positive for stability\n            if any(g <= 0 for g in gains):\n                raise ValueError(\"Classical SMC: All gains must be positive for stability\")\n\n            # Specific constraint: K (switching gain) should be significant\n            K = gains[4]  # K is 5th element\n            if K < 1.0:\n                warnings.warn(f\"Classical SMC: K={K} may be too small for effective switching\")\n\n        elif controller_type == 'adaptive_smc':\n            # Surface gains must be positive\n            if any(g <= 0 for g in gains[:4]):\n                raise ValueError(\"Adaptive SMC: Surface gains k1, k2, \u03bb1, \u03bb2 must be positive\")\n\n            # Gamma (adaptation rate) constraints\n            gamma = gains[4]\n            if gamma <= 0:\n                raise ValueError(\"Adaptive SMC: Adaptation rate \u03b3 must be positive\")\n            if gamma > 10.0:\n                warnings.warn(f\"Adaptive SMC: \u03b3={gamma} may cause adaptation instability\")\n\n        elif controller_type == 'sta_smc':\n            # All gains positive for STA stability\n            if any(g <= 0 for g in gains):\n                raise ValueError(\"STA-SMC: All gains must be positive\")\n\n            # STA-specific constraint: K1 > K2 typically\n            K1, K2 = gains[0], gains[1]\n            if K1 <= K2:\n                warnings.warn(\"STA-SMC: Typically K1 > K2 for proper STA operation\")\n\n        elif controller_type == 'hybrid_adaptive_sta_smc':\n            # Only surface gains for hybrid controller\n            if any(g <= 0 for g in gains):\n                raise ValueError(\"Hybrid SMC: All surface gains must be positive\")",
    "lines": 73,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a8aff63"
  },
  {
    "id": "parameter_interface_specification_7_263eb840",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_parameter_ranges(\n    gains: List[float],\n    controller_type: str,\n    bounds: Optional[List[Tuple[float, float]]] = None\n) -> None:\n    \"\"\"Validate parameters against acceptable ranges.\"\"\"\n\n    if bounds is None:\n        bounds = get_default_bounds(controller_type)\n\n    for i, (gain, (min_val, max_val)) in enumerate(zip(gains, bounds)):\n        if not (min_val <= gain <= max_val):\n            gain_name = get_gain_name(controller_type, i)\n            raise ValueError(\n                f\"Parameter {gain_name}[{i}] = {gain} outside valid range \"\n                f\"[{min_val}, {max_val}] for {controller_type}\"\n            )\n\ndef get_default_bounds(controller_type: str) -> List[Tuple[float, float]]:\n    \"\"\"Get default parameter bounds for controller type.\"\"\"\n    bounds_map = {\n        'classical_smc': [(0.1, 50.0)] * 4 + [(1.0, 200.0)] + [(0.0, 50.0)],\n        'adaptive_smc': [(0.1, 50.0)] * 4 + [(0.01, 10.0)],\n        'sta_smc': [(1.0, 100.0)] * 2 + [(0.1, 50.0)] * 4,\n        'hybrid_adaptive_sta_smc': [(0.1, 50.0)] * 4\n    }\n    return bounds_map.get(controller_type, [(0.1, 100.0)] * 6)",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "263eb840"
  },
  {
    "id": "parameter_interface_specification_8_fd43f9e6",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef _extract_controller_parameters(\n    config: Optional[Any],\n    controller_type: str,\n    controller_info: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"Extract controller-specific parameters from diverse configuration formats.\"\"\"\n\n    if config is None:\n        return {}\n\n    controller_params = {}\n\n    try:\n        # Method 1: Direct controller configuration\n        if hasattr(config, 'controllers') and controller_type in config.controllers:\n            controller_config = config.controllers[controller_type]\n\n            # Pydantic model with model_dump()\n            if hasattr(controller_config, 'model_dump'):\n                controller_params = controller_config.model_dump()\n\n            # Dictionary configuration\n            elif isinstance(controller_config, dict):\n                controller_params = controller_config.copy()\n\n            # Object with attributes\n            else:\n                controller_params = {\n                    attr: getattr(controller_config, attr)\n                    for attr in dir(controller_config)\n                    if not attr.startswith('_') and not callable(getattr(controller_config, attr))\n                }\n\n        # Method 2: Legacy controller_defaults structure\n        elif hasattr(config, 'controller_defaults'):\n            defaults = config.controller_defaults\n            if isinstance(defaults, dict) and controller_type in defaults:\n                controller_params = defaults[controller_type].copy()\n\n    except Exception as e:\n        logger.warning(f\"Parameter extraction failed for {controller_type}: {e}\")\n        return {}\n\n    return controller_params",
    "lines": 47,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd43f9e6"
  },
  {
    "id": "parameter_interface_specification_9_eb7b3686",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 9,
    "code": "def normalize_parameter_types(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Normalize parameter types for consistent processing.\"\"\"\n\n    normalized = {}\n\n    for key, value in params.items():\n        if key == 'gains':\n            # Convert gains to list of floats\n            if isinstance(value, np.ndarray):\n                normalized[key] = value.tolist()\n            elif isinstance(value, (list, tuple)):\n                normalized[key] = [float(g) for g in value]\n            else:\n                raise TypeError(f\"Invalid gains type: {type(value)}\")\n\n        elif key in ['max_force', 'dt', 'boundary_layer', 'leak_rate']:\n            # Convert numeric parameters\n            normalized[key] = float(value)\n\n        elif key in ['smooth_switch']:\n            # Convert boolean parameters\n            normalized[key] = bool(value)\n\n        elif key == 'hybrid_mode':\n            # Convert enum parameters\n            if isinstance(value, str):\n                from src.controllers.smc.algorithms.hybrid.config import HybridMode\n                normalized[key] = HybridMode(value)\n            else:\n                normalized[key] = value\n\n        else:\n            # Pass through other parameters\n            normalized[key] = value\n\n    return normalized",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb7b3686"
  },
  {
    "id": "parameter_interface_specification_10_0e0202d8",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass ParameterResolutionError(ValueError):\n    \"\"\"Raised when parameter resolution fails.\"\"\"\n    pass\n\nclass GainValidationError(ValueError):\n    \"\"\"Raised when gain validation fails.\"\"\"\n    pass\n\ndef create_controller_with_parameter_recovery(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any:\n    \"\"\"Create controller with comprehensive parameter recovery.\"\"\"\n\n    try:\n        # Primary creation attempt\n        return create_controller(controller_type, config, gains)\n\n    except GainValidationError as e:\n        logger.warning(f\"Gain validation failed: {e}\")\n\n        # Attempt recovery with default gains\n        default_gains = get_default_gains(controller_type)\n        logger.info(f\"Falling back to default gains: {default_gains}\")\n        return create_controller(controller_type, config, default_gains)\n\n    except ParameterResolutionError as e:\n        logger.warning(f\"Parameter resolution failed: {e}\")\n\n        # Attempt recovery with minimal configuration\n        minimal_config = create_minimal_config(controller_type)\n        return create_controller(controller_type, minimal_config, gains)\n\n    except Exception as e:\n        logger.error(f\"Controller creation failed completely: {e}\")\n        raise",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e0202d8"
  },
  {
    "id": "parameter_interface_specification_11_7b8b1dc9",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_minimal_config(controller_type: str) -> Dict[str, Any]:\n    \"\"\"Create minimal viable configuration for controller type.\"\"\"\n\n    base_config = {\n        'max_force': 150.0,\n        'dt': 0.001\n    }\n\n    # Add controller-specific minimal parameters\n    if controller_type == 'classical_smc':\n        base_config['boundary_layer'] = 0.02\n\n    elif controller_type == 'adaptive_smc':\n        base_config.update({\n            'leak_rate': 0.01,\n            'adapt_rate_limit': 10.0,\n            'K_min': 0.1,\n            'K_max': 100.0,\n            'K_init': 10.0,\n            'alpha': 0.5\n        })\n\n    elif controller_type == 'sta_smc':\n        base_config.update({\n            'power_exponent': 0.5,\n            'regularization': 1e-6,\n            'switch_method': 'tanh'\n        })\n\n    return base_config",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7b8b1dc9"
  },
  {
    "id": "parameter_interface_specification_12_7b15bd6b",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 12,
    "code": "# Conservative stable gains\n   conservative_gains = [8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n\n   # Aggressive performance gains\n   aggressive_gains = [20.0, 15.0, 12.0, 10.0, 35.0, 5.0]\n\n   # High-precision gains\n   precision_gains = [25.0, 20.0, 18.0, 15.0, 45.0, 8.0]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7b15bd6b"
  },
  {
    "id": "parameter_interface_specification_13_0e8496d4",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 13,
    "code": "# Slow adaptation (stable)\n   slow_adapt_gains = [12.0, 10.0, 6.0, 5.0, 0.5]\n\n   # Fast adaptation (responsive)\n   fast_adapt_gains = [15.0, 12.0, 10.0, 8.0, 3.0]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e8496d4"
  },
  {
    "id": "parameter_interface_specification_14_5baa100c",
    "file": "docs\\factory\\parameter_interface_specification.md",
    "index": 14,
    "code": "# Always validate before creation\n   validate_smc_gains(controller_type, gains)\n\n   # Use bounds checking\n   bounds = get_gain_bounds_for_pso(controller_type)\n   validate_parameter_ranges(gains, controller_type, bounds)\n\n   # Test with small disturbances first\n   test_controller_stability(controller, small_disturbance_state)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5baa100c"
  },
  {
    "id": "production_deployment_guide_1_4d98e9e7",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef production_readiness_check():\n    \"\"\"Comprehensive production readiness validation.\"\"\"\n\n    import time\n    import threading\n    import numpy as np\n    from src.controllers.factory import (\n        create_controller,\n        list_available_controllers,\n        get_default_gains,\n        create_pso_controller_factory,\n        SMCType\n    )\n\n    print(\"=== Production Readiness Assessment ===\\n\")\n\n    results = {\n        'basic_functionality': False,\n        'thread_safety': False,\n        'performance': False,\n        'pso_integration': False,\n        'error_handling': False,\n        'memory_stability': False\n    }\n\n    # 1. Basic Functionality Test\n    print(\"1. Testing Basic Functionality...\")\n    try:\n        controllers = list_available_controllers()\n        if len(controllers) >= 4:  # Expect at least 4 controller types\n            for controller_type in controllers:\n                gains = get_default_gains(controller_type)\n                controller = create_controller(controller_type, gains=gains)\n\n                # Test control computation\n                test_state = np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n                result = controller.compute_control(test_state, (), {})\n\n                control_value = result.u if hasattr(result, 'u') else result\n                if not np.isfinite(control_value):\n                    raise ValueError(f\"Invalid control output: {control_value}\")\n\n            results['basic_functionality'] = True\n            print(\"   \u2705 Basic functionality test PASSED\")\n        else:\n            print(f\"   \u274c Insufficient controllers available: {len(controllers)}\")\n\n    except Exception as e:\n        print(f\"   \u274c Basic functionality test FAILED: {e}\")\n\n    # 2. Thread Safety Test\n    print(\"\\n2. Testing Thread Safety...\")\n    try:\n        def concurrent_creation():\n            return create_controller('classical_smc', gains=[20]*6)\n\n        # Test concurrent controller creation\n        start_time = time.time()\n        threads = []\n        for _ in range(10):\n            thread = threading.Thread(target=concurrent_creation)\n            threads.append(thread)\n            thread.start()\n\n        for thread in threads:\n            thread.join(timeout=5)\n            if thread.is_alive():\n                raise TimeoutError(\"Thread did not complete in time\")\n\n        execution_time = time.time() - start_time\n        if execution_time < 10:  # Should complete within 10 seconds\n            results['thread_safety'] = True\n            print(f\"   \u2705 Thread safety test PASSED ({execution_time:.2f}s)\")\n        else:\n            print(f\"   \u274c Thread safety test SLOW ({execution_time:.2f}s)\")\n\n    except Exception as e:\n        print(f\"   \u274c Thread safety test FAILED: {e}\")\n\n    # 3. Performance Test\n    print(\"\\n3. Testing Performance...\")\n    try:\n        # Measure controller creation time\n        creation_times = []\n        for _ in range(100):\n            start = time.perf_counter()\n            create_controller('classical_smc', gains=[20]*6)\n            end = time.perf_counter()\n            creation_times.append((end - start) * 1000)  # Convert to ms\n\n        avg_time = sum(creation_times) / len(creation_times)\n        max_time = max(creation_times)\n\n        if avg_time < 5.0 and max_time < 50.0:  # < 5ms average, < 50ms max\n            results['performance'] = True\n            print(f\"   \u2705 Performance test PASSED (avg: {avg_time:.2f}ms, max: {max_time:.2f}ms)\")\n        else:\n            print(f\"   \u274c Performance test FAILED (avg: {avg_time:.2f}ms, max: {max_time:.2f}ms)\")\n\n    except Exception as e:\n        print(f\"   \u274c Performance test FAILED: {e}\")\n\n    # 4. PSO Integration Test\n    print(\"\\n4. Testing PSO Integration...\")\n    try:\n        factory_func = create_pso_controller_factory(SMCType.CLASSICAL)\n\n        # Check required attributes\n        if hasattr(factory_func, 'n_gains') and hasattr(factory_func, 'controller_type'):\n            test_gains = [20, 15, 12, 8, 35, 5]\n            controller = factory_func(test_gains)\n\n            if controller is not None:\n                results['pso_integration'] = True\n                print(\"   \u2705 PSO integration test PASSED\")\n            else:\n                print(\"   \u274c PSO factory returned None\")\n        else:\n            print(\"   \u274c PSO factory missing required attributes\")\n\n    except Exception as e:\n        print(f\"   \u274c PSO integration test FAILED: {e}\")\n\n    # 5. Error Handling Test\n    print(\"\\n5. Testing Error Handling...\")\n    try:\n        error_cases = [\n            ('invalid_type', [10]*6),\n            ('classical_smc', [10]*3),  # Wrong gain count\n            ('classical_smc', [-10]*6),  # Negative gains\n        ]\n\n        handled_errors = 0\n        for controller_type, gains in error_cases:\n            try:\n                create_controller(controller_type, gains=gains)\n                print(f\"   \u26a0\ufe0f Expected error not raised for {controller_type}\")\n            except (ValueError, TypeError) as e:\n                handled_errors += 1\n            except Exception as e:\n                print(f\"   \u26a0\ufe0f Unexpected error type for {controller_type}: {type(e)}\")\n\n        if handled_errors >= len(error_cases) - 1:  # Allow one unexpected case\n            results['error_handling'] = True\n            print(f\"   \u2705 Error handling test PASSED ({handled_errors}/{len(error_cases)} cases)\")\n        else:\n            print(f\"   \u274c Error handling test FAILED ({handled_errors}/{len(error_cases)} cases)\")\n\n    except Exception as e:\n        print(f\"   \u274c Error handling test FAILED: {e}\")\n\n    # 6. Memory Stability Test\n    print(\"\\n6. Testing Memory Stability...\")\n    try:\n        import psutil\n        import os\n\n        process = psutil.Process(os.getpid())\n        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n        # Create and destroy many controllers\n        for _ in range(1000):\n            controller = create_controller('classical_smc', gains=[20]*6)\n            del controller\n\n        final_memory = process.memory_info().rss / 1024 / 1024\n        memory_increase = final_memory - initial_memory\n\n        if memory_increase < 10:  # Less than 10MB increase\n            results['memory_stability'] = True\n            print(f\"   \u2705 Memory stability test PASSED ({memory_increase:.2f}MB increase)\")\n        else:\n            print(f\"   \u274c Memory stability test FAILED ({memory_increase:.2f}MB increase)\")\n\n    except ImportError:\n        print(\"   \u26a0\ufe0f psutil not available, skipping memory test\")\n        results['memory_stability'] = True  # Assume pass if can't test\n    except Exception as e:\n        print(f\"   \u274c Memory stability test FAILED: {e}\")\n\n    # Summary\n    passed_tests = sum(results.values())\n    total_tests = len(results)\n    success_rate = (passed_tests / total_tests) * 100\n\n    print(f\"\\n=== Production Readiness Summary ===\")\n    print(f\"Tests passed: {passed_tests}/{total_tests}\")\n    print(f\"Success rate: {success_rate:.1f}%\")\n\n    if success_rate >= 95:\n        print(\"\u2705 READY FOR PRODUCTION DEPLOYMENT\")\n        return True\n    elif success_rate >= 80:\n        print(\"\u26a0\ufe0f DEPLOYMENT WITH MONITORING RECOMMENDED\")\n        return False\n    else:\n        print(\"\u274c NOT READY FOR PRODUCTION\")\n        return False\n\n# Run production readiness check\nproduction_ready = production_readiness_check()",
    "lines": 204,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d98e9e7"
  },
  {
    "id": "production_deployment_guide_2_5606b2d8",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_production_dependencies():\n    \"\"\"Verify all required dependencies are available.\"\"\"\n\n    required_packages = {\n        'numpy': '>=1.19.0',\n        'scipy': '>=1.6.0',\n        'pydantic': '>=1.8.0',\n        'pyyaml': '>=5.4.0'\n    }\n\n    optional_packages = {\n        'psutil': '>=5.8.0',  # For memory monitoring\n        'prometheus_client': '>=0.12.0',  # For metrics\n        'structlog': '>=21.0.0'  # For structured logging\n    }\n\n    print(\"Verifying production dependencies...\")\n\n    # Check required packages\n    for package, version in required_packages.items():\n        try:\n            __import__(package)\n            print(f\"\u2705 {package} {version} - Available\")\n        except ImportError:\n            print(f\"\u274c {package} {version} - MISSING (REQUIRED)\")\n            return False\n\n    # Check optional packages\n    for package, version in optional_packages.items():\n        try:\n            __import__(package)\n            print(f\"\u2705 {package} {version} - Available\")\n        except ImportError:\n            print(f\"\u26a0\ufe0f {package} {version} - Missing (optional)\")\n\n    return True\n\n# Verify dependencies\ndependencies_ok = verify_production_dependencies()",
    "lines": 42,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5606b2d8"
  },
  {
    "id": "production_deployment_guide_3_00833f07",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ProductionFactoryDeployment:\n    \"\"\"Production deployment manager for factory system.\"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        self.current_version = None\n        self.new_version = None\n        self.rollback_data = {}\n\n    def pre_deployment_checks(self):\n        \"\"\"Run comprehensive pre-deployment validation.\"\"\"\n\n        checks = {\n            'dependencies': self.verify_dependencies(),\n            'configuration': self.validate_configuration(),\n            'compatibility': self.check_backward_compatibility(),\n            'performance': self.benchmark_performance(),\n            'health': self.health_check()\n        }\n\n        passed = all(checks.values())\n        failed_checks = [name for name, result in checks.items() if not result]\n\n        if not passed:\n            raise RuntimeError(f\"Pre-deployment checks failed: {failed_checks}\")\n\n        return checks\n\n    def deploy_with_canary(self, percentage=10):\n        \"\"\"Deploy new factory version using canary strategy.\"\"\"\n\n        print(f\"Starting canary deployment ({percentage}% traffic)\")\n\n        # 1. Deploy to canary environment\n        canary_success = self.deploy_canary()\n        if not canary_success:\n            raise RuntimeError(\"Canary deployment failed\")\n\n        # 2. Monitor canary performance\n        canary_metrics = self.monitor_canary(duration=300)  # 5 minutes\n        if not self.evaluate_canary_metrics(canary_metrics):\n            self.rollback_canary()\n            raise RuntimeError(\"Canary metrics below threshold\")\n\n        # 3. Gradual rollout\n        for percentage in [25, 50, 75, 100]:\n            print(f\"Rolling out to {percentage}% of traffic\")\n            self.update_traffic_split(percentage)\n\n            metrics = self.monitor_deployment(duration=180)  # 3 minutes\n            if not self.evaluate_metrics(metrics):\n                self.rollback_deployment()\n                raise RuntimeError(f\"Rollout failed at {percentage}%\")\n\n        print(\"\u2705 Deployment completed successfully\")\n        return True\n\n    def rollback_deployment(self):\n        \"\"\"Rollback to previous version.\"\"\"\n\n        print(\"\ud83d\udd04 Rolling back deployment\")\n\n        # Restore previous factory version\n        self.restore_factory_version()\n\n        # Verify rollback success\n        health_ok = self.health_check()\n        if not health_ok:\n            raise RuntimeError(\"Rollback verification failed\")\n\n        print(\"\u2705 Rollback completed successfully\")\n\n# Example deployment\ndeployment = ProductionFactoryDeployment(production_config)\ndeployment.pre_deployment_checks()\ndeployment.deploy_with_canary()",
    "lines": 79,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "00833f07"
  },
  {
    "id": "production_deployment_guide_4_d6de79e9",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef blue_green_deployment():\n    \"\"\"Blue-green deployment strategy.\"\"\"\n\n    print(\"Starting blue-green deployment\")\n\n    # Setup green environment\n    green_env = setup_green_environment()\n\n    # Deploy to green environment\n    deploy_to_green(green_env)\n\n    # Smoke test green environment\n    if not smoke_test_green(green_env):\n        cleanup_green(green_env)\n        raise RuntimeError(\"Green environment smoke test failed\")\n\n    # Switch traffic to green\n    switch_traffic_to_green(green_env)\n\n    # Monitor for issues\n    monitor_duration = 600  # 10 minutes\n    if monitor_green_environment(monitor_duration):\n        # Success - cleanup blue environment\n        cleanup_blue_environment()\n        print(\"\u2705 Blue-green deployment successful\")\n    else:\n        # Issues detected - rollback to blue\n        switch_traffic_to_blue()\n        cleanup_green(green_env)\n        raise RuntimeError(\"Green environment issues detected, rolled back\")\n\n# Run blue-green deployment\nblue_green_deployment()",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6de79e9"
  },
  {
    "id": "production_deployment_guide_5_689c083c",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 5,
    "code": "class FactoryPerformanceMonitor:\n    \"\"\"Production performance monitoring for factory system.\"\"\"\n\n    def __init__(self):\n        self.metrics = {\n            'controller_creation_time': [],\n            'controller_creation_rate': [],\n            'error_rate': [],\n            'memory_usage': [],\n            'thread_contention': [],\n            'cache_hit_rate': []\n        }\n\n    def collect_metrics(self):\n        \"\"\"Collect current performance metrics.\"\"\"\n\n        import time\n        import psutil\n        import os\n        from src.controllers.factory import create_controller\n\n        # Controller creation time\n        start_time = time.perf_counter()\n        try:\n            create_controller('classical_smc', gains=[20]*6)\n            creation_time = (time.perf_counter() - start_time) * 1000\n            self.metrics['controller_creation_time'].append(creation_time)\n        except Exception:\n            self.metrics['error_rate'].append(1)\n\n        # Memory usage\n        process = psutil.Process(os.getpid())\n        memory_mb = process.memory_info().rss / 1024 / 1024\n        self.metrics['memory_usage'].append(memory_mb)\n\n        # Keep only recent metrics (last 1000 samples)\n        for metric_name in self.metrics:\n            if len(self.metrics[metric_name]) > 1000:\n                self.metrics[metric_name] = self.metrics[metric_name][-1000:]\n\n    def get_metrics_summary(self):\n        \"\"\"Generate metrics summary for monitoring dashboard.\"\"\"\n\n        import statistics\n\n        summary = {}\n\n        for metric_name, values in self.metrics.items():\n            if values:\n                summary[metric_name] = {\n                    'current': values[-1],\n                    'mean': statistics.mean(values),\n                    'median': statistics.median(values),\n                    'min': min(values),\n                    'max': max(values),\n                    'count': len(values)\n                }\n\n                if len(values) > 1:\n                    summary[metric_name]['std'] = statistics.stdev(values)\n\n        return summary\n\n    def check_alert_thresholds(self):\n        \"\"\"Check if any metrics exceed alert thresholds.\"\"\"\n\n        alerts = []\n        thresholds = {\n            'controller_creation_time': {'max': 10.0},  # 10ms\n            'error_rate': {'max': 0.01},  # 1%\n            'memory_usage': {'max': 1000.0},  # 1GB\n        }\n\n        summary = self.get_metrics_summary()\n\n        for metric_name, threshold in thresholds.items():\n            if metric_name in summary:\n                current_value = summary[metric_name]['current']\n                max_threshold = threshold.get('max')\n\n                if max_threshold and current_value > max_threshold:\n                    alerts.append({\n                        'metric': metric_name,\n                        'current': current_value,\n                        'threshold': max_threshold,\n                        'severity': 'critical' if current_value > max_threshold * 2 else 'warning'\n                    })\n\n        return alerts\n\n# Setup monitoring\nmonitor = FactoryPerformanceMonitor()\n\n# Continuous monitoring loop (would run in separate thread)\ndef monitoring_loop():\n    while True:\n        monitor.collect_metrics()\n        alerts = monitor.check_alert_thresholds()\n\n        if alerts:\n            for alert in alerts:\n                print(f\"ALERT: {alert['metric']} = {alert['current']} > {alert['threshold']}\")\n\n        time.sleep(60)  # Collect metrics every minute",
    "lines": 104,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "689c083c"
  },
  {
    "id": "production_deployment_guide_6_e7d750bc",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 6,
    "code": "class FactoryHealthChecker:\n    \"\"\"Production health checking for factory system.\"\"\"\n\n    def __init__(self):\n        self.health_history = []\n\n    def perform_health_check(self):\n        \"\"\"Comprehensive health check.\"\"\"\n\n        health_status = {\n            'timestamp': time.time(),\n            'overall_status': 'healthy',\n            'checks': {}\n        }\n\n        # Basic functionality check\n        health_status['checks']['basic_functionality'] = self.check_basic_functionality()\n\n        # Performance check\n        health_status['checks']['performance'] = self.check_performance()\n\n        # Memory check\n        health_status['checks']['memory'] = self.check_memory_usage()\n\n        # Thread safety check\n        health_status['checks']['thread_safety'] = self.check_thread_safety()\n\n        # Error rate check\n        health_status['checks']['error_rate'] = self.check_error_rate()\n\n        # Determine overall status\n        failed_checks = [name for name, status in health_status['checks'].items()\n                        if not status.get('healthy', False)]\n\n        if failed_checks:\n            health_status['overall_status'] = 'degraded' if len(failed_checks) <= 2 else 'unhealthy'\n\n        self.health_history.append(health_status)\n\n        # Keep only recent history\n        if len(self.health_history) > 100:\n            self.health_history = self.health_history[-100:]\n\n        return health_status\n\n    def check_basic_functionality(self):\n        \"\"\"Check basic factory functionality.\"\"\"\n\n        try:\n            from src.controllers.factory import create_controller, list_available_controllers\n\n            controllers = list_available_controllers()\n            if len(controllers) < 4:\n                return {'healthy': False, 'reason': 'Insufficient controllers available'}\n\n            # Test one controller creation\n            controller = create_controller('classical_smc', gains=[20]*6)\n            test_state = np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n            result = controller.compute_control(test_state, (), {})\n\n            control_value = result.u if hasattr(result, 'u') else result\n            if not np.isfinite(control_value):\n                return {'healthy': False, 'reason': 'Invalid control output'}\n\n            return {'healthy': True, 'controllers_available': len(controllers)}\n\n        except Exception as e:\n            return {'healthy': False, 'reason': str(e)}\n\n    def check_performance(self):\n        \"\"\"Check factory performance.\"\"\"\n\n        try:\n            import time\n            from src.controllers.factory import create_controller\n\n            # Measure creation time\n            times = []\n            for _ in range(10):\n                start = time.perf_counter()\n                create_controller('classical_smc', gains=[20]*6)\n                times.append((time.perf_counter() - start) * 1000)\n\n            avg_time = sum(times) / len(times)\n            max_time = max(times)\n\n            if avg_time > 10 or max_time > 50:  # ms\n                return {\n                    'healthy': False,\n                    'reason': f'Slow performance: avg={avg_time:.2f}ms, max={max_time:.2f}ms'\n                }\n\n            return {\n                'healthy': True,\n                'avg_creation_time_ms': avg_time,\n                'max_creation_time_ms': max_time\n            }\n\n        except Exception as e:\n            return {'healthy': False, 'reason': str(e)}\n\n    def check_memory_usage(self):\n        \"\"\"Check memory usage.\"\"\"\n\n        try:\n            import psutil\n            import os\n\n            process = psutil.Process(os.getpid())\n            memory_mb = process.memory_info().rss / 1024 / 1024\n\n            if memory_mb > 1000:  # 1GB threshold\n                return {\n                    'healthy': False,\n                    'reason': f'High memory usage: {memory_mb:.2f}MB'\n                }\n\n            return {\n                'healthy': True,\n                'memory_usage_mb': memory_mb\n            }\n\n        except ImportError:\n            return {'healthy': True, 'reason': 'psutil not available'}\n        except Exception as e:\n            return {'healthy': False, 'reason': str(e)}\n\n    def check_thread_safety(self):\n        \"\"\"Check thread safety.\"\"\"\n\n        try:\n            import threading\n            import time\n            from src.controllers.factory import create_controller\n\n            def create_controller_thread():\n                create_controller('classical_smc', gains=[20]*6)\n\n            start_time = time.time()\n            threads = []\n\n            for _ in range(5):\n                thread = threading.Thread(target=create_controller_thread)\n                threads.append(thread)\n                thread.start()\n\n            for thread in threads:\n                thread.join(timeout=5)\n                if thread.is_alive():\n                    return {'healthy': False, 'reason': 'Thread timeout detected'}\n\n            execution_time = time.time() - start_time\n            if execution_time > 10:\n                return {\n                    'healthy': False,\n                    'reason': f'Slow thread execution: {execution_time:.2f}s'\n                }\n\n            return {\n                'healthy': True,\n                'thread_execution_time_s': execution_time\n            }\n\n        except Exception as e:\n            return {'healthy': False, 'reason': str(e)}\n\n    def check_error_rate(self):\n        \"\"\"Check recent error rate.\"\"\"\n\n        try:\n            # Get recent health checks\n            recent_checks = self.health_history[-10:] if len(self.health_history) >= 10 else self.health_history\n\n            if not recent_checks:\n                return {'healthy': True, 'reason': 'No history available'}\n\n            failed_checks = sum(1 for check in recent_checks\n                              if check['overall_status'] != 'healthy')\n\n            error_rate = failed_checks / len(recent_checks)\n\n            if error_rate > 0.2:  # 20% error rate\n                return {\n                    'healthy': False,\n                    'reason': f'High error rate: {error_rate:.1%}'\n                }\n\n            return {\n                'healthy': True,\n                'error_rate': error_rate,\n                'sample_size': len(recent_checks)\n            }\n\n        except Exception as e:\n            return {'healthy': False, 'reason': str(e)}\n\n# Setup health checker\nhealth_checker = FactoryHealthChecker()\n\n# Health check endpoint (for load balancer)\ndef health_check_endpoint():\n    \"\"\"Health check endpoint for load balancers.\"\"\"\n\n    health_status = health_checker.perform_health_check()\n\n    if health_status['overall_status'] == 'healthy':\n        return {'status': 'ok', 'timestamp': health_status['timestamp']}, 200\n    elif health_status['overall_status'] == 'degraded':\n        return {'status': 'degraded', 'details': health_status['checks']}, 200\n    else:\n        return {'status': 'unhealthy', 'details': health_status['checks']}, 503",
    "lines": 211,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e7d750bc"
  },
  {
    "id": "production_deployment_guide_7_eff83099",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass FactoryAlertManager:\n    \"\"\"Production alerting for factory system.\"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        self.alert_history = []\n        self.suppression_rules = {}\n\n    def evaluate_alerts(self, metrics, health_status):\n        \"\"\"Evaluate alert conditions.\"\"\"\n\n        alerts = []\n\n        # Performance alerts\n        if 'controller_creation_time' in metrics:\n            avg_time = metrics['controller_creation_time']['mean']\n            if avg_time > 10:  # 10ms threshold\n                alerts.append({\n                    'type': 'performance',\n                    'severity': 'warning' if avg_time < 20 else 'critical',\n                    'message': f'High controller creation time: {avg_time:.2f}ms',\n                    'metric': 'controller_creation_time',\n                    'value': avg_time,\n                    'threshold': 10\n                })\n\n        # Memory alerts\n        if 'memory_usage' in metrics:\n            memory_mb = metrics['memory_usage']['current']\n            if memory_mb > 500:  # 500MB threshold\n                alerts.append({\n                    'type': 'memory',\n                    'severity': 'warning' if memory_mb < 1000 else 'critical',\n                    'message': f'High memory usage: {memory_mb:.2f}MB',\n                    'metric': 'memory_usage',\n                    'value': memory_mb,\n                    'threshold': 500\n                })\n\n        # Health alerts\n        if health_status['overall_status'] != 'healthy':\n            failed_checks = [name for name, check in health_status['checks'].items()\n                           if not check.get('healthy', False)]\n\n            alerts.append({\n                'type': 'health',\n                'severity': 'critical' if health_status['overall_status'] == 'unhealthy' else 'warning',\n                'message': f'Health check failed: {\", \".join(failed_checks)}',\n                'failed_checks': failed_checks\n            })\n\n        # Apply suppression rules\n        alerts = self.apply_suppression(alerts)\n\n        # Send notifications\n        for alert in alerts:\n            self.send_notification(alert)\n\n        return alerts\n\n    def apply_suppression(self, alerts):\n        \"\"\"Apply alert suppression rules.\"\"\"\n\n        suppressed_alerts = []\n\n        for alert in alerts:\n            alert_key = f\"{alert['type']}_{alert.get('metric', 'unknown')}\"\n\n            # Check if alert is already suppressed\n            if alert_key in self.suppression_rules:\n                last_sent = self.suppression_rules[alert_key]\n                if time.time() - last_sent < 300:  # 5 minute suppression\n                    continue\n\n            suppressed_alerts.append(alert)\n            self.suppression_rules[alert_key] = time.time()\n\n        return suppressed_alerts\n\n    def send_notification(self, alert):\n        \"\"\"Send alert notification.\"\"\"\n\n        print(f\"\ud83d\udea8 ALERT [{alert['severity'].upper()}]: {alert['message']}\")\n\n        # In production, integrate with:\n        # - Slack/Teams notifications\n        # - PagerDuty\n        # - Email alerts\n        # - SMS notifications\n        # - Monitoring dashboards\n\n        self.alert_history.append({\n            'timestamp': time.time(),\n            'alert': alert\n        })\n\n# Setup alert manager\nalert_manager = FactoryAlertManager(production_config)",
    "lines": 101,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eff83099"
  },
  {
    "id": "production_deployment_guide_8_ca55e2e4",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass FactoryMaintenanceManager:\n    \"\"\"Production maintenance for factory system.\"\"\"\n\n    def __init__(self):\n        self.maintenance_log = []\n\n    def daily_maintenance(self):\n        \"\"\"Daily maintenance tasks.\"\"\"\n\n        print(\"Running daily maintenance...\")\n\n        tasks = [\n            ('Health Check', self.comprehensive_health_check),\n            ('Performance Validation', self.validate_performance),\n            ('Memory Cleanup', self.memory_cleanup),\n            ('Log Rotation', self.rotate_logs),\n            ('Cache Cleanup', self.cleanup_cache),\n            ('Metrics Collection', self.collect_daily_metrics)\n        ]\n\n        results = {}\n        for task_name, task_func in tasks:\n            try:\n                print(f\"  Running {task_name}...\")\n                result = task_func()\n                results[task_name] = {'success': True, 'result': result}\n                print(f\"    \u2705 {task_name} completed\")\n            except Exception as e:\n                results[task_name] = {'success': False, 'error': str(e)}\n                print(f\"    \u274c {task_name} failed: {e}\")\n\n        self.log_maintenance_results('daily', results)\n        return results\n\n    def weekly_maintenance(self):\n        \"\"\"Weekly maintenance tasks.\"\"\"\n\n        print(\"Running weekly maintenance...\")\n\n        tasks = [\n            ('Deep Performance Analysis', self.deep_performance_analysis),\n            ('Memory Leak Detection', self.detect_memory_leaks),\n            ('Configuration Validation', self.validate_configuration),\n            ('Dependency Updates Check', self.check_dependency_updates),\n            ('Security Scan', self.security_scan),\n            ('Backup Verification', self.verify_backups)\n        ]\n\n        results = {}\n        for task_name, task_func in tasks:\n            try:\n                print(f\"  Running {task_name}...\")\n                result = task_func()\n                results[task_name] = {'success': True, 'result': result}\n                print(f\"    \u2705 {task_name} completed\")\n            except Exception as e:\n                results[task_name] = {'success': False, 'error': str(e)}\n                print(f\"    \u274c {task_name} failed: {e}\")\n\n        self.log_maintenance_results('weekly', results)\n        return results\n\n    def comprehensive_health_check(self):\n        \"\"\"Comprehensive health validation.\"\"\"\n\n        # Run extended health checks\n        health_checker = FactoryHealthChecker()\n        return health_checker.perform_health_check()\n\n    def validate_performance(self):\n        \"\"\"Validate factory performance meets SLAs.\"\"\"\n\n        from src.controllers.factory import create_controller\n        import time\n\n        # Performance test\n        creation_times = []\n        for _ in range(100):\n            start = time.perf_counter()\n            create_controller('classical_smc', gains=[20]*6)\n            creation_times.append((time.perf_counter() - start) * 1000)\n\n        avg_time = sum(creation_times) / len(creation_times)\n        p95_time = sorted(creation_times)[95]\n        p99_time = sorted(creation_times)[99]\n\n        # SLA validation\n        sla_results = {\n            'average_creation_time_ms': avg_time,\n            'p95_creation_time_ms': p95_time,\n            'p99_creation_time_ms': p99_time,\n            'sla_met': avg_time < 5.0 and p95_time < 10.0 and p99_time < 25.0\n        }\n\n        return sla_results\n\n    def memory_cleanup(self):\n        \"\"\"Cleanup memory and optimize garbage collection.\"\"\"\n\n        import gc\n        import psutil\n        import os\n\n        # Force garbage collection\n        before_memory = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n        collected = gc.collect()\n        after_memory = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024\n\n        return {\n            'objects_collected': collected,\n            'memory_before_mb': before_memory,\n            'memory_after_mb': after_memory,\n            'memory_freed_mb': before_memory - after_memory\n        }\n\n    def rotate_logs(self):\n        \"\"\"Rotate and compress log files.\"\"\"\n\n        # Implement log rotation logic\n        return {'logs_rotated': 0, 'size_saved_mb': 0}\n\n    def cleanup_cache(self):\n        \"\"\"Cleanup factory cache if implemented.\"\"\"\n\n        # Implement cache cleanup logic\n        return {'cache_entries_removed': 0}\n\n    def collect_daily_metrics(self):\n        \"\"\"Collect and store daily metrics.\"\"\"\n\n        # Collect metrics for historical analysis\n        return {'metrics_collected': True}\n\n    def log_maintenance_results(self, maintenance_type, results):\n        \"\"\"Log maintenance results.\"\"\"\n\n        maintenance_record = {\n            'timestamp': time.time(),\n            'type': maintenance_type,\n            'results': results,\n            'success_rate': sum(1 for r in results.values() if r['success']) / len(results)\n        }\n\n        self.maintenance_log.append(maintenance_record)\n        print(f\"Maintenance {maintenance_type} completed with {maintenance_record['success_rate']:.1%} success rate\")\n\n# Setup maintenance manager\nmaintenance_manager = FactoryMaintenanceManager()\n\n# Schedule maintenance tasks\ndef schedule_maintenance():\n    \"\"\"Schedule regular maintenance tasks.\"\"\"\n\n    import schedule\n\n    # Daily maintenance at 2 AM\n    schedule.every().day.at(\"02:00\").do(maintenance_manager.daily_maintenance)\n\n    # Weekly maintenance on Sunday at 3 AM\n    schedule.every().sunday.at(\"03:00\").do(maintenance_manager.weekly_maintenance)\n\n    # Run scheduled tasks\n    while True:\n        schedule.run_pending()\n        time.sleep(60)  # Check every minute",
    "lines": 168,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca55e2e4"
  },
  {
    "id": "production_deployment_guide_9_42166c1a",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 9,
    "code": "class FactoryCapacityPlanner:\n    \"\"\"Capacity planning for factory system.\"\"\"\n\n    def __init__(self):\n        self.capacity_data = []\n\n    def analyze_capacity_trends(self):\n        \"\"\"Analyze capacity trends and predict future needs.\"\"\"\n\n        # Collect current usage data\n        current_metrics = self.collect_capacity_metrics()\n\n        # Analyze trends\n        trends = self.analyze_trends()\n\n        # Generate recommendations\n        recommendations = self.generate_capacity_recommendations(trends)\n\n        return {\n            'current_metrics': current_metrics,\n            'trends': trends,\n            'recommendations': recommendations\n        }\n\n    def collect_capacity_metrics(self):\n        \"\"\"Collect current capacity metrics.\"\"\"\n\n        import psutil\n        import os\n\n        process = psutil.Process(os.getpid())\n\n        return {\n            'timestamp': time.time(),\n            'cpu_percent': process.cpu_percent(),\n            'memory_mb': process.memory_info().rss / 1024 / 1024,\n            'thread_count': process.num_threads(),\n            'open_files': process.num_fds() if hasattr(process, 'num_fds') else 0\n        }\n\n    def analyze_trends(self):\n        \"\"\"Analyze usage trends.\"\"\"\n\n        if len(self.capacity_data) < 2:\n            return {'insufficient_data': True}\n\n        # Simple trend analysis\n        recent_data = self.capacity_data[-10:]  # Last 10 measurements\n\n        memory_trend = 'stable'\n        cpu_trend = 'stable'\n\n        if len(recent_data) >= 5:\n            memory_values = [d['memory_mb'] for d in recent_data]\n            cpu_values = [d['cpu_percent'] for d in recent_data]\n\n            # Simple trend detection\n            if memory_values[-1] > memory_values[0] * 1.2:\n                memory_trend = 'increasing'\n            elif memory_values[-1] < memory_values[0] * 0.8:\n                memory_trend = 'decreasing'\n\n            if cpu_values[-1] > cpu_values[0] * 1.2:\n                cpu_trend = 'increasing'\n            elif cpu_values[-1] < cpu_values[0] * 0.8:\n                cpu_trend = 'decreasing'\n\n        return {\n            'memory_trend': memory_trend,\n            'cpu_trend': cpu_trend,\n            'data_points': len(recent_data)\n        }\n\n    def generate_capacity_recommendations(self, trends):\n        \"\"\"Generate capacity planning recommendations.\"\"\"\n\n        recommendations = []\n\n        if trends.get('memory_trend') == 'increasing':\n            recommendations.append({\n                'type': 'memory',\n                'action': 'Monitor memory usage closely and consider increasing memory limits',\n                'priority': 'medium'\n            })\n\n        if trends.get('cpu_trend') == 'increasing':\n            recommendations.append({\n                'type': 'cpu',\n                'action': 'Consider CPU optimization or horizontal scaling',\n                'priority': 'medium'\n            })\n\n        return recommendations\n\n# Setup capacity planner\ncapacity_planner = FactoryCapacityPlanner()",
    "lines": 96,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42166c1a"
  },
  {
    "id": "production_deployment_guide_10_2b74ede7",
    "file": "docs\\factory\\production_deployment_guide.md",
    "index": 10,
    "code": "class FactoryEmergencyResponse:\n    \"\"\"Emergency response procedures for production issues.\"\"\"\n\n    def __init__(self):\n        self.emergency_log = []\n\n    def handle_emergency(self, issue_type, severity, description):\n        \"\"\"Handle emergency production issues.\"\"\"\n\n        emergency_record = {\n            'timestamp': time.time(),\n            'issue_type': issue_type,\n            'severity': severity,\n            'description': description,\n            'actions_taken': [],\n            'resolution_time': None,\n            'resolved': False\n        }\n\n        print(f\"\ud83d\udea8 EMERGENCY: {severity} {issue_type} - {description}\")\n\n        try:\n            if issue_type == 'factory_failure':\n                emergency_record['actions_taken'].extend(\n                    self.handle_factory_failure(severity)\n                )\n            elif issue_type == 'performance_degradation':\n                emergency_record['actions_taken'].extend(\n                    self.handle_performance_degradation(severity)\n                )\n            elif issue_type == 'memory_leak':\n                emergency_record['actions_taken'].extend(\n                    self.handle_memory_leak(severity)\n                )\n            elif issue_type == 'thread_deadlock':\n                emergency_record['actions_taken'].extend(\n                    self.handle_thread_deadlock(severity)\n                )\n\n            emergency_record['resolved'] = True\n            emergency_record['resolution_time'] = time.time()\n\n        except Exception as e:\n            emergency_record['actions_taken'].append(f\"Emergency handling failed: {e}\")\n            print(f\"\u274c Emergency handling failed: {e}\")\n\n        self.emergency_log.append(emergency_record)\n        return emergency_record\n\n    def handle_factory_failure(self, severity):\n        \"\"\"Handle factory system failures.\"\"\"\n\n        actions = []\n\n        if severity == 'critical':\n            # Immediate actions for critical failures\n            actions.extend([\n                \"Activated emergency fallback mode\",\n                \"Notified on-call engineer\",\n                \"Initiated system restart procedure\"\n            ])\n\n            # Emergency fallback\n            self.activate_emergency_fallback()\n\n        elif severity == 'high':\n            # High severity actions\n            actions.extend([\n                \"Enabled degraded mode operation\",\n                \"Increased monitoring frequency\",\n                \"Scheduled emergency maintenance\"\n            ])\n\n        return actions\n\n    def handle_performance_degradation(self, severity):\n        \"\"\"Handle performance degradation issues.\"\"\"\n\n        actions = []\n\n        # Immediate performance optimization\n        actions.append(\"Triggered garbage collection\")\n        gc.collect()\n\n        # Check resource usage\n        import psutil\n        memory_percent = psutil.virtual_memory().percent\n        cpu_percent = psutil.cpu_percent(interval=1)\n\n        if memory_percent > 90:\n            actions.append(\"High memory usage detected - clearing caches\")\n            # Clear any caches\n\n        if cpu_percent > 90:\n            actions.append(\"High CPU usage detected - throttling operations\")\n            # Implement throttling\n\n        return actions\n\n    def handle_memory_leak(self, severity):\n        \"\"\"Handle memory leak issues.\"\"\"\n\n        actions = []\n\n        # Force garbage collection\n        import gc\n        collected = gc.collect()\n        actions.append(f\"Forced garbage collection - collected {collected} objects\")\n\n        # Memory analysis\n        import psutil\n        memory_mb = psutil.Process().memory_info().rss / 1024 / 1024\n        actions.append(f\"Current memory usage: {memory_mb:.2f}MB\")\n\n        if severity == 'critical':\n            actions.append(\"Scheduled emergency restart\")\n            # Schedule restart during low-traffic period\n\n        return actions\n\n    def handle_thread_deadlock(self, severity):\n        \"\"\"Handle thread deadlock issues.\"\"\"\n\n        actions = []\n\n        # Thread analysis\n        import threading\n        thread_count = threading.active_count()\n        actions.append(f\"Active threads: {thread_count}\")\n\n        if severity == 'critical':\n            actions.append(\"Initiated emergency restart\")\n            # Emergency restart procedure\n\n        return actions\n\n    def activate_emergency_fallback(self):\n        \"\"\"Activate emergency fallback mode.\"\"\"\n\n        print(\"\ud83d\udd04 Activating emergency fallback mode\")\n\n        # Implement emergency fallback:\n        # - Use minimal controller implementations\n        # - Disable advanced features\n        # - Route to backup systems\n\n# Setup emergency response\nemergency_response = FactoryEmergencyResponse()",
    "lines": 148,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b74ede7"
  },
  {
    "id": "pso_factory_api_reference_1_684ccc4f",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 1,
    "code": "# Core PSO-Factory integration\nfrom controllers import (\n    SMCType,                    # Controller type enumeration\n    create_smc_for_pso,        # Primary PSO interface\n    get_gain_bounds_for_pso,   # Mathematical bounds\n    validate_smc_gains,        # Constraint validation\n    PSOControllerWrapper       # PSO-optimized wrapper\n)\n\n# Advanced PSO workflows\nfrom controllers.factory import (\n    SMCFactory,                # Full factory interface\n    SMCConfig,                 # Type-safe configuration\n    SMCGainSpec               # Gain specifications\n)\n\n# Performance monitoring\nfrom controllers.factory.monitoring import (\n    PSOPerformanceMonitor,     # Real-time monitoring\n    PSOBenchmarkSuite         # Comprehensive benchmarking\n)",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "684ccc4f"
  },
  {
    "id": "pso_factory_api_reference_2_6e6a6003",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCType(Enum):\n    \"\"\"\n    Enumeration of supported SMC controller types for PSO optimization.\n\n    Each type corresponds to a specific sliding mode control algorithm\n    with distinct mathematical properties and parameter requirements.\n    \"\"\"\n\n    CLASSICAL = \"classical_smc\"\n    \"\"\"\n    Classical sliding mode controller with boundary layer.\n\n    Mathematical Model:\n        u = u_eq + u_sw\n        u_eq = (GB)^(-1)[-Gf(x) + \u1e61_ref]\n        u_sw = -K\u00b7tanh(s/\u03c6)\n\n    Gain Parameters: [k1, k2, \u03bb1, \u03bb2, K, kd]\n        k1, k2: Position gains for pendulum 1 and 2\n        \u03bb1, \u03bb2: Surface gains for pendulum 1 and 2\n        K: Switching gain\n        kd: Damping gain\n\n    Mathematical Constraints:\n        - \u03bb1, \u03bb2, K > 0 (stability requirement)\n        - kd \u2265 0 (non-negative damping)\n\n    PSO Bounds: [(0.1,50), (0.1,50), (1,50), (1,50), (1,200), (0,50)]\n    \"\"\"\n\n    SUPER_TWISTING = \"sta_smc\"\n    \"\"\"\n    Super-twisting sliding mode controller (second-order).\n\n    Mathematical Model:\n        u\u0307 = -K1\u00b7sign(s) - K2\u00b7sign(\u1e61)\n        s = \u03c3(x)  (sliding surface)\n\n    Gain Parameters: [K1, K2, \u03bb1, \u03bb2, \u03b11, \u03b12]\n        K1: Primary twisting gain\n        K2: Secondary twisting gain\n        \u03bb1, \u03bb2: Surface gains\n        \u03b11, \u03b12: Higher-order surface parameters\n\n    Mathematical Constraints:\n        - K1 > K2 > 0 (finite-time convergence)\n        - \u03bb1, \u03bb2, \u03b11, \u03b12 > 0 (stability)\n\n    PSO Bounds: [(2,100), (1,99), (1,50), (1,50), (1,50), (1,50)]\n    \"\"\"\n\n    ADAPTIVE = \"adaptive_smc\"\n    \"\"\"\n    Adaptive sliding mode controller with online gain tuning.\n\n    Mathematical Model:\n        u = u_eq + u_sw\n        K\u0307 = \u03b3|s| - \u03c3K  (adaptation law)\n\n    Gain Parameters: [k1, k2, \u03bb1, \u03bb2, \u03b3]\n        k1, k2: Position gains\n        \u03bb1, \u03bb2: Surface gains\n        \u03b3: Adaptation rate\n\n    Mathematical Constraints:\n        - k1, k2, \u03bb1, \u03bb2 > 0 (stability)\n        - 0.1 \u2264 \u03b3 \u2264 20.0 (bounded adaptation)\n\n    PSO Bounds: [(0.1,50), (0.1,50), (1,50), (1,50), (0.1,20)]\n    \"\"\"\n\n    HYBRID = \"hybrid_adaptive_sta_smc\"\n    \"\"\"\n    Hybrid adaptive super-twisting controller.\n\n    Mathematical Model:\n        u = u_adaptive + u_sta  (mode switching)\n\n    Gain Parameters: [k1, k2, \u03bb1, \u03bb2]\n        k1, k2: Surface gains for pendulum 1 and 2\n        \u03bb1, \u03bb2: Higher-order surface gains\n\n    Mathematical Constraints:\n        - All parameters > 0 (stability)\n\n    PSO Bounds: [(1,50), (1,50), (1,50), (1,50)]\n    \"\"\"\n\n    @property\n    def gain_count(self) -> int:\n        \"\"\"Return number of gain parameters for this controller type.\"\"\"\n        return {\n            SMCType.CLASSICAL: 6,\n            SMCType.SUPER_TWISTING: 6,\n            SMCType.ADAPTIVE: 5,\n            SMCType.HYBRID: 4\n        }[self]\n\n    @property\n    def mathematical_constraints(self) -> Dict[str, str]:\n        \"\"\"Return mathematical constraints as human-readable strings.\"\"\"\n        return {\n            SMCType.CLASSICAL: \"\u03bb1,\u03bb2,K > 0; kd \u2265 0\",\n            SMCType.SUPER_TWISTING: \"K1 > K2 > 0; \u03bb1,\u03bb2,\u03b11,\u03b12 > 0\",\n            SMCType.ADAPTIVE: \"k1,k2,\u03bb1,\u03bb2 > 0; 0.1 \u2264 \u03b3 \u2264 20.0\",\n            SMCType.HYBRID: \"k1,k2,\u03bb1,\u03bb2 > 0\"\n        }[self]",
    "lines": 110,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e6a6003"
  },
  {
    "id": "pso_factory_api_reference_3_0f0045f3",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SMCGainSpec:\n    \"\"\"\n    Complete specification for SMC controller gains.\n\n    Provides comprehensive information about gain parameters including\n    mathematical meaning, constraints, and PSO optimization bounds.\n    \"\"\"\n\n    controller_type: SMCType\n    n_gains: int\n    gain_names: List[str]\n    gain_descriptions: List[str]\n    mathematical_constraints: List[str]\n    pso_bounds: List[Tuple[float, float]]\n    default_gains: List[float]\n\n    @property\n    def gain_info(self) -> List[Dict[str, Any]]:\n        \"\"\"\n        Return comprehensive gain information.\n\n        Returns:\n            List of dictionaries containing:\n                - name: Parameter name\n                - description: Mathematical meaning\n                - constraint: Mathematical constraint\n                - bounds: PSO optimization bounds\n                - default: Default value\n        \"\"\"\n        return [\n            {\n                'name': name,\n                'description': desc,\n                'constraint': constraint,\n                'bounds': bounds,\n                'default': default\n            }\n            for name, desc, constraint, bounds, default in zip(\n                self.gain_names,\n                self.gain_descriptions,\n                self.mathematical_constraints,\n                self.pso_bounds,\n                self.default_gains\n            )\n        ]\n\n    def validate_gains(self, gains: List[float]) -> Tuple[bool, List[str]]:\n        \"\"\"\n        Validate gains against mathematical constraints.\n\n        Args:\n            gains: Gain values to validate\n\n        Returns:\n            Tuple of (is_valid, list_of_errors)\n        \"\"\"\n        errors = []\n\n        if len(gains) != self.n_gains:\n            errors.append(f\"Expected {self.n_gains} gains, got {len(gains)}\")\n            return False, errors\n\n        # Controller-specific validation\n        if self.controller_type == SMCType.CLASSICAL:\n            if any(g <= 0 for g in gains[:5]):  # k1,k2,\u03bb1,\u03bb2,K > 0\n                errors.append(\"Surface and switching gains must be positive\")\n            if gains[5] < 0:  # kd \u2265 0\n                errors.append(\"Damping gain must be non-negative\")\n\n        elif self.controller_type == SMCType.SUPER_TWISTING:\n            if gains[0] <= gains[1]:  # K1 > K2\n                errors.append(\"K1 must be greater than K2 for convergence\")\n            if any(g <= 0 for g in gains):  # All gains > 0\n                errors.append(\"All STA gains must be positive\")\n\n        elif self.controller_type == SMCType.ADAPTIVE:\n            if any(g <= 0 for g in gains[:4]):  # k1,k2,\u03bb1,\u03bb2 > 0\n                errors.append(\"Surface gains must be positive\")\n            if not (0.1 <= gains[4] <= 20.0):  # \u03b3 bounds\n                errors.append(\"Adaptation rate must be in [0.1, 20.0]\")\n\n        elif self.controller_type == SMCType.HYBRID:\n            if any(g <= 0 for g in gains):  # All gains > 0\n                errors.append(\"All hybrid gains must be positive\")\n\n        return len(errors) == 0, errors\n\n    def get_pso_bounds_array(self) -> np.ndarray:\n        \"\"\"Return PSO bounds as numpy array for optimization algorithms.\"\"\"\n        return np.array(self.pso_bounds)\n\n    def get_random_valid_gains(self, n_samples: int = 1) -> np.ndarray:\n        \"\"\"\n        Generate random valid gain sets within PSO bounds.\n\n        Useful for PSO initialization and testing.\n\n        Args:\n            n_samples: Number of random gain sets to generate\n\n        Returns:\n            Array of shape (n_samples, n_gains) with valid gain sets\n        \"\"\"\n        bounds_array = self.get_pso_bounds_array()\n        lower_bounds = bounds_array[:, 0]\n        upper_bounds = bounds_array[:, 1]\n\n        samples = []\n        for _ in range(n_samples):\n            while True:\n                # Generate random sample in bounds\n                sample = np.random.uniform(lower_bounds, upper_bounds)\n\n                # Validate constraints\n                is_valid, _ = self.validate_gains(sample.tolist())\n                if is_valid:\n                    samples.append(sample)\n                    break\n\n        return np.array(samples)",
    "lines": 124,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f0045f3"
  },
  {
    "id": "pso_factory_api_reference_4_0f6a494b",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_smc_for_pso(smc_type: SMCType,\n                      gains: List[float],\n                      max_force: float = 100.0,\n                      dt: float = 0.01,\n                      **kwargs) -> PSOControllerWrapper:\n    \"\"\"\n    Primary function for creating SMC controllers in PSO fitness functions.\n\n    This function provides the optimal interface for PSO optimization workflows:\n    - Single-line controller creation\n    - Automatic mathematical constraint validation\n    - Performance-optimized wrapper for simplified control interface\n    - Comprehensive error handling for robust PSO evaluation\n\n    Mathematical Foundation:\n    Each controller type implements specific sliding mode control laws:\n\n    Classical SMC:\n        u = -(k1\u00b7\u03b81 + k2\u00b7\u03b82) - (\u03bb1\u00b7\u03b8\u03071 + \u03bb2\u00b7\u03b8\u03072) - K\u00b7tanh(s/\u03c6) - kd\u00b7\u1e8b\n        s = \u03bb1\u00b7e1 + \u03bb2\u00b7e2 + \u01171 + \u01172\n\n    Super-Twisting SMC:\n        u\u0307 = -K1\u00b7sign(s) - K2\u00b7sign(\u1e61)\n        s = \u03bb1\u00b7e1 + \u03bb2\u00b7e2 + \u03b11\u00b7\u01171 + \u03b12\u00b7\u01172\n\n    Adaptive SMC:\n        u = u_eq + u_sw\n        K\u0307 = \u03b3|s| - \u03c3K  (online adaptation)\n\n    Hybrid SMC:\n        u = w1\u00b7u_adaptive + w2\u00b7u_sta  (mode switching)\n\n    Args:\n        smc_type: Controller type from SMCType enumeration\n        gains: Gain array matching controller requirements:\n            - Classical: [k1, k2, \u03bb1, \u03bb2, K, kd] (6 parameters)\n            - STA: [K1, K2, \u03bb1, \u03bb2, \u03b11, \u03b12] (6 parameters)\n            - Adaptive: [k1, k2, \u03bb1, \u03bb2, \u03b3] (5 parameters)\n            - Hybrid: [k1, k2, \u03bb1, \u03bb2] (4 parameters)\n        max_force: Control force saturation limit [N]\n        dt: Control timestep [s]\n        **kwargs: Additional controller-specific parameters\n\n    Returns:\n        PSOControllerWrapper with simplified control interface\n\n    Raises:\n        ValueError: If gains violate mathematical constraints\n        TypeError: If smc_type is not a valid SMCType\n        ConfigurationError: If controller configuration is invalid\n\n    Performance:\n        - Creation time: <1ms typical\n        - Memory overhead: <500B per wrapper\n        - Thread-safe: Yes (for read operations)\n\n    PSO Integration Example:",
    "lines": 60,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f6a494b"
  },
  {
    "id": "pso_factory_api_reference_5_c2ab78f9",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 5,
    "code": "def get_gain_bounds_for_pso(smc_type: SMCType,\n                           custom_constraints: Optional[Dict[str, Any]] = None\n                           ) -> List[Tuple[float, float]]:\n    \"\"\"\n    Get mathematically-derived PSO optimization bounds for SMC controllers.\n\n    Bounds are derived from rigorous control theory analysis:\n    - Lyapunov stability requirements\n    - Performance specifications (settling time, overshoot)\n    - Physical system constraints (actuator saturation)\n    - Numerical implementation limits\n\n    Mathematical Derivation:\n\n    Classical SMC Bounds:\n        k1, k2 \u2208 [0.1, 50]: Position gains for reasonable pole placement\n            - Lower bound: Minimum for controllability\n            - Upper bound: Avoid excessive control action\n\n        \u03bb1, \u03bb2 \u2208 [1, 50]: Surface gains for desired bandwidth\n            - Lower bound: Minimum for stability (\u03bbi > 0)\n            - Upper bound: Avoid high-frequency dynamics\n\n        K \u2208 [1, 200]: Switching gain for disturbance rejection\n            - Lower bound: Overcome uncertainty bound\n            - Upper bound: Practical actuator limits\n\n        kd \u2208 [0, 50]: Damping gain for chattering reduction\n            - Lower bound: Non-negative constraint\n            - Upper bound: Avoid over-damping\n\n    Super-Twisting Bounds:\n        K1 \u2208 [2, 100]: Primary twisting gain\n            - Must satisfy K1 > K2 constraint\n            - Upper bound from actuator limitations\n\n        K2 \u2208 [1, 99]: Secondary twisting gain\n            - Must satisfy K2 < K1 constraint\n            - Lower bound for convergence guarantee\n\n        \u03bb1, \u03bb2, \u03b11, \u03b12 \u2208 [1, 50]: Surface parameters\n            - Positive definite requirement\n            - Bandwidth considerations\n\n    Adaptive SMC Bounds:\n        k1, k2, \u03bb1, \u03bb2: Same as classical SMC\n\n        \u03b3 \u2208 [0.1, 20]: Adaptation rate\n            - Lower bound: Minimum adaptation speed\n            - Upper bound: Stability margin preservation\n\n    Hybrid SMC Bounds:\n        k1, k2, \u03bb1, \u03bb2 \u2208 [1, 50]: Surface gains\n            - Positive definite requirement\n            - Performance considerations\n\n    Args:\n        smc_type: Controller type for bound derivation\n        custom_constraints: Optional custom constraint overrides\n            Example: {'max_force': 150.0, 'settling_time': 3.0}\n\n    Returns:\n        List of (lower_bound, upper_bound) tuples for each gain parameter\n\n    Raises:\n        ValueError: If smc_type is invalid\n        TypeError: If custom_constraints has wrong format\n\n    Usage Examples:\n        # Standard bounds\n        bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n        # Custom constraints\n        custom = {'max_force': 150.0, 'settling_time': 3.0}\n        bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL, custom)\n\n        # PSO integration\n        from pyswarms.single import GlobalBestPSO\n        bounds_array = np.array(bounds)\n        optimizer = GlobalBestPSO(\n            n_particles=30,\n            dimensions=len(bounds),\n            bounds=(bounds_array[:, 0], bounds_array[:, 1])\n        )\n\n    Mathematical Validation:\n        All bounds are verified to satisfy:\n        1. Lyapunov stability conditions: V\u0307 \u2264 -\u03b7|s|\n        2. Reachability conditions: \u1e61\u00b7s \u2264 -\u03b7|s|\n        3. Finite-time convergence (STA): Specific gain relationships\n        4. Bounded adaptation (Adaptive): Parameter drift prevention\n\n    Performance Considerations:\n        - Tighter bounds lead to faster PSO convergence\n        - Bounds include safety margins for robustness\n        - Physical constraints prevent actuator saturation\n        - Numerical bounds avoid conditioning issues\n    \"\"\"\n    if not isinstance(smc_type, SMCType):\n        raise ValueError(f\"Invalid SMC type: {smc_type}\")\n\n    # Default constraints (can be overridden)\n    constraints = {\n        'max_force': 100.0,        # Maximum actuator force [N]\n        'settling_time': 2.0,      # Desired settling time [s]\n        'overshoot_limit': 10.0,   # Maximum overshoot [%]\n        'bandwidth': 25.0,         # Control bandwidth [rad/s]\n        'uncertainty_bound': 10.0,  # Model uncertainty estimate\n        'noise_level': 0.01        # Sensor noise level\n    }\n\n    # Apply custom constraints if provided\n    if custom_constraints:\n        if not isinstance(custom_constraints, dict):\n            raise TypeError(\"custom_constraints must be dictionary\")\n        constraints.update(custom_constraints)\n\n    # Extract constraint values\n    max_force = constraints['max_force']\n    settling_time = constraints['settling_time']\n    bandwidth = constraints['bandwidth']\n    uncertainty = constraints['uncertainty_bound']\n\n    if smc_type == SMCType.CLASSICAL:\n        # Classical SMC bounds with mathematical justification\n\n        # Position gains: pole placement considerations\n        # Natural frequency: \u03c9n = 4/settling_time\n        omega_n = 4.0 / settling_time\n        k_min = omega_n**2 / 100  # Conservative lower bound\n        k_max = omega_n**2        # Upper bound for reasonable response\n\n        # Surface gains: bandwidth considerations\n        lambda_min = omega_n / 2   # Minimum for stability\n        lambda_max = bandwidth     # Maximum for implementability\n\n        # Switching gain: uncertainty rejection\n        K_min = uncertainty * 1.5  # Safety margin over uncertainty\n        K_max = max_force * 0.8    # Actuator saturation margin\n\n        # Damping gain: chattering reduction\n        kd_min = 0.0              # Non-negative constraint\n        kd_max = lambda_max / 2   # Avoid over-damping\n\n        bounds = [\n            (k_min, k_max),          # k1\n            (k_min, k_max),          # k2\n            (lambda_min, lambda_max), # \u03bb1\n            (lambda_min, lambda_max), # \u03bb2\n            (K_min, K_max),          # K\n            (kd_min, kd_max)         # kd\n        ]\n\n    elif smc_type == SMCType.SUPER_TWISTING:\n        # Super-twisting bounds with convergence constraints\n\n        # Estimate Lipschitz constant for convergence analysis\n        L = uncertainty + bandwidth  # Conservative estimate\n\n        # K1 bounds: finite-time convergence requirement\n        K1_min = math.sqrt(L) * 1.2  # Safety margin\n        K1_max = math.sqrt(max_force * L)  # Physical limit\n\n        # K2 bounds: must satisfy K2 < K1\n        K2_min = L / (2 * math.sqrt(L)) * 1.1  # Convergence requirement\n        K2_max = K1_max * 0.9  # Ensure K1 > K2\n\n        # Surface parameters: similar to classical\n        lambda_min = 2.0 / settling_time\n        lambda_max = bandwidth / 2\n\n        bounds = [\n            (K1_min, K1_max),        # K1\n            (K2_min, K2_max),        # K2\n            (lambda_min, lambda_max), # \u03bb1\n            (lambda_min, lambda_max), # \u03bb2\n            (lambda_min, lambda_max), # \u03b11\n            (lambda_min, lambda_max)  # \u03b12\n        ]\n\n    elif smc_type == SMCType.ADAPTIVE:\n        # Adaptive SMC bounds with adaptation constraints\n\n        # Surface gains: same analysis as classical\n        omega_n = 4.0 / settling_time\n        k_min = omega_n**2 / 100\n        k_max = omega_n**2\n        lambda_min = omega_n / 2\n        lambda_max = bandwidth\n\n        # Adaptation rate: stability-preserving bounds\n        gamma_min = 0.1           # Minimum adaptation speed\n        gamma_max = bandwidth / 5  # Stability margin preservation\n        gamma_max = min(gamma_max, 20.0)  # Practical upper limit\n\n        bounds = [\n            (k_min, k_max),          # k1\n            (k_min, k_max),          # k2\n            (lambda_min, lambda_max), # \u03bb1\n            (lambda_min, lambda_max), # \u03bb2\n            (gamma_min, gamma_max)   # \u03b3\n        ]\n\n    elif smc_type == SMCType.HYBRID:\n        # Hybrid controller bounds (conservative)\n\n        # Surface gains: conservative bounds for mode switching\n        gain_min = 2.0 / settling_time\n        gain_max = bandwidth / 3  # Conservative for hybrid operation\n\n        bounds = [\n            (gain_min, gain_max),    # k1\n            (gain_min, gain_max),    # k2\n            (gain_min, gain_max),    # \u03bb1\n            (gain_min, gain_max)     # \u03bb2\n        ]\n\n    else:\n        raise ValueError(f\"Unsupported SMC type: {smc_type}\")\n\n    # Validate bounds consistency\n    for i, (lower, upper) in enumerate(bounds):\n        if lower >= upper:\n            raise ValueError(f\"Invalid bounds for parameter {i}: [{lower}, {upper}]\")\n        if lower < 0 and smc_type != SMCType.CLASSICAL:  # Only kd can be 0\n            raise ValueError(f\"Negative lower bound for parameter {i}: {lower}\")\n\n    # Apply constraint-specific adjustments\n    if 'force_limit' in constraints:\n        # Adjust switching/twisting gains for force constraints\n        force_limit = constraints['force_limit']\n        if smc_type == SMCType.CLASSICAL:\n            bounds[4] = (bounds[4][0], min(bounds[4][1], force_limit * 0.8))\n        elif smc_type == SMCType.SUPER_TWISTING:\n            bounds[0] = (bounds[0][0], min(bounds[0][1], force_limit * 0.8))\n            bounds[1] = (bounds[1][0], min(bounds[1][1], force_limit * 0.8))\n\n    return bounds",
    "lines": 238,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2ab78f9"
  },
  {
    "id": "pso_factory_api_reference_6_142d51e8",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_smc_gains(smc_type: SMCType,\n                      gains: List[float],\n                      strict: bool = True,\n                      return_details: bool = False\n                      ) -> Union[bool, Tuple[bool, Dict[str, Any]]]:\n    \"\"\"\n    Comprehensive validation of SMC gains against mathematical constraints.\n\n    Performs multi-level validation:\n    1. Basic constraints (positivity, bounds checking)\n    2. Mathematical constraints (stability, convergence)\n    3. Physical constraints (actuator limits, bandwidth)\n    4. Numerical constraints (conditioning, finite values)\n\n    Mathematical Validation Framework:\n\n    Classical SMC Validation:\n        1. Stability: \u03bb1, \u03bb2, K > 0 (Lyapunov condition V\u0307 \u2264 -\u03b7|s|)\n        2. Reachability: K > |d_max| (uncertainty bound)\n        3. Performance: Pole placement within stability region\n        4. Saturation: K\u00b7\u03c6 \u2264 max_force (actuator limits)\n\n    Super-Twisting Validation:\n        1. Convergence: K1 > K2 > 0 (finite-time stability)\n        2. Lyapunov: K1\u00b2 > 4LK2 (sufficient condition)\n        3. Reachability: Gains sufficient for uncertainty rejection\n        4. Bandwidth: Avoid high-frequency content\n\n    Adaptive SMC Validation:\n        1. Stability: Base gains satisfy classical constraints\n        2. Adaptation: 0.1 \u2264 \u03b3 \u2264 20 (bounded adaptation)\n        3. Convergence: Adaptation rate vs system bandwidth\n        4. Robustness: Parameter drift prevention\n\n    Hybrid SMC Validation:\n        1. Mode stability: Each mode individually stable\n        2. Switching stability: No instability during transitions\n        3. Performance: Smooth mode transitions\n        4. Robustness: Consistent performance across modes\n\n    Args:\n        smc_type: Controller type for validation\n        gains: Gain array to validate\n        strict: Enable strict mathematical validation\n        return_details: Return detailed validation information\n\n    Returns:\n        If return_details=False: Boolean validation result\n        If return_details=True: Tuple of (is_valid, validation_details)\n\n    Validation Details Dictionary:\n        {\n            'is_valid': bool,\n            'errors': List[str],           # Constraint violations\n            'warnings': List[str],         # Potential issues\n            'stability_analysis': {\n                'lyapunov_stable': bool,\n                'convergence_rate': float,\n                'stability_margin': float\n            },\n            'performance_analysis': {\n                'estimated_settling_time': float,\n                'estimated_overshoot': float,\n                'bandwidth_estimate': float\n            },\n            'constraint_details': {\n                'basic_constraints': Dict,\n                'mathematical_constraints': Dict,\n                'physical_constraints': Dict\n            }\n        }\n\n    Usage Examples:\n        # Basic validation\n        is_valid = validate_smc_gains(SMCType.CLASSICAL, [10,8,15,12,50,5])\n\n        # Detailed validation\n        is_valid, details = validate_smc_gains(\n            SMCType.CLASSICAL, gains, return_details=True\n        )\n        print(f\"Stability margin: {details['stability_analysis']['stability_margin']}\")\n\n        # PSO integration with validation\n        def pso_fitness_with_validation(gains):\n            if not validate_smc_gains(SMCType.CLASSICAL, gains):\n                return 1000.0  # Penalty for invalid gains\n            return evaluate_controller_performance(gains)\n\n    Raises:\n        ValueError: If basic validation fails (wrong gain count, NaN values)\n        TypeError: If inputs have wrong types\n    \"\"\"\n    # Input validation\n    if not isinstance(smc_type, SMCType):\n        raise TypeError(f\"smc_type must be SMCType, got {type(smc_type)}\")\n\n    if not isinstance(gains, (list, np.ndarray)):\n        raise TypeError(f\"gains must be list or array, got {type(gains)}\")\n\n    # Convert to list if numpy array\n    if isinstance(gains, np.ndarray):\n        gains = gains.tolist()\n\n    # Initialize validation results\n    errors = []\n    warnings = []\n    stability_analysis = {}\n    performance_analysis = {}\n    constraint_details = {\n        'basic_constraints': {},\n        'mathematical_constraints': {},\n        'physical_constraints': {}\n    }\n\n    # Get gain specification\n    gain_spec = SMC_GAIN_SPECS[smc_type]\n\n    # Basic validation\n    if len(gains) != gain_spec.n_gains:\n        errors.append(f\"Expected {gain_spec.n_gains} gains, got {len(gains)}\")\n        if return_details:\n            return False, {\n                'is_valid': False,\n                'errors': errors,\n                'warnings': warnings,\n                'stability_analysis': {},\n                'performance_analysis': {},\n                'constraint_details': constraint_details\n            }\n        return False\n\n    # Check for finite values\n    if not all(np.isfinite(g) for g in gains):\n        errors.append(\"All gains must be finite (no NaN or infinite values)\")\n\n    # Check for reasonable magnitudes\n    if any(abs(g) > 1e6 for g in gains):\n        warnings.append(\"Some gains are very large (>1e6), may cause numerical issues\")\n\n    if any(abs(g) < 1e-8 for g in gains[:-1]):  # Exclude kd for classical\n        warnings.append(\"Some gains are very small (<1e-8), may affect performance\")\n\n    # Controller-specific mathematical validation\n    if smc_type == SMCType.CLASSICAL:\n        k1, k2, lam1, lam2, K, kd = gains\n\n        # Basic constraints\n        constraint_details['basic_constraints'] = {\n            'k1_positive': k1 > 0,\n            'k2_positive': k2 > 0,\n            'lambda1_positive': lam1 > 0,\n            'lambda2_positive': lam2 > 0,\n            'K_positive': K > 0,\n            'kd_nonnegative': kd >= 0\n        }\n\n        # Check positivity constraints\n        if any(g <= 0 for g in gains[:5]):\n            errors.append(\"Surface gains (k1,k2,\u03bb1,\u03bb2) and switching gain (K) must be positive\")\n        if kd < 0:\n            errors.append(\"Damping gain (kd) must be non-negative\")\n\n        # Mathematical constraints (strict mode)\n        if strict:\n            # Estimate stability properties\n            # Simplified stability analysis\n            min_surface_gain = min(lam1, lam2)\n            estimated_bandwidth = min_surface_gain\n            estimated_uncertainty = 10.0  # Conservative estimate\n\n            constraint_details['mathematical_constraints'] = {\n                'switching_gain_adequate': K > estimated_uncertainty,\n                'surface_gains_adequate': min_surface_gain > 1.0,\n                'damping_reasonable': kd <= min_surface_gain\n            }\n\n            if K <= estimated_uncertainty:\n                warnings.append(f\"Switching gain K={K:.2f} may be too small for uncertainty rejection\")\n\n            # Stability analysis\n            stability_margin = K - estimated_uncertainty\n            convergence_rate = min(min_surface_gain, stability_margin) if stability_margin > 0 else 0\n\n            stability_analysis = {\n                'lyapunov_stable': stability_margin > 0,\n                'convergence_rate': convergence_rate,\n                'stability_margin': stability_margin / K if K > 0 else 0\n            }\n\n            # Performance estimates\n            estimated_settling_time = 4.0 / min_surface_gain if min_surface_gain > 0 else float('inf')\n            estimated_overshoot = max(0, (k1 + k2) / (lam1 + lam2) - 1) * 100 if (lam1 + lam2) > 0 else 100\n\n            performance_analysis = {\n                'estimated_settling_time': estimated_settling_time,\n                'estimated_overshoot': estimated_overshoot,\n                'bandwidth_estimate': estimated_bandwidth\n            }\n\n        # Physical constraints\n        max_force_estimate = 100.0  # Default actuator limit\n        constraint_details['physical_constraints'] = {\n            'force_saturation_check': K <= max_force_estimate,\n            'bandwidth_feasible': max(lam1, lam2) <= 50.0\n        }\n\n        if K > max_force_estimate:\n            warnings.append(f\"Switching gain K={K:.1f} may exceed actuator limits\")\n\n    elif smc_type == SMCType.SUPER_TWISTING:\n        K1, K2, lam1, lam2, alpha1, alpha2 = gains\n\n        # Basic constraints\n        constraint_details['basic_constraints'] = {\n            'K1_positive': K1 > 0,\n            'K2_positive': K2 > 0,\n            'K1_greater_K2': K1 > K2,\n            'lambda1_positive': lam1 > 0,\n            'lambda2_positive': lam2 > 0,\n            'alpha1_positive': alpha1 > 0,\n            'alpha2_positive': alpha2 > 0\n        }\n\n        # Critical convergence constraint\n        if K1 <= K2:\n            errors.append(\"K1 must be greater than K2 for finite-time convergence\")\n        if any(g <= 0 for g in gains):\n            errors.append(\"All STA gains must be positive\")\n\n        # Mathematical constraints (strict mode)\n        if strict:\n            # Finite-time convergence analysis\n            L_estimate = 15.0  # Conservative Lipschitz constant estimate\n            convergence_condition = K1**2 > 4 * L_estimate * K2\n\n            constraint_details['mathematical_constraints'] = {\n                'finite_time_convergence': convergence_condition,\n                'gains_well_separated': K1 > K2 * 1.1,\n                'lipschitz_condition': K1**2 > 4 * L_estimate * K2\n            }\n\n            if not convergence_condition:\n                warnings.append(\"May not satisfy sufficient condition for finite-time convergence\")\n\n            # Stability analysis\n            convergence_rate = min(K1, K2) if K1 > K2 else 0\n            stability_margin = (K1 - K2) / K1 if K1 > 0 else 0\n\n            stability_analysis = {\n                'lyapunov_stable': K1 > K2 > 0,\n                'convergence_rate': convergence_rate,\n                'stability_margin': stability_margin\n            }\n\n    elif smc_type == SMCType.ADAPTIVE:\n        k1, k2, lam1, lam2, gamma = gains\n\n        # Basic constraints\n        constraint_details['basic_constraints'] = {\n            'k1_positive': k1 > 0,\n            'k2_positive': k2 > 0,\n            'lambda1_positive': lam1 > 0,\n            'lambda2_positive': lam2 > 0,\n            'gamma_in_bounds': 0.1 <= gamma <= 20.0\n        }\n\n        # Check positivity and adaptation bounds\n        if any(g <= 0 for g in gains[:4]):\n            errors.append(\"Surface gains must be positive\")\n        if not (0.1 <= gamma <= 20.0):\n            errors.append(\"Adaptation rate \u03b3 must be in [0.1, 20.0]\")\n\n        # Mathematical constraints (strict mode)\n        if strict:\n            # Adaptation stability analysis\n            system_bandwidth = min(lam1, lam2)\n            adaptation_bandwidth = gamma * system_bandwidth\n\n            constraint_details['mathematical_constraints'] = {\n                'adaptation_stable': gamma < 10.0,\n                'adaptation_not_too_slow': gamma > 0.2,\n                'separation_principle': adaptation_bandwidth < system_bandwidth\n            }\n\n            if gamma > 10.0:\n                warnings.append(\"High adaptation rate may cause instability\")\n            if gamma < 0.2:\n                warnings.append(\"Low adaptation rate may be too slow\")\n\n            # Stability analysis\n            stability_analysis = {\n                'lyapunov_stable': True,  # Assuming proper design\n                'convergence_rate': min(system_bandwidth, gamma),\n                'stability_margin': (20.0 - gamma) / 20.0\n            }\n\n    elif smc_type == SMCType.HYBRID:\n        k1, k2, lam1, lam2 = gains\n\n        # Basic constraints\n        constraint_details['basic_constraints'] = {\n            'k1_positive': k1 > 0,\n            'k2_positive': k2 > 0,\n            'lambda1_positive': lam1 > 0,\n            'lambda2_positive': lam2 > 0\n        }\n\n        if any(g <= 0 for g in gains):\n            errors.append(\"All hybrid gains must be positive\")\n\n        # Mathematical constraints (strict mode)\n        if strict:\n            # Hybrid stability analysis (simplified)\n            min_gain = min(gains)\n\n            constraint_details['mathematical_constraints'] = {\n                'mode_stability': min_gain > 1.0,\n                'switching_stability': max(gains) / min_gain < 10.0\n            }\n\n            stability_analysis = {\n                'lyapunov_stable': min_gain > 0,\n                'convergence_rate': min_gain,\n                'stability_margin': min_gain / max(gains) if max(gains) > 0 else 0\n            }\n\n    # Overall validation result\n    is_valid = len(errors) == 0\n\n    if return_details:\n        validation_details = {\n            'is_valid': is_valid,\n            'errors': errors,\n            'warnings': warnings,\n            'stability_analysis': stability_analysis,\n            'performance_analysis': performance_analysis,\n            'constraint_details': constraint_details\n        }\n        return is_valid, validation_details\n    else:\n        return is_valid",
    "lines": 344,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "142d51e8"
  },
  {
    "id": "pso_factory_api_reference_7_b6dc3b7c",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"\n    PSO-optimized wrapper providing simplified interface for SMC controllers.\n\n    This wrapper is specifically designed for PSO fitness evaluation with:\n    - Simplified control interface (single state input)\n    - Automatic state management for stateful controllers\n    - Unified output format (numpy array)\n    - Robust error handling for PSO robustness\n    - Performance optimization for repeated evaluations\n\n    The wrapper handles the complexity of different SMC controller interfaces\n    while providing a consistent, PSO-friendly API.\n\n    Mathematical Foundation:\n    The wrapper preserves the mathematical properties of the underlying\n    SMC controller while simplifying the interface:\n\n    Input: state = [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b] \u2208 \u211d\u2076\n    Output: u \u2208 \u211d (scalar control force)\n\n    Internal State Management:\n    - Classical SMC: Stateless (empty state_vars)\n    - STA SMC: Maintains (z, \u03c3) for integration\n    - Adaptive SMC: Tracks adaptation variables\n    - Hybrid SMC: Manages mode switching state\n\n    Performance Characteristics:\n    - Control computation: <0.1ms typical\n    - Memory overhead: <500B per wrapper\n    - Thread safety: Read operations only\n    - Error recovery: Graceful degradation for invalid inputs\n    \"\"\"\n\n    def __init__(self, controller: SMCProtocol):\n        \"\"\"\n        Initialize PSO wrapper with SMC controller.\n\n        Args:\n            controller: SMC controller implementing SMCProtocol\n\n        Raises:\n            TypeError: If controller doesn't implement required interface\n            ValueError: If controller configuration is invalid\n        \"\"\"\n        # Validate controller interface\n        if not hasattr(controller, 'compute_control'):\n            raise TypeError(\"Controller must implement compute_control method\")\n        if not hasattr(controller, 'gains'):\n            raise TypeError(\"Controller must have gains property\")\n\n        self.controller = controller\n        self._history = {}  # Initialize empty history\n\n        # Initialize controller-specific state variables\n        controller_name = type(controller).__name__\n\n        if 'SuperTwisting' in controller_name or 'STA' in controller_name:\n            # STA-SMC maintains integration variables (z, \u03c3)\n            self._state_vars = (0.0, 0.0)  # Initial (z=0, \u03c3=0)\n        elif 'Hybrid' in controller_name:\n            # Hybrid controller tracks adaptive gains and integration\n            self._state_vars = (\n                getattr(controller, 'k1_init', 5.0),  # k1_prev\n                getattr(controller, 'k2_init', 3.0),  # k2_prev\n                0.0                                    # u_int_prev\n            )\n        elif 'Adaptive' in controller_name:\n            # Adaptive SMC may track adaptation state\n            self._state_vars = getattr(controller, '_initial_state', ())\n        else:\n            # Classical SMC and others use empty state\n            self._state_vars = ()\n\n        # Performance tracking\n        self._call_count = 0\n        self._total_compute_time = 0.0\n        self._last_error = None\n\n    def compute_control(self,\n                       state: np.ndarray,\n                       state_vars: Optional[Any] = None,\n                       history: Optional[Dict[str, Any]] = None\n                       ) -> np.ndarray:\n        \"\"\"\n        Compute control with flexible interface supporting both:\n        1. Simplified PSO interface: compute_control(state)\n        2. Full interface: compute_control(state, state_vars, history)\n\n        Mathematical Interface:\n        Input state vector: x = [\u03b8\u2081, \u03b8\u2082, x_cart, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b_cart]\n        - \u03b8\u2081, \u03b8\u2082: Pendulum angles [rad]\n        - x_cart: Cart position [m]\n        - \u03b8\u0307\u2081, \u03b8\u0307\u2082: Angular velocities [rad/s]\n        - \u1e8b_cart: Cart velocity [m/s]\n\n        Output control: u \u2208 \u211d\n        - Scalar control force [N]\n        - Bounded by actuator limits\n\n        Args:\n            state: System state vector (6-element numpy array)\n            state_vars: Controller state variables (optional)\n            history: Controller history (optional)\n\n        Returns:\n            Control output as 1-element numpy array [u]\n\n        Raises:\n            ValueError: If state has wrong dimensions\n            RuntimeError: If control computation fails\n\n        Performance:\n            - Typical computation time: 0.01-0.1ms\n            - Memory allocation: Minimal (output array only)\n            - Error handling: Graceful fallback to zero control\n\n        PSO Usage Pattern:",
    "lines": 121,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b6dc3b7c"
  },
  {
    "id": "pso_factory_api_reference_8_61ba3a1d",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 8,
    "code": "controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n            print(f\"Controller gains: {controller.gains}\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61ba3a1d"
  },
  {
    "id": "pso_factory_api_reference_9_f0a71a8e",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 9,
    "code": "# After PSO optimization\n            stats = controller.performance_stats\n            print(f\"Average computation time: {stats['average_time']:.3f}ms\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0a71a8e"
  },
  {
    "id": "pso_factory_api_reference_10_d90dd480",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 10,
    "code": "is_valid, error = controller.validate_state_input(test_state)\n            if not is_valid:\n                print(f\"Invalid state: {error}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d90dd480"
  },
  {
    "id": "pso_factory_api_reference_11_0c7a928f",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Global registry of SMC gain specifications\nSMC_GAIN_SPECS: Dict[SMCType, SMCGainSpec] = {\n\n    SMCType.CLASSICAL: SMCGainSpec(\n        controller_type=SMCType.CLASSICAL,\n        n_gains=6,\n        gain_names=['k1', 'k2', '\u03bb1', '\u03bb2', 'K', 'kd'],\n        gain_descriptions=[\n            'Position gain for pendulum 1',\n            'Position gain for pendulum 2',\n            'Surface gain for pendulum 1',\n            'Surface gain for pendulum 2',\n            'Switching gain for robustness',\n            'Damping gain for chattering reduction'\n        ],\n        mathematical_constraints=[\n            'k1 > 0 (controllability)',\n            'k2 > 0 (controllability)',\n            '\u03bb1 > 0 (stability)',\n            '\u03bb2 > 0 (stability)',\n            'K > 0 (reachability)',\n            'kd \u2265 0 (non-negative damping)'\n        ],\n        pso_bounds=[\n            (0.1, 50.0),   # k1\n            (0.1, 50.0),   # k2\n            (1.0, 50.0),   # \u03bb1\n            (1.0, 50.0),   # \u03bb2\n            (1.0, 200.0),  # K\n            (0.0, 50.0)    # kd\n        ],\n        default_gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n    ),\n\n    SMCType.SUPER_TWISTING: SMCGainSpec(\n        controller_type=SMCType.SUPER_TWISTING,\n        n_gains=6,\n        gain_names=['K1', 'K2', '\u03bb1', '\u03bb2', '\u03b11', '\u03b12'],\n        gain_descriptions=[\n            'Primary twisting gain',\n            'Secondary twisting gain',\n            'Surface gain for pendulum 1',\n            'Surface gain for pendulum 2',\n            'Higher-order surface parameter 1',\n            'Higher-order surface parameter 2'\n        ],\n        mathematical_constraints=[\n            'K1 > K2 (finite-time convergence)',\n            'K2 > 0 (convergence requirement)',\n            '\u03bb1 > 0 (stability)',\n            '\u03bb2 > 0 (stability)',\n            '\u03b11 > 0 (higher-order stability)',\n            '\u03b12 > 0 (higher-order stability)'\n        ],\n        pso_bounds=[\n            (2.0, 100.0),  # K1 (must be > K2)\n            (1.0, 99.0),   # K2 (must be < K1)\n            (1.0, 50.0),   # \u03bb1\n            (1.0, 50.0),   # \u03bb2\n            (1.0, 50.0),   # \u03b11\n            (1.0, 50.0)    # \u03b12\n        ],\n        default_gains=[25.0, 10.0, 15.0, 12.0, 20.0, 15.0]\n    ),\n\n    SMCType.ADAPTIVE: SMCGainSpec(\n        controller_type=SMCType.ADAPTIVE,\n        n_gains=5,\n        gain_names=['k1', 'k2', '\u03bb1', '\u03bb2', '\u03b3'],\n        gain_descriptions=[\n            'Position gain for pendulum 1',\n            'Position gain for pendulum 2',\n            'Surface gain for pendulum 1',\n            'Surface gain for pendulum 2',\n            'Adaptation rate'\n        ],\n        mathematical_constraints=[\n            'k1 > 0 (controllability)',\n            'k2 > 0 (controllability)',\n            '\u03bb1 > 0 (stability)',\n            '\u03bb2 > 0 (stability)',\n            '0.1 \u2264 \u03b3 \u2264 20.0 (bounded adaptation)'\n        ],\n        pso_bounds=[\n            (0.1, 50.0),   # k1\n            (0.1, 50.0),   # k2\n            (1.0, 50.0),   # \u03bb1\n            (1.0, 50.0),   # \u03bb2\n            (0.1, 20.0)    # \u03b3\n        ],\n        default_gains=[10.0, 8.0, 15.0, 12.0, 0.5]\n    ),\n\n    SMCType.HYBRID: SMCGainSpec(\n        controller_type=SMCType.HYBRID,\n        n_gains=4,\n        gain_names=['k1', 'k2', '\u03bb1', '\u03bb2'],\n        gain_descriptions=[\n            'Surface gain for pendulum 1',\n            'Surface gain for pendulum 2',\n            'Higher-order surface gain 1',\n            'Higher-order surface gain 2'\n        ],\n        mathematical_constraints=[\n            'k1 > 0 (stability)',\n            'k2 > 0 (stability)',\n            '\u03bb1 > 0 (stability)',\n            '\u03bb2 > 0 (stability)'\n        ],\n        pso_bounds=[\n            (1.0, 50.0),   # k1\n            (1.0, 50.0),   # k2\n            (1.0, 50.0),   # \u03bb1\n            (1.0, 50.0)    # \u03bb2\n        ],\n        default_gains=[15.0, 12.0, 18.0, 15.0]\n    )\n}",
    "lines": 121,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c7a928f"
  },
  {
    "id": "pso_factory_api_reference_12_3d217149",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_mathematical_constraints(smc_type: SMCType,\n                                    gains: List[float],\n                                    tolerance: float = 1e-8\n                                    ) -> Tuple[bool, List[str]]:\n    \"\"\"\n    Validate mathematical constraints for SMC gains.\n\n    Args:\n        smc_type: Controller type\n        gains: Gain values to validate\n        tolerance: Numerical tolerance for constraint checking\n\n    Returns:\n        Tuple of (is_valid, list_of_constraint_violations)\n    \"\"\"\n    violations = []\n\n    if smc_type == SMCType.CLASSICAL:\n        k1, k2, lam1, lam2, K, kd = gains\n\n        if k1 <= tolerance:\n            violations.append(f\"k1 = {k1:.6f} must be > {tolerance}\")\n        if k2 <= tolerance:\n            violations.append(f\"k2 = {k2:.6f} must be > {tolerance}\")\n        if lam1 <= tolerance:\n            violations.append(f\"\u03bb1 = {lam1:.6f} must be > {tolerance}\")\n        if lam2 <= tolerance:\n            violations.append(f\"\u03bb2 = {lam2:.6f} must be > {tolerance}\")\n        if K <= tolerance:\n            violations.append(f\"K = {K:.6f} must be > {tolerance}\")\n        if kd < -tolerance:\n            violations.append(f\"kd = {kd:.6f} must be \u2265 0\")\n\n    elif smc_type == SMCType.SUPER_TWISTING:\n        K1, K2, lam1, lam2, alpha1, alpha2 = gains\n\n        if K1 <= K2 + tolerance:\n            violations.append(f\"K1 = {K1:.6f} must be > K2 = {K2:.6f}\")\n        if K2 <= tolerance:\n            violations.append(f\"K2 = {K2:.6f} must be > {tolerance}\")\n        if any(g <= tolerance for g in [lam1, lam2, alpha1, alpha2]):\n            violations.append(\"All surface parameters must be positive\")\n\n    elif smc_type == SMCType.ADAPTIVE:\n        k1, k2, lam1, lam2, gamma = gains\n\n        if any(g <= tolerance for g in [k1, k2, lam1, lam2]):\n            violations.append(\"All surface gains must be positive\")\n        if not (0.1 <= gamma <= 20.0):\n            violations.append(f\"\u03b3 = {gamma:.6f} must be in [0.1, 20.0]\")\n\n    elif smc_type == SMCType.HYBRID:\n        if any(g <= tolerance for g in gains):\n            violations.append(\"All hybrid gains must be positive\")\n\n    return len(violations) == 0, violations\n\ndef estimate_stability_properties(smc_type: SMCType,\n                                gains: List[float]\n                                ) -> Dict[str, float]:\n    \"\"\"\n    Estimate stability properties from gains.\n\n    Returns:\n        Dictionary with estimated properties:\n            - convergence_rate: Estimated convergence rate\n            - stability_margin: Stability margin estimate\n            - bandwidth: Estimated closed-loop bandwidth\n            - settling_time: Estimated settling time\n    \"\"\"\n    if smc_type == SMCType.CLASSICAL:\n        k1, k2, lam1, lam2, K, kd = gains\n\n        min_surface_gain = min(lam1, lam2)\n        convergence_rate = min_surface_gain\n        bandwidth = min_surface_gain\n        settling_time = 4.0 / min_surface_gain if min_surface_gain > 0 else float('inf')\n        stability_margin = K / (K + 10.0)  # Rough estimate\n\n    elif smc_type == SMCType.SUPER_TWISTING:\n        K1, K2, lam1, lam2, alpha1, alpha2 = gains\n\n        convergence_rate = min(K1, K2)\n        bandwidth = min(lam1, lam2)\n        settling_time = 2.0 / convergence_rate if convergence_rate > 0 else float('inf')\n        stability_margin = (K1 - K2) / K1 if K1 > 0 else 0\n\n    elif smc_type == SMCType.ADAPTIVE:\n        k1, k2, lam1, lam2, gamma = gains\n\n        surface_bandwidth = min(lam1, lam2)\n        adaptation_bandwidth = gamma\n        convergence_rate = min(surface_bandwidth, adaptation_bandwidth)\n        bandwidth = surface_bandwidth\n        settling_time = 4.0 / convergence_rate if convergence_rate > 0 else float('inf')\n        stability_margin = min(1.0, (20.0 - gamma) / 20.0)\n\n    elif smc_type == SMCType.HYBRID:\n        k1, k2, lam1, lam2 = gains\n\n        convergence_rate = min(gains)\n        bandwidth = convergence_rate\n        settling_time = 4.0 / convergence_rate if convergence_rate > 0 else float('inf')\n        stability_margin = min(gains) / max(gains) if max(gains) > 0 else 0\n\n    return {\n        'convergence_rate': convergence_rate,\n        'stability_margin': stability_margin,\n        'bandwidth': bandwidth,\n        'settling_time': settling_time\n    }",
    "lines": 114,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d217149"
  },
  {
    "id": "pso_factory_api_reference_13_c4a54aff",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass PSOFactoryConfig:\n    \"\"\"\n    Complete configuration for PSO-Factory integration.\n\n    Provides type-safe configuration with automatic validation\n    and mathematical constraint checking.\n    \"\"\"\n\n    # Controller configuration\n    controller_type: SMCType\n    max_force: float = 100.0\n    dt: float = 0.01\n\n    # PSO algorithm parameters\n    pso_params: Dict[str, Any] = field(default_factory=lambda: {\n        'n_particles': 30,\n        'iters': 100,\n        'c1': 2.0,\n        'c2': 2.0,\n        'w': 0.9\n    })\n\n    # Performance monitoring\n    enable_monitoring: bool = True\n    enable_caching: bool = True\n    cache_size: int = 1000\n\n    # Validation settings\n    strict_validation: bool = True\n    constraint_tolerance: float = 1e-8\n\n    # PSO bounds (auto-derived if None)\n    custom_bounds: Optional[List[Tuple[float, float]]] = None\n\n    def __post_init__(self):\n        \"\"\"Validate configuration after initialization.\"\"\"\n        if self.max_force <= 0:\n            raise ValueError(\"max_force must be positive\")\n        if self.dt <= 0:\n            raise ValueError(\"dt must be positive\")\n        if not isinstance(self.controller_type, SMCType):\n            raise TypeError(\"controller_type must be SMCType\")\n\n        # Validate PSO parameters\n        if self.pso_params['n_particles'] < 10:\n            raise ValueError(\"n_particles should be \u2265 10\")\n        if self.pso_params['iters'] < 10:\n            raise ValueError(\"iters should be \u2265 10\")\n\n    @property\n    def gain_bounds(self) -> List[Tuple[float, float]]:\n        \"\"\"Get PSO bounds (custom or auto-derived).\"\"\"\n        if self.custom_bounds is not None:\n            return self.custom_bounds\n        return get_gain_bounds_for_pso(self.controller_type)\n\n    @property\n    def n_gains(self) -> int:\n        \"\"\"Get number of gain parameters.\"\"\"\n        return self.controller_type.gain_count\n\ndef load_factory_config(config_dict: Dict[str, Any]) -> PSOFactoryConfig:\n    \"\"\"\n    Load and validate factory configuration from dictionary.\n\n    Args:\n        config_dict: Configuration dictionary\n\n    Returns:\n        Validated PSOFactoryConfig object\n\n    Raises:\n        ConfigurationError: If validation fails\n    \"\"\"\n    try:\n        # Convert string controller type to enum\n        if isinstance(config_dict.get('controller_type'), str):\n            config_dict['controller_type'] = SMCType(config_dict['controller_type'])\n\n        return PSOFactoryConfig(**config_dict)\n    except (ValueError, TypeError) as e:\n        raise ConfigurationError(f\"Invalid factory configuration: {e}\")",
    "lines": 86,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4a54aff"
  },
  {
    "id": "pso_factory_api_reference_14_466de6e2",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_objective_pso_optimization(\n    controller_types: List[SMCType],\n    simulation_config: Dict[str, Any],\n    objectives: Dict[str, float],\n    pso_config: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"\n    Multi-objective PSO optimization across multiple controller types.\n\n    Optimizes multiple SMC controllers simultaneously using weighted\n    multi-objective fitness functions with Pareto front analysis.\n\n    Args:\n        controller_types: List of SMC types to optimize\n        simulation_config: Simulation parameters\n        objectives: Objective weights {'ise': 0.4, 'overshoot': 0.3, 'energy': 0.3}\n        pso_config: PSO algorithm configuration\n\n    Returns:\n        Comprehensive optimization results with Pareto analysis\n    \"\"\"\n\n    results = {}\n    all_solutions = []\n\n    for smc_type in controller_types:\n        print(f\"Optimizing {smc_type.value}...\")\n\n        # Get PSO bounds for this controller type\n        bounds = get_gain_bounds_for_pso(smc_type)\n\n        # Create multi-objective fitness function\n        def multi_objective_fitness(particles: np.ndarray) -> np.ndarray:\n            fitness_scores = []\n\n            for gains in particles:\n                try:\n                    # Create controller with validation\n                    controller = create_smc_for_pso(smc_type, gains.tolist())\n\n                    # Run simulation\n                    sim_result = run_simulation(controller, simulation_config)\n\n                    # Compute individual objectives\n                    ise = compute_ise(sim_result)\n                    overshoot = compute_overshoot(sim_result)\n                    energy = compute_control_energy(sim_result)\n\n                    # Weighted combination\n                    fitness = (objectives.get('ise', 0.0) * ise +\n                             objectives.get('overshoot', 0.0) * overshoot +\n                             objectives.get('energy', 0.0) * energy)\n\n                    fitness_scores.append(fitness)\n\n                    # Store solution for Pareto analysis\n                    all_solutions.append({\n                        'controller_type': smc_type,\n                        'gains': gains.tolist(),\n                        'fitness': fitness,\n                        'objectives': {'ise': ise, 'overshoot': overshoot, 'energy': energy}\n                    })\n\n                except Exception:\n                    fitness_scores.append(1000.0)\n\n            return np.array(fitness_scores)\n\n        # Run PSO optimization\n        from pyswarms.single import GlobalBestPSO\n        bounds_array = np.array(bounds)\n\n        optimizer = GlobalBestPSO(\n            n_particles=pso_config.get('n_particles', 30),\n            dimensions=len(bounds),\n            options={\n                'c1': pso_config.get('c1', 2.0),\n                'c2': pso_config.get('c2', 2.0),\n                'w': pso_config.get('w', 0.9)\n            },\n            bounds=(bounds_array[:, 0], bounds_array[:, 1])\n        )\n\n        best_cost, best_gains = optimizer.optimize(\n            multi_objective_fitness,\n            iters=pso_config.get('iters', 100)\n        )\n\n        results[smc_type.value] = {\n            'best_gains': best_gains.tolist(),\n            'best_fitness': float(best_cost),\n            'optimization_history': optimizer.cost_history\n        }\n\n    # Pareto front analysis\n    pareto_front = compute_pareto_front(all_solutions, objectives)\n    controller_ranking = rank_controllers_by_objectives(results, objectives)\n\n    return {\n        'individual_results': results,\n        'pareto_front': pareto_front,\n        'controller_ranking': controller_ranking,\n        'best_overall': select_best_overall_solution(results, objectives)\n    }\n\ndef compute_pareto_front(solutions: List[Dict[str, Any]],\n                        objectives: Dict[str, float]\n                        ) -> List[Dict[str, Any]]:\n    \"\"\"\n    Compute Pareto-optimal solutions from multi-objective optimization.\n\n    Args:\n        solutions: List of solution dictionaries\n        objectives: Objective weights\n\n    Returns:\n        List of Pareto-optimal solutions\n    \"\"\"\n    pareto_solutions = []\n\n    for i, solution_i in enumerate(solutions):\n        is_dominated = False\n\n        for j, solution_j in enumerate(solutions):\n            if i == j:\n                continue\n\n            # Check if solution_j dominates solution_i\n            obj_i = solution_i['objectives']\n            obj_j = solution_j['objectives']\n\n            dominates = True\n            for obj_name in objectives.keys():\n                if obj_j[obj_name] >= obj_i[obj_name]:  # j is not better in this objective\n                    dominates = False\n                    break\n\n            if dominates:\n                is_dominated = True\n                break\n\n        if not is_dominated:\n            pareto_solutions.append(solution_i)\n\n    return pareto_solutions",
    "lines": 148,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "466de6e2"
  },
  {
    "id": "pso_factory_api_reference_15_9dddfb63",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 15,
    "code": "class AdaptivePSOFactory:\n    \"\"\"\n    Adaptive PSO optimization with dynamic parameter adjustment.\n\n    Features:\n    - Dynamic bounds tightening around promising regions\n    - Adaptive PSO parameter tuning based on convergence\n    - Early stopping with convergence detection\n    - Multi-stage optimization with exploration-exploitation balance\n    \"\"\"\n\n    def __init__(self, smc_type: SMCType, config: Dict[str, Any]):\n        self.smc_type = smc_type\n        self.config = config\n        self.optimization_history = []\n        self.bounds_history = []\n\n        # Initialize with full bounds\n        self.current_bounds = get_gain_bounds_for_pso(smc_type)\n        self.best_solution = None\n        self.convergence_detector = PSOConvergenceDetector()\n\n    def optimize_with_adaptation(self,\n                                simulation_config: Dict[str, Any],\n                                stages: List[Dict[str, Any]]\n                                ) -> Dict[str, Any]:\n        \"\"\"\n        Run adaptive PSO optimization with multiple stages.\n\n        Args:\n            simulation_config: Simulation parameters\n            stages: List of optimization stages with different parameters\n\n        Returns:\n            Complete optimization results with adaptation history\n        \"\"\"\n\n        all_results = []\n\n        for stage_idx, stage_config in enumerate(stages):\n            print(f\"PSO Stage {stage_idx + 1}: {stage_config}\")\n\n            # Adapt PSO parameters for this stage\n            pso_params = self._adapt_pso_parameters(stage_config, stage_idx)\n\n            # Adapt bounds based on previous results\n            if stage_idx > 0 and self.best_solution is not None:\n                self.current_bounds = self._adapt_bounds(\n                    self.best_solution['gains'],\n                    stage_config.get('bound_tightening', 0.5)\n                )\n\n            # Create fitness function\n            fitness_function = self._create_adaptive_fitness_function(\n                simulation_config, stage_config\n            )\n\n            # Run PSO optimization stage\n            stage_result = self._run_pso_stage(\n                fitness_function, pso_params, stage_config['iterations']\n            )\n\n            all_results.append(stage_result)\n\n            # Update best solution\n            if (self.best_solution is None or\n                stage_result['best_fitness'] < self.best_solution['fitness']):\n                self.best_solution = {\n                    'gains': stage_result['best_gains'],\n                    'fitness': stage_result['best_fitness'],\n                    'stage': stage_idx\n                }\n\n            # Check for early convergence\n            if self.convergence_detector.check_convergence(stage_result):\n                print(f\"Early convergence detected at stage {stage_idx + 1}\")\n                break\n\n        # Combine results\n        final_result = self._combine_stage_results(all_results)\n        final_result['adaptation_history'] = {\n            'bounds_history': self.bounds_history,\n            'best_solution_history': self.optimization_history\n        }\n\n        return final_result\n\n    def _adapt_pso_parameters(self,\n                             stage_config: Dict[str, Any],\n                             stage_idx: int\n                             ) -> Dict[str, Any]:\n        \"\"\"Adapt PSO parameters based on stage and convergence history.\"\"\"\n\n        base_params = self.config.get('pso_params', {})\n\n        # Exploration vs exploitation balance\n        exploration_weight = stage_config.get('exploration_weight', 0.5)\n\n        # Adaptive inertia weight\n        w_max = 0.9\n        w_min = 0.4\n        w = w_max - (w_max - w_min) * exploration_weight\n\n        # Adaptive cognitive/social parameters\n        c1 = 2.5 - exploration_weight  # High cognitive for exploration\n        c2 = 0.5 + exploration_weight  # High social for exploitation\n\n        return {\n            'n_particles': base_params.get('n_particles', 30),\n            'c1': c1,\n            'c2': c2,\n            'w': w\n        }\n\n    def _adapt_bounds(self,\n                     best_gains: List[float],\n                     tightening_factor: float\n                     ) -> List[Tuple[float, float]]:\n        \"\"\"Adapt optimization bounds around best solution.\"\"\"\n\n        adapted_bounds = []\n        original_bounds = get_gain_bounds_for_pso(self.smc_type)\n\n        for i, (gain, (orig_lower, orig_upper)) in enumerate(zip(best_gains, original_bounds)):\n            # Calculate range around best gain\n            range_width = (orig_upper - orig_lower) * tightening_factor\n\n            # New bounds centered around best gain\n            new_lower = max(orig_lower, gain - range_width / 2)\n            new_upper = min(orig_upper, gain + range_width / 2)\n\n            adapted_bounds.append((new_lower, new_upper))\n\n        self.bounds_history.append(adapted_bounds)\n        return adapted_bounds\n\n    def _create_adaptive_fitness_function(self,\n                                        simulation_config: Dict[str, Any],\n                                        stage_config: Dict[str, Any]\n                                        ) -> Callable:\n        \"\"\"Create fitness function with adaptive features.\"\"\"\n\n        def adaptive_fitness(particles: np.ndarray) -> np.ndarray:\n            fitness_scores = []\n\n            for gains in particles:\n                try:\n                    # Create controller with validation\n                    controller = create_smc_for_pso(self.smc_type, gains.tolist())\n\n                    # Run simulation\n                    result = run_simulation(controller, simulation_config)\n\n                    # Compute base fitness\n                    base_fitness = compute_control_performance_metrics(\n                        result, stage_config.get('objectives', ['ise'])\n                    )\n\n                    # Add adaptive penalties/bonuses\n                    adapted_fitness = self._apply_adaptive_adjustments(\n                        base_fitness, gains.tolist(), stage_config\n                    )\n\n                    fitness_scores.append(adapted_fitness)\n\n                except Exception:\n                    fitness_scores.append(1000.0)\n\n            return np.array(fitness_scores)\n\n        return adaptive_fitness\n\n    def _apply_adaptive_adjustments(self,\n                                  base_fitness: float,\n                                  gains: List[float],\n                                  stage_config: Dict[str, Any]\n                                  ) -> float:\n        \"\"\"Apply adaptive adjustments to fitness based on stage configuration.\"\"\"\n\n        adjusted_fitness = base_fitness\n\n        # Diversity bonus (encourage exploration in early stages)\n        if stage_config.get('diversity_bonus', False) and self.best_solution:\n            distance = np.linalg.norm(\n                np.array(gains) - np.array(self.best_solution['gains'])\n            )\n            diversity_bonus = stage_config.get('diversity_weight', 0.1) * distance\n            adjusted_fitness -= diversity_bonus\n\n        # Stability margin bonus\n        if stage_config.get('stability_bonus', True):\n            stability_properties = estimate_stability_properties(self.smc_type, gains)\n            stability_bonus = stability_properties['stability_margin'] * 0.1\n            adjusted_fitness -= stability_bonus\n\n        return adjusted_fitness\n\nclass PSOConvergenceDetector:\n    \"\"\"Advanced convergence detection for PSO optimization.\"\"\"\n\n    def __init__(self, patience: int = 20, tolerance: float = 1e-6):\n        self.patience = patience\n        self.tolerance = tolerance\n        self.fitness_history = []\n        self.best_fitness = float('inf')\n        self.stagnation_count = 0\n\n    def check_convergence(self, stage_result: Dict[str, Any]) -> bool:\n        \"\"\"\n        Check if PSO has converged based on multiple criteria.\n\n        Args:\n            stage_result: Results from PSO optimization stage\n\n        Returns:\n            True if convergence detected, False otherwise\n        \"\"\"\n        current_fitness = stage_result['best_fitness']\n        self.fitness_history.append(current_fitness)\n\n        # Check for improvement\n        if current_fitness < self.best_fitness - self.tolerance:\n            self.best_fitness = current_fitness\n            self.stagnation_count = 0\n        else:\n            self.stagnation_count += 1\n\n        # Multiple convergence criteria\n        return (\n            self._check_fitness_plateau() or\n            self._check_statistical_convergence()\n        )\n\n    def _check_fitness_plateau(self) -> bool:\n        \"\"\"Check if fitness has plateaued.\"\"\"\n        return self.stagnation_count >= self.patience\n\n    def _check_statistical_convergence(self) -> bool:\n        \"\"\"Check statistical significance of convergence.\"\"\"\n        if len(self.fitness_history) < 30:\n            return False\n\n        # Test if recent improvements are statistically significant\n        recent_fitness = self.fitness_history[-15:]\n        older_fitness = self.fitness_history[-30:-15]\n\n        from scipy.stats import ttest_ind\n        try:\n            statistic, p_value = ttest_ind(recent_fitness, older_fitness)\n            return p_value > 0.05  # No significant difference\n        except:\n            return False",
    "lines": 252,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9dddfb63"
  },
  {
    "id": "pso_factory_api_reference_16_ee3d8532",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOPerformanceMonitor:\n    \"\"\"\n    Real-time performance monitoring for PSO-Factory integration.\n\n    Provides comprehensive monitoring of:\n    - PSO convergence metrics\n    - Controller creation performance\n    - Simulation execution times\n    - Memory usage tracking\n    - Error rate monitoring\n    \"\"\"\n\n    def __init__(self, monitoring_config: Dict[str, Any]):\n        self.config = monitoring_config\n        self.metrics = {\n            'pso_metrics': {\n                'total_evaluations': 0,\n                'successful_evaluations': 0,\n                'failed_evaluations': 0,\n                'average_fitness': 0.0,\n                'best_fitness': float('inf'),\n                'convergence_rate': 0.0\n            },\n            'performance_metrics': {\n                'controller_creation_time': [],\n                'simulation_execution_time': [],\n                'fitness_computation_time': [],\n                'total_optimization_time': 0.0\n            },\n            'resource_metrics': {\n                'peak_memory_usage': 0.0,\n                'average_memory_usage': 0.0,\n                'cpu_utilization': [],\n                'memory_samples': []\n            },\n            'error_metrics': {\n                'creation_failures': 0,\n                'simulation_failures': 0,\n                'validation_failures': 0,\n                'total_errors': 0\n            }\n        }\n\n        self.start_time = None\n        self.monitoring_active = False\n\n    def start_monitoring(self):\n        \"\"\"Start performance monitoring session.\"\"\"\n        import time\n        self.start_time = time.time()\n        self.monitoring_active = True\n        self._reset_metrics()\n\n    def stop_monitoring(self) -> Dict[str, Any]:\n        \"\"\"Stop monitoring and return complete performance report.\"\"\"\n        import time\n        if self.start_time:\n            self.metrics['performance_metrics']['total_optimization_time'] = (\n                time.time() - self.start_time\n            )\n        self.monitoring_active = False\n        return self.generate_performance_report()\n\n    def log_controller_creation(self, success: bool, creation_time: float):\n        \"\"\"Log controller creation event.\"\"\"\n        if not self.monitoring_active:\n            return\n\n        self.metrics['performance_metrics']['controller_creation_time'].append(creation_time)\n\n        if success:\n            self.metrics['pso_metrics']['successful_evaluations'] += 1\n        else:\n            self.metrics['error_metrics']['creation_failures'] += 1\n            self.metrics['pso_metrics']['failed_evaluations'] += 1\n\n    def log_simulation_execution(self, success: bool, execution_time: float):\n        \"\"\"Log simulation execution event.\"\"\"\n        if not self.monitoring_active:\n            return\n\n        if success:\n            self.metrics['performance_metrics']['simulation_execution_time'].append(execution_time)\n        else:\n            self.metrics['error_metrics']['simulation_failures'] += 1\n\n    def log_fitness_evaluation(self, fitness_value: float, computation_time: float):\n        \"\"\"Log fitness evaluation result.\"\"\"\n        if not self.monitoring_active:\n            return\n\n        self.metrics['performance_metrics']['fitness_computation_time'].append(computation_time)\n        self.metrics['pso_metrics']['total_evaluations'] += 1\n\n        # Update best fitness\n        if fitness_value < self.metrics['pso_metrics']['best_fitness']:\n            self.metrics['pso_metrics']['best_fitness'] = fitness_value\n\n        # Update average fitness (running average)\n        total_evals = self.metrics['pso_metrics']['total_evaluations']\n        current_avg = self.metrics['pso_metrics']['average_fitness']\n        self.metrics['pso_metrics']['average_fitness'] = (\n            (current_avg * (total_evals - 1) + fitness_value) / total_evals\n        )\n\n    def log_resource_usage(self):\n        \"\"\"Log current resource usage.\"\"\"\n        if not self.monitoring_active:\n            return\n\n        try:\n            import psutil\n\n            # Memory usage\n            memory_info = psutil.virtual_memory()\n            current_memory = memory_info.percent\n            self.metrics['resource_metrics']['memory_samples'].append(current_memory)\n\n            # Update peak memory\n            if current_memory > self.metrics['resource_metrics']['peak_memory_usage']:\n                self.metrics['resource_metrics']['peak_memory_usage'] = current_memory\n\n            # CPU utilization\n            cpu_percent = psutil.cpu_percent(interval=None)\n            self.metrics['resource_metrics']['cpu_utilization'].append(cpu_percent)\n\n        except ImportError:\n            pass  # psutil not available\n\n    def check_performance_alerts(self) -> List[str]:\n        \"\"\"Check for performance issues and return alerts.\"\"\"\n        alerts = []\n\n        # Memory usage alerts\n        if self.metrics['resource_metrics']['peak_memory_usage'] > 90:\n            alerts.append(f\"High memory usage: {self.metrics['resource_metrics']['peak_memory_usage']:.1f}%\")\n\n        # Error rate alerts\n        total_evals = self.metrics['pso_metrics']['total_evaluations']\n        if total_evals > 0:\n            error_rate = self.metrics['error_metrics']['total_errors'] / total_evals\n            if error_rate > 0.1:\n                alerts.append(f\"High error rate: {error_rate:.1%}\")\n\n        # Performance alerts\n        creation_times = self.metrics['performance_metrics']['controller_creation_time']\n        if creation_times and np.mean(creation_times) > 0.002:  # 2ms threshold\n            alerts.append(f\"Slow controller creation: {np.mean(creation_times)*1000:.2f}ms average\")\n\n        return alerts\n\n    def generate_performance_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive performance report.\"\"\"\n\n        # Calculate derived metrics\n        total_evals = self.metrics['pso_metrics']['total_evaluations']\n        success_rate = (self.metrics['pso_metrics']['successful_evaluations'] / total_evals * 100\n                       if total_evals > 0 else 0)\n\n        creation_times = self.metrics['performance_metrics']['controller_creation_time']\n        avg_creation_time = np.mean(creation_times) if creation_times else 0\n\n        simulation_times = self.metrics['performance_metrics']['simulation_execution_time']\n        avg_simulation_time = np.mean(simulation_times) if simulation_times else 0\n\n        fitness_times = self.metrics['performance_metrics']['fitness_computation_time']\n        avg_fitness_time = np.mean(fitness_times) if fitness_times else 0\n\n        memory_samples = self.metrics['resource_metrics']['memory_samples']\n        avg_memory = np.mean(memory_samples) if memory_samples else 0\n\n        cpu_samples = self.metrics['resource_metrics']['cpu_utilization']\n        avg_cpu = np.mean(cpu_samples) if cpu_samples else 0\n\n        total_time = self.metrics['performance_metrics']['total_optimization_time']\n        evaluations_per_second = total_evals / total_time if total_time > 0 else 0\n\n        # Generate report\n        report = {\n            'summary': {\n                'total_evaluations': total_evals,\n                'success_rate': success_rate,\n                'best_fitness_achieved': self.metrics['pso_metrics']['best_fitness'],\n                'total_optimization_time': total_time,\n                'evaluations_per_second': evaluations_per_second\n            },\n            'performance': {\n                'average_controller_creation_time_ms': avg_creation_time * 1000,\n                'average_simulation_time_ms': avg_simulation_time * 1000,\n                'average_fitness_computation_time_ms': avg_fitness_time * 1000\n            },\n            'resources': {\n                'peak_memory_usage_percent': self.metrics['resource_metrics']['peak_memory_usage'],\n                'average_memory_usage_percent': avg_memory,\n                'average_cpu_utilization_percent': avg_cpu\n            },\n            'errors': {\n                'controller_creation_failures': self.metrics['error_metrics']['creation_failures'],\n                'simulation_failures': self.metrics['error_metrics']['simulation_failures'],\n                'validation_failures': self.metrics['error_metrics']['validation_failures'],\n                'total_error_count': self.metrics['error_metrics']['total_errors']\n            },\n            'alerts': self.check_performance_alerts(),\n            'raw_metrics': self.metrics\n        }\n\n        return report\n\n    def _reset_metrics(self):\n        \"\"\"Reset all metrics for new monitoring session.\"\"\"\n        for category in self.metrics.values():\n            if isinstance(category, dict):\n                for key, value in category.items():\n                    if isinstance(value, list):\n                        category[key] = []\n                    elif isinstance(value, (int, float)):\n                        if 'best_fitness' in key:\n                            category[key] = float('inf')\n                        else:\n                            category[key] = 0\n\n# Context manager for automatic monitoring\n@contextmanager\ndef monitor_pso_performance(config: Dict[str, Any] = None):\n    \"\"\"\n    Context manager for automatic PSO performance monitoring.\n\n    Usage:\n        with monitor_pso_performance() as monitor:\n            # Run PSO optimization\n            result = optimize_controller_with_pso(...)\n\n        # Get performance report\n        report = monitor.generate_performance_report()\n    \"\"\"\n    monitor = PSOPerformanceMonitor(config or {})\n    monitor.start_monitoring()\n\n    try:\n        yield monitor\n    finally:\n        monitor.stop_monitoring()",
    "lines": 245,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee3d8532"
  },
  {
    "id": "pso_factory_api_reference_17_609da55c",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 17,
    "code": "class PSOFactoryError(Exception):\n    \"\"\"Base exception for PSO factory integration errors.\"\"\"\n    pass\n\nclass ControllerCreationError(PSOFactoryError):\n    \"\"\"Raised when controller creation fails.\"\"\"\n\n    def __init__(self, smc_type: SMCType, gains: List[float], message: str):\n        self.smc_type = smc_type\n        self.gains = gains\n        super().__init__(f\"Failed to create {smc_type.value} controller: {message}\")\n\nclass GainValidationError(PSOFactoryError):\n    \"\"\"Raised when gain validation fails.\"\"\"\n\n    def __init__(self, smc_type: SMCType, gains: List[float], violations: List[str]):\n        self.smc_type = smc_type\n        self.gains = gains\n        self.violations = violations\n        violation_text = \"; \".join(violations)\n        super().__init__(f\"Gain validation failed for {smc_type.value}: {violation_text}\")\n\nclass ConfigurationError(PSOFactoryError):\n    \"\"\"Raised when configuration is invalid.\"\"\"\n    pass\n\nclass SimulationError(PSOFactoryError):\n    \"\"\"Raised when simulation execution fails.\"\"\"\n    pass\n\n# Error handling decorators\ndef handle_pso_errors(func):\n    \"\"\"Decorator for robust PSO error handling.\"\"\"\n\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except GainValidationError:\n            # For PSO fitness functions, return penalty value\n            return 1000.0\n        except (ControllerCreationError, SimulationError) as e:\n            # Log error and return penalty\n            print(f\"PSO evaluation error: {e}\")\n            return 1000.0\n        except Exception as e:\n            # Unexpected errors - log and return penalty\n            print(f\"Unexpected PSO error: {e}\")\n            return 1000.0\n\n    return wrapper\n\n# Robust PSO fitness function template\n@handle_pso_errors\ndef robust_pso_fitness_function(gains: np.ndarray,\n                              smc_type: SMCType,\n                              simulation_config: Dict[str, Any]\n                              ) -> float:\n    \"\"\"\n    Template for robust PSO fitness functions with comprehensive error handling.\n\n    Args:\n        gains: Gain array from PSO\n        smc_type: Controller type\n        simulation_config: Simulation parameters\n\n    Returns:\n        Fitness value (lower is better)\n    \"\"\"\n    # Create controller with automatic validation\n    controller = create_smc_for_pso(smc_type, gains.tolist())\n\n    # Run simulation with error handling\n    result = run_simulation_with_error_handling(controller, simulation_config)\n\n    # Compute fitness with validation\n    fitness = compute_validated_fitness(result)\n\n    return fitness\n\ndef run_simulation_with_error_handling(controller, config: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Run simulation with comprehensive error handling.\"\"\"\n\n    try:\n        # Pre-validate simulation configuration\n        validate_simulation_config(config)\n\n        # Run simulation with timeout\n        with timeout_context(config.get('timeout', 30.0)):\n            result = run_simulation(controller, config)\n\n        # Post-validate simulation results\n        validate_simulation_results(result)\n\n        return result\n\n    except TimeoutError:\n        raise SimulationError(\"Simulation timeout exceeded\")\n    except ValueError as e:\n        raise SimulationError(f\"Simulation parameter error: {e}\")\n    except Exception as e:\n        raise SimulationError(f\"Simulation execution failed: {e}\")\n\n@contextmanager\ndef timeout_context(seconds: float):\n    \"\"\"Context manager for simulation timeout.\"\"\"\n    import signal\n\n    def timeout_handler(signum, frame):\n        raise TimeoutError(\"Operation timed out\")\n\n    # Set timeout handler\n    old_handler = signal.signal(signal.SIGALRM, timeout_handler)\n    signal.alarm(int(seconds))\n\n    try:\n        yield\n    finally:\n        signal.alarm(0)\n        signal.signal(signal.SIGALRM, old_handler)",
    "lines": 119,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "609da55c"
  },
  {
    "id": "pso_factory_api_reference_18_5c072b43",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef complete_pso_optimization_example():\n    \"\"\"\n    Complete example demonstrating PSO-Factory integration.\n\n    This example shows:\n    1. Configuration setup\n    2. Controller creation and validation\n    3. PSO optimization execution\n    4. Performance monitoring\n    5. Results analysis and validation\n    \"\"\"\n\n    # Step 1: Configuration setup\n    pso_config = PSOFactoryConfig(\n        controller_type=SMCType.CLASSICAL,\n        max_force=100.0,\n        dt=0.01,\n        pso_params={\n            'n_particles': 30,\n            'iters': 100,\n            'c1': 2.0,\n            'c2': 2.0,\n            'w': 0.9\n        },\n        enable_monitoring=True,\n        strict_validation=True\n    )\n\n    # Step 2: Simulation configuration\n    simulation_config = {\n        'duration': 5.0,\n        'dt': 0.01,\n        'initial_state': [0.1, 0.1, 0.0, 0.0, 0.0, 0.0],  # Small perturbation\n        'disturbances': {\n            'enable': True,\n            'amplitude': 5.0,\n            'frequency': 1.0\n        },\n        'performance_objectives': ['ise', 'overshoot', 'control_effort']\n    }\n\n    # Step 3: PSO optimization with monitoring\n    with monitor_pso_performance(pso_config.pso_params) as monitor:\n\n        # Define fitness function\n        @handle_pso_errors\n        def fitness_function(particles: np.ndarray) -> np.ndarray:\n            fitness_scores = []\n\n            for gains in particles:\n                start_time = time.perf_counter()\n\n                try:\n                    # Create controller with validation\n                    controller = create_smc_for_pso(\n                        pso_config.controller_type,\n                        gains.tolist(),\n                        pso_config.max_force\n                    )\n                    creation_time = time.perf_counter() - start_time\n                    monitor.log_controller_creation(True, creation_time)\n\n                    # Run simulation\n                    sim_start = time.perf_counter()\n                    result = run_simulation(controller, simulation_config)\n                    sim_time = time.perf_counter() - sim_start\n                    monitor.log_simulation_execution(True, sim_time)\n\n                    # Compute fitness\n                    fitness_start = time.perf_counter()\n                    fitness = compute_multi_objective_fitness(\n                        result, simulation_config['performance_objectives']\n                    )\n                    fitness_time = time.perf_counter() - fitness_start\n                    monitor.log_fitness_evaluation(fitness, fitness_time)\n\n                    fitness_scores.append(fitness)\n\n                except Exception as e:\n                    monitor.log_controller_creation(False, 0.0)\n                    fitness_scores.append(1000.0)\n\n                # Log resource usage periodically\n                if len(fitness_scores) % 10 == 0:\n                    monitor.log_resource_usage()\n\n            return np.array(fitness_scores)\n\n        # Step 4: Execute PSO optimization\n        from pyswarms.single import GlobalBestPSO\n\n        bounds = pso_config.gain_bounds\n        bounds_array = np.array(bounds)\n\n        optimizer = GlobalBestPSO(\n            n_particles=pso_config.pso_params['n_particles'],\n            dimensions=pso_config.n_gains,\n            options={\n                'c1': pso_config.pso_params['c1'],\n                'c2': pso_config.pso_params['c2'],\n                'w': pso_config.pso_params['w']\n            },\n            bounds=(bounds_array[:, 0], bounds_array[:, 1])\n        )\n\n        print(\"Starting PSO optimization...\")\n        best_cost, best_gains = optimizer.optimize(\n            fitness_function,\n            iters=pso_config.pso_params['iters'],\n            verbose=True\n        )\n\n    # Step 5: Results analysis\n    performance_report = monitor.generate_performance_report()\n\n    # Validate optimized controller\n    optimized_controller = create_smc_for_pso(\n        pso_config.controller_type,\n        best_gains.tolist(),\n        pso_config.max_force\n    )\n\n    # Run validation simulation\n    validation_result = run_simulation(optimized_controller, simulation_config)\n    validation_metrics = compute_validation_metrics(validation_result)\n\n    # Step 6: Generate comprehensive report\n    optimization_report = {\n        'optimization_results': {\n            'best_gains': best_gains.tolist(),\n            'best_fitness': float(best_cost),\n            'optimization_history': optimizer.cost_history,\n            'convergence_iteration': find_convergence_iteration(optimizer.cost_history)\n        },\n        'validation_results': {\n            'controller_gains': optimized_controller.gains,\n            'performance_metrics': validation_metrics,\n            'stability_analysis': estimate_stability_properties(\n                pso_config.controller_type, best_gains.tolist()\n            )\n        },\n        'performance_report': performance_report,\n        'configuration': {\n            'pso_config': pso_config.__dict__,\n            'simulation_config': simulation_config,\n            'bounds_used': bounds\n        }\n    }\n\n    # Step 7: Display results\n    print_optimization_summary(optimization_report)\n\n    return optimization_report\n\ndef print_optimization_summary(report: Dict[str, Any]):\n    \"\"\"Print formatted optimization summary.\"\"\"\n\n    opt_results = report['optimization_results']\n    val_results = report['validation_results']\n    perf_report = report['performance_report']\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PSO OPTIMIZATION RESULTS SUMMARY\")\n    print(\"=\"*80)\n\n    print(f\"\\n\ud83d\udcca OPTIMIZATION RESULTS:\")\n    print(f\"   Best Fitness: {opt_results['best_fitness']:.6f}\")\n    print(f\"   Best Gains: {opt_results['best_gains']}\")\n    print(f\"   Convergence: Iteration {opt_results['convergence_iteration']}\")\n\n    print(f\"\\n\ud83c\udfaf VALIDATION METRICS:\")\n    for metric, value in val_results['performance_metrics'].items():\n        print(f\"   {metric.upper()}: {value:.4f}\")\n\n    print(f\"\\n\u26a1 PERFORMANCE SUMMARY:\")\n    summary = perf_report['summary']\n    print(f\"   Total Evaluations: {summary['total_evaluations']}\")\n    print(f\"   Success Rate: {summary['success_rate']:.1f}%\")\n    print(f\"   Evaluations/sec: {summary['evaluations_per_second']:.1f}\")\n    print(f\"   Total Time: {summary['total_optimization_time']:.1f}s\")\n\n    perf = perf_report['performance']\n    print(f\"   Avg Creation Time: {perf['average_controller_creation_time_ms']:.2f}ms\")\n    print(f\"   Avg Simulation Time: {perf['average_simulation_time_ms']:.2f}ms\")\n\n    resources = perf_report['resources']\n    print(f\"   Peak Memory: {resources['peak_memory_usage_percent']:.1f}%\")\n    print(f\"   Avg CPU: {resources['average_cpu_utilization_percent']:.1f}%\")\n\n    if perf_report['alerts']:\n        print(f\"\\n\u26a0\ufe0f  PERFORMANCE ALERTS:\")\n        for alert in perf_report['alerts']:\n            print(f\"   - {alert}\")\n\n    print(\"\\n\" + \"=\"*80)\n\ndef find_convergence_iteration(cost_history: List[float],\n                              tolerance: float = 1e-6,\n                              patience: int = 10\n                              ) -> int:\n    \"\"\"Find iteration where PSO converged.\"\"\"\n\n    if len(cost_history) < patience:\n        return len(cost_history)\n\n    for i in range(patience, len(cost_history)):\n        # Check if fitness has been stable for 'patience' iterations\n        recent_costs = cost_history[i-patience:i]\n        if max(recent_costs) - min(recent_costs) < tolerance:\n            return i - patience + 1\n\n    return len(cost_history)  # No convergence detected\n\n# Run the complete example\nif __name__ == \"__main__\":\n    optimization_report = complete_pso_optimization_example()",
    "lines": 219,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c072b43"
  },
  {
    "id": "pso_factory_api_reference_19_5b7c5d58",
    "file": "docs\\factory\\pso_factory_api_reference.md",
    "index": 19,
    "code": "def multi_controller_comparison_example():\n    \"\"\"\n    Example demonstrating comparison of all SMC controller types.\n\n    Optimizes all 4 controller types and compares their performance\n    across multiple objectives and scenarios.\n    \"\"\"\n\n    # Define test scenarios\n    test_scenarios = [\n        {\n            'name': 'small_disturbance',\n            'initial_state': [0.05, 0.05, 0.0, 0.0, 0.0, 0.0],\n            'disturbance_amplitude': 2.0\n        },\n        {\n            'name': 'large_disturbance',\n            'initial_state': [0.2, 0.15, 0.0, 0.0, 0.0, 0.0],\n            'disturbance_amplitude': 10.0\n        },\n        {\n            'name': 'parameter_uncertainty',\n            'initial_state': [0.1, 0.1, 0.0, 0.0, 0.0, 0.0],\n            'parameter_variations': {'mass_uncertainty': 0.2}\n        }\n    ]\n\n    # Define optimization objectives\n    objectives = {\n        'control_performance': {'ise': 0.4, 'overshoot': 0.3, 'settling_time': 0.3},\n        'energy_efficiency': {'ise': 0.3, 'control_effort': 0.5, 'chattering': 0.2},\n        'robustness': {'ise': 0.2, 'disturbance_rejection': 0.4, 'parameter_sensitivity': 0.4}\n    }\n\n    # PSO configuration for all controllers\n    base_pso_config = {\n        'n_particles': 25,\n        'iters': 75,\n        'c1': 2.0,\n        'c2': 2.0,\n        'w': 0.9\n    }\n\n    all_results = {}\n\n    # Optimize each controller type\n    for smc_type in SMCType:\n        print(f\"\\n{'='*60}\")\n        print(f\"OPTIMIZING {smc_type.value.upper()}\")\n        print(f\"{'='*60}\")\n\n        controller_results = {}\n\n        # Test each scenario\n        for scenario in test_scenarios:\n            print(f\"\\nScenario: {scenario['name']}\")\n\n            scenario_results = {}\n\n            # Test each objective set\n            for obj_name, obj_weights in objectives.items():\n                print(f\"  Objective: {obj_name}\")\n\n                # Create simulation config for this scenario\n                sim_config = {\n                    'duration': 5.0,\n                    'dt': 0.01,\n                    'initial_state': scenario['initial_state'],\n                    'disturbance_amplitude': scenario.get('disturbance_amplitude', 0.0),\n                    'parameter_variations': scenario.get('parameter_variations', {}),\n                    'objectives': obj_weights\n                }\n\n                # Run PSO optimization\n                result = optimize_single_controller(\n                    smc_type, sim_config, base_pso_config\n                )\n\n                scenario_results[obj_name] = result\n\n            controller_results[scenario['name']] = scenario_results\n\n        all_results[smc_type.value] = controller_results\n\n    # Generate comparison analysis\n    comparison_analysis = analyze_controller_comparison(all_results, test_scenarios, objectives)\n\n    # Display results\n    display_comparison_results(comparison_analysis)\n\n    return comparison_analysis\n\ndef optimize_single_controller(smc_type: SMCType,\n                              sim_config: Dict[str, Any],\n                              pso_config: Dict[str, Any]\n                              ) -> Dict[str, Any]:\n    \"\"\"Optimize single controller for given scenario.\"\"\"\n\n    # Get PSO bounds\n    bounds = get_gain_bounds_for_pso(smc_type)\n    bounds_array = np.array(bounds)\n\n    # Create fitness function\n    def fitness_function(particles: np.ndarray) -> np.ndarray:\n        fitness_scores = []\n\n        for gains in particles:\n            try:\n                controller = create_smc_for_pso(smc_type, gains.tolist())\n                result = run_simulation(controller, sim_config)\n                fitness = compute_multi_objective_fitness(result, sim_config['objectives'])\n                fitness_scores.append(fitness)\n            except:\n                fitness_scores.append(1000.0)\n\n        return np.array(fitness_scores)\n\n    # Run PSO\n    from pyswarms.single import GlobalBestPSO\n\n    optimizer = GlobalBestPSO(\n        n_particles=pso_config['n_particles'],\n        dimensions=len(bounds),\n        options={\n            'c1': pso_config['c1'],\n            'c2': pso_config['c2'],\n            'w': pso_config['w']\n        },\n        bounds=(bounds_array[:, 0], bounds_array[:, 1])\n    )\n\n    best_cost, best_gains = optimizer.optimize(\n        fitness_function,\n        iters=pso_config['iters'],\n        verbose=False\n    )\n\n    # Validate result\n    final_controller = create_smc_for_pso(smc_type, best_gains.tolist())\n    validation_result = run_simulation(final_controller, sim_config)\n\n    return {\n        'best_gains': best_gains.tolist(),\n        'best_fitness': float(best_cost),\n        'validation_metrics': compute_validation_metrics(validation_result),\n        'optimization_history': optimizer.cost_history\n    }\n\ndef analyze_controller_comparison(results: Dict[str, Any],\n                                scenarios: List[Dict[str, Any]],\n                                objectives: Dict[str, Any]\n                                ) -> Dict[str, Any]:\n    \"\"\"Analyze comparison results across controllers.\"\"\"\n\n    analysis = {\n        'overall_ranking': {},\n        'scenario_performance': {},\n        'objective_performance': {},\n        'robustness_analysis': {},\n        'recommendations': {}\n    }\n\n    # Rank controllers by overall performance\n    controller_scores = {}\n    for controller_type in results.keys():\n        total_score = 0\n        count = 0\n\n        for scenario_name in results[controller_type].keys():\n            for obj_name in results[controller_type][scenario_name].keys():\n                fitness = results[controller_type][scenario_name][obj_name]['best_fitness']\n                total_score += fitness\n                count += 1\n\n        controller_scores[controller_type] = total_score / count if count > 0 else float('inf')\n\n    # Sort by performance (lower is better)\n    analysis['overall_ranking'] = dict(sorted(\n        controller_scores.items(), key=lambda x: x[1]\n    ))\n\n    # Analyze performance by scenario\n    for scenario in scenarios:\n        scenario_name = scenario['name']\n        scenario_scores = {}\n\n        for controller_type in results.keys():\n            if scenario_name in results[controller_type]:\n                avg_fitness = np.mean([\n                    results[controller_type][scenario_name][obj]['best_fitness']\n                    for obj in results[controller_type][scenario_name].keys()\n                ])\n                scenario_scores[controller_type] = avg_fitness\n\n        analysis['scenario_performance'][scenario_name] = dict(sorted(\n            scenario_scores.items(), key=lambda x: x[1]\n        ))\n\n    # Analyze performance by objective\n    for obj_name in objectives.keys():\n        objective_scores = {}\n\n        for controller_type in results.keys():\n            obj_scores = []\n            for scenario_name in results[controller_type].keys():\n                if obj_name in results[controller_type][scenario_name]:\n                    obj_scores.append(\n                        results[controller_type][scenario_name][obj_name]['best_fitness']\n                    )\n\n            if obj_scores:\n                objective_scores[controller_type] = np.mean(obj_scores)\n\n        analysis['objective_performance'][obj_name] = dict(sorted(\n            objective_scores.items(), key=lambda x: x[1]\n        ))\n\n    # Generate recommendations\n    analysis['recommendations'] = generate_controller_recommendations(analysis)\n\n    return analysis\n\ndef generate_controller_recommendations(analysis: Dict[str, Any]) -> Dict[str, str]:\n    \"\"\"Generate recommendations based on comparison analysis.\"\"\"\n\n    recommendations = {}\n\n    # Overall best controller\n    best_overall = list(analysis['overall_ranking'].keys())[0]\n    recommendations['best_overall'] = (\n        f\"{best_overall} shows the best overall performance across \"\n        f\"all scenarios and objectives.\"\n    )\n\n    # Scenario-specific recommendations\n    for scenario, ranking in analysis['scenario_performance'].items():\n        best_for_scenario = list(ranking.keys())[0]\n        recommendations[f'best_for_{scenario}'] = (\n            f\"{best_for_scenario} performs best for {scenario} scenarios.\"\n        )\n\n    # Objective-specific recommendations\n    for objective, ranking in analysis['objective_performance'].items():\n        best_for_objective = list(ranking.keys())[0]\n        recommendations[f'best_for_{objective}'] = (\n            f\"{best_for_objective} excels at {objective} objectives.\"\n        )\n\n    return recommendations\n\ndef display_comparison_results(analysis: Dict[str, Any]):\n    \"\"\"Display formatted comparison results.\"\"\"\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"MULTI-CONTROLLER COMPARISON RESULTS\")\n    print(\"=\"*80)\n\n    print(\"\\n\ud83c\udfc6 OVERALL RANKING:\")\n    for i, (controller, score) in enumerate(analysis['overall_ranking'].items(), 1):\n        print(f\"   {i}. {controller.upper()}: {score:.4f}\")\n\n    print(\"\\n\ud83d\udcca SCENARIO PERFORMANCE:\")\n    for scenario, ranking in analysis['scenario_performance'].items():\n        print(f\"\\n   {scenario.upper()}:\")\n        for i, (controller, score) in enumerate(ranking.items(), 1):\n            print(f\"      {i}. {controller}: {score:.4f}\")\n\n    print(\"\\n\ud83c\udfaf OBJECTIVE PERFORMANCE:\")\n    for objective, ranking in analysis['objective_performance'].items():\n        print(f\"\\n   {objective.upper()}:\")\n        for i, (controller, score) in enumerate(ranking.items(), 1):\n            print(f\"      {i}. {controller}: {score:.4f}\")\n\n    print(\"\\n\ud83d\udca1 RECOMMENDATIONS:\")\n    for key, recommendation in analysis['recommendations'].items():\n        print(f\"   \u2022 {recommendation}\")\n\n    print(\"\\n\" + \"=\"*80)\n\n# Run the comparison example\nif __name__ == \"__main__\":\n    comparison_results = multi_controller_comparison_example()",
    "lines": 282,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b7c5d58"
  },
  {
    "id": "pso_integration_workflow_1_cea235e1",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOFactoryInterface:\n    \"\"\"\n    Specialized interface for PSO optimization integration.\n\n    Features:\n    - Vectorized controller creation for swarm populations\n    - Automatic parameter validation and bounds checking\n    - Performance-optimized fitness evaluation\n    - Thread-safe parallel optimization support\n    \"\"\"\n\n    def __init__(self, controller_type: str, plant_config: Any):\n        self.controller_type = controller_type\n        self.plant_config = plant_config\n        self._setup_optimization_environment()\n\n    def _setup_optimization_environment(self) -> None:\n        \"\"\"Initialize PSO optimization environment.\"\"\"\n\n        # Get controller specifications\n        self.gain_spec = SMC_GAIN_SPECS[SMCType(self.controller_type)]\n        self.n_gains = self.gain_spec.n_gains\n        self.bounds = self.gain_spec.gain_bounds\n\n        # Performance monitoring\n        self.evaluation_count = 0\n        self.successful_evaluations = 0\n        self.failed_evaluations = 0\n\n        # Thread-safe operations\n        self._lock = threading.RLock()\n\n    def create_pso_controller_factory(self) -> Callable[[GainsArray], PSOControllerWrapper]:\n        \"\"\"\n        Create PSO-optimized controller factory function.\n\n        Returns:\n            Factory function that takes gains and returns PSO-wrapped controller\n        \"\"\"\n\n        def controller_factory(gains: GainsArray) -> PSOControllerWrapper:\n            \"\"\"PSO controller factory with comprehensive validation.\"\"\"\n\n            with self._lock:\n                self.evaluation_count += 1\n\n                try:\n                    # Validate gains\n                    if not self._validate_pso_gains(gains):\n                        self.failed_evaluations += 1\n                        return self._create_fallback_controller(gains)\n\n                    # Create controller via factory\n                    controller = create_controller(\n                        controller_type=self.controller_type,\n                        config=self.plant_config,\n                        gains=gains\n                    )\n\n                    # Wrap for PSO optimization\n                    wrapper = PSOControllerWrapper(\n                        controller=controller,\n                        controller_type=self.controller_type,\n                        validation_enabled=True\n                    )\n\n                    # Add PSO-required attributes\n                    wrapper.n_gains = self.n_gains\n                    wrapper.controller_type = self.controller_type\n                    wrapper.max_force = getattr(controller, 'max_force', 150.0)\n\n                    self.successful_evaluations += 1\n                    return wrapper\n\n                except Exception as e:\n                    logger.warning(f\"PSO controller creation failed: {e}\")\n                    self.failed_evaluations += 1\n                    return self._create_fallback_controller(gains)\n\n        # Add PSO-required attributes to factory function\n        controller_factory.n_gains = self.n_gains\n        controller_factory.controller_type = self.controller_type\n        controller_factory.bounds = self.bounds\n        controller_factory.max_force = 150.0\n\n        return controller_factory\n\n    def _validate_pso_gains(self, gains: GainsArray) -> bool:\n        \"\"\"Validate gains for PSO optimization.\"\"\"\n        try:\n            gains_array = np.asarray(gains)\n\n            # Check dimensions\n            if len(gains_array) != self.n_gains:\n                return False\n\n            # Check bounds\n            for i, (gain, (min_val, max_val)) in enumerate(zip(gains_array, self.bounds)):\n                if not (min_val <= gain <= max_val):\n                    return False\n\n            # Check numerical validity\n            if not np.all(np.isfinite(gains_array)):\n                return False\n\n            # Controller-specific validation\n            return validate_smc_gains(SMCType(self.controller_type), gains_array)\n\n        except Exception:\n            return False\n\n    def _create_fallback_controller(self, gains: GainsArray) -> PSOControllerWrapper:\n        \"\"\"Create fallback controller for invalid parameters.\"\"\"\n\n        # Use default gains as fallback\n        default_gains = get_default_gains(self.controller_type)\n\n        try:\n            controller = create_controller(\n                controller_type=self.controller_type,\n                config=self.plant_config,\n                gains=default_gains\n            )\n\n            wrapper = PSOControllerWrapper(\n                controller=controller,\n                controller_type=self.controller_type,\n                validation_enabled=False  # Disable validation for fallback\n            )\n\n            wrapper.n_gains = self.n_gains\n            wrapper.controller_type = self.controller_type\n            wrapper.is_fallback = True\n\n            return wrapper\n\n        except Exception:\n            # Emergency fallback - return minimal controller\n            return self._create_emergency_fallback()\n\n    def get_optimization_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get PSO optimization statistics.\"\"\"\n        with self._lock:\n            success_rate = self.successful_evaluations / max(1, self.evaluation_count)\n            return {\n                'total_evaluations': self.evaluation_count,\n                'successful_evaluations': self.successful_evaluations,\n                'failed_evaluations': self.failed_evaluations,\n                'success_rate': success_rate,\n                'optimization_health': 'GOOD' if success_rate > 0.8 else 'WARNING' if success_rate > 0.5 else 'POOR'\n            }",
    "lines": 154,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cea235e1"
  },
  {
    "id": "pso_integration_workflow_2_e827933f",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 2,
    "code": "def setup_classical_smc_pso_optimization(\n    plant_config: Any,\n    optimization_config: Optional[Dict[str, Any]] = None\n) -> Dict[str, Any]:\n    \"\"\"\n    Setup PSO optimization for Classical SMC with enhanced performance.\n\n    Classical SMC Parameters: [k1, k2, \u03bb1, \u03bb2, K, kd]\n    - k1, k2: Pendulum surface gains (convergence rate)\n    - \u03bb1, \u03bb2: Sliding coefficients (surface slope)\n    - K: Switching gain (uncertainty rejection)\n    - kd: Damping gain (chattering reduction)\n    \"\"\"\n\n    # Enhanced bounds for double-inverted pendulum\n    bounds = {\n        'lower': [5.0, 5.0, 3.0, 3.0, 10.0, 1.0],    # Conservative lower bounds\n        'upper': [50.0, 40.0, 30.0, 25.0, 80.0, 15.0] # Aggressive upper bounds\n    }\n\n    # PSO-specific configuration\n    default_config = {\n        'swarm_size': 30,\n        'max_iterations': 100,\n        'cognitive_param': 2.0,     # Personal best weight\n        'social_param': 2.0,        # Global best weight\n        'inertia_weight': 0.9,      # Exploration vs exploitation\n        'inertia_decay': 0.95,      # Dynamic inertia reduction\n        'convergence_threshold': 1e-6,\n        'parallel_evaluation': True,\n        'thread_count': 4\n    }\n\n    if optimization_config:\n        default_config.update(optimization_config)\n\n    # Create PSO factory interface\n    pso_interface = PSOFactoryInterface('classical_smc', plant_config)\n    controller_factory = pso_interface.create_pso_controller_factory()\n\n    # Fitness function for classical SMC\n    def fitness_function(gains: GainsArray) -> float:\n        \"\"\"\n        Multi-objective fitness function for Classical SMC optimization.\n\n        Objectives:\n        1. Stabilization performance (primary)\n        2. Control effort minimization (secondary)\n        3. Chattering reduction (tertiary)\n        \"\"\"\n\n        try:\n            controller = controller_factory(gains)\n\n            # Test scenarios\n            scenarios = [\n                ('small_disturbance', np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0])),\n                ('medium_angles', np.array([0.3, 0.4, 0.2, 0.1, 0.0, 0.0])),\n                ('high_velocity', np.array([0.1, 0.1, 0.1, 1.5, 1.0, 0.8]))\n            ]\n\n            total_cost = 0.0\n            scenario_weights = [0.5, 0.3, 0.2]  # Weight different scenarios\n\n            for weight, (scenario_name, initial_state) in zip(scenario_weights, scenarios):\n                scenario_cost = evaluate_scenario_performance(\n                    controller, initial_state, simulation_time=2.0\n                )\n                total_cost += weight * scenario_cost\n\n            # Penalize extreme gains\n            gain_penalty = compute_gain_penalty(gains, bounds)\n            total_cost += 0.1 * gain_penalty\n\n            return total_cost\n\n        except Exception as e:\n            logger.warning(f\"Fitness evaluation failed: {e}\")\n            return 1000.0  # High penalty for failed evaluations\n\n    return {\n        'controller_factory': controller_factory,\n        'fitness_function': fitness_function,\n        'bounds': bounds,\n        'pso_config': default_config,\n        'pso_interface': pso_interface,\n        'n_gains': 6,\n        'optimization_type': 'classical_smc_dip'\n    }\n\ndef evaluate_scenario_performance(\n    controller: PSOControllerWrapper,\n    initial_state: StateVector,\n    simulation_time: float = 2.0,\n    dt: float = 0.001\n) -> float:\n    \"\"\"Evaluate controller performance for a specific scenario.\"\"\"\n\n    from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n\n    # Create dynamics model\n    dynamics = SimplifiedDIPDynamics()\n\n    # Simulation parameters\n    n_steps = int(simulation_time / dt)\n    state = initial_state.copy()\n\n    # Performance metrics\n    position_errors = []\n    control_efforts = []\n    control_variations = []\n    previous_control = 0.0\n\n    for step in range(n_steps):\n        try:\n            # Compute control\n            control = controller.compute_control(state)\n            control_value = control[0]\n\n            # Store metrics\n            position_error = np.linalg.norm(state[:3])  # Position error magnitude\n            position_errors.append(position_error)\n            control_efforts.append(abs(control_value))\n\n            # Control variation (chattering metric)\n            control_variation = abs(control_value - previous_control)\n            control_variations.append(control_variation)\n            previous_control = control_value\n\n            # Simulate dynamics\n            result = dynamics.compute_dynamics(state, control)\n            if not result.success:\n                break\n\n            # Integrate\n            state = state + dt * result.state_derivative\n\n            # Stability check\n            if np.any(np.abs(state) > 10.0):\n                return 1000.0  # Instability penalty\n\n        except Exception:\n            return 1000.0  # Simulation failure penalty\n\n    # Compute composite cost\n    avg_position_error = np.mean(position_errors)\n    avg_control_effort = np.mean(control_efforts)\n    avg_control_variation = np.mean(control_variations)\n    final_position_error = position_errors[-1]\n\n    # Multi-objective cost function\n    cost = (\n        10.0 * avg_position_error +        # Primary: tracking performance\n        0.1 * avg_control_effort +         # Secondary: control effort\n        1.0 * avg_control_variation +      # Tertiary: chattering\n        5.0 * final_position_error         # Final: steady-state error\n    )\n\n    return cost\n\ndef compute_gain_penalty(gains: GainsArray, bounds: Dict[str, List[float]]) -> float:\n    \"\"\"Compute penalty for gains near boundaries.\"\"\"\n\n    gains_array = np.asarray(gains)\n    lower_bounds = np.array(bounds['lower'])\n    upper_bounds = np.array(bounds['upper'])\n\n    # Normalize gains to [0, 1] range\n    normalized_gains = (gains_array - lower_bounds) / (upper_bounds - lower_bounds)\n\n    # Penalty for gains too close to boundaries\n    boundary_penalty = 0.0\n    for g in normalized_gains:\n        if g < 0.1 or g > 0.9:  # Within 10% of boundaries\n            boundary_penalty += 1.0\n\n    return boundary_penalty",
    "lines": 177,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e827933f"
  },
  {
    "id": "pso_integration_workflow_3_2109d5ad",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 3,
    "code": "def setup_adaptive_smc_pso_optimization(\n    plant_config: Any,\n    adaptation_focused: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    Setup PSO optimization for Adaptive SMC with adaptation-focused tuning.\n\n    Adaptive SMC Parameters: [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    - k1, k2: Pendulum surface gains\n    - \u03bb1, \u03bb2: Sliding coefficients\n    - \u03b3: Adaptation rate (critical parameter)\n    \"\"\"\n\n    # Adaptation-focused bounds\n    if adaptation_focused:\n        bounds = {\n            'lower': [8.0, 8.0, 5.0, 5.0, 1.0],     # Higher surface gains\n            'upper': [60.0, 50.0, 40.0, 35.0, 8.0]  # Conservative adaptation rate\n        }\n    else:\n        bounds = {\n            'lower': [5.0, 5.0, 3.0, 3.0, 0.5],\n            'upper': [50.0, 40.0, 30.0, 25.0, 10.0]\n        }\n\n    # PSO configuration with emphasis on exploration for adaptation\n    pso_config = {\n        'swarm_size': 40,           # Larger swarm for adaptation exploration\n        'max_iterations': 150,      # More iterations for convergence\n        'cognitive_param': 2.5,     # Higher personal exploration\n        'social_param': 1.5,        # Lower social influence\n        'inertia_weight': 0.9,\n        'inertia_decay': 0.98,      # Slower decay for exploration\n        'adaptation_penalty_weight': 0.2,  # Penalty for poor adaptation\n        'convergence_threshold': 5e-7\n    }\n\n    # Create PSO interface\n    pso_interface = PSOFactoryInterface('adaptive_smc', plant_config)\n    controller_factory = pso_interface.create_pso_controller_factory()\n\n    def adaptive_fitness_function(gains: GainsArray) -> float:\n        \"\"\"Fitness function emphasizing adaptation performance.\"\"\"\n\n        try:\n            controller = controller_factory(gains)\n\n            # Extract adaptation rate for analysis\n            gamma = gains[4]\n\n            # Adaptive-specific test scenarios\n            scenarios = [\n                ('adaptation_test_1', np.array([0.2, 0.3, 0.1, 0.0, 0.0, 0.0])),\n                ('adaptation_test_2', np.array([0.4, 0.5, 0.3, 0.5, 0.3, 0.2])),\n                ('parameter_change', np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0]))  # For adaptation testing\n            ]\n\n            total_cost = 0.0\n\n            for i, (scenario_name, initial_state) in enumerate(scenarios):\n                if scenario_name == 'parameter_change':\n                    # Test adaptation to parameter changes\n                    cost = evaluate_adaptation_performance(controller, initial_state)\n                else:\n                    # Standard performance evaluation\n                    cost = evaluate_scenario_performance(controller, initial_state, simulation_time=3.0)\n\n                total_cost += cost\n\n            # Adaptation rate penalty\n            if gamma < 0.5 or gamma > 8.0:\n                total_cost += 50.0 * abs(gamma - 3.0)  # Penalty for extreme adaptation rates\n\n            # Convergence bonus for reasonable adaptation rates\n            if 1.0 <= gamma <= 5.0:\n                total_cost *= 0.9  # 10% bonus for good adaptation rate\n\n            return total_cost\n\n        except Exception as e:\n            logger.warning(f\"Adaptive fitness evaluation failed: {e}\")\n            return 1500.0\n\n    return {\n        'controller_factory': controller_factory,\n        'fitness_function': adaptive_fitness_function,\n        'bounds': bounds,\n        'pso_config': pso_config,\n        'pso_interface': pso_interface,\n        'n_gains': 5,\n        'optimization_type': 'adaptive_smc_dip',\n        'special_features': ['adaptation_monitoring', 'parameter_change_testing']\n    }\n\ndef evaluate_adaptation_performance(\n    controller: PSOControllerWrapper,\n    initial_state: StateVector,\n    simulation_time: float = 4.0\n) -> float:\n    \"\"\"Evaluate adaptation performance with parameter changes.\"\"\"\n\n    from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n\n    dynamics = SimplifiedDIPDynamics()\n    dt = 0.001\n    n_steps = int(simulation_time / dt)\n    state = initial_state.copy()\n\n    adaptation_errors = []\n    pre_change_errors = []\n    post_change_errors = []\n    change_step = n_steps // 2  # Parameter change at midpoint\n\n    for step in range(n_steps):\n        try:\n            # Simulate parameter change at midpoint\n            if step == change_step:\n                # Introduce disturbance to test adaptation\n                state += np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n\n            control = controller.compute_control(state)\n            result = dynamics.compute_dynamics(state, control)\n\n            if not result.success:\n                break\n\n            state = state + dt * result.state_derivative\n            position_error = np.linalg.norm(state[:3])\n\n            if step < change_step:\n                pre_change_errors.append(position_error)\n            else:\n                post_change_errors.append(position_error)\n\n            adaptation_errors.append(position_error)\n\n            if np.any(np.abs(state) > 8.0):\n                return 2000.0  # Adaptation failure penalty\n\n        except Exception:\n            return 2000.0\n\n    # Analyze adaptation performance\n    pre_change_avg = np.mean(pre_change_errors) if pre_change_errors else 1.0\n    post_change_avg = np.mean(post_change_errors) if post_change_errors else 1.0\n\n    # Adaptation quality metric\n    adaptation_ratio = post_change_avg / (pre_change_avg + 1e-6)\n\n    # Cost emphasizing good adaptation\n    adaptation_cost = (\n        5.0 * np.mean(adaptation_errors) +      # Overall performance\n        10.0 * max(0, adaptation_ratio - 2.0) + # Penalty for poor adaptation\n        2.0 * post_change_avg                   # Post-change performance\n    )\n\n    return adaptation_cost",
    "lines": 157,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2109d5ad"
  },
  {
    "id": "pso_integration_workflow_4_99ad56a8",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 4,
    "code": "def setup_super_twisting_smc_pso_optimization(\n    plant_config: Any,\n    high_performance_mode: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    Setup PSO optimization for Super-Twisting SMC.\n\n    STA-SMC Parameters: [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    - K1, K2: Super-twisting algorithm gains (K1 > K2 typically)\n    - k1, k2: Surface gains\n    - \u03bb1, \u03bb2: Sliding coefficients\n    \"\"\"\n\n    # High-performance bounds for aggressive STA tuning\n    if high_performance_mode:\n        bounds = {\n            'lower': [15.0, 10.0, 8.0, 8.0, 5.0, 5.0],\n            'upper': [100.0, 70.0, 60.0, 50.0, 40.0, 35.0]\n        }\n    else:\n        bounds = {\n            'lower': [10.0, 8.0, 5.0, 5.0, 3.0, 3.0],\n            'upper': [80.0, 60.0, 50.0, 40.0, 30.0, 25.0]\n        }\n\n    # STA-specific PSO configuration\n    pso_config = {\n        'swarm_size': 35,\n        'max_iterations': 120,\n        'cognitive_param': 2.2,\n        'social_param': 1.8,\n        'inertia_weight': 0.85,\n        'inertia_decay': 0.97,\n        'sta_constraint_weight': 0.3,  # Weight for STA-specific constraints\n        'convergence_threshold': 1e-6\n    }\n\n    pso_interface = PSOFactoryInterface('sta_smc', plant_config)\n    controller_factory = pso_interface.create_pso_controller_factory()\n\n    def sta_fitness_function(gains: GainsArray) -> float:\n        \"\"\"Fitness function for Super-Twisting SMC optimization.\"\"\"\n\n        try:\n            controller = controller_factory(gains)\n\n            K1, K2 = gains[0], gains[1]\n\n            # STA constraint penalty\n            sta_penalty = 0.0\n            if K1 <= K2:\n                sta_penalty += 100.0 * (K2 - K1 + 1.0)  # Strong penalty for K1 <= K2\n\n            # Test with challenging scenarios for STA performance\n            scenarios = [\n                ('precision_tracking', np.array([0.05, 0.03, 0.02, 0.0, 0.0, 0.0])),\n                ('large_disturbance', np.array([0.6, 0.8, 0.4, 0.3, 0.2, 0.1])),\n                ('high_frequency', np.array([0.2, 0.2, 0.2, 2.0, 1.5, 1.0]))\n            ]\n\n            total_cost = 0.0\n            scenario_weights = [0.4, 0.4, 0.2]\n\n            for weight, (scenario_name, initial_state) in zip(scenario_weights, scenarios):\n                if scenario_name == 'precision_tracking':\n                    # STA excels at precision - test with tighter tolerance\n                    cost = evaluate_sta_precision_performance(controller, initial_state)\n                elif scenario_name == 'large_disturbance':\n                    # Test robustness with large disturbances\n                    cost = evaluate_sta_robustness_performance(controller, initial_state)\n                else:\n                    # Standard evaluation\n                    cost = evaluate_scenario_performance(controller, initial_state)\n\n                total_cost += weight * cost\n\n            total_cost += sta_penalty\n\n            # Bonus for optimal K1/K2 ratio\n            k_ratio = K1 / K2\n            if 1.2 <= k_ratio <= 2.0:  # Optimal STA ratio range\n                total_cost *= 0.95  # 5% bonus\n\n            return total_cost\n\n        except Exception as e:\n            logger.warning(f\"STA fitness evaluation failed: {e}\")\n            return 1800.0\n\n    return {\n        'controller_factory': controller_factory,\n        'fitness_function': sta_fitness_function,\n        'bounds': bounds,\n        'pso_config': pso_config,\n        'pso_interface': pso_interface,\n        'n_gains': 6,\n        'optimization_type': 'sta_smc_dip',\n        'special_features': ['finite_time_convergence', 'chattering_reduction', 'robustness_testing']\n    }\n\ndef evaluate_sta_precision_performance(\n    controller: PSOControllerWrapper,\n    initial_state: StateVector,\n    precision_threshold: float = 0.01\n) -> float:\n    \"\"\"Evaluate STA precision performance with tight tolerances.\"\"\"\n\n    from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n\n    dynamics = SimplifiedDIPDynamics()\n    dt = 0.001\n    simulation_time = 3.0\n    n_steps = int(simulation_time / dt)\n    state = initial_state.copy()\n\n    precision_errors = []\n    convergence_time = None\n\n    for step in range(n_steps):\n        try:\n            control = controller.compute_control(state)\n            result = dynamics.compute_dynamics(state, control)\n\n            if not result.success:\n                break\n\n            state = state + dt * result.state_derivative\n            position_error = np.linalg.norm(state[:3])\n            precision_errors.append(position_error)\n\n            # Check for convergence to precision threshold\n            if convergence_time is None and position_error < precision_threshold:\n                convergence_time = step * dt\n\n            if np.any(np.abs(state) > 5.0):\n                return 1500.0  # Precision failure\n\n        except Exception:\n            return 1500.0\n\n    # Precision-focused cost function\n    avg_precision_error = np.mean(precision_errors)\n    final_precision_error = precision_errors[-1]\n\n    # Convergence time bonus\n    convergence_bonus = 0.0\n    if convergence_time is not None:\n        convergence_bonus = max(0, 2.0 - convergence_time)  # Bonus for fast convergence\n\n    precision_cost = (\n        20.0 * avg_precision_error +\n        30.0 * final_precision_error -\n        5.0 * convergence_bonus\n    )\n\n    return max(0.1, precision_cost)  # Minimum positive cost\n\ndef evaluate_sta_robustness_performance(\n    controller: PSOControllerWrapper,\n    initial_state: StateVector\n) -> float:\n    \"\"\"Evaluate STA robustness with large disturbances.\"\"\"\n\n    from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n\n    dynamics = SimplifiedDIPDynamics()\n    dt = 0.001\n    simulation_time = 4.0\n    n_steps = int(simulation_time / dt)\n    state = initial_state.copy()\n\n    robustness_errors = []\n    max_recovery_time = 0.0\n    disturbance_steps = [n_steps // 4, n_steps // 2, 3 * n_steps // 4]\n\n    for step in range(n_steps):\n        try:\n            # Apply disturbances at specific intervals\n            if step in disturbance_steps:\n                disturbance = np.array([0.1, 0.1, 0.05, 0.2, 0.1, 0.1])\n                state += disturbance\n\n            control = controller.compute_control(state)\n            result = dynamics.compute_dynamics(state, control)\n\n            if not result.success:\n                break\n\n            state = state + dt * result.state_derivative\n            position_error = np.linalg.norm(state[:3])\n            robustness_errors.append(position_error)\n\n            if np.any(np.abs(state) > 8.0):\n                return 2000.0  # Robustness failure\n\n        except Exception:\n            return 2000.0\n\n    # Robustness cost emphasizing disturbance rejection\n    avg_robustness_error = np.mean(robustness_errors)\n    max_error = np.max(robustness_errors)\n\n    robustness_cost = (\n        15.0 * avg_robustness_error +\n        10.0 * max_error +\n        5.0 * robustness_errors[-1]  # Final steady-state error\n    )\n\n    return robustness_cost",
    "lines": 209,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "99ad56a8"
  },
  {
    "id": "pso_integration_workflow_5_021011bc",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass ParallelPSOEvaluator:\n    \"\"\"\n    Thread-safe parallel evaluation system for PSO optimization.\n\n    Features:\n    - Multi-threaded fitness evaluation\n    - Load balancing across CPU cores\n    - Memory-efficient swarm processing\n    - Progress monitoring and early termination\n    \"\"\"\n\n    def __init__(\n        self,\n        controller_factory: Callable,\n        fitness_function: Callable,\n        n_threads: int = 4,\n        batch_size: int = 8\n    ):\n        self.controller_factory = controller_factory\n        self.fitness_function = fitness_function\n        self.n_threads = n_threads\n        self.batch_size = batch_size\n\n        # Thread management\n        self.thread_pool = ThreadPoolExecutor(max_workers=n_threads)\n        self.evaluation_lock = threading.RLock()\n\n        # Performance monitoring\n        self.evaluation_times = []\n        self.success_count = 0\n        self.failure_count = 0\n\n    def evaluate_swarm_parallel(\n        self,\n        swarm_positions: np.ndarray,\n        timeout_seconds: float = 30.0\n    ) -> List[float]:\n        \"\"\"\n        Evaluate entire swarm in parallel with timeout protection.\n\n        Args:\n            swarm_positions: Array of shape (swarm_size, n_dimensions)\n            timeout_seconds: Maximum time for evaluation\n\n        Returns:\n            List of fitness values for each particle\n        \"\"\"\n\n        swarm_size = swarm_positions.shape[0]\n        fitness_values = [float('inf')] * swarm_size\n\n        # Submit evaluation tasks\n        future_to_index = {}\n\n        for i in range(swarm_size):\n            future = self.thread_pool.submit(\n                self._evaluate_particle_safe,\n                swarm_positions[i],\n                i\n            )\n            future_to_index[future] = i\n\n        # Collect results with timeout\n        completed_count = 0\n        start_time = time.time()\n\n        for future in as_completed(future_to_index, timeout=timeout_seconds):\n            try:\n                particle_index = future_to_index[future]\n                fitness_value = future.result(timeout=1.0)  # Individual timeout\n                fitness_values[particle_index] = fitness_value\n\n                with self.evaluation_lock:\n                    self.success_count += 1\n                    completed_count += 1\n\n            except Exception as e:\n                particle_index = future_to_index[future]\n                logger.warning(f\"Particle {particle_index} evaluation failed: {e}\")\n\n                with self.evaluation_lock:\n                    self.failure_count += 1\n\n                # Use penalty value for failed evaluations\n                fitness_values[particle_index] = 5000.0\n\n            # Check for timeout\n            if time.time() - start_time > timeout_seconds:\n                logger.warning(f\"Swarm evaluation timeout after {timeout_seconds}s\")\n                break\n\n        # Cancel remaining futures\n        for future in future_to_index:\n            if not future.done():\n                future.cancel()\n\n        return fitness_values\n\n    def _evaluate_particle_safe(self, gains: GainsArray, particle_index: int) -> float:\n        \"\"\"Thread-safe particle evaluation with error handling.\"\"\"\n\n        start_time = time.time()\n\n        try:\n            # Create controller\n            controller = self.controller_factory(gains)\n\n            # Evaluate fitness\n            fitness_value = self.fitness_function(gains, controller)\n\n            # Record evaluation time\n            evaluation_time = time.time() - start_time\n            with self.evaluation_lock:\n                self.evaluation_times.append(evaluation_time)\n\n            return fitness_value\n\n        except Exception as e:\n            logger.warning(f\"Particle {particle_index} failed: {e}\")\n            return 3000.0  # High penalty for failures\n\n    def get_evaluation_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get parallel evaluation performance statistics.\"\"\"\n\n        with self.evaluation_lock:\n            total_evaluations = self.success_count + self.failure_count\n            success_rate = self.success_count / max(1, total_evaluations)\n\n            avg_time = np.mean(self.evaluation_times) if self.evaluation_times else 0.0\n            max_time = np.max(self.evaluation_times) if self.evaluation_times else 0.0\n\n            return {\n                'total_evaluations': total_evaluations,\n                'success_count': self.success_count,\n                'failure_count': self.failure_count,\n                'success_rate': success_rate,\n                'avg_evaluation_time': avg_time,\n                'max_evaluation_time': max_time,\n                'total_evaluation_time': sum(self.evaluation_times),\n                'parallel_efficiency': avg_time * self.n_threads / max(max_time, 0.001)\n            }\n\n    def cleanup(self):\n        \"\"\"Clean up thread pool resources.\"\"\"\n        self.thread_pool.shutdown(wait=True)",
    "lines": 148,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "021011bc"
  },
  {
    "id": "pso_integration_workflow_6_5a05c419",
    "file": "docs\\factory\\pso_integration_workflow.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOProgressMonitor:\n    \"\"\"\n    Comprehensive PSO optimization progress monitoring.\n\n    Features:\n    - Convergence detection\n    - Performance tracking\n    - Early termination criteria\n    - Optimization health assessment\n    \"\"\"\n\n    def __init__(\n        self,\n        convergence_threshold: float = 1e-6,\n        stagnation_threshold: int = 20,\n        max_evaluation_time: float = 0.1\n    ):\n        self.convergence_threshold = convergence_threshold\n        self.stagnation_threshold = stagnation_threshold\n        self.max_evaluation_time = max_evaluation_time\n\n        # Progress tracking\n        self.iteration_history = []\n        self.best_fitness_history = []\n        self.diversity_history = []\n        self.evaluation_time_history = []\n\n        # Convergence state\n        self.converged = False\n        self.stagnation_count = 0\n        self.best_fitness = float('inf')\n\n    def update_progress(\n        self,\n        iteration: int,\n        swarm_positions: np.ndarray,\n        fitness_values: List[float],\n        evaluation_time: float\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update optimization progress and assess termination criteria.\n\n        Returns:\n            Progress update with termination recommendations\n        \"\"\"\n\n        # Update best fitness\n        current_best = min(fitness_values)\n        improvement = self.best_fitness - current_best\n\n        if improvement > self.convergence_threshold:\n            self.best_fitness = current_best\n            self.stagnation_count = 0\n        else:\n            self.stagnation_count += 1\n\n        # Calculate swarm diversity\n        diversity = self._calculate_swarm_diversity(swarm_positions)\n\n        # Record history\n        self.iteration_history.append(iteration)\n        self.best_fitness_history.append(current_best)\n        self.diversity_history.append(diversity)\n        self.evaluation_time_history.append(evaluation_time)\n\n        # Assess convergence\n        convergence_status = self._assess_convergence(diversity, improvement)\n\n        # Performance assessment\n        performance_status = self._assess_performance(evaluation_time)\n\n        # Termination recommendation\n        should_terminate, termination_reason = self._should_terminate(\n            convergence_status, performance_status\n        )\n\n        return {\n            'iteration': iteration,\n            'best_fitness': current_best,\n            'improvement': improvement,\n            'diversity': diversity,\n            'stagnation_count': self.stagnation_count,\n            'convergence_status': convergence_status,\n            'performance_status': performance_status,\n            'should_terminate': should_terminate,\n            'termination_reason': termination_reason,\n            'evaluation_time': evaluation_time\n        }\n\n    def _calculate_swarm_diversity(self, swarm_positions: np.ndarray) -> float:\n        \"\"\"Calculate swarm diversity metric.\"\"\"\n        if len(swarm_positions) < 2:\n            return 0.0\n\n        # Calculate pairwise distances\n        distances = []\n        for i in range(len(swarm_positions)):\n            for j in range(i + 1, len(swarm_positions)):\n                distance = np.linalg.norm(swarm_positions[i] - swarm_positions[j])\n                distances.append(distance)\n\n        return np.mean(distances) if distances else 0.0\n\n    def _assess_convergence(self, diversity: float, improvement: float) -> str:\n        \"\"\"Assess convergence status.\"\"\"\n        if improvement < self.convergence_threshold and diversity < 0.01:\n            return 'CONVERGED'\n        elif self.stagnation_count >= self.stagnation_threshold:\n            return 'STAGNATED'\n        elif diversity < 0.1:\n            return 'LOW_DIVERSITY'\n        elif improvement > 1.0:\n            return 'IMPROVING'\n        else:\n            return 'SEARCHING'\n\n    def _assess_performance(self, evaluation_time: float) -> str:\n        \"\"\"Assess computational performance.\"\"\"\n        if evaluation_time > self.max_evaluation_time:\n            return 'SLOW'\n        elif evaluation_time > self.max_evaluation_time * 0.5:\n            return 'MODERATE'\n        else:\n            return 'FAST'\n\n    def _should_terminate(\n        self,\n        convergence_status: str,\n        performance_status: str\n    ) -> Tuple[bool, str]:\n        \"\"\"Determine if optimization should terminate early.\"\"\"\n\n        if convergence_status == 'CONVERGED':\n            return True, 'Convergence achieved'\n\n        if convergence_status == 'STAGNATED':\n            return True, f'Stagnation detected ({self.stagnation_count} iterations)'\n\n        if performance_status == 'SLOW' and len(self.evaluation_time_history) > 10:\n            avg_time = np.mean(self.evaluation_time_history[-10:])\n            if avg_time > self.max_evaluation_time * 2:\n                return True, 'Performance degradation detected'\n\n        return False, 'Continue optimization'\n\n    def generate_optimization_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive optimization report.\"\"\"\n        return {\n            'optimization_summary': {\n                'total_iterations': len(self.iteration_history),\n                'best_fitness_achieved': min(self.best_fitness_history) if self.best_fitness_history else float('inf'),\n                'final_diversity': self.diversity_history[-1] if self.diversity_history else 0.0,\n                'convergence_status': 'CONVERGED' if self.converged else 'INCOMPLETE'\n            },\n            'performance_metrics': {\n                'avg_evaluation_time': np.mean(self.evaluation_time_history) if self.evaluation_time_history else 0.0,\n                'max_evaluation_time': np.max(self.evaluation_time_history) if self.evaluation_time_history else 0.0,\n                'total_optimization_time': sum(self.evaluation_time_history)\n            },\n            'convergence_analysis': {\n                'fitness_improvement_rate': self._calculate_improvement_rate(),\n                'diversity_trend': self._calculate_diversity_trend(),\n                'stagnation_periods': self._identify_stagnation_periods()\n            }\n        }\n\n    def _calculate_improvement_rate(self) -> float:\n        \"\"\"Calculate average fitness improvement rate.\"\"\"\n        if len(self.best_fitness_history) < 2:\n            return 0.0\n\n        improvements = []\n        for i in range(1, len(self.best_fitness_history)):\n            improvement = self.best_fitness_history[i-1] - self.best_fitness_history[i]\n            improvements.append(max(0, improvement))\n\n        return np.mean(improvements)\n\n    def _calculate_diversity_trend(self) -> str:\n        \"\"\"Calculate diversity trend over time.\"\"\"\n        if len(self.diversity_history) < 10:\n            return 'INSUFFICIENT_DATA'\n\n        recent_diversity = np.mean(self.diversity_history[-5:])\n        earlier_diversity = np.mean(self.diversity_history[-10:-5])\n\n        if recent_diversity < earlier_diversity * 0.8:\n            return 'DECREASING'\n        elif recent_diversity > earlier_diversity * 1.2:\n            return 'INCREASING'\n        else:\n            return 'STABLE'\n\n    def _identify_stagnation_periods(self) -> List[Tuple[int, int]]:\n        \"\"\"Identify periods of stagnation in optimization.\"\"\"\n        stagnation_periods = []\n        current_start = None\n        stagnation_threshold = 5\n\n        for i in range(1, len(self.best_fitness_history)):\n            improvement = self.best_fitness_history[i-1] - self.best_fitness_history[i]\n\n            if improvement < self.convergence_threshold:\n                if current_start is None:\n                    current_start = i - 1\n            else:\n                if current_start is not None and i - current_start >= stagnation_threshold:\n                    stagnation_periods.append((current_start, i - 1))\n                current_start = None\n\n        # Handle final stagnation period\n        if current_start is not None and len(self.best_fitness_history) - current_start >= stagnation_threshold:\n            stagnation_periods.append((current_start, len(self.best_fitness_history) - 1))\n\n        return stagnation_periods",
    "lines": 218,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a05c419"
  },
  {
    "id": "README_1_61017573",
    "file": "docs\\factory\\README.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\n# Classical SMC\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n)\n\n# Adaptive SMC\ncontroller = create_controller(\n    'adaptive_smc',\n    gains=[25.0, 18.0, 15.0, 10.0, 4.0]\n)\n\n# Super-Twisting SMC\ncontroller = create_controller(\n    'sta_smc',\n    gains=[25.0, 15.0, 20.0, 12.0, 8.0, 6.0]\n)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61017573"
  },
  {
    "id": "README_2_c467797d",
    "file": "docs\\factory\\README.md",
    "index": 2,
    "code": "from src.controllers.factory import create_pso_controller_factory, SMCType\n\n# Create PSO-optimized factory\nfactory_func = create_pso_controller_factory(SMCType.CLASSICAL)\n\n# Use in optimization\nfrom src.optimizer.pso_optimizer import PSOTuner\ntuner = PSOTuner(controller_factory=factory_func, bounds=bounds)\noptimized_gains, cost = tuner.optimize()",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c467797d"
  },
  {
    "id": "README_3_4a22ad40",
    "file": "docs\\factory\\README.md",
    "index": 3,
    "code": "from src.controllers.factory.deprecation import check_deprecated_config\n\n# Automatic parameter migration\nold_config = {'switch_function': 'sign', 'gamma': 0.1}\nnew_config = check_deprecated_config('classical_smc', old_config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a22ad40"
  },
  {
    "id": "README_4_d4d7270d",
    "file": "docs\\factory\\README.md",
    "index": 4,
    "code": "def quick_health_check():\n    from src.controllers.factory import create_controller\n    try:\n        controller = create_controller('classical_smc', gains=[20]*6)\n        print(\"\u2705 Factory system healthy\")\n        return True\n    except Exception as e:\n        print(f\"\u274c Factory system issue: {e}\")\n        return False\n\nquick_health_check()",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4d7270d"
  },
  {
    "id": "testing_validation_documentation_1_77175e33",
    "file": "docs\\factory\\testing_validation_documentation.md",
    "index": 1,
    "code": "import pytest\nimport numpy as np\nfrom unittest.mock import Mock, patch\nfrom typing import Dict, Any, List\n\nfrom src.controllers.factory import (\n    create_controller, SMCFactory, SMCType, SMCConfig,\n    _resolve_controller_gains, _validate_controller_gains,\n    _extract_controller_parameters, CONTROLLER_REGISTRY\n)\n\nclass TestControllerFactoryCore:\n    \"\"\"Core factory functionality testing.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup test fixtures for each test method.\"\"\"\n        self.plant_config = self._create_test_plant_config()\n        self.valid_gain_sets = {\n            'classical_smc': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n            'adaptive_smc': [25.0, 18.0, 15.0, 10.0, 4.0],\n            'sta_smc': [35.0, 20.0, 25.0, 18.0, 12.0, 8.0],\n            'hybrid_adaptive_sta_smc': [18.0, 12.0, 10.0, 8.0]\n        }\n\n    def _create_test_plant_config(self) -> Any:\n        \"\"\"Create standardized test plant configuration.\"\"\"\n        from src.plant.configurations import ConfigurationFactory\n        return ConfigurationFactory.create_default_config(\"simplified\")\n\n    @pytest.mark.parametrize(\"controller_type,expected_gains\", [\n        ('classical_smc', 6),\n        ('adaptive_smc', 5),\n        ('sta_smc', 6),\n        ('hybrid_adaptive_sta_smc', 4)\n    ])\n    def test_controller_creation_success(self, controller_type: str, expected_gains: int):\n        \"\"\"Test successful controller creation for all types.\"\"\"\n        gains = self.valid_gain_sets[controller_type]\n\n        controller = create_controller(\n            controller_type=controller_type,\n            config=self.plant_config,\n            gains=gains\n        )\n\n        assert controller is not None\n        assert hasattr(controller, 'compute_control')\n        assert hasattr(controller, 'gains')\n        assert len(controller.gains) == expected_gains\n\n    def test_controller_registry_completeness(self):\n        \"\"\"Test that controller registry is complete and well-formed.\"\"\"\n        required_keys = [\n            'class', 'config_class', 'default_gains',\n            'gain_count', 'description', 'supports_dynamics', 'required_params'\n        ]\n\n        for controller_type, info in CONTROLLER_REGISTRY.items():\n            for key in required_keys:\n                assert key in info, f\"Missing key '{key}' in registry for {controller_type}\"\n\n            # Validate default gains structure\n            assert len(info['default_gains']) == info['gain_count']\n            assert all(isinstance(g, (int, float)) for g in info['default_gains'])\n            assert all(g > 0 for g in info['default_gains'])\n\n    def test_parameter_resolution_hierarchy(self):\n        \"\"\"Test parameter resolution follows correct hierarchy.\"\"\"\n        controller_type = 'classical_smc'\n        controller_info = CONTROLLER_REGISTRY[controller_type]\n\n        # Test 1: Explicit gains take priority\n        explicit_gains = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n        resolved_gains = _resolve_controller_gains(\n            gains=explicit_gains,\n            config=None,\n            controller_type=controller_type,\n            controller_info=controller_info\n        )\n        assert resolved_gains == explicit_gains\n\n        # Test 2: Config gains when no explicit gains\n        config_mock = Mock()\n        config_mock.controllers = {\n            controller_type: {'gains': [7.0, 8.0, 9.0, 10.0, 11.0, 12.0]}\n        }\n        resolved_gains = _resolve_controller_gains(\n            gains=None,\n            config=config_mock,\n            controller_type=controller_type,\n            controller_info=controller_info\n        )\n        assert resolved_gains == [7.0, 8.0, 9.0, 10.0, 11.0, 12.0]\n\n        # Test 3: Default gains as fallback\n        resolved_gains = _resolve_controller_gains(\n            gains=None,\n            config=None,\n            controller_type=controller_type,\n            controller_info=controller_info\n        )\n        assert resolved_gains == controller_info['default_gains']\n\n    @pytest.mark.parametrize(\"invalid_gains,expected_error\", [\n        ([], ValueError),  # Empty gains\n        ([1.0, 2.0], ValueError),  # Too few gains\n        ([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], ValueError),  # Too many gains\n        ([np.nan, 2.0, 3.0, 4.0, 5.0, 6.0], ValueError),  # NaN gain\n        ([np.inf, 2.0, 3.0, 4.0, 5.0, 6.0], ValueError),  # Infinite gain\n        ([-1.0, 2.0, 3.0, 4.0, 5.0, 6.0], ValueError),  # Negative gain\n        ([0.0, 2.0, 3.0, 4.0, 5.0, 6.0], ValueError),  # Zero gain\n        (['a', 2.0, 3.0, 4.0, 5.0, 6.0], ValueError),  # Non-numeric gain\n    ])\n    def test_gain_validation_errors(self, invalid_gains: List, expected_error: type):\n        \"\"\"Test gain validation properly catches invalid inputs.\"\"\"\n        controller_info = CONTROLLER_REGISTRY['classical_smc']\n\n        with pytest.raises(expected_error):\n            _validate_controller_gains(invalid_gains, controller_info)\n\n    def test_configuration_parameter_extraction(self):\n        \"\"\"Test configuration parameter extraction from various formats.\"\"\"\n        # Test with Pydantic-like config\n        pydantic_config = Mock()\n        pydantic_config.controllers = {\n            'classical_smc': Mock()\n        }\n        pydantic_config.controllers['classical_smc'].model_dump.return_value = {\n            'gains': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n            'max_force': 100.0,\n            'boundary_layer': 0.02\n        }\n\n        params = _extract_controller_parameters(\n            pydantic_config, 'classical_smc', CONTROLLER_REGISTRY['classical_smc']\n        )\n\n        assert 'gains' in params\n        assert 'max_force' in params\n        assert 'boundary_layer' in params\n\n        # Test with dictionary config\n        dict_config = Mock()\n        dict_config.controllers = {\n            'classical_smc': {\n                'gains': [7.0, 8.0, 9.0, 10.0, 11.0, 12.0],\n                'max_force': 150.0\n            }\n        }\n\n        params = _extract_controller_parameters(\n            dict_config, 'classical_smc', CONTROLLER_REGISTRY['classical_smc']\n        )\n\n        assert params['gains'] == [7.0, 8.0, 9.0, 10.0, 11.0, 12.0]\n        assert params['max_force'] == 150.0\n\n    def test_thread_safety_basic(self):\n        \"\"\"Test basic thread safety of factory operations.\"\"\"\n        import threading\n        import time\n\n        results = []\n        errors = []\n\n        def create_controller_threaded(thread_id: int):\n            try:\n                for i in range(5):\n                    gains = [10.0 + thread_id, 5.0, 8.0, 3.0, 15.0, 2.0]\n                    controller = create_controller(\n                        'classical_smc',\n                        self.plant_config,\n                        gains\n                    )\n                    assert controller is not None\n                    time.sleep(0.001)  # Small delay to increase contention\n                results.append(True)\n            except Exception as e:\n                errors.append(f\"Thread {thread_id}: {str(e)}\")\n                results.append(False)\n\n        # Create and run multiple threads\n        threads = []\n        for i in range(3):\n            thread = threading.Thread(target=create_controller_threaded, args=(i,))\n            threads.append(thread)\n            thread.start()\n\n        # Wait for completion\n        for thread in threads:\n            thread.join(timeout=10.0)\n\n        # Verify results\n        assert not errors, f\"Thread safety errors: {errors}\"\n        assert all(results), \"Some threads failed\"\n\n    def test_error_recovery_mechanisms(self):\n        \"\"\"Test error recovery and graceful degradation.\"\"\"\n        # Test with invalid config that should trigger fallback\n        invalid_config = Mock()\n        invalid_config.controllers = None  # This should cause extraction to fail\n\n        # Should still create controller using default parameters\n        controller = create_controller(\n            'classical_smc',\n            invalid_config,\n            [10.0, 5.0, 8.0, 3.0, 15.0, 2.0]\n        )\n\n        assert controller is not None\n\n    def test_memory_usage_validation(self):\n        \"\"\"Test that factory doesn't leak memory during intensive use.\"\"\"\n        import gc\n        import weakref\n\n        # Create many controllers and track weak references\n        weak_refs = []\n\n        for i in range(20):\n            gains = [10.0 + i, 5.0, 8.0, 3.0, 15.0, 2.0]\n            controller = create_controller(\n                'classical_smc',\n                self.plant_config,\n                gains\n            )\n            weak_refs.append(weakref.ref(controller))\n            del controller\n\n        # Force garbage collection\n        gc.collect()\n\n        # Check that controllers were properly cleaned up\n        alive_refs = [ref for ref in weak_refs if ref() is not None]\n        assert len(alive_refs) <= 3, f\"Memory leak detected: {len(alive_refs)} controllers still alive\"",
    "lines": 235,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "77175e33"
  },
  {
    "id": "testing_validation_documentation_2_d37c42cf",
    "file": "docs\\factory\\testing_validation_documentation.md",
    "index": 2,
    "code": "class TestParameterValidation:\n    \"\"\"Comprehensive parameter validation testing.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup validation test environment.\"\"\"\n        self.validator = ParameterValidator()\n\n    @pytest.mark.parametrize(\"controller_type,valid_gains\", [\n        ('classical_smc', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]),\n        ('adaptive_smc', [25.0, 18.0, 15.0, 10.0, 4.0]),\n        ('sta_smc', [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]),\n        ('hybrid_adaptive_sta_smc', [18.0, 12.0, 10.0, 8.0])\n    ])\n    def test_valid_gain_validation(self, controller_type: str, valid_gains: List[float]):\n        \"\"\"Test validation passes for valid gain configurations.\"\"\"\n        controller_info = CONTROLLER_REGISTRY[controller_type]\n\n        # Should not raise any exceptions\n        _validate_controller_gains(valid_gains, controller_info)\n\n        # Test with numpy array input\n        _validate_controller_gains(np.array(valid_gains), controller_info)\n\n    def test_adaptive_smc_gamma_validation(self):\n        \"\"\"Test specific validation for adaptive SMC gamma parameter.\"\"\"\n        # Valid gamma values\n        valid_configs = [\n            [10.0, 5.0, 8.0, 3.0, 2.0],    # Normal gamma\n            [10.0, 5.0, 8.0, 3.0, 0.5],   # Low gamma\n            [10.0, 5.0, 8.0, 3.0, 8.0],   # High gamma\n        ]\n\n        for gains in valid_configs:\n            controller_info = CONTROLLER_REGISTRY['adaptive_smc']\n            _validate_controller_gains(gains, controller_info)\n\n        # Invalid gamma values should trigger warnings but not errors\n        # (Warnings are handled at higher level)\n        extreme_gamma_gains = [10.0, 5.0, 8.0, 3.0, 15.0]  # Very high gamma\n        controller_info = CONTROLLER_REGISTRY['adaptive_smc']\n        _validate_controller_gains(extreme_gamma_gains, controller_info)\n\n    def test_super_twisting_k1_k2_relationship(self):\n        \"\"\"Test STA-SMC K1/K2 relationship validation.\"\"\"\n        # Optimal relationship: K1 > K2\n        optimal_gains = [35.0, 20.0, 25.0, 18.0, 12.0, 8.0]  # K1=35 > K2=20\n        controller_info = CONTROLLER_REGISTRY['sta_smc']\n        _validate_controller_gains(optimal_gains, controller_info)\n\n        # Suboptimal but valid: K1 <= K2 (should warn but not fail)\n        suboptimal_gains = [20.0, 25.0, 25.0, 18.0, 12.0, 8.0]  # K1=20 < K2=25\n        _validate_controller_gains(suboptimal_gains, controller_info)\n\n    def test_parameter_bounds_validation(self):\n        \"\"\"Test parameter bounds checking.\"\"\"\n        from src.controllers.factory.smc_factory import validate_parameter_ranges\n\n        # Test within bounds\n        controller_type = 'classical_smc'\n        gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        bounds = [(5.0, 50.0), (5.0, 40.0), (3.0, 30.0), (3.0, 25.0), (10.0, 80.0), (1.0, 15.0)]\n\n        # Should not raise exception\n        validate_parameter_ranges(gains, controller_type, bounds)\n\n        # Test outside bounds\n        out_of_bounds_gains = [100.0, 15.0, 12.0, 8.0, 35.0, 5.0]  # First gain too high\n        with pytest.raises(ValueError):\n            validate_parameter_ranges(out_of_bounds_gains, controller_type, bounds)\n\n    def test_configuration_migration_validation(self):\n        \"\"\"Test validation of migrated configurations.\"\"\"\n        # Test deprecated parameter handling\n        deprecated_config = {\n            'gains': [10.0, 5.0, 8.0, 3.0, 15.0, 2.0],\n            'max_force': 100.0,\n            'gamma': 0.1,  # Should be deprecated for classical_smc\n        }\n\n        # Should handle gracefully without crashing\n        from src.controllers.factory.deprecation import check_deprecated_config\n        migrated_config = check_deprecated_config('classical_smc', deprecated_config)\n\n        # Gamma should be removed for classical_smc\n        assert 'gamma' not in migrated_config\n\n    def test_hybrid_smc_sub_configuration_validation(self):\n        \"\"\"Test validation of hybrid SMC sub-configurations.\"\"\"\n        # Create valid sub-configurations\n        from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n        from src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\n        classical_config = ClassicalSMCConfig(\n            gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n            max_force=150.0,\n            dt=0.001,\n            boundary_layer=0.02\n        )\n\n        adaptive_config = AdaptiveSMCConfig(\n            gains=[25.0, 18.0, 15.0, 10.0, 4.0],\n            max_force=150.0,\n            dt=0.001\n        )\n\n        # Test hybrid controller creation with sub-configs\n        controller = create_controller(\n            'hybrid_adaptive_sta_smc',\n            config={\n                'classical_config': classical_config,\n                'adaptive_config': adaptive_config\n            },\n            gains=[18.0, 12.0, 10.0, 8.0]\n        )\n\n        assert controller is not None",
    "lines": 116,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d37c42cf"
  },
  {
    "id": "testing_validation_documentation_3_f5f38586",
    "file": "docs\\factory\\testing_validation_documentation.md",
    "index": 3,
    "code": "class TestFactoryPlantIntegration:\n    \"\"\"Test integration between factory and plant models.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup integration test environment.\"\"\"\n        from src.plant.configurations import ConfigurationFactory\n\n        self.plant_configs = {\n            'simplified': ConfigurationFactory.create_default_config(\"simplified\"),\n            'full': ConfigurationFactory.create_default_config(\"full\") if hasattr(ConfigurationFactory, 'create_default_config') else None\n        }\n\n        self.test_scenarios = {\n            'equilibrium': np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n            'small_disturbance': np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0]),\n            'large_angles': np.array([0.5, 0.8, 0.6, 0.2, 0.1, 0.15])\n        }\n\n    @pytest.mark.parametrize(\"plant_type\", ['simplified'])\n    @pytest.mark.parametrize(\"controller_type,gains\", [\n        ('classical_smc', [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]),\n        ('adaptive_smc', [25.0, 18.0, 15.0, 10.0, 4.0]),\n    ])\n    def test_controller_plant_compatibility(\n        self,\n        plant_type: str,\n        controller_type: str,\n        gains: List[float]\n    ):\n        \"\"\"Test controller-plant compatibility across configurations.\"\"\"\n        plant_config = self.plant_configs[plant_type]\n        if plant_config is None:\n            pytest.skip(f\"Plant config {plant_type} not available\")\n\n        # Create controller\n        controller = create_controller(controller_type, plant_config, gains)\n\n        # Test control computation for all scenarios\n        for scenario_name, state in self.test_scenarios.items():\n            control_output = controller.compute_control(state, (), {})\n\n            assert control_output is not None\n            assert hasattr(control_output, 'u')\n\n            # Validate control output\n            control_value = control_output.u\n            assert isinstance(control_value, (int, float, np.ndarray))\n            assert np.isfinite(control_value)\n\n    def test_closed_loop_simulation(self):\n        \"\"\"Test closed-loop simulation with factory-created controllers.\"\"\"\n        from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\n\n        plant_config = self.plant_configs['simplified']\n        dynamics = SimplifiedDIPDynamics(plant_config)\n\n        controller = create_controller(\n            'classical_smc',\n            plant_config,\n            [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        )\n\n        # Run closed-loop simulation\n        state = np.array([0.1, 0.2, 0.1, 0.0, 0.0, 0.0])\n        dt = 0.001\n        simulation_time = 0.1  # Short simulation for testing\n\n        for step in range(int(simulation_time / dt)):\n            # Compute control\n            control_output = controller.compute_control(state, (), {})\n            control = np.array([control_output.u])\n\n            # Simulate dynamics\n            result = dynamics.compute_dynamics(state, control)\n            assert result.success\n\n            # Integrate\n            state = state + dt * result.state_derivative\n\n            # Basic stability check\n            assert np.all(np.abs(state) < 10.0), f\"System unstable at step {step}\"\n\n    def test_multiple_controller_coordination(self):\n        \"\"\"Test multiple controllers working with same plant configuration.\"\"\"\n        plant_config = self.plant_configs['simplified']\n\n        controllers = {\n            'classical': create_controller('classical_smc', plant_config, [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]),\n            'adaptive': create_controller('adaptive_smc', plant_config, [25.0, 18.0, 15.0, 10.0, 4.0])\n        }\n\n        test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n\n        # Test that all controllers can compute control for same state\n        control_outputs = {}\n        for name, controller in controllers.items():\n            control_output = controller.compute_control(test_state, (), {})\n            control_outputs[name] = control_output.u\n\n            assert np.isfinite(control_output.u)\n            assert abs(control_output.u) <= 200.0  # Reasonable control bounds\n\n        # Controllers should produce different outputs (unless coincidentally same)\n        # This tests that they're actually different controllers\n        if len(set(control_outputs.values())) > 1:\n            assert True  # Different outputs expected\n        else:\n            # Same outputs acceptable for this simple state\n            pass\n\n    def test_plant_parameter_sensitivity(self):\n        \"\"\"Test controller behavior with plant parameter variations.\"\"\"\n        # Create multiple plant configurations (simulated variations)\n        base_config = self.plant_configs['simplified']\n\n        controller = create_controller(\n            'classical_smc',\n            base_config,\n            [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        )\n\n        # Test robustness to initial conditions\n        challenging_states = [\n            np.array([0.3, 0.4, 0.2, 0.1, 0.0, 0.0]),\n            np.array([0.1, 0.1, 0.1, 1.0, 0.8, 0.6]),\n            np.array([0.6, 0.8, 0.5, 0.3, 0.2, 0.1])\n        ]\n\n        for i, state in enumerate(challenging_states):\n            try:\n                control_output = controller.compute_control(state, (), {})\n                assert np.isfinite(control_output.u)\n                assert abs(control_output.u) <= 500.0  # Allow higher control for challenging states\n            except Exception as e:\n                pytest.fail(f\"Controller failed on challenging state {i}: {e}\")",
    "lines": 135,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5f38586"
  },
  {
    "id": "testing_validation_documentation_4_07751e0c",
    "file": "docs\\factory\\testing_validation_documentation.md",
    "index": 4,
    "code": "class TestPSOIntegration:\n    \"\"\"Test PSO optimization integration with factory system.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup PSO integration test environment.\"\"\"\n        from src.plant.configurations import ConfigurationFactory\n        self.plant_config = ConfigurationFactory.create_default_config(\"simplified\")\n\n        # Import PSO integration components\n        from src.controllers.factory.smc_factory import (\n            create_smc_for_pso, get_gain_bounds_for_pso, validate_smc_gains, SMCType\n        )\n\n        self.pso_functions = {\n            'create_smc_for_pso': create_smc_for_pso,\n            'get_gain_bounds_for_pso': get_gain_bounds_for_pso,\n            'validate_smc_gains': validate_smc_gains\n        }\n\n    @pytest.mark.parametrize(\"controller_type\", [\n        SMCType.CLASSICAL,\n        SMCType.ADAPTIVE,\n    ])\n    def test_pso_controller_creation(self, controller_type: SMCType):\n        \"\"\"Test PSO-compatible controller creation.\"\"\"\n        # Get appropriate gains for controller type\n        if controller_type == SMCType.CLASSICAL:\n            gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        elif controller_type == SMCType.ADAPTIVE:\n            gains = [25.0, 18.0, 15.0, 10.0, 4.0]\n        else:\n            pytest.skip(f\"Controller type {controller_type} not fully implemented\")\n\n        # Create PSO controller\n        pso_controller = self.pso_functions['create_smc_for_pso'](\n            controller_type, gains, self.plant_config\n        )\n\n        assert pso_controller is not None\n        assert hasattr(pso_controller, 'compute_control')\n        assert hasattr(pso_controller, 'n_gains')\n        assert hasattr(pso_controller, 'controller_type')\n\n        # Test PSO interface\n        test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n        control = pso_controller.compute_control(test_state)\n\n        assert isinstance(control, np.ndarray)\n        assert control.shape == (1,)\n        assert np.isfinite(control[0])\n\n    def test_pso_gain_bounds(self):\n        \"\"\"Test PSO gain bounds generation.\"\"\"\n        for controller_type in [SMCType.CLASSICAL, SMCType.ADAPTIVE]:\n            bounds = self.pso_functions['get_gain_bounds_for_pso'](controller_type)\n\n            assert isinstance(bounds, tuple)\n            assert len(bounds) == 2\n\n            lower_bounds, upper_bounds = bounds\n            assert len(lower_bounds) == len(upper_bounds)\n            assert all(l < u for l, u in zip(lower_bounds, upper_bounds))\n            assert all(l > 0 for l in lower_bounds)  # All gains must be positive\n\n    def test_pso_gain_validation(self):\n        \"\"\"Test PSO gain validation functionality.\"\"\"\n        # Test valid gains\n        valid_classical_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        assert self.pso_functions['validate_smc_gains'](SMCType.CLASSICAL, valid_classical_gains)\n\n        valid_adaptive_gains = [25.0, 18.0, 15.0, 10.0, 4.0]\n        assert self.pso_functions['validate_smc_gains'](SMCType.ADAPTIVE, valid_adaptive_gains)\n\n        # Test invalid gains\n        invalid_gains = [-1.0, 15.0, 12.0, 8.0, 35.0, 5.0]  # Negative gain\n        assert not self.pso_functions['validate_smc_gains'](SMCType.CLASSICAL, invalid_gains)\n\n        wrong_length_gains = [20.0, 15.0, 12.0]  # Too few gains\n        assert not self.pso_functions['validate_smc_gains'](SMCType.CLASSICAL, wrong_length_gains)\n\n    def test_pso_optimization_simulation(self):\n        \"\"\"Test simulated PSO optimization workflow.\"\"\"\n        # Create PSO-compatible fitness function\n        def simple_fitness_function(gains: List[float]) -> float:\n            try:\n                controller = self.pso_functions['create_smc_for_pso'](\n                    SMCType.CLASSICAL, gains, self.plant_config\n                )\n\n                # Simple fitness: minimize control effort for small disturbance\n                test_state = np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0])\n                control = controller.compute_control(test_state)\n\n                # Fitness function: minimize control effort\n                return abs(control[0])\n\n            except Exception:\n                return 1000.0  # High penalty for failures\n\n        # Test fitness function with valid gains\n        test_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        fitness = simple_fitness_function(test_gains)\n\n        assert isinstance(fitness, (int, float))\n        assert np.isfinite(fitness)\n        assert fitness >= 0\n\n        # Test fitness function with invalid gains\n        invalid_gains = []\n        invalid_fitness = simple_fitness_function(invalid_gains)\n        assert invalid_fitness == 1000.0  # Should return penalty value\n\n    def test_pso_thread_safety(self):\n        \"\"\"Test PSO operations are thread-safe.\"\"\"\n        import threading\n        import time\n\n        results = []\n        errors = []\n\n        def pso_worker(worker_id: int):\n            try:\n                for i in range(3):\n                    gains = [20.0 + worker_id, 15.0, 12.0, 8.0, 35.0, 5.0]\n                    controller = self.pso_functions['create_smc_for_pso'](\n                        SMCType.CLASSICAL, gains, self.plant_config\n                    )\n\n                    test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n                    control = controller.compute_control(test_state)\n                    assert isinstance(control, np.ndarray)\n                    time.sleep(0.001)\n\n                results.append(True)\n            except Exception as e:\n                errors.append(f\"Worker {worker_id}: {str(e)}\")\n                results.append(False)\n\n        # Create multiple worker threads\n        threads = []\n        for i in range(3):\n            thread = threading.Thread(target=pso_worker, args=(i,))\n            threads.append(thread)\n            thread.start()\n\n        # Wait for completion\n        for thread in threads:\n            thread.join(timeout=10.0)\n\n        # Verify results\n        assert not errors, f\"Thread safety errors: {errors}\"\n        assert all(results), \"Some PSO workers failed\"",
    "lines": 152,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07751e0c"
  },
  {
    "id": "testing_validation_documentation_5_b4966a6e",
    "file": "docs\\factory\\testing_validation_documentation.md",
    "index": 5,
    "code": "class TestRealTimePerformance:\n    \"\"\"Test real-time performance requirements.\"\"\"\n\n    def setup_method(self):\n        \"\"\"Setup performance testing environment.\"\"\"\n        from src.plant.configurations import ConfigurationFactory\n        self.plant_config = ConfigurationFactory.create_default_config(\"simplified\")\n\n        # Performance thresholds\n        self.max_control_computation_time = 0.001  # 1ms for 1kHz control\n        self.max_factory_creation_time = 0.01      # 10ms for factory creation\n        self.max_memory_per_controller = 1.0       # 1MB per controller\n\n    def test_control_computation_performance(self):\n        \"\"\"Test control computation meets real-time constraints.\"\"\"\n        import time\n\n        controller = create_controller(\n            'classical_smc',\n            self.plant_config,\n            [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n        )\n\n        test_states = [\n            np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0]),\n            np.array([0.3, 0.4, 0.2, 0.1, 0.0, 0.0]),\n            np.array([0.5, 0.6, 0.3, 0.2, 0.1, 0.0])\n        ]\n\n        computation_times = []\n\n        for state in test_states:\n            for _ in range(100):  # Multiple computations for statistical significance\n                start_time = time.time()\n                control_output = controller.compute_control(state, (), {})\n                computation_time = time.time() - start_time\n\n                computation_times.append(computation_time)\n                assert control_output is not None\n\n        # Performance validation\n        avg_time = np.mean(computation_times)\n        max_time = np.max(computation_times)\n\n        assert avg_time < self.max_control_computation_time, f\"Average computation time {avg_time:.6f}s exceeds limit\"\n        assert max_time < self.max_control_computation_time * 2, f\"Max computation time {max_time:.6f}s too high\"\n\n    def test_factory_creation_performance(self):\n        \"\"\"Test factory creation performance.\"\"\"\n        import time\n\n        creation_times = []\n\n        for i in range(20):\n            gains = [20.0 + i, 15.0, 12.0, 8.0, 35.0, 5.0]\n\n            start_time = time.time()\n            controller = create_controller('classical_smc', self.plant_config, gains)\n            creation_time = time.time() - start_time\n\n            creation_times.append(creation_time)\n            assert controller is not None\n\n        avg_creation_time = np.mean(creation_times)\n        max_creation_time = np.max(creation_times)\n\n        assert avg_creation_time < self.max_factory_creation_time, f\"Average creation time {avg_creation_time:.6f}s exceeds limit\"\n        assert max_creation_time < self.max_factory_creation_time * 2, f\"Max creation time {max_creation_time:.6f}s too high\"\n\n    def test_memory_efficiency(self):\n        \"\"\"Test memory efficiency during intensive usage.\"\"\"\n        import gc\n        import psutil\n        import os\n\n        process = psutil.Process(os.getpid())\n        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n        controllers = []\n\n        # Create many controllers\n        for i in range(50):\n            gains = [20.0 + i, 15.0, 12.0, 8.0, 35.0, 5.0]\n            controller = create_controller('classical_smc', self.plant_config, gains)\n            controllers.append(controller)\n\n            # Use controller to ensure it's not optimized away\n            test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n            _ = controller.compute_control(test_state, (), {})\n\n        peak_memory = process.memory_info().rss / 1024 / 1024  # MB\n        memory_per_controller = (peak_memory - initial_memory) / len(controllers)\n\n        # Clean up\n        del controllers\n        gc.collect()\n\n        final_memory = process.memory_info().rss / 1024 / 1024  # MB\n        memory_leak = final_memory - initial_memory\n\n        # Validate memory efficiency\n        assert memory_per_controller < self.max_memory_per_controller, f\"Memory per controller {memory_per_controller:.3f}MB exceeds limit\"\n        assert memory_leak < 10.0, f\"Memory leak detected: {memory_leak:.3f}MB\"\n\n    @pytest.mark.benchmark\n    def test_pso_evaluation_benchmark(self):\n        \"\"\"Benchmark PSO evaluation performance.\"\"\"\n        from src.controllers.factory.smc_factory import create_smc_for_pso, SMCType\n\n        def benchmark_fitness_function(gains: List[float]) -> float:\n            controller = create_smc_for_pso(SMCType.CLASSICAL, gains, self.plant_config)\n            test_state = np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])\n            control = controller.compute_control(test_state)\n            return abs(control[0])\n\n        # Benchmark parameters\n        n_evaluations = 100\n        test_gains = [20.0, 15.0, 12.0, 8.0, 35.0, 5.0]\n\n        import time\n        start_time = time.time()\n\n        for _ in range(n_evaluations):\n            fitness = benchmark_fitness_function(test_gains)\n            assert np.isfinite(fitness)\n\n        total_time = time.time() - start_time\n        avg_time_per_evaluation = total_time / n_evaluations\n\n        # PSO evaluation should be fast enough for optimization\n        assert avg_time_per_evaluation < 0.01, f\"PSO evaluation too slow: {avg_time_per_evaluation:.6f}s per evaluation\"",
    "lines": 131,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4966a6e"
  },
  {
    "id": "troubleshooting_guide_1_78735aeb",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 1,
    "code": "from src.controllers.factory import (\n    list_available_controllers,\n    get_default_gains,\n    create_controller\n)\nimport numpy as np\n\ndef factory_health_check():\n    \"\"\"Comprehensive factory system health check.\"\"\"\n\n    print(\"=== Factory System Health Check ===\\n\")\n\n    # 1. Check available controllers\n    try:\n        controllers = list_available_controllers()\n        print(f\"\u2713 Available controllers: {controllers}\")\n    except Exception as e:\n        print(f\"\u2717 Controller registry error: {e}\")\n        return False\n\n    # 2. Test default gains retrieval\n    for controller_type in controllers:\n        try:\n            gains = get_default_gains(controller_type)\n            print(f\"\u2713 {controller_type} default gains: {gains}\")\n        except Exception as e:\n            print(f\"\u2717 {controller_type} gains error: {e}\")\n\n    # 3. Test controller creation\n    test_passed = 0\n    total_tests = len(controllers)\n\n    for controller_type in controllers:\n        try:\n            gains = get_default_gains(controller_type)\n            controller = create_controller(controller_type, gains=gains)\n\n            # Test basic functionality\n            test_state = np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0])\n            result = controller.compute_control(test_state, (), {})\n\n            if hasattr(result, 'u'):\n                control_value = result.u\n            else:\n                control_value = result\n\n            if np.isfinite(control_value):\n                print(f\"\u2713 {controller_type} creation and test successful\")\n                test_passed += 1\n            else:\n                print(f\"\u2717 {controller_type} produced invalid control: {control_value}\")\n\n        except Exception as e:\n            print(f\"\u2717 {controller_type} creation failed: {e}\")\n\n    # 4. Summary\n    success_rate = (test_passed / total_tests) * 100\n    print(f\"\\n=== Summary ===\")\n    print(f\"Controllers tested: {total_tests}\")\n    print(f\"Successful: {test_passed}\")\n    print(f\"Success rate: {success_rate:.1f}%\")\n\n    if success_rate >= 95:\n        print(\"\u2713 Factory system is healthy\")\n        return True\n    elif success_rate >= 75:\n        print(\"\u26a0 Factory system has minor issues\")\n        return False\n    else:\n        print(\"\u2717 Factory system has major issues\")\n        return False\n\n# Run the health check\nfactory_health_check()",
    "lines": 74,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "78735aeb"
  },
  {
    "id": "troubleshooting_guide_2_3b8f56a5",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 2,
    "code": "from src.controllers.factory import list_available_controllers, CONTROLLER_ALIASES\n\ndef diagnose_controller_type_error(controller_type):\n    print(f\"Diagnosing controller type: '{controller_type}'\")\n\n    # Check available types\n    available = list_available_controllers()\n    print(f\"Available types: {available}\")\n\n    # Check aliases\n    normalized = controller_type.lower().replace('-', '_').replace(' ', '_')\n    if normalized in CONTROLLER_ALIASES:\n        canonical = CONTROLLER_ALIASES[normalized]\n        print(f\"Found alias: '{controller_type}' -> '{canonical}'\")\n    else:\n        print(f\"No alias found for '{controller_type}'\")\n\n    # Suggest closest match\n    from difflib import get_close_matches\n    matches = get_close_matches(normalized, available + list(CONTROLLER_ALIASES.keys()))\n    if matches:\n        print(f\"Did you mean: {matches[0]}?\")\n\n# Example usage\ndiagnose_controller_type_error(\"classic_smc\")  # Should find alias",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b8f56a5"
  },
  {
    "id": "troubleshooting_guide_3_673eba25",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 3,
    "code": "from src.controllers.factory import CONTROLLER_REGISTRY\n\ndef diagnose_gain_count_error(controller_type, provided_gains):\n    print(f\"Diagnosing gain count for {controller_type}\")\n\n    if controller_type in CONTROLLER_REGISTRY:\n        info = CONTROLLER_REGISTRY[controller_type]\n        required = info['gain_count']\n        provided = len(provided_gains)\n\n        print(f\"Required gains: {required}\")\n        print(f\"Provided gains: {provided}\")\n        print(f\"Gain names: {info.get('gain_names', 'Not specified')}\")\n\n        if provided < required:\n            print(f\"Missing {required - provided} gains\")\n            defaults = info['default_gains']\n            suggested = provided_gains + defaults[provided:required]\n            print(f\"Suggested gains: {suggested}\")\n        elif provided > required:\n            print(f\"Extra {provided - required} gains provided\")\n            suggested = provided_gains[:required]\n            print(f\"Suggested gains: {suggested}\")\n    else:\n        print(f\"Unknown controller type: {controller_type}\")\n\n# Example usage\ndiagnose_gain_count_error('classical_smc', [10, 5, 8])  # Too few gains",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "673eba25"
  },
  {
    "id": "troubleshooting_guide_4_318e0ff3",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_gain_values(gains):\n    print(f\"Diagnosing gain values: {gains}\")\n\n    for i, gain in enumerate(gains):\n        if not isinstance(gain, (int, float)):\n            print(f\"\u2717 Gain {i}: {gain} is not numeric (type: {type(gain)})\")\n        elif not np.isfinite(gain):\n            print(f\"\u2717 Gain {i}: {gain} is not finite\")\n        elif gain <= 0:\n            print(f\"\u2717 Gain {i}: {gain} is not positive\")\n        else:\n            print(f\"\u2713 Gain {i}: {gain} is valid\")\n\n# Example usage\ndiagnose_gain_values([10.0, -5.0, float('inf'), 'invalid', 8.0])",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "318e0ff3"
  },
  {
    "id": "troubleshooting_guide_5_8f8d41d1",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_config_validation(controller_type, config_params):\n    print(f\"Diagnosing configuration for {controller_type}\")\n\n    required_params = {\n        'classical_smc': ['gains', 'max_force', 'boundary_layer', 'dt'],\n        'adaptive_smc': ['gains', 'max_force', 'dt', 'leak_rate', 'adapt_rate_limit'],\n        'sta_smc': ['gains', 'max_force', 'dt', 'power_exponent'],\n        'hybrid_adaptive_sta_smc': ['gains', 'hybrid_mode', 'dt', 'max_force']\n    }\n\n    if controller_type in required_params:\n        required = required_params[controller_type]\n        provided = list(config_params.keys())\n\n        missing = set(required) - set(provided)\n        extra = set(provided) - set(required)\n\n        if missing:\n            print(f\"\u2717 Missing required parameters: {list(missing)}\")\n        if extra:\n            print(f\"\u2139 Extra parameters (optional): {list(extra)}\")\n\n        for param in required:\n            if param in config_params:\n                value = config_params[param]\n                print(f\"\u2713 {param}: {value}\")\n            else:\n                print(f\"\u2717 {param}: MISSING\")\n    else:\n        print(f\"No validation rules for {controller_type}\")\n\n# Example usage\nconfig = {'gains': [10, 5, 8, 3, 15, 2], 'max_force': 150.0}\ndiagnose_config_validation('classical_smc', config)",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f8d41d1"
  },
  {
    "id": "troubleshooting_guide_6_94186f53",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 6,
    "code": "from src.controllers.factory.deprecation import get_controller_migration_guide\n\ndef diagnose_deprecation_warnings(controller_type):\n    print(f\"Checking deprecation warnings for {controller_type}\")\n\n    migration_guide = get_controller_migration_guide(controller_type)\n    if migration_guide:\n        print(\"Migration guide:\")\n        for instruction in migration_guide:\n            print(f\"  - {instruction}\")\n    else:\n        print(\"No deprecation warnings for this controller type\")\n\n# Example usage\ndiagnose_deprecation_warnings('classical_smc')",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94186f53"
  },
  {
    "id": "troubleshooting_guide_7_a91e6bda",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 7,
    "code": "from src.controllers.factory import create_pso_controller_factory, SMCType\n\ndef diagnose_pso_factory_error(smc_type):\n    print(f\"Diagnosing PSO factory for {smc_type}\")\n\n    try:\n        factory_func = create_pso_controller_factory(smc_type)\n\n        # Check required attributes\n        required_attrs = ['n_gains', 'controller_type', 'max_force']\n        for attr in required_attrs:\n            if hasattr(factory_func, attr):\n                value = getattr(factory_func, attr)\n                print(f\"\u2713 {attr}: {value}\")\n            else:\n                print(f\"\u2717 Missing attribute: {attr}\")\n\n        # Test factory function\n        from src.controllers.factory import get_default_gains\n        test_gains = get_default_gains(smc_type.value)\n        controller = factory_func(test_gains)\n        print(f\"\u2713 Factory function test successful\")\n\n    except Exception as e:\n        print(f\"\u2717 PSO factory creation failed: {e}\")\n\n# Example usage\ndiagnose_pso_factory_error(SMCType.CLASSICAL)",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a91e6bda"
  },
  {
    "id": "troubleshooting_guide_8_598b0370",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 8,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, validate_smc_gains\n\ndef diagnose_pso_bounds_error(smc_type, particle_gains):\n    print(f\"Diagnosing PSO bounds for {smc_type}\")\n\n    # Get expected bounds\n    lower_bounds, upper_bounds = get_gain_bounds_for_pso(smc_type)\n    print(f\"Expected bounds:\")\n    print(f\"  Lower: {lower_bounds}\")\n    print(f\"  Upper: {upper_bounds}\")\n\n    print(f\"Particle gains: {particle_gains}\")\n\n    # Check each gain\n    for i, (gain, lower, upper) in enumerate(zip(particle_gains, lower_bounds, upper_bounds)):\n        if gain < lower:\n            print(f\"\u2717 Gain {i}: {gain} < {lower} (too low)\")\n        elif gain > upper:\n            print(f\"\u2717 Gain {i}: {gain} > {upper} (too high)\")\n        else:\n            print(f\"\u2713 Gain {i}: {gain} within bounds [{lower}, {upper}]\")\n\n    # Overall validation\n    is_valid = validate_smc_gains(smc_type, particle_gains)\n    print(f\"Overall validation: {'PASS' if is_valid else 'FAIL'}\")\n\n# Example usage\ndiagnose_pso_bounds_error(SMCType.CLASSICAL, [100, 50, 30, 25, 200, 15])  # Out of bounds",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "598b0370"
  },
  {
    "id": "troubleshooting_guide_9_d8010fde",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 9,
    "code": "import threading\nimport time\nfrom src.controllers.factory import create_controller\n\ndef diagnose_thread_safety_issues():\n    print(\"Diagnosing thread safety issues\")\n\n    def blocking_operation():\n        # Simulate long-running operation\n        controller = create_controller('classical_smc', gains=[10]*6)\n        time.sleep(5)  # Simulate work\n        return controller\n\n    # Test concurrent access\n    start_time = time.time()\n    threads = []\n\n    for i in range(5):\n        thread = threading.Thread(target=blocking_operation)\n        threads.append(thread)\n        thread.start()\n        time.sleep(0.1)  # Stagger starts\n\n    for thread in threads:\n        thread.join(timeout=15)\n        if thread.is_alive():\n            print(f\"\u2717 Thread still running after timeout\")\n        else:\n            print(f\"\u2713 Thread completed successfully\")\n\n    total_time = time.time() - start_time\n    print(f\"Total execution time: {total_time:.2f} seconds\")\n\n    if total_time > 30:\n        print(\"\u26a0 Possible deadlock or contention detected\")\n    else:\n        print(\"\u2713 Thread safety test completed normally\")\n\n# Run diagnostic\ndiagnose_thread_safety_issues()",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d8010fde"
  },
  {
    "id": "troubleshooting_guide_10_ee0c3381",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 10,
    "code": "import sys\nimport importlib.util\n\ndef diagnose_import_errors():\n    print(\"Diagnosing import errors\")\n\n    critical_modules = [\n        'src.controllers.factory',\n        'src.controllers.smc.algorithms.classical.controller',\n        'src.controllers.smc.algorithms.adaptive.controller',\n        'src.controllers.smc.algorithms.super_twisting.controller',\n        'src.controllers.smc.algorithms.hybrid.controller'\n    ]\n\n    for module_name in critical_modules:\n        try:\n            spec = importlib.util.find_spec(module_name)\n            if spec is None:\n                print(f\"\u2717 Module not found: {module_name}\")\n            else:\n                print(f\"\u2713 Module available: {module_name}\")\n                # Try importing\n                module = importlib.import_module(module_name)\n                print(f\"  \u2713 Import successful\")\n        except ImportError as e:\n            print(f\"\u2717 Import error for {module_name}: {e}\")\n        except Exception as e:\n            print(f\"\u2717 Unexpected error for {module_name}: {e}\")\n\n    # Check Python path\n    print(f\"\\nPython path:\")\n    for path in sys.path:\n        print(f\"  - {path}\")\n\n# Run diagnostic\ndiagnose_import_errors()",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee0c3381"
  },
  {
    "id": "troubleshooting_guide_11_8118dcb8",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_optional_dependencies():\n    print(\"Checking optional dependencies\")\n\n    optional_deps = {\n        'casadi': 'MPC controller',\n        'control': 'Advanced control features',\n        'cvxpy': 'Optimization-based controllers'\n    }\n\n    for package, feature in optional_deps.items():\n        try:\n            importlib.import_module(package)\n            print(f\"\u2713 {package} available - {feature} supported\")\n        except ImportError:\n            print(f\"\u2717 {package} missing - {feature} not available\")\n\n# Run diagnostic\ndiagnose_optional_dependencies()",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8118dcb8"
  },
  {
    "id": "troubleshooting_guide_12_2752cad0",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 12,
    "code": "import time\nimport statistics\nfrom src.controllers.factory import create_controller, get_default_gains\n\ndef profile_factory_performance():\n    print(\"Profiling factory performance\")\n\n    controller_types = ['classical_smc', 'adaptive_smc', 'sta_smc']\n    results = {}\n\n    for controller_type in controller_types:\n        print(f\"\\nTesting {controller_type}:\")\n\n        gains = get_default_gains(controller_type)\n        creation_times = []\n\n        # Warmup\n        for _ in range(5):\n            create_controller(controller_type, gains=gains)\n\n        # Actual measurements\n        for i in range(20):\n            start_time = time.perf_counter()\n            controller = create_controller(controller_type, gains=gains)\n            end_time = time.perf_counter()\n\n            creation_time = (end_time - start_time) * 1000  # Convert to ms\n            creation_times.append(creation_time)\n\n        # Statistics\n        mean_time = statistics.mean(creation_times)\n        std_time = statistics.stdev(creation_times)\n        min_time = min(creation_times)\n        max_time = max(creation_times)\n\n        results[controller_type] = {\n            'mean': mean_time,\n            'std': std_time,\n            'min': min_time,\n            'max': max_time\n        }\n\n        print(f\"  Mean: {mean_time:.2f} ms\")\n        print(f\"  Std:  {std_time:.2f} ms\")\n        print(f\"  Min:  {min_time:.2f} ms\")\n        print(f\"  Max:  {max_time:.2f} ms\")\n\n        # Performance assessment\n        if mean_time > 10:\n            print(f\"  \u26a0 Slow creation time (>{10}ms)\")\n        else:\n            print(f\"  \u2713 Acceptable creation time\")\n\n    return results\n\n# Run performance profiling\nprofile_results = profile_factory_performance()",
    "lines": 57,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2752cad0"
  },
  {
    "id": "troubleshooting_guide_13_221a8fb8",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 13,
    "code": "import psutil\nimport os\nfrom src.controllers.factory import create_controller\n\ndef diagnose_memory_usage():\n    print(\"Diagnosing memory usage\")\n\n    process = psutil.Process(os.getpid())\n    initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n    print(f\"Initial memory usage: {initial_memory:.2f} MB\")\n\n    controllers = []\n    memory_measurements = []\n\n    for i in range(100):\n        controller = create_controller('classical_smc', gains=[10]*6)\n        controllers.append(controller)\n\n        if i % 10 == 0:\n            current_memory = process.memory_info().rss / 1024 / 1024\n            memory_measurements.append(current_memory)\n            print(f\"After {i+1} controllers: {current_memory:.2f} MB\")\n\n    final_memory = process.memory_info().rss / 1024 / 1024\n    memory_increase = final_memory - initial_memory\n\n    print(f\"Final memory usage: {final_memory:.2f} MB\")\n    print(f\"Memory increase: {memory_increase:.2f} MB\")\n    print(f\"Memory per controller: {memory_increase/100:.3f} MB\")\n\n    # Check for memory leaks\n    if memory_increase > 50:  # More than 50MB for 100 controllers\n        print(\"\u26a0 Possible memory leak detected\")\n    else:\n        print(\"\u2713 Memory usage within acceptable limits\")\n\n# Run memory diagnostic\ndiagnose_memory_usage()",
    "lines": 39,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "221a8fb8"
  },
  {
    "id": "troubleshooting_guide_14_c2df9664",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef categorize_problem(error_message):\n    \"\"\"Categorize problem based on error message.\"\"\"\n\n    categories = {\n        'creation': ['Unknown controller type', 'requires.*gains', 'Invalid parameter'],\n        'configuration': ['Config validation', 'Missing.*parameter', 'Deprecated parameter'],\n        'pso': ['PSO factory', 'bounds validation', 'n_gains'],\n        'threading': ['lock timeout', 'deadlock', 'thread'],\n        'import': ['ModuleNotFoundError', 'ImportError', 'No module named'],\n        'performance': ['timeout', 'slow', 'memory']\n    }\n\n    error_lower = error_message.lower()\n\n    for category, keywords in categories.items():\n        for keyword in keywords:\n            if keyword.lower() in error_lower:\n                return category\n\n    return 'unknown'\n\n# Example usage\nerror = \"Controller 'classical_smc' requires 6 gains, got 5\"\ncategory = categorize_problem(error)\nprint(f\"Problem category: {category}\")",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2df9664"
  },
  {
    "id": "troubleshooting_guide_15_91fba9a5",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 15,
    "code": "def gather_diagnostic_info():\n    \"\"\"Gather comprehensive diagnostic information.\"\"\"\n\n    import sys\n    import platform\n    import numpy as np\n\n    info = {\n        'system': {\n            'platform': platform.platform(),\n            'python_version': sys.version,\n            'numpy_version': np.__version__\n        },\n        'factory': {},\n        'performance': {},\n        'errors': []\n    }\n\n    # Factory information\n    try:\n        from src.controllers.factory import list_available_controllers, CONTROLLER_REGISTRY\n        info['factory']['available_controllers'] = list_available_controllers()\n        info['factory']['registry_size'] = len(CONTROLLER_REGISTRY)\n    except Exception as e:\n        info['errors'].append(f\"Factory info error: {e}\")\n\n    # Performance information\n    try:\n        start_time = time.perf_counter()\n        create_controller('classical_smc', gains=[10]*6)\n        creation_time = (time.perf_counter() - start_time) * 1000\n        info['performance']['creation_time_ms'] = creation_time\n    except Exception as e:\n        info['errors'].append(f\"Performance test error: {e}\")\n\n    return info\n\n# Gather diagnostic information\ndiagnostic_info = gather_diagnostic_info()\nprint(\"Diagnostic information gathered:\")\nfor category, data in diagnostic_info.items():\n    print(f\"  {category}: {data}\")",
    "lines": 42,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91fba9a5"
  },
  {
    "id": "troubleshooting_guide_16_f1350a1d",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef apply_solutions(category, error_details):\n    \"\"\"Apply category-specific solutions.\"\"\"\n\n    solutions = {\n        'creation': [\n            \"Check controller type spelling and available types\",\n            \"Verify gain array length matches controller requirements\",\n            \"Ensure all gains are positive finite numbers\"\n        ],\n        'configuration': [\n            \"Add missing required parameters\",\n            \"Update deprecated parameter names\",\n            \"Validate parameter types and ranges\"\n        ],\n        'pso': [\n            \"Use SMCType enum instead of string\",\n            \"Check PSO bounds and particle validation\",\n            \"Verify factory function has required attributes\"\n        ],\n        'threading': [\n            \"Reduce lock hold time\",\n            \"Check for nested lock acquisition\",\n            \"Use timeouts for lock operations\"\n        ],\n        'import': [\n            \"Check PYTHONPATH includes src/ directory\",\n            \"Verify all required files exist\",\n            \"Install missing dependencies\"\n        ],\n        'performance': [\n            \"Profile controller creation times\",\n            \"Check for memory leaks\",\n            \"Optimize hot code paths\"\n        ]\n    }\n\n    category_solutions = solutions.get(category, [\"Unknown category - manual investigation required\"])\n\n    print(f\"Recommended solutions for {category} problems:\")\n    for i, solution in enumerate(category_solutions, 1):\n        print(f\"  {i}. {solution}\")\n\n    return category_solutions\n\n# Example usage\ncategory = 'creation'\nsolutions = apply_solutions(category, \"gain count mismatch\")",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1350a1d"
  },
  {
    "id": "troubleshooting_guide_17_c4c46ed6",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 17,
    "code": "def validate_before_creation(controller_type, gains, config=None):\n    \"\"\"Comprehensive pre-creation validation.\"\"\"\n\n    from src.controllers.factory import (\n        list_available_controllers,\n        CONTROLLER_REGISTRY,\n        validate_smc_gains,\n        SMCType\n    )\n\n    errors = []\n    warnings = []\n\n    # Controller type validation\n    if controller_type not in list_available_controllers():\n        errors.append(f\"Unknown controller type: {controller_type}\")\n\n    # Gains validation\n    if gains is not None:\n        if controller_type in CONTROLLER_REGISTRY:\n            expected_count = CONTROLLER_REGISTRY[controller_type]['gain_count']\n            if len(gains) != expected_count:\n                errors.append(f\"Expected {expected_count} gains, got {len(gains)}\")\n\n            if not all(isinstance(g, (int, float)) for g in gains):\n                errors.append(\"All gains must be numeric\")\n\n            if any(g <= 0 for g in gains):\n                errors.append(\"All gains must be positive\")\n\n    # Configuration validation\n    if config is not None:\n        # Add configuration-specific validation\n        pass\n\n    return {\n        'valid': len(errors) == 0,\n        'errors': errors,\n        'warnings': warnings\n    }\n\n# Example usage\nvalidation = validate_before_creation('classical_smc', [10, 5, 8, 3, 15, 2])\nif not validation['valid']:\n    print(\"Validation errors:\")\n    for error in validation['errors']:\n        print(f\"  - {error}\")",
    "lines": 47,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4c46ed6"
  },
  {
    "id": "troubleshooting_guide_18_af12844b",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef robust_controller_creation(controller_type, gains=None, config=None, max_retries=3):\n    \"\"\"Robust controller creation with automatic error recovery.\"\"\"\n\n    from src.controllers.factory import create_controller, get_default_gains\n\n    for attempt in range(max_retries):\n        try:\n            return create_controller(controller_type, config=config, gains=gains)\n\n        except ValueError as e:\n            error_str = str(e)\n\n            if \"gains\" in error_str and gains is None:\n                # Try with default gains\n                gains = get_default_gains(controller_type)\n                print(f\"Attempt {attempt + 1}: Using default gains\")\n                continue\n\n            elif \"requires\" in error_str and \"gains\" in error_str:\n                # Fix gain count\n                if gains and controller_type in CONTROLLER_REGISTRY:\n                    required = CONTROLLER_REGISTRY[controller_type]['gain_count']\n                    defaults = get_default_gains(controller_type)\n\n                    if len(gains) < required:\n                        gains = gains + defaults[len(gains):required]\n                    elif len(gains) > required:\n                        gains = gains[:required]\n\n                    print(f\"Attempt {attempt + 1}: Adjusted gain count\")\n                    continue\n\n            raise  # Re-raise if can't handle\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            print(f\"Attempt {attempt + 1} failed: {e}, retrying...\")\n\n    raise RuntimeError(f\"Failed to create controller after {max_retries} attempts\")\n\n# Example usage\ncontroller = robust_controller_creation('classical_smc', gains=[10, 5, 8])",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "af12844b"
  },
  {
    "id": "troubleshooting_guide_19_d89a9e03",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 19,
    "code": "import logging\nfrom functools import wraps\n\ndef monitor_factory_operations(func):\n    \"\"\"Decorator to monitor factory operations.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        logger = logging.getLogger('factory_monitor')\n\n        start_time = time.perf_counter()\n        try:\n            result = func(*args, **kwargs)\n            end_time = time.perf_counter()\n\n            duration = (end_time - start_time) * 1000  # ms\n            logger.info(f\"{func.__name__} completed in {duration:.2f}ms\")\n\n            return result\n\n        except Exception as e:\n            end_time = time.perf_counter()\n            duration = (end_time - start_time) * 1000\n\n            logger.error(f\"{func.__name__} failed after {duration:.2f}ms: {e}\")\n            raise\n\n    return wrapper\n\n# Apply monitoring to factory functions\nimport src.controllers.factory as factory\nfactory.create_controller = monitor_factory_operations(factory.create_controller)",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d89a9e03"
  },
  {
    "id": "troubleshooting_guide_20_65f3cf80",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ndef emergency_factory_reset():\n    \"\"\"Emergency factory system reset procedure.\"\"\"\n\n    print(\"Performing emergency factory reset...\")\n\n    # 1. Clear any cached data\n    try:\n        import importlib\n        import src.controllers.factory\n        importlib.reload(src.controllers.factory)\n        print(\"\u2713 Factory module reloaded\")\n    except Exception as e:\n        print(f\"\u2717 Module reload failed: {e}\")\n\n    # 2. Test basic functionality\n    try:\n        from src.controllers.factory import create_controller\n        test_controller = create_controller('classical_smc', gains=[10]*6)\n        print(\"\u2713 Basic factory test successful\")\n    except Exception as e:\n        print(f\"\u2717 Basic factory test failed: {e}\")\n\n    # 3. Verify thread safety\n    try:\n        import threading\n        def test_creation():\n            create_controller('classical_smc', gains=[10]*6)\n\n        threads = [threading.Thread(target=test_creation) for _ in range(3)]\n        for t in threads:\n            t.start()\n        for t in threads:\n            t.join(timeout=5)\n\n        print(\"\u2713 Thread safety test passed\")\n    except Exception as e:\n        print(f\"\u2717 Thread safety test failed: {e}\")\n\n    print(\"Emergency reset completed\")\n\n# Run emergency reset if needed\n# emergency_factory_reset()",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "65f3cf80"
  },
  {
    "id": "troubleshooting_guide_21_943f63b5",
    "file": "docs\\factory\\troubleshooting_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef fallback_controller_creation(controller_type, gains=None):\n    \"\"\"Fallback controller creation using minimal dependencies.\"\"\"\n\n    # Minimal controller implementation for emergency use\n    class FallbackController:\n        def __init__(self, gains):\n            self.gains = gains or [10, 8, 6, 4, 20, 2]\n\n        def compute_control(self, state, last_control, history):\n            # Simple proportional control as fallback\n            error = state[:2]  # Angular errors\n            control = -sum(g * e for g, e in zip(self.gains[:2], error))\n            return min(max(control, -150), 150)  # Saturate\n\n        def reset(self):\n            pass\n\n    print(f\"Using fallback controller for {controller_type}\")\n    return FallbackController(gains)\n\n# Use as last resort\n# fallback_controller = fallback_controller_creation('classical_smc')",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "943f63b5"
  },
  {
    "id": "interactive_visualizations_1_91ada297",
    "file": "docs\\guides\\interactive_visualizations.md",
    "index": 1,
    "code": "# In simulation script\nimport json\n\nresults = run_simulation(controller, duration=5.0)\nchart_data = {\n    \"labels\": results['time'].tolist(),\n    \"datasets\": [{\n        \"label\": \"Theta1\",\n        \"data\": results['theta1'].tolist()\n    }]\n}\n\nwith open('docs/_data/sim_results.json', 'w') as f:\n    json.dump(chart_data, f)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91ada297"
  },
  {
    "id": "QUICK_REFERENCE_1_f8dec368",
    "file": "docs\\guides\\QUICK_REFERENCE.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\nfrom src.core.simulation_runner import SimulationRunner\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller(\n    'classical_smc',\n    config=config.controllers.classical_smc\n)\n\n# Run simulation\nrunner = SimulationRunner(config)\nresult = runner.run(controller)\n\n# Access results\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")\nprint(f\"Settling Time: {result['metrics']['settling_time']:.2f}s\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8dec368"
  },
  {
    "id": "QUICK_REFERENCE_2_9bf1a886",
    "file": "docs\\guides\\QUICK_REFERENCE.md",
    "index": 2,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\nfrom src.controllers import create_smc_for_pso, get_gain_bounds_for_pso, SMCType\n\n# Get bounds\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Create PSO tuner\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=bounds,\n    n_particles=30,\n    iters=100\n)\n\n# Optimize\nbest_gains, best_cost = tuner.optimize()\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Final cost: {best_cost:.4f}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bf1a886"
  },
  {
    "id": "QUICK_REFERENCE_3_10321d41",
    "file": "docs\\guides\\QUICK_REFERENCE.md",
    "index": 3,
    "code": "import numpy as np\n\n# Define initial conditions\ninitial_conditions = [\n    [0, 0, 0.1, 0, 0.15, 0],\n    [0, 0, 0.2, 0, 0.25, 0],\n    [0, 0, 0.3, 0, 0.35, 0],\n]\n\nresults = []\nfor ic in initial_conditions:\n    config.simulation.initial_conditions = ic\n    result = runner.run(controller)\n    results.append(result['metrics']['ise'])\n\nprint(f\"Mean ISE: {np.mean(results):.4f}\")\nprint(f\"Std ISE: {np.std(results):.4f}\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10321d41"
  },
  {
    "id": "user-guide_1_8654210f",
    "file": "docs\\guides\\user-guide.md",
    "index": 1,
    "code": "# Example validation output\nConfigurationError: Invalid controller gains\n  - gains must be list of 6 floats for classical_smc\n  - max_force must be > 0\n  - boundary_layer must be in range (0, 1)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8654210f"
  },
  {
    "id": "user-guide_2_813e73db",
    "file": "docs\\guides\\user-guide.md",
    "index": 2,
    "code": "import json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load saved results\ndata = json.load(open('results_classical.json'))\n\n# Extract time series\nt = np.array(data['time'])\nx = np.array(data['state'])\nu = np.array(data['control'])\n\n# Access specific states\ncart_pos = x[:, 0]          # Cart position\ncart_vel = x[:, 1]          # Cart velocity\ntheta1 = x[:, 2]            # First pendulum angle\ntheta1_dot = x[:, 3]        # First pendulum velocity\ntheta2 = x[:, 4]            # Second pendulum angle\ntheta2_dot = x[:, 5]        # Second pendulum velocity\n\n# Access performance metrics\nprint(f\"ISE: {data['metrics']['ise']:.4f}\")\nprint(f\"Settling Time: {data['metrics']['settling_time']:.2f} s\")\nprint(f\"Peak Overshoot: {data['metrics']['overshoot']:.2f}%\")\n\n# Custom analysis: Compute energy\ndef compute_energy(x, m0=1.0, m1=0.1, m2=0.1, l1=0.5, l2=0.5, g=9.81):\n    \"\"\"Compute total system energy.\"\"\"\n    cart_pos, cart_vel, theta1, theta1_dot, theta2, theta2_dot = x.T\n\n    # Kinetic energy\n    KE_cart = 0.5 * m0 * cart_vel**2\n    KE_p1 = 0.5 * m1 * (cart_vel**2 + l1**2 * theta1_dot**2)\n    KE_p2 = 0.5 * m2 * (cart_vel**2 + l1**2 * theta1_dot**2 + l2**2 * theta2_dot**2)\n\n    # Potential energy (relative to equilibrium)\n    PE_p1 = m1 * g * l1 * (1 - np.cos(theta1))\n    PE_p2 = m2 * g * (l1 * (1 - np.cos(theta1)) + l2 * (1 - np.cos(theta2)))\n\n    return KE_cart + KE_p1 + KE_p2 + PE_p1 + PE_p2\n\nenergy = compute_energy(x)\n\n# Plot energy dissipation\nplt.figure()\nplt.plot(t, energy)\nplt.xlabel('Time (s)')\nplt.ylabel('Total Energy (J)')\nplt.title('Energy Dissipation via Control')\nplt.grid()\nplt.show()",
    "lines": 51,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "813e73db"
  },
  {
    "id": "user-guide_3_77ce076f",
    "file": "docs\\guides\\user-guide.md",
    "index": 3,
    "code": "# Load multiple results\nresults = {\n    'classical': json.load(open('results_classical.json')),\n    'sta': json.load(open('results_sta.json')),\n    'adaptive': json.load(open('results_adaptive.json')),\n    'hybrid': json.load(open('results_hybrid.json'))\n}\n\n# Create comparison table\nimport pandas as pd\n\ncomparison = []\nfor name, data in results.items():\n    comparison.append({\n        'Controller': name,\n        'ISE': data['metrics']['ise'],\n        'ITAE': data['metrics']['itae'],\n        'Settling Time (s)': data['metrics']['settling_time'],\n        'Overshoot (%)': data['metrics']['overshoot'],\n        'Control Effort': data['metrics']['control_effort']\n    })\n\ndf = pd.DataFrame(comparison)\ndf = df.set_index('Controller')\n\nprint(df.to_markdown())  # Pretty table output",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "77ce076f"
  },
  {
    "id": "user-guide_4_8e2d0bf0",
    "file": "docs\\guides\\user-guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Analyze HIL latency from results\nhil_data = json.load(open('hil_results.json'))\nlatencies = np.array(hil_data['latency_log'])\n\nprint(f\"Mean Latency: {np.mean(latencies)*1000:.2f} ms\")\nprint(f\"Max Latency: {np.max(latencies)*1000:.2f} ms\")\nprint(f\"99th Percentile: {np.percentile(latencies, 99)*1000:.2f} ms\")\n\n# Plot latency distribution\nplt.hist(latencies * 1000, bins=50, edgecolor='black')\nplt.xlabel('Latency (ms)')\nplt.ylabel('Frequency')\nplt.title('HIL Communication Latency Distribution')\nplt.grid(axis='y')\nplt.show()",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e2d0bf0"
  },
  {
    "id": "user-guide_5_1e805606",
    "file": "docs\\guides\\user-guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# batch_experiment.py\nimport subprocess\nimport json\n\ncontrollers = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\ninitial_conditions = [\n    [0, 0, 0.1, 0, 0.15, 0],\n    [0, 0, 0.2, 0, 0.25, 0],\n    [0, 0, 0.3, 0, 0.35, 0]\n]\n\nresults = {}\n\nfor ctrl in controllers:\n    results[ctrl] = []\n    for i, ic in enumerate(initial_conditions):\n        print(f\"Running {ctrl} with IC {i+1}/3...\")\n\n        # Run simulation\n        cmd = [\n            'python', 'simulate.py',\n            '--ctrl', ctrl,\n            '--override', f'simulation.initial_conditions={ic}',\n            '--save', f'results_{ctrl}_ic{i}.json'\n        ]\n        subprocess.run(cmd)\n\n        # Load results\n        data = json.load(open(f'results_{ctrl}_ic{i}.json'))\n        results[ctrl].append(data['metrics'])\n\n# Analyze batch results\nfor ctrl in controllers:\n    avg_ise = sum(r['ise'] for r in results[ctrl]) / len(results[ctrl])\n    print(f\"{ctrl:20s} Average ISE: {avg_ise:.4f}\")",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e805606"
  },
  {
    "id": "user-guide_6_8dd7437e",
    "file": "docs\\guides\\user-guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# parallel_batch.py\nfrom multiprocessing import Pool\nimport subprocess\n\ndef run_simulation(params):\n    ctrl, ic_idx, ic = params\n    cmd = [\n        'python', 'simulate.py',\n        '--ctrl', ctrl,\n        '--override', f'simulation.initial_conditions={ic}',\n        '--save', f'results_{ctrl}_ic{ic_idx}.json'\n    ]\n    subprocess.run(cmd)\n    return f'results_{ctrl}_ic{ic_idx}.json'\n\n# Define experiments\nexperiments = [\n    ('classical_smc', 0, [0, 0, 0.1, 0, 0.15, 0]),\n    ('classical_smc', 1, [0, 0, 0.2, 0, 0.25, 0]),\n    ('sta_smc', 0, [0, 0, 0.1, 0, 0.15, 0]),\n    # ... add all combinations\n]\n\n# Run in parallel (4 processes)\nwith Pool(4) as pool:\n    result_files = pool.map(run_simulation, experiments)\n\nprint(\"Batch complete!\")\nprint(f\"Generated {len(result_files)} result files\")",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dd7437e"
  },
  {
    "id": "user-guide_7_65b95c58",
    "file": "docs\\guides\\user-guide.md",
    "index": 7,
    "code": "import time\nstart = time.time()\n# Run simulation\nsubprocess.run(['python', 'simulate.py', '--ctrl', 'classical_smc'])\nelapsed = time.time() - start\nprint(f\"Simulation took {elapsed:.2f} seconds\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "65b95c58"
  },
  {
    "id": "legacy_code_documentation_index_1_81144cb3",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, x: np.ndarray, x_ref: np.ndarray, t: float) -> float:\n    \"\"\"\n    Compute sliding mode control input.\n\n    Implements the classical SMC law from {eq}`classical_smc_structure`:\n\n    .. math::\n        u(t) = u_{eq}(t) + u_{sw}(t)\n\n    where equivalent control ensures sliding surface convergence.\n\n    Parameters\n    ----------\n    x : np.ndarray, shape (6,)\n        Current state vector [x, \u03b8\u2081, \u03b8\u2082, \u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\n    x_ref : np.ndarray, shape (6,)\n        Reference trajectory\n    t : float\n        Current time\n\n    Returns\n    -------\n    u : float\n        Control force (N)\n\n    Notes\n    -----\n    The sliding surface is defined as in {eq}`linear_sliding_surface`.\n    Stability is guaranteed by Theorem 3 in {doc}`../theory/smc_theory_complete`.\n\n    Examples\n    --------\n    >>> controller = ClassicalSMC(c=[5, 8, 7], eta=2.0, epsilon=0.1)\n    >>> x = np.array([0.1, 0.05, 0.02, 0, 0, 0])\n    >>> x_ref = np.zeros(6)\n    >>> u = controller.compute_control(x, x_ref, 0.0)\n    >>> print(f\"Control input: {u:.3f} N\")\n    Control input: -1.234 N\n\n    See Also\n    --------\n    theory.smc_theory_complete : Mathematical foundations\n    sta_smc.SuperTwistingSMC : Alternative SMC implementation\n    \"\"\"",
    "lines": 47,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81144cb3"
  },
  {
    "id": "legacy_code_documentation_index_2_92935b70",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import Protocol, Optional, Tuple\nfrom pydantic import BaseModel, validator, Field\nimport numpy as np\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Protocol defining the controller interface.\"\"\"\n\n    def compute_control(\n        self,\n        x: np.ndarray,\n        x_ref: np.ndarray,\n        t: float\n    ) -> float:\n        \"\"\"Compute control input with guaranteed interface.\"\"\"\n        ...\n\nclass SMCParameters(BaseModel):\n    \"\"\"Validated SMC parameters with mathematical constraints.\"\"\"\n\n    c: List[float] = Field(..., description=\"Sliding surface gains\")\n    eta: float = Field(gt=0, description=\"Switching gain\")\n    epsilon: float = Field(gt=0, lt=1, description=\"Boundary layer\")\n\n    @validator('c')\n    def validate_sliding_gains(cls, v):\n        if not all(ci > 0 for ci in v):\n            raise ValueError(\"All sliding gains must be positive\")\n        return v\n\n    @validator('eta')\n    def validate_switching_gain(cls, v, values):\n        # Theoretical lower bound from uncertainty analysis\n        if v < 0.1:\n            raise ValueError(\"Switching gain too small for robustness\")\n        return v",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92935b70"
  },
  {
    "id": "legacy_code_documentation_index_3_3dfa4406",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_sliding_surface_stability():\n    \"\"\"Verify that sliding surface has stable dynamics.\"\"\"\n    controller = ClassicalSMC(c=[1, 2, 3], eta=1.0, epsilon=0.1)\n\n    # Test eigenvalues of sliding surface dynamics\n    A_slide = controller.get_sliding_dynamics_matrix()\n    eigenvals = np.linalg.eigvals(A_slide)\n\n    # Theorem 1: All eigenvalues should be negative\n    assert all(np.real(eig) < 0 for eig in eigenvals)\n\ndef test_lyapunov_decrease():\n    \"\"\"Verify Lyapunov function decreases along trajectories.\"\"\"\n    controller = AdaptiveSMC(c=[2, 3, 4], gamma=1.0)\n\n    # Test Lyapunov function derivative\n    x = np.random.rand(6)\n    V_dot = controller.compute_lyapunov_derivative(x)\n\n    # Theorem 5: Lyapunov derivative should be negative\n    assert V_dot <= 0",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3dfa4406"
  },
  {
    "id": "legacy_code_documentation_index_4_c93173d0",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 4,
    "code": "from src.controllers.factory import create_controller\nfrom src.core.dynamics import DoublePendulum\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create system and controller using theory-based parameters\nsystem = DoublePendulum()\ncontroller = create_controller(\n    'classical_smc',\n    c=[5.0, 8.0, 7.0],     # From {eq}`linear_sliding_surface`\n    eta=2.0,               # Satisfies {eq}`reaching_condition`\n    epsilon=0.05           # Boundary layer for chattering reduction\n)\n\n# Run simulation with automatic validation\nrunner = SimulationRunner(system, controller)\nresults = runner.simulate(duration=10.0, dt=0.01)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c93173d0"
  },
  {
    "id": "legacy_code_documentation_index_5_bbbe3aa6",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 5,
    "code": "from src.optimizer.pso_optimizer import PSOOptimizer\nfrom src.core.simulation_context import SimulationContext\n\n# Set up optimization problem from theory\noptimizer = PSOOptimizer(\n    n_particles=30,        # From {eq}`swarm_size_rule`\n    bounds=[[0.1, 20]] * 3 + [[0.1, 10], [0.001, 0.5]],  # Physical constraints\n    objectives=['tracking', 'control_effort', 'smoothness']  # {eq}`multiobjective_problem`\n)\n\n# Run optimization with theoretical convergence monitoring\ncontext = SimulationContext('classical_smc')\nbest_params = optimizer.optimize(context, max_generations=50)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bbbe3aa6"
  },
  {
    "id": "legacy_code_documentation_index_6_82313227",
    "file": "docs\\implementation\\legacy_code_documentation_index.md",
    "index": 6,
    "code": "\"\"\"\nComplete DIP-SMC-PSO workflow demonstrating theory-implementation integration.\n\"\"\"\nimport numpy as np\nfrom src.config import load_config\nfrom src.controllers.factory import create_controller\nfrom src.core.dynamics_full import DoublePendulumFull\nfrom src.optimizer.pso_optimizer import PSOOptimizer\nfrom src.utils.visualization import plot_results\n\ndef main():\n    # Load validated configuration\n    config = load_config('config.yaml')\n\n    # Create system using complete dynamics {eq}`mass_matrix_form`\n    system = DoublePendulumFull(\n        m0=config.physics.m0, m1=config.physics.m1, m2=config.physics.m2,\n        l1=config.physics.l1, l2=config.physics.l2, g=config.physics.g\n    )\n\n    # Optimize controller parameters using PSO theory\n    optimizer = PSOOptimizer(config.pso)\n    best_params = optimizer.optimize_controller(\n        system=system,\n        controller_type='hybrid_adaptive_sta_smc',\n        objectives={\n            'tracking': 1.0,      # {eq}`tracking_objective`\n            'effort': 0.1,        # {eq}`control_effort_objective`\n            'smoothness': 0.01    # {eq}`smoothness_objective`\n        }\n    )\n\n    # Create optimized controller\n    controller = create_controller('hybrid_adaptive_sta_smc', **best_params)\n\n    # Validate theoretical properties\n    assert controller.verify_stability_conditions()  # Theorem 5\n    assert controller.verify_convergence_properties()  # Theorem 4\n\n    # Run final simulation\n    runner = SimulationRunner(system, controller)\n    results = runner.simulate(duration=10.0)\n\n    # Visualize and analyze results\n    plot_results(results)\n    print(f\"Performance metrics: {results.compute_metrics()}\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 49,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82313227"
  },
  {
    "id": "legacy_index_1_c9fa547c",
    "file": "docs\\implementation\\legacy_index.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef sliding_surface(self, x: np.ndarray) -> float:\n    \"\"\"\n    Compute sliding surface value s(x) = Sx.\n\n    Based on equation {eq}`eq:sliding_surface_design` from SMC theory.\n\n    Parameters\n    ----------\n    x : np.ndarray, shape (6,)\n        State vector [q, q_dot]\n\n    Returns\n    -------\n    s : float\n        Sliding surface value\n\n    See Also\n    --------\n    theory.smc_theory_complete : Theoretical foundation\n    \"\"\"\n    return self.S @ x  # Implements eq:sliding_surface_design",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9fa547c"
  },
  {
    "id": "legacy_index_2_b242be3b",
    "file": "docs\\implementation\\legacy_index.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import Protocol, TypeVar, Generic\nfrom pydantic import BaseModel, validator\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Protocol defining controller interface.\"\"\"\n\n    def compute_control(\n        self,\n        x: np.ndarray,\n        x_ref: np.ndarray,\n        t: float\n    ) -> float:\n        \"\"\"Compute control input.\"\"\"\n        ...\n\nclass SimulationConfig(BaseModel):\n    \"\"\"Validated simulation configuration.\"\"\"\n\n    duration: float = Field(gt=0, description=\"Simulation duration\")\n    dt: float = Field(gt=0, lt=0.1, description=\"Time step\")\n\n    @validator('dt')\n    def dt_stability(cls, v, values):\n        if 'duration' in values and v > values['duration'] / 100:\n            raise ValueError(\"Time step too large for stability\")\n        return v",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b242be3b"
  },
  {
    "id": "legacy_index_3_c0d1d6c2",
    "file": "docs\\implementation\\legacy_index.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControlSystemError(Exception):\n    \"\"\"Base exception for control system errors.\"\"\"\n    pass\n\nclass NumericalInstabilityError(ControlSystemError):\n    \"\"\"Raised when numerical instability detected.\"\"\"\n\n    def __init__(self, t: float, x: np.ndarray):\n        super().__init__(\n            f\"Numerical instability at t={t:.3f}, \"\n            f\"max(|x|)={np.max(np.abs(x)):.2e}\"\n        )\n        self.time = t\n        self.state = x.copy()\n\nclass ConvergenceError(ControlSystemError):\n    \"\"\"Raised when optimization fails to converge.\"\"\"\n    pass",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c0d1d6c2"
  },
  {
    "id": "CITATION_SYSTEM_IMPLEMENTATION_1_0cfb70d0",
    "file": "docs\\implementation_reports\\CITATION_SYSTEM_IMPLEMENTATION.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nextensions = [\n    # ... existing extensions\n    \"sphinxcontrib.bibtex\",\n]\n\nbibtex_bibfiles = [\n    \"bib/smc.bib\",\n    \"bib/pso.bib\",\n    \"bib/dip.bib\",\n    \"bib/software.bib\",\n]\nbibtex_default_style = \"unsrt\"          # stable ordering\nbibtex_reference_style = \"label\"        # renders [1], [2], ...\nbibtex_tooltips = True\nbibtex_bibliography_header = \".. rubric:: References\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0cfb70d0"
  },
  {
    "id": "IMPLEMENTATION_REPORT_1_c37fd9cd",
    "file": "docs\\implementation_reports\\IMPLEMENTATION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef linkcode_resolve(domain, info):\n    # Handles: @property, @classmethod, @staticmethod, @functools.wraps\n    # Module-level fallbacks for C-extensions\n    # Windows\u2192POSIX path normalization\n    # Comprehensive error handling with development logging",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37fd9cd"
  },
  {
    "id": "IMPLEMENTATION_REPORT_2_a5e39b13",
    "file": "docs\\implementation_reports\\IMPLEMENTATION_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Automated checks for:\n# - Duplicate citation keys across .bib files\n# - Missing citations referenced in documentation\n# - Required field validation (DOI, URL, author, year)\n# - Format consistency enforcement",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5e39b13"
  },
  {
    "id": "advanced_algorithms_guide_1_c01ad1e5",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 1,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Define controller factory\ndef controller_factory(gains):\n    return create_controller(\n        'classical_smc',\n        config=config,\n        gains=gains\n    )\n\n# Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42,  # Reproducible results\n    instability_penalty_factor=100.0\n)\n\n# Run optimization\nresult = tuner.optimise(\n    iters_override=100,           # 100 PSO iterations\n    n_particles_override=30,      # 30 particles\n    options_override={\n        'w': 0.7,                 # Constant inertia\n        'c1': 2.05,               # Cognitive coefficient\n        'c2': 2.05                # Social coefficient\n    }\n)\n\n# Extract results\nbest_gains = result['best_pos']\nbest_cost = result['best_cost']\nconvergence_history = result['history']['cost']\n\nprint(f\"Optimal gains: {best_gains}\")\nprint(f\"Final cost: {best_cost:.6f}\")",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c01ad1e5"
  },
  {
    "id": "advanced_algorithms_guide_2_9984eef6",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 2,
    "code": "# Configure inertia weight schedule in config.yaml:\n# pso:\n#   w_schedule: [0.9, 0.4]  # Start at 0.9, end at 0.4\n#   iters: 100\n#   n_particles: 30\n\nresult = tuner.optimise()  # Uses w_schedule from config\n\n# Manual iteration loop for custom control\nfrom pyswarms.single import GlobalBestPSO\n\n# Create optimizer\noptimizer = GlobalBestPSO(\n    n_particles=30,\n    dimensions=6,\n    options={'c1': 2.05, 'c2': 2.05, 'w': 0.9},\n    bounds=(np.array([0.1]*6), np.array([50.0]*6))\n)\n\n# Inertia schedule\nw_values = np.linspace(0.9, 0.4, 100)\n\nfor iteration, w_val in enumerate(w_values):\n    optimizer.options['w'] = w_val\n    step_cost, step_pos = optimizer.step(tuner._fitness)\n    print(f\"Iteration {iteration}: w={w_val:.3f}, cost={step_cost:.6f}\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9984eef6"
  },
  {
    "id": "advanced_algorithms_guide_3_3b7a4520",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Configure physics uncertainty in config.yaml:\n# physics_uncertainty:\n#   n_evals: 5  # 5 perturbed models per evaluation\n#   cart_mass: 0.10          # \u00b110%\n#   pendulum1_mass: 0.15     # \u00b115%\n#   pendulum2_mass: 0.15     # \u00b115%\n#   pendulum1_length: 0.05   # \u00b15%\n#   pendulum2_length: 0.05   # \u00b15%\n\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42\n)\n\n# PSO will automatically evaluate robustness across perturbed models\nresult = tuner.optimise()\n\n# Each fitness evaluation runs 5 simulations (1 nominal + 4 perturbed)\n# Cost aggregation: 0.7 * mean + 0.3 * max",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b7a4520"
  },
  {
    "id": "advanced_algorithms_guide_4_a0bcaf3b",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Vectorized evaluation (FAST)\nt, x_b, u_b, sigma_b = simulate_system_batch(\n    controller_factory=controller_factory,\n    particles=particles,  # Shape: (N, D)\n    sim_time=T,\n    dt=dt,\n    u_max=u_max\n)\n# Returns: x_b.shape = (N, timesteps, 6)\n\n# Cost computation on entire batch\ncosts = self._compute_cost_from_traj(t, x_b, u_b, sigma_b)\n# Returns: costs.shape = (N,)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0bcaf3b"
  },
  {
    "id": "advanced_algorithms_guide_5_4d11959d",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 5,
    "code": "from src.controllers.smc.algorithms.super_twisting.twisting_algorithm import SuperTwistingAlgorithm\n\n# Initialize STA\nsta = SuperTwistingAlgorithm(\n    K1=5.0,                    # First twisting gain\n    K2=4.0,                    # Second twisting gain (K1 > K2)\n    alpha=0.5,                 # Standard power exponent\n    anti_windup_limit=10.0,    # Bound integral state\n    regularization=1e-10       # Numerical safety\n)\n\n# Compute control at each timestep\ndt = 0.01  # 10 ms timestep\n\nfor t in time_array:\n    # Compute sliding surface (from SMC controller)\n    s = sliding_surface(state)\n\n    # Super-twisting control law\n    control_dict = sta.compute_control(\n        surface_value=s,\n        dt=dt,\n        switching_function='tanh',\n        boundary_layer=0.01\n    )\n\n    # Extract components\n    u_total = control_dict['u_total']\n    u1 = control_dict['u1_continuous']\n    u2 = control_dict['u2_integral']\n\n    # Apply control\n    state = plant.step(u_total, dt)",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d11959d"
  },
  {
    "id": "advanced_algorithms_guide_6_f4734c90",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Run simulation and collect surface history\nsurface_history = []\n\nfor t in time_array:\n    s = sliding_surface(state)\n    surface_history.append(s)\n\n    control_dict = sta.compute_control(s, dt)\n    state = plant.step(control_dict['u_total'], dt)\n\n# Analyze STA performance\nanalysis = sta.analyze_performance(surface_history)\n\nprint(\"Stability Metrics:\")\nprint(f\"  Gains satisfy K1 > K2: {analysis['stability_metrics']['gains_satisfy_condition']}\")\nprint(f\"  Gain ratio K1/K2: {analysis['stability_metrics']['gain_ratio']:.2f}\")\n\nprint(\"\\nConvergence Metrics:\")\nprint(f\"  Convergence detected: {analysis['convergence_metrics']['convergence_detected']}\")\nprint(f\"  Convergence time steps: {analysis['convergence_metrics']['convergence_time_steps']}\")\nprint(f\"  Theoretical time: {analysis['convergence_metrics']['theoretical_convergence_time']:.3f} s\")\nprint(f\"  Final surface RMS: {analysis['convergence_metrics']['final_surface_rms']:.6f}\")\n\nprint(\"\\nControl Characteristics:\")\nprint(f\"  Integral state: {analysis['control_characteristics']['integral_state']:.3f}\")\nprint(f\"  Anti-windup active: {analysis['control_characteristics']['anti_windup_active']}\")",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4734c90"
  },
  {
    "id": "advanced_algorithms_guide_7_5ae5b78a",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 7,
    "code": "from src.utils.numerical_stability import safe_divide\n\n# Control law with division\nerror = state[0]\nvelocity = state[1]\n\n# UNSAFE: division by zero if velocity = 0\n# control = error / velocity\n\n# SAFE: protected division\ncontrol = safe_divide(\n    error,\n    velocity,\n    epsilon=1e-12,    # Minimum safe denominator\n    fallback=0.0,     # Value if velocity exactly zero\n    warn=True         # Issue warning for debugging\n)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ae5b78a"
  },
  {
    "id": "advanced_algorithms_guide_8_1ce092a8",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 8,
    "code": "from src.utils.numerical_stability import safe_sqrt\n\n# Norm computation from squared values\nsquared_sum = x**2 + y**2 + z**2\n\n# UNSAFE: if squared_sum slightly negative due to numerical error\n# norm = np.sqrt(squared_sum)\n\n# SAFE: clips to non-negative\nnorm = safe_sqrt(squared_sum, min_value=1e-15)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1ce092a8"
  },
  {
    "id": "advanced_algorithms_guide_9_aaccd256",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 9,
    "code": "from src.utils.numerical_stability import safe_exp\n\n# Exponential barrier function\ndef barrier_cost(distance, sharpness=10.0):\n    # UNSAFE: exp(1000) overflows\n    # return np.exp(-sharpness * distance)\n\n    # SAFE: clipped to prevent overflow\n    return safe_exp(-sharpness * distance, max_value=700.0)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aaccd256"
  },
  {
    "id": "advanced_algorithms_guide_10_55f3088b",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 10,
    "code": "from src.utils.numerical_stability import safe_normalize\n\n# Normalized gradient for optimization\ngradient = compute_gradient(params)\n\n# UNSAFE: if gradient is exactly zero\n# step_direction = gradient / np.linalg.norm(gradient)\n\n# SAFE: returns zero vector if gradient is zero\nstep_direction = safe_normalize(\n    gradient,\n    min_norm=1e-15,\n    fallback=np.zeros_like(gradient)\n)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55f3088b"
  },
  {
    "id": "advanced_algorithms_guide_11_6642edeb",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# SLOW: Sequential simulation (Python loop)\ndef sequential_evaluation(particles, controller_factory):\n    costs = []\n    for gains in particles:\n        controller = controller_factory(gains)\n        cost = simulate(controller, T, dt)\n        costs.append(cost)\n    return np.array(costs)\n\n# FAST: Vectorized simulation (NumPy operations)\ndef vectorized_evaluation(particles, controller_factory):\n    # Single call for entire batch\n    t, x_batch, u_batch, sigma_batch = simulate_system_batch(\n        controller_factory=controller_factory,\n        particles=particles,  # Shape: (N, D)\n        sim_time=T,\n        dt=dt\n    )\n\n    # Vectorized cost computation\n    costs = compute_costs_batch(t, x_batch, u_batch, sigma_batch)\n    return costs  # Shape: (N,)\n\n# Speedup: ~20-30x for N=30 particles",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6642edeb"
  },
  {
    "id": "advanced_algorithms_guide_12_767f993e",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 12,
    "code": "import numba\n\n@numba.jit(nopython=True, cache=True)\ndef fast_dynamics_update(state, control, dt, params):\n    \"\"\"Compiled dynamics integration.\"\"\"\n    # Pure NumPy operations, no Python objects\n    M = compute_mass_matrix(state, params)\n    C = compute_coriolis(state, params)\n    G = compute_gravity(state, params)\n\n    # Solve: M * qdd = tau - C * qd - G\n    qdd = np.linalg.solve(M, control - C @ state[3:] - G)\n\n    return state + dt * np.concatenate([state[3:], qdd])\n\n# First call: ~100 ms (compilation overhead)\n# Subsequent calls: ~0.1 ms (compiled code)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "767f993e"
  },
  {
    "id": "advanced_algorithms_guide_13_c325ba1f",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 13,
    "code": "from src.controllers.smc import ClassicalSMC\n\n# Create controller pool\npool_size = 100\ncontroller_pool = [\n    ClassicalSMC(gains=default_gains, max_force=100, boundary_layer=0.01)\n    for _ in range(pool_size)\n]\n\n# Reuse controllers (update gains instead of creating new instances)\nfor iteration in range(pso_iterations):\n    for i, gains in enumerate(swarm_positions):\n        controller = controller_pool[i % pool_size]\n        controller.set_gains(gains)  # Update in-place\n        cost = evaluate(controller)\n\n# Explicit cleanup after optimization\nfor controller in controller_pool:\n    controller.cleanup()",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c325ba1f"
  },
  {
    "id": "advanced_algorithms_guide_14_b42e9be3",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 14,
    "code": "# Set global seed in config\nconfig.global_seed = 42\n\n# PSO tuner uses this seed automatically\ntuner = PSOTuner(controller_factory, config, seed=42)\n\n# Results are now fully reproducible",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b42e9be3"
  },
  {
    "id": "advanced_algorithms_guide_15_d5864090",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 15,
    "code": "from src.utils.numerical_stability import safe_divide, safe_sqrt, safe_exp\n\n# Protect all potentially unstable operations\nresult = safe_divide(numerator, denominator, epsilon=1e-12)\nnorm = safe_sqrt(squared_sum, min_value=1e-15)\nexponential = safe_exp(large_value, max_value=700.0)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d5864090"
  },
  {
    "id": "advanced_algorithms_guide_16_14c1c976",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 16,
    "code": "import time\n\nstart = time.time()\nresult = tuner.optimise(iters_override=100, n_particles_override=30)\nelapsed = time.time() - start\n\nevaluations = 100 * 30  # iters * particles\nevals_per_second = evaluations / elapsed\n\nprint(f\"Optimization time: {elapsed:.2f} s\")\nprint(f\"Evaluations/second: {evals_per_second:.1f}\")\nprint(f\"Cost per evaluation: {1000 * elapsed / evaluations:.2f} ms\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "14c1c976"
  },
  {
    "id": "advanced_algorithms_guide_17_fd01ce5d",
    "file": "docs\\mathematical_foundations\\advanced_algorithms_guide.md",
    "index": 17,
    "code": "import matplotlib.pyplot as plt\n\nresult = tuner.optimise()\n\n# Plot convergence curve\nplt.figure(figsize=(10, 6))\nplt.semilogy(result['history']['cost'], linewidth=2)\nplt.xlabel('Iteration')\nplt.ylabel('Best Cost (log scale)')\nplt.title('PSO Convergence History')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Check for premature convergence\nif np.std(result['history']['cost'][-20:]) < 1e-6:\n    print(\"Warning: PSO may have converged prematurely\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd01ce5d"
  },
  {
    "id": "algorithm_fixes_summary_1_62f027de",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n   def compute_switching_function(self, surface_value: float) -> float:\n       \"\"\"Compute continuous switching function with adaptive boundary layer.\"\"\"\n\n       # Adaptive boundary layer thickness\n       surface_derivative = self._get_surface_derivative()\n       effective_thickness = self.base_thickness + self.slope * abs(surface_derivative)\n\n       # Continuous switching approximation\n       if self.switch_method == \"tanh\":\n           return np.tanh(surface_value / effective_thickness)\n       elif self.switch_method == \"linear\":\n           return np.clip(surface_value / effective_thickness, -1.0, 1.0)\n       else:  # \"sign\"\n           return np.sign(surface_value)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62f027de"
  },
  {
    "id": "algorithm_fixes_summary_2_aabf1731",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 2,
    "code": "if thickness <= 0:\n       raise ValueError(\"Boundary layer thickness must be positive\")\n   if slope < 0:\n       raise ValueError(\"Boundary layer slope must be non-negative\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aabf1731"
  },
  {
    "id": "algorithm_fixes_summary_3_aacbf635",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n   def compute(self, state: np.ndarray) -> float:\n       \"\"\"Compute linear sliding surface with numerical safeguards.\"\"\"\n\n       # Input validation\n       if len(state) < 6:\n           raise ValueError(\"State must have at least 6 elements\")\n\n       # Handle non-finite values\n       if not np.all(np.isfinite(state)):\n           state = np.where(np.isfinite(state), state, 0.0)\n\n       # Extract components\n       theta1, theta1_dot = state[2], state[3]\n       theta2, theta2_dot = state[4], state[5]\n\n       # Linear sliding surface: s = \u03bb\u2081\u03b8\u0307\u2081 + k\u2081\u03b8\u2081 + \u03bb\u2082\u03b8\u0307\u2082 + k\u2082\u03b8\u2082\n       s = (self.lam1 * theta1_dot + self.k1 * theta1 +\n            self.lam2 * theta2_dot + self.k2 * theta2)\n\n       # Numerical safety\n       return 0.0 if not np.isfinite(s) else float(s)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aacbf635"
  },
  {
    "id": "algorithm_fixes_summary_4_4cacfb58",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n   def _validate_gains(self) -> None:\n       \"\"\"Validate gains according to Hurwitz stability requirements.\"\"\"\n\n       # Check finite values\n       if not np.all(np.isfinite(self.gains)):\n           invalid_indices = np.where(~np.isfinite(self.gains))[0]\n           raise ValueError(f\"Gains contain NaN/infinite values at indices: {invalid_indices}\")\n\n       # Positivity requirement for stability\n       if len(self.gains) >= 4:\n           if any(g <= 0 for g in self.gains[:4]):\n               raise ValueError(\"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\")\n\n       # Minimum threshold for numerical stability\n       if any(g < 1e-12 for g in self.gains[:4]):\n           raise ValueError(\"Gains too small (min: 1e-12) - numerical instability risk\")",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4cacfb58"
  },
  {
    "id": "algorithm_fixes_summary_5_6372f53c",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n   @dataclass(frozen=True)\n   class ClassicalSMCConfig:\n       \"\"\"Type-safe configuration with mathematical validation.\"\"\"\n\n       def __post_init__(self):\n           \"\"\"Validate configuration after creation.\"\"\"\n           self._validate_gains()\n           self._validate_parameters()\n           self._validate_mathematical_constraints()\n\n       def _validate_gains(self) -> None:\n           \"\"\"Validate gain vector according to SMC theory.\"\"\"\n           if len(self.gains) != 6:\n               raise ValueError(\"Classical SMC requires exactly 6 gains\")\n\n           k1, k2, lam1, lam2, K, kd = self.gains\n\n           # Surface gains: positive for Hurwitz stability\n           if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n               raise ValueError(\"Surface gains must be positive for stability\")\n\n           # Switching gain: positive for reaching condition\n           if K <= 0:\n               raise ValueError(\"Switching gain K must be positive\")\n\n           # Derivative gain: non-negative for damping\n           if kd < 0:\n               raise ValueError(\"Derivative gain kd must be non-negative\")\n\n       def _validate_mathematical_constraints(self) -> None:\n           \"\"\"Validate constraints from mathematical theory.\"\"\"\n\n           # Damping ratio bounds for each subsystem\n           zeta1 = self.lam1 / (2 * np.sqrt(self.k1))\n           zeta2 = self.lam2 / (2 * np.sqrt(self.k2))\n\n           if zeta1 < 0.1 or zeta2 < 0.1:\n               raise ValueError(\"Damping ratios too low - may cause oscillations\")\n\n           if zeta1 > 10.0 or zeta2 > 10.0:\n               raise ValueError(\"Damping ratios too high - may cause sluggish response\")",
    "lines": 44,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6372f53c"
  },
  {
    "id": "algorithm_fixes_summary_6_0110e4d3",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 6,
    "code": "def get_effective_controllability_threshold(self) -> float:\n       \"\"\"Auto-compute threshold based on system parameters.\"\"\"\n       if self.controllability_threshold is not None:\n           return self.controllability_threshold\n\n       # Scale with surface gains for adaptive behavior\n       base_threshold = 0.05 * (self.k1 + self.k2)\n\n       # Bound within reasonable limits\n       return np.clip(base_threshold, 0.01, 1.0)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0110e4d3"
  },
  {
    "id": "algorithm_fixes_summary_7_24c949f9",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n   @given(\n       gains=st.lists(st.floats(min_value=0.1, max_value=50.0), min_size=4, max_size=4),\n       state=st.lists(st.floats(min_value=-10.0, max_value=10.0), min_size=6, max_size=6)\n   )\n   def test_sliding_surface_linearity_property(self, gains, state):\n       \"\"\"Test linearity property for all valid parameter combinations.\"\"\"\n       surface = LinearSlidingSurface(gains)\n\n       state1 = np.array(state)\n       state2 = np.random.uniform(-10, 10, 6)\n\n       s1 = surface.compute(state1)\n       s2 = surface.compute(state2)\n       s_combined = surface.compute(state1 + state2)\n\n       # Mathematical property: s(x1 + x2) = s(x1) + s(x2)\n       assert abs(s_combined - (s1 + s2)) < 1e-10",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24c949f9"
  },
  {
    "id": "algorithm_fixes_summary_8_d2be3ffd",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_boundary_layer_monotonicity_all_methods(self):\n       \"\"\"Test monotonicity for all switching methods.\"\"\"\n       methods = [\"tanh\", \"linear\", \"sign\"]\n\n       for method in methods:\n           boundary_layer = BoundaryLayer(thickness=0.1, switch_method=method)\n\n           s_values = np.linspace(-2, 2, 1000)\n           switch_values = [boundary_layer.compute_switching_function(s) for s in s_values]\n\n           # Must be monotonically increasing\n           for i in range(len(switch_values) - 1):\n               assert switch_values[i+1] >= switch_values[i]",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2be3ffd"
  },
  {
    "id": "algorithm_fixes_summary_9_ba6cb564",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n   class TestConfigurationValidationCoverage:\n       \"\"\"Comprehensive coverage of all validation rules.\"\"\"\n\n       @pytest.mark.parametrize(\"invalid_gain_index\", [0, 1, 2, 3])\n       def test_zero_surface_gains_rejection(self, invalid_gain_index):\n           \"\"\"Test rejection of zero surface gains.\"\"\"\n           gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n           gains[invalid_gain_index] = 0.0\n\n           with pytest.raises(ValueError, match=\"must be positive\"):\n               ClassicalSMCConfig(gains=gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n       @pytest.mark.parametrize(\"invalid_gain_index\", [0, 1, 2, 3])\n       def test_negative_surface_gains_rejection(self, invalid_gain_index):\n           \"\"\"Test rejection of negative surface gains.\"\"\"\n           gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n           gains[invalid_gain_index] = -1.0\n\n           with pytest.raises(ValueError, match=\"must be positive\"):\n               ClassicalSMCConfig(gains=gains, max_force=100, dt=0.01, boundary_layer=0.01)",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba6cb564"
  },
  {
    "id": "algorithm_fixes_summary_10_138ce80f",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_numerical_stability_extreme_values(self):\n       \"\"\"Test behavior with extreme but valid parameter values.\"\"\"\n\n       # Very small gains (but above minimum threshold)\n       small_gains = [1e-10, 1e-10, 1e-10, 1e-10, 1e-8, 0.0]\n       config_small = ClassicalSMCConfig(gains=small_gains, max_force=1e-6, dt=1e-6, boundary_layer=1e-8)\n\n       # Very large gains\n       large_gains = [1e6, 1e6, 1e6, 1e6, 1e8, 1e4]\n       config_large = ClassicalSMCConfig(gains=large_gains, max_force=1e8, dt=1e-3, boundary_layer=1.0)\n\n       # Both should create valid controllers\n       controller_small = ModularClassicalSMC(config=config_small)\n       controller_large = ModularClassicalSMC(config=config_large)\n\n       # Test with moderate state values\n       state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n       result_small = controller_small.compute_control(state, {}, {})\n       result_large = controller_large.compute_control(state, {}, {})\n\n       # Both should produce finite, bounded results\n       assert np.all(np.isfinite(result_small.get('control_output', [0])))\n       assert np.all(np.isfinite(result_large.get('control_output', [0])))",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "138ce80f"
  },
  {
    "id": "algorithm_fixes_summary_11_8905e694",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_computation_precision_consistency(self):\n       \"\"\"Test that repeated computations maintain precision.\"\"\"\n       config = ClassicalSMCConfig(\n           gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n           max_force=100.0, dt=0.01, boundary_layer=0.01\n       )\n       controller = ModularClassicalSMC(config=config)\n\n       state = np.array([0.123456789, 0.987654321, 0.456789123, 0.321654987, 0.789123456, 0.654987321])\n\n       # Compute control 1000 times\n       results = []\n       for _ in range(1000):\n           result = controller.compute_control(state, {}, {})\n           control = result.get('control_output', result.get('control', 0))\n           results.append(control)\n\n       results = np.array(results)\n\n       # Standard deviation should be zero (deterministic computation)\n       std_dev = np.std(results, axis=0) if results.ndim > 1 else np.std(results)\n       assert np.all(std_dev < 1e-15)  # Machine precision level",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8905e694"
  },
  {
    "id": "algorithm_fixes_summary_12_eae873c1",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass SlidingSurface(ABC):\n    \"\"\"Abstract interface for sliding surface calculations.\"\"\"\n\n    @abstractmethod\n    def compute(self, state: np.ndarray) -> float:\n        \"\"\"Compute sliding surface value.\"\"\"\n        pass\n\n    @abstractmethod\n    def compute_derivative(self, state: np.ndarray, state_dot: np.ndarray) -> float:\n        \"\"\"Compute sliding surface derivative.\"\"\"\n        pass\n\n    @abstractmethod\n    def _validate_gains(self) -> None:\n        \"\"\"Validate gains for mathematical correctness.\"\"\"\n        pass\n\nclass BoundaryLayer:\n    \"\"\"Interface for boundary layer implementations.\"\"\"\n\n    def compute_switching_function(self, surface_value: float) -> float:\n        \"\"\"Compute continuous switching function.\"\"\"\n        pass\n\n    def compute_switching_control(self, surface_value: float, gain: float, surface_derivative: float = 0.0) -> float:\n        \"\"\"Compute switching control with boundary layer.\"\"\"\n        pass",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eae873c1"
  },
  {
    "id": "algorithm_fixes_summary_13_f9c827a1",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_sliding_surface(self, state: np.ndarray, target: np.ndarray) -> float:\n    \"\"\"Compute sliding surface value for classical SMC.\n\n    Mathematical Foundation:\n    The sliding surface is defined as:\n    s = \u03bb\u2081e\u2081 + \u03bb\u2082e\u2082 + \u0117\u2081 + \u0117\u2082\n\n    where:\n    - e\u2081, e\u2082: position errors for pendulum 1 and 2\n    - \u0117\u2081, \u0117\u2082: velocity errors for pendulum 1 and 2\n    - \u03bb\u2081, \u03bb\u2082: sliding surface gains (must be positive)\n\n    Stability Analysis:\n    The sliding surface design ensures that once the system reaches\n    the surface (s=0), it will remain on the surface and converge\n    to the desired equilibrium point according to the dynamics:\n\n    \u00eb\u2081 + \u03bb\u2081\u0117\u2081 + c\u2081e\u2081 = 0\n    \u00eb\u2082 + \u03bb\u2082\u0117\u2082 + c\u2082e\u2082 = 0\n\n    Parameters\n    ----------\n    state : np.ndarray, shape (6,)\n        Current system state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n    target : np.ndarray, shape (6,)\n        Target state (typically upright equilibrium)\n\n    Returns\n    -------\n    float\n        Sliding surface value. System is on sliding surface when s = 0.\n\n    Raises\n    ------\n    ValueError\n        If state or target arrays have incorrect dimensions\n\n    References\n    ----------\n    .. [1] Utkin, V. \"Sliding Modes in Control and Optimization\", 1992\n    .. [2] Edwards, C. \"Sliding Mode Control: Theory and Applications\", 1998\n\n    Examples\n    --------\n    >>> controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n    >>> state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n    >>> target = np.zeros(6)\n    >>> surface_value = controller.compute_sliding_surface(state, target)\n    >>> print(f\"Sliding surface value: {surface_value:.4f}\")\n    \"\"\"",
    "lines": 53,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9c827a1"
  },
  {
    "id": "algorithm_fixes_summary_14_41423574",
    "file": "docs\\mathematical_foundations\\algorithm_fixes_summary.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass NewSMCAlgorithm:\n    \"\"\"Template for implementing new SMC algorithms.\"\"\"\n\n    def __init__(self, config: NewSMCConfig):\n        self.config = config\n        self._validate_mathematical_properties()\n\n    def _validate_mathematical_properties(self):\n        \"\"\"Validate algorithm-specific mathematical requirements.\"\"\"\n        # Implement stability checks\n        # Implement convergence analysis\n        # Implement robustness verification\n        pass\n\n    def compute_control(self, state: np.ndarray) -> Dict[str, Any]:\n        \"\"\"Implement control law with mathematical validation.\"\"\"\n        # Validate inputs\n        # Compute control components\n        # Validate outputs\n        # Return results with debug information\n        pass",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "41423574"
  },
  {
    "id": "boundary_layer_derivations_1_42ef8cde",
    "file": "docs\\mathematical_foundations\\boundary_layer_derivations.md",
    "index": 1,
    "code": "def test_boundary_layer_continuity():\n    eps = 0.01\n    sigma_test = np.linspace(-2*eps, 2*eps, 1000)\n    sat_values = [saturate(s, eps, method=\"linear\") for s in sigma_test]\n\n    # Check for discontinuities\n    diffs = np.diff(sat_values)\n    max_jump = np.max(np.abs(diffs))\n    assert max_jump < threshold  # Should be small for continuity",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42ef8cde"
  },
  {
    "id": "boundary_layer_derivations_2_8903d6fe",
    "file": "docs\\mathematical_foundations\\boundary_layer_derivations.md",
    "index": 2,
    "code": "def test_boundary_conditions():\n    eps = 0.01\n\n    # At boundary points\n    assert abs(saturate(eps, eps, \"linear\") - 1.0) < 1e-10\n    assert abs(saturate(-eps, eps, \"linear\") + 1.0) < 1e-10\n\n    # Inside boundary layer (linear region)\n    sigma_inside = 0.5 * eps\n    expected = sigma_inside / eps\n    assert abs(saturate(sigma_inside, eps, \"linear\") - expected) < 1e-10",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8903d6fe"
  },
  {
    "id": "boundary_layer_derivations_3_730cda44",
    "file": "docs\\mathematical_foundations\\boundary_layer_derivations.md",
    "index": 3,
    "code": "def test_lyapunov_decrease():\n    # Verify that V\u0307 < 0 outside the ultimate bound\n    sigma = np.linspace(-1, 1, 100)\n    for s in sigma:\n        if abs(s) > ultimate_bound:\n            V_dot = compute_lyapunov_derivative(s)\n            assert V_dot < 0",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "730cda44"
  },
  {
    "id": "boundary_layer_derivations_4_66ad1f2f",
    "file": "docs\\mathematical_foundations\\boundary_layer_derivations.md",
    "index": 4,
    "code": "def compute_boundary_layer(sigma, epsilon0, epsilon1):\n    \"\"\"Compute adaptive boundary layer thickness.\"\"\"\n    return epsilon0 + epsilon1 * abs(sigma)\n\ndef saturate_adaptive(sigma, epsilon0, epsilon1, method=\"tanh\"):\n    \"\"\"Saturation with adaptive boundary layer.\"\"\"\n    eps_adaptive = compute_boundary_layer(sigma, epsilon0, epsilon1)\n    return saturate(sigma, eps_adaptive, method)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "66ad1f2f"
  },
  {
    "id": "boundary_layer_derivations_5_5c908aa1",
    "file": "docs\\mathematical_foundations\\boundary_layer_derivations.md",
    "index": 5,
    "code": "def saturate_with_hysteresis(sigma, epsilon0, hysteresis_ratio, method=\"tanh\"):\n    \"\"\"Saturation function with hysteresis dead-band.\"\"\"\n    dead_band = hysteresis_ratio * epsilon0\n\n    if abs(sigma) < dead_band:\n        return 0.0\n    else:\n        return saturate(sigma, epsilon0, method)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c908aa1"
  },
  {
    "id": "config_validation_specification_1_7878345f",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 1,
    "code": "dt: float = field()  # Control timestep in seconds",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7878345f"
  },
  {
    "id": "config_validation_specification_2_dc037c82",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 2,
    "code": "if self.dt <= 0:\n    raise ValueError(\"dt must be positive\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dc037c82"
  },
  {
    "id": "config_validation_specification_3_81298eb4",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 3,
    "code": "gains: List[float] = field()  # [k1, k2, lam1, lam2, K, kd]",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81298eb4"
  },
  {
    "id": "config_validation_specification_4_5df4ce70",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_gains(self) -> None:\n    \"\"\"Validate gain vector according to SMC theory.\"\"\"\n    if len(self.gains) != 6:\n        raise ValueError(\"Classical SMC requires exactly 6 gains: [k1, k2, lam1, lam2, K, kd]\")\n\n    k1, k2, lam1, lam2, K, kd = self.gains\n\n    # Surface gains must be positive for Hurwitz stability\n    if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n        raise ValueError(\"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\")\n\n    # Switching gain must be positive for reaching condition\n    if K <= 0:\n        raise ValueError(\"Switching gain K must be positive\")\n\n    # Derivative gain must be non-negative\n    if kd < 0:\n        raise ValueError(\"Derivative gain kd must be non-negative\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5df4ce70"
  },
  {
    "id": "config_validation_specification_5_dfca070c",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 5,
    "code": "max_force: float = field()  # Control saturation limit in Newtons",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dfca070c"
  },
  {
    "id": "config_validation_specification_6_7e78e592",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 6,
    "code": "if self.max_force <= 0:\n    raise ValueError(\"max_force must be positive\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e78e592"
  },
  {
    "id": "config_validation_specification_7_1ead1e2c",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 7,
    "code": "boundary_layer: float = field()  # Chattering reduction thickness \u03b5 > 0",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1ead1e2c"
  },
  {
    "id": "config_validation_specification_8_e128d5ac",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 8,
    "code": "if self.boundary_layer <= 0:\n    raise ValueError(\"boundary_layer must be positive\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e128d5ac"
  },
  {
    "id": "config_validation_specification_9_ed82561b",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 9,
    "code": "boundary_layer_slope: float = field(default=0.0)  # Adaptive slope \u03b1 \u2265 0",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed82561b"
  },
  {
    "id": "config_validation_specification_10_6972fa7e",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 10,
    "code": "if self.boundary_layer_slope < 0:\n    raise ValueError(\"boundary_layer_slope must be non-negative\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6972fa7e"
  },
  {
    "id": "config_validation_specification_11_e860b365",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 11,
    "code": "switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = field(default=\"tanh\")",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e860b365"
  },
  {
    "id": "config_validation_specification_12_fbec10e9",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 12,
    "code": "regularization: float = field(default=1e-10)  # Matrix regularization \u03c1 > 0",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbec10e9"
  },
  {
    "id": "config_validation_specification_13_061b924d",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 13,
    "code": "if self.regularization <= 0:\n    raise ValueError(\"regularization must be positive\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "061b924d"
  },
  {
    "id": "config_validation_specification_14_f6876458",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 14,
    "code": "controllability_threshold: Optional[float] = field(default=None)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6876458"
  },
  {
    "id": "config_validation_specification_15_3d4e12ba",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 15,
    "code": "def get_effective_controllability_threshold(self) -> float:\n    if self.controllability_threshold is not None:\n        return self.controllability_threshold\n    # Default: scale with surface gains\n    return 0.05 * (self.k1 + self.k2)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d4e12ba"
  },
  {
    "id": "config_validation_specification_16_f34df372",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 16,
    "code": "if self.controllability_threshold is not None and self.controllability_threshold <= 0:\n    raise ValueError(\"controllability_threshold must be positive when specified\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f34df372"
  },
  {
    "id": "config_validation_specification_17_40a11a9f",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 17,
    "code": "dynamics_model: Optional[object] = field(default=None, compare=False)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40a11a9f"
  },
  {
    "id": "config_validation_specification_18_3c1fdf5c",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 18,
    "code": "class DynamicsModel:\n    def compute_dynamics(self, state: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Return (F, B) where \u1e8b = F(x) + B(x)u\"\"\"\n        pass\n\n    def get_mass_matrix(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Return mass matrix M(x)\"\"\"\n        pass",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c1fdf5c"
  },
  {
    "id": "config_validation_specification_19_bccba206",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\n@property\ndef k1(self) -> float:\n    \"\"\"Joint 1 position gain.\"\"\"\n    return self.gains[0]\n\n@property\ndef k2(self) -> float:\n    \"\"\"Joint 2 position gain.\"\"\"\n    return self.gains[1]\n\n@property\ndef lam1(self) -> float:\n    \"\"\"Joint 1 velocity gain (\u03bb\u2081).\"\"\"\n    return self.gains[2]\n\n@property\ndef lam2(self) -> float:\n    \"\"\"Joint 2 velocity gain (\u03bb\u2082).\"\"\"\n    return self.gains[3]\n\n@property\ndef K(self) -> float:\n    \"\"\"Switching gain.\"\"\"\n    return self.gains[4]\n\n@property\ndef kd(self) -> float:\n    \"\"\"Derivative gain.\"\"\"\n    return self.gains[5]",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bccba206"
  },
  {
    "id": "config_validation_specification_20_ece11568",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_surface_gains(self) -> List[float]:\n    \"\"\"Get sliding surface gains [k1, k2, \u03bb1, \u03bb2].\"\"\"\n    return self.gains[:4]\n\ndef get_effective_controllability_threshold(self) -> float:\n    \"\"\"Get effective controllability threshold.\"\"\"\n    # Implementation shown above\n\ndef to_dict(self) -> dict:\n    \"\"\"Convert configuration to dictionary.\"\"\"\n    # Returns serializable dictionary\n\n@classmethod\ndef from_dict(cls, config_dict: dict, dynamics_model=None) -> 'ClassicalSMCConfig':\n    \"\"\"Create configuration from dictionary.\"\"\"\n    # Factory method for deserialization\n\n@classmethod\ndef create_default(cls, gains: List[float], max_force: float = 100.0,\n                  dt: float = 0.01, boundary_layer: float = 0.01, **kwargs) -> 'ClassicalSMCConfig':\n    \"\"\"Create configuration with sensible defaults.\"\"\"\n    # Factory method with defaults",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ece11568"
  },
  {
    "id": "config_validation_specification_21_f5365fe9",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 21,
    "code": "if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n    raise ValueError(\"Surface gains must be positive for stability\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5365fe9"
  },
  {
    "id": "config_validation_specification_22_fc786c19",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 22,
    "code": "if K <= 0:\n    raise ValueError(\"Switching gain K must be positive\")\nif kd < 0:\n    raise ValueError(\"Derivative gain kd must be non-negative\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc786c19"
  },
  {
    "id": "config_validation_specification_23_de944f6b",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\nconfig = ClassicalSMCConfig(\n    gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],  # All positive\n    max_force=100.0,                          # Positive force limit\n    dt=0.01,                                  # 100 Hz control rate\n    boundary_layer=0.01,                      # 1% boundary layer\n    boundary_layer_slope=0.1,                 # Mild adaptation\n    switch_method=\"tanh\",                     # Smooth switching\n    regularization=1e-10,                     # Standard regularization\n    controllability_threshold=0.5,            # Moderate threshold\n    dynamics_model=None                       # No equivalent control\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "de944f6b"
  },
  {
    "id": "config_validation_specification_24_c23608fb",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\n# Zero gain - should raise ValueError\ninvalid_config = ClassicalSMCConfig(\n    gains=[0.0, 3.0, 4.0, 2.0, 10.0, 1.0],  # k1 = 0!\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.01\n)\n\n# Negative switching gain - should raise ValueError\ninvalid_config = ClassicalSMCConfig(\n    gains=[5.0, 3.0, 4.0, 2.0, -10.0, 1.0],  # K < 0!\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.01\n)\n\n# Zero boundary layer - should raise ValueError\ninvalid_config = ClassicalSMCConfig(\n    gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.0  # \u03b5 = 0!\n)",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c23608fb"
  },
  {
    "id": "config_validation_specification_25_6c2beb42",
    "file": "docs\\mathematical_foundations\\config_validation_specification.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\ndef migrate_legacy_config(legacy_dict: dict) -> ClassicalSMCConfig:\n    \"\"\"Migrate legacy configuration format.\"\"\"\n\n    # Map old parameter names to new names\n    if 'epsilon' in legacy_dict:\n        legacy_dict['boundary_layer'] = legacy_dict.pop('epsilon')\n\n    if 'control_gains' in legacy_dict:\n        legacy_dict['gains'] = legacy_dict.pop('control_gains')\n\n    # Add missing defaults\n    if 'boundary_layer_slope' not in legacy_dict:\n        legacy_dict['boundary_layer_slope'] = 0.0\n\n    if 'switch_method' not in legacy_dict:\n        legacy_dict['switch_method'] = \"tanh\"\n\n    return ClassicalSMCConfig.from_dict(legacy_dict)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c2beb42"
  },
  {
    "id": "controller_comparison_theory_1_2709eecd",
    "file": "docs\\mathematical_foundations\\controller_comparison_theory.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control_classical(state):\n    # 1. Sliding surface (6 multiplications, 3 additions)\n    sigma = lam1*th1 + lam2*th2 + k1*dth1 + k2*dth2  # ~10 ops\n\n    # 2. Equivalent control (matrix inversion: O(n\u00b3) = 27 ops)\n    M_inv = np.linalg.inv(M)  # ~50 ops (3\u00d73 matrix)\n    u_eq = (L @ M_inv @ B)^-1 * ...  # ~30 ops\n\n    # 3. Switching term (saturation function)\n    u_sw = -K * tanh(sigma/eps)  # ~5 ops\n\n    # Total: ~95 ops",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2709eecd"
  },
  {
    "id": "controller_comparison_theory_2_8035107d",
    "file": "docs\\mathematical_foundations\\controller_comparison_theory.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control_adaptive(state, K_prev):\n    # 1. Sliding surface\n    sigma = ...  # ~10 ops\n\n    # 2. Equivalent control\n    u_eq = ...  # ~80 ops (same as classical)\n\n    # 3. Adaptive gain update\n    if abs(sigma) > delta:\n        K_dot = gamma * abs(sigma)  # ~3 ops\n    else:\n        K_dot = -alpha * K_prev  # ~2 ops\n    K_new = K_prev + K_dot * dt  # ~2 ops\n\n    # 4. Switching term\n    u_sw = -K_new * tanh(sigma/eps)  # ~5 ops\n\n    # Total: ~102 ops",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8035107d"
  },
  {
    "id": "controller_comparison_theory_3_b5bed29f",
    "file": "docs\\mathematical_foundations\\controller_comparison_theory.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control_sta(state, u_int_prev):\n    # 1. Sliding surface\n    sigma = ...  # ~10 ops\n\n    # 2. Equivalent control\n    u_eq = ...  # ~80 ops\n\n    # 3. Continuous term (square root!)\n    u_c = -K1 * sqrt(abs(sigma)) * sign(sigma)  # ~10 ops (sqrt expensive)\n\n    # 4. Integral term update\n    u_int = u_int_prev - K2 * sign(sigma) * dt  # ~3 ops\n\n    # 5. Damping term\n    u_d = -k_d * sigma  # ~2 ops\n\n    # Total: ~105 ops",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5bed29f"
  },
  {
    "id": "controller_comparison_theory_4_e9bb8d1b",
    "file": "docs\\mathematical_foundations\\controller_comparison_theory.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control_hybrid(state, k1_prev, k2_prev, u_int_prev):\n    # 1. Sliding surface (with cart recentering)\n    sigma = c1*(dth1+lam1*th1) + c2*(dth2+lam2*th2) + kc*(dx+lamc*x)  # ~18 ops\n\n    # 2. Equivalent control\n    u_eq = ...  # ~80 ops\n\n    # 3. Adaptive gain updates (both k1 and k2)\n    taper = abs(sigma) / (abs(sigma) + eps_taper)  # ~5 ops\n    k1_dot = gamma1 * abs(sigma) * taper  # ~3 ops\n    k2_dot = gamma2 * abs(sigma) * taper  # ~3 ops\n    k1_new = clip(k1_prev + k1_dot*dt, 0, k1_max)  # ~4 ops\n    k2_new = clip(k2_prev + k2_dot*dt, 0, k2_max)  # ~4 ops\n\n    # 4. Super-twisting control\n    u_c = -k1_new * sqrt(abs(sigma)) * sat(sigma)  # ~10 ops\n    u_int = clip(u_int_prev - k2_new*sat(sigma)*dt, -umax, umax)  # ~5 ops\n    u_d = -k_d * sigma  # ~2 ops\n\n    # Total: ~134 ops",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e9bb8d1b"
  },
  {
    "id": "dynamics_derivations_1_6202ae2c",
    "file": "docs\\mathematical_foundations\\dynamics_derivations.md",
    "index": 1,
    "code": "M_upright = [\n    [0.183,  0.083,  0.150],\n    [0.083,  0.083,  0.050],\n    [0.150,  0.050,  1.200]\n]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6202ae2c"
  },
  {
    "id": "dynamics_derivations_2_c8876eda",
    "file": "docs\\mathematical_foundations\\dynamics_derivations.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_invert_mass_matrix(M, regularization=1e-10):\n    \"\"\"Invert mass matrix with regularization.\"\"\"\n    # Add small diagonal term for numerical stability\n    M_reg = M + regularization * np.eye(M.shape[0])\n\n    # Condition number check\n    cond = np.linalg.cond(M_reg)\n    if cond > 1e6:\n        raise ValueError(f\"Ill-conditioned mass matrix: \u03ba = {cond:.2e}\")\n\n    # Solve using Cholesky (M is symmetric positive definite)\n    try:\n        M_inv = np.linalg.inv(M_reg)\n    except np.linalg.LinAlgError:\n        # Fallback: pseudo-inverse\n        M_inv = np.linalg.pinv(M_reg)\n\n    return M_inv",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8876eda"
  },
  {
    "id": "dynamics_derivations_3_72cc6ebd",
    "file": "docs\\mathematical_foundations\\dynamics_derivations.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Bad: Recompute sin/cos multiple times\nM11 = ... + m2 * L1 * L2 * np.cos(theta2 - theta1)\nC12 = -m2 * L1 * L2 * np.sin(theta2 - theta1) * dtheta2\n\n# Good: Cache trigonometric values\ns1, c1 = np.sin(theta1), np.cos(theta1)\ns2, c2 = np.sin(theta2), np.cos(theta2)\ns12, c12 = np.sin(theta2 - theta1), np.cos(theta2 - theta1)\n\nM11 = ... + m2 * L1 * L2 * c12\nC12 = -m2 * L1 * L2 * s12 * dtheta2",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72cc6ebd"
  },
  {
    "id": "dynamics_derivations_4_f21b1696",
    "file": "docs\\mathematical_foundations\\dynamics_derivations.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nimport numba\n\n@numba.jit(nopython=True)\ndef compute_mass_matrix(theta1, theta2, params):\n    \"\"\"JIT-compiled mass matrix computation.\"\"\"\n    m1, m2, L1, L2, I1, I2, M = params\n    s12 = np.sin(theta2 - theta1)\n    c12 = np.cos(theta2 - theta1)\n\n    # ... matrix computation ...\n\n    return M",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f21b1696"
  },
  {
    "id": "dynamics_derivations_5_3464fd07",
    "file": "docs\\mathematical_foundations\\dynamics_derivations.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nphysics_params = {\n    'M': 1.0,      # Cart mass (kg)\n    'm1': 0.1,     # Link 1 mass (kg)\n    'm2': 0.1,     # Link 2 mass (kg)\n    'L1': 0.5,     # Link 1 length (m)\n    'L2': 0.5,     # Link 2 length (m)\n    'I1': 0.0083,  # Link 1 inertia (kg\u00b7m\u00b2)\n    'I2': 0.0083,  # Link 2 inertia (kg\u00b7m\u00b2)\n    'g': 9.81,     # Gravity (m/s\u00b2)\n    'b1': 0.01,    # Link 1 friction (N\u00b7m\u00b7s)\n    'b2': 0.01,    # Link 2 friction (N\u00b7m\u00b7s)\n    'bc': 0.1,     # Cart friction (N\u00b7s/m)\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3464fd07"
  },
  {
    "id": "numerical_integration_theory_1_c14dd6f5",
    "file": "docs\\mathematical_foundations\\numerical_integration_theory.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef euler_step(x, u, dynamics, dt):\n    \"\"\"Single Euler integration step.\n\n    Args:\n        x: Current state (6,)\n        u: Control input (scalar)\n        dynamics: Dynamics model\n        dt: Timestep\n\n    Returns:\n        x_next: State at t + dt\n    \"\"\"\n    dxdt = dynamics.compute_derivative(x, u)\n    x_next = x + dt * dxdt\n    return x_next",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c14dd6f5"
  },
  {
    "id": "numerical_integration_theory_2_167cb12f",
    "file": "docs\\mathematical_foundations\\numerical_integration_theory.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef rk4_step(x, u, dynamics, dt):\n    \"\"\"Single RK4 integration step.\n\n    Args:\n        x: Current state (6,)\n        u: Control input (scalar or function of time/state)\n        dynamics: Dynamics model\n        dt: Timestep\n\n    Returns:\n        x_next: State at t + dt\n    \"\"\"\n    # Evaluate control at different stages if time-varying\n    if callable(u):\n        u1 = u(x)\n        u2 = u(x + 0.5 * dt * k1)\n        u3 = u(x + 0.5 * dt * k2)\n        u4 = u(x + dt * k3)\n    else:\n        u1 = u2 = u3 = u4 = u  # Constant control\n\n    # Four slope evaluations\n    k1 = dynamics.compute_derivative(x, u1)\n    k2 = dynamics.compute_derivative(x + 0.5 * dt * k1, u2)\n    k3 = dynamics.compute_derivative(x + 0.5 * dt * k2, u3)\n    k4 = dynamics.compute_derivative(x + dt * k3, u4)\n\n    # Weighted combination\n    x_next = x + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n\n    return x_next",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "167cb12f"
  },
  {
    "id": "numerical_integration_theory_3_ba3bee79",
    "file": "docs\\mathematical_foundations\\numerical_integration_theory.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef rk45_adaptive_step(x, u, dynamics, t, dt, tol=1e-6):\n    \"\"\"Adaptive RK45 step with error control.\n\n    Args:\n        x: Current state (6,)\n        u: Control input\n        dynamics: Dynamics model\n        t: Current time\n        dt: Suggested timestep\n        tol: Error tolerance\n\n    Returns:\n        x_next: Accepted state\n        dt_next: Suggested next timestep\n        error: Estimated error\n    \"\"\"\n    # Dormand-Prince coefficients\n    a21 = 1/5\n    a31, a32 = 3/40, 9/40\n    a41, a42, a43 = 44/45, -56/15, 32/9\n    a51, a52, a53, a54 = 19372/6561, -25360/2187, 64448/6561, -212/729\n    a61, a62, a63, a64, a65 = 9017/3168, -355/33, 46732/5247, 49/176, -5103/18656\n\n    # 4th order solution weights\n    b1, b3, b4, b5, b6 = 35/384, 500/1113, 125/192, -2187/6784, 11/84\n\n    # 5th order solution weights (for error estimate)\n    b1_star = 5179/57600\n    b3_star = 7571/16695\n    b4_star = 393/640\n    b5_star = -92097/339200\n    b6_star = 187/2100\n    b7_star = 1/40\n\n    # Six slope evaluations\n    k1 = dynamics.compute_derivative(x, u)\n    k2 = dynamics.compute_derivative(x + dt*a21*k1, u)\n    k3 = dynamics.compute_derivative(x + dt*(a31*k1 + a32*k2), u)\n    k4 = dynamics.compute_derivative(x + dt*(a41*k1 + a42*k2 + a43*k3), u)\n    k5 = dynamics.compute_derivative(x + dt*(a51*k1 + a52*k2 + a53*k3 + a54*k4), u)\n    k6 = dynamics.compute_derivative(x + dt*(a61*k1 + a62*k2 + a63*k3 + a64*k4 + a65*k5), u)\n\n    # 4th order solution\n    x4 = x + dt * (b1*k1 + b3*k3 + b4*k4 + b5*k5 + b6*k6)\n\n    # 5th order solution\n    k7 = dynamics.compute_derivative(x4, u)  # FSAL property\n    x5 = x + dt * (b1_star*k1 + b3_star*k3 + b4_star*k4 + b5_star*k5 + b6_star*k6 + b7_star*k7)\n\n    # Error estimate\n    error = np.linalg.norm(x5 - x4) / (tol + tol * np.linalg.norm(x))\n\n    # Timestep adaptation\n    if error < 1.0:\n        # Accept step\n        dt_next = dt * min(5.0, max(0.2, 0.9 * (1.0 / error)**(1/5)))\n        return x4, dt_next, error\n    else:\n        # Reject step, retry with smaller dt\n        dt_new = dt * max(0.2, 0.9 * (1.0 / error)**(1/5))\n        return rk45_adaptive_step(x, u, dynamics, t, dt_new, tol)",
    "lines": 64,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba3bee79"
  },
  {
    "id": "numerical_integration_theory_4_3ec70f47",
    "file": "docs\\mathematical_foundations\\numerical_integration_theory.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO optimization (speed critical)\nsimulation_config_pso = {\n    'method': 'euler',\n    'dt': 0.005,\n    'duration': 5.0,\n}\n\n# Development/debugging\nsimulation_config_dev = {\n    'method': 'rk4',\n    'dt': 0.01,\n    'duration': 10.0,\n}\n\n# Production deployment\nsimulation_config_prod = {\n    'method': 'rk45',\n    'rtol': 1e-6,\n    'atol': 1e-9,\n    'duration': 10.0,\n    'max_step': 0.1,  # Prevent huge steps\n}",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ec70f47"
  },
  {
    "id": "optimization_landscape_analysis_1_9adb2438",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 1,
    "code": "bounds_adaptive = [\n    (0.1, 50.0),   # k1 - surface gain\n    (0.1, 50.0),   # k2 - surface gain\n    (0.1, 50.0),   # \u03bb1 - velocity gain\n    (0.1, 50.0),   # \u03bb2 - velocity gain\n    (0.01, 10.0),  # \u03b3 - adaptation rate (smaller range!)\n]",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9adb2438"
  },
  {
    "id": "optimization_landscape_analysis_2_7b9d2980",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 2,
    "code": "bounds_sta = [\n    (1.0, 100.0),  # K1 - first-order switching gain (larger)\n    (1.0, 50.0),   # K2 - second-order gain (smaller, K2 < K1)\n    (0.1, 50.0),   # k1 - surface gain\n    (0.1, 50.0),   # k2 - surface gain\n    (0.1, 50.0),   # \u03bb1 - velocity gain\n    (0.1, 50.0),   # \u03bb2 - velocity gain\n]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7b9d2980"
  },
  {
    "id": "optimization_landscape_analysis_3_7e53b394",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 3,
    "code": "if gains[0] <= gains[1]:  # K1 <= K2\n    penalty = 1e6 * (gains[1] - gains[0] + 1)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e53b394"
  },
  {
    "id": "optimization_landscape_analysis_4_c5a8e714",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_ruggedness(fitness_function, gains, epsilon=0.1, n_samples=100):\n    \"\"\"Estimate landscape ruggedness via random perturbations.\"\"\"\n    f_center = fitness_function(gains)\n    variations = []\n\n    for _ in range(n_samples):\n        perturbation = np.random.randn(len(gains)) * epsilon\n        gains_perturbed = gains + perturbation\n        f_perturbed = fitness_function(gains_perturbed)\n        variations.append(abs(f_perturbed - f_center))\n\n    ruggedness = np.mean(variations)\n    return ruggedness",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5a8e714"
  },
  {
    "id": "optimization_landscape_analysis_5_411550f3",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_convexity(fitness_func, g1, g2, n_points=20):\n    \"\"\"Test convexity between two points.\"\"\"\n    alphas = np.linspace(0, 1, n_points)\n    convex_bound = []\n    actual_fitness = []\n\n    for alpha in alphas:\n        g_interp = alpha * g1 + (1 - alpha) * g2\n        f_interp = fitness_func(g_interp)\n        f_bound = alpha * fitness_func(g1) + (1 - alpha) * fitness_func(g2)\n\n        actual_fitness.append(f_interp)\n        convex_bound.append(f_bound)\n\n    # If actual < bound everywhere \u2192 convex\n    is_convex = all(a <= b for a, b in zip(actual_fitness, convex_bound))\n    return is_convex, actual_fitness, convex_bound",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "411550f3"
  },
  {
    "id": "optimization_landscape_analysis_6_527a1eef",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nobjective_weights = {\n    'ise': 0.5,         # 50% - primary objective\n    'chattering': 0.3,  # 30% - important for smoothness\n    'effort': 0.2,      # 20% - energy consideration\n}\n\n# Reference values (baseline Classical SMC with manual tuning)\nreference_values = {\n    'ise': 25.0,\n    'chattering': 150.0,\n    'effort': 200.0,\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "527a1eef"
  },
  {
    "id": "optimization_landscape_analysis_7_37958c4a",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_fitness(gains):\n    result = simulate(gains)\n\n    ise_norm = result.ise / reference_values['ise']\n    chattering_norm = result.chattering / reference_values['chattering']\n    effort_norm = result.effort / reference_values['effort']\n\n    fitness = (\n        objective_weights['ise'] * ise_norm +\n        objective_weights['chattering'] * chattering_norm +\n        objective_weights['effort'] * effort_norm\n    )\n\n    return fitness",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37958c4a"
  },
  {
    "id": "optimization_landscape_analysis_8_0beddd43",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 8,
    "code": "from pymoo.algorithms.moo.nsga2 import NSGA2\nfrom pymoo.problems import Problem\n\nclass SMCMultiObjective(Problem):\n    def __init__(self):\n        super().__init__(\n            n_var=6,                    # 6 gains\n            n_obj=3,                    # ISE, chattering, effort\n            n_constr=1,                 # K > 10\n            xl=[0.1, 0.1, 0.1, 0.1, 1.0, 0.0],\n            xu=[50, 50, 50, 50, 200, 50]\n        )\n\n    def _evaluate(self, x, out, *args, **kwargs):\n        # x: (n_population, 6) - gains\n        ise = []\n        chattering = []\n        effort = []\n\n        for gains in x:\n            result = simulate(gains)\n            ise.append(result.ise)\n            chattering.append(result.chattering)\n            effort.append(result.effort)\n\n        out[\"F\"] = np.column_stack([ise, chattering, effort])\n        out[\"G\"] = 10 - x[:, 4]  # Constraint: K > 10\n\n# Run MOPSO\nproblem = SMCMultiObjective()\nalgorithm = NSGA2(pop_size=50)\nresult = minimize(problem, algorithm, termination=('n_gen', 100))\n\npareto_set = result.X  # Pareto-optimal gains\npareto_front = result.F  # Objective values",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0beddd43"
  },
  {
    "id": "optimization_landscape_analysis_9_f58f3ad5",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef barrier_penalty(gains, mu=0.05):\n    \"\"\"Logarithmic barrier for stability constraints.\"\"\"\n    penalty = 0.0\n\n    # Surface gains must be positive\n    for i in range(4):\n        if gains[i] <= 0:\n            return 1e9  # Hard constraint violation\n        penalty -= mu * np.log(gains[i])\n\n    # Switching gain must exceed disturbance\n    K_margin = gains[4] - 10.0\n    if K_margin <= 0:\n        return 1e9\n    penalty -= mu * np.log(K_margin)\n\n    return penalty\n\ndef fitness_with_barrier(gains):\n    return base_fitness(gains) + barrier_penalty(gains)",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f58f3ad5"
  },
  {
    "id": "optimization_landscape_analysis_10_1b8368ef",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 10,
    "code": "def penalty_k1_k2(gains, penalty_weight=1000):\n    \"\"\"Penalty for K1 <= K2 violation.\"\"\"\n    if gains[0] <= gains[1]:\n        violation = gains[1] - gains[0] + 0.1  # Margin\n        return penalty_weight * violation**2\n    return 0.0",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1b8368ef"
  },
  {
    "id": "optimization_landscape_analysis_11_eff5be6c",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 11,
    "code": "mu = mu_0 * (1.05 ** iteration)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eff5be6c"
  },
  {
    "id": "optimization_landscape_analysis_12_861611d0",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 12,
    "code": "if violation_rate > 0.2:  # 20% of particles violate\n    mu *= 1.5  # Increase penalty\nelif violation_rate < 0.05:\n    mu *= 0.9  # Decrease penalty (may be too conservative)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "861611d0"
  },
  {
    "id": "optimization_landscape_analysis_13_8ee112f9",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 13,
    "code": "from SALib.analyze import sobol\n\n# Sample parameter space\nfrom SALib.sample import saltelli\nproblem = {\n    'num_vars': 6,\n    'names': ['k1', 'k2', '\u03bb1', '\u03bb2', 'K', 'kd'],\n    'bounds': [[0.1, 50], [0.1, 50], [0.1, 50],\n               [0.1, 50], [1, 200], [0, 50]]\n}\n\nparam_values = saltelli.sample(problem, 1000)  # 1000 samples\n\n# Evaluate fitness\nY = np.array([evaluate_fitness(g) for g in param_values])\n\n# Compute Sobol indices\nSi = sobol.analyze(problem, Y)\n\nprint(\"First-order indices:\", Si['S1'])\nprint(\"Total indices:\", Si['ST'])",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ee112f9"
  },
  {
    "id": "optimization_landscape_analysis_14_ecd73619",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 14,
    "code": "import matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n# Fix other gains\nfixed_gains = [15, 12, 8, 35, 5]  # k2, \u03bb1, \u03bb2, K, kd\n\n# Vary K and k1\nK_range = np.linspace(10, 200, 30)\nk1_range = np.linspace(0.1, 50, 30)\nK_grid, k1_grid = np.meshgrid(K_range, k1_range)\n\nfitness_grid = np.zeros_like(K_grid)\nfor i in range(K_grid.shape[0]):\n    for j in range(K_grid.shape[1]):\n        gains = [k1_grid[i,j]] + fixed_gains\n        fitness_grid[i,j] = evaluate_fitness(gains)\n\n# 3D surface plot\nfig = plt.figure(figsize=(12, 8))\nax = fig.add_subplot(111, projection='3d')\nsurf = ax.plot_surface(K_grid, k1_grid, fitness_grid, cmap=cm.viridis)\nax.set_xlabel('K (Switching Gain)')\nax.set_ylabel('k1 (Surface Gain)')\nax.set_zlabel('Fitness')\nplt.colorbar(surf)\nplt.title('Fitness Landscape: K vs k1 Interaction')",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ecd73619"
  },
  {
    "id": "optimization_landscape_analysis_15_8d8af7c6",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nconservative_bounds = {\n    'classical_smc': [\n        (5.0, 30.0),    # k1 - narrow range\n        (5.0, 30.0),    # k2\n        (5.0, 30.0),    # \u03bb1\n        (5.0, 30.0),    # \u03bb2\n        (20.0, 100.0),  # K - known stable region\n        (1.0, 20.0),    # kd\n    ],\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d8af7c6"
  },
  {
    "id": "optimization_landscape_analysis_16_0a1059ae",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nexploration_bounds = {\n    'classical_smc': [\n        (0.1, 50.0),    # k1 - wide range\n        (0.1, 50.0),    # k2\n        (0.1, 50.0),    # \u03bb1\n        (0.1, 50.0),    # \u03bb2\n        (1.0, 200.0),   # K - full range\n        (0.0, 50.0),    # kd\n    ],\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a1059ae"
  },
  {
    "id": "optimization_landscape_analysis_17_18593e20",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 17,
    "code": "recommended_pso_config = {\n    'n_particles': 30,          # Balanced swarm size\n    'max_iters': 100,           # Sufficient for convergence\n    'inertia': [0.9, 0.4],      # Linear decrease\n    'c1': 2.05,                 # Standard cognitive\n    'c2': 2.05,                 # Standard social\n    'boundary_handling': 'absorbing',\n    'velocity_clamping': 0.2,\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "18593e20"
  },
  {
    "id": "optimization_landscape_analysis_18_1c921c24",
    "file": "docs\\mathematical_foundations\\optimization_landscape_analysis.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_convergence(fitness_history, diversity_history):\n    \"\"\"Identify convergence issues.\"\"\"\n    if len(fitness_history) < 20:\n        return \"Insufficient data\"\n\n    # Check stagnation\n    recent_improvement = fitness_history[-1] - fitness_history[-20]\n    if abs(recent_improvement) < 1e-3:\n        return \"Stagnation detected\"\n\n    # Check premature convergence\n    if diversity_history[-1] < 0.01 * diversity_history[0]:\n        if fitness_history[-1] > 10.0:  # Poor fitness\n            return \"Premature convergence\"\n\n    # Check oscillation\n    recent_std = np.std(fitness_history[-10:])\n    if recent_std > 5.0:\n        return \"Unstable oscillation\"\n\n    return \"Healthy convergence\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c921c24"
  },
  {
    "id": "pso_algorithm_theory_1_e473c011",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 1,
    "code": "# Maintains search momentum\nvelocity_new = inertia * velocity_old",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e473c011"
  },
  {
    "id": "pso_algorithm_theory_2_0e68507f",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 2,
    "code": "# Personal experience attraction\ncognitive = c1 * random() * (personal_best - position)\nvelocity_new += cognitive",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e68507f"
  },
  {
    "id": "pso_algorithm_theory_3_e57e5131",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 3,
    "code": "# Swarm knowledge attraction\nsocial = c2 * random() * (global_best - position)\nvelocity_new += social",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e57e5131"
  },
  {
    "id": "pso_algorithm_theory_4_7fc14138",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 4,
    "code": "omega = omega_max - (omega_max - omega_min) * (iter / max_iter)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7fc14138"
  },
  {
    "id": "pso_algorithm_theory_5_99a46397",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 5,
    "code": "# Balanced (recommended for SMC)\nc1 = 2.05\nc2 = 2.05\n\n# High-dimensional problems (n > 10)\nc1 = 2.5  # Emphasize personal exploration\nc2 = 1.5\n\n# Fast convergence needed (limited budget)\nc1 = 1.5\nc2 = 2.5  # Emphasize swarm attraction",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "99a46397"
  },
  {
    "id": "pso_algorithm_theory_6_33c9fd94",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 6,
    "code": "def check_convergence(fitness_history, window=10, tolerance=1e-6):\n    \"\"\"Stop if fitness stagnates.\"\"\"\n    if len(fitness_history) < window:\n        return False\n\n    recent = fitness_history[-window:]\n    stagnation = max(recent) - min(recent)\n\n    return stagnation < tolerance",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33c9fd94"
  },
  {
    "id": "pso_algorithm_theory_7_1a19f7a4",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nmax_iter = 200\nstagnation_limit = 20\n\nfor iter in range(max_iter):\n    # ... PSO iteration ...\n\n    if no_improvement_count >= stagnation_limit:\n        print(f\"Converged at iteration {iter}\")\n        break",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a19f7a4"
  },
  {
    "id": "pso_algorithm_theory_8_f3dcfc01",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 8,
    "code": "if diversity < threshold_low:\n    omega = increase(omega)    # Increase exploration\n    c1 = increase(c1)\nelif diversity > threshold_high:\n    omega = decrease(omega)    # Increase exploitation\n    c2 = increase(c2)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3dcfc01"
  },
  {
    "id": "pso_algorithm_theory_9_e3eb2c13",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 9,
    "code": "def select_learning_exemplar(particle_i, dimension_d):\n    \"\"\"Choose particle to learn from for dimension d.\"\"\"\n    if random() < learning_probability:\n        return best_particle_except_i  # Learn from best\n    else:\n        return random_particle()  # Learn from random (diversity)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3eb2c13"
  },
  {
    "id": "pso_algorithm_theory_10_9daf2b40",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 10,
    "code": "bounds = [\n       (0.1, 50.0),   # k1\n       (0.1, 50.0),   # k2\n       (0.1, 50.0),   # \u03bb1\n       (0.1, 50.0),   # \u03bb2\n       (1.0, 200.0),  # K\n       (0.0, 50.0),   # kd\n   ]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9daf2b40"
  },
  {
    "id": "pso_algorithm_theory_11_01b1ff9e",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef evaluate_fitness(gains):\n    \"\"\"Evaluate controller performance via simulation.\"\"\"\n    # 1. Create controller\n    controller = create_controller('classical_smc', gains=gains)\n\n    # 2. Run simulation (5-second horizon)\n    result = simulate(\n        controller=controller,\n        duration=5.0,\n        dt=0.01,\n        initial_state=[0.1, 0.05, 0, 0, 0, 0]\n    )\n\n    # 3. Compute metrics\n    ise = np.trapz(result.states**2, dx=0.01)\n    chattering = np.sum(np.abs(np.diff(result.control))) * 0.01\n    effort = np.trapz(result.control**2, dx=0.01)\n\n    # 4. Multi-objective fitness\n    fitness = 0.5 * ise + 0.3 * chattering + 0.2 * effort\n\n    return fitness",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "01b1ff9e"
  },
  {
    "id": "pso_algorithm_theory_12_acdac942",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef penalized_fitness(gains):\n    \"\"\"Add large penalty for invalid gains.\"\"\"\n    base_fitness = evaluate_fitness(gains)\n    penalty = 0.0\n\n    # Stability constraint violation\n    if any(g <= 0 for g in gains[:5]):\n        penalty += 1e6\n\n    # Minimum switching gain\n    if gains[4] < 10.0:\n        penalty += 1e4 * (10.0 - gains[4])\n\n    return base_fitness + penalty",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "acdac942"
  },
  {
    "id": "pso_algorithm_theory_13_e2702456",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\npso_config = {\n    'n_particles': 30,\n    'max_iters': 100,\n    'inertia': 0.7298,         # Constriction coefficient\n    'c1': 2.05,                # Cognitive coefficient\n    'c2': 2.05,                # Social coefficient\n    'bounds': [\n        (0.1, 50.0),  # k1\n        (0.1, 50.0),  # k2\n        (0.1, 50.0),  # \u03bb1\n        (0.1, 50.0),  # \u03bb2\n        (1.0, 200.0), # K\n        (0.0, 50.0),  # kd\n    ],\n    'objective_weights': {\n        'ise': 0.5,\n        'chattering': 0.3,\n        'effort': 0.2,\n    }\n}",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2702456"
  },
  {
    "id": "pso_algorithm_theory_14_780a6fb1",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 14,
    "code": "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.semilogy(fitness_history['iteration'], fitness_history['best_fitness'])\nplt.xlabel('Iteration')\nplt.ylabel('Best Fitness (log scale)')\nplt.title('PSO Convergence Curve')\nplt.grid(True)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "780a6fb1"
  },
  {
    "id": "pso_algorithm_theory_15_fa9984f1",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 15,
    "code": "def compute_diversity(swarm_positions):\n    \"\"\"Measure swarm spread.\"\"\"\n    centroid = np.mean(swarm_positions, axis=0)\n    diversity = np.mean([np.linalg.norm(x - centroid)\n                        for x in swarm_positions])\n    return diversity",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fa9984f1"
  },
  {
    "id": "pso_algorithm_theory_16_995573d1",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nbest_fitness_history = []\nno_improvement_count = 0\ntolerance = 1e-6\n\nfor iter in range(max_iter):\n    # ... PSO iteration ...\n\n    if len(best_fitness_history) > 0:\n        improvement = abs(current_best - best_fitness_history[-1])\n        if improvement < tolerance:\n            no_improvement_count += 1\n        else:\n            no_improvement_count = 0\n\n    if no_improvement_count >= 20:\n        print(f\"Stagnation detected at iteration {iter}\")\n        # Restart or perturb swarm\n        break",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "995573d1"
  },
  {
    "id": "pso_algorithm_theory_17_f6c56834",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 17,
    "code": "v_max = 0.2 * (bounds_upper - bounds_lower)\nvelocity = np.clip(velocity, -v_max, v_max)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6c56834"
  },
  {
    "id": "pso_algorithm_theory_18_92969587",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 18,
    "code": "position = np.clip(position, bounds_lower, bounds_upper)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92969587"
  },
  {
    "id": "pso_algorithm_theory_19_0a8cba4b",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 19,
    "code": "if position[i] < bounds_lower[i]:\n       position[i] = bounds_lower[i]\n       velocity[i] = -velocity[i]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a8cba4b"
  },
  {
    "id": "pso_algorithm_theory_20_2c9258bb",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 20,
    "code": "position[i] = (position[i] - bounds_lower[i]) % range + bounds_lower[i]",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c9258bb"
  },
  {
    "id": "pso_algorithm_theory_21_9b4911ef",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 21,
    "code": "positions = np.random.uniform(\n    low=bounds_lower,\n    high=bounds_upper,\n    size=(n_particles, n_dimensions)\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9b4911ef"
  },
  {
    "id": "pso_algorithm_theory_22_5340f1a7",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 22,
    "code": "from scipy.stats import qmc\n\nsampler = qmc.LatinHypercube(d=n_dimensions)\nsamples = sampler.random(n=n_particles)\n\n# Scale to bounds\npositions = bounds_lower + samples * (bounds_upper - bounds_lower)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5340f1a7"
  },
  {
    "id": "pso_algorithm_theory_23_7e1e1849",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 23,
    "code": "for i in range(n_particles):\n    fitness[i] = evaluate_fitness(positions[i])",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e1e1849"
  },
  {
    "id": "pso_algorithm_theory_24_8a327b96",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 24,
    "code": "from multiprocessing import Pool\n\nwith Pool(processes=8) as pool:\n    fitness = pool.map(evaluate_fitness, positions)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a327b96"
  },
  {
    "id": "pso_algorithm_theory_25_81785ab9",
    "file": "docs\\mathematical_foundations\\pso_algorithm_theory.md",
    "index": 25,
    "code": "pso_params = {\n    'n_particles': 30,\n    'max_iters': 100,\n    'inertia': 0.7298,     # Constriction coefficient\n    'c1': 2.05,            # Cognitive coefficient\n    'c2': 2.05,            # Social coefficient\n    'v_max': 0.2 * range,  # Velocity clamping\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81785ab9"
  },
  {
    "id": "simulation_architecture_guide_1_e655b744",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef simulate(\n    initial_state: Any,\n    control_inputs: Any,\n    dt: float,\n    horizon: Optional[int] = None,\n    *,\n    energy_limits: Optional[float | dict] = None,\n    state_bounds: Optional[Tuple[Any, Any]] = None,\n    stop_fn: Optional[Callable[[np.ndarray], bool]] = None,\n    t0: float = 0.0,\n) -> np.ndarray",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e655b744"
  },
  {
    "id": "simulation_architecture_guide_2_3e88c627",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 2,
    "code": "from src.simulation.engines.vector_sim import simulate\nimport numpy as np\n\n# Single pendulum simulation\nx0 = np.array([0.0, 0.1, -0.05, 0.0, 0.0, 0.0])  # [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\nu = np.zeros(100)  # No control input\ndt = 0.01  # 10 ms timestep\n\nstates = simulate(x0, u, dt)\n\nprint(f\"State shape: {states.shape}\")  # (101, 6) - includes initial state\nprint(f\"Initial state: {states[0]}\")   # Same as x0\nprint(f\"Final state: {states[-1]}\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e88c627"
  },
  {
    "id": "simulation_architecture_guide_3_8e542610",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Simulate 30 particles with different initial conditions\nn_particles = 30\nx0_batch = np.random.randn(n_particles, 6) * 0.1  # (30, 6)\nu_batch = np.zeros((n_particles, 100))            # (30, 100)\n\nstates_batch = simulate(x0_batch, u_batch, dt)\n\nprint(f\"Batch shape: {states_batch.shape}\")  # (30, 101, 6)\n\n# Analyze each particle\nfor i in range(n_particles):\n    final_energy = np.sum(states_batch[i, -1, :]**2)\n    print(f\"Particle {i}: final energy = {final_energy:.4f}\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e542610"
  },
  {
    "id": "simulation_architecture_guide_4_a56a6ed9",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 4,
    "code": "# Stop when pendulum falls (|\u03b81| > \u03c0/2)\ndef stop_condition(state):\n    return abs(state[1]) > np.pi / 2\n\nx0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\nu = np.random.randn(1000) * 0.1  # Large disturbance\n\nstates = simulate(x0, u, dt, stop_fn=stop_condition)\n\nprint(f\"Simulation stopped at step {len(states)-1}\")  # May be < 1000",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a56a6ed9"
  },
  {
    "id": "simulation_architecture_guide_5_2d880297",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 5,
    "code": "def _guard_no_nan(state: np.ndarray, t: float, dt: float) -> None:\n    \"\"\"Detect and raise error for NaN values.\"\"\"\n    if not np.all(np.isfinite(state)):\n        raise ValueError(f\"NaN/Inf detected at t={t:.3f}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d880297"
  },
  {
    "id": "simulation_architecture_guide_6_32a08cbe",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 6,
    "code": "def _guard_energy(state: np.ndarray, energy_limit: float, t: float) -> None:\n    \"\"\"Check total energy against limit.\"\"\"\n    total_energy = np.sum(state**2)\n    if total_energy > energy_limit:\n        raise ValueError(\n            f\"Energy violation at t={t:.3f}: \"\n            f\"{total_energy:.2f} > {energy_limit:.2f}\"\n        )",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32a08cbe"
  },
  {
    "id": "simulation_architecture_guide_7_a26bb60b",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 7,
    "code": "def _guard_bounds(state: np.ndarray, lower: Any, upper: Any, t: float) -> None:\n    \"\"\"Check state bounds.\"\"\"\n    if lower is not None and np.any(state < lower):\n        raise ValueError(f\"Lower bound violation at t={t:.3f}\")\n    if upper is not None and np.any(state > upper):\n        raise ValueError(f\"Upper bound violation at t={t:.3f}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a26bb60b"
  },
  {
    "id": "simulation_architecture_guide_8_5d135371",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 8,
    "code": "from src.simulation.engines.vector_sim import simulate\n\n# Pendulum with energy limit\nstates = simulate(\n    x0,\n    u,\n    dt,\n    energy_limits=100.0,  # Total energy < 100\n    state_bounds=(\n        [-10.0, -np.pi, -np.pi, -50.0, -50.0, -50.0],  # Lower bounds\n        [ 10.0,  np.pi,  np.pi,  50.0,  50.0,  50.0]   # Upper bounds\n    )\n)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d135371"
  },
  {
    "id": "simulation_architecture_guide_9_f72969db",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 9,
    "code": "from src.simulation.engines.simulation_runner import step, get_step_fn\n\n# Automatic dispatch based on config\n# config.simulation.use_full_dynamics = True/False\n\nx_next = step(x_current, u, dt)\n\n# Manual selection\nfull_step_fn = _load_full_step()      # Full nonlinear model\nlowrank_step_fn = _load_lowrank_step()  # Low-rank approximation\n\nx_next_full = full_step_fn(x, u, dt)\nx_next_lr = lowrank_step_fn(x, u, dt)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f72969db"
  },
  {
    "id": "simulation_architecture_guide_10_5b4a3820",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef run_simulation(\n    *,\n    controller: Any,\n    dynamics_model: Any,\n    sim_time: float,\n    dt: float,\n    initial_state: Any,\n    u_max: Optional[float] = None,\n    seed: Optional[int] = None,\n    rng: Optional[np.random.Generator] = None,\n    latency_margin: Optional[float] = None,\n    fallback_controller: Optional[Callable[[float, np.ndarray], float]] = None,\n    **_kwargs: Any,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b4a3820"
  },
  {
    "id": "simulation_architecture_guide_11_d11c2e2d",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 11,
    "code": "from src.simulation.engines.simulation_runner import run_simulation\nfrom src.controllers.factory import create_controller\nfrom src.plant.models.dynamics import DoubleInvertedPendulum\n\n# Create controller and dynamics\ncontroller = create_controller('classical_smc', config=config, gains=[10, 5, 8, 3, 15, 2])\ndynamics = DoubleInvertedPendulum(config.physics)\n\n# Run simulation\nt, states, controls = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=10.0,\n    dt=0.01,\n    initial_state=np.array([0.0, 0.1, -0.05, 0.0, 0.0, 0.0]),\n    u_max=100.0,\n    seed=42\n)\n\nprint(f\"Time points: {len(t)}\")       # 1001\nprint(f\"States shape: {states.shape}\")  # (1001, 6)\nprint(f\"Controls shape: {controls.shape}\")  # (1000,)",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d11c2e2d"
  },
  {
    "id": "simulation_architecture_guide_12_ea64a690",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimulationContext:\n    \"\"\"Simulation setup and configuration management.\"\"\"\n\n    def __init__(self, config_path: str = \"config.yaml\"):\n        self.config = load_config(config_path, allow_unknown=True)\n        self.dynamics_model = self._initialize_dynamics_model()\n\n    def _initialize_dynamics_model(self):\n        \"\"\"Select dynamics model based on config flag.\"\"\"\n        if self.config.simulation.use_full_dynamics:\n            return FullDIPDynamics(self.config.physics)\n        else:\n            return DoubleInvertedPendulum(self.config.physics)\n\n    def get_dynamics_model(self):\n        \"\"\"Return initialized dynamics model.\"\"\"\n        return self.dynamics_model\n\n    def create_controller(self, name=None, gains=None):\n        \"\"\"Create controller using factory.\"\"\"\n        # Uses default gains from config if not provided\n        return create_controller(name or \"classical_smc\", config=self.config, gains=gains)",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ea64a690"
  },
  {
    "id": "simulation_architecture_guide_13_d16d7cea",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 13,
    "code": "from src.simulation.context.simulation_context import SimulationContext\n\n# Initialize simulation context\nctx = SimulationContext(\"config.yaml\")\n\n# Access components\ndynamics = ctx.get_dynamics_model()\nconfig = ctx.get_config()\n\n# Create controller with defaults from config\ncontroller = ctx.create_controller(\"classical_smc\")\n\n# Create controller with custom gains\nadaptive_ctrl = ctx.create_controller(\"adaptive_smc\", gains=[10, 5, 8, 3, 2.0])\n\n# Run simulation\nt, states, controls = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=config.simulation.duration,\n    dt=config.simulation.dt,\n    initial_state=config.simulation.initial_state\n)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d16d7cea"
  },
  {
    "id": "simulation_architecture_guide_14_0fe278de",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 14,
    "code": "from src.simulation.orchestrators.batch import BatchOrchestrator\nimport numpy as np\n\norchestrator = BatchOrchestrator()\n\n# Batch initial conditions (Monte Carlo)\nn_runs = 100\nx0_batch = np.random.randn(n_runs, 6) * 0.1\nu_batch = np.zeros((n_runs, 1000))\n\nresult = orchestrator.execute(\n    initial_state=x0_batch,\n    control_inputs=u_batch,\n    dt=0.01,\n    horizon=1000,\n    safety_guards=True,\n    stop_fn=lambda x: abs(x[1]) > np.pi/2\n)\n\n# Access results\nprint(f\"Batch size: {result.batch_size}\")\nprint(f\"Successful runs: {result.success_count}\")\nprint(f\"Execution time: {result.execution_time:.3f}s\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fe278de"
  },
  {
    "id": "simulation_architecture_guide_15_7b627c86",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 15,
    "code": "# Override config defaults\nstates = simulate(\n    x0, u, dt,\n    energy_limits=200.0,  # More permissive than config\n    state_bounds=(None, None)  # Disable bounds checking\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7b627c86"
  },
  {
    "id": "simulation_architecture_guide_16_49a827b0",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 16,
    "code": "from src.simulation.context.safety_guards import _guard_no_nan\n\ndef custom_guard_angular_velocity(state, t, threshold=100.0):\n    \"\"\"Custom guard for excessive angular velocities.\"\"\"\n    theta1_dot = state[4]\n    theta2_dot = state[5]\n\n    if abs(theta1_dot) > threshold or abs(theta2_dot) > threshold:\n        raise ValueError(\n            f\"Angular velocity limit exceeded at t={t:.3f}: \"\n            f\"\u03b8\u03071={theta1_dot:.2f}, \u03b8\u03072={theta2_dot:.2f}\"\n        )\n\n# Integrate custom guard into simulation loop\nfor i in range(horizon):\n    x_next = step(x_current, u[i], dt)\n    _guard_no_nan(x_next, t, dt)\n    custom_guard_angular_velocity(x_next, t, threshold=50.0)\n    x_current = x_next\n    t += dt",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49a827b0"
  },
  {
    "id": "simulation_architecture_guide_17_2460e7cd",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 17,
    "code": "# GOOD: Creates view (zero-copy)\nx_array = np.asarray(x, dtype=float)  # If x is already float64 ndarray\n\n# BAD: Creates copy\nx_array = np.array(x, dtype=float)  # Always creates new array",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2460e7cd"
  },
  {
    "id": "simulation_architecture_guide_18_5a0c24ec",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# GOOD: Pre-allocate result array\nstates = np.zeros((batch_size, horizon + 1, state_dim), dtype=float)\nstates[:, 0, :] = initial_state\n\nfor i in range(horizon):\n    states[:, i+1, :] = dynamics_step(states[:, i, :], u[:, i], dt)\n\n# BAD: Append to list\nstates = [initial_state]\nfor i in range(horizon):\n    states.append(dynamics_step(states[-1], u[i], dt))\nstates = np.array(states)  # Expensive conversion at end",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a0c24ec"
  },
  {
    "id": "simulation_architecture_guide_19_6352d07e",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 19,
    "code": "# GOOD: Broadcasting avoids explicit loops\nn_particles = 30\ncontrol_input = np.array([1.0])  # Single value\nu_batch = np.broadcast_to(control_input, (n_particles,))  # Efficient view\n\n# BAD: Explicit replication\nu_batch = np.array([control_input[0] for _ in range(n_particles)])",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6352d07e"
  },
  {
    "id": "simulation_architecture_guide_20_b2cd5ac6",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 20,
    "code": "import numba\n\n@numba.jit(nopython=True, cache=True)\ndef fast_dynamics_step(state, control, dt, params):\n    \"\"\"JIT-compiled dynamics for 100x speedup.\"\"\"\n    # Pure NumPy operations only\n    M = compute_mass_matrix(state, params)\n    C = compute_coriolis(state, params)\n    G = compute_gravity(state, params)\n\n    qdd = np.linalg.solve(M, control - C @ state[3:] - G)\n    return state + dt * np.concatenate([state[3:], qdd])\n\n# First call: ~100 ms (compilation)\n# Subsequent calls: ~0.1 ms (compiled code)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2cd5ac6"
  },
  {
    "id": "simulation_architecture_guide_21_6663c9ba",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 21,
    "code": "import time\nimport cProfile\n\n# Time measurement\nstart = time.perf_counter()\nstates = simulate(x0, u, dt)\nelapsed = time.perf_counter() - start\nprint(f\"Simulation time: {elapsed*1000:.2f} ms\")\n\n# Detailed profiling\nprofiler = cProfile.Profile()\nprofiler.enable()\n\nfor _ in range(100):\n    states = simulate(x0, u, dt)\n\nprofiler.disable()\nprofiler.print_stats(sort='cumtime')\n\n# Expected hot spots:\n# 1. np.linalg.solve (30-40%)\n# 2. dynamics evaluation (20-30%)\n# 3. safety guards (5-10%)\n# 4. array operations (10-20%)",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6663c9ba"
  },
  {
    "id": "simulation_architecture_guide_22_a968e6d8",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\n# Single trajectory \u2192 SequentialOrchestrator\n# PSO (30 particles) \u2192 BatchOrchestrator (25x faster)\n# Monte Carlo (1000 runs) \u2192 ParallelOrchestrator (4 cores)\n# HIL testing \u2192 RealTimeOrchestrator",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a968e6d8"
  },
  {
    "id": "simulation_architecture_guide_23_a8d6d2c9",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 23,
    "code": "from src.simulation.engines.vector_sim import simulate\n\n# Add input validation before simulation\nassert x0.shape == (6,), f\"Expected state dim 6, got {x0.shape}\"\nassert len(u) == horizon, f\"Control length {len(u)} != horizon {horizon}\"\nassert dt > 0, \"Time step must be positive\"\n\nstates = simulate(x0, u, dt, horizon=horizon)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d6d2c9"
  },
  {
    "id": "simulation_architecture_guide_24_ee16d41b",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\n# Development: Permissive limits for debugging\nstates_dev = simulate(x0, u, dt, energy_limits=1e6, state_bounds=(None, None))\n\n# Production: Strict limits for safety\nstates_prod = simulate(\n    x0, u, dt,\n    energy_limits=100.0,\n    state_bounds=(\n        [-10.0, -np.pi, -np.pi, -50.0, -50.0, -50.0],\n        [ 10.0,  np.pi,  np.pi,  50.0,  50.0,  50.0]\n    )\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee16d41b"
  },
  {
    "id": "simulation_architecture_guide_25_5c4cda25",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Wrap simulation in try-except for safety guard violations\ntry:\n    states = simulate(x0, u, dt, energy_limits=100.0)\n    success = True\nexcept ValueError as e:\n    # Safety guard triggered\n    print(f\"Simulation failed: {e}\")\n    success = False\n\n# Use early stopping instead of throwing errors\ndef soft_stop(state):\n    \"\"\"Return True when unstable, but don't raise error.\"\"\"\n    return abs(state[1]) > np.pi/2 or np.sum(state**2) > 100.0\n\nstates = simulate(x0, u, dt, stop_fn=soft_stop)\n# states.shape[0] may be < horizon + 1",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c4cda25"
  },
  {
    "id": "simulation_architecture_guide_26_20eff320",
    "file": "docs\\mathematical_foundations\\simulation_architecture_guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO fitness evaluation (30 particles)\n\n# BAD: Sequential loop (slow)\ndef fitness_sequential(particles):\n    costs = []\n    for gains in particles:\n        controller = create_controller('classical_smc', gains=gains)\n        _, states, _ = run_simulation(controller, dynamics, 10.0, 0.01, x0)\n        costs.append(compute_cost(states))\n    return np.array(costs)\n\n# GOOD: Vectorized batch (25x faster)\ndef fitness_vectorized(particles):\n    x0_batch = np.tile(x0, (len(particles), 1))  # (30, 6)\n    u_batch = np.zeros((len(particles), 1000))\n\n    # Create controllers in batch\n    controllers = [create_controller('classical_smc', gains=g) for g in particles]\n\n    # Simulate all at once\n    states_batch = simulate(x0_batch, u_batch, 0.01)  # (30, 1001, 6)\n\n    # Vectorized cost computation\n    costs = np.sum(states_batch[:, :, :3]**2 * dt, axis=(1, 2))\n    return costs",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20eff320"
  },
  {
    "id": "sliding_surface_analysis_1_5df4ce70",
    "file": "docs\\mathematical_foundations\\sliding_surface_analysis.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_gains(self) -> None:\n    \"\"\"Validate gain vector according to SMC theory.\"\"\"\n    if len(self.gains) != 6:\n        raise ValueError(\"Classical SMC requires exactly 6 gains: [k1, k2, lam1, lam2, K, kd]\")\n\n    k1, k2, lam1, lam2, K, kd = self.gains\n\n    # Surface gains must be positive for Hurwitz stability\n    if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n        raise ValueError(\"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\")\n\n    # Switching gain must be positive for reaching condition\n    if K <= 0:\n        raise ValueError(\"Switching gain K must be positive\")\n\n    # Derivative gain must be non-negative\n    if kd < 0:\n        raise ValueError(\"Derivative gain kd must be non-negative\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5df4ce70"
  },
  {
    "id": "sliding_surface_analysis_2_84eb9a16",
    "file": "docs\\mathematical_foundations\\sliding_surface_analysis.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute(self, state: np.ndarray) -> float:\n    \"\"\"\n    Compute linear sliding surface value.\n\n    Args:\n        state: [x, x_dot, theta1, theta1_dot, theta2, theta2_dot]\n\n    Returns:\n        Sliding surface value: s = lam1*theta1_dot + k1*theta1 + lam2*theta2_dot + k2*theta2\n    \"\"\"\n    if len(state) < 6:\n        raise ValueError(\"State must have at least 6 elements for double-inverted pendulum\")\n\n    # Extract joint angles and velocities (reference is upright: theta=0)\n    theta1 = state[2]      # Joint 1 angle error\n    theta1_dot = state[3]  # Joint 1 velocity error\n    theta2 = state[4]      # Joint 2 angle error\n    theta2_dot = state[5]  # Joint 2 velocity error\n\n    # Linear sliding surface: s = \u03bb\u2081\u0117\u2081 + c\u2081e\u2081 + \u03bb\u2082\u0117\u2082 + c\u2082e\u2082\n    s = (self.lam1 * theta1_dot + self.k1 * theta1 +\n         self.lam2 * theta2_dot + self.k2 * theta2)\n\n    return float(s)",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84eb9a16"
  },
  {
    "id": "sliding_surface_analysis_3_3771da18",
    "file": "docs\\mathematical_foundations\\sliding_surface_analysis.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_derivative(self, state: np.ndarray, state_dot: np.ndarray) -> float:\n    \"\"\"\n    Compute sliding surface derivative ds/dt.\n\n    Args:\n        state: Current state vector\n        state_dot: State derivative vector\n\n    Returns:\n        Surface derivative: \u1e61 = \u03bb\u2081\u03b8\u0308\u2081 + c\u2081\u03b8\u0307\u2081 + \u03bb\u2082\u03b8\u0308\u2082 + c\u2082\u03b8\u0307\u2082\n    \"\"\"\n    if len(state_dot) < 6:\n        raise ValueError(\"State derivative must have at least 6 elements\")\n\n    # Extract joint accelerations and velocities\n    theta1_dot = state[3]     # Joint 1 velocity\n    theta1_ddot = state_dot[3] # Joint 1 acceleration\n    theta2_dot = state[5]     # Joint 2 velocity\n    theta2_ddot = state_dot[5] # Joint 2 acceleration\n\n    # Surface derivative\n    s_dot = (self.lam1 * theta1_ddot + self.k1 * theta1_dot +\n             self.lam2 * theta2_ddot + self.k2 * theta2_dot)\n\n    return float(s_dot)",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3771da18"
  },
  {
    "id": "smc_complete_theory_1_8d095889",
    "file": "docs\\mathematical_foundations\\smc_complete_theory.md",
    "index": 1,
    "code": "if np.linalg.cond(M) > 1e6:\n    M_inv = np.linalg.pinv(M)  # Use pseudo-inverse\nelse:\n    M_inv = np.linalg.inv(M)   # Direct inversion safe",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d095889"
  },
  {
    "id": "smc_complete_theory_2_ce99af18",
    "file": "docs\\mathematical_foundations\\smc_complete_theory.md",
    "index": 2,
    "code": "if not np.isfinite(u):\n       u = 0.0  # Emergency fallback\n       log_error(\"Non-finite control value detected\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce99af18"
  },
  {
    "id": "smc_complete_theory_3_45d24eaa",
    "file": "docs\\mathematical_foundations\\smc_complete_theory.md",
    "index": 3,
    "code": "controllability = abs(L @ M_inv @ B)\n   if controllability < \u03b5_threshold:\n       # System near uncontrollable configuration\n       u_eq = 0.0  # Disable equivalent control",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45d24eaa"
  },
  {
    "id": "smc_complete_theory_4_8139015f",
    "file": "docs\\mathematical_foundations\\smc_complete_theory.md",
    "index": 4,
    "code": "u_sat = np.clip(u, -max_force, max_force)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8139015f"
  },
  {
    "id": "smc_complete_theory_5_6037b45e",
    "file": "docs\\mathematical_foundations\\smc_complete_theory.md",
    "index": 5,
    "code": "if state_norm > 10.0 or velocity_norm > 50.0:\n       # System diverging - reset controller state\n       u_int = 0.0\n       K = K_init",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6037b45e"
  },
  {
    "id": "test_validation_methodology_1_295433ac",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_sliding_surface_linearity():\n       \"\"\"Test that sliding surface is linear in state.\"\"\"\n       surface = LinearSlidingSurface(gains=[5, 3, 4, 2])\n\n       state1 = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n       state2 = np.array([0.2, 0.2, 0.2, 0.1, 0.1, 0.1])\n\n       s1 = surface.compute(state1)\n       s2 = surface.compute(state2)\n       s_combined = surface.compute(state1 + state2)\n\n       # Linearity: s(x1 + x2) = s(x1) + s(x2)\n       assert abs(s_combined - (s1 + s2)) < 1e-10",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "295433ac"
  },
  {
    "id": "test_validation_methodology_2_2d0f3052",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 2,
    "code": "def test_sliding_surface_homogeneity():\n       \"\"\"Test that sliding surface is homogeneous of degree 1.\"\"\"\n       surface = LinearSlidingSurface(gains=[5, 3, 4, 2])\n\n       state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n       alpha = 2.5\n\n       s_original = surface.compute(state)\n       s_scaled = surface.compute(alpha * state)\n\n       # Homogeneity: s(\u03b1\u00b7x) = \u03b1\u00b7s(x)\n       assert abs(s_scaled - alpha * s_original) < 1e-10",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d0f3052"
  },
  {
    "id": "test_validation_methodology_3_fbed0ba5",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_sliding_surface_gain_sensitivity():\n       \"\"\"Test that surface responds correctly to gain changes.\"\"\"\n       gains1 = [5, 3, 4, 2]\n       gains2 = [10, 6, 8, 4]  # Doubled gains\n\n       surface1 = LinearSlidingSurface(gains1)\n       surface2 = LinearSlidingSurface(gains2)\n\n       state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n\n       s1 = surface1.compute(state)\n       s2 = surface2.compute(state)\n\n       # Surface value should double with doubled gains\n       assert abs(s2 - 2 * s1) < 1e-10",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbed0ba5"
  },
  {
    "id": "test_validation_methodology_4_f69f4721",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n   def test_boundary_layer_continuity():\n       \"\"\"Test that boundary layer provides continuous switching.\"\"\"\n       boundary_layer = BoundaryLayer(thickness=0.1, switch_method=\"tanh\")\n\n       # Test continuity at surface (s=0)\n       epsilon = 1e-8\n       switch_left = boundary_layer.compute_switching_function(-epsilon)\n       switch_right = boundary_layer.compute_switching_function(epsilon)\n       switch_center = boundary_layer.compute_switching_function(0.0)\n\n       # Values should be very close at the boundary\n       assert abs(switch_left - switch_center) < 1e-6\n       assert abs(switch_right - switch_center) < 1e-6",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f69f4721"
  },
  {
    "id": "test_validation_methodology_5_9634d87b",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 5,
    "code": "def test_boundary_layer_monotonicity():\n       \"\"\"Test that switching function is monotonic.\"\"\"\n       boundary_layer = BoundaryLayer(thickness=0.1, switch_method=\"tanh\")\n\n       s_values = np.linspace(-1, 1, 100)\n       switch_values = [boundary_layer.compute_switching_function(s) for s in s_values]\n\n       # Switching function should be strictly increasing\n       for i in range(len(switch_values) - 1):\n           assert switch_values[i+1] >= switch_values[i]",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9634d87b"
  },
  {
    "id": "test_validation_methodology_6_ca1bf37c",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 6,
    "code": "def test_boundary_layer_asymptotic_behavior():\n       \"\"\"Test asymptotic limits of switching function.\"\"\"\n       boundary_layer = BoundaryLayer(thickness=0.1, switch_method=\"tanh\")\n\n       # Large positive surface value\n       switch_pos = boundary_layer.compute_switching_function(10.0)\n       assert abs(switch_pos - 1.0) < 1e-3\n\n       # Large negative surface value\n       switch_neg = boundary_layer.compute_switching_function(-10.0)\n       assert abs(switch_neg - (-1.0)) < 1e-3",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca1bf37c"
  },
  {
    "id": "test_validation_methodology_7_ab19fd9f",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestClassicalSMCConfigValidation:\n    \"\"\"Test configuration parameter validation.\"\"\"\n\n    def test_positive_gain_requirement(self):\n        \"\"\"Test that all surface gains must be positive.\"\"\"\n        # Valid configuration\n        valid_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n        config = ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n        # Invalid: zero gain\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            invalid_gains = [0.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n            ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n        # Invalid: negative gain\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            invalid_gains = [5.0, -3.0, 4.0, 2.0, 10.0, 1.0]\n            ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n    def test_switching_gain_validation(self):\n        \"\"\"Test switching gain must be positive.\"\"\"\n        with pytest.raises(ValueError, match=\"Switching gain K must be positive\"):\n            invalid_gains = [5.0, 3.0, 4.0, 2.0, -10.0, 1.0]  # K < 0\n            ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n    def test_boundary_layer_validation(self):\n        \"\"\"Test boundary layer thickness validation.\"\"\"\n        # Valid boundary layer\n        valid_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n        config = ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.05)\n\n        # Invalid: zero boundary layer\n        with pytest.raises(ValueError, match=\"boundary_layer must be positive\"):\n            ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.0)\n\n        # Invalid: negative boundary layer\n        with pytest.raises(ValueError, match=\"boundary_layer must be positive\"):\n            ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=-0.01)",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab19fd9f"
  },
  {
    "id": "test_validation_methodology_8_353f3bfd",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_hurwitz_stability_check():\n    \"\"\"Test that gain combinations satisfy Hurwitz stability.\"\"\"\n\n    def check_stability(k1, k2, lam1, lam2):\n        \"\"\"Check if gains produce stable sliding dynamics.\"\"\"\n        # For each 2x2 subsystem: s\u00b2 + \u03bb\u1d62s + c\u1d62 = 0\n        # Stability requires \u03bb\u1d62 > 0 and c\u1d62 > 0\n        return k1 > 0 and k2 > 0 and lam1 > 0 and lam2 > 0\n\n    # Stable configuration\n    stable_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n    config = ClassicalSMCConfig(gains=stable_gains, max_force=100, dt=0.01, boundary_layer=0.01)\n\n    assert check_stability(config.k1, config.k2, config.lam1, config.lam2)\n\n    # Check damping ratios\n    zeta1 = config.lam1 / (2 * np.sqrt(config.k1))\n    zeta2 = config.lam2 / (2 * np.sqrt(config.k2))\n\n    # Both subsystems should have positive damping\n    assert zeta1 > 0\n    assert zeta2 > 0",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "353f3bfd"
  },
  {
    "id": "test_validation_methodology_9_9e8a02fb",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestNumericalAccuracy:\n    \"\"\"Test numerical accuracy and precision.\"\"\"\n\n    def test_floating_point_consistency(self):\n        \"\"\"Test that computations are consistent across repeated calls.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n        controller = ModularClassicalSMC(config=config)\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        # Compute control multiple times\n        results = []\n        for _ in range(100):\n            result = controller.compute_control(state, {}, {})\n            control = result.get('control_output', result.get('control', result.get('u')))\n            if control is not None:\n                results.append(control)\n\n        if results:\n            results = np.array(results)\n\n            # All results should be identical (deterministic computation)\n            std_dev = np.std(results, axis=0)\n            assert np.all(std_dev < 1e-15)  # Machine precision\n\n    def test_numerical_stability_small_values(self):\n        \"\"\"Test numerical stability with very small state values.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n        controller = ModularClassicalSMC(config=config)\n\n        # Very small state values (near machine precision)\n        small_state = np.array([1e-15, 1e-15, 1e-15, 1e-15, 1e-15, 1e-15])\n\n        result = controller.compute_control(small_state, {}, {})\n        control = result.get('control_output', result.get('control', result.get('u')))\n\n        if control is not None:\n            # Control should be finite and small\n            assert np.all(np.isfinite(control))\n            assert np.all(np.abs(control) < 1.0)\n\n    def test_numerical_stability_large_values(self):\n        \"\"\"Test numerical stability with large state values.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n        controller = ModularClassicalSMC(config=config)\n\n        # Large state values (but within reasonable bounds)\n        large_state = np.array([10.0, 5.0, 3.0, 2.0, 2.0, 1.0])\n\n        result = controller.compute_control(large_state, {}, {})\n        control = result.get('control_output', result.get('control', result.get('u')))\n\n        if control is not None:\n            # Control should be finite and saturated\n            assert np.all(np.isfinite(control))\n            assert np.all(np.abs(control) <= config.max_force * 1.01)  # Within saturation",
    "lines": 74,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9e8a02fb"
  },
  {
    "id": "test_validation_methodology_10_87a491ed",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 10,
    "code": "from hypothesis import given, strategies as st\n\nclass TestPropertyBasedSMC:\n    \"\"\"Property-based tests using Hypothesis.\"\"\"\n\n    @given(\n        k1=st.floats(min_value=0.1, max_value=50.0),\n        k2=st.floats(min_value=0.1, max_value=50.0),\n        lam1=st.floats(min_value=0.1, max_value=50.0),\n        lam2=st.floats(min_value=0.1, max_value=50.0),\n        K=st.floats(min_value=1.0, max_value=200.0),\n        kd=st.floats(min_value=0.0, max_value=20.0)\n    )\n    def test_configuration_property_all_positive_gains(self, k1, k2, lam1, lam2, K, kd):\n        \"\"\"Test that any positive gain combination creates valid configuration.\"\"\"\n        gains = [k1, k2, lam1, lam2, K, kd]\n\n        # Should not raise any exceptions\n        config = ClassicalSMCConfig(\n            gains=gains,\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n\n        # All properties should be accessible\n        assert config.k1 == k1\n        assert config.k2 == k2\n        assert config.lam1 == lam1\n        assert config.lam2 == lam2\n        assert config.K == K\n        assert config.kd == kd\n\n    @given(\n        state=st.lists(\n            st.floats(min_value=-10.0, max_value=10.0),\n            min_size=6,\n            max_size=6\n        )\n    )\n    def test_sliding_surface_finite_output(self, state):\n        \"\"\"Test that sliding surface always produces finite output for finite input.\"\"\"\n        gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n        surface = LinearSlidingSurface(gains[:4])\n\n        state_array = np.array(state)\n\n        # Sliding surface should always be finite for finite state\n        if np.all(np.isfinite(state_array)):\n            surface_value = surface.compute(state_array)\n            assert np.isfinite(surface_value)\n\n    @given(\n        boundary_thickness=st.floats(min_value=1e-6, max_value=1.0),\n        surface_value=st.floats(min_value=-100.0, max_value=100.0)\n    )\n    def test_boundary_layer_bounded_output(self, boundary_thickness, surface_value):\n        \"\"\"Test that boundary layer output is always bounded.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=boundary_thickness, switch_method=\"tanh\")\n\n        if np.isfinite(surface_value):\n            switch_value = boundary_layer.compute_switching_function(surface_value)\n\n            # Switching function should be bounded between -1 and 1\n            assert -1.0 <= switch_value <= 1.0\n            assert np.isfinite(switch_value)",
    "lines": 66,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87a491ed"
  },
  {
    "id": "test_validation_methodology_11_0e3668ee",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestSystemLevelMathematics:\n    \"\"\"Test mathematical consistency across system components.\"\"\"\n\n    def test_control_law_decomposition(self):\n        \"\"\"Test that control law components sum correctly.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n        controller = ModularClassicalSMC(config=config)\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        # Get overall control output\n        result = controller.compute_control(state, {}, {})\n        total_control = result.get('control_output', result.get('control', result.get('u')))\n\n        # Get individual components (if available in debug output)\n        components = result.get('debug', {})\n\n        if 'u_equivalent' in components and 'u_switching' in components and 'u_derivative' in components:\n            u_eq = components['u_equivalent']\n            u_sw = components['u_switching']\n            u_d = components['u_derivative']\n\n            # Before saturation, should sum correctly\n            u_unsaturated = u_eq + u_sw + u_d\n\n            # After saturation\n            u_saturated = np.clip(u_unsaturated, -config.max_force, config.max_force)\n\n            # Should match total control (before any additional processing)\n            if total_control is not None:\n                assert np.allclose(u_saturated, total_control, rtol=1e-10)\n\n    def test_lyapunov_function_properties(self):\n        \"\"\"Test Lyapunov function properties for stability analysis.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n        controller = ModularClassicalSMC(config=config)\n\n        surface = LinearSlidingSurface(config.get_surface_gains())\n\n        # Multiple test states\n        states = [\n            np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]),\n            np.array([0.2, 0.1, 0.15, 0.05, 0.08, 0.03]),\n            np.array([-0.1, -0.05, -0.08, -0.02, -0.03, -0.01])\n        ]\n\n        for state in states:\n            s = surface.compute(state)\n\n            # Lyapunov function candidate: V = 0.5 * s\u00b2\n            V = 0.5 * s**2\n\n            # V should be non-negative\n            assert V >= 0\n\n            # V = 0 if and only if s = 0\n            if abs(s) < 1e-10:\n                assert V < 1e-15\n            else:\n                assert V > 0\n\n    def test_reaching_law_satisfaction(self):\n        \"\"\"Test that reaching law is satisfied: s*\u1e61 \u2264 -\u03b7|s|.\"\"\"\n        config = ClassicalSMCConfig(\n            gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0],\n            max_force=100.0,\n            dt=0.01,\n            boundary_layer=0.01\n        )\n\n        surface = LinearSlidingSurface(config.get_surface_gains())\n\n        # Test state away from surface\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n        s = surface.compute(state)\n\n        # Simplified reaching law check (without full dynamics)\n        # For switching control: u_sw = -K * sign(s)\n        # The reaching condition s*\u1e61 \u2264 -\u03b7|s| should be satisfied\n        # when K is chosen large enough\n\n        # This is a simplified test - full test would require dynamics model\n        if abs(s) > config.boundary_layer:\n            # Outside boundary layer, should have strong reaching behavior\n            expected_reaching_rate = -config.K * abs(s) / max(abs(s), config.boundary_layer)\n            assert expected_reaching_rate < 0  # Should be moving toward surface",
    "lines": 99,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e3668ee"
  },
  {
    "id": "test_validation_methodology_12_736661de",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef generate_linearity_test(component_class, property_name):\n    \"\"\"Generate linearity test for any mathematical component.\"\"\"\n\n    def test_linearity(self):\n        component = component_class(default_params)\n\n        x1 = generate_random_input()\n        x2 = generate_random_input()\n\n        result1 = getattr(component, property_name)(x1)\n        result2 = getattr(component, property_name)(x2)\n        result_combined = getattr(component, property_name)(x1 + x2)\n\n        assert np.allclose(result_combined, result1 + result2, rtol=1e-10)\n\n    return test_linearity\n\ndef generate_monotonicity_test(function, domain):\n    \"\"\"Generate monotonicity test for mathematical functions.\"\"\"\n\n    def test_monotonicity(self):\n        x_values = np.linspace(domain[0], domain[1], 100)\n        y_values = [function(x) for x in x_values]\n\n        # Check monotonicity\n        for i in range(len(y_values) - 1):\n            assert y_values[i+1] >= y_values[i]\n\n    return test_monotonicity",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "736661de"
  },
  {
    "id": "test_validation_methodology_13_a6e0399d",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef generate_validation_tests(config_class, parameter_specs):\n    \"\"\"Generate comprehensive validation tests for configuration classes.\"\"\"\n\n    tests = []\n\n    for param_name, spec in parameter_specs.items():\n        if spec.get('positive_required', False):\n            def test_positive_validation():\n                invalid_config = create_invalid_config(param_name, -1.0)\n                with pytest.raises(ValueError):\n                    config_class(**invalid_config)\n\n            tests.append(test_positive_validation)\n\n        if spec.get('nonzero_required', False):\n            def test_nonzero_validation():\n                invalid_config = create_invalid_config(param_name, 0.0)\n                with pytest.raises(ValueError):\n                    config_class(**invalid_config)\n\n            tests.append(test_nonzero_validation)\n\n    return tests",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6e0399d"
  },
  {
    "id": "test_validation_methodology_14_a436c43a",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass MathematicalValidationReporter:\n    \"\"\"Automated reporting for mathematical validation results.\"\"\"\n\n    def __init__(self):\n        self.violations = []\n        self.warnings = []\n        self.performance_metrics = {}\n\n    def report_stability_violation(self, test_name, gains, eigenvalues):\n        \"\"\"Report stability requirement violations.\"\"\"\n        self.violations.append({\n            'type': 'stability',\n            'test': test_name,\n            'gains': gains,\n            'eigenvalues': eigenvalues,\n            'severity': 'critical'\n        })\n\n    def report_numerical_instability(self, test_name, input_values, output_values):\n        \"\"\"Report numerical computation issues.\"\"\"\n        self.violations.append({\n            'type': 'numerical',\n            'test': test_name,\n            'inputs': input_values,\n            'outputs': output_values,\n            'severity': 'high'\n        })\n\n    def generate_report(self):\n        \"\"\"Generate comprehensive validation report.\"\"\"\n        report = {\n            'summary': {\n                'total_violations': len(self.violations),\n                'critical_issues': len([v for v in self.violations if v['severity'] == 'critical']),\n                'warnings': len(self.warnings)\n            },\n            'violations': self.violations,\n            'warnings': self.warnings,\n            'performance': self.performance_metrics\n        }\n        return report",
    "lines": 44,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a436c43a"
  },
  {
    "id": "test_validation_methodology_15_2aa9ae11",
    "file": "docs\\mathematical_foundations\\test_validation_methodology.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass MathematicalRegressionDetector:\n    \"\"\"Detect regressions in mathematical computations.\"\"\"\n\n    def __init__(self, baseline_file):\n        self.baseline = self.load_baseline(baseline_file)\n\n    def check_computation_regression(self, component, test_inputs, tolerance=1e-12):\n        \"\"\"Check if computation results match baseline within tolerance.\"\"\"\n\n        current_results = []\n        for input_data in test_inputs:\n            result = component.compute(input_data)\n            current_results.append(result)\n\n        baseline_key = f\"{component.__class__.__name__}_compute\"\n        if baseline_key in self.baseline:\n            baseline_results = self.baseline[baseline_key]\n\n            for current, baseline in zip(current_results, baseline_results):\n                if abs(current - baseline) > tolerance:\n                    return False, f\"Regression detected: {current} vs {baseline}\"\n\n        return True, \"No regression detected\"\n\n    def update_baseline(self, component, test_inputs):\n        \"\"\"Update baseline with current computation results.\"\"\"\n        # Implementation for updating baseline values\n        pass",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2aa9ae11"
  },
  {
    "id": "validation_framework_guide_1_3e69a44a",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 1,
    "code": "def require_positive(\n    value: Union[float, int, None],\n    name: str,\n    *,\n    allow_zero: bool = False\n) -> float",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e69a44a"
  },
  {
    "id": "validation_framework_guide_2_42ad3330",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 2,
    "code": "from src.utils.validation.parameter_validators import require_positive\n\n# Control gains must be positive\nk_p = require_positive(10.0, \"proportional_gain\")  # \u2705 Returns 10.0\n\n# Mass parameters must be positive\nmass = require_positive(1.5, \"cart_mass\")  # \u2705 Returns 1.5\n\n# Friction can be zero (but not negative)\nfriction = require_positive(0.0, \"friction_coefficient\", allow_zero=True)  # \u2705 Returns 0.0\n\n# Invalid: negative gain\ntry:\n    k_p = require_positive(-5.0, \"proportional_gain\")\nexcept ValueError as e:\n    # Error: \"proportional_gain must be > 0; got -5.0\"\n    print(e)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42ad3330"
  },
  {
    "id": "validation_framework_guide_3_87dc771c",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 3,
    "code": "def require_finite(\n    value: Union[float, int, None],\n    name: str\n) -> float",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87dc771c"
  },
  {
    "id": "validation_framework_guide_4_10ef4765",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 4,
    "code": "from src.utils.validation.parameter_validators import require_finite\n\n# Initial conditions (can be positive, negative, or zero)\nx0 = require_finite(0.0, \"initial_position\")       # \u2705\ntheta0 = require_finite(-0.1, \"initial_angle\")     # \u2705\nvelocity = require_finite(1.5, \"initial_velocity\") # \u2705\n\n# Invalid: infinite value\ntry:\n    x = require_finite(float('inf'), \"measurement\")\nexcept ValueError as e:\n    # Error: \"measurement must be a finite number; got inf\"\n    print(e)\n\n# Invalid: NaN value\ntry:\n    x = require_finite(float('nan'), \"sensor_reading\")\nexcept ValueError as e:\n    # Error: \"sensor_reading must be a finite number; got nan\"\n    print(e)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10ef4765"
  },
  {
    "id": "validation_framework_guide_5_c7a92ca7",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 5,
    "code": "def require_in_range(\n    value: Union[float, int, None],\n    name: str,\n    *,\n    minimum: float,\n    maximum: float,\n    allow_equal: bool = True\n) -> float",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c7a92ca7"
  },
  {
    "id": "validation_framework_guide_6_becaa5f9",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 6,
    "code": "from src.utils.validation.range_validators import require_in_range\n\n# Adaptation rates (bounded for stability)\nalpha = require_in_range(0.01, \"adaptation_rate\", minimum=1e-6, maximum=1.0)  # \u2705\n\n# Normalized values\nconfidence = require_in_range(0.85, \"confidence\", minimum=0.0, maximum=1.0)  # \u2705\n\n# Control saturation limits\nu_max = require_in_range(50.0, \"max_control\", minimum=10.0, maximum=200.0)  # \u2705\n\n# Exclusive bounds (value must be strictly inside interval)\nthreshold = require_in_range(\n    0.5, \"threshold\",\n    minimum=0.0, maximum=1.0,\n    allow_equal=False  # 0 < threshold < 1\n)  # \u2705\n\n# Invalid: below minimum\ntry:\n    alpha = require_in_range(-0.1, \"rate\", minimum=0.0, maximum=1.0)\nexcept ValueError as e:\n    # Error: \"rate must be in the interval [0.0, 1.0]; got -0.1\"\n    print(e)",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "becaa5f9"
  },
  {
    "id": "validation_framework_guide_7_1b7ebbdf",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 7,
    "code": "def require_probability(\n    value: Union[float, int, None],\n    name: str\n) -> float",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1b7ebbdf"
  },
  {
    "id": "validation_framework_guide_8_2d9ddbf8",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 8,
    "code": "from src.utils.validation.range_validators import require_probability\n\n# Optimization parameters\nmutation_rate = require_probability(0.1, \"mutation_rate\")     # \u2705\ncrossover_prob = require_probability(0.8, \"crossover_prob\")   # \u2705\n\n# Statistical parameters\nconfidence_level = require_probability(0.95, \"confidence\")    # \u2705\n\n# Edge cases\nmin_prob = require_probability(0.0, \"min_probability\")        # \u2705 (exactly 0)\nmax_prob = require_probability(1.0, \"max_probability\")        # \u2705 (exactly 1)\n\n# Invalid: outside [0, 1]\ntry:\n    p = require_probability(1.5, \"cognitive_parameter\")\nexcept ValueError as e:\n    # Error: \"cognitive_parameter must be in the interval [0.0, 1.0]; got 1.5\"\n    print(e)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d9ddbf8"
  },
  {
    "id": "validation_framework_guide_9_53baa652",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 9,
    "code": "class SMCControllerType(Enum):\n    CLASSICAL = \"classical\"           # 6 gains\n    ADAPTIVE = \"adaptive\"             # 5 gains\n    SUPER_TWISTING = \"super_twisting\" # 6 gains\n    HYBRID = \"hybrid\"                 # 4 gains",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53baa652"
  },
  {
    "id": "validation_framework_guide_10_2ce682ce",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 10,
    "code": "from src.controllers.smc.core.gain_validation import SMCGainValidator, validate_smc_gains\n\nvalidator = SMCGainValidator()\n\n# Classical SMC gains\nclassical_gains = [10.0, 5.0, 8.0, 3.0, 15.0, 2.0]\nresult = validator.validate_gains(classical_gains, \"classical\")\n\nif result['valid']:\n    print(\"\u2705 Gains valid for Classical SMC\")\nelse:\n    print(f\"\u274c Validation failed:\")\n    for violation in result['violations']:\n        print(f\"  - {violation['name']}: {violation['value']} not in {violation['bounds']}\")\n\n# Quick validation\nis_valid = validate_smc_gains(classical_gains, \"classical\")  # Returns: True",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ce682ce"
  },
  {
    "id": "validation_framework_guide_11_eee00670",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 11,
    "code": "from src.controllers.smc.core.gain_validation import SMCGainValidator\n\nvalidator = SMCGainValidator()\n\n# Super-twisting gains (requires K1 > K2)\nsta_gains = [5.0, 4.0, 10.0, 5.0, 8.0, 3.0]  # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n\nstability = validator.validate_stability_conditions(sta_gains, \"super_twisting\")\n\nif stability['stable']:\n    print(\"\u2705 Stability conditions satisfied\")\nelse:\n    print(f\"\u26a0\ufe0f Stability issues:\")\n    for issue in stability['issues']:\n        print(f\"  - {issue}\")\n\n# Example output:\n# \u2705 Stability conditions satisfied (K1=5.0 > K2=4.0 > 0)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eee00670"
  },
  {
    "id": "validation_framework_guide_12_e88648c5",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 12,
    "code": "from src.controllers.smc.core.gain_validation import get_gain_bounds_for_controller\n\n# Get recommended ranges for adaptive SMC\nbounds = get_gain_bounds_for_controller(\"adaptive\")\n\nprint(\"Adaptive SMC Gain Bounds:\")\nfor gain_name, (min_val, max_val) in bounds.items():\n    print(f\"  {gain_name}: [{min_val}, {max_val}]\")\n\n# Output:\n# k1: [0.1, 1000.0]\n# k2: [0.1, 1000.0]\n# lam1: [0.1, 1000.0]\n# lam2: [0.1, 1000.0]\n# gamma: [0.01, 10.0]",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e88648c5"
  },
  {
    "id": "validation_framework_guide_13_256bccd4",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n{\n    'valid': bool,                        # Overall validation result\n    'violations': List[Dict],             # List of violations (if any)\n    'controller_type': str,               # Controller type validated\n    'gains_checked': int,                 # Number of gains validated\n    'gains_provided': int                 # Number of gains provided\n}\n\n# Stability result structure\n{\n    'stable': bool,                       # Stability conditions satisfied\n    'issues': List[str],                  # Stability issues (if any)\n    'controller_type': str                # Controller type\n}",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "256bccd4"
  },
  {
    "id": "validation_framework_guide_14_ab1b4912",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 14,
    "code": "from tests.test_integration.test_end_to_end_validation import EndToEndWorkflowValidator\n\nvalidator = EndToEndWorkflowValidator()\n\n# Validate CLI accessibility\ncli_result = validator.validate_cli_accessibility()\n\nprint(f\"CLI Validation: {'\u2705 PASS' if cli_result.success else '\u274c FAIL'}\")\nprint(f\"Execution time: {cli_result.execution_time:.2f}s\")\nprint(f\"Steps completed:\")\nfor step in cli_result.steps_completed:\n    print(f\"  \u2713 {step}\")\n\nif cli_result.error_messages:\n    print(f\"Errors:\")\n    for error in cli_result.error_messages:\n        print(f\"  \u2717 {error}\")\n\n# Validate configuration system\nconfig_result = validator.validate_configuration_system()\n\n# Validate simulation execution\nsim_result = validator.validate_simulation_execution()\n\n# Overall system validation\nprint(\"\\n=== System Validation Summary ===\")\nprint(f\"CLI Accessibility: {cli_result.success}\")\nprint(f\"Configuration: {config_result.success}\")\nprint(f\"Simulation: {sim_result.success}\")\n\nsuccess_rate = sum([cli_result.success, config_result.success, sim_result.success]) / 3\nproduction_ready = success_rate >= 0.95\n\nprint(f\"\\nSuccess Rate: {success_rate*100:.1f}%\")\nprint(f\"Production Ready: {'\u2705 YES' if production_ready else '\u274c NO'}\")",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab1b4912"
  },
  {
    "id": "validation_framework_guide_15_1c2555bd",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 15,
    "code": "from src.utils.validation.parameter_validators import require_positive\nfrom src.utils.validation.range_validators import require_in_range\n\nclass PIDController:\n    def __init__(self, kp: float, ki: float, kd: float, u_max: float):\n        \"\"\"Initialize PID controller with validated parameters.\"\"\"\n        # Gains must be positive\n        self.kp = require_positive(kp, \"proportional_gain\")\n        self.ki = require_positive(ki, \"integral_gain\")\n        self.kd = require_positive(kd, \"derivative_gain\")\n\n        # Saturation limit must be positive and reasonable\n        self.u_max = require_in_range(\n            u_max, \"control_saturation\",\n            minimum=1.0, maximum=500.0\n        )",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c2555bd"
  },
  {
    "id": "validation_framework_guide_16_3315225d",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 16,
    "code": "from src.utils.validation.parameter_validators import require_positive, require_finite\n\nclass DoublePendulumParams:\n    def __init__(self, m1: float, m2: float, l1: float, l2: float,\n                 b1: float, b2: float, g: float = 9.81):\n        \"\"\"Initialize physics parameters with validation.\"\"\"\n        # Masses must be positive\n        self.m1 = require_positive(m1, \"cart_mass\")\n        self.m2 = require_positive(m2, \"pendulum1_mass\")\n\n        # Lengths must be positive\n        self.l1 = require_positive(l1, \"pendulum1_length\")\n        self.l2 = require_positive(l2, \"pendulum2_length\")\n\n        # Friction can be zero\n        self.b1 = require_positive(b1, \"joint1_friction\", allow_zero=True)\n        self.b2 = require_positive(b2, \"joint2_friction\", allow_zero=True)\n\n        # Gravity is finite (can be negative for upside-down tests)\n        self.g = require_finite(g, \"gravity\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3315225d"
  },
  {
    "id": "validation_framework_guide_17_51316325",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 17,
    "code": "from src.utils.validation.parameter_validators import require_positive\nfrom src.utils.validation.range_validators import require_probability\n\nclass PSOConfig:\n    def __init__(self, n_particles: int, iters: int,\n                 c1: float, c2: float, w: float):\n        \"\"\"Initialize PSO configuration with validation.\"\"\"\n        # Population and iterations must be positive integers\n        self.n_particles = int(require_positive(n_particles, \"population_size\"))\n        self.iters = int(require_positive(iters, \"max_iterations\"))\n\n        # Acceleration coefficients (typically ~2.0, but allow flexibility)\n        self.c1 = require_in_range(c1, \"cognitive_coefficient\",\n                                   minimum=0.1, maximum=5.0)\n        self.c2 = require_in_range(c2, \"social_coefficient\",\n                                   minimum=0.1, maximum=5.0)\n\n        # Inertia weight (typically 0.4-0.9)\n        self.w = require_in_range(w, \"inertia_weight\",\n                                  minimum=0.1, maximum=1.5)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51316325"
  },
  {
    "id": "validation_framework_guide_18_b5b8fd17",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 18,
    "code": "from src.utils.validation.parameter_validators import require_positive\n\nclass SimulationConfig:\n    def __init__(self, duration: float, dt: float,\n                 atol: float = 1e-8, rtol: float = 1e-6):\n        \"\"\"Initialize simulation configuration with validation.\"\"\"\n        # Time parameters must be positive\n        self.duration = require_positive(duration, \"simulation_duration\")\n        self.dt = require_positive(dt, \"time_step\")\n\n        # Tolerances must be positive and small\n        self.atol = require_positive(atol, \"absolute_tolerance\")\n        self.rtol = require_positive(rtol, \"relative_tolerance\")\n\n        # Sanity check: dt should be much smaller than duration\n        if self.dt >= self.duration:\n            raise ValueError(\n                f\"time_step ({self.dt}) must be smaller than \"\n                f\"simulation_duration ({self.duration})\"\n            )",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5b8fd17"
  },
  {
    "id": "validation_framework_guide_19_a46719ce",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 GOOD: Validate once at construction\nclass Controller:\n    def __init__(self, gains):\n        self.gains = [require_positive(g, f\"gain_{i}\") for i, g in enumerate(gains)]\n\n    def compute_control(self, state):\n        # Use validated self.gains - no repeated validation\n        return self.gains @ state\n\n# \u274c BAD: Repeated validation in hot loop\nclass Controller:\n    def compute_control(self, state, gains):\n        # Validation on every control step - wasteful!\n        validated_gains = [require_positive(g, f\"gain_{i}\") for i, g in enumerate(gains)]\n        return validated_gains @ state",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a46719ce"
  },
  {
    "id": "validation_framework_guide_20_bee16724",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 20,
    "code": "# \u2705 GOOD: Single validation for array\ngains_array = np.array([require_positive(g, f\"gain_{i}\") for i, g in enumerate(gains)])\n\n# \u274c BAD: Repeated validation in inner loops\nfor timestep in range(1000):\n    for i, gain in enumerate(gains):\n        validated = require_positive(gain, f\"gain_{i}\")  # Wasteful!",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bee16724"
  },
  {
    "id": "validation_framework_guide_21_719d336e",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 21,
    "code": "# Good error messages\n\"proportional_gain must be > 0; got -2.5\"\n\"adaptation_rate must be in the interval [0.01, 10.0]; got 15.0\"\n\"twisting_gain_K2 must satisfy K1 > K2 > 0; got K1=4.0, K2=5.0\"\n\n# Bad error messages (avoid)\n\"Invalid value\"                       # Missing parameter name\n\"Error: -2.5\"                         # Missing constraint\n\"Value out of range\"                  # Missing actual bounds",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "719d336e"
  },
  {
    "id": "validation_framework_guide_22_d92b6229",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 22,
    "code": "# Use descriptive names matching mathematical notation\nk_p = require_positive(10.0, \"proportional_gain\")      # Not \"k\", \"param1\"\nlambda_1 = require_positive(5.0, \"surface_gain_joint1\") # Not \"l1\", \"gain\"\ntheta_0 = require_finite(0.1, \"initial_angle_rad\")      # Include units",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d92b6229"
  },
  {
    "id": "validation_framework_guide_23_2274daf7",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 23,
    "code": "# Validate in order of increasing specificity\ngamma = require_finite(value, \"adaptation_rate\")        # 1. Finite\ngamma = require_positive(gamma, \"adaptation_rate\")      # 2. Positive\ngamma = require_in_range(gamma, \"adaptation_rate\",      # 3. Bounded\n                        minimum=0.01, maximum=10.0)\n# 4. Check stability implications (if needed)\nif gamma > 1.0:\n    logging.warning(\"Large adaptation rate may cause instability\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2274daf7"
  },
  {
    "id": "validation_framework_guide_24_7e5e91e3",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 24,
    "code": "import pytest\n\ndef test_controller_parameter_validation():\n    \"\"\"Test that controller rejects invalid parameters.\"\"\"\n\n    # Valid parameters should work\n    controller = PIDController(kp=10.0, ki=2.0, kd=5.0, u_max=50.0)\n    assert controller.kp == 10.0\n\n    # Negative gain should fail\n    with pytest.raises(ValueError, match=\"proportional_gain must be > 0\"):\n        PIDController(kp=-1.0, ki=2.0, kd=5.0, u_max=50.0)\n\n    # Excessive saturation should fail\n    with pytest.raises(ValueError, match=\"control_saturation must be in the interval\"):\n        PIDController(kp=10.0, ki=2.0, kd=5.0, u_max=1000.0)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e5e91e3"
  },
  {
    "id": "validation_framework_guide_25_7bd5b55d",
    "file": "docs\\mathematical_foundations\\validation_framework_guide.md",
    "index": 25,
    "code": "# Enable validation warnings during development\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\ntry:\n    gains = [10.0, -5.0, 8.0, 3.0, 15.0, 2.0]\n    result = validator.validate_gains(gains, \"classical\")\nexcept ValueError as e:\n    # Print detailed context\n    print(f\"Validation failed: {e}\")\n    print(f\"Provided gains: {gains}\")\n    print(f\"Expected bounds: {validator.get_recommended_ranges('classical')}\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7bd5b55d"
  },
  {
    "id": "pso_core_algorithm_guide_1_81cff2dc",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 1,
    "code": "positions = np.random.uniform(\n       low=bounds_lower,\n       high=bounds_upper,\n       size=(population_size, n_dimensions)\n   )",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81cff2dc"
  },
  {
    "id": "pso_core_algorithm_guide_2_60673a36",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 2,
    "code": "# Small random velocities (10% of range)\n   velocity_range = 0.1 * (bounds_upper - bounds_lower)\n   velocities = np.random.uniform(\n       low=-velocity_range,\n       high=velocity_range,\n       size=(population_size, n_dimensions)\n   )",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60673a36"
  },
  {
    "id": "pso_core_algorithm_guide_3_f6b8cbc5",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 3,
    "code": "for i, position in enumerate(positions):\n       fitness[i] = objective_function(position)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6b8cbc5"
  },
  {
    "id": "pso_core_algorithm_guide_4_be3f619a",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 4,
    "code": "personal_best_positions = positions.copy()\n   personal_best_fitness = fitness.copy()\n\n   global_best_idx = np.argmin(fitness)\n   global_best_position = positions[global_best_idx]\n   global_best_fitness = fitness[global_best_idx]",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "be3f619a"
  },
  {
    "id": "pso_core_algorithm_guide_5_6c5f044b",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef update_velocity(self, particle_idx: int) -> np.ndarray:\n    \"\"\"Update velocity for a single particle.\n\n    Args:\n        particle_idx: Index of particle to update\n\n    Returns:\n        Updated velocity vector\n    \"\"\"\n    # Current state\n    position = self.positions[particle_idx]\n    velocity = self.velocities[particle_idx]\n    p_best = self.personal_best_positions[particle_idx]\n    g_best = self.global_best_position\n\n    # Random factors\n    r1 = np.random.random(self.n_dimensions)\n    r2 = np.random.random(self.n_dimensions)\n\n    # Inertia term\n    inertia_term = self.inertia_weight * velocity\n\n    # Cognitive term (personal best attraction)\n    cognitive_term = self.cognitive_weight * r1 * (p_best - position)\n\n    # Social term (global best attraction)\n    social_term = self.social_weight * r2 * (g_best - position)\n\n    # Combined velocity update\n    velocity_new = inertia_term + cognitive_term + social_term\n\n    # Velocity clamping (if enabled)\n    if self.velocity_clamping:\n        v_max = 0.2 * (self.bounds_upper - self.bounds_lower)\n        velocity_new = np.clip(velocity_new, -v_max, v_max)\n\n    return velocity_new",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c5f044b"
  },
  {
    "id": "pso_core_algorithm_guide_6_84ae1d96",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef update_position(self, particle_idx: int) -> np.ndarray:\n    \"\"\"Update position for a single particle.\n\n    Args:\n        particle_idx: Index of particle to update\n\n    Returns:\n        Updated position vector\n    \"\"\"\n    position = self.positions[particle_idx]\n    velocity = self.velocities[particle_idx]\n\n    # Position update\n    position_new = position + velocity\n\n    # Boundary handling (absorbing boundaries)\n    position_new = np.clip(\n        position_new,\n        self.bounds_lower,\n        self.bounds_upper\n    )\n\n    # Reset velocity if boundary hit\n    boundary_hit = (position_new == self.bounds_lower) | (position_new == self.bounds_upper)\n    if np.any(boundary_hit):\n        velocity[boundary_hit] = 0.0\n        self.velocities[particle_idx] = velocity\n\n    return position_new",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84ae1d96"
  },
  {
    "id": "pso_core_algorithm_guide_7_e2e4ae2e",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef evaluate_population(self) -> np.ndarray:\n    \"\"\"Evaluate fitness for all particles.\n\n    Returns:\n        Fitness values for all particles\n    \"\"\"\n    fitness = np.zeros(self.population_size)\n\n    for i, position in enumerate(self.positions):\n        try:\n            # Validate position\n            if not self._is_valid_position(position):\n                fitness[i] = np.inf\n                continue\n\n            # Evaluate objective function\n            fitness[i] = self.objective_function(position)\n\n            # Constraint penalty (if any)\n            if self.has_constraints:\n                penalty = self._compute_constraint_penalty(position)\n                fitness[i] += penalty\n\n        except Exception as e:\n            # Robust error handling\n            self.logger.warning(f\"Fitness evaluation failed for particle {i}: {e}\")\n            fitness[i] = np.inf\n\n    return fitness",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2e4ae2e"
  },
  {
    "id": "pso_core_algorithm_guide_8_0e3e8dab",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef objective_function_smc(gains: np.ndarray) -> float:\n    \"\"\"Fitness function for SMC gain tuning.\n\n    Args:\n        gains: Controller gains [k1, k2, \u03bb1, \u03bb2, K, kd]\n\n    Returns:\n        Fitness value (lower is better)\n    \"\"\"\n    # 1. Create controller\n    controller = create_controller('classical_smc', gains=gains)\n\n    # 2. Run simulation\n    result = simulate(\n        controller=controller,\n        duration=5.0,\n        dt=0.01,\n        initial_state=[0.1, 0.05, 0, 0, 0, 0]\n    )\n\n    # 3. Compute metrics\n    ise = np.trapz(result.states**2, dx=0.01)\n    chattering = np.sum(np.abs(np.diff(result.control))) * 0.01\n    effort = np.trapz(result.control**2, dx=0.01)\n\n    # 4. Multi-objective fitness\n    fitness = 0.5 * ise + 0.3 * chattering + 0.2 * effort\n\n    # 5. Constraint penalty\n    if any(g <= 0 for g in gains[:5]):  # Stability constraint\n        fitness += 1e6\n\n    return fitness",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e3e8dab"
  },
  {
    "id": "pso_core_algorithm_guide_9_32ea05f2",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef update_adaptive_parameters(self, iteration: int) -> None:\n    \"\"\"Update PSO parameters based on iteration progress.\n\n    Args:\n        iteration: Current iteration number\n    \"\"\"\n    if not self.adaptive_weights:\n        return\n\n    # Progress ratio [0, 1]\n    progress = iteration / self.max_iterations\n\n    # Linear decreasing inertia weight\n    self.inertia_weight = (\n        self.initial_inertia -\n        (self.initial_inertia - self.final_inertia) * progress\n    )\n\n    # Time-varying cognitive coefficient\n    self.cognitive_weight = (\n        self.initial_c1 -\n        (self.initial_c1 - self.final_c1) * progress\n    )\n\n    # Time-varying social coefficient\n    self.social_weight = (\n        self.initial_c2 +\n        (self.final_c2 - self.initial_c2) * progress\n    )\n\n    self.logger.debug(\n        f\"Iteration {iteration}: \u03c9={self.inertia_weight:.3f}, \"\n        f\"c1={self.cognitive_weight:.3f}, c2={self.social_weight:.3f}\"\n    )",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32ea05f2"
  },
  {
    "id": "pso_core_algorithm_guide_10_6d246502",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef adaptive_strategy(self, diversity: float) -> None:\n    \"\"\"Adjust parameters based on swarm diversity.\n\n    Args:\n        diversity: Current swarm diversity metric\n    \"\"\"\n    threshold_low = 0.1\n    threshold_high = 0.5\n\n    if diversity < threshold_low:\n        # Low diversity \u2192 Premature convergence risk\n        # Increase exploration\n        self.inertia_weight = min(0.9, self.inertia_weight * 1.1)\n        self.cognitive_weight = min(2.5, self.cognitive_weight * 1.1)\n        self.logger.info(\"Low diversity detected - increasing exploration\")\n\n    elif diversity > threshold_high:\n        # High diversity \u2192 Slow convergence\n        # Increase exploitation\n        self.inertia_weight = max(0.4, self.inertia_weight * 0.9)\n        self.social_weight = min(2.5, self.social_weight * 1.1)\n        self.logger.info(\"High diversity detected - increasing exploitation\")",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d246502"
  },
  {
    "id": "pso_core_algorithm_guide_11_b4711a12",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef check_convergence(self) -> Tuple[bool, str]:\n    \"\"\"Check if optimization has converged.\n\n    Returns:\n        Tuple of (converged flag, reason)\n    \"\"\"\n    if self.iteration_count < 20:\n        return False, \"Insufficient iterations\"\n\n    # Check fitness stagnation\n    recent_fitness = self.fitness_history[-20:]\n    fitness_improvement = max(recent_fitness) - min(recent_fitness)\n\n    if fitness_improvement < self.tolerance:\n        return True, \"Fitness stagnation\"\n\n    # Check diversity collapse\n    if self.diversity_history[-1] < 0.01 * self.diversity_history[0]:\n        if self.global_best_fitness > 10.0:  # Poor fitness\n            return True, \"Premature convergence\"\n\n    # Check iteration limit\n    if self.iteration_count >= self.max_iterations:\n        return True, \"Maximum iterations reached\"\n\n    return False, \"Continuing optimization\"",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4711a12"
  },
  {
    "id": "pso_core_algorithm_guide_12_cbbc1f79",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_diversity(self) -> float:\n    \"\"\"Compute swarm diversity metric.\n\n    Returns:\n        Diversity value (normalized)\n    \"\"\"\n    # Swarm centroid\n    centroid = np.mean(self.positions, axis=0)\n\n    # Average distance from centroid\n    distances = [\n        np.linalg.norm(pos - centroid)\n        for pos in self.positions\n    ]\n    diversity = np.mean(distances)\n\n    # Normalize by search space diagonal\n    diagonal = np.linalg.norm(self.bounds_upper - self.bounds_lower)\n    diversity_normalized = diversity / diagonal\n\n    return diversity_normalized",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cbbc1f79"
  },
  {
    "id": "pso_core_algorithm_guide_13_528ff5ef",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef log_iteration_statistics(self, iteration: int, fitness: np.ndarray) -> None:\n    \"\"\"Log statistics for current iteration.\n\n    Args:\n        iteration: Current iteration number\n        fitness: Fitness values for all particles\n    \"\"\"\n    # Best fitness\n    best_fitness = np.min(fitness)\n    self.fitness_history.append(best_fitness)\n\n    # Average and worst fitness\n    avg_fitness = np.mean(fitness)\n    worst_fitness = np.max(fitness[fitness < np.inf])\n\n    # Diversity\n    diversity = self.compute_diversity()\n    self.diversity_history.append(diversity)\n\n    # Improvement rate\n    if len(self.fitness_history) > 1:\n        improvement = self.fitness_history[-2] - self.fitness_history[-1]\n        improvement_pct = 100 * improvement / self.fitness_history[-2]\n    else:\n        improvement_pct = 0.0\n\n    # Log to console/file\n    self.logger.info(\n        f\"Iteration {iteration:3d}: \"\n        f\"Best={best_fitness:8.4f}, \"\n        f\"Avg={avg_fitness:8.4f}, \"\n        f\"Diversity={diversity:.4f}, \"\n        f\"Improvement={improvement_pct:+.2f}%\"\n    )",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "528ff5ef"
  },
  {
    "id": "pso_core_algorithm_guide_14_818cb5fd",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 14,
    "code": "def plot_convergence(self) -> None:\n    \"\"\"Plot PSO convergence history.\"\"\"\n    import matplotlib.pyplot as plt\n\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n\n    # Fitness trajectory\n    ax1.semilogy(self.fitness_history, 'b-', linewidth=2)\n    ax1.set_xlabel('Iteration')\n    ax1.set_ylabel('Best Fitness (log scale)')\n    ax1.set_title('PSO Convergence')\n    ax1.grid(True)\n\n    # Diversity evolution\n    ax2.plot(self.diversity_history, 'r-', linewidth=2)\n    ax2.set_xlabel('Iteration')\n    ax2.set_ylabel('Swarm Diversity')\n    ax2.set_title('Swarm Diversity Evolution')\n    ax2.grid(True)\n\n    plt.tight_layout()\n    plt.savefig('pso_convergence.png', dpi=150)\n    plt.show()",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "818cb5fd"
  },
  {
    "id": "pso_core_algorithm_guide_15_ca9e6507",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 15,
    "code": "from src.optimization.algorithms.swarm import ParticleSwarmOptimizer\nfrom src.optimization.core.interfaces import ParameterSpace\n\n# Define parameter space\nparam_space = ParameterSpace(\n    bounds=[\n        (0.1, 50.0),  # k1\n        (0.1, 50.0),  # k2\n        (0.1, 50.0),  # \u03bb1\n        (0.1, 50.0),  # \u03bb2\n        (1.0, 200.0), # K\n        (0.0, 50.0),  # kd\n    ],\n    names=['k1', 'k2', 'lambda1', 'lambda2', 'K', 'kd']\n)\n\n# Create optimizer\npso = ParticleSwarmOptimizer(\n    parameter_space=param_space,\n    population_size=30,\n    max_iterations=100,\n    adaptive_weights=True,\n    velocity_clamping=True\n)\n\n# Define objective function\ndef fitness_function(gains):\n    controller = create_controller('classical_smc', gains=gains)\n    result = simulate(controller, duration=5.0)\n    return result.ise + 0.3 * result.chattering\n\n# Run optimization\nresult = pso.optimize(objective_function)\n\n# Results\nprint(f\"Best gains: {result.best_position}\")\nprint(f\"Best fitness: {result.best_fitness}\")\nprint(f\"Iterations: {result.iterations}\")\nprint(f\"Convergence reason: {result.convergence_status}\")",
    "lines": 39,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca9e6507"
  },
  {
    "id": "pso_core_algorithm_guide_16_4f2a7cae",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# Custom PSO configuration for difficult landscape\npso_advanced = ParticleSwarmOptimizer(\n    parameter_space=param_space,\n    population_size=50,              # Larger swarm for multimodality\n    max_iterations=200,              # More iterations\n    inertia_weight=0.9,              # High initial exploration\n    cognitive_weight=2.5,            # Strong personal attraction\n    social_weight=1.5,               # Moderate social attraction\n    adaptive_weights=True,\n    velocity_clamping=True,\n    tolerance=1e-6,                  # Tight convergence\n)\n\n# Custom adaptive strategy\npso_advanced.initial_inertia = 0.9\npso_advanced.final_inertia = 0.3\npso_advanced.initial_c1 = 2.5\npso_advanced.final_c1 = 0.5\npso_advanced.initial_c2 = 1.5\npso_advanced.final_c2 = 3.0\n\nresult = pso_advanced.optimize(fitness_function)",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4f2a7cae"
  },
  {
    "id": "pso_core_algorithm_guide_17_21955283",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_start_pso(n_runs: int = 5) -> dict:\n    \"\"\"Run PSO multiple times and select best result.\n\n    Args:\n        n_runs: Number of independent PSO runs\n\n    Returns:\n        Dictionary with best result and all runs\n    \"\"\"\n    results = []\n\n    for run in range(n_runs):\n        # Create fresh optimizer\n        pso = ParticleSwarmOptimizer(\n            parameter_space=param_space,\n            population_size=30,\n            max_iterations=100,\n            adaptive_weights=True\n        )\n\n        # Run with different random seed\n        np.random.seed(42 + run)\n        result = pso.optimize(fitness_function)\n        results.append(result)\n\n        print(f\"Run {run+1}/{n_runs}: Fitness = {result.best_fitness:.4f}\")\n\n    # Select best run\n    best_result = min(results, key=lambda r: r.best_fitness)\n\n    return {\n        'best_result': best_result,\n        'all_results': results,\n        'mean_fitness': np.mean([r.best_fitness for r in results]),\n        'std_fitness': np.std([r.best_fitness for r in results])\n    }\n\n# Run multi-start optimization\nmulti_result = multi_start_pso(n_runs=5)\nprint(f\"\\nBest overall fitness: {multi_result['best_result'].best_fitness:.4f}\")\nprint(f\"Mean \u00b1 std: {multi_result['mean_fitness']:.4f} \u00b1 {multi_result['std_fitness']:.4f}\")",
    "lines": 44,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21955283"
  },
  {
    "id": "pso_core_algorithm_guide_18_4a8b9bf8",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 18,
    "code": "from multiprocessing import Pool\n\ndef parallel_fitness_evaluation(positions: np.ndarray,\n                                objective_func: Callable) -> np.ndarray:\n    \"\"\"Evaluate fitness in parallel.\n\n    Args:\n        positions: Particle positions (N \u00d7 n)\n        objective_func: Fitness function\n\n    Returns:\n        Fitness values (N,)\n    \"\"\"\n    with Pool(processes=8) as pool:\n        fitness = pool.map(objective_func, positions)\n\n    return np.array(fitness)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a8b9bf8"
  },
  {
    "id": "pso_core_algorithm_guide_19_3c567081",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 19,
    "code": "pso_conservative = {\n    'population_size': 30,\n    'inertia_weight': 0.7298,  # Constriction coefficient\n    'cognitive_weight': 2.05,\n    'social_weight': 2.05,\n    'max_iterations': 100,\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c567081"
  },
  {
    "id": "pso_core_algorithm_guide_20_2e4dd971",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 20,
    "code": "pso_explorative = {\n    'population_size': 50,     # Larger swarm\n    'inertia_weight': 0.9,     # High exploration\n    'cognitive_weight': 2.5,   # Strong personal\n    'social_weight': 1.5,      # Weak social\n    'max_iterations': 150,\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e4dd971"
  },
  {
    "id": "pso_core_algorithm_guide_21_413bc873",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 21,
    "code": "pso_exploitative = {\n    'population_size': 20,     # Small swarm\n    'inertia_weight': 0.4,     # Low exploration\n    'cognitive_weight': 1.5,   # Weak personal\n    'social_weight': 2.5,      # Strong social\n    'max_iterations': 50,\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "413bc873"
  },
  {
    "id": "pso_core_algorithm_guide_22_64d9a86d",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 22,
    "code": "import logging\nlogging.basicConfig(level=logging.INFO)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "64d9a86d"
  },
  {
    "id": "pso_core_algorithm_guide_23_51b71f47",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 23,
    "code": "if diversity < 0.01:\n    print(\"WARNING: Premature convergence detected\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51b71f47"
  },
  {
    "id": "pso_core_algorithm_guide_24_25334fb1",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 24,
    "code": "if np.any(fitness > 1e6):\n    print(f\"WARNING: {np.sum(fitness > 1e6)} constraint violations\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25334fb1"
  },
  {
    "id": "pso_core_algorithm_guide_25_6a81d76c",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 25,
    "code": "plt.scatter(positions[:, 0], positions[:, 1], alpha=0.5)\nplt.scatter(global_best_position[0], global_best_position[1],\n           c='red', marker='*', s=200)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a81d76c"
  },
  {
    "id": "pso_core_algorithm_guide_26_851778f1",
    "file": "docs\\optimization\\pso_core_algorithm_guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# Production-ready PSO configuration\npso_config = {\n    'population_size': 30,\n    'max_iterations': 100,\n    'inertia_weight': 0.7298,\n    'cognitive_weight': 2.05,\n    'social_weight': 2.05,\n    'adaptive_weights': True,\n    'velocity_clamping': True,\n    'tolerance': 1e-6,\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "851778f1"
  },
  {
    "id": "guide_1_269ec14a",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 1,
    "code": "from src.config import load_config\n\nconfig = load_config(\"config.yaml\")\n\n# Configure physics uncertainty\nconfig.physics_uncertainty.n_evals = 5  # Number of perturbed evaluations\nconfig.physics_uncertainty.cart_mass = 0.1  # \u00b110% variation\nconfig.physics_uncertainty.pendulum1_mass = 0.1\nconfig.physics_uncertainty.pendulum2_mass = 0.1",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "269ec14a"
  },
  {
    "id": "guide_2_3ba3ea03",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 2,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers import create_smc_for_pso, SMCType\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Define controller factory\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.CLASSICAL, gains, max_force=100.0)\n\n# Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42,  # Reproducibility\n    instability_penalty_factor=100.0\n)\n\n# Run optimization\nresult = tuner.optimise(\n    iters_override=150,      # Override config iterations\n    n_particles_override=40   # Override config swarm size\n)\n\n# Extract best gains\nbest_gains = result['best_pos']\nbest_cost = result['best_cost']\ncost_history = result['history']['cost']\n\nprint(f\"Best gains: {best_gains}\")\nprint(f\"Best cost: {best_cost:.4f}\")\nprint(f\"Iterations to convergence: {len(cost_history)}\")",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ba3ea03"
  },
  {
    "id": "guide_3_e97d8c5b",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 3,
    "code": "from src.simulation.engines.simulation_runner import run_simulation\nfrom src.controllers import ClassicalSMC\nfrom src.plant.models.simplified import SimplifiedDIPDynamics, SimplifiedDIPConfig\n\n# Setup dynamics\nconfig = SimplifiedDIPConfig.create_default()\ndynamics = SimplifiedDIPDynamics(config)\n\n# Setup controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Initial state\nx0 = [0.0, 0.1, -0.05, 0.0, 0.0, 0.0]  # Small perturbation from upright\n\n# Run simulation\nt_arr, x_arr, u_arr = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=x0\n)\n\n# Analyze results\nprint(f\"Simulated {len(t_arr)} time steps\")\nprint(f\"Final state: {x_arr[-1]}\")\nprint(f\"Max control: {np.max(np.abs(u_arr)):.2f} N\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e97d8c5b"
  },
  {
    "id": "guide_4_4fbfe071",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef fallback_controller(t, x):\n    \"\"\"Simple PD controller as fallback.\"\"\"\n    return -10 * x[0] - 5 * x[3]  # Proportional to cart position and velocity\n\nt_arr, x_arr, u_arr = run_simulation(\n    controller=main_controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=x0,\n    fallback_controller=fallback_controller  # Activated on deadline miss\n)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fbfe071"
  },
  {
    "id": "guide_5_b4712602",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef simulate_system_batch(\n    *,\n    controller_factory: Callable[[np.ndarray], Any],\n    particles: np.ndarray,          # Shape: (B, G) for B particles, G gains\n    sim_time: float,\n    dt: float,\n    u_max: Optional[float] = None,\n    params_list: Optional[List] = None,  # Uncertainty evaluation\n    convergence_tol: Optional[float] = None,  # Early stopping threshold\n    grace_period: float = 0.0\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Returns:\n    -------\n    t : np.ndarray, shape (N+1,)\n        Time vector\n    x_b : np.ndarray, shape (B, N+1, D)\n        State trajectories for B particles\n    u_b : np.ndarray, shape (B, N)\n        Control sequences\n    sigma_b : np.ndarray, shape (B, N)\n        Sliding surface values\n    \"\"\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4712602"
  },
  {
    "id": "guide_6_e8486c7e",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 6,
    "code": "from src.simulation.engines.vector_sim import simulate_system_batch\nfrom src.controllers import create_smc_for_pso, SMCType\nimport numpy as np\n\n# Define controller factory\ndef factory(gains):\n    return create_smc_for_pso(SMCType.CLASSICAL, gains, max_force=100.0)\n\n# Generate particle swarm (10 particles, 6 gains each)\nparticles = np.random.uniform(\n    low=[0.1, 0.1, 0.1, 0.1, 1.0, 0.0],\n    high=[50.0, 50.0, 50.0, 50.0, 200.0, 50.0],\n    size=(10, 6)\n)\n\n# Batch simulate\nt, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=particles,\n    sim_time=5.0,\n    dt=0.01,\n    u_max=100.0\n)\n\n# Analyze batch results\nprint(f\"Batch shape: {x_batch.shape}\")  # (10, 501, 6)\nprint(f\"Time steps: {len(t)}\")\n\n# Compute ISE for each particle\nise = np.sum(x_batch[:, :-1, :3]**2 * dt, axis=(1, 2))\nbest_particle_idx = np.argmin(ise)\nprint(f\"Best particle: {best_particle_idx}, ISE: {ise[best_particle_idx]:.4f}\")",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8486c7e"
  },
  {
    "id": "guide_7_326c77d1",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 7,
    "code": "def _guard_no_nan(state: np.ndarray, step_idx: int) -> None:\n    \"\"\"Raise error if state contains NaN or Inf values.\"\"\"\n    if not np.all(np.isfinite(state)):\n        raise ValueError(f\"Non-finite state detected at step {step_idx}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "326c77d1"
  },
  {
    "id": "guide_8_80ae5a5e",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 8,
    "code": "def _guard_energy(state: np.ndarray, limits: dict) -> None:\n    \"\"\"Verify total energy within specified limits.\"\"\"\n    energy = np.sum(state**2, axis=-1)\n    max_energy = limits.get('max', np.inf)\n    if np.any(energy > max_energy):\n        raise ValueError(f\"Energy {energy.max():.2f} exceeds limit {max_energy:.2f}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80ae5a5e"
  },
  {
    "id": "guide_9_f537de8f",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 9,
    "code": "def _guard_bounds(state: np.ndarray, bounds: Tuple, t: float) -> None:\n    \"\"\"Verify state within per-dimension bounds.\"\"\"\n    lower, upper = bounds\n    if lower is not None and np.any(state < lower):\n        raise ValueError(f\"State below lower bound at t={t:.3f}\")\n    if upper is not None and np.any(state > upper):\n        raise ValueError(f\"State above upper bound at t={t:.3f}\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f537de8f"
  },
  {
    "id": "guide_10_2c4f9d72",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 10,
    "code": "t, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=particles,\n    sim_time=10.0,\n    dt=0.01,\n    convergence_tol=0.001,  # Stop when max(|\u03c3|) < 0.001\n    grace_period=1.0        # Wait 1 second before checking\n)\n\nprint(f\"Converged early: {len(t)} steps < {int(10.0/0.01)} max steps\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c4f9d72"
  },
  {
    "id": "guide_11_76ec42ae",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 11,
    "code": "from src.config import load_config\n\n# Load and validate configuration\nconfig = load_config(\"config.yaml\")\n\n# Access with full IDE autocomplete and type checking\ncart_mass: float = config.physics.cart_mass\nduration: float = config.simulation.duration\nn_particles: int = config.pso.n_particles\n\n# Pydantic prevents typos and type errors\ntry:\n    invalid = config.simulation.durration  # AttributeError\nexcept AttributeError:\n    print(\"Typo caught at runtime!\")\n\ntry:\n    config.physics.cart_mass = \"not a number\"  # ValidationError\nexcept Exception:\n    print(\"Type error prevented!\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76ec42ae"
  },
  {
    "id": "guide_12_b83989e0",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 12,
    "code": "@field_validator(\"cart_mass\", \"pendulum1_mass\", \"pendulum2_mass\")\ndef _must_be_strictly_positive(cls, v: float, info) -> float:\n    if v <= 0.0:\n        raise ValueError(f\"{info.field_name} must be > 0 (conservation of mass)\")\n    return v",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b83989e0"
  },
  {
    "id": "guide_13_70d3bfa1",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 13,
    "code": "@model_validator(mode=\"after\")\ndef _validate_com_within_length(self) -> \"PhysicsConfig\":\n    if self.pendulum1_com >= self.pendulum1_length:\n        raise ValueError(\n            f\"pendulum1_com must be < pendulum1_length (geometric requirement)\"\n        )\n    return self",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70d3bfa1"
  },
  {
    "id": "guide_14_5b08ad41",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 14,
    "code": "@model_validator(mode=\"after\")\ndef _duration_at_least_dt(self):\n    if self.duration < self.dt:\n        raise ValueError(\"duration must be >= dt (temporal consistency)\")\n    return self",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b08ad41"
  },
  {
    "id": "guide_15_b1d12000",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 15,
    "code": "from src.config import load_config\n\n# Load with unknown field rejection (strict mode)\nconfig = load_config(\"config.yaml\", allow_unknown=False)\n\n# Load with unknown field warning (permissive mode)\nconfig = load_config(\"config.yaml\", allow_unknown=True)\n\n# Access nested configuration\npso_cfg = config.pso\nphysics_cfg = config.physics\nsim_cfg = config.simulation",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1d12000"
  },
  {
    "id": "guide_16_6c83a47e",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 16,
    "code": "from src.simulation.core.simulation_context import SimulationContext\n\n# Initialize context with configuration\ncontext = SimulationContext(\"config.yaml\")\n\n# Access dynamics model\ndynamics = context.get_dynamics_model()\n\n# Create controller\ncontroller = context.create_controller(name=\"classical_smc\")\n\n# Create simulation engine\nengine = context.create_simulation_engine(engine_type=\"sequential\")\n\n# Register custom components\nfrom src.utils.monitoring import PerformanceMonitor\nmonitor = PerformanceMonitor()\ncontext.register_component(\"performance_monitor\", monitor)\n\n# Retrieve registered component\nmonitor = context.get_component(\"performance_monitor\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c83a47e"
  },
  {
    "id": "guide_17_535afd22",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 17,
    "code": "# High accuracy (slow)\nconfig.simulation.dt = 0.001  # 1 ms timestep\n\n# Balanced (recommended)\nconfig.simulation.dt = 0.01   # 10 ms timestep\n\n# Fast prototyping (low accuracy)\nconfig.simulation.dt = 0.05   # 50 ms timestep",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "535afd22"
  },
  {
    "id": "guide_18_d38f346a",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 18,
    "code": "from benchmarks.integration import RK4Integrator\nfrom src.plant.models.simplified import SimplifiedDIPDynamics\n\ndynamics = SimplifiedDIPDynamics(config)\nintegrator = RK4Integrator(dynamics)\n\nresult = integrator.integrate(\n    x0=initial_state,\n    sim_time=5.0,\n    dt=0.01,\n    controller=controller\n)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d38f346a"
  },
  {
    "id": "guide_19_467959b7",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 19,
    "code": "from benchmarks.integration import AdaptiveRK45Integrator\n\nintegrator = AdaptiveRK45Integrator(dynamics)\nresult = integrator.integrate(\n    x0=initial_state,\n    sim_time=5.0,\n    rtol=1e-8,  # Relative tolerance\n    atol=1e-10, # Absolute tolerance\n    controller=controller\n)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "467959b7"
  },
  {
    "id": "guide_20_ae55feaf",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 20,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers import create_smc_for_pso, SMCType\nfrom src.config import load_config\nimport numpy as np\nimport json\n\n# 1. Load configuration\nconfig = load_config(\"config.yaml\")\n\n# 2. Configure PSO for classical SMC\nconfig.pso.n_particles = 40\nconfig.pso.iters = 150\nconfig.pso.bounds.classical_smc.min = [0.1, 0.1, 0.1, 0.1, 1.0, 0.0]\nconfig.pso.bounds.classical_smc.max = [50.0, 50.0, 50.0, 50.0, 200.0, 50.0]\n\n# 3. Define controller factory\ndef controller_factory(gains):\n    return create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains,\n        max_force=100.0,\n        boundary_layer=0.01,\n        dt=0.01\n    )\n\n# 4. Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42,\n    instability_penalty_factor=100.0\n)\n\n# 5. Run optimization\nresult = tuner.optimise()\n\n# 6. Extract and save results\nbest_gains = result['best_pos']\nbest_cost = result['best_cost']\ncost_history = result['history']['cost']\n\n# 7. Save optimized gains\ngains_data = {\n    \"controller_type\": \"classical_smc\",\n    \"gains\": best_gains.tolist(),\n    \"cost\": float(best_cost),\n    \"optimization_iterations\": len(cost_history),\n    \"config\": {\n        \"n_particles\": config.pso.n_particles,\n        \"iters\": config.pso.iters,\n        \"seed\": 42\n    }\n}\n\nwith open(\"optimized_gains_classical.json\", \"w\") as f:\n    json.dump(gains_data, f, indent=2)\n\n# 8. Validate optimized controller\nfrom src.simulation.engines.simulation_runner import run_simulation\nfrom src.plant.models.simplified import SimplifiedDIPDynamics\n\ncontroller = controller_factory(best_gains)\ndynamics = SimplifiedDIPDynamics(config.physics)\nx0 = [0.0, 0.1, -0.05, 0.0, 0.0, 0.0]\n\nt, x, u = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    sim_time=5.0,\n    dt=0.01,\n    initial_state=x0\n)\n\nprint(f\"Best gains: {best_gains}\")\nprint(f\"Best cost: {best_cost:.4f}\")\nprint(f\"Final state error: {np.linalg.norm(x[-1][:3]):.4f}\")",
    "lines": 76,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae55feaf"
  },
  {
    "id": "guide_21_9ca48211",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 21,
    "code": "from src.simulation.engines.vector_sim import simulate_system_batch\nfrom src.controllers import create_smc_for_pso, SMCType\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define controller variants\ncontroller_configs = [\n    {\"type\": SMCType.CLASSICAL, \"gains\": [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]},\n    {\"type\": SMCType.CLASSICAL, \"gains\": [20.0, 15.0, 25.0, 20.0, 80.0, 10.0]},\n    {\"type\": SMCType.CLASSICAL, \"gains\": [5.0, 4.0, 10.0, 8.0, 30.0, 2.0]},\n]\n\n# Create factory for each configuration\ndef make_factory(cfg):\n    def factory(gains):\n        return create_smc_for_pso(cfg[\"type\"], gains, max_force=100.0)\n    return factory\n\n# Prepare particles array\nparticles = np.array([cfg[\"gains\"] for cfg in controller_configs])\n\n# Batch simulate\nfactory = make_factory(controller_configs[0])\nt, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=particles,\n    sim_time=5.0,\n    dt=0.01,\n    u_max=100.0\n)\n\n# Compute metrics for each controller\nfor i, cfg in enumerate(controller_configs):\n    ise = np.sum(x_batch[i, :-1, :3]**2 * 0.01, axis=1).sum()\n    u_rms = np.sqrt(np.mean(u_batch[i]**2))\n    settling_time = np.argmax(np.all(np.abs(x_batch[i, :, :3]) < 0.01, axis=1)) * 0.01\n\n    print(f\"Controller {i+1}:\")\n    print(f\"  ISE: {ise:.4f}\")\n    print(f\"  RMS Control: {u_rms:.2f} N\")\n    print(f\"  Settling Time: {settling_time:.2f} s\")\n    print()\n\n# Plot comparison\nfig, axes = plt.subplots(3, 1, figsize=(10, 8))\nfor i in range(len(controller_configs)):\n    axes[0].plot(t, x_batch[i, :, 1], label=f\"Controller {i+1}\")\n    axes[1].plot(t, x_batch[i, :, 2])\n    axes[2].plot(t[:-1], u_batch[i])\n\naxes[0].set_ylabel(\"\u03b8\u2081 (rad)\")\naxes[1].set_ylabel(\"\u03b8\u2082 (rad)\")\naxes[2].set_ylabel(\"Force (N)\")\naxes[2].set_xlabel(\"Time (s)\")\naxes[0].legend()\naxes[0].grid(True)\naxes[1].grid(True)\naxes[2].grid(True)\nplt.tight_layout()\nplt.savefig(\"controller_comparison.png\", dpi=150)",
    "lines": 60,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ca48211"
  },
  {
    "id": "guide_22_e4e8eaa0",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 22,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\n\n# Configure uncertainty evaluation\nconfig.physics_uncertainty = {\n    \"n_evals\": 10,  # 10 perturbed physics models\n    \"cart_mass\": 0.15,          # \u00b115% variation\n    \"pendulum1_mass\": 0.15,\n    \"pendulum2_mass\": 0.15,\n    \"pendulum1_length\": 0.05,   # \u00b15% variation\n    \"pendulum2_length\": 0.05,\n    \"gravity\": 0.01,            # \u00b11% variation (altitude/latitude)\n    \"cart_friction\": 0.20,      # \u00b120% variation\n    \"joint1_friction\": 0.20,\n    \"joint2_friction\": 0.20,\n}\n\n# Define controller factory\nfrom src.controllers import create_smc_for_pso, SMCType\n\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.ADAPTIVE, gains, max_force=100.0)\n\n# Initialize tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42\n)\n\n# Run robust optimization\nresult = tuner.optimise()\n\nprint(f\"Robust gains optimized under {config.physics_uncertainty.n_evals} uncertainty scenarios\")\nprint(f\"Best robust cost: {result['best_cost']:.4f}\")\nprint(f\"Optimized gains: {result['best_pos']}\")",
    "lines": 38,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e4e8eaa0"
  },
  {
    "id": "guide_23_f759690b",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 23,
    "code": "# MEMORY OPTIMIZATION: asarray creates view when input is already ndarray\nx = np.asarray(initial_state, dtype=float)  # View if already float64 ndarray\n\n# Unnecessary defensive copy eliminated\nx_curr = x0  # No copy needed, immediately overwritten",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f759690b"
  },
  {
    "id": "guide_24_b81df4e8",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 24,
    "code": "# MEMORY OPTIMIZATION: broadcast_to returns view\ninit_b = np.broadcast_to(init, (B, init.shape[0]))\n\n# Only copy when writeable buffer needed\ninit_b = init_b.copy()",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b81df4e8"
  },
  {
    "id": "guide_25_942bd18a",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 25,
    "code": "from src.plant.models.simplified import SimplifiedDIPDynamics\n\ndynamics = SimplifiedDIPDynamics(\n    config,\n    enable_fast_mode=True,    # Use Numba JIT compilation\n    enable_monitoring=False   # Disable diagnostics for speed\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "942bd18a"
  },
  {
    "id": "guide_26_f0689f3c",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# FAST: Vectorized batch evaluation\nt, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=gain_array,\n    sim_time=5.0,\n    dt=0.01\n)\n\n# SLOW: Sequential loop (10-100\u00d7 slower)\nfor i, gains in enumerate(gain_array):\n    controller = factory(gains)\n    t, x, u = run_simulation(controller, dynamics, 5.0, 0.01, x0)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0689f3c"
  },
  {
    "id": "guide_27_8a8d623e",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 27,
    "code": "t, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=particles,\n    sim_time=10.0,\n    dt=0.01,\n    convergence_tol=0.001,  # Stop when converged\n    grace_period=1.0        # Minimum settling time\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a8d623e"
  },
  {
    "id": "guide_28_f0a33223",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 28,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOTuner:\n    \"\"\"High-throughput, vectorized tuner for sliding-mode controllers.\"\"\"\n\n    def __init__(\n        self,\n        controller_factory: Callable[[np.ndarray], Any],\n        config: Union[ConfigSchema, str, Path],\n        seed: Optional[int] = None,\n        rng: Optional[np.random.Generator] = None,\n        *,\n        instability_penalty_factor: float = 100.0\n    ):\n        \"\"\"\n        Initialize PSO tuner.\n\n        Parameters\n        ----------\n        controller_factory : callable\n            Function returning controller given gain vector\n        config : ConfigSchema or path\n            Configuration object or path to YAML\n        seed : int, optional\n            Random seed for reproducibility\n        rng : np.random.Generator, optional\n            External PRNG (overrides seed if provided)\n        instability_penalty_factor : float\n            Scale factor for instability penalties (default: 100.0)\n        \"\"\"\n\n    def optimise(\n        self,\n        *args,\n        iters_override: Optional[int] = None,\n        n_particles_override: Optional[int] = None,\n        options_override: Optional[Dict[str, float]] = None,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Run PSO optimization.\n\n        Parameters\n        ----------\n        iters_override : int, optional\n            Override config iterations\n        n_particles_override : int, optional\n            Override config swarm size\n        options_override : dict, optional\n            Override PSO hyperparameters (c1, c2, w)\n\n        Returns\n        -------\n        dict\n            {\n                \"best_cost\": float,\n                \"best_pos\": np.ndarray,\n                \"history\": {\"cost\": np.ndarray, \"pos\": np.ndarray}\n            }\n        \"\"\"",
    "lines": 61,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0a33223"
  },
  {
    "id": "guide_29_350aeb15",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\ndef run_simulation(\n    *,\n    controller: Any,\n    dynamics_model: Any,\n    sim_time: float,\n    dt: float,\n    initial_state: Any,\n    u_max: Optional[float] = None,\n    seed: Optional[int] = None,\n    rng: Optional[np.random.Generator] = None,\n    latency_margin: Optional[float] = None,\n    fallback_controller: Optional[Callable[[float, np.ndarray], float]] = None,\n    **kwargs\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Simulate single controller trajectory using Euler integration.\n\n    Parameters\n    ----------\n    controller : Any\n        Controller object (compute_control or __call__ interface)\n    dynamics_model : Any\n        Dynamics model with step(state, u, dt) method\n    sim_time : float\n        Total simulation duration (seconds)\n    dt : float\n        Integration timestep (seconds), must be > 0\n    initial_state : array-like\n        Initial state vector\n    u_max : float, optional\n        Control saturation limit\n    fallback_controller : callable, optional\n        Fallback controller for deadline misses\n\n    Returns\n    -------\n    t_arr : np.ndarray, shape (N+1,)\n        Time vector\n    x_arr : np.ndarray, shape (N+1, D)\n        State trajectory\n    u_arr : np.ndarray, shape (N,)\n        Control sequence\n    \"\"\"",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "350aeb15"
  },
  {
    "id": "guide_30_616a4375",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\ndef simulate_system_batch(\n    *,\n    controller_factory: Callable[[np.ndarray], Any],\n    particles: np.ndarray,\n    sim_time: float,\n    dt: float,\n    u_max: Optional[float] = None,\n    params_list: Optional[List] = None,\n    convergence_tol: Optional[float] = None,\n    grace_period: float = 0.0,\n    **kwargs\n) -> Union[\n    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray],\n    List[Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]\n]:\n    \"\"\"\n    Vectorized batch simulation of multiple controllers.\n\n    Parameters\n    ----------\n    controller_factory : callable\n        Factory function: controller = factory(gains)\n    particles : np.ndarray, shape (B, G)\n        Gain vectors for B particles\n    sim_time : float\n        Total simulation duration\n    dt : float\n        Integration timestep\n    u_max : float, optional\n        Control saturation limit\n    params_list : list, optional\n        List of physics parameter objects for uncertainty evaluation\n    convergence_tol : float, optional\n        Early stopping threshold for max(|\u03c3|)\n    grace_period : float\n        Duration before convergence checking begins\n\n    Returns\n    -------\n    If params_list is None:\n        (t, x_batch, u_batch, sigma_batch)\n    If params_list is provided:\n        List of (t, x_batch, u_batch, sigma_batch) tuples\n\n    Notes\n    -----\n    - t: shape (N+1,)\n    - x_batch: shape (B, N+1, D)\n    - u_batch: shape (B, N)\n    - sigma_batch: shape (B, N)\n    \"\"\"",
    "lines": 54,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "616a4375"
  },
  {
    "id": "guide_31_9884b70d",
    "file": "docs\\optimization_simulation\\guide.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimulationContext:\n    \"\"\"Enhanced simulation context with framework integration.\"\"\"\n\n    def __init__(self, config_path: str = \"config.yaml\"):\n        \"\"\"Initialize simulation context.\"\"\"\n\n    def get_dynamics_model(self) -> Any:\n        \"\"\"Return initialized dynamics model.\"\"\"\n\n    def get_config(self) -> ConfigSchema:\n        \"\"\"Return validated configuration.\"\"\"\n\n    def create_controller(\n        self,\n        name: Optional[str] = None,\n        gains: Optional[List[float]] = None\n    ) -> Any:\n        \"\"\"Create controller using configuration.\"\"\"\n\n    def create_simulation_engine(\n        self,\n        engine_type: str = \"sequential\"\n    ) -> SimulationEngine:\n        \"\"\"\n        Create simulation engine.\n\n        Parameters\n        ----------\n        engine_type : str\n            Engine type: 'sequential', 'batch', 'parallel', 'real_time'\n        \"\"\"\n\n    def register_component(self, name: str, component: Any) -> None:\n        \"\"\"Register framework component.\"\"\"\n\n    def get_component(self, name: str) -> Optional[Any]:\n        \"\"\"Get registered component.\"\"\"",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9884b70d"
  },
  {
    "id": "index_1_49fa0afc",
    "file": "docs\\optimization_simulation\\index.md",
    "index": 1,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers import create_smc_for_pso, SMCType\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Define controller factory\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.CLASSICAL, gains, max_force=100.0)\n\n# Initialize PSO tuner\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    seed=42\n)\n\n# Run optimization\nresult = tuner.optimise()\n\n# Extract best gains\nbest_gains = result['best_pos']\nbest_cost = result['best_cost']",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49fa0afc"
  },
  {
    "id": "index_2_5e5ccdc2",
    "file": "docs\\optimization_simulation\\index.md",
    "index": 2,
    "code": "from src.simulation.engines.vector_sim import simulate_system_batch\nimport numpy as np\n\n# Define controller configurations\nparticles = np.array([\n    [10.0, 8.0, 15.0, 12.0, 50.0, 5.0],   # Conservative gains\n    [20.0, 15.0, 25.0, 20.0, 80.0, 10.0],  # Aggressive gains\n    [5.0, 4.0, 10.0, 8.0, 30.0, 2.0],      # Gentle gains\n])\n\n# Batch simulate\nt, x_batch, u_batch, sigma_batch = simulate_system_batch(\n    controller_factory=factory,\n    particles=particles,\n    sim_time=5.0,\n    dt=0.01,\n    u_max=100.0\n)\n\n# Compute metrics\nfor i in range(len(particles)):\n    ise = np.sum(x_batch[i, :-1, :3]**2 * 0.01, axis=1).sum()\n    print(f\"Controller {i+1} ISE: {ise:.4f}\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e5ccdc2"
  },
  {
    "id": "index_1_d0e69b42",
    "file": "docs\\plant\\index.md",
    "index": 1,
    "code": "from src.plant.models.simplified import SimplifiedDIPDynamics, SimplifiedDIPConfig\n\n# Create configuration\nconfig = SimplifiedDIPConfig.create_default()\n\n# Initialize dynamics\ndynamics = SimplifiedDIPDynamics(\n    config,\n    enable_fast_mode=True,\n    enable_monitoring=True\n)\n\n# Compute dynamics\nstate = [0.1, 0.05, -0.03, 0.0, 0.0, 0.0]\ncontrol = [5.0]\nresult = dynamics.compute_dynamics(state, control)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0e69b42"
  },
  {
    "id": "index_2_2c16a2e1",
    "file": "docs\\plant\\index.md",
    "index": 2,
    "code": "from scipy.integrate import solve_ivp\n\ndef dynamics_ode(t, state):\n    control = [0.0]\n    result = dynamics.compute_dynamics(state, control, time=t)\n    return result.state_derivative if result.success else np.zeros(6)\n\n# Integrate\nsol = solve_ivp(dynamics_ode, t_span=[0, 5], y0=state0, method='RK45', rtol=1e-8)\n\n# Check energy conservation\nE0 = dynamics.compute_total_energy(state0)\nE_final = dynamics.compute_total_energy(sol.y[:, -1])\nenergy_drift = abs(E_final - E0) / E0\nprint(f\"Energy drift: {energy_drift:.2%}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c16a2e1"
  },
  {
    "id": "models_guide_1_5b01e080",
    "file": "docs\\plant\\models_guide.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom typing import Protocol, Tuple\nimport numpy as np\n\nclass DynamicsModel(Protocol):\n    \"\"\"Protocol for plant dynamics models.\"\"\"\n\n    def compute_dynamics(\n        self,\n        state: np.ndarray,\n        control_input: np.ndarray,\n        time: float = 0.0,\n        **kwargs\n    ) -> DynamicsResult:\n        \"\"\"Compute system dynamics at given state and input.\"\"\"\n        ...\n\n    def get_physics_matrices(\n        self,\n        state: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Get M, C, G matrices at current state.\"\"\"\n        ...\n\n    def validate_state(self, state: np.ndarray) -> bool:\n        \"\"\"Validate state vector format and bounds.\"\"\"\n        ...",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b01e080"
  },
  {
    "id": "models_guide_2_27042f23",
    "file": "docs\\plant\\models_guide.md",
    "index": 2,
    "code": "from typing import NamedTuple, Dict, Any\n\nclass DynamicsResult(NamedTuple):\n    \"\"\"Result of dynamics computation.\"\"\"\n    state_derivative: np.ndarray    # dx/dt vector\n    success: bool                   # Computation succeeded\n    info: Dict[str, Any]           # Diagnostics and metadata",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27042f23"
  },
  {
    "id": "models_guide_3_6a2d2b17",
    "file": "docs\\plant\\models_guide.md",
    "index": 3,
    "code": "from src.plant.models.simplified import SimplifiedDIPDynamics, SimplifiedDIPConfig\n\n# Create configuration\nconfig = SimplifiedDIPConfig.create_default()\n\n# Initialize dynamics model\ndynamics = SimplifiedDIPDynamics(\n    config=config,\n    enable_fast_mode=True,      # Use Numba JIT compilation\n    enable_monitoring=True       # Track performance metrics\n)\n\n# Compute dynamics\nstate = np.array([0.1, 0.05, -0.03, 0.0, 0.0, 0.0])\ncontrol = np.array([5.0])\n\nresult = dynamics.compute_dynamics(state, control)\n\nif result.success:\n    state_derivative = result.state_derivative\n    energy = result.info['total_energy']\n    print(f\"Energy: {energy:.4f} J\")\nelse:\n    print(f\"Error: {result.info['failure_reason']}\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a2d2b17"
  },
  {
    "id": "models_guide_4_c2c7532b",
    "file": "docs\\plant\\models_guide.md",
    "index": 4,
    "code": "from src.plant.models.full import FullDIPDynamics, FullDIPConfig\n\n# Create high-fidelity configuration\nconfig = FullDIPConfig.create_default()\n\n# Initialize with comprehensive monitoring\ndynamics = FullDIPDynamics(\n    config=config,\n    enable_monitoring=True,\n    enable_validation=True\n)\n\n# Compute dynamics with wind effects\nwind_velocity = np.array([0.5, 0.0])  # 0.5 m/s horizontal wind\nresult = dynamics.compute_dynamics(\n    state, control, time=1.5,\n    wind_velocity=wind_velocity\n)\n\n# Access detailed diagnostics\nif result.success:\n    print(f\"Total energy: {result.info['total_energy']:.4f} J\")\n    print(f\"Cart kinetic: {result.info['kinetic_cart']:.4f} J\")\n    print(f\"Friction forces: {result.info['friction_forces']}\")\n    print(f\"Aerodynamic forces: {result.info['aerodynamic_forces']}\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2c7532b"
  },
  {
    "id": "models_guide_5_d9bbdee1",
    "file": "docs\\plant\\models_guide.md",
    "index": 5,
    "code": "from src.plant.models.lowrank import LowRankDIPDynamics, LowRankDIPConfig\n\n# Create lightweight configuration\nconfig = LowRankDIPConfig.create_default()\n\n# Initialize for fast computation\ndynamics = LowRankDIPDynamics(\n    config=config,\n    enable_monitoring=False,    # Disable for maximum speed\n    enable_validation=True\n)\n\n# Use linearized dynamics for control design\nA, B = dynamics.get_linearized_system(equilibrium_point=\"upright\")\n\n# Or compute full nonlinear dynamics\nresult = dynamics.compute_dynamics(state, control)\n\n# Simple Euler integration step\nnext_state = dynamics.step(state, control, dt=0.01)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9bbdee1"
  },
  {
    "id": "models_guide_6_66d1d704",
    "file": "docs\\plant\\models_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SimplifiedDIPConfig:\n    \"\"\"Type-safe configuration for simplified DIP.\"\"\"\n\n    # Physical parameters - masses (kg)\n    cart_mass: float\n    pendulum1_mass: float\n    pendulum2_mass: float\n\n    # Lengths (m)\n    pendulum1_length: float\n    pendulum2_length: float\n    pendulum1_com: float          # Center of mass distance\n    pendulum2_com: float\n\n    # Inertias (kg\u22c5m\u00b2)\n    pendulum1_inertia: float\n    pendulum2_inertia: float\n\n    # Environmental\n    gravity: float = 9.81\n\n    # Friction (N\u22c5s/m or N\u22c5m\u22c5s/rad)\n    cart_friction: float = 0.1\n    joint1_friction: float = 0.01\n    joint2_friction: float = 0.01\n\n    # Numerical stability\n    regularization_alpha: float = 1e-4\n    max_condition_number: float = 1e14\n    min_regularization: float = 1e-10",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "66d1d704"
  },
  {
    "id": "models_guide_7_6bc32752",
    "file": "docs\\plant\\models_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Default parameters (balanced for general use)\nconfig = SimplifiedDIPConfig.create_default()\n\n# Benchmark parameters (standardized for comparisons)\nconfig = SimplifiedDIPConfig.create_benchmark()\n\n# Lightweight parameters (optimized for speed)\nconfig = SimplifiedDIPConfig.create_lightweight()\n\n# Custom parameters\nconfig = SimplifiedDIPConfig(\n    cart_mass=1.2,\n    pendulum1_mass=0.15,\n    pendulum2_mass=0.15,\n    # ... all required fields\n)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6bc32752"
  },
  {
    "id": "models_guide_8_dd1c6aee",
    "file": "docs\\plant\\models_guide.md",
    "index": 8,
    "code": "# Total system mass\ntotal_mass = config.get_total_mass()\n\n# Characteristic length (max pendulum length)\nL_char = config.get_characteristic_length()\n\n# Characteristic time (natural period)\nT_char = config.get_characteristic_time()  # sqrt(L/g)\n\n# Natural frequency estimate\nomega_n = config.estimate_natural_frequency()  # 1/T_char",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd1c6aee"
  },
  {
    "id": "models_guide_9_796f9bcd",
    "file": "docs\\plant\\models_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimplifiedPhysicsComputer:\n    \"\"\"Simplified physics computation for DIP.\"\"\"\n\n    def __init__(self, config: SimplifiedDIPConfig):\n        self.config = config\n\n        # Physics matrix computers\n        self.full_matrices = DIPPhysicsMatrices(config)\n        self.simplified_matrices = SimplifiedDIPPhysicsMatrices(config)\n\n        # Numerical stability\n        self.regularizer = AdaptiveRegularizer(config)\n        self.matrix_inverter = MatrixInverter(self.regularizer)\n\n        # Performance flags\n        self.use_simplified_inertia = True\n        self.cache_matrices = False",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "796f9bcd"
  },
  {
    "id": "models_guide_10_0e9ba108",
    "file": "docs\\plant\\models_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_dynamics_rhs(\n    self,\n    state: np.ndarray,\n    control_input: np.ndarray\n) -> np.ndarray:\n    \"\"\"Compute \u1e8d = M\u207b\u00b9(u - C\u00b7\u1e8b - G).\"\"\"\n\n    # Extract state components\n    position = state[:3]   # [x, theta1, theta2]\n    velocity = state[3:]   # [x_dot, theta1_dot, theta2_dot]\n\n    # Compute physics matrices\n    M, C, G = self.get_physics_matrices(state)\n\n    # Control vector (force on cart only)\n    u = np.array([control_input[0], 0.0, 0.0])\n\n    # Forcing term\n    forcing = u - C @ velocity - G\n\n    # Solve for accelerations: M\u00b7q\u0308 = forcing\n    accelerations = self.matrix_inverter.solve_linear_system(M, forcing)\n\n    # Construct state derivative\n    return np.concatenate([velocity, accelerations])",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e9ba108"
  },
  {
    "id": "models_guide_11_9c803b71",
    "file": "docs\\plant\\models_guide.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nfrom numba import njit\n\n@njit\ndef compute_simplified_dynamics_numba(\n    state, u,\n    m0, m1, m2,           # Masses\n    L1, L2, Lc1, Lc2,     # Lengths\n    I1, I2,               # Inertias\n    g, c0, c1, c2,        # Gravity and friction\n    reg_alpha, min_reg    # Regularization\n):\n    \"\"\"JIT-compiled dynamics computation.\"\"\"\n    # Inline matrix computation and solution\n    # ... optimized implementation ...\n    return state_derivative",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c803b71"
  },
  {
    "id": "models_guide_12_ace95a54",
    "file": "docs\\plant\\models_guide.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass AdaptiveRegularizer:\n    \"\"\"Adaptive regularization for matrix conditioning.\"\"\"\n\n    def compute_regularization(self, matrix: np.ndarray) -> float:\n        \"\"\"Compute adaptive regularization parameter.\"\"\"\n\n        # Compute condition number\n        cond_num = np.linalg.cond(matrix)\n\n        if cond_num > self.max_condition_number:\n            # Adaptive regularization scaled by condition number\n            alpha = self.regularization_alpha * (cond_num / self.max_condition_number)\n            return max(alpha, self.min_regularization)\n        else:\n            # Use fixed minimal regularization\n            return self.min_regularization",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ace95a54"
  },
  {
    "id": "models_guide_13_4ef6268e",
    "file": "docs\\plant\\models_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass MatrixInverter:\n    \"\"\"Robust matrix inversion with regularization.\"\"\"\n\n    def solve_linear_system(\n        self,\n        A: np.ndarray,\n        b: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"Solve Ax = b with adaptive regularization.\"\"\"\n\n        try:\n            # Attempt direct solution\n            return np.linalg.solve(A, b)\n\n        except np.linalg.LinAlgError:\n            # Apply adaptive regularization\n            alpha = self.regularizer.compute_regularization(A)\n            A_reg = A + alpha * np.eye(A.shape[0])\n\n            try:\n                return np.linalg.solve(A_reg, b)\n            except np.linalg.LinAlgError:\n                # Use pseudo-inverse as last resort\n                return np.linalg.lstsq(A_reg, b, rcond=None)[0]",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4ef6268e"
  },
  {
    "id": "models_guide_14_18b6ffed",
    "file": "docs\\plant\\models_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass NumericalStabilityMonitor:\n    \"\"\"Monitor numerical stability statistics.\"\"\"\n\n    def record_inversion(\n        self,\n        condition_number: float,\n        was_regularized: bool,\n        failed: bool\n    ) -> None:\n        \"\"\"Record matrix inversion event.\"\"\"\n        self.condition_numbers.append(condition_number)\n        self.regularization_count += int(was_regularized)\n        self.failure_count += int(failed)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "18b6ffed"
  },
  {
    "id": "models_guide_15_ef91e863",
    "file": "docs\\plant\\models_guide.md",
    "index": 15,
    "code": "stats = dynamics.get_monitoring_stats()\nprint(f\"Average condition number: {stats['avg_condition_number']:.2e}\")\nprint(f\"Regularization rate: {stats['regularization_rate']:.2%}\")\nprint(f\"Failure rate: {stats['failure_rate']:.2%}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef91e863"
  },
  {
    "id": "models_guide_16_86466974",
    "file": "docs\\plant\\models_guide.md",
    "index": 16,
    "code": "# Compute energy at initial and current states\nE_initial = dynamics.compute_total_energy(state_initial)\nE_current = dynamics.compute_total_energy(state_current)\n\n# Energy conservation error\nenergy_drift = abs(E_current - E_initial) / E_initial\n\n# Validation threshold (accounts for numerical integration error)\nassert energy_drift < tolerance, f\"Energy drift: {energy_drift:.2%}\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "86466974"
  },
  {
    "id": "models_guide_17_781696c5",
    "file": "docs\\plant\\models_guide.md",
    "index": 17,
    "code": "import numpy as np\nfrom src.plant.models.simplified import SimplifiedDIPDynamics, SimplifiedDIPConfig\n\n# Setup\nconfig = SimplifiedDIPConfig.create_default()\ndynamics = SimplifiedDIPDynamics(config, enable_fast_mode=True)\n\n# Initial state (small perturbation from upright)\nstate = np.array([0.0, 0.1, -0.05, 0.0, 0.0, 0.0])\n\n# Control input\ncontrol = np.array([5.0])  # 5 N force on cart\n\n# Compute dynamics\nresult = dynamics.compute_dynamics(state, control, time=0.0)\n\nif result.success:\n    print(f\"State derivative: {result.state_derivative}\")\n    print(f\"Total energy: {result.info['total_energy']:.4f} J\")\nelse:\n    print(f\"Computation failed: {result.info['failure_reason']}\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "781696c5"
  },
  {
    "id": "models_guide_18_c7a6949b",
    "file": "docs\\plant\\models_guide.md",
    "index": 18,
    "code": "from scipy.integrate import solve_ivp\n\ndef dynamics_ode(t, state):\n    \"\"\"ODE right-hand side for scipy integration.\"\"\"\n    control = np.array([0.0])  # No control input\n    result = dynamics.compute_dynamics(state, control, time=t)\n    return result.state_derivative if result.success else np.zeros(6)\n\n# Initial state with energy\nstate0 = np.array([0.0, 0.2, -0.15, 0.0, 0.1, -0.05])\nE0 = dynamics.compute_total_energy(state0)\n\n# Integrate for 5 seconds\nsol = solve_ivp(dynamics_ode, t_span=[0, 5], y0=state0,\n                method='RK45', rtol=1e-8)\n\n# Check energy conservation\nE_final = dynamics.compute_total_energy(sol.y[:, -1])\nenergy_drift = abs(E_final - E0) / E0\n\nprint(f\"Initial energy: {E0:.6f} J\")\nprint(f\"Final energy: {E_final:.6f} J\")\nprint(f\"Energy drift: {energy_drift:.2e} ({energy_drift*100:.4f}%)\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c7a6949b"
  },
  {
    "id": "models_guide_19_cd604ae9",
    "file": "docs\\plant\\models_guide.md",
    "index": 19,
    "code": "from src.plant.models.lowrank import LowRankDIPDynamics, LowRankDIPConfig\n\n# Use low-rank model for fast linearization\nconfig = LowRankDIPConfig.create_default()\ndynamics = LowRankDIPDynamics(config)\n\n# Get linearized system around upright equilibrium\nA, B = dynamics.get_linearized_system(equilibrium_point=\"upright\")\n\n# Analyze controllability\nfrom scipy.linalg import ctrb\nC = ctrb(A, B)\nrank = np.linalg.matrix_rank(C)\n\nif rank == A.shape[0]:\n    print(\"System is controllable \u2713\")\nelse:\n    print(f\"System rank deficient: {rank}/{A.shape[0]}\")\n\n# Compute eigenvalues\neigenvalues = np.linalg.eigvals(A)\nprint(f\"Open-loop poles: {eigenvalues}\")\n\n# Check for unstable modes\nunstable = np.any(np.real(eigenvalues) > 0)\nprint(f\"Unstable: {unstable}\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cd604ae9"
  },
  {
    "id": "models_guide_20_5ed51cc7",
    "file": "docs\\plant\\models_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.models.simplified import SimplifiedDIPDynamics\nfrom src.plant.models.full import FullDIPDynamics\nfrom src.plant.models.lowrank import LowRankDIPDynamics\nimport time\n\n# Create all three models with same configuration\nconfig_dict = {\n    'cart_mass': 1.0,\n    'pendulum1_mass': 0.1,\n    'pendulum2_mass': 0.1,\n    # ... (same parameters for all)\n}\n\nsimplified = SimplifiedDIPDynamics(config_dict, enable_fast_mode=True)\nfull = FullDIPDynamics(config_dict)\nlowrank = LowRankDIPDynamics(config_dict)\n\n# Test state\nstate = np.array([0.0, 0.1, -0.05, 0.0, 0.0, 0.0])\ncontrol = np.array([5.0])\n\n# Benchmark computation time\nmodels = [('Simplified', simplified), ('Full', full), ('Low-Rank', lowrank)]\n\nfor name, model in models:\n    start = time.perf_counter()\n    for _ in range(1000):\n        result = model.compute_dynamics(state, control)\n    elapsed = time.perf_counter() - start\n\n    print(f\"{name:12s}: {elapsed*1000:.2f} ms (1000 evaluations)\")\n    print(f\"  Energy: {result.info.get('total_energy', 0.0):.6f} J\")",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ed51cc7"
  },
  {
    "id": "models_guide_21_a03728df",
    "file": "docs\\plant\\models_guide.md",
    "index": 21,
    "code": "dynamics = SimplifiedDIPDynamics(\n    config,\n    enable_fast_mode=True,    # Use Numba JIT compilation\n    enable_monitoring=False   # Disable monitoring for maximum speed\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a03728df"
  },
  {
    "id": "models_guide_22_b5db0199",
    "file": "docs\\plant\\models_guide.md",
    "index": 22,
    "code": "physics = dynamics.physics\nphysics.enable_matrix_caching(True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5db0199"
  },
  {
    "id": "models_guide_23_5d49f4df",
    "file": "docs\\plant\\models_guide.md",
    "index": 23,
    "code": "physics.set_simplified_inertia(True)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d49f4df"
  },
  {
    "id": "models_guide_24_7a19c5e8",
    "file": "docs\\plant\\models_guide.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimplifiedDIPDynamics(BaseDynamicsModel):\n    \"\"\"Simplified DIP dynamics with balanced speed and accuracy.\"\"\"\n\n    def __init__(\n        self,\n        config: Union[SimplifiedDIPConfig, Dict[str, Any]],\n        enable_fast_mode: bool = False,\n        enable_monitoring: bool = True\n    ):\n        \"\"\"\n        Initialize simplified DIP dynamics.\n\n        Args:\n            config: Configuration or dictionary\n            enable_fast_mode: Use Numba JIT compilation\n            enable_monitoring: Enable performance monitoring\n        \"\"\"\n\n    def compute_dynamics(\n        self,\n        state: np.ndarray,\n        control_input: np.ndarray,\n        time: float = 0.0,\n        **kwargs\n    ) -> DynamicsResult:\n        \"\"\"Compute simplified DIP dynamics.\"\"\"\n\n    def get_physics_matrices(\n        self,\n        state: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Get M, C, G matrices.\"\"\"\n\n    def compute_total_energy(self, state: np.ndarray) -> float:\n        \"\"\"Compute total system energy.\"\"\"\n\n    def compute_linearization(\n        self,\n        equilibrium_state: np.ndarray,\n        equilibrium_input: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Compute linearization matrices A, B.\"\"\"",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a19c5e8"
  },
  {
    "id": "models_guide_25_ade2b798",
    "file": "docs\\plant\\models_guide.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\nclass FullDIPDynamics(BaseDynamicsModel):\n    \"\"\"Full-fidelity DIP dynamics with comprehensive physics.\"\"\"\n\n    def __init__(\n        self,\n        config: Union[FullDIPConfig, Dict[str, Any]],\n        enable_monitoring: bool = True,\n        enable_validation: bool = True\n    ):\n        \"\"\"Initialize full-fidelity dynamics.\"\"\"\n\n    def compute_energy_analysis(\n        self,\n        state: np.ndarray\n    ) -> Dict[str, float]:\n        \"\"\"Compute comprehensive energy breakdown.\"\"\"\n\n    def compute_stability_metrics(\n        self,\n        state: np.ndarray\n    ) -> Dict[str, float]:\n        \"\"\"Compute stability and conditioning metrics.\"\"\"\n\n    def set_wind_model(self, wind_function):\n        \"\"\"Set custom wind velocity function.\"\"\"\n\n    def get_integration_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get integration performance statistics.\"\"\"",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ade2b798"
  },
  {
    "id": "models_guide_26_80edbeac",
    "file": "docs\\plant\\models_guide.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\nclass LowRankDIPDynamics(BaseDynamicsModel):\n    \"\"\"Low-rank DIP dynamics for fast prototyping.\"\"\"\n\n    def __init__(\n        self,\n        config: Union[LowRankDIPConfig, Dict[str, Any]],\n        enable_monitoring: bool = False,\n        enable_validation: bool = True\n    ):\n        \"\"\"Initialize low-rank dynamics.\"\"\"\n\n    def get_linearized_system(\n        self,\n        equilibrium_point: str = \"upright\",\n        force_recompute: bool = False\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Get linearized system matrices.\"\"\"\n\n    def compute_linearized_dynamics(\n        self,\n        state: np.ndarray,\n        control_input: np.ndarray,\n        equilibrium_point: str = \"upright\"\n    ) -> np.ndarray:\n        \"\"\"Compute dynamics using linearized model.\"\"\"\n\n    def step(\n        self,\n        state: np.ndarray,\n        control_input: np.ndarray,\n        dt: float\n    ) -> np.ndarray:\n        \"\"\"Simple Euler integration step.\"\"\"",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80edbeac"
  },
  {
    "id": "production_readiness_assessment_v2_1_52c67649",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 1,
    "code": "# Optimized Gains Summary\nclassical_gains = [10.5, 8.3, 15.2, 12.1, 50.0, 5.5]    # 0.000000 cost\nadaptive_gains = [12.8, 9.7, 14.6, 11.3, 45.2]          # 0.000000 cost\nsta_gains = [11.2, 7.9, 16.1, 13.4, 48.7, 6.2]          # 0.000000 cost\nhybrid_gains = [77.6, 44.4, 17.3, 14.2]                 # 0.000000 cost",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52c67649"
  },
  {
    "id": "production_readiness_assessment_v2_2_3e25cb68",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 2,
    "code": "# Emergency Reset Conditions\nemergency_reset = (\n    not np.isfinite(u_sat) or abs(u_sat) > self.max_force * 2 or\n    not np.isfinite(k1_new) or k1_new > self.k1_max * 0.9 or\n    not np.isfinite(k2_new) or k2_new > self.k2_max * 0.9 or\n    state_norm > 10.0 or velocity_norm > 50.0\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e25cb68"
  },
  {
    "id": "production_readiness_assessment_v2_3_de618498",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# All controller types successfully instantiated\ntest_results = {\n    'classical_smc': \u2705 SUCCESS,\n    'adaptive_smc': \u2705 SUCCESS,\n    'sta_smc': \u2705 SUCCESS,\n    'hybrid_adaptive_sta_smc': \u2705 SUCCESS\n}\n\n# Interface compliance verified\nfor controller_name in test_results:\n    controller = create_controller(controller_name, config)\n    assert hasattr(controller, 'compute_control')\n    assert hasattr(controller, 'reset')\n    assert hasattr(controller, 'initialize_state')",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "de618498"
  },
  {
    "id": "production_readiness_assessment_v2_4_87546e08",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 4,
    "code": "# Type hint coverage by module\ncoverage_results = {\n    'controllers/': 98.5%,    # Excellent type coverage\n    'core/': 97.2%,          # Very good coverage\n    'utils/': 95.8%,         # Good coverage\n    'optimization/': 96.4%    # Very good coverage\n}\n\n# Overall type coverage: 97.0% (Target: 95%+)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87546e08"
  },
  {
    "id": "production_readiness_assessment_v2_5_59e8baa1",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 5,
    "code": "coverage_summary = {\n    'overall_coverage': 87.2%,           # Target: \u226585%\n    'critical_components': 96.8%,        # Target: \u226595%\n    'safety_critical': 100%,             # Target: 100%\n    'controllers': 98.5%,                # Excellent\n    'optimization': 94.2%,               # Very good\n    'core_simulation': 97.1%             # Excellent\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59e8baa1"
  },
  {
    "id": "production_readiness_assessment_v2_6_11ad0c34",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 6,
    "code": "test_distribution = {\n    'unit_tests': 245,           # 65% of total\n    'integration_tests': 89,     # 24% of total\n    'property_tests': 28,        # 7% of total\n    'performance_tests': 15      # 4% of total\n}\n# Total: 377 tests (excellent coverage)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "11ad0c34"
  },
  {
    "id": "production_readiness_assessment_v2_7_bdb92e17",
    "file": "docs\\production\\production_readiness_assessment_v2.md",
    "index": 7,
    "code": "doc_coverage = {\n    'api_documentation': 100%,      # Complete coverage\n    'mathematical_theory': 95%,     # Excellent theoretical foundation\n    'user_guides': 90%,            # Good user support\n    'troubleshooting': 100%,       # Complete error documentation\n    'deployment_guides': 85%       # Good production support\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bdb92e17"
  },
  {
    "id": "bibliography_1_2718195f",
    "file": "docs\\references\\bibliography.md",
    "index": 1,
    "code": "def super_twisting_control(self, s: float) -> float:\n    \"\"\"\n    Implements super-twisting algorithm from {cite}`levant2003higher`.\n\n    Based on the theoretical development in {cite}`moreno2012strict`\n    with Lyapunov analysis ensuring finite-time convergence.\n    \"\"\"\n    return -self.alpha * np.abs(s)**0.5 * np.sign(s) - self.beta * np.sign(s)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2718195f"
  },
  {
    "id": "index_1_eed0ff18",
    "file": "docs\\references\\index.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass SuperTwistingSMC:\n    \"\"\"\n    Super-twisting sliding mode controller.\n\n    Based on the algorithm described in {cite}`levant2003higher`\n    with finite-time convergence analysis from {cite}`moreno2012strict`.\n\n    References\n    ----------\n    .. bibliography::\n       :filter: key in [\"levant2003higher\", \"moreno2012strict\"]\n    \"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eed0ff18"
  },
  {
    "id": "code_beautification_optimization_report_1_0d2f6f76",
    "file": "docs\\reports\\code_beautification_optimization_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#============================== src/controllers/factory.py =============================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d2f6f76"
  },
  {
    "id": "CODE_BEAUTIFICATION_QUALITY_POLISH_REPORT_1_c1f1e629",
    "file": "docs\\reports\\CODE_BEAUTIFICATION_QUALITY_POLISH_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports (alphabetical)\nimport logging\nfrom typing import Dict, List, Optional\n\n# Third-party imports (alphabetical)\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Local project imports (absolute paths preferred)\nfrom src.controllers.factory import create_controller",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c1f1e629"
  },
  {
    "id": "CODE_BEAUTIFICATION_QUALITY_POLISH_REPORT_2_4c59b7a4",
    "file": "docs\\reports\\CODE_BEAUTIFICATION_QUALITY_POLISH_REPORT.md",
    "index": 2,
    "code": "# Before: Hard dependencies\ndef create_controller():\n    config = load_config()  # Fixed dependency\n\n# After: Injectable dependencies\ndef create_controller(config: Optional[Dict] = None):\n    config = config or load_config()  # Testable",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c59b7a4"
  },
  {
    "id": "CODE_BEAUTIFICATION_QUALITY_REPORT_1_38d9dc46",
    "file": "docs\\reports\\CODE_BEAUTIFICATION_QUALITY_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#=======================================================================================\\\\\\\n#================================= src/path/filename.py ===============================\\\\\\\n#=======================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38d9dc46"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_1_45e21d69",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 1,
    "code": "# Before: No K1 > K2 validation\n# After: Strict constraint enforcement\nvalid = (k1 > 0.0) & (k2 > 0.0) & (k1 > k2)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45e21d69"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_2_ebcf7d26",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 2,
    "code": "# src/controllers/factory/optimization.py\nclass ControllerPreCompiler:\n    \"\"\"Pre-compile controller configurations for faster instantiation.\"\"\"\n\n    @lru_cache(maxsize=128)\n    def get_optimized_config(self, controller_type: str, config_hash: str):\n        # Optimized configuration caching",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ebcf7d26"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_3_6cb8165b",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 3,
    "code": "# src/controllers/factory/thread_safety.py\nclass LockFreeRegistry:\n    \"\"\"Lock-free controller registry using immutable data structures.\"\"\"\n\n    def get_controller_info(self, controller_type: str):\n        # Atomic read of current snapshot - no locking required\n        current_snapshot = self._registry_snapshot\n        return current_snapshot.get(controller_type)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6cb8165b"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_4_d3adb8a0",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 4,
    "code": "# Before: 6 gains (static + adaptive)\ndef gains(self) -> List[float]:\n    static_gains = list(self.config.gains)\n    current_adaptive_gain = self._adaptation.get_current_gain()\n    return static_gains + [current_adaptive_gain]  # 6 gains\n\n# After: 5 gains (static only)\ndef gains(self) -> List[float]:\n    return list(self.config.gains)  # 5 gains as expected",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3adb8a0"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_5_0a918caf",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 5,
    "code": "# Enhanced stability constraint validation\ndef validate_gains(self, gains_b: np.ndarray) -> np.ndarray:\n    k1, k2 = gains_b[:, 0], gains_b[:, 1]\n    valid = (k1 > 0.0) & (k2 > 0.0) & (k1 > k2)  # Strict K1 > K2\n    return valid",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a918caf"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_6_d003fe6c",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 6,
    "code": "@contextmanager\ndef acquire_minimal_lock(self, resource_id: str, timeout: float = 5.0):\n    \"\"\"Acquire lock with minimal hold time and performance tracking.\"\"\"\n    # Lock acquisition with contention monitoring\n    # Automatic hold time statistics\n    # Deadlock prevention with timeout",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d003fe6c"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_7_0416157c",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 7,
    "code": "class ThreadPerformanceMonitor:\n    \"\"\"Monitor thread performance for factory operations.\"\"\"\n    # Real-time operation timing\n    # Thread-specific performance statistics\n    # Contention rate analysis",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0416157c"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_8_6453ca5d",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# PRIORITY: Fix hybrid controller stability validation\n# Current Issue: Surface gain validation incomplete\n# Solution: Implement proper 4-gain validation logic",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6453ca5d"
  },
  {
    "id": "CONTROLLER_OPTIMIZATION_REPORT_9_27f0f492",
    "file": "docs\\reports\\CONTROLLER_OPTIMIZATION_REPORT.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# PRIORITY: Enhance dynamics model integration\n# Current Issue: Simplified fallback dynamics in accuracy tests\n# Solution: Full DIPDynamics integration for realistic control testing",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27f0f492"
  },
  {
    "id": "CONTROLLER_TEST_VALIDATION_REPORT_1_54d9c79b",
    "file": "docs\\reports\\CONTROLLER_TEST_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# Fixed constructor signatures in test fixtures\n@pytest.fixture(scope=\"session\")\ndef dynamics(physics_cfg):\n    from src.core.dynamics import DIPDynamics\n    return DIPDynamics(config=physics_cfg)  # Fixed: was params=physics_cfg",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "54d9c79b"
  },
  {
    "id": "CONTROLLER_TEST_VALIDATION_REPORT_2_15f95cb6",
    "file": "docs\\reports\\CONTROLLER_TEST_VALIDATION_REPORT.md",
    "index": 2,
    "code": "# Fixed config instantiation across all test files\nconfig = FullDIPConfig.create_default()  # Fixed: was FullDIPConfig()\nconfig = LowRankDIPConfig.create_default()  # Fixed: was LowRankDIPConfig()",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15f95cb6"
  },
  {
    "id": "CONTROLLER_TEST_VALIDATION_REPORT_3_16056a6c",
    "file": "docs\\reports\\CONTROLLER_TEST_VALIDATION_REPORT.md",
    "index": 3,
    "code": "# Fixed parameter bounds and compatibility\n'max_condition_number': assert 1e3 <= reg_value <= 1e15  # Was: 1e12\n'pendulum2_inertia': 0.008,  # Fixed: was 0.005 (below physical bound)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "16056a6c"
  },
  {
    "id": "CONTROLLER_TEST_VALIDATION_REPORT_4_52247c36",
    "file": "docs\\reports\\CONTROLLER_TEST_VALIDATION_REPORT.md",
    "index": 4,
    "code": "# Fixed dynamics computation interface\nresult = dynamics.compute_dynamics(test_state, np.array([1.0]))\nassert result.success, \"Dynamics computation should succeed\"\nstate_dot = result.state_derivative  # Fixed: was using result directly",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52247c36"
  },
  {
    "id": "docs_visual_audit_report_1_ce957c0d",
    "file": "docs\\reports\\docs_visual_audit_report.md",
    "index": 1,
    "code": "# In screenshot_docs.py, line ~85\nawait page.goto(file_url, wait_until=\"networkidle\", timeout=60000)  # 60 seconds",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce957c0d"
  },
  {
    "id": "docs_visual_audit_report_2_c2bc8312",
    "file": "docs\\reports\\docs_visual_audit_report.md",
    "index": 2,
    "code": "# Change from \"networkidle\" to \"domcontentloaded\"\nawait page.goto(file_url, wait_until=\"domcontentloaded\", timeout=30000)\n\n# Then wait for specific elements\nawait page.wait_for_selector(\"body\", timeout=10000)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2bc8312"
  },
  {
    "id": "docs_visual_audit_report_3_fdf87144",
    "file": "docs\\reports\\docs_visual_audit_report.md",
    "index": 3,
    "code": "# Add special handling for known slow pages\nif \"genindex\" in str(html_file) or \"coverage_analysis\" in str(html_file):\n    await page.goto(file_url, wait_until=\"load\", timeout=60000)\nelse:\n    await page.goto(file_url, wait_until=\"networkidle\", timeout=30000)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fdf87144"
  },
  {
    "id": "docs_visual_audit_report_4_855a7ad9",
    "file": "docs\\reports\\docs_visual_audit_report.md",
    "index": 4,
    "code": "# Add to screenshot script\n   viewport={\"width\": 375, \"height\": 812}  # Mobile",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "855a7ad9"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_1_8d216348",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 1,
    "code": "# Example: Classical SMC Configuration\n\"\"\"\nType-safe configuration for Classical SMC controller.\n\nBased on SMC theory requirements:\n- Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for Hurwitz stability\n- Switching gain K must be positive for reaching condition\n- Derivative gain kd must be non-negative for damping\n\"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d216348"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_2_5fde937b",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Surface computation: s = \u03bb\u2081\u0117\u2081 + c\u2081e\u2081 + \u03bb\u2082\u0117\u2082 + c\u2082e\u2082\n# Mathematical Background documented with stability guarantees",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fde937b"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_3_b0211db0",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nParticle Swarm Optimisation (PSO) tuner for sliding-mode controllers.\n\nThis module defines the high-throughput, vectorised `PSOTuner` class that wraps\na particle swarm optimisation algorithm around the vectorised simulation...\nIt incorporates improvements from design review steps, including decoupling of\nglobal state, explicit random number generation, dynamic instability penalties\nand configurable cost normalisation.\n\"\"\"",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0211db0"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_4_d6343893",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass MonteCarloConfig:\n    \"\"\"Configuration for Monte Carlo analysis.\"\"\"\n    # Basic simulation parameters\n    n_samples: int = 1000\n    confidence_level: float = 0.95\n\n    # Sampling methods\n    sampling_method: str = \"random\"  # \"random\", \"latin_hypercube\", \"sobol\", \"halton\"\n    antithetic_variates: bool = False\n    control_variates: bool = False",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6343893"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_5_59ce0d54",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# ISE = \u222b\u2080\u1d40 ||x(t)||\u00b2 dt\n# ITAE = \u222b\u2080\u1d40 t\u00b7||x(t)||\u2081 dt",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59ce0d54"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_6_e77008e5",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state: np.ndarray, state_vars: Any, history: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Compute classical SMC control law.\n\n    Args:\n        state: System state [x, x_dot, theta1, theta1_dot, theta2, theta2_dot]\n        state_vars: Controller internal state (for interface compatibility)\n        history: Controller history (for interface compatibility)\n\n    Returns:\n        Control result dictionary\n    \"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e77008e5"
  },
  {
    "id": "DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT_7_f98cf744",
    "file": "docs\\reports\\DOCUMENTATION_EXPERT_TECHNICAL_ASSESSMENT_REPORT.md",
    "index": 7,
    "code": "# Enhance docstrings with LaTeX mathematical notation\n   \"\"\"\n   Sliding surface computation:\n\n   .. math::\n       s = \\lambda_1 \\dot{e}_1 + c_1 e_1 + \\lambda_2 \\dot{e}_2 + c_2 e_2\n\n   Where the stability condition requires :math:`\\lambda_i > 0` for Hurwitz stability.\n   \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f98cf744"
  },
  {
    "id": "FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT_1_c3af8402",
    "file": "docs\\reports\\FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#====================== src/controllers/factory/smc_factory.py =======================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3af8402"
  },
  {
    "id": "FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT_2_16cb868b",
    "file": "docs\\reports\\FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports\nimport logging\nimport threading\nfrom enum import Enum\nfrom typing import Dict, List, Optional, Protocol, TypeVar, Union\n\n# Third-party imports\nimport numpy as np\nfrom numpy.typing import NDArray\n\n# Local imports - organized by domain\nfrom src.controllers.smc.algorithms.classical.controller import ModularClassicalSMC\nfrom src.controllers.factory.core.validation import validate_controller_gains",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "16cb868b"
  },
  {
    "id": "FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT_3_a0f4d4c8",
    "file": "docs\\reports\\FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT.md",
    "index": 3,
    "code": "from numba import jit\n\n   @jit(nopython=True)\n   def validate_gains_vectorized(gains_array: np.ndarray) -> np.ndarray:\n       # Vectorized validation for PSO operations",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0f4d4c8"
  },
  {
    "id": "FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT_4_d9c045de",
    "file": "docs\\reports\\FACTORY_BEAUTIFICATION_OPTIMIZATION_REPORT.md",
    "index": 4,
    "code": "from functools import lru_cache\n\n   @lru_cache(maxsize=128)\n   def get_controller_info(controller_type: str) -> Dict[str, Any]:\n       # Cache controller metadata for frequent lookups",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9c045de"
  },
  {
    "id": "factory_code_beautification_report_1_68f81410",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 1,
    "code": "# Before: Weak typing\ndef create_controller(controller_type: str, config=None, gains=None):\n\n# After: Strong typing with protocols\ndef create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[List[float], np.ndarray]] = None\n) -> ControllerProtocol:",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68f81410"
  },
  {
    "id": "factory_code_beautification_report_2_83c2bbc8",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports (grouped and sorted)\nimport logging\nimport threading\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union, Protocol, TypeVar\n\n# Third-party imports (version-aware)\nimport numpy as np\nfrom numpy.typing import NDArray\n\n# Local imports (hierarchical organization)\nfrom src.core.dynamics import DIPDynamics\nfrom src.controllers.smc.algorithms.classical.controller import ModularClassicalSMC",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83c2bbc8"
  },
  {
    "id": "factory_code_beautification_report_3_5faa08ac",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Registry-based factory with metadata\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5faa08ac"
  },
  {
    "id": "factory_code_beautification_report_4_7c088058",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    \"\"\"Protocol defining the standard controller interface.\"\"\"\n\n    def compute_control(\n        self,\n        state: StateVector,\n        last_control: float,\n        history: ConfigDict\n    ) -> ControlOutput:\n        \"\"\"Compute control output for given state.\"\"\"\n        ...",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c088058"
  },
  {
    "id": "factory_code_beautification_report_5_4723e80c",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Thread-safe factory operations with timeout protection\n_factory_lock = threading.RLock()\n_LOCK_TIMEOUT = 10.0  # seconds\n\ndef create_controller(...) -> ControllerProtocol:\n    with _factory_lock:\n        # Thread-safe controller creation",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4723e80c"
  },
  {
    "id": "factory_code_beautification_report_6_b9caceda",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"Wrapper for SMC controllers to provide PSO-compatible interface.\"\"\"\n\n    def __init__(self, controller: ControllerProtocol, n_gains: int, controller_type: str) -> None:\n        self.controller = controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n    def validate_gains(self, particles: np.ndarray) -> np.ndarray:\n        \"\"\"Validate gain particles for PSO optimization.\"\"\"\n        # Controller-specific validation logic\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"PSO-compatible control computation interface.\"\"\"\n        # Safe control computation with fallback",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9caceda"
  },
  {
    "id": "factory_code_beautification_report_7_73b4105d",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCGainSpec:\n    \"\"\"SMC gain specification with expected interface.\"\"\"\n    def __init__(self, gain_names: List[str], gain_bounds: List[Tuple[float, float]],\n                 controller_type: str, n_gains: int):\n        self.gain_names = gain_names\n        self.gain_bounds = gain_bounds\n        self.controller_type = controller_type\n        self.n_gains = n_gains\n\nSMC_GAIN_SPECS = {\n    SMCType.CLASSICAL: SMCGainSpec(\n        gain_names=['k1', 'k2', 'lambda1', 'lambda2', 'K', 'kd'],\n        gain_bounds=[(1.0, 30.0), (1.0, 30.0), (1.0, 20.0), (1.0, 20.0), (5.0, 50.0), (0.1, 10.0)],\n        controller_type='classical_smc',\n        n_gains=6\n    )\n}",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "73b4105d"
  },
  {
    "id": "factory_code_beautification_report_8_8b9c489e",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Backwards compatibility aliases\ndef create_classical_smc_controller(\n    config: Optional[Any] = None,\n    gains: Optional[Union[List[float], np.ndarray]] = None\n) -> ControllerProtocol:\n    \"\"\"Create classical SMC controller (backwards compatibility).\"\"\"\n    return create_controller('classical_smc', config, gains)\n\ndef create_controller_legacy(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[List[float], np.ndarray]] = None\n) -> ControllerProtocol:\n    \"\"\"Legacy factory function (backwards compatibility).\"\"\"\n    return create_controller(controller_type, config, gains)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b9c489e"
  },
  {
    "id": "factory_code_beautification_report_9_e33ba872",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCType(Enum):\n    \"\"\"SMC Controller types enumeration.\"\"\"\n    CLASSICAL = \"classical_smc\"\n    ADAPTIVE = \"adaptive_smc\"\n    SUPER_TWISTING = \"sta_smc\"\n    HYBRID = \"hybrid_adaptive_sta_smc\"\n\nclass SMCFactory:\n    \"\"\"Factory class for creating SMC controllers.\"\"\"\n\n    @staticmethod\n    def create_controller(smc_type: SMCType, config: SMCConfig) -> ControllerProtocol:\n        \"\"\"Create controller using SMCType enum.\"\"\"\n        return create_controller(smc_type.value, config, config.gains)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e33ba872"
  },
  {
    "id": "factory_code_beautification_report_10_0d2f6f76",
    "file": "docs\\reports\\factory_code_beautification_report.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#============================== src/controllers/factory.py =============================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d2f6f76"
  },
  {
    "id": "FACTORY_SYSTEM_ANALYSIS_REPORT_1_ceda1b2c",
    "file": "docs\\reports\\FACTORY_SYSTEM_ANALYSIS_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    # ... additional controllers\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceda1b2c"
  },
  {
    "id": "FACTORY_SYSTEM_ANALYSIS_REPORT_2_ca55cb02",
    "file": "docs\\reports\\FACTORY_SYSTEM_ANALYSIS_REPORT.md",
    "index": 2,
    "code": "# Factory creates PSO-compatible wrapper\npso_controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\ncontrol_output = pso_controller.compute_control(state)  # Returns np.array",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca55cb02"
  },
  {
    "id": "FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT_1_b055e00c",
    "file": "docs\\reports\\FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# All controllers successfully implement:\n- compute_control(state, last_control, history) -> ControlOutput\n- reset() -> None\n- gains property for parameter access\n- Proper error handling and validation",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b055e00c"
  },
  {
    "id": "FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT_2_f1bb7374",
    "file": "docs\\reports\\FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT.md",
    "index": 2,
    "code": "# All controllers successfully support:\n- PSO wrapper creation and optimization\n- Parameter bounds validation\n- Optimal gains application\n- Cost function evaluation",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1bb7374"
  },
  {
    "id": "FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT_3_0e6a4009",
    "file": "docs\\reports\\FINAL_4_CONTROLLER_INTEGRATION_VALIDATION_REPORT.md",
    "index": 3,
    "code": "# All controllers successfully support:\n- YAML configuration loading\n- Parameter extraction and validation\n- Default value handling\n- Error reporting for invalid configurations",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e6a4009"
  },
  {
    "id": "GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT_1_aa0829a3",
    "file": "docs\\reports\\GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT.md",
    "index": 1,
    "code": "# Verified Components:\n- create_controller() function: \u2705 Operational\n- list_available_controllers(): \u2705 Returns ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n- Controller registry: \u2705 Complete with metadata\n- Thread-safe operations: \u2705 RLock protection\n- Configuration validation: \u2705 Parameter checking",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa0829a3"
  },
  {
    "id": "GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT_2_ada2a530",
    "file": "docs\\reports\\GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Validated PSO Integration:\n- PSOTuner import: \u2705 Successful\n- create_smc_for_pso(): \u2705 Functional\n- PSO wrapper creation: \u2705 All controller types supported\n- Control computation: \u2705 Verified outputs\n\n# PSO Test Results:\n- Classical SMC PSO wrapper: \u2705 Control output: [-49.0]\n- Adaptive SMC PSO wrapper: \u2705 Control output: [-20.25]\n- STA SMC PSO wrapper: \u2705 Control output: [-75.83]\n- Hybrid SMC PSO wrapper: \u26a0\ufe0f NoneType issue detected",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ada2a530"
  },
  {
    "id": "GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT_3_049e6052",
    "file": "docs\\reports\\GITHUB_ISSUE_6_FACTORY_INTEGRATION_VALIDATION_FINAL_REPORT.md",
    "index": 3,
    "code": "# Validated Module Connections:\nsrc.core.dynamics: \u2705 DIPDynamics integration\nsrc.simulation.engines: \u2705 Vector simulation engine\nsrc.plant.models: \u2705 DIPParams integration\nsrc.optimization.algorithms: \u2705 PSOTuner accessibility\nsrc.utils.*: \u2705 Utility modules accessible\nsrc.analysis.*: \u2705 Performance metrics available\nsrc.config.*: \u2705 Configuration validation",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "049e6052"
  },
  {
    "id": "GITHUB_ISSUE_6_RESOLUTION_REPORT_1_8784e056",
    "file": "docs\\reports\\GITHUB_ISSUE_6_RESOLUTION_REPORT.md",
    "index": 1,
    "code": "# Fixed registry consistency test to handle optional controllers\nif controller_info.get('class') is not None:\n    assert controller_type in available_types",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8784e056"
  },
  {
    "id": "GITHUB_ISSUE_6_RESOLUTION_REPORT_2_c8f1ca9c",
    "file": "docs\\reports\\GITHUB_ISSUE_6_RESOLUTION_REPORT.md",
    "index": 2,
    "code": "# control_accuracy_benchmark.py - READY FOR EXECUTION\nclass ControlAccuracyBenchmark:\n    \"\"\"Comprehensive control accuracy benchmarking system.\"\"\"\n    # Validates factory integration through closed-loop testing\n    # Supports all 4 controller types with realistic dynamics\n    # Provides production readiness assessment",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8f1ca9c"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_1_70ed6acb",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/hybrid_adaptive_sta_smc.py\nclass HybridAdaptiveSTASMC:\n    def compute_control(self, state, state_vars, history):\n        \"\"\"Compute hybrid adaptive STA-SMC control action.\"\"\"\n\n        # ... 674 lines of complex control algorithm implementation ...\n\n        # Calculate control outputs\n        u_sat = float(np.clip(u_total, -self.max_force, self.max_force))\n        k1_new = max(0.0, min(k1_new, self.k1_max))\n        k2_new = max(0.0, min(k2_new, self.k2_max))\n        u_int_new = float(np.clip(u_int_new, -self.u_int_max, self.u_int_max))\n        s = float(s)\n\n        # Comments about packaging outputs...\n        # Package the outputs into a structured named tuple. Returning a\n        # named tuple formalises the contract and allows clients to\n        # access fields by name while retaining tuple compatibility.\n\n        # \u274c CRITICAL BUG: Missing return statement!\n        # Function implicitly returns None instead of HybridSTAOutput\n\n    def reset(self) -> None:\n        \"\"\"Reset controller state.\"\"\"\n        # ... reset logic ...\n\n        # \u274c WRONG: Return statement with out-of-scope variables\n        return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n        # Variables u_sat, k1_new, k2_new, u_int_new, history, s are NOT in scope here!",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70ed6acb"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_2_0cce747a",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# FIXED IMPLEMENTATION\nclass HybridAdaptiveSTASMC:\n    def compute_control(self, state, state_vars, history):\n        \"\"\"Compute hybrid adaptive STA-SMC control action.\"\"\"\n\n        # ... 674 lines of control algorithm implementation ...\n\n        # Calculate final control values\n        u_sat = float(np.clip(u_total, -self.max_force, self.max_force))\n        k1_new = max(0.0, min(k1_new, self.k1_max))\n        k2_new = max(0.0, min(k2_new, self.k2_max))\n        u_int_new = float(np.clip(u_int_new, -self.u_int_max, self.u_int_max))\n\n        # \u2705 CRITICAL FIX: Proper return statement with correct variable scope\n        return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\n    def reset(self) -> None:\n        \"\"\"Reset controller state to initial conditions.\"\"\"\n        self.k1 = self.k1_init\n        self.k2 = self.k2_init\n        self.u_int = 0.0\n        self.last_s = 0.0\n\n        # \u2705 CORRECT: No return statement (method returns None as intended)\n        pass",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0cce747a"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_3_ec21e7e4",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _normalize_result(self, result):\n    \"\"\"Ensure result is properly formatted as HybridSTAOutput.\"\"\"\n    if result is None:\n        # Emergency fallback for None returns\n        logger.warning(\"Controller returned None - using emergency fallback\")\n        return HybridSTAOutput(\n            control=0.0,\n            state_vars=(self.k1_init, self.k2_init, 0.0),\n            history=self.initialize_history(),\n            sliding_surface=0.0\n        )\n\n    if isinstance(result, np.ndarray):\n        # Convert numpy array to dictionary structure\n        return self._array_to_output(result)\n\n    return result",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec21e7e4"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_4_23e4fe9a",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 4,
    "code": "def _extract_control_value(self, active_result):\n    \"\"\"Extract control value with comprehensive type checking.\"\"\"\n    if isinstance(active_result, dict):\n        return active_result.get('control', 0.0)\n    elif hasattr(active_result, 'control'):\n        return active_result.control\n    else:\n        logger.warning(f\"Unexpected result type: {type(active_result)}\")\n        return 0.0",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23e4fe9a"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_5_cd268874",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef _check_emergency_conditions(self, u_sat, k1_new, k2_new, u_int_new, s, state):\n    \"\"\"Check for numerical instability requiring emergency reset.\"\"\"\n    state_norm = np.linalg.norm(state[:3])  # Position magnitudes\n    velocity_norm = np.linalg.norm(state[3:])  # Velocity magnitudes\n\n    emergency_reset = (\n        not np.isfinite(u_sat) or abs(u_sat) > self.max_force * 2 or\n        not np.isfinite(k1_new) or k1_new > self.k1_max * 0.9 or\n        not np.isfinite(k2_new) or k2_new > self.k2_max * 0.9 or\n        not np.isfinite(u_int_new) or abs(u_int_new) > self.u_int_max * 1.5 or\n        not np.isfinite(s) or abs(s) > 100.0 or\n        state_norm > 10.0 or velocity_norm > 50.0\n    )\n\n    return emergency_reset",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cd268874"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_6_55c0d206",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 6,
    "code": "orchestration_metrics = {\n    'coordination_efficiency': 95,      # Minimal communication overhead\n    'parallel_work_percentage': 80,     # 80% of work done in parallel\n    'decision_latency': '< 5 minutes',  # Fast decision making\n    'knowledge_sharing': 100,           # Complete information sharing\n    'quality_gate_compliance': 100,    # All quality gates passed\n    'resolution_time': '< 24 hours'     # Rapid resolution\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55c0d206"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_7_5d925829",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_all_controllers_operational():\n    \"\"\"Verify all 4 controllers remain operational after hybrid fix.\"\"\"\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n\n    for controller_name in controllers:\n        controller = create_controller(controller_name)\n        result = controller.compute_control(test_state)\n\n        assert result is not None, f\"{controller_name} returned None\"\n        assert hasattr(result, 'control'), f\"{controller_name} missing control\"\n        assert np.isfinite(result.control), f\"{controller_name} non-finite control\"\n\n    print(\"\u2705 All 4 controllers operational\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d925829"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_8_590c54e6",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/validate_return_statements.py\ndef validate_return_statements(file_path):\n    \"\"\"Ensure methods with return type annotations have return statements.\"\"\"\n    with open(file_path, 'r') as f:\n        tree = ast.parse(f.read())\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef) and node.returns:\n            if not has_return_statement(node):\n                raise ValueError(\n                    f\"Method '{node.name}' has return type annotation \"\n                    f\"but missing return statement\"\n                )",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "590c54e6"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_9_0f837b80",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars=None, history=None) -> HybridSTAOutput:\n    \"\"\"Compute control with runtime validation.\"\"\"\n\n    # ... control algorithm implementation ...\n\n    result = HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\n    # Development mode validation\n    if __debug__:\n        assert isinstance(result, HybridSTAOutput)\n        assert isinstance(result.control, (int, float))\n        assert len(result.state_vars) == 3\n        assert isinstance(result.history, dict)\n        assert np.isfinite(result.control)\n\n    return result",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f837b80"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_10_6c6ce954",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller_with_validation(controller_type: str, **kwargs):\n    \"\"\"Create controller with enhanced output validation.\"\"\"\n    controller = _create_controller_impl(controller_type, **kwargs)\n\n    # Wrap compute_control with validation\n    original_method = controller.compute_control\n\n    def validated_compute_control(*args, **kwargs):\n        result = original_method(*args, **kwargs)\n\n        if result is None:\n            raise TypeError(f\"{controller_type}: compute_control returned None\")\n\n        if not hasattr(result, 'control'):\n            raise TypeError(f\"{controller_type}: Missing control attribute\")\n\n        return result\n\n    controller.compute_control = validated_compute_control\n    return controller",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c6ce954"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_11_6dbffcb9",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestControllerReturnTypes:\n    \"\"\"Comprehensive return type validation tests.\"\"\"\n\n    @pytest.mark.parametrize(\"controller_name\", [\n        'classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc'\n    ])\n    def test_compute_control_never_returns_none(self, controller_name):\n        \"\"\"Ensure compute_control never returns None.\"\"\"\n        controller = create_controller(controller_name)\n\n        test_states = [\n            np.zeros(6),                           # Zero state\n            np.ones(6) * 0.1,                     # Small values\n            np.array([1, 0.5, -0.3, 0.1, -0.2, 0.05]),  # Mixed values\n        ]\n\n        for state in test_states:\n            result = controller.compute_control(state)\n            assert result is not None, f\"{controller_name} returned None\"\n            assert hasattr(result, 'control'), f\"{controller_name} missing control\"",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6dbffcb9"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_12_bef71f42",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_pso_integration_no_errors(controller_name, caplog):\n    \"\"\"Test PSO optimization produces no runtime errors.\"\"\"\n    tuner = PSOTuner(bounds=get_bounds(controller_name), n_particles=5, iters=10)\n\n    best_gains, best_cost = tuner.optimize(\n        controller_type=controller_name,\n        dynamics=test_dynamics\n    )\n\n    # Verify no error logs\n    error_logs = [r for r in caplog.records if r.levelname == 'ERROR']\n    assert len(error_logs) == 0, f\"Found errors: {[r.message for r in error_logs]}\"\n\n    # Verify valid optimization results\n    assert isinstance(best_cost, float)\n    assert best_cost >= 0.0",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bef71f42"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_13_5cef50bc",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nproduction_metrics = {\n    'before_fix': {\n        'controller_availability': '3/4 (75%)',\n        'runtime_error_rate': 'High (masked)',\n        'pso_reliability': 'False positives',\n        'production_readiness': '7.8/10',\n        'deployment_status': 'BLOCKED'\n    },\n    'after_fix': {\n        'controller_availability': '4/4 (100%)',\n        'runtime_error_rate': '0% (eliminated)',\n        'pso_reliability': 'Genuine results',\n        'production_readiness': '9.5/10',\n        'deployment_status': 'APPROVED'\n    },\n    'improvement': {\n        'availability_increase': '+25%',\n        'error_reduction': '-100%',\n        'reliability_improvement': '+100%',\n        'readiness_increase': '+1.7 points',\n        'status_change': 'BLOCKED \u2192 APPROVED'\n    }\n}",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cef50bc"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_14_96039ab8",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Before (Problematic)\ntry:\n    result = controller.compute_control(state)\nexcept Exception:\n    return \"Error occurred\"  # Masks real issues\n\n# After (Improved)\ntry:\n    result = controller.compute_control(state)\n    if result is None:\n        raise TypeError(\"Controller returned None - implementation bug\")\n    return result\nexcept TypeError as e:\n    logger.error(f\"Implementation error: {e}\", exc_info=True)\n    raise  # Don't mask implementation bugs\nexcept Exception as e:\n    logger.warning(f\"Operational error: {e}\")\n    return fallback_result()  # Handle operational errors gracefully",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "96039ab8"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_15_7ca64663",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced development workflow\ndevelopment_workflow = {\n    'pre_commit': [\n        'return_statement_validation',\n        'type_checking_with_mypy',\n        'unit_test_execution',\n        'static_analysis'\n    ],\n    'continuous_integration': [\n        'comprehensive_test_suite',\n        'integration_testing',\n        'performance_regression_tests',\n        'documentation_validation'\n    ],\n    'deployment_gates': [\n        'all_controllers_operational',\n        'zero_runtime_errors',\n        'pso_optimization_success',\n        'production_readiness_score'\n    ]\n}",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca64663"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_16_2a68c349",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 16,
    "code": "# Recommended tools and configurations\nstatic_analysis_stack = {\n    'mypy': 'Strict type checking with return type validation',\n    'pylint': 'Code quality and pattern detection',\n    'bandit': 'Security vulnerability scanning',\n    'flake8': 'Style and complexity analysis',\n    'custom_validators': 'Return statement and scope validation'\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a68c349"
  },
  {
    "id": "GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT_17_b4a82faa",
    "file": "docs\\reports\\GITHUB_ISSUE_HYBRID_SMC_RESOLUTION_REPORT.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Property-based testing for controller interfaces\n@given(st.arrays(np.float64, shape=(6,), elements=st.floats(-10, 10)))\ndef test_controller_always_returns_valid_output(state):\n    \"\"\"Property: Controllers always return valid control outputs.\"\"\"\n    for controller_name in ALL_CONTROLLERS:\n        controller = create_controller(controller_name)\n        result = controller.compute_control(state)\n\n        assert result is not None\n        assert hasattr(result, 'control')\n        assert np.isfinite(result.control)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4a82faa"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_1_736486a2",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#=======================================================================================\\\\\\\n#================== src/controllers/smc/algorithms/hybrid/controller.py =================\\\\\\\n#=======================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "736486a2"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_2_b8c30c54",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 2,
    "code": "# Type-safe initialization\ndef __init__(self, config: HybridSMCConfig, dynamics=None, **kwargs):\n\n# Comprehensive return type annotations\ndef compute_control(self, state: np.ndarray, state_vars: Any = None,\n                   history: Dict[str, Any] = None, dt: float = None) -> Union[Dict[str, Any], np.ndarray]:\n\n# Robust type imports\nfrom typing import Dict, List, Union, Optional, Any",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b8c30c54"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_3_4a2f8523",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 3,
    "code": "# Dual interface support for compatibility\nif dt is not None or (state_vars is None and history is None):\n    # Test interface: return numpy array\n    return np.array([u_saturated, 0.0, 0.0])\nelse:\n    # Standard interface: return dictionary\n    return control_result",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a2f8523"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_4_fb8b4fd7",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Multi-level error handling\ntry:\n    # Main control computation\n    for controller_name, controller in self.controllers.items():\n        try:\n            # Individual controller execution\n            result = controller.compute_control(state, safe_state_vars, safe_history)\n            # Type normalization with fallback\n        except Exception as e:\n            self.logger.warning(f\"Controller {controller_name} failed: {e}\")\n            all_control_results[controller_name] = {'u': 0.0, 'error': str(e)}\n\nexcept Exception as e:\n    self.logger.error(f\"Hybrid control computation failed: {e}\")\n    error_result = self._create_error_result(str(e))",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb8b4fd7"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_5_ccd6f1ae",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nModular Hybrid SMC Controller.\n\nImplements Hybrid Sliding Mode Control that intelligently switches between\nmultiple SMC algorithms based on system conditions and performance metrics.\n\nOrchestrates:\n- Multiple SMC controllers (Classical, Adaptive, Super-Twisting)\n- Intelligent switching logic\n- Smooth control transitions\n- Performance monitoring and learning\n\"\"\"",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccd6f1ae"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_6_ac2480c7",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 6,
    "code": "class ModularHybridSMC:\n    \"\"\"Modular design with clear responsibilities\"\"\"\n\n    # Clean initialization\n    def __init__(self, config: HybridSMCConfig, dynamics=None, **kwargs):\n        self.config = config\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self._initialize_controllers()\n        self.switching_logic = HybridSwitchingLogic(config)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac2480c7"
  },
  {
    "id": "HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT_7_3b099943",
    "file": "docs\\reports\\HYBRID_SMC_CODE_QUALITY_VALIDATION_REPORT.md",
    "index": 7,
    "code": "# Factory instantiation success\ncontroller = ModularHybridSMC(config)\n\u2705 SUCCESS: Controller instantiation and control computation works",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b099943"
  },
  {
    "id": "integration_health_report_1_e8e0b023",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 1,
    "code": "# Current Status: PARTIALLY BROKEN\n# Location: /d/Projects/main/src/controllers/factory.py\n\nIssues Identified:\n1. Configuration class parameter validation insufficient\n2. Fallback mechanism inconsistent across controller types\n3. Dynamic parameter mapping fails for newer controllers\n4. Missing configuration migration support",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8e0b023"
  },
  {
    "id": "integration_health_report_2_c4e76b3d",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 2,
    "code": "# Current Status: FUNCTIONAL WITH WARNINGS\n# Location: Multiple PSO modules integrated successfully\n\nStrengths:\n+ PSO optimization completes successfully\n+ Gains generation and application works\n+ Integration with factory pattern functional\n\nWarnings:\n- Factory configuration warnings during PSO iterations\n- No impact on optimization performance",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4e76b3d"
  },
  {
    "id": "integration_health_report_3_28489aef",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 3,
    "code": "# Current Status: FUNCTIONAL BUT INCOMPLETE\n# Location: /d/Projects/main/config.yaml + src/config/\n\nIssues:\n1. Empty gains arrays cause controller creation failures\n2. Parameter name mismatches between YAML and constructors\n3. Configuration validation insufficient for catching schema mismatches",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28489aef"
  },
  {
    "id": "integration_health_report_4_0afe57a1",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Required Fix: src/controllers/factory.py\n# Add parameter validation and mapping logic\n\ndef validate_controller_config(controller_type: str, config_params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate and map configuration parameters for controller constructors.\"\"\"\n\n    # Remove unsupported parameters\n    parameter_mappings = {\n        'adaptive_smc': {'remove': ['dynamics_model']},\n        'hybrid_adaptive_sta_smc': {\n            'rename': {'k1_init': 'k1_initial', 'k2_init': 'k2_initial'}\n        }\n    }\n\n    # Apply mappings and validation\n    # ... implementation needed",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0afe57a1"
  },
  {
    "id": "integration_health_report_5_e6ec057c",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Required Fix: ModularHybridSMC control computation\n# Location: src/controllers/smc/algorithms/hybrid/controller.py\n\n# Issue: Accessing .get() method on numpy array instead of dict\n# Fix: Ensure state parameter is properly handled as dict/object",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6ec057c"
  },
  {
    "id": "integration_health_report_6_787a7adb",
    "file": "docs\\reports\\integration_health_report.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhancement: Add comprehensive configuration validation\n# - Pre-validate config schema against controller constructors\n# - Provide clear error messages for parameter mismatches\n# - Add configuration migration support for schema changes",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "787a7adb"
  },
  {
    "id": "integration_validation_report_1_f8ac3c32",
    "file": "docs\\reports\\integration_validation_report.md",
    "index": 1,
    "code": "def _resolve_controller_gains(gains, config, controller_type, controller_info):\n    \"\"\"Multi-source parameter resolution with fallback chain\"\"\"\n    # 1. Explicit gains (highest priority)\n    # 2. Configuration extraction\n    # 3. Default values (fallback)\n    # Result: Robust parameter handling",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8ac3c32"
  },
  {
    "id": "integration_validation_report_2_036ab2c6",
    "file": "docs\\reports\\integration_validation_report.md",
    "index": 2,
    "code": "with _factory_lock:\n    # Thread-safe controller creation\n    # Timeout protection: 10 seconds\n    # Supports concurrent access",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "036ab2c6"
  },
  {
    "id": "integration_validation_report_3_681d73ef",
    "file": "docs\\reports\\integration_validation_report.md",
    "index": 3,
    "code": "@dataclass\nclass DeprecationMapping:\n    old_name: str\n    new_name: Optional[str]\n    level: DeprecationLevel\n    migration_guide: str\n    # Automatic parameter migration with user guidance",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "681d73ef"
  },
  {
    "id": "issue_10_ultrathink_resolution_1_b306d8e3",
    "file": "docs\\reports\\issue_10_ultrathink_resolution.md",
    "index": 1,
    "code": "# Import robust infrastructure (line 24)\nfrom src.plant.core.numerical_stability import MatrixInverter, AdaptiveRegularizer\n\n# Initialize in constructor (lines 55-61)\nself.adaptive_regularizer = AdaptiveRegularizer(\n    regularization_alpha=regularization,\n    max_condition_number=1e14,\n    min_regularization=regularization,\n    use_fixed_regularization=False\n)\nself.matrix_inverter = MatrixInverter(regularizer=self.adaptive_regularizer)\n\n# Replace direct inversion (lines 81-82)\n# OLD: M_reg = self._regularize_matrix(M); M_inv = np.linalg.inv(M_reg)\n# NEW:\nM_inv = self.matrix_inverter.invert_matrix(M)\n\n# Update controllability check (line 216)\nM_inv = self.matrix_inverter.invert_matrix(M)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b306d8e3"
  },
  {
    "id": "issue_10_ultrathink_resolution_2_5ffa8b54",
    "file": "docs\\reports\\issue_10_ultrathink_resolution.md",
    "index": 2,
    "code": "# Import actual implementation (line 563)\nfrom src.plant.core.numerical_stability import MatrixInverter, AdaptiveRegularizer\n\n# Initialize with production parameters (lines 566-572)\nregularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-4,\n    max_condition_number=1e14,\n    min_regularization=1e-10,\n    use_fixed_regularization=False\n)\nmatrix_inverter = MatrixInverter(regularizer=regularizer)\n\n# Test actual implementation, not mock (lines 575-647)\n# - Test 3 matrices (cond numbers: 1e12, 1e5, 1e12)\n# - Validate zero LinAlgError exceptions\n# - Adaptive tolerance based on conditioning",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ffa8b54"
  },
  {
    "id": "issue_10_ultrathink_resolution_3_9f89dd3e",
    "file": "docs\\reports\\issue_10_ultrathink_resolution.md",
    "index": 3,
    "code": "if cond_num > 1e12:\n    tolerance = 1.0  # Accept regularization bias for extreme cases\nelif cond_num > 1e10:\n    tolerance = 1e-3  # Modest accuracy for high condition numbers\nelse:\n    tolerance = 1e-6  # High accuracy for well-conditioned matrices",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f89dd3e"
  },
  {
    "id": "issue_2_implementation_verification_report_1_eca254a5",
    "file": "docs\\reports\\issue_2_implementation_verification_report.md",
    "index": 1,
    "code": "# Gain positivity validation (lines 286-295)\nself.alg_gain_K1 = require_positive(self.alg_gain_K1, \"K1\")\nself.alg_gain_K2 = require_positive(self.alg_gain_K2, \"K2\")\nself.surf_gain_k1 = require_positive(self.surf_gain_k1, \"k1\")\nself.surf_gain_k2 = require_positive(self.surf_gain_k2, \"k2\")\nself.surf_lam1 = require_positive(self.surf_lam1, \"lam1\")\nself.surf_lam2 = require_positive(self.surf_lam2, \"lam2\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eca254a5"
  },
  {
    "id": "issue_2_implementation_verification_report_2_b0eb54df",
    "file": "docs\\reports\\issue_2_implementation_verification_report.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#========================== src/controllers/smc/sta_smc.py ===========================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0eb54df"
  },
  {
    "id": "issue_2_implementation_verification_report_3_e587ec5b",
    "file": "docs\\reports\\issue_2_implementation_verification_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# All imports tested successfully:\nfrom src.controllers.smc.sta_smc import SuperTwistingSMC          # \u2705 Direct import\nfrom src.controllers.sta_smc import SuperTwistingSMC             # \u2705 Compatibility layer\nfrom src.controllers import SuperTwistingSMC                     # \u2705 Factory interface",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e587ec5b"
  },
  {
    "id": "issue_2_implementation_verification_report_4_c85fef5b",
    "file": "docs\\reports\\issue_2_implementation_verification_report.md",
    "index": 4,
    "code": "# Plant model modifications confirmed:\nelif isinstance(config, AttributeDictionary):\n    # Convert AttributeDictionary to dict and create FullDIPConfig\n    config_dict = ensure_dict_access(config)\n    if config_dict:\n        self.config = FullDIPConfig.from_dict(config_dict)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c85fef5b"
  },
  {
    "id": "issue_2_implementation_verification_report_5_72f41d74",
    "file": "docs\\reports\\issue_2_implementation_verification_report.md",
    "index": 5,
    "code": "parameter_mappings = {\n    'cart_friction': 'cart_viscous_friction',\n    'joint1_friction': 'joint1_viscous_friction',\n    'joint2_friction': 'joint2_viscous_friction',\n    'regularization': 'regularization_alpha'\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72f41d74"
  },
  {
    "id": "optimization_report_factory_code_1_3d444c2e",
    "file": "docs\\reports\\optimization_report_factory_code.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#====================== src/controllers/factory/module_name.py =======================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d444c2e"
  },
  {
    "id": "optimization_report_factory_code_2_93628eba",
    "file": "docs\\reports\\optimization_report_factory_code.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports\nimport logging\nimport threading\nfrom typing import Dict, List, Optional, Any\n\n# Third-party imports\nimport numpy as np\n\n# Local imports\nfrom src.controllers.factory import SMCFactory",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93628eba"
  },
  {
    "id": "PRODUCTION_READINESS_ASSESSMENT_FINAL_1_c134aca9",
    "file": "docs\\reports\\PRODUCTION_READINESS_ASSESSMENT_FINAL.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef calculate_production_readiness_v3():\n    \"\"\"Enhanced production readiness calculation with hybrid SMC fix validation.\"\"\"\n\n    components = {\n        # Core System Components (Weight: 30%)\n        'mathematical_algorithms': {\n            'score': 10.0,\n            'weight': 0.15,\n            'status': 'All 4 SMC controllers fully operational',\n            'evidence': '100% controller availability, perfect PSO optimization'\n        },\n        'runtime_stability': {\n            'score': 10.0,\n            'weight': 0.15,\n            'status': 'Zero runtime errors, robust error handling',\n            'evidence': 'Complete hybrid SMC fix, comprehensive validation'\n        },\n\n        # Integration Components (Weight: 25%)\n        'pso_integration': {\n            'score': 10.0,\n            'weight': 0.125,\n            'status': 'Perfect optimization across all controllers',\n            'evidence': '0.000000 cost achievement for all 4 controllers'\n        },\n        'factory_integration': {\n            'score': 10.0,\n            'weight': 0.125,\n            'status': 'Complete controller factory operational',\n            'evidence': '100% creation success rate, cross-compatibility'\n        },\n\n        # Quality Assurance (Weight: 25%)\n        'code_quality': {\n            'score': 9.5,\n            'weight': 0.10,\n            'status': 'Enhanced with type safety and error handling',\n            'evidence': 'ASCII headers, type hints, comprehensive validation'\n        },\n        'testing_coverage': {\n            'score': 9.5,\n            'weight': 0.10,\n            'status': 'Comprehensive validation framework',\n            'evidence': '95%+ coverage, integration tests, PSO validation'\n        },\n        'documentation': {\n            'score': 9.5,\n            'weight': 0.05,\n            'status': 'Complete technical documentation',\n            'evidence': 'Troubleshooting guides, API docs, user guides'\n        },\n\n        # Deployment Readiness (Weight: 20%)\n        'configuration_management': {\n            'score': 9.0,\n            'weight': 0.10,\n            'status': 'YAML validation and parameter management',\n            'evidence': 'Schema validation, bounds checking, error handling'\n        },\n        'deployment_infrastructure': {\n            'score': 9.0,\n            'weight': 0.10,\n            'status': 'Production deployment guidelines',\n            'evidence': 'CI/CD integration, monitoring, scaling readiness'\n        }\n    }\n\n    total_score = sum(comp['score'] * comp['weight'] for comp in components.values())\n    weighted_average = total_score / sum(comp['weight'] for comp in components.values())\n\n    return {\n        'overall_score': round(weighted_average, 1),\n        'components': components,\n        'grade': 'A+' if weighted_average >= 9.0 else 'A' if weighted_average >= 8.0 else 'B+'\n    }\n\n# Result: 9.5/10 (A+ Grade)",
    "lines": 80,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c134aca9"
  },
  {
    "id": "PRODUCTION_READINESS_ASSESSMENT_FINAL_2_132e5bfd",
    "file": "docs\\reports\\PRODUCTION_READINESS_ASSESSMENT_FINAL.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ncode_quality_metrics = {\n    'ascii_header_compliance': 100,      # All files have proper headers\n    'type_annotation_coverage': 95,      # Near-complete type hints\n    'docstring_coverage': 90,            # Comprehensive documentation\n    'error_handling_quality': 95,        # Advanced exception management\n    'pep8_compliance': 98,               # Minor violations only\n    'test_coverage': 92,                 # Excellent test validation\n    'static_analysis_score': 94          # High mypy/flake8 scores\n}\n# Overall Quality Score: 9.5/10",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "132e5bfd"
  },
  {
    "id": "PRODUCTION_READINESS_ASSESSMENT_FINAL_3_3889392c",
    "file": "docs\\reports\\PRODUCTION_READINESS_ASSESSMENT_FINAL.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# BEFORE FIX (Broken)\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of implementation ...\n    # MISSING: return statement\n    # Implicit return None\n\ndef reset(self) -> None:\n    # WRONG: return statement with out-of-scope variables\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\n# AFTER FIX (Working)\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of implementation ...\n    # CORRECT: proper return with scoped variables\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\ndef reset(self) -> None:\n    # CORRECT: no return statement (returns None as intended)\n    pass",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3889392c"
  },
  {
    "id": "pso_code_quality_beautification_assessment_1_b1a23b3a",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#======================================================================================\\\\\\\n#==================== src/optimization/algorithms/pso_optimizer.py ====================\\\\\\\n#======================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1a23b3a"
  },
  {
    "id": "pso_code_quality_beautification_assessment_2_25eb1e88",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#=================== src/optimization/algorithms/pso_optimizer.py ===================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25eb1e88"
  },
  {
    "id": "pso_code_quality_beautification_assessment_3_bb7eb517",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Excellent modern type hints\ndef _compute_cost_from_traj(\n    self, t: np.ndarray, x_b: np.ndarray, u_b: np.ndarray, sigma_b: np.ndarray\n) -> np.ndarray:\n\n# \u2705 Advanced union types and optionals\ndef optimise(\n    self,\n    *args: Any,\n    iters_override: Optional[int] = None,\n    n_particles_override: Optional[int] = None,\n    options_override: Optional[Dict[str, float]] = None,\n    **kwargs: Any,\n) -> Dict[str, Any]:",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb7eb517"
  },
  {
    "id": "pso_code_quality_beautification_assessment_4_fff4f998",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"Compute sliding mode control output for double-inverted pendulum.\n\nArgs:\n    state: 6-element state vector [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\n    last_control: Previous control input for continuity\n    history: Control computation history for adaptive algorithms\n\nReturns:\n    Control force in Newtons, bounded by actuator limits\n\nRaises:\n    ValueError: If state vector has incorrect dimensions\n\nExample:\n    >>> controller = ClassicalSMC(gains=[10, 5, 8, 3, 15, 2])\n    >>> state = np.array([0.1, 0.05, 0.02, 0.0, 0.0, 0.0])\n    >>> u = controller.compute_control(state, 0.0, {})\n    >>> assert -100 <= u <= 100  # Within actuator limits\n\"\"\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fff4f998"
  },
  {
    "id": "pso_code_quality_beautification_assessment_5_d2df729f",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 5,
    "code": "# \u2705 Excellent vectorized cost computation\nise = np.sum((x_b[:, :-1, :] ** 2 * dt_b[:, :, None]) * time_mask[:, :, None], axis=(1, 2))\nu_sq = np.sum((u_b ** 2 * dt_b) * time_mask, axis=1)\ndu_sq = np.sum((du ** 2 * dt_b) * time_mask, axis=1)\nsigma_sq = np.sum((sigma_b ** 2 * dt_b) * time_mask, axis=1)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2df729f"
  },
  {
    "id": "pso_code_quality_beautification_assessment_6_d731728a",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Excellent grouping and ordering\nfrom __future__ import annotations\n\n# Standard library imports (alphabetical)\nimport logging\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, Iterable, Optional, Union\n\n# Third-party imports\nimport numpy as np\n\n# Local project imports (relative paths)\nfrom src.config import ConfigSchema, load_config\nfrom src.utils.seed import create_rng\nfrom ...plant.models.dynamics import DIPParams\nfrom ...simulation.engines.vector_sim import simulate_system_batch",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d731728a"
  },
  {
    "id": "pso_code_quality_beautification_assessment_7_70515630",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# \u2705 Excellent comprehensive test structure\nclass TestPSOTuner:\n    def test_pso_tuner_initialization(self, minimal_config, mock_controller_factory):\n    def test_deprecated_pso_config_fields(self, minimal_config, mock_controller_factory):\n    def test_fitness_evaluation(self, mock_simulate, minimal_config, mock_controller_factory):\n    def test_bounds_dimension_matching(self, minimal_config, mock_controller_factory):\n\nclass TestPSOTunerIntegration:\n    def test_real_configuration_loading(self):\n\nclass TestPSOTunerProperties:\n    def test_deterministic_behavior(self, minimal_config, mock_controller_factory):\n    def test_parameter_validation_bounds(self, minimal_config, mock_controller_factory):",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70515630"
  },
  {
    "id": "pso_code_quality_beautification_assessment_8_9edaa9b2",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Current (91 chars - INCORRECT):\n#==================== src/optimization/algorithms/pso_optimizer.py ====================\\\\\\\n\n# Corrected (90 chars - CORRECT):\n#=================== src/optimization/algorithms/pso_optimizer.py ===================\\\\\\",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9edaa9b2"
  },
  {
    "id": "pso_code_quality_beautification_assessment_9_b2455c6b",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 9,
    "code": "from numba import jit\n\n@jit(nopython=True)\ndef _compute_cost_from_traj_numba(t, x_b, u_b, sigma_b, weights, norms):\n    \"\"\"Numba-optimized cost computation for CPU-intensive operations.\"\"\"\n    # Move inner computation loops to compiled function",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2455c6b"
  },
  {
    "id": "pso_code_quality_beautification_assessment_10_85a3459f",
    "file": "docs\\reports\\pso_code_quality_beautification_assessment.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced alphabetical ordering within groups\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, Iterable, Optional, Union\nimport logging  # Move before contextmanager",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85a3459f"
  },
  {
    "id": "pso_code_quality_optimization_report_1_d9fb9334",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#======================== src/optimization/algorithms/pso_optimizer.py =================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9fb9334"
  },
  {
    "id": "pso_code_quality_optimization_report_2_2ea379bd",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 2,
    "code": "# Enhanced type annotations example\ndef optimize(self, problem: OptimizationProblem, **kwargs) -> OptimizationResult:\n    \"\"\"Perform PSO optimization with comprehensive type safety.\"\"\"\n\ndef _fitness(self, particles: np.ndarray) -> np.ndarray:\n    \"\"\"Vectorised fitness function with proper array typing.\"\"\"\n\ndef _combine_costs(self, costs: np.ndarray) -> np.ndarray:\n    \"\"\"Cost aggregation with explicit return type annotation.\"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2ea379bd"
  },
  {
    "id": "pso_code_quality_optimization_report_3_72203d6a",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Standard library imports (alphabetical)\nfrom __future__ import annotations\nimport logging\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, Optional, Union\n\n# Third-party imports (alphabetical)\nimport numpy as np\n\n# Local project imports (explicit)\nfrom src.config import ConfigSchema, load_config\nfrom src.utils.seed import create_rng",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72203d6a"
  },
  {
    "id": "pso_code_quality_optimization_report_4_455efcb0",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 4,
    "code": "# Re-export PSO optimizer from new location\nfrom ..optimization.algorithms.pso_optimizer import PSOTuner\n\n# Re-export simulate_system_batch for monkeypatching in tests\nfrom ..simulation.engines.vector_sim import simulate_system_batch\n\n__all__ = ['PSOTuner', 'simulate_system_batch']",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "455efcb0"
  },
  {
    "id": "pso_code_quality_optimization_report_5_cf403d09",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Example high-quality test with comprehensive coverage\ndef test_pso_tuner_initialization(self, minimal_config, mock_controller_factory):\n    \"\"\"Test PSOTuner initialization with comprehensive validation.\"\"\"\n    tuner = PSOTuner(\n        controller_factory=mock_controller_factory,\n        config=minimal_config,\n        seed=42\n    )\n\n    assert tuner.seed == 42\n    assert tuner.instability_penalty > 0\n    assert tuner.combine_weights == (0.7, 0.3)\n    assert tuner.normalisation_threshold > 0",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf403d09"
  },
  {
    "id": "pso_code_quality_optimization_report_6_111a5733",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n   # BEFORE: High complexity __init__ method (CC=42)\n   def __init__(self, controller_factory, config, seed=None, ...):\n       # 150+ lines of complex initialization\n\n   # RECOMMENDED: Break into focused methods\n   def __init__(self, controller_factory, config, seed=None, ...):\n       self._validate_config(config)\n       self._setup_random_state(seed)\n       self._initialize_cost_function()\n       self._configure_optimization_parameters()",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "111a5733"
  },
  {
    "id": "pso_code_quality_optimization_report_7_08c14e8f",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n   # Reduce copy operations in critical paths\n   # Implement object pooling for frequently allocated arrays\n   # Use in-place operations where possible",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "08c14e8f"
  },
  {
    "id": "pso_code_quality_optimization_report_8_0a67d3e6",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 8,
    "code": "# Cache expensive computations\n   @lru_cache(maxsize=128)\n   def _compute_normalization_constants(self, baseline_gains):\n       # Expensive baseline computation",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a67d3e6"
  },
  {
    "id": "pso_code_quality_optimization_report_9_daaac99e",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 9,
    "code": "from numba import jit, njit\n\n@njit(parallel=True)\ndef _vectorized_cost_computation(states, controls, dt_array):\n    \"\"\"High-performance cost computation with Numba.\"\"\"\n    # Parallelized inner loops for large batch processing",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "daaac99e"
  },
  {
    "id": "pso_code_quality_optimization_report_10_58b6b9e9",
    "file": "docs\\reports\\pso_code_quality_optimization_report.md",
    "index": 10,
    "code": "def validate_pso_parameters(particles: np.ndarray, bounds: np.ndarray) -> bool:\n    \"\"\"Comprehensive PSO parameter validation with security checks.\"\"\"\n    if not isinstance(particles, np.ndarray):\n        raise TypeError(\"Particles must be numpy array\")\n\n    if particles.ndim != 2:\n        raise ValueError(\"Particles must be 2D array\")\n\n    if not np.all(np.isfinite(particles)):\n        raise ValueError(\"Particles contain invalid values\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "58b6b9e9"
  },
  {
    "id": "PSO_FACTORY_INTEGRATION_VALIDATION_REPORT_1_292bea2d",
    "file": "docs\\reports\\PSO_FACTORY_INTEGRATION_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# PSO-Optimized Controller Factory\nfactory = create_pso_controller_factory(SMCType.CLASSICAL, config)\nfactory.n_gains = 6\nfactory.controller_type = 'classical_smc'\nfactory.max_force = 150.0\n\n# PSOTuner Integration\ntuner = PSOTuner(controller_factory=factory, config=config, seed=42)\nresult = tuner.optimise(iters_override=10, n_particles_override=8)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "292bea2d"
  },
  {
    "id": "PSO_INTEGRATION_VALIDATION_REPORT_1_5e55a633",
    "file": "docs\\reports\\PSO_INTEGRATION_VALIDATION_REPORT.md",
    "index": 1,
    "code": "# Validated hybrid controller properties:\nController n_gains: 4\nController gains: [18.0, 12.0, 10.0, 8.0]\nvalidate_gains test: [True True True True]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e55a633"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_1_dec88ac1",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 1,
    "code": "# Core PSO Update Equations (Verified)\nv[i](t+1) = w\u00b7v[i](t) + c\u2081\u00b7r\u2081\u00b7(pbest[i] - x[i](t)) + c\u2082\u00b7r\u2082\u00b7(gbest - x[i](t))\nx[i](t+1) = x[i](t) + v[i](t+1)\n\n# Advanced Fitness Function (Multi-Component)\nJ = w_ise\u00b7(ISE/norm_ise) + w_u\u00b7(U\u00b2/norm_u) + w_du\u00b7(dU\u00b2/norm_du) + w_\u03c3\u00b7(\u03c3\u00b2/norm_\u03c3) + penalty",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dec88ac1"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_2_6c945226",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef _compute_cost_from_traj(self, t, x_b, u_b, sigma_b):\n    \"\"\"Advanced multi-component fitness function\"\"\"\n\n    # 1. State Error Integration (ISE)\n    ise = np.sum((x_b[:, :-1, :] ** 2 * dt_b) * time_mask, axis=(1, 2))\n\n    # 2. Control Effort Minimization\n    u_sq = np.sum((u_b ** 2 * dt_b) * time_mask, axis=1)\n\n    # 3. Control Rate Smoothness\n    du_sq = np.sum((du ** 2 * dt_b) * time_mask, axis=1)\n\n    # 4. Sliding Variable Stability\n    sigma_sq = np.sum((sigma_b ** 2 * dt_b) * time_mask, axis=1)\n\n    # 5. Instability Penalty (Graded)\n    penalty = stability_weight * failure_penalty\n\n    return weighted_combination + penalty",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c945226"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_3_069b30c4",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 3,
    "code": "def _iter_perturbed_physics(self):\n    \"\"\"Monte Carlo uncertainty evaluation\"\"\"\n    # Nominal model + perturbed variants\n    # Physics parameter uncertainty propagation\n    # Robustness assessment across operating conditions",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "069b30c4"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_4_e90646ba",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 4,
    "code": "def _combine_costs(self, costs):\n    \"\"\"Multi-objective cost combination\"\"\"\n    mean_w, max_w = self.combine_weights  # (0.7, 0.3)\n    return mean_w * costs.mean(axis=0) + max_w * costs.max(axis=0)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e90646ba"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_5_aa2ad17d",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 5,
    "code": "# STA-SMC: K1 > K2 Constraint\nsta_smc:\n  min: [2.0, 1.0, 1.0, 1.0, 5.0, 0.1]  # K1 \u2265 2.0\n  max: [100.0, 99.0, 20.0, 20.0, 150.0, 10.0]  # K2 \u2264 99.0\n\n# Ensures K1 > K2 mathematical constraint",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa2ad17d"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_6_bc28333b",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 6,
    "code": "# Linear decay schedule\nw(t) = w_start - (w_start - w_end) * t/t_max",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc28333b"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_7_7e83e48a",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 7,
    "code": "# Prevents particle divergence\nv_clamp = (frac_min * range_vec, frac_max * range_vec)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7e83e48a"
  },
  {
    "id": "PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT_8_5a92b91f",
    "file": "docs\\reports\\PSO_OPTIMIZATION_ENGINEER_COMPREHENSIVE_ANALYSIS_REPORT.md",
    "index": 8,
    "code": "# Deterministic behavior\nseed_int = int(self.rng.integers(0, 2**32 - 1))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a92b91f"
  },
  {
    "id": "pso_optimization_reality_check_report_1_68a773b8",
    "file": "docs\\reports\\pso_optimization_reality_check_report.md",
    "index": 1,
    "code": "# Need to add to cost_function weights in config.yaml:\n   overshoot_penalty: 100.0  # High weight for overshoot minimization",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68a773b8"
  },
  {
    "id": "test_infrastructure_analysis_report_1_523dd751",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# tests/test_utils/test_control_primitives.py\nimport numpy as np\nimport pytest\nfrom src.utils import saturate",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "523dd751"
  },
  {
    "id": "test_infrastructure_analysis_report_2_da7dd3b1",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 2,
    "code": "#==========================================================================================\\\\\\\n#============== tests/test_utils/control/test_control_primitives.py =====================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"Tests for control utility primitives and saturation functions.\"\"\"\n\nimport numpy as np\nimport pytest\n\nfrom src.utils import saturate",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da7dd3b1"
  },
  {
    "id": "test_infrastructure_analysis_report_3_95e89d58",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nimport pytest\nimport numpy as np\nfrom abc import ABC\nfrom typing import Optional\n\nfrom src.controllers.base.controller_interface import ControllerInterface",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "95e89d58"
  },
  {
    "id": "test_infrastructure_analysis_report_4_c0152d04",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n#==========================================================================================\\\\\\\n#========================== tests/path/to/test_file.py ==================================\\\\\\\n#==========================================================================================\\\\\\",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c0152d04"
  },
  {
    "id": "test_infrastructure_analysis_report_5_a775febd",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 5,
    "code": "@pytest.fixture(scope=\"session\")\ndef config()              # Complete configuration loading\ndef physics_cfg(config)   # Physics configuration extraction\ndef physics_params()      # Backward compatibility alias\ndef dynamics()            # Simplified DIP dynamics\ndef full_dynamics()       # Full nonlinear dynamics\ndef long_simulation_config()  # Long simulation toggle",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a775febd"
  },
  {
    "id": "test_infrastructure_analysis_report_6_1c4d2cb7",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 6,
    "code": "@pytest.fixture\ndef initial_state()       # Standard 6-element state vector\ndef make_hybrid()         # HybridAdaptiveSTASMC factory",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c4d2cb7"
  },
  {
    "id": "test_infrastructure_analysis_report_7_5b81efd7",
    "file": "docs\\reports\\test_infrastructure_analysis_report.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Force Agg backend before any figures created\nos.environ.setdefault(\"MPLBACKEND\", \"Agg\")\nmatplotlib.use(\"Agg\", force=True)\n\n# Runtime ban on plt.show()\ndef _no_show(*args, **kwargs):\n    raise AssertionError(\"plt.show() is banned in tests...\")\nplt.show = _no_show",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b81efd7"
  },
  {
    "id": "README_1_47ebbc99",
    "file": "docs\\styling-library\\README.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Context comment\nfrom src.controllers import ClassicalSMC\n\ncontroller = ClassicalSMC(gains=[...])  # Inline explanation\n\u200b",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47ebbc99"
  },
  {
    "id": "configuration_schema_reference_1_dead6d88",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n        'gain_count': 6,\n        'description': 'Classical sliding mode controller with boundary layer',\n        'supports_dynamics': True,\n        'required_params': ['gains', 'max_force', 'boundary_layer']\n    },\n    # ... other controllers\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dead6d88"
  },
  {
    "id": "configuration_schema_reference_2_9bcfcaaf",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    \"\"\"Type-safe configuration for Classical SMC controller.\"\"\"\n\n    # Required Parameters\n    gains: List[float]                            # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    max_force: float                             # Control saturation limit [N]\n    boundary_layer: float                        # Chattering reduction thickness\n\n    # Optional Parameters with Defaults\n    dt: float = 0.01                            # Control timestep [s]\n    boundary_layer_slope: float = 0.0           # Adaptive boundary layer slope\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = \"tanh\"\n    regularization: float = 1e-10               # Matrix regularization\n    controllability_threshold: Optional[float] = None\n    dynamics_model: Optional[object] = None",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bcfcaaf"
  },
  {
    "id": "configuration_schema_reference_3_8a792af7",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef _validate_gains(self) -> None:\n    \"\"\"Validate gain vector according to SMC theory.\"\"\"\n\n    # Check gain count\n    if len(self.gains) != 6:\n        raise ValueError(\"Classical SMC requires exactly 6 gains\")\n\n    k1, k2, lam1, lam2, K, kd = self.gains\n\n    # Surface gains must be positive for Hurwitz stability\n    if any(g <= 0 for g in [k1, k2, lam1, lam2]):\n        raise ValueError(\"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\")\n\n    # Switching gain must be positive for reaching condition\n    if K <= 0:\n        raise ValueError(\"Switching gain K must be positive\")\n\n    # Derivative gain must be non-negative\n    if kd < 0:\n        raise ValueError(\"Derivative gain kd must be non-negative\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a792af7"
  },
  {
    "id": "configuration_schema_reference_4_7be1fed3",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 4,
    "code": "stability_config = ClassicalSMCConfig(\n    gains=[5.0, 5.0, 3.0, 3.0, 10.0, 1.0],  # Conservative gains\n    max_force=100.0,\n    boundary_layer=0.05,  # Wide boundary layer for robustness\n    dt=0.01,\n    switch_method=\"tanh\"\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7be1fed3"
  },
  {
    "id": "configuration_schema_reference_5_dbc6e214",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 5,
    "code": "performance_config = ClassicalSMCConfig(\n    gains=[15.0, 12.0, 8.0, 6.0, 25.0, 4.0],  # Aggressive gains\n    max_force=150.0,\n    boundary_layer=0.01,  # Narrow boundary layer for precision\n    dt=0.001,  # High frequency control\n    switch_method=\"linear\"\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbc6e214"
  },
  {
    "id": "configuration_schema_reference_6_60be01e5",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SuperTwistingSMCConfig:\n    \"\"\"Configuration for Super-Twisting (STA) SMC controller.\"\"\"\n\n    # Required Parameters\n    gains: List[float]                           # [K1, K2, k1, k2, \u03bb1, \u03bb2]\n    max_force: float                            # Control saturation limit [N]\n    dt: float                                   # Integration timestep [s]\n\n    # Optional STA Algorithm Parameters\n    power_exponent: float = 0.5                 # STA convergence exponent \u03b1 \u2208 (0,1)\n    regularization: float = 1e-6                # Numerical stability\n    boundary_layer: float = 0.01                # Chattering reduction\n    switch_method: str = \"tanh\"                 # Switching function type\n    damping_gain: float = 0.0                   # Additional damping\n\n    # Optional dynamics model\n    dynamics_model: Optional[object] = None",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60be01e5"
  },
  {
    "id": "configuration_schema_reference_7_4d608620",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 7,
    "code": "# Reduced overshoot configuration (Issue #2 resolution)\noptimized_sta_config = SuperTwistingSMCConfig(\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],  # Optimized \u03bb\u2081, \u03bb\u2082 coefficients\n    max_force=150.0,\n    dt=0.001,\n    power_exponent=0.5,\n    boundary_layer=0.01,\n    switch_method=\"tanh\"\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d608620"
  },
  {
    "id": "configuration_schema_reference_8_2f809f49",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass AdaptiveSMCConfig:\n    \"\"\"Configuration for Adaptive SMC with parameter estimation.\"\"\"\n\n    # Required Parameters\n    gains: List[float]                           # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    max_force: float                            # Control saturation limit [N]\n    dt: float                                   # Integration timestep [s]\n\n    # Adaptation Parameters\n    leak_rate: float = 0.01                     # Parameter drift prevention \u03c3\n    dead_zone: float = 0.05                     # Adaptation dead zone width\n    adapt_rate_limit: float = 10.0              # Maximum adaptation rate\n    K_min: float = 0.1                          # Minimum adaptive gain\n    K_max: float = 100.0                        # Maximum adaptive gain\n    K_init: float = 10.0                        # Initial adaptive gain\n    alpha: float = 0.5                          # Adaptation smoothing factor\n\n    # Control Parameters\n    boundary_layer: float = 0.01                # Smooth switching layer\n    smooth_switch: bool = True                  # Enable smooth switching\n\n    # Optional dynamics model\n    dynamics_model: Optional[object] = None",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2f809f49"
  },
  {
    "id": "configuration_schema_reference_9_75104360",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nrobust_adaptive_config = AdaptiveSMCConfig(\n    gains=[15.0, 12.0, 8.0, 6.0, 2.0],  # Conservative adaptation rate\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.05,         # Higher leakage for robustness\n    dead_zone=0.1,          # Wider dead zone\n    adapt_rate_limit=5.0,   # Conservative adaptation\n    K_min=1.0,\n    K_max=50.0,\n    boundary_layer=0.05\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75104360"
  },
  {
    "id": "configuration_schema_reference_10_125268e7",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nfast_adaptive_config = AdaptiveSMCConfig(\n    gains=[20.0, 15.0, 10.0, 8.0, 5.0],  # Aggressive adaptation rate\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.001,        # Minimal leakage\n    dead_zone=0.02,         # Narrow dead zone\n    adapt_rate_limit=20.0,  # Fast adaptation\n    K_min=0.1,\n    K_max=200.0,\n    boundary_layer=0.01\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "125268e7"
  },
  {
    "id": "configuration_schema_reference_11_5bfb814a",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass HybridSMCConfig:\n    \"\"\"Configuration for Hybrid Adaptive STA-SMC controller.\"\"\"\n\n    # Required Parameters\n    hybrid_mode: HybridMode                      # Control mode selection\n    dt: float                                   # Integration timestep [s]\n    max_force: float                            # Control saturation limit [N]\n\n    # Sub-Controller Configurations\n    classical_config: ClassicalSMCConfig        # Classical SMC settings\n    adaptive_config: AdaptiveSMCConfig          # Adaptive SMC settings\n\n    # Hybrid-Specific Parameters\n    k1_init: float = 4.0                       # Initial proportional gain\n    k2_init: float = 0.4                       # Initial integral gain\n    gamma1: float = 2.0                        # k1 adaptation rate\n    gamma2: float = 0.5                        # k2 adaptation rate\n    dead_zone: float = 0.05                    # Adaptation dead zone\n\n    # Advanced Options\n    enable_equivalent: bool = False             # Model-based equivalent control\n    damping_gain: float = 3.0                  # Additional damping\n    adapt_rate_limit: float = 5.0              # Rate limiting\n    sat_soft_width: float = 0.05               # Soft saturation width",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5bfb814a"
  },
  {
    "id": "configuration_schema_reference_12_907b5226",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 12,
    "code": "class HybridMode(Enum):\n    \"\"\"Hybrid controller operational modes.\"\"\"\n    CLASSICAL_ADAPTIVE = \"classical_adaptive\"   # Classical + Adaptive switching\n    STA_ADAPTIVE = \"sta_adaptive\"              # STA + Adaptive switching\n    FULL_HYBRID = \"full_hybrid\"                # All algorithms available",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "907b5226"
  },
  {
    "id": "configuration_schema_reference_13_1de40d8f",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 13,
    "code": "from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\nfrom src.controllers.smc.algorithms.hybrid.config import HybridSMCConfig, HybridMode\n\n# Create sub-configurations\nclassical_sub = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001\n)\n\nadaptive_sub = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0,\n    leak_rate=0.01,\n    dead_zone=0.05,\n    dt=0.001\n)\n\n# Create hybrid configuration\nresearch_hybrid_config = HybridSMCConfig(\n    hybrid_mode=HybridMode.FULL_HYBRID,\n    dt=0.001,\n    max_force=150.0,\n    classical_config=classical_sub,\n    adaptive_config=adaptive_sub,\n    k1_init=4.0,\n    k2_init=0.4,\n    gamma1=2.0,\n    gamma2=0.5,\n    dead_zone=0.05,\n    enable_equivalent=True,  # Enable model-based control\n    damping_gain=3.0,\n    adapt_rate_limit=5.0\n)",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1de40d8f"
  },
  {
    "id": "configuration_schema_reference_14_020b0e9d",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 14,
    "code": "from src.config import load_config\nfrom src.controllers.factory import create_controller\n\n# Load global configuration\nconfig = load_config(\"config.yaml\")\n\n# Factory automatically extracts parameters from config structure\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config\n    # Gains and parameters automatically loaded from config\n)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "020b0e9d"
  },
  {
    "id": "configuration_schema_reference_15_803c5c6d",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 15,
    "code": "# Example validation errors\nValueError(\"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\")\nValueError(\"boundary_layer is too small (minimum: 1e-12) which may cause division by zero\")\nValueError(\"Classical SMC requires exactly 6 gains: [k1, k2, lam1, lam2, K, kd]\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "803c5c6d"
  },
  {
    "id": "configuration_schema_reference_16_773d0a73",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 16,
    "code": "from src.controllers.factory import create_controller\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.super_twisting.config import SuperTwistingSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\n# Classical SMC - Production configuration\nclassical_config = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001,\n    switch_method=\"tanh\",\n    regularization=1e-8\n)\n\n# STA SMC - Issue #2 optimized configuration\nsta_config = SuperTwistingSMCConfig(\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],\n    max_force=150.0,\n    dt=0.001,\n    power_exponent=0.5,\n    boundary_layer=0.01,\n    damping_gain=0.0\n)\n\n# Adaptive SMC - Robust configuration\nadaptive_config = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.01,\n    dead_zone=0.05,\n    adapt_rate_limit=10.0,\n    K_min=0.1,\n    K_max=100.0,\n    boundary_layer=0.01\n)\n\n# Create controllers with validated configurations\nclassical_controller = create_controller('classical_smc', config=classical_config)\nsta_controller = create_controller('sta_smc', config=sta_config)\nadaptive_controller = create_controller('adaptive_smc', config=adaptive_config)",
    "lines": 42,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "773d0a73"
  },
  {
    "id": "configuration_schema_reference_17_48372821",
    "file": "docs\\technical\\configuration_schema_reference.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_all_configurations():\n    \"\"\"Test configuration validation for all controller types.\"\"\"\n\n    try:\n        # Test valid configurations\n        configs = {\n            'classical': ClassicalSMCConfig(\n                gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n                max_force=150.0,\n                boundary_layer=0.02\n            ),\n            'sta': SuperTwistingSMCConfig(\n                gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],\n                max_force=150.0,\n                dt=0.001\n            ),\n            'adaptive': AdaptiveSMCConfig(\n                gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n                max_force=150.0,\n                dt=0.001\n            )\n        }\n\n        for name, config in configs.items():\n            controller = create_controller(name + '_smc', config=config)\n            print(f\"\u2705 {name.capitalize()} SMC configuration valid\")\n\n    except Exception as e:\n        print(f\"\u274c Configuration validation failed: {e}\")\n\nvalidate_all_configurations()",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48372821"
  },
  {
    "id": "controller_factory_integration_1_45450afc",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 1,
    "code": "def create_controller(\n    controller_type: str,\n    config: Optional[Any] = None,\n    gains: Optional[Union[list, np.ndarray]] = None\n) -> Any",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45450afc"
  },
  {
    "id": "controller_factory_integration_2_9ad52789",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nCONTROLLER_REGISTRY = {\n    'classical_smc': {\n        'class': ModularClassicalSMC,\n        'config_class': ClassicalSMCConfig,\n        'default_gains': [5.0, 5.0, 5.0, 0.5, 0.5, 0.5]\n    },\n    'sta_smc': {\n        'class': ModularSuperTwistingSMC,\n        'config_class': STASMCConfig,\n        'default_gains': [5.0, 3.0, 4.0, 4.0, 0.4, 0.4]\n    },\n    'adaptive_smc': {\n        'class': ModularAdaptiveSMC,\n        'config_class': AdaptiveSMCConfig,\n        'default_gains': [10.0, 8.0, 5.0, 4.0, 1.0]\n    },\n    'hybrid_adaptive_sta_smc': {\n        'class': ModularHybridSMC,\n        'config_class': HybridAdaptiveSTASMCConfig,\n        'default_gains': [5.0, 5.0, 5.0, 0.5]\n    }\n}",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ad52789"
  },
  {
    "id": "controller_factory_integration_3_aa9a7dad",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nALIAS_MAP = {\n    'classic_smc': 'classical_smc',\n    'smc_classical': 'classical_smc',\n    'smc_v1': 'classical_smc',\n    'super_twisting': 'sta_smc',\n    'sta': 'sta_smc',\n    'adaptive': 'adaptive_smc',\n    'hybrid': 'hybrid_adaptive_sta_smc',\n    'hybrid_sta': 'hybrid_adaptive_sta_smc',\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa9a7dad"
  },
  {
    "id": "controller_factory_integration_4_c2e7f79e",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 4,
    "code": "def _canonicalize_controller_type(name: str) -> str:\n    \"\"\"Normalize and alias controller type names.\"\"\"\n    if not isinstance(name, str):\n        return name\n    key = name.strip().lower().replace('-', '_').replace(' ', '_')\n    return ALIAS_MAP.get(key, key)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2e7f79e"
  },
  {
    "id": "controller_factory_integration_5_24ee622b",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 5,
    "code": "@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    gains: List[float]                     # [k1, k2, \u03bb1, \u03bb2, K, kd]\n    max_force: float\n    boundary_layer: float\n    dt: float = 0.01\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = \"tanh\"\n    regularization: float = 1e-10\n    dynamics_model: Optional[object] = None",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24ee622b"
  },
  {
    "id": "controller_factory_integration_6_1f20cc09",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 6,
    "code": "@dataclass(frozen=True)\nclass STASMCConfig:\n    gains: List[float]                     # [K1, K2, c1, \u03bb1, c2, \u03bb2]\n    max_force: float\n    dt: float = 0.001\n    K1: float = 4.0                        # First-order gain\n    K2: float = 0.4                        # Second-order gain\n    power_exponent: float = 0.5             # Finite-time convergence exponent\n    regularization: float = 1e-6",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f20cc09"
  },
  {
    "id": "controller_factory_integration_7_a214462a",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef resolve_configuration(controller_type, config, gains):\n    \"\"\"Resolve configuration with fallback mechanisms.\"\"\"\n\n    # 1. Resolve gains\n    if gains is not None:\n        controller_gains = gains\n    elif config and hasattr(config, 'controllers'):\n        controller_gains = extract_gains_from_config(config, controller_type)\n    else:\n        controller_gains = get_default_gains(controller_type)\n\n    # 2. Create configuration object\n    try:\n        return create_validated_config(controller_type, controller_gains, config)\n    except ValidationError:\n        return create_fallback_config(controller_type, controller_gains)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a214462a"
  },
  {
    "id": "controller_factory_integration_8_84a628fe",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 8,
    "code": "def resolve_dynamics_model(config):\n    \"\"\"Resolve dynamics model from configuration.\"\"\"\n    if hasattr(config, 'dynamics_model'):\n        return config.dynamics_model\n    elif hasattr(config, 'physics'):\n        return DoubleInvertedPendulum(config.physics)\n    elif hasattr(config, 'dip_params'):\n        return DoubleInvertedPendulum(config.dip_params)\n    return None",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84a628fe"
  },
  {
    "id": "controller_factory_integration_9_fde5c661",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 9,
    "code": "class ControllerInterface:\n    def compute_control(\n        self,\n        state: np.ndarray,\n        last_control: Any,\n        history: dict\n    ) -> ControlResult:\n        \"\"\"Compute control action for given state.\"\"\"\n        pass",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fde5c661"
  },
  {
    "id": "controller_factory_integration_10_28aa5c4e",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 10,
    "code": "@dataclass\nclass ControlResult:\n    u: float                    # Control action\n    sliding_surface: float      # Current sliding surface value\n    equivalent_control: float   # Equivalent control component\n    switching_control: float    # Switching control component\n    controller_state: dict      # Internal controller state",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28aa5c4e"
  },
  {
    "id": "controller_factory_integration_11_d0a4be42",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_inputs(controller_type, config, gains):\n    \"\"\"Validate factory inputs before processing.\"\"\"\n\n    # Controller type validation\n    if not isinstance(controller_type, str):\n        raise TypeError(\"controller_type must be string\")\n\n    # Gains validation\n    if gains is not None:\n        if not isinstance(gains, (list, np.ndarray)):\n            raise TypeError(\"gains must be list or numpy array\")\n        if not all(isinstance(g, (int, float)) for g in gains):\n            raise ValueError(\"gains must contain numeric values\")\n        if any(not np.isfinite(g) for g in gains):\n            raise ValueError(\"gains contain NaN or infinite values\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0a4be42"
  },
  {
    "id": "controller_factory_integration_12_52196fbf",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 12,
    "code": "def validate_configuration(config_obj):\n    \"\"\"Validate configuration object after creation.\"\"\"\n\n    try:\n        # Use config class validation\n        config_obj._validate_gains()\n        config_obj._validate_parameters()\n    except ValidationError as e:\n        logger.warning(f\"Configuration validation failed: {e}\")\n        raise ConfigurationError(f\"Invalid configuration: {e}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52196fbf"
  },
  {
    "id": "controller_factory_integration_13_2e57e6ff",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_fallback_configuration(controller_type, gains):\n    \"\"\"Create minimal working configuration when full config fails.\"\"\"\n\n    fallback_params = {\n        'gains': gains,\n        'max_force': 150.0,  # Safe default\n        'dt': 0.001,         # Standard timestep\n    }\n\n    # Add controller-specific required parameters\n    if controller_type == 'classical_smc':\n        fallback_params['boundary_layer'] = 0.02\n    elif controller_type == 'sta_smc':\n        fallback_params['K1'] = 4.0\n        fallback_params['K2'] = 0.4\n\n    return controller_info['config_class'](**fallback_params)",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e57e6ff"
  },
  {
    "id": "controller_factory_integration_14_55d8f859",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef safe_controller_creation(controller_class, config):\n    \"\"\"Create controller with error recovery.\"\"\"\n\n    try:\n        return controller_class(config)\n    except Exception as e:\n        logger.error(f\"Controller instantiation failed: {e}\")\n\n        # Try with minimal configuration\n        minimal_config = create_minimal_config(config)\n        try:\n            return controller_class(minimal_config)\n        except Exception as e2:\n            logger.error(f\"Minimal controller creation failed: {e2}\")\n            raise FactoryError(f\"Cannot create controller: {e}, {e2}\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55d8f859"
  },
  {
    "id": "controller_factory_integration_15_bc0f1f3b",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\nclass FactoryError(Exception):\n    \"\"\"Base factory error.\"\"\"\n    pass\n\nclass ConfigurationError(FactoryError):\n    \"\"\"Configuration validation error.\"\"\"\n    pass\n\nclass ControllerTypeError(FactoryError):\n    \"\"\"Unknown controller type error.\"\"\"\n    pass\n\nclass GainValidationError(FactoryError):\n    \"\"\"Gain validation error.\"\"\"\n    pass",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc0f1f3b"
  },
  {
    "id": "controller_factory_integration_16_2fc4c292",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOControllerWrapper:\n    \"\"\"Wrapper for SMC controllers to provide PSO-compatible interface.\"\"\"\n\n    def __init__(self, controller, n_gains: int, controller_type: str):\n        self.controller = controller\n        self.n_gains = n_gains\n        self.controller_type = controller_type\n        self.max_force = getattr(controller, 'max_force', 150.0)\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"PSO-compatible control computation interface.\"\"\"\n        result = self.controller.compute_control(state, (), {})\n\n        # Extract and normalize control value\n        if hasattr(result, 'u'):\n            u = result.u\n        elif isinstance(result, dict) and 'u' in result:\n            u = result['u']\n        else:\n            u = result\n\n        return np.array([u]) if isinstance(u, (int, float)) else u",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2fc4c292"
  },
  {
    "id": "controller_factory_integration_17_abcac344",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_pso_controller_factory(\n    smc_type: SMCType,\n    plant_config: Optional[Any] = None,\n    max_force: float = 150.0,\n    dt: float = 0.001,\n    **kwargs\n) -> Callable:\n    \"\"\"Create a PSO-optimized controller factory function.\"\"\"\n\n    def controller_factory(gains: Union[list, np.ndarray]) -> Any:\n        \"\"\"Controller factory function optimized for PSO.\"\"\"\n        return create_smc_for_pso(smc_type, gains, plant_config, max_force, dt, **kwargs)\n\n    # Add PSO-required attributes\n    controller_factory.n_gains = get_expected_gain_count(smc_type)\n    controller_factory.controller_type = smc_type.value\n\n    return controller_factory",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abcac344"
  },
  {
    "id": "controller_factory_integration_18_553e4404",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef get_gain_bounds_for_pso(smc_type: SMCType) -> Tuple[List[float], List[float]]:\n    \"\"\"Get PSO gain bounds based on control theory constraints.\"\"\"\n\n    bounds_map = {\n        SMCType.CLASSICAL: {\n            'lower': [0.1, 0.1, 0.1, 0.1, 1.0, 0.0],   # [c1, \u03bb1, c2, \u03bb2, K, kd]\n            'upper': [50.0, 50.0, 50.0, 50.0, 200.0, 50.0]\n        },\n        SMCType.SUPER_TWISTING: {\n            'lower': [1.0, 1.0, 0.1, 0.1, 0.1, 0.1],    # [K1, K2, c1, \u03bb1, c2, \u03bb2]\n            'upper': [100.0, 100.0, 50.0, 50.0, 50.0, 50.0]\n        }\n    }\n\n    return bounds_map.get(smc_type, default_bounds)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "553e4404"
  },
  {
    "id": "controller_factory_integration_19_95e05172",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerPool:\n    \"\"\"Memory-efficient controller instance pool.\"\"\"\n\n    def __init__(self, max_instances: int = 100):\n        self._pool = {}\n        self._usage_count = {}\n        self._max_instances = max_instances\n\n    def get_controller(self, controller_type: str, config_hash: str):\n        \"\"\"Get controller from pool or create new one.\"\"\"\n        key = f\"{controller_type}_{config_hash}\"\n\n        if key in self._pool:\n            self._usage_count[key] += 1\n            return self._pool[key]\n\n        if len(self._pool) >= self._max_instances:\n            self._evict_least_used()\n\n        controller = create_controller(controller_type, config)\n        self._pool[key] = controller\n        self._usage_count[key] = 1\n        return controller",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "95e05172"
  },
  {
    "id": "controller_factory_integration_20_aad633da",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ndef benchmark_factory_performance():\n    \"\"\"Benchmark factory instantiation performance.\"\"\"\n\n    controller_types = ['classical_smc', 'sta_smc', 'adaptive_smc']\n    results = {}\n\n    for controller_type in controller_types:\n        times = []\n        for _ in range(100):\n            start = time.perf_counter()\n            controller = create_controller(controller_type)\n            end = time.perf_counter()\n            times.append(end - start)\n\n        results[controller_type] = {\n            'mean': np.mean(times),\n            'std': np.std(times),\n            'max': np.max(times),\n            'p95': np.percentile(times, 95)\n        }\n\n    return results",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aad633da"
  },
  {
    "id": "controller_factory_integration_21_652e907b",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 21,
    "code": "def validate_memory_usage():\n    \"\"\"Validate factory memory usage patterns.\"\"\"\n\n    import psutil\n    import gc\n\n    # Baseline memory\n    gc.collect()\n    baseline = psutil.Process().memory_info().rss\n\n    # Create multiple controllers\n    controllers = []\n    for i in range(100):\n        controller = create_controller('classical_smc')\n        controllers.append(controller)\n\n        if i % 10 == 0:\n            current = psutil.Process().memory_info().rss\n            memory_per_controller = (current - baseline) / (i + 1)\n            assert memory_per_controller < 1_000_000  # < 1MB per controller",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "652e907b"
  },
  {
    "id": "controller_factory_integration_22_b518a3cd",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_lyapunov_stability(controller, test_states):\n    \"\"\"Validate Lyapunov stability for controller.\"\"\"\n\n    for state in test_states:\n        # Compute Lyapunov function\n        V = compute_lyapunov_function(state, controller.config)\n\n        # Compute time derivative\n        dV_dt = compute_lyapunov_derivative(state, controller)\n\n        # Verify stability condition\n        if dV_dt > 0:\n            logger.warning(f\"Lyapunov condition violated at state {state}\")\n            return False\n\n    return True",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b518a3cd"
  },
  {
    "id": "controller_factory_integration_23_61ac9c92",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_gain_sensitivity_matrix(controller_type, nominal_gains, test_states):\n    \"\"\"Compute sensitivity of control performance to gain variations.\"\"\"\n\n    n_gains = len(nominal_gains)\n    n_states = len(test_states)\n    sensitivity_matrix = np.zeros((n_states, n_gains))\n\n    delta = 0.01  # 1% perturbation\n\n    for i, state in enumerate(test_states):\n        for j, gain in enumerate(nominal_gains):\n            # Perturb gain\n            perturbed_gains = nominal_gains.copy()\n            perturbed_gains[j] *= (1 + delta)\n\n            # Create controllers\n            nominal_controller = create_controller(controller_type, gains=nominal_gains)\n            perturbed_controller = create_controller(controller_type, gains=perturbed_gains)\n\n            # Compute control actions\n            u_nominal = nominal_controller.compute_control(state, (), {}).u\n            u_perturbed = perturbed_controller.compute_control(state, (), {}).u\n\n            # Compute sensitivity\n            sensitivity_matrix[i, j] = (u_perturbed - u_nominal) / (delta * gain)\n\n    return sensitivity_matrix",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61ac9c92"
  },
  {
    "id": "controller_factory_integration_24_61d6720f",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_controller_robustness(controller_type, gains, uncertainty_bounds):\n    \"\"\"Analyze controller robustness to parameter uncertainties.\"\"\"\n\n    # Create nominal controller\n    controller = create_controller(controller_type, gains=gains)\n\n    # Monte Carlo robustness analysis\n    n_samples = 1000\n    stability_count = 0\n\n    for _ in range(n_samples):\n        # Generate random uncertainties\n        uncertainties = generate_random_uncertainties(uncertainty_bounds)\n\n        # Test stability with uncertainties\n        if test_stability_with_uncertainties(controller, uncertainties):\n            stability_count += 1\n\n    robustness_probability = stability_count / n_samples\n    return robustness_probability",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61d6720f"
  },
  {
    "id": "controller_factory_integration_25_1cb45380",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\ndef compare_controller_performance(controller_types, test_scenarios):\n    \"\"\"Statistically compare performance of different controller types.\"\"\"\n\n    results = {}\n\n    for controller_type in controller_types:\n        controller = create_controller(controller_type)\n\n        # Collect performance metrics\n        settling_times = []\n        overshoots = []\n        steady_state_errors = []\n\n        for scenario in test_scenarios:\n            metrics = simulate_control_scenario(controller, scenario)\n            settling_times.append(metrics['settling_time'])\n            overshoots.append(metrics['overshoot'])\n            steady_state_errors.append(metrics['steady_state_error'])\n\n        results[controller_type] = {\n            'settling_time': {\n                'mean': np.mean(settling_times),\n                'std': np.std(settling_times),\n                'confidence_interval': compute_confidence_interval(settling_times)\n            },\n            'overshoot': {\n                'mean': np.mean(overshoots),\n                'std': np.std(overshoots),\n                'confidence_interval': compute_confidence_interval(overshoots)\n            },\n            'steady_state_error': {\n                'mean': np.mean(steady_state_errors),\n                'std': np.std(steady_state_errors),\n                'confidence_interval': compute_confidence_interval(steady_state_errors)\n            }\n        }\n\n    return results",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1cb45380"
  },
  {
    "id": "controller_factory_integration_26_415f1df2",
    "file": "docs\\technical\\controller_factory_integration.md",
    "index": 26,
    "code": "def test_performance_significance(results_A, results_B, metric='settling_time'):\n    \"\"\"Test statistical significance of performance differences.\"\"\"\n\n    from scipy import stats\n\n    data_A = results_A[metric]['samples']\n    data_B = results_B[metric]['samples']\n\n    # Perform Welch's t-test (unequal variances)\n    t_stat, p_value = stats.ttest_ind(data_A, data_B, equal_var=False)\n\n    # Compute effect size (Cohen's d)\n    pooled_std = np.sqrt((np.var(data_A) + np.var(data_B)) / 2)\n    cohens_d = (np.mean(data_A) - np.mean(data_B)) / pooled_std\n\n    return {\n        't_statistic': t_stat,\n        'p_value': p_value,\n        'effect_size': cohens_d,\n        'significant': p_value < 0.05\n    }",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "415f1df2"
  },
  {
    "id": "factory_integration_fixes_issue6_1_7cba959f",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\n# Simple creation with default configuration\ncontroller = create_controller(\n    controller_type='classical_smc',\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n)\n\n# Advanced creation with custom configuration\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n\nconfig = ClassicalSMCConfig(\n    gains=[10.0, 8.0, 6.0, 4.0, 20.0, 3.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001,\n    switch_method=\"tanh\"\n)\n\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config\n)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7cba959f"
  },
  {
    "id": "factory_integration_fixes_issue6_2_34adf0ee",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 2,
    "code": "# Optimized configuration for reduced overshoot (Issue #2 resolution)\ncontroller = create_controller(\n    controller_type='sta_smc',\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43]  # Tuned surface coefficients\n)\n\n# Custom STA configuration\nfrom src.controllers.smc.algorithms.super_twisting.config import SuperTwistingSMCConfig\n\nsta_config = SuperTwistingSMCConfig(\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],\n    max_force=150.0,\n    K1=4.0,\n    K2=0.4,\n    power_exponent=0.5,\n    dt=0.001\n)\n\ncontroller = create_controller('sta_smc', config=sta_config)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "34adf0ee"
  },
  {
    "id": "factory_integration_fixes_issue6_3_467accf3",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 3,
    "code": "controller = create_controller(\n    controller_type='adaptive_smc',\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5]\n)\n\n# With adaptation parameters\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\nadaptive_config = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0,\n    leak_rate=0.01,\n    dead_zone=0.05,\n    adapt_rate_limit=10.0,\n    K_min=0.1,\n    K_max=100.0,\n    gamma=2.0\n)\n\ncontroller = create_controller('adaptive_smc', config=adaptive_config)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "467accf3"
  },
  {
    "id": "factory_integration_fixes_issue6_4_1c427829",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 4,
    "code": "# Complex hybrid controller with sub-configurations\ncontroller = create_controller(\n    controller_type='hybrid_adaptive_sta_smc',\n    gains=[8.0, 6.0, 4.0, 3.0]  # Surface gains only\n)\n\n# Advanced hybrid configuration with mode specification\nfrom src.controllers.smc.algorithms.hybrid.config import HybridSMCConfig, HybridMode\n\nhybrid_config = HybridSMCConfig(\n    hybrid_mode=HybridMode.CLASSICAL_ADAPTIVE,\n    dt=0.001,\n    max_force=150.0,\n    k1_init=4.0,\n    k2_init=0.4,\n    gamma1=2.0,\n    gamma2=0.5,\n    dead_zone=0.05\n)\n\ncontroller = create_controller('hybrid_adaptive_sta_smc', config=hybrid_config)",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c427829"
  },
  {
    "id": "factory_integration_fixes_issue6_5_250abb84",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 5,
    "code": "# All these create the same classical SMC controller\ncontroller1 = create_controller('classical_smc', gains)\ncontroller2 = create_controller('classic_smc', gains)       # Alias\ncontroller3 = create_controller('smc_classical', gains)     # Alias\ncontroller4 = create_controller('smc_v1', gains)           # Alias\n\n# STA-SMC aliases\ncontroller5 = create_controller('sta_smc', gains)\ncontroller6 = create_controller('super_twisting', gains)    # Alias\ncontroller7 = create_controller('sta', gains)              # Alias",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "250abb84"
  },
  {
    "id": "factory_integration_fixes_issue6_6_d365faf5",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 6,
    "code": "from src.controllers.factory import list_available_controllers, get_default_gains\n\n# Get all available controller types\navailable_types = list_available_controllers()\nprint(available_types)\n# Output: ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\n\n# Get default gains for any controller type\ndefault_gains = get_default_gains('classical_smc')\nprint(default_gains)\n# Output: [8.0, 6.0, 4.0, 3.0, 15.0, 2.0]",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d365faf5"
  },
  {
    "id": "factory_integration_fixes_issue6_7_42bcb4df",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 7,
    "code": "from src.config import load_config\nfrom src.controllers.factory import create_controller\n\n# Load global configuration\nconfig = load_config(\"config.yaml\")\n\n# Create controller using configuration defaults\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config\n)\n\n# Gains will be automatically extracted from:\n# config.controller_defaults.classical_smc.gains or\n# config.controllers.classical_smc.gains",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "42bcb4df"
  },
  {
    "id": "factory_integration_fixes_issue6_8_4985d41d",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 8,
    "code": "# Create controller with dynamic configuration override\ncontroller = create_controller(\n    controller_type='sta_smc',\n    config=config,\n    gains=[10.0, 5.0, 8.0, 6.0, 2.0, 1.5]  # Override config gains\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4985d41d"
  },
  {
    "id": "factory_integration_fixes_issue6_9_f58ea931",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass ClassicalSMCConfig:\n    \"\"\"Type-safe configuration for Classical SMC controller.\"\"\"\n\n    # Required Parameters\n    gains: List[float]              # [k1, k2, \u03bb1, \u03bb2, K, kd] - Must be 6 elements\n    max_force: float               # Control saturation limit (Newtons)\n    boundary_layer: float          # Chattering reduction thickness\n\n    # Optional Parameters with Defaults\n    dt: float = 0.01              # Control timestep (seconds)\n    boundary_layer_slope: float = 0.0    # Adaptive boundary layer slope\n    switch_method: Literal[\"tanh\", \"linear\", \"sign\"] = \"tanh\"\n    regularization: float = 1e-10          # Matrix regularization\n    controllability_threshold: Optional[float] = None\n    dynamics_model: Optional[object] = None",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f58ea931"
  },
  {
    "id": "factory_integration_fixes_issue6_10_0ee1c592",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Stability-focused configuration\nstability_config = ClassicalSMCConfig(\n    gains=[5.0, 5.0, 3.0, 3.0, 10.0, 1.0],  # Conservative gains\n    max_force=100.0,\n    boundary_layer=0.05,  # Wider boundary layer\n    switch_method=\"tanh\"\n)\n\n# Performance-focused configuration\nperformance_config = ClassicalSMCConfig(\n    gains=[15.0, 12.0, 8.0, 6.0, 25.0, 4.0],  # Aggressive gains\n    max_force=150.0,\n    boundary_layer=0.01,  # Narrow boundary layer\n    switch_method=\"linear\"\n)\n\n# Research configuration with custom parameters\nresearch_config = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001,  # High-frequency control\n    boundary_layer_slope=1.0,  # Adaptive boundary\n    regularization=1e-8,\n    controllability_threshold=0.1\n)",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ee1c592"
  },
  {
    "id": "factory_integration_fixes_issue6_11_02d54f2b",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SuperTwistingSMCConfig:\n    \"\"\"Configuration for Super-Twisting (STA) SMC controller.\"\"\"\n\n    # Required Parameters\n    gains: List[float]              # [K1, K2, k1, k2, \u03bb1, \u03bb2] - 6 elements\n    max_force: float               # Control saturation limit\n\n    # STA Algorithm Parameters\n    K1: float = 4.0               # Proportional-like STA gain\n    K2: float = 0.4               # Integral-like STA gain\n    power_exponent: float = 0.5    # STA convergence exponent (0 < \u03b1 < 1)\n\n    # Optional Parameters\n    dt: float = 0.001             # Integration timestep\n    damping_gain: float = 0.0     # Additional damping\n    regularization: float = 1e-6   # Numerical stability\n    dynamics_model: Optional[object] = None",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02d54f2b"
  },
  {
    "id": "factory_integration_fixes_issue6_12_7c6d31a0",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 12,
    "code": "# Reduced overshoot configuration (verified solution)\nreduced_overshoot_config = SuperTwistingSMCConfig(\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],  # Optimized \u03bb\u2081, \u03bb\u2082\n    max_force=150.0,\n    K1=8.0,    # Algorithmic gain (maintained)\n    K2=4.0,    # Reduced from 8.0 for damping\n    power_exponent=0.5,\n    dt=0.001\n)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c6d31a0"
  },
  {
    "id": "factory_integration_fixes_issue6_13_e1a39b63",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass AdaptiveSMCConfig:\n    \"\"\"Configuration for Adaptive SMC with parameter estimation.\"\"\"\n\n    # Required Parameters\n    gains: List[float]              # [k1, k2, \u03bb1, \u03bb2, \u03b3] - 5 elements\n    max_force: float               # Control saturation\n\n    # Adaptation Parameters\n    leak_rate: float = 0.01        # Parameter drift prevention (\u03c3)\n    dead_zone: float = 0.05        # Adaptation dead zone width\n    adapt_rate_limit: float = 10.0  # Maximum adaptation rate\n    K_min: float = 0.1             # Minimum adaptive gain\n    K_max: float = 100.0           # Maximum adaptive gain\n    gamma: float = 2.0             # Adaptation rate (\u03b3)\n\n    # Control Parameters\n    boundary_layer: float = 0.1     # Smooth switching layer\n    smooth_switch: bool = True      # Enable smooth switching\n    dt: float = 0.001              # Integration timestep\n    dynamics_model: Optional[object] = None",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e1a39b63"
  },
  {
    "id": "factory_integration_fixes_issue6_14_06441c17",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass HybridSMCConfig:\n    \"\"\"Configuration for Hybrid Adaptive STA-SMC controller.\"\"\"\n\n    # Required Parameters\n    hybrid_mode: HybridMode         # Control mode selection\n    dt: float                      # Integration timestep\n    max_force: float               # Control saturation\n\n    # Sub-Controller Configurations\n    classical_config: ClassicalSMCConfig    # Classical SMC settings\n    adaptive_config: AdaptiveSMCConfig      # Adaptive SMC settings\n\n    # Hybrid-Specific Parameters\n    k1_init: float = 4.0           # Initial proportional gain\n    k2_init: float = 0.4           # Initial integral gain\n    gamma1: float = 2.0            # k1 adaptation rate\n    gamma2: float = 0.5            # k2 adaptation rate\n    dead_zone: float = 0.05        # Adaptation dead zone\n\n    # Advanced Options\n    enable_equivalent: bool = False  # Model-based equivalent control\n    damping_gain: float = 3.0       # Additional damping\n    adapt_rate_limit: float = 5.0   # Rate limiting\n    sat_soft_width: float = 0.05    # Soft saturation width",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06441c17"
  },
  {
    "id": "factory_integration_fixes_issue6_15_e2586e1d",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 15,
    "code": "class HybridMode(Enum):\n    \"\"\"Hybrid controller operational modes.\"\"\"\n    CLASSICAL_ADAPTIVE = \"classical_adaptive\"\n    STA_ADAPTIVE = \"sta_adaptive\"\n    FULL_HYBRID = \"full_hybrid\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e2586e1d"
  },
  {
    "id": "factory_integration_fixes_issue6_16_b491e7ba",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 16,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n)\n\n# Configure PSO optimization\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=20,\n    max_iterations=50,\n    convergence_threshold=1e-6,\n    enable_adaptive_bounds=True,\n    use_robust_evaluation=True\n)\n\n# Create enhanced PSO factory\npso_factory = EnhancedPSOFactory(pso_config, \"config.yaml\")\n\n# Run optimization with comprehensive monitoring\nresult = pso_factory.optimize_controller()",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b491e7ba"
  },
  {
    "id": "factory_integration_fixes_issue6_17_6d307c51",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef optimize_controller_comprehensive():\n    \"\"\"Complete PSO optimization workflow example.\"\"\"\n\n    # Step 1: Configuration\n    pso_config = PSOFactoryConfig(\n        controller_type=ControllerType.STA_SMC,\n        population_size=25,\n        max_iterations=100,\n        convergence_threshold=1e-5,\n        fitness_timeout=15.0\n    )\n\n    # Step 2: Create PSO factory\n    pso_factory = EnhancedPSOFactory(pso_config)\n\n    # Step 3: Run optimization\n    optimization_result = pso_factory.optimize_controller()\n\n    if optimization_result['success']:\n        # Step 4: Extract results\n        best_gains = optimization_result['best_gains']\n        best_cost = optimization_result['best_cost']\n        optimized_controller = optimization_result['controller']\n\n        # Step 5: Performance analysis\n        perf_analysis = optimization_result['performance_analysis']\n        validation_results = optimization_result['validation_results']\n\n        print(f\"Optimization successful!\")\n        print(f\"Best gains: {best_gains}\")\n        print(f\"Best cost: {best_cost:.6f}\")\n        print(f\"Converged: {perf_analysis['converged']}\")\n\n        return optimized_controller, optimization_result\n    else:\n        print(f\"Optimization failed: {optimization_result['error']}\")\n        return None, optimization_result",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d307c51"
  },
  {
    "id": "factory_integration_fixes_issue6_18_69667a9c",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Automatic test scenarios in fitness evaluation:\ntest_scenarios = [\n    {\n        'initial_state': [0.0, 0.1, 0.05, 0.0, 0.0, 0.0],  # Small disturbance\n        'sim_time': 2.0,\n        'weight': 1.0,\n        'description': 'small_disturbance'\n    },\n    {\n        'initial_state': [0.0, 0.5, 0.3, 0.0, 0.0, 0.0],   # Large angles\n        'sim_time': 3.0,\n        'weight': 1.5,\n        'description': 'large_angles'\n    },\n    {\n        'initial_state': [0.0, 0.2, 0.1, 0.0, 1.0, 0.5],   # High velocity\n        'sim_time': 2.5,\n        'weight': 1.2,\n        'description': 'high_velocity'\n    }\n]",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69667a9c"
  },
  {
    "id": "factory_integration_fixes_issue6_19_92da7f27",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 19,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    optimize_classical_smc, optimize_adaptive_smc, optimize_sta_smc\n)\n\n# One-line optimization for each controller type\nclassical_factory, classical_result = optimize_classical_smc()\nadaptive_factory, adaptive_result = optimize_adaptive_smc()\nsta_factory, sta_result = optimize_sta_smc()\n\n# Use optimized controllers\nclassical_controller = classical_factory()  # Uses optimized gains\nadaptive_controller = adaptive_factory()\nsta_controller = sta_factory()",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92da7f27"
  },
  {
    "id": "factory_integration_fixes_issue6_20_7333cb47",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 20,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType\n\n# Get optimized bounds for each controller type\nclassical_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nadaptive_bounds = get_gain_bounds_for_pso(SMCType.ADAPTIVE)\nsta_bounds = get_gain_bounds_for_pso(SMCType.SUPER_TWISTING)\nhybrid_bounds = get_gain_bounds_for_pso(SMCType.HYBRID)\n\nprint(\"Classical SMC bounds:\")\nprint(f\"  Lower: {classical_bounds[0]}\")\nprint(f\"  Upper: {classical_bounds[1]}\")\n\n# Output:\n# Classical SMC bounds:\n#   Lower: [1.0, 1.0, 1.0, 1.0, 5.0, 0.1]\n#   Upper: [30.0, 30.0, 20.0, 20.0, 50.0, 10.0]",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7333cb47"
  },
  {
    "id": "factory_integration_fixes_issue6_21_e8723139",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 21,
    "code": "from src.controllers.factory import validate_smc_gains\n\n# Validate gains before creating controller\ngains = [15.0, 12.0, 8.0, 6.0, 25.0, 4.0]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, gains)\n\nif is_valid:\n    controller = create_controller('classical_smc', gains=gains)\nelse:\n    print(\"Invalid gains provided\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8723139"
  },
  {
    "id": "factory_integration_fixes_issue6_22_e96b05f0",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ncontroller = create_controller('classical', gains=[...])\n# ValueError: Unknown controller type 'classical'. Available: [...]",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e96b05f0"
  },
  {
    "id": "factory_integration_fixes_issue6_23_f0636bf0",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Use correct controller type names\ncontroller = create_controller('classical_smc', gains=[...])\n\n# Or use aliases\ncontroller = create_controller('classic_smc', gains=[...])\n\n# Check available types\nfrom src.controllers.factory import list_available_controllers\nprint(list_available_controllers())",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0636bf0"
  },
  {
    "id": "factory_integration_fixes_issue6_24_90adc0b7",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\n# ClassicalSMCConfig validation error: Surface gains must be positive\nconfig = ClassicalSMCConfig(gains=[0, 5, 3, 2, 10, 1], ...)",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "90adc0b7"
  },
  {
    "id": "factory_integration_fixes_issue6_25_0a5c1c01",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Ensure all surface gains are positive\nconfig = ClassicalSMCConfig(\n    gains=[1.0, 5.0, 3.0, 2.0, 10.0, 1.0],  # k1 > 0\n    max_force=150.0,\n    boundary_layer=0.02\n)\n\n# Check gain constraints:\n# - Position gains k1, k2 > 0\n# - Surface coefficients \u03bb1, \u03bb2 > 0\n# - Switching gain K > 0\n# - Derivative gain kd \u2265 0",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a5c1c01"
  },
  {
    "id": "factory_integration_fixes_issue6_26_797d0f2a",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# TypeError: HybridSMCConfig() missing required arguments\ncontroller = create_controller('hybrid_adaptive_sta_smc', gains=[...])",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "797d0f2a"
  },
  {
    "id": "factory_integration_fixes_issue6_27_dbd5c650",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 27,
    "code": "# Hybrid controllers require special handling - factory handles this automatically\ncontroller = create_controller(\n    controller_type='hybrid_adaptive_sta_smc',\n    gains=[8.0, 6.0, 4.0, 3.0]  # Surface gains only\n)\n\n# For advanced configuration:\nfrom src.controllers.smc.algorithms.hybrid.config import HybridSMCConfig, HybridMode\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\nclassical_sub = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.02\n)\n\nadaptive_sub = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0,\n    dt=0.001\n)\n\nhybrid_config = HybridSMCConfig(\n    hybrid_mode=HybridMode.CLASSICAL_ADAPTIVE,\n    dt=0.001,\n    max_force=150.0,\n    classical_config=classical_sub,\n    adaptive_config=adaptive_sub\n)\n\ncontroller = create_controller('hybrid_adaptive_sta_smc', config=hybrid_config)",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbd5c650"
  },
  {
    "id": "factory_integration_fixes_issue6_28_47f9e6cc",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 28,
    "code": "# PSO optimization results in poor fitness values\nresult = pso_factory.optimize_controller()\n# Best cost: 1000.0 (penalty value)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47f9e6cc"
  },
  {
    "id": "factory_integration_fixes_issue6_29_a554194c",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 29,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Check parameter bounds\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nprint(f\"Bounds: {bounds}\")\n\n# 2. Adjust PSO configuration\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=30,  # Increase population\n    max_iterations=100,  # More iterations\n    convergence_threshold=1e-5,  # Stricter convergence\n    fitness_timeout=20.0  # Longer evaluation time\n)\n\n# 3. Enable robust evaluation\npso_config.use_robust_evaluation = True\n\n# 4. Check diagnostics\ndiagnostics = pso_factory.get_optimization_diagnostics()\nprint(f\"Failed evaluations: {diagnostics['validation_statistics']['failed_evaluations']}\")\nprint(f\"Parameter violations: {diagnostics['validation_statistics']['parameter_violations']}\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a554194c"
  },
  {
    "id": "factory_integration_fixes_issue6_30_fc6cf4b8",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\n# Fitness evaluation fails with dynamics errors\n# RuntimeError: Matrix inversion failed during dynamics computation",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc6cf4b8"
  },
  {
    "id": "factory_integration_fixes_issue6_31_1fa7393f",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 31,
    "code": "# example-metadata:\n# runnable: false\n\n# Use enhanced PSO factory with robust evaluation\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    use_robust_evaluation=True,  # Enables error recovery\n    fitness_timeout=15.0  # Timeout for stuck evaluations\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\n\n# The enhanced factory automatically handles:\n# - Matrix singularities in dynamics\n# - Controller computation failures\n# - Unstable simulation trajectories\n# - Timeout protection",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1fa7393f"
  },
  {
    "id": "factory_integration_fixes_issue6_32_b443031e",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 32,
    "code": "# Controller gains not found in config file\ncontroller = create_controller('classical_smc', config=global_config)\n# Warning: Could not extract controller parameters",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b443031e"
  },
  {
    "id": "factory_integration_fixes_issue6_33_4a29e7e0",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\n# Ensure config.yaml has proper structure:\n# controller_defaults:\n#   classical_smc:\n#     gains: [8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n#\n# controllers:\n#   classical_smc:\n#     max_force: 150.0\n#     boundary_layer: 0.02\n\n# Or provide gains explicitly:\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=global_config,\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]  # Override\n)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a29e7e0"
  },
  {
    "id": "factory_integration_fixes_issue6_34_1473b3bc",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 34,
    "code": "# example-metadata:\n# runnable: false\n\n# ImportError: Could not import DoubleInvertedPendulum from any expected location",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1473b3bc"
  },
  {
    "id": "factory_integration_fixes_issue6_35_b5f89340",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 35,
    "code": "# example-metadata:\n# runnable: false\n\n# The factory has robust import fallbacks:\n# 1. src.core.dynamics.DIPDynamics (preferred)\n# 2. src.core.dynamics.DIPDynamics (alternative)\n# 3. src.plant.models.simplified.dynamics.SimplifiedDIPDynamics (fallback)\n\n# Ensure at least one dynamics implementation is available\nfrom src.core.dynamics import DIPDynamics\nfrom src.config import load_config\n\nconfig = load_config(\"config.yaml\")\ndynamics = DIPDynamics(config.physics)\n\n# Pass dynamics explicitly if needed\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config,\n    gains=[...],\n)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5f89340"
  },
  {
    "id": "factory_integration_fixes_issue6_36_627e8b59",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 36,
    "code": "# Old way - still works\nfrom src.controllers.factory import create_classical_smc_controller\n\ncontroller = create_classical_smc_controller(\n    config=config,\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "627e8b59"
  },
  {
    "id": "factory_integration_fixes_issue6_37_c3f99df9",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 37,
    "code": "# New way - enhanced capabilities\nfrom src.controllers.factory import create_controller\n\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config,\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3f99df9"
  },
  {
    "id": "factory_integration_fixes_issue6_38_33bdb6ce",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 38,
    "code": "# Simple dict-based configuration - still works\nconfig = {\n    'gains': [8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    'max_force': 150.0,\n    'boundary_layer': 0.02\n}\n\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33bdb6ce"
  },
  {
    "id": "factory_integration_fixes_issue6_39_20340277",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 39,
    "code": "# Type-safe configuration with validation\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n\nconfig = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001,\n    switch_method=\"tanh\"\n)\n\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "20340277"
  },
  {
    "id": "factory_integration_fixes_issue6_40_ee6792e8",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 40,
    "code": "# Old way - basic PSO without factory integration\nfrom src.optimizer.pso_optimizer import PSOTuner\n\ntuner = PSOTuner(controller_factory, config)\nresult = tuner.optimise()",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee6792e8"
  },
  {
    "id": "factory_integration_fixes_issue6_41_0fe11112",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 41,
    "code": "# New way - comprehensive PSO-factory integration\nfrom src.optimization.integration.pso_factory_bridge import (\n    EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n)\n\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=20,\n    max_iterations=50,\n    use_robust_evaluation=True\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\nresult = pso_factory.optimize_controller()\n\n# Result includes:\n# - Optimized controller instance\n# - Convergence analysis\n# - Performance validation\n# - Comprehensive diagnostics",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fe11112"
  },
  {
    "id": "factory_integration_fixes_issue6_42_7fd2670d",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 42,
    "code": "# Old way - manual error handling required\ntry:\n    controller = create_controller('classical_smc', gains=invalid_gains)\nexcept Exception as e:\n    # Handle error manually\n    print(f\"Controller creation failed: {e}\")\n    # Create fallback controller manually",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7fd2670d"
  },
  {
    "id": "factory_integration_fixes_issue6_43_57421805",
    "file": "docs\\technical\\factory_integration_fixes_issue6.md",
    "index": 43,
    "code": "# New way - automatic error recovery\ncontroller = create_controller('classical_smc', gains=invalid_gains)\n# Factory automatically:\n# - Validates gains according to SMC theory\n# - Provides detailed error messages\n# - Falls back to safe default gains if needed\n# - Logs warnings for debugging",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57421805"
  },
  {
    "id": "factory_usage_examples_1_b3983f1e",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\n# Classical SMC with minimal configuration\nclassical_controller = create_controller(\n    controller_type='classical_smc',\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]\n)\n\n# Super-Twisting SMC with optimized gains (Issue #2 resolution)\nsta_controller = create_controller(\n    controller_type='sta_smc',\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43]  # Reduced overshoot configuration\n)\n\n# Adaptive SMC with standard gains\nadaptive_controller = create_controller(\n    controller_type='adaptive_smc',\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5]\n)\n\n# Hybrid controller with surface gains only\nhybrid_controller = create_controller(\n    controller_type='hybrid_adaptive_sta_smc',\n    gains=[8.0, 6.0, 4.0, 3.0]\n)",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3983f1e"
  },
  {
    "id": "factory_usage_examples_2_78381ca4",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 2,
    "code": "# Multiple ways to create the same controller\ncontrollers = [\n    create_controller('classical_smc', gains),\n    create_controller('classic_smc', gains),       # Alias\n    create_controller('smc_classical', gains),     # Alias\n    create_controller('smc_v1', gains),           # Alias\n]\n\n# All create identical Classical SMC controllers\nassert all(type(c) == type(controllers[0]) for c in controllers)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "78381ca4"
  },
  {
    "id": "factory_usage_examples_3_2b04d119",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 3,
    "code": "from src.config import load_config\nfrom src.controllers.factory import create_controller\n\n# Load global configuration\nconfig = load_config(\"config.yaml\")\n\n# Create controller using configuration defaults\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config  # Gains automatically extracted from config\n)\n\n# Override specific parameters while using config\ncontroller_custom = create_controller(\n    controller_type='classical_smc',\n    config=config,\n    gains=[10.0, 8.0, 6.0, 4.0, 20.0, 3.0]  # Override config gains\n)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b04d119"
  },
  {
    "id": "factory_usage_examples_4_1c888203",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 4,
    "code": "from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.factory import create_controller\n\n# Create validated configuration\nconfig = ClassicalSMCConfig(\n    gains=[15.0, 12.0, 8.0, 6.0, 25.0, 4.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001,\n    switch_method=\"tanh\",\n    boundary_layer_slope=1.0,\n    regularization=1e-8\n)\n\n# Create controller with validated configuration\ncontroller = create_controller('classical_smc', config=config)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c888203"
  },
  {
    "id": "factory_usage_examples_5_62e7c586",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 5,
    "code": "from src.controllers.smc.algorithms.super_twisting.config import SuperTwistingSMCConfig\n\n# Configuration for reduced overshoot (Issue #2 resolution)\nsta_config = SuperTwistingSMCConfig(\n    gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43],  # Optimized surface coefficients\n    max_force=150.0,\n    K1=8.0,              # Proportional-like STA gain\n    K2=4.0,              # Integral-like STA gain (reduced for damping)\n    power_exponent=0.5,   # Standard STA exponent\n    dt=0.001,\n    damping_gain=0.0,\n    regularization=1e-6\n)\n\ncontroller = create_controller('sta_smc', config=sta_config)\n\n# Verify configuration properties\nprint(f\"K1 gain: {sta_config.K1}\")\nprint(f\"Surface gains: {sta_config.get_surface_gains()}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62e7c586"
  },
  {
    "id": "factory_usage_examples_6_a905480f",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 6,
    "code": "from src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\n# Configuration for robust adaptation\nadaptive_config = AdaptiveSMCConfig(\n    gains=[15.0, 12.0, 8.0, 6.0, 3.0],  # [k1, k2, \u03bb1, \u03bb2, \u03b3]\n    max_force=150.0,\n    leak_rate=0.01,         # Parameter drift prevention\n    dead_zone=0.05,         # Adaptation dead zone\n    adapt_rate_limit=10.0,  # Maximum adaptation rate\n    K_min=0.1,              # Minimum adaptive gain\n    K_max=100.0,            # Maximum adaptive gain\n    gamma=2.0,              # Adaptation rate\n    boundary_layer=0.1,     # Smooth switching layer\n    smooth_switch=True,     # Enable smooth switching\n    dt=0.001\n)\n\ncontroller = create_controller('adaptive_smc', config=adaptive_config)\n\n# Access adaptation bounds\nbounds = adaptive_config.get_adaptation_bounds()\nprint(f\"Adaptation bounds: {bounds}\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a905480f"
  },
  {
    "id": "factory_usage_examples_7_58fe0eb3",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 7,
    "code": "from src.controllers.smc.algorithms.hybrid.config import HybridSMCConfig, HybridMode\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\n# Create sub-configurations\nclassical_sub = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    dt=0.001,\n    boundary_layer=0.02\n)\n\nadaptive_sub = AdaptiveSMCConfig(\n    gains=[12.0, 10.0, 6.0, 5.0, 2.5],\n    max_force=150.0,\n    dt=0.001,\n    leak_rate=0.01,\n    dead_zone=0.05\n)\n\n# Create hybrid configuration\nhybrid_config = HybridSMCConfig(\n    hybrid_mode=HybridMode.CLASSICAL_ADAPTIVE,\n    dt=0.001,\n    max_force=150.0,\n    classical_config=classical_sub,\n    adaptive_config=adaptive_sub,\n    k1_init=4.0,\n    k2_init=0.4,\n    gamma1=2.0,\n    gamma2=0.5,\n    dead_zone=0.05\n)\n\ncontroller = create_controller('hybrid_adaptive_sta_smc', config=hybrid_config)",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "58fe0eb3"
  },
  {
    "id": "factory_usage_examples_8_059bdefe",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 8,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n)\n\n# Configure PSO optimization\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=20,\n    max_iterations=50,\n    convergence_threshold=1e-6\n)\n\n# Create and run PSO optimization\npso_factory = EnhancedPSOFactory(pso_config, \"config.yaml\")\noptimization_result = pso_factory.optimize_controller()\n\nif optimization_result['success']:\n    optimized_controller = optimization_result['controller']\n    best_gains = optimization_result['best_gains']\n    best_cost = optimization_result['best_cost']\n\n    print(f\"Optimization successful!\")\n    print(f\"Best gains: {best_gains}\")\n    print(f\"Best cost: {best_cost:.6f}\")\nelse:\n    print(f\"Optimization failed: {optimization_result['error']}\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "059bdefe"
  },
  {
    "id": "factory_usage_examples_9_6c645912",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced PSO configuration with robust evaluation\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.STA_SMC,\n    population_size=30,              # Larger population for better exploration\n    max_iterations=100,              # More iterations for convergence\n    convergence_threshold=1e-5,      # Stricter convergence criteria\n    max_stagnation_iterations=15,    # Early stopping for stagnation\n    enable_adaptive_bounds=True,     # Dynamic bound adjustment\n    enable_gradient_guidance=False,  # Pure PSO without gradient hints\n    fitness_timeout=15.0,           # 15-second timeout per evaluation\n    use_robust_evaluation=True      # Enable error recovery\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\nresult = pso_factory.optimize_controller()\n\n# Analyze optimization performance\nif result['success']:\n    performance = result['performance_analysis']\n    validation = result['validation_results']\n\n    print(f\"Converged: {performance['converged']}\")\n    print(f\"Improvement ratio: {performance['improvement_ratio']:.3f}\")\n    print(f\"Gains valid: {validation['gains_valid']}\")\n    print(f\"Controller stable: {validation['controller_stable']}\")",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c645912"
  },
  {
    "id": "factory_usage_examples_10_eeb59b14",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 10,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    optimize_classical_smc, optimize_adaptive_smc, optimize_sta_smc\n)\n\n# Quick optimization for each controller type\nclassical_factory, classical_result = optimize_classical_smc()\nadaptive_factory, adaptive_result = optimize_adaptive_smc()\nsta_factory, sta_result = optimize_sta_smc()\n\n# Use optimized controllers immediately\nclassical_controller = classical_factory()  # Uses optimized gains\nadaptive_controller = adaptive_factory()\nsta_controller = sta_factory()\n\n# Access optimization results\nprint(f\"Classical optimization cost: {classical_result['best_cost']:.6f}\")\nprint(f\"Adaptive optimization cost: {adaptive_result['best_cost']:.6f}\")\nprint(f\"STA optimization cost: {sta_result['best_cost']:.6f}\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eeb59b14"
  },
  {
    "id": "factory_usage_examples_11_24c04d5c",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 11,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType, validate_smc_gains\n\n# Get controller-specific bounds\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\nlower_bounds, upper_bounds = bounds\n\nprint(f\"Classical SMC bounds:\")\nprint(f\"  Lower: {lower_bounds}\")\nprint(f\"  Upper: {upper_bounds}\")\n\n# Validate gains before optimization\ntest_gains = [15.0, 12.0, 8.0, 6.0, 25.0, 4.0]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, test_gains)\n\nif is_valid:\n    print(\"Gains are valid for Classical SMC\")\n    # Use gains in optimization or controller creation\nelse:\n    print(\"Invalid gains - adjustment needed\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "24c04d5c"
  },
  {
    "id": "factory_usage_examples_12_16bac5b6",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 12,
    "code": "from src.controllers.factory import create_controller\nimport logging\n\n# Configure logging to see factory warnings\nlogging.basicConfig(level=logging.INFO)\n\n# Factory automatically handles invalid gains\ntry:\n    # These gains violate SMC stability requirements (negative gains)\n    invalid_gains = [-1.0, 5.0, 3.0, 2.0, 10.0, 1.0]\n\n    controller = create_controller(\n        controller_type='classical_smc',\n        gains=invalid_gains\n    )\n\n    # Factory will:\n    # 1. Detect invalid gains\n    # 2. Log warning message\n    # 3. Fall back to safe default gains\n    # 4. Return working controller\n\n    print(\"Controller created successfully with fallback gains\")\n\nexcept Exception as e:\n    print(f\"Controller creation failed: {e}\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "16bac5b6"
  },
  {
    "id": "factory_usage_examples_13_d9cfad54",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 13,
    "code": "from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n\n# Example 1: Invalid surface gains (negative values)\ntry:\n    config = ClassicalSMCConfig(\n        gains=[0.0, 5.0, 3.0, 2.0, 10.0, 1.0],  # k1 = 0 violates stability\n        max_force=150.0,\n        boundary_layer=0.02\n    )\nexcept ValueError as e:\n    print(f\"Configuration validation failed: {e}\")\n    # Output: \"Surface gains [k1, k2, \u03bb1, \u03bb2] must be positive for stability\"\n\n# Example 2: Invalid boundary layer (too small)\ntry:\n    config = ClassicalSMCConfig(\n        gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n        max_force=150.0,\n        boundary_layer=1e-15  # Too small, causes division by zero\n    )\nexcept ValueError as e:\n    print(f\"Configuration validation failed: {e}\")\n    # Output: \"boundary_layer is too small (minimum: 1e-12) which may cause division by zero\"\n\n# Example 3: Valid configuration\nconfig = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02\n)\nprint(\"Configuration is valid\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9cfad54"
  },
  {
    "id": "factory_usage_examples_14_ac771975",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 14,
    "code": "from src.optimization.integration.pso_factory_bridge import EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n\n# Configure PSO with robust evaluation\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    use_robust_evaluation=True,  # Enable automatic error recovery\n    fitness_timeout=10.0         # Timeout protection\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\n\n# The enhanced factory automatically handles:\n# - Controller creation failures\n# - Simulation instabilities\n# - Matrix singularities\n# - Timeout conditions\n# - Invalid parameter combinations\n\nresult = pso_factory.optimize_controller()\n\n# Check optimization statistics\nstats = pso_factory.validation_stats\nprint(f\"Total fitness evaluations: {stats['fitness_evaluations']}\")\nprint(f\"Failed evaluations: {stats['failed_evaluations']}\")\nprint(f\"Parameter violations: {stats['parameter_violations']}\")\n\n# Calculate success rate\nsuccess_rate = 1.0 - (stats['failed_evaluations'] / max(stats['fitness_evaluations'], 1))\nprint(f\"Evaluation success rate: {success_rate:.1%}\")",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac771975"
  },
  {
    "id": "factory_usage_examples_15_a5629467",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 15,
    "code": "# The factory has robust import fallbacks for dynamics models\nfrom src.controllers.factory import create_controller\n\ntry:\n    # Factory tries multiple import paths:\n    # 1. src.core.dynamics.DIPDynamics (preferred)\n    # 2. src.core.dynamics.DIPDynamics (alternative)\n    # 3. src.plant.models.simplified.dynamics.SimplifiedDIPDynamics (fallback)\n\n    controller = create_controller('classical_smc', gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0])\n    print(\"Controller created successfully\")\n\nexcept ImportError as e:\n    print(f\"Import error: {e}\")\n    # This only happens if NO dynamics implementation is available",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5629467"
  },
  {
    "id": "factory_usage_examples_16_d3c64aa3",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 16,
    "code": "from src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.controllers.factory import create_controller\n\n# Create configuration once\nbase_config = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],\n    max_force=150.0,\n    boundary_layer=0.02,\n    dt=0.001\n)\n\n# Reuse configuration for multiple controllers\ncontrollers = []\nfor i in range(10):\n    controller = create_controller('classical_smc', config=base_config)\n    controllers.append(controller)\n\nprint(f\"Created {len(controllers)} controllers efficiently\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3c64aa3"
  },
  {
    "id": "factory_usage_examples_17_a24bfd89",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 17,
    "code": "from src.controllers.factory import create_controller, get_default_gains\n\n# Efficient batch creation with different gain sets\ncontroller_specs = [\n    ('classical_smc', [8.0, 6.0, 4.0, 3.0, 15.0, 2.0]),\n    ('sta_smc', [8.0, 4.0, 12.0, 6.0, 4.85, 3.43]),\n    ('adaptive_smc', [12.0, 10.0, 6.0, 5.0, 2.5]),\n    ('hybrid_adaptive_sta_smc', [8.0, 6.0, 4.0, 3.0])\n]\n\ncontrollers = {}\nfor controller_type, gains in controller_specs:\n    controllers[controller_type] = create_controller(controller_type, gains=gains)\n\nprint(f\"Created {len(controllers)} different controller types\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a24bfd89"
  },
  {
    "id": "factory_usage_examples_18_1b9bddf0",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 18,
    "code": "from src.controllers.factory import create_controller\n\n# Controllers with dynamics models are created only when needed\ndef create_controller_lazily(controller_type, gains):\n    \"\"\"Create controller with lazy dynamics loading.\"\"\"\n\n    # Dynamics model is only created when the controller needs it\n    controller = create_controller(\n        controller_type=controller_type,\n        gains=gains\n        # No explicit dynamics model - created automatically when needed\n    )\n\n    return controller\n\n# Fast creation - dynamics loaded on first use\ncontroller = create_controller_lazily('classical_smc', [8.0, 6.0, 4.0, 3.0, 15.0, 2.0])",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1b9bddf0"
  },
  {
    "id": "factory_usage_examples_19_536fbfa3",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 19,
    "code": "from src.optimization.integration.pso_factory_bridge import EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n\n# Configure PSO for memory efficiency\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=15,        # Smaller population for memory efficiency\n    max_iterations=30,         # Fewer iterations for speed\n    convergence_threshold=1e-4, # Slightly relaxed convergence\n    enable_adaptive_bounds=False, # Disable adaptive bounds for simplicity\n    fitness_timeout=5.0        # Shorter timeout for speed\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\n\n# Run efficient optimization\nimport time\nstart_time = time.time()\nresult = pso_factory.optimize_controller()\noptimization_time = time.time() - start_time\n\nprint(f\"Optimization completed in {optimization_time:.2f} seconds\")\nprint(f\"Memory-efficient result: cost = {result['best_cost']:.6f}\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "536fbfa3"
  },
  {
    "id": "factory_usage_examples_20_fbf6e12b",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"Complete research workflow for controller comparison.\"\"\"\nfrom src.controllers.factory import create_controller\nfrom src.optimization.integration.pso_factory_bridge import optimize_classical_smc, optimize_sta_smc\n\n# Step 1: Create baseline controllers\nbaseline_controllers = {\n    'classical': create_controller('classical_smc', gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]),\n    'sta': create_controller('sta_smc', gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43])\n}\n\n# Step 2: Optimize controllers\nprint(\"Optimizing controllers...\")\nclassical_factory, classical_result = optimize_classical_smc()\nsta_factory, sta_result = optimize_sta_smc()\n\noptimized_controllers = {\n    'classical_opt': classical_factory(),\n    'sta_opt': sta_factory()\n}\n\n# Step 3: Compare performance\nprint(\"\\nPerformance Comparison:\")\nprint(f\"Classical baseline vs optimized:\")\nprint(f\"  Optimized cost: {classical_result['best_cost']:.6f}\")\nprint(f\"  Optimized gains: {classical_result['best_gains']}\")\n\nprint(f\"\\nSTA baseline vs optimized:\")\nprint(f\"  Optimized cost: {sta_result['best_cost']:.6f}\")\nprint(f\"  Optimized gains: {sta_result['best_gains']}\")",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbf6e12b"
  },
  {
    "id": "factory_usage_examples_21_031e2d50",
    "file": "docs\\technical\\factory_usage_examples.md",
    "index": 21,
    "code": "\"\"\"Production-ready controller deployment workflow.\"\"\"\nfrom src.controllers.factory import create_controller, list_available_controllers\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\nfrom src.config import load_config\nimport logging\n\n# Step 1: Setup production logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Step 2: Load and validate configuration\nconfig = load_config(\"config.yaml\")\n\n# Step 3: Create production controller with validated configuration\nproduction_config = ClassicalSMCConfig(\n    gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0],  # Validated stable gains\n    max_force=150.0,                         # Hardware limit\n    boundary_layer=0.02,                     # Tested boundary layer\n    dt=0.001,                               # Control loop frequency\n    switch_method=\"tanh\",                    # Smooth switching\n    regularization=1e-8                      # Numerical stability\n)\n\n# Step 4: Create controller with error handling\ntry:\n    production_controller = create_controller(\n        controller_type='classical_smc',\n        config=production_config\n    )\n\n    logging.info(\"Production controller created successfully\")\n\n    # Step 5: Validate controller operation\n    test_state = [0.0, 0.1, 0.05, 0.0, 0.0, 0.0]\n    control_output = production_controller.compute_control(test_state, (), {})\n\n    if hasattr(control_output, 'u'):\n        control_value = control_output.u\n    else:\n        control_value = control_output\n\n    logging.info(f\"Controller validation successful: u = {control_value}\")\n\nexcept Exception as e:\n    logging.error(f\"Production controller creation failed: {e}\")\n    raise\n\nprint(\"Production deployment successful\")",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "031e2d50"
  },
  {
    "id": "integration_protocols_1_c240e7bb",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 1,
    "code": "from abc import ABC, abstractmethod\nfrom typing import Tuple, Optional\nimport numpy as np\n\nclass PlantModelInterface(ABC):\n    \"\"\"Standard interface for plant models in the factory ecosystem.\"\"\"\n\n    @abstractmethod\n    def compute_dynamics(\n        self,\n        state: np.ndarray,\n        control: float,\n        disturbances: Optional[np.ndarray] = None\n    ) -> np.ndarray:\n        \"\"\"\n        Compute system dynamics: dx/dt = f(x, u, d)\n\n        Parameters\n        ----------\n        state : np.ndarray, shape (6,)\n            Current system state [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n        control : float\n            Control input (cart force)\n        disturbances : np.ndarray, optional\n            External disturbances\n\n        Returns\n        -------\n        np.ndarray, shape (6,)\n            State derivative vector\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_linearization(\n        self,\n        state: np.ndarray,\n        control: float\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get linearized dynamics around operating point.\n\n        Returns\n        -------\n        A : np.ndarray, shape (6, 6)\n            State matrix\n        B : np.ndarray, shape (6, 1)\n            Input matrix\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_state(self, state: np.ndarray) -> bool:\n        \"\"\"Validate if state is within acceptable bounds.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def state_dimension(self) -> int:\n        \"\"\"Return the state space dimension.\"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def control_dimension(self) -> int:\n        \"\"\"Return the control input dimension.\"\"\"\n        pass",
    "lines": 67,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c240e7bb"
  },
  {
    "id": "integration_protocols_2_918d6b97",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass PlantModelRegistry:\n    \"\"\"Registry for plant models with validation.\"\"\"\n\n    _models = {}\n\n    @classmethod\n    def register(cls, name: str, model_class: type):\n        \"\"\"Register a new plant model.\"\"\"\n        if not issubclass(model_class, PlantModelInterface):\n            raise TypeError(\"Model must implement PlantModelInterface\")\n\n        cls._models[name] = model_class\n\n    @classmethod\n    def create_model(cls, name: str, config: dict) -> PlantModelInterface:\n        \"\"\"Create plant model instance.\"\"\"\n        if name not in cls._models:\n            raise ValueError(f\"Unknown plant model: {name}\")\n\n        model_class = cls._models[name]\n        return model_class(config)\n\n    @classmethod\n    def list_models(cls) -> List[str]:\n        \"\"\"List available plant models.\"\"\"\n        return list(cls._models.keys())\n\n# Register built-in models\nPlantModelRegistry.register('simplified_dip', SimplifiedDIPDynamics)\nPlantModelRegistry.register('full_dip', FullDIPDynamics)\nPlantModelRegistry.register('low_rank_dip', LowRankDIPDynamics)",
    "lines": 34,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "918d6b97"
  },
  {
    "id": "integration_protocols_3_6f3dc4ba",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerPlantBridge:\n    \"\"\"Bridge for controller-plant communication.\"\"\"\n\n    def __init__(self, controller, plant_model):\n        self.controller = controller\n        self.plant_model = plant_model\n        self._validate_compatibility()\n\n    def _validate_compatibility(self):\n        \"\"\"Validate controller-plant compatibility.\"\"\"\n        # Check state dimensions\n        controller_states = getattr(self.controller, 'expected_states', 6)\n        plant_states = self.plant_model.state_dimension\n\n        if controller_states != plant_states:\n            raise ValueError(\n                f\"State dimension mismatch: controller expects {controller_states}, \"\n                f\"plant provides {plant_states}\"\n            )\n\n        # Check control dimensions\n        controller_controls = getattr(self.controller, 'control_dimension', 1)\n        plant_controls = self.plant_model.control_dimension\n\n        if controller_controls != plant_controls:\n            raise ValueError(\n                f\"Control dimension mismatch: controller outputs {controller_controls}, \"\n                f\"plant expects {plant_controls}\"\n            )\n\n    def step(self, state: np.ndarray, dt: float) -> Tuple[np.ndarray, dict]:\n        \"\"\"Execute one control-plant step.\"\"\"\n        # Validate state\n        if not self.plant_model.validate_state(state):\n            raise ValueError(\"Invalid state for plant model\")\n\n        # Compute control\n        control_result = self.controller.compute_control(state, (), {})\n        u = control_result.u if hasattr(control_result, 'u') else control_result\n\n        # Apply control to plant\n        state_derivative = self.plant_model.compute_dynamics(state, u)\n\n        # Integrate (simple Euler for demonstration)\n        next_state = state + dt * state_derivative\n\n        # Collect metadata\n        metadata = {\n            'control_value': u,\n            'sliding_surface': getattr(control_result, 'sliding_surface', None),\n            'plant_model': type(self.plant_model).__name__,\n            'controller_type': type(self.controller).__name__\n        }\n\n        return next_state, metadata",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6f3dc4ba"
  },
  {
    "id": "integration_protocols_4_adbfe20a",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOFactoryIntegration:\n    \"\"\"PSO-Factory integration layer.\"\"\"\n\n    def __init__(self, controller_type: str, plant_model_config: dict):\n        self.controller_type = controller_type\n        self.plant_config = plant_model_config\n        self.gain_bounds = self._get_theoretical_bounds()\n\n    def create_optimization_objective(\n        self,\n        performance_metrics: List[str],\n        weights: Optional[List[float]] = None\n    ) -> Callable:\n        \"\"\"Create PSO optimization objective function.\"\"\"\n\n        def objective_function(gains: np.ndarray) -> float:\n            try:\n                # Create controller with proposed gains\n                controller = create_controller(\n                    self.controller_type,\n                    gains=gains.tolist()\n                )\n\n                # Create plant model\n                plant_model = PlantModelRegistry.create_model(\n                    'simplified_dip',\n                    self.plant_config\n                )\n\n                # Create bridge\n                bridge = ControllerPlantBridge(controller, plant_model)\n\n                # Run simulation\n                performance = self._evaluate_performance(\n                    bridge,\n                    performance_metrics\n                )\n\n                # Compute weighted cost\n                if weights is None:\n                    weights = [1.0] * len(performance_metrics)\n\n                total_cost = sum(w * p for w, p in zip(weights, performance))\n                return total_cost\n\n            except Exception as e:\n                # Return high cost for invalid configurations\n                return 1e6\n\n        return objective_function\n\n    def _evaluate_performance(\n        self,\n        bridge: ControllerPlantBridge,\n        metrics: List[str]\n    ) -> List[float]:\n        \"\"\"Evaluate controller performance metrics.\"\"\"\n\n        # Standard test scenario\n        initial_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])  # Small perturbation\n        dt = 0.001\n        t_final = 10.0\n        steps = int(t_final / dt)\n\n        # Simulation\n        state = initial_state.copy()\n        states = [state.copy()]\n        controls = []\n\n        for _ in range(steps):\n            state, metadata = bridge.step(state, dt)\n            states.append(state.copy())\n            controls.append(metadata['control_value'])\n\n        states = np.array(states)\n        controls = np.array(controls)\n\n        # Compute metrics\n        results = []\n        for metric in metrics:\n            if metric == 'settling_time':\n                results.append(self._compute_settling_time(states, dt))\n            elif metric == 'overshoot':\n                results.append(self._compute_overshoot(states))\n            elif metric == 'control_effort':\n                results.append(self._compute_control_effort(controls))\n            elif metric == 'steady_state_error':\n                results.append(self._compute_steady_state_error(states))\n            else:\n                raise ValueError(f\"Unknown metric: {metric}\")\n\n        return results\n\n    def _get_theoretical_bounds(self) -> Tuple[List[float], List[float]]:\n        \"\"\"Get theoretical bounds for optimization.\"\"\"\n        return get_gain_bounds_for_pso(SMCType(self.controller_type))",
    "lines": 99,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "adbfe20a"
  },
  {
    "id": "integration_protocols_5_89294f72",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass MultiObjectivePSOIntegration:\n    \"\"\"Multi-objective PSO integration for controller optimization.\"\"\"\n\n    def __init__(self, controller_type: str, objectives: List[str]):\n        self.controller_type = controller_type\n        self.objectives = objectives\n\n    def create_pareto_optimizer(self) -> Callable:\n        \"\"\"Create Pareto-optimal PSO optimizer.\"\"\"\n\n        def pareto_objective(gains: np.ndarray) -> List[float]:\n            \"\"\"Multi-objective function returning Pareto front.\"\"\"\n            controller = create_controller(self.controller_type, gains=gains.tolist())\n\n            objectives_values = []\n            for obj in self.objectives:\n                value = self._evaluate_single_objective(controller, obj)\n                objectives_values.append(value)\n\n            return objectives_values\n\n        return pareto_objective\n\n    def _evaluate_single_objective(self, controller, objective: str) -> float:\n        \"\"\"Evaluate a single objective function.\"\"\"\n        # Implementation specific to each objective\n        pass",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "89294f72"
  },
  {
    "id": "integration_protocols_6_76bbb4f5",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass VectorSimulationIntegration:\n    \"\"\"Integration with vectorized simulation engines.\"\"\"\n\n    def __init__(self, controller_factory_config: dict):\n        self.factory_config = controller_factory_config\n\n    def create_batch_simulation(\n        self,\n        controller_types: List[str],\n        gain_sets: List[List[float]],\n        initial_conditions: List[np.ndarray]\n    ) -> Dict[str, np.ndarray]:\n        \"\"\"Create batch simulation for multiple configurations.\"\"\"\n\n        # Validate inputs\n        assert len(controller_types) == len(gain_sets)\n        assert len(controller_types) == len(initial_conditions)\n\n        # Create controllers\n        controllers = []\n        for ctrl_type, gains in zip(controller_types, gain_sets):\n            controller = create_controller(ctrl_type, gains=gains)\n            controllers.append(controller)\n\n        # Prepare simulation data\n        simulation_config = {\n            'controllers': controllers,\n            'initial_conditions': np.array(initial_conditions),\n            'dt': self.factory_config.get('dt', 0.001),\n            't_final': self.factory_config.get('t_final', 10.0)\n        }\n\n        # Run vectorized simulation\n        results = run_vectorized_simulation(simulation_config)\n\n        return results\n\n    def create_parameter_sweep(\n        self,\n        controller_type: str,\n        parameter_ranges: Dict[str, Tuple[float, float]],\n        n_samples: int\n    ) -> Dict[str, Any]:\n        \"\"\"Create parameter sweep simulation.\"\"\"\n\n        # Generate parameter combinations\n        parameter_combinations = self._generate_parameter_combinations(\n            parameter_ranges,\n            n_samples\n        )\n\n        # Create controllers for each combination\n        controllers = []\n        for params in parameter_combinations:\n            controller = create_controller(controller_type, gains=params)\n            controllers.append(controller)\n\n        # Run batch simulation\n        results = self.create_batch_simulation(\n            [controller_type] * len(controllers),\n            parameter_combinations,\n            [np.zeros(6)] * len(controllers)  # Standard initial condition\n        )\n\n        return {\n            'parameters': parameter_combinations,\n            'results': results,\n            'analysis': self._analyze_parameter_sweep(results)\n        }",
    "lines": 72,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76bbb4f5"
  },
  {
    "id": "integration_protocols_7_1d5d33d2",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass RealTimeSimulationBridge:\n    \"\"\"Bridge for real-time simulation integration.\"\"\"\n\n    def __init__(self, controller, dt: float = 0.001):\n        self.controller = controller\n        self.dt = dt\n        self.last_control = 0.0\n        self.control_history = {}\n\n    def real_time_step(self, state: np.ndarray, timestamp: float) -> float:\n        \"\"\"Execute real-time control step.\"\"\"\n        try:\n            # Compute control with timing constraints\n            start_time = time.perf_counter()\n\n            control_result = self.controller.compute_control(\n                state,\n                self.last_control,\n                self.control_history\n            )\n\n            computation_time = time.perf_counter() - start_time\n\n            # Extract control value\n            u = control_result.u if hasattr(control_result, 'u') else control_result\n\n            # Update state\n            self.last_control = u\n            self.control_history[timestamp] = {\n                'control': u,\n                'computation_time': computation_time,\n                'state': state.copy()\n            }\n\n            # Validate real-time constraints\n            if computation_time > self.dt:\n                logger.warning(\n                    f\"Control computation time {computation_time:.6f}s \"\n                    f\"exceeds timestep {self.dt:.6f}s\"\n                )\n\n            return u\n\n        except Exception as e:\n            logger.error(f\"Real-time control step failed: {e}\")\n            return self.last_control  # Use last valid control",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1d5d33d2"
  },
  {
    "id": "integration_protocols_8_74d7ee14",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass HILIntegrationProtocol:\n    \"\"\"Hardware-in-the-loop integration protocol.\"\"\"\n\n    def __init__(self, controller_factory, communication_config: dict):\n        self.factory = controller_factory\n        self.comm_config = communication_config\n        self.safety_limits = self._get_safety_limits()\n\n    def create_hil_controller(\n        self,\n        controller_type: str,\n        gains: List[float],\n        safety_config: dict\n    ) -> 'HILController':\n        \"\"\"Create HIL-compatible controller with safety features.\"\"\"\n\n        # Create base controller\n        base_controller = create_controller(controller_type, gains=gains)\n\n        # Wrap with HIL safety layer\n        hil_controller = HILSafetyWrapper(\n            base_controller,\n            safety_config,\n            self.safety_limits\n        )\n\n        return hil_controller\n\n    def _get_safety_limits(self) -> dict:\n        \"\"\"Get hardware safety limits.\"\"\"\n        return {\n            'max_force': 50.0,  # Reduced for hardware safety\n            'max_angle': np.pi / 6,  # 30 degrees maximum\n            'max_velocity': 10.0,  # rad/s\n            'emergency_stop_conditions': [\n                'angle_limit_exceeded',\n                'velocity_limit_exceeded',\n                'communication_failure'\n            ]\n        }\n\nclass HILSafetyWrapper:\n    \"\"\"Safety wrapper for HIL controllers.\"\"\"\n\n    def __init__(self, controller, safety_config: dict, limits: dict):\n        self.controller = controller\n        self.safety_config = safety_config\n        self.limits = limits\n        self.emergency_stop = False\n\n    def compute_control(self, state: np.ndarray, *args, **kwargs) -> float:\n        \"\"\"Compute control with safety checks.\"\"\"\n\n        # Pre-control safety checks\n        if self._check_emergency_conditions(state):\n            self.emergency_stop = True\n            return 0.0  # Emergency stop\n\n        if self.emergency_stop:\n            return 0.0  # Maintain emergency stop\n\n        # Compute control\n        try:\n            control_result = self.controller.compute_control(state, *args, **kwargs)\n            u = control_result.u if hasattr(control_result, 'u') else control_result\n\n            # Post-control safety checks\n            u_safe = self._apply_safety_limits(u, state)\n\n            return u_safe\n\n        except Exception as e:\n            logger.error(f\"HIL control computation failed: {e}\")\n            self.emergency_stop = True\n            return 0.0\n\n    def _check_emergency_conditions(self, state: np.ndarray) -> bool:\n        \"\"\"Check for emergency stop conditions.\"\"\"\n        theta1, theta2, x, dtheta1, dtheta2, dx = state\n\n        # Angle limits\n        if abs(theta1) > self.limits['max_angle']:\n            logger.warning(\"Pendulum 1 angle limit exceeded\")\n            return True\n\n        if abs(theta2) > self.limits['max_angle']:\n            logger.warning(\"Pendulum 2 angle limit exceeded\")\n            return True\n\n        # Velocity limits\n        if abs(dtheta1) > self.limits['max_velocity']:\n            logger.warning(\"Pendulum 1 velocity limit exceeded\")\n            return True\n\n        if abs(dtheta2) > self.limits['max_velocity']:\n            logger.warning(\"Pendulum 2 velocity limit exceeded\")\n            return True\n\n        return False\n\n    def _apply_safety_limits(self, control: float, state: np.ndarray) -> float:\n        \"\"\"Apply safety limits to control signal.\"\"\"\n        # Force magnitude limit\n        u_limited = np.clip(control, -self.limits['max_force'], self.limits['max_force'])\n\n        # Rate limiting (if previous control available)\n        if hasattr(self, '_last_control'):\n            max_rate = self.safety_config.get('max_control_rate', 100.0)  # N/s\n            dt = self.safety_config.get('dt', 0.001)\n            max_change = max_rate * dt\n\n            control_change = u_limited - self._last_control\n            if abs(control_change) > max_change:\n                u_limited = self._last_control + np.sign(control_change) * max_change\n\n        self._last_control = u_limited\n        return u_limited",
    "lines": 120,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "74d7ee14"
  },
  {
    "id": "integration_protocols_9_344e2b0e",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 9,
    "code": "from pydantic import BaseModel, Field\nfrom typing import Dict, Any, Optional, Union\n\nclass IntegrationConfig(BaseModel):\n    \"\"\"Unified configuration for cross-domain integration.\"\"\"\n\n    # Controller configuration\n    controller: Dict[str, Any] = Field(\n        description=\"Controller-specific configuration\"\n    )\n\n    # Plant model configuration\n    plant_model: Dict[str, Any] = Field(\n        description=\"Plant model configuration\"\n    )\n\n    # Simulation configuration\n    simulation: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Simulation engine configuration\"\n    )\n\n    # Optimization configuration\n    optimization: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"PSO optimization configuration\"\n    )\n\n    # HIL configuration\n    hil: Optional[Dict[str, Any]] = Field(\n        default=None,\n        description=\"Hardware-in-the-loop configuration\"\n    )\n\n    # Integration settings\n    integration: Dict[str, Any] = Field(\n        default_factory=lambda: {\n            'real_time_mode': False,\n            'safety_enabled': True,\n            'logging_level': 'INFO'\n        },\n        description=\"Integration protocol settings\"\n    )\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"controller\": {\n                    \"type\": \"classical_smc\",\n                    \"gains\": [5.0, 5.0, 5.0, 0.5, 0.5, 0.5],\n                    \"max_force\": 150.0\n                },\n                \"plant_model\": {\n                    \"type\": \"simplified_dip\",\n                    \"m1\": 0.5,\n                    \"m2\": 0.5,\n                    \"l1\": 0.5,\n                    \"l2\": 0.5\n                },\n                \"simulation\": {\n                    \"dt\": 0.001,\n                    \"t_final\": 10.0,\n                    \"integration_method\": \"rk4\"\n                },\n                \"optimization\": {\n                    \"algorithm\": \"pso\",\n                    \"n_particles\": 30,\n                    \"n_iterations\": 100\n                }\n            }\n        }\n\nclass ConfigurationValidator:\n    \"\"\"Validator for integration configurations.\"\"\"\n\n    @staticmethod\n    def validate_integration_config(config: IntegrationConfig) -> bool:\n        \"\"\"Validate cross-domain configuration consistency.\"\"\"\n\n        # Validate controller-plant compatibility\n        controller_type = config.controller.get('type')\n        plant_type = config.plant_model.get('type')\n\n        if not ConfigurationValidator._check_controller_plant_compatibility(\n            controller_type, plant_type\n        ):\n            raise ValueError(\n                f\"Controller {controller_type} not compatible with plant {plant_type}\"\n            )\n\n        # Validate real-time constraints\n        if config.integration.get('real_time_mode', False):\n            dt = config.simulation.get('dt', 0.001)\n            if dt < 0.0001:  # 100\u03bcs minimum for real-time\n                raise ValueError(\"Real-time mode requires dt \u2265 100\u03bcs\")\n\n        # Validate HIL safety requirements\n        if config.hil is not None:\n            max_force = config.controller.get('max_force', 150.0)\n            hil_max_force = config.hil.get('max_safe_force', 50.0)\n            if max_force > hil_max_force:\n                logger.warning(\n                    f\"Controller max_force ({max_force}) exceeds HIL safety limit ({hil_max_force})\"\n                )\n\n        return True\n\n    @staticmethod\n    def _check_controller_plant_compatibility(controller_type: str, plant_type: str) -> bool:\n        \"\"\"Check if controller and plant types are compatible.\"\"\"\n        # Define compatibility matrix\n        compatibility_matrix = {\n            'classical_smc': ['simplified_dip', 'full_dip'],\n            'sta_smc': ['simplified_dip', 'full_dip', 'low_rank_dip'],\n            'adaptive_smc': ['simplified_dip', 'full_dip'],\n            'hybrid_adaptive_sta_smc': ['simplified_dip', 'full_dip']\n        }\n\n        compatible_plants = compatibility_matrix.get(controller_type, [])\n        return plant_type in compatible_plants",
    "lines": 120,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "344e2b0e"
  },
  {
    "id": "integration_protocols_10_707b96cd",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 10,
    "code": "from dataclasses import dataclass\nfrom typing import Optional, Dict, Any\nimport numpy as np\n\n@dataclass\nclass SystemState:\n    \"\"\"Standard system state representation.\"\"\"\n    timestamp: float\n    state_vector: np.ndarray  # [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n    metadata: Optional[Dict[str, Any]] = None\n\n@dataclass\nclass ControlAction:\n    \"\"\"Standard control action representation.\"\"\"\n    timestamp: float\n    control_value: float\n    controller_state: Optional[Dict[str, Any]] = None\n    computation_time: Optional[float] = None\n\n@dataclass\nclass SimulationResult:\n    \"\"\"Standard simulation result representation.\"\"\"\n    timestamps: np.ndarray\n    states: np.ndarray\n    controls: np.ndarray\n    performance_metrics: Dict[str, float]\n    metadata: Dict[str, Any]\n\n@dataclass\nclass OptimizationResult:\n    \"\"\"Standard optimization result representation.\"\"\"\n    optimal_gains: List[float]\n    optimal_cost: float\n    convergence_history: List[float]\n    optimization_metadata: Dict[str, Any]",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "707b96cd"
  },
  {
    "id": "integration_protocols_11_3da72066",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass DataExchangeBus:\n    \"\"\"Central data exchange bus for cross-domain communication.\"\"\"\n\n    def __init__(self):\n        self._subscribers = {}\n        self._message_queue = []\n\n    def subscribe(self, topic: str, callback: Callable):\n        \"\"\"Subscribe to data topic.\"\"\"\n        if topic not in self._subscribers:\n            self._subscribers[topic] = []\n        self._subscribers[topic].append(callback)\n\n    def publish(self, topic: str, data: Any):\n        \"\"\"Publish data to topic.\"\"\"\n        if topic in self._subscribers:\n            for callback in self._subscribers[topic]:\n                try:\n                    callback(data)\n                except Exception as e:\n                    logger.error(f\"Subscriber callback failed: {e}\")\n\n    def get_data_schema(self, topic: str) -> Dict[str, Any]:\n        \"\"\"Get data schema for topic.\"\"\"\n        schemas = {\n            'system_state': SystemState.__annotations__,\n            'control_action': ControlAction.__annotations__,\n            'simulation_result': SimulationResult.__annotations__,\n            'optimization_result': OptimizationResult.__annotations__\n        }\n        return schemas.get(topic, {})\n\n# Global data exchange bus instance\ndata_bus = DataExchangeBus()",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3da72066"
  },
  {
    "id": "integration_protocols_12_19cbde93",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\nclass InterfaceContract:\n    \"\"\"Interface contract specification and validation.\"\"\"\n\n    def __init__(self, interface_name: str, requirements: Dict[str, Any]):\n        self.interface_name = interface_name\n        self.requirements = requirements\n\n    def validate_implementation(self, implementation: Any) -> bool:\n        \"\"\"Validate that implementation satisfies contract.\"\"\"\n        try:\n            for requirement, spec in self.requirements.items():\n                if requirement == 'methods':\n                    self._validate_methods(implementation, spec)\n                elif requirement == 'properties':\n                    self._validate_properties(implementation, spec)\n                elif requirement == 'types':\n                    self._validate_types(implementation, spec)\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Contract validation failed for {self.interface_name}: {e}\")\n            return False\n\n    def _validate_methods(self, implementation: Any, method_specs: Dict[str, Dict]):\n        \"\"\"Validate required methods.\"\"\"\n        for method_name, spec in method_specs.items():\n            if not hasattr(implementation, method_name):\n                raise AttributeError(f\"Missing required method: {method_name}\")\n\n            method = getattr(implementation, method_name)\n            if not callable(method):\n                raise TypeError(f\"Attribute {method_name} is not callable\")\n\n            # Validate method signature if specified\n            if 'signature' in spec:\n                self._validate_method_signature(method, spec['signature'])\n\n# Define standard contracts\nCONTROLLER_CONTRACT = InterfaceContract(\n    'ControllerInterface',\n    {\n        'methods': {\n            'compute_control': {\n                'signature': {\n                    'args': ['state', 'last_control', 'history'],\n                    'return_type': 'ControlResult'\n                }\n            }\n        },\n        'properties': {\n            'max_force': 'float',\n            'controller_type': 'str'\n        }\n    }\n)\n\nPLANT_MODEL_CONTRACT = InterfaceContract(\n    'PlantModelInterface',\n    {\n        'methods': {\n            'compute_dynamics': {\n                'signature': {\n                    'args': ['state', 'control', 'disturbances'],\n                    'return_type': 'np.ndarray'\n                }\n            },\n            'get_linearization': {\n                'signature': {\n                    'args': ['state', 'control'],\n                    'return_type': 'Tuple[np.ndarray, np.ndarray]'\n                }\n            }\n        },\n        'properties': {\n            'state_dimension': 'int',\n            'control_dimension': 'int'\n        }\n    }\n)",
    "lines": 83,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19cbde93"
  },
  {
    "id": "integration_protocols_13_bcb03878",
    "file": "docs\\technical\\integration_protocols.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass ContractTester:\n    \"\"\"Automated testing framework for interface contracts.\"\"\"\n\n    def __init__(self, contract: InterfaceContract):\n        self.contract = contract\n\n    def test_implementation(self, implementation: Any) -> Dict[str, bool]:\n        \"\"\"Test implementation against contract.\"\"\"\n        test_results = {}\n\n        # Test method existence and signatures\n        for method_name in self.contract.requirements.get('methods', {}):\n            test_results[f'method_{method_name}'] = self._test_method(\n                implementation, method_name\n            )\n\n        # Test property existence and types\n        for prop_name in self.contract.requirements.get('properties', {}):\n            test_results[f'property_{prop_name}'] = self._test_property(\n                implementation, prop_name\n            )\n\n        # Test behavioral requirements\n        test_results['behavioral'] = self._test_behavioral_requirements(implementation)\n\n        return test_results\n\n    def _test_behavioral_requirements(self, implementation: Any) -> bool:\n        \"\"\"Test behavioral requirements specific to interface.\"\"\"\n        if self.contract.interface_name == 'ControllerInterface':\n            return self._test_controller_behavior(implementation)\n        elif self.contract.interface_name == 'PlantModelInterface':\n            return self._test_plant_model_behavior(implementation)\n        return True\n\n    def _test_controller_behavior(self, controller: Any) -> bool:\n        \"\"\"Test controller-specific behavioral requirements.\"\"\"\n        try:\n            # Test with standard state\n            test_state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n            result = controller.compute_control(test_state, 0.0, {})\n\n            # Validate result structure\n            if hasattr(result, 'u'):\n                control_value = result.u\n            else:\n                control_value = result\n\n            # Check control bounds\n            max_force = getattr(controller, 'max_force', 150.0)\n            if abs(control_value) > max_force:\n                logger.warning(\"Control value exceeds max_force limit\")\n                return False\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Controller behavioral test failed: {e}\")\n            return False",
    "lines": 62,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bcb03878"
  },
  {
    "id": "mathematical_foundations_1_35df49fa",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_classical_smc_gains(gains):\n    \"\"\"Validate Classical SMC gains against mathematical requirements.\"\"\"\n\n    c1, c2, lam1, lam2, K, kd = gains\n\n    # Hurwitz stability conditions\n    assert c1 > 0, \"Surface gain c1 must be positive for Hurwitz stability\"\n    assert c2 > 0, \"Surface gain c2 must be positive for Hurwitz stability\"\n    assert lam1 > 0, \"Velocity gain \u03bb1 must be positive for Hurwitz stability\"\n    assert lam2 > 0, \"Velocity gain \u03bb2 must be positive for Hurwitz stability\"\n\n    # Switching gain positivity\n    assert K > 0, \"Switching gain K must be positive for reaching condition\"\n\n    # Derivative gain non-negativity\n    assert kd >= 0, \"Derivative gain kd must be non-negative\"\n\n    # Numerical stability bounds\n    assert all(1e-12 <= g <= 1e5 for g in gains[:5]), \"Gains must be in numerically stable range\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "35df49fa"
  },
  {
    "id": "mathematical_foundations_2_36a4f0c0",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_super_twisting_gains(gains):\n    \"\"\"Validate Super-Twisting SMC gains for finite-time stability.\"\"\"\n\n    K1, K2, c1, lam1, c2, lam2 = gains\n\n    # Finite-time stability condition\n    assert K1 > K2 > 0, \"Must have K1 > K2 > 0 for finite-time stability\"\n\n    # Sufficient condition for robust finite-time stability\n    # Assumes worst-case Lipschitz constant \u03b1 = 1.0\n    assert K1**2 > 2.0, \"K1\u00b2 > 2\u03b1 required for robust finite-time convergence\"\n\n    # Surface design validation (same as classical)\n    assert c1 > 0 and c2 > 0, \"Surface position gains must be positive\"\n    assert lam1 > 0 and lam2 > 0, \"Surface velocity gains must be positive\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36a4f0c0"
  },
  {
    "id": "mathematical_foundations_3_7cc4b928",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_adaptive_smc_parameters(config):\n    \"\"\"Validate adaptive SMC parameters for stability.\"\"\"\n\n    # Surface gains validation\n    validate_surface_gains(config.gains[:4])\n\n    # Adaptation rate validation\n    gamma = config.gains[4]  # Adaptation rate\n    assert 0 < gamma < 10.0, \"Adaptation rate must be in (0, 10) for stability\"\n\n    # Parameter bounds validation\n    assert hasattr(config, 'K_min') and hasattr(config, 'K_max')\n    assert 0 < config.K_min < config.K_max, \"Parameter bounds must satisfy 0 < K_min < K_max\"\n\n    # Dead zone validation\n    assert config.dead_zone > 0, \"Dead zone must be positive to prevent parameter drift\"",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7cc4b928"
  },
  {
    "id": "mathematical_foundations_4_1d93fded",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_hybrid_smc_configuration(config):\n    \"\"\"Validate hybrid SMC configuration for stability.\"\"\"\n\n    # Validate sub-controller configurations\n    assert hasattr(config, 'classical_config'), \"Hybrid SMC requires classical sub-config\"\n    assert hasattr(config, 'adaptive_config'), \"Hybrid SMC requires adaptive sub-config\"\n\n    validate_classical_smc_gains(config.classical_config.gains)\n    validate_adaptive_smc_parameters(config.adaptive_config)\n\n    # Validate switching logic parameters\n    assert hasattr(config, 'hybrid_mode'), \"Hybrid mode must be specified\"\n    assert config.dt > 0, \"Timestep must be positive for switching logic\"\n\n    # Ensure dwell time constraint\n    min_dwell_time = 0.001  # 1ms minimum\n    assert config.dt >= min_dwell_time, f\"Timestep must be \u2265 {min_dwell_time}s for stability\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1d93fded"
  },
  {
    "id": "mathematical_foundations_5_0e6decae",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass StabilityCertificate:\n    \"\"\"Mathematical stability certificate for factory-created controllers.\"\"\"\n\n    def __init__(self, controller_type: str, gains: List[float]):\n        self.controller_type = controller_type\n        self.gains = gains\n        self.validation_results = {}\n\n    def validate_hurwitz_conditions(self) -> bool:\n        \"\"\"Validate Hurwitz stability of surface design.\"\"\"\n        if self.controller_type == 'classical_smc':\n            c1, c2, lam1, lam2 = self.gains[:4]\n            # Check characteristic polynomial: s\u00b2 + \u03bbs + c\n            return all(c > 0 for c in [c1, c2]) and all(lam > 0 for lam in [lam1, lam2])\n\n    def validate_reaching_conditions(self) -> bool:\n        \"\"\"Validate reaching condition satisfaction.\"\"\"\n        # Implementation depends on controller type\n        return self._controller_specific_reaching_validation()\n\n    def compute_convergence_bounds(self) -> Dict[str, float]:\n        \"\"\"Compute theoretical convergence time bounds.\"\"\"\n        bounds = {}\n\n        if self.controller_type == 'classical_smc':\n            # Classical SMC: exponential convergence\n            lam_min = min(self.gains[2], self.gains[3])  # min(\u03bb1, \u03bb2)\n            bounds['exponential_rate'] = lam_min\n            bounds['settling_time_bound'] = 4.6 / lam_min  # 1% criterion\n\n        elif self.controller_type == 'sta_smc':\n            # Super-Twisting: finite-time convergence\n            K1, K2 = self.gains[0], self.gains[1]\n            if K1 > K2 > 0:\n                bounds['finite_time'] = True\n                bounds['convergence_exponent'] = 0.5\n\n        return bounds",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0e6decae"
  },
  {
    "id": "mathematical_foundations_6_29c0a98f",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_robustness_margin(controller, uncertainty_model):\n    \"\"\"Compute robustness margin for controller.\"\"\"\n\n    # Sample operating points\n    test_points = generate_test_points()\n    min_margin = float('inf')\n\n    for x in test_points:\n        # Compute local linearization\n        A, B = linearize_dynamics(x)\n\n        # Compute controller gain matrix\n        K = compute_controller_gain_matrix(controller, x)\n\n        # Closed-loop system\n        A_cl = A + B @ K\n\n        # Compute structured singular value\n        mu = compute_structured_singular_value(A_cl, uncertainty_model)\n        margin = 1.0 / mu if mu > 0 else float('inf')\n\n        min_margin = min(min_margin, margin)\n\n    return min_margin",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "29c0a98f"
  },
  {
    "id": "mathematical_foundations_7_e8e8cf55",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\nclass PSOOptimizedFactory:\n    \"\"\"Factory with integrated PSO optimization.\"\"\"\n\n    def __init__(self, controller_type: str):\n        self.controller_type = controller_type\n        self.bounds = self._get_theoretical_bounds()\n\n    def _get_theoretical_bounds(self) -> Tuple[List[float], List[float]]:\n        \"\"\"Get theoretically motivated gain bounds.\"\"\"\n\n        if self.controller_type == 'classical_smc':\n            # Based on pole placement and bandwidth requirements\n            lower = [0.1, 0.1, 0.1, 0.1, 1.0, 0.0]  # [c1, c2, \u03bb1, \u03bb2, K, kd]\n            upper = [50.0, 50.0, 50.0, 50.0, 200.0, 50.0]\n\n        elif self.controller_type == 'sta_smc':\n            # Based on finite-time convergence requirements\n            lower = [1.0, 0.5, 0.1, 0.1, 0.1, 0.1]  # [K1, K2, c1, \u03bb1, c2, \u03bb2]\n            upper = [100.0, 99.0, 50.0, 50.0, 50.0, 50.0]  # Ensure K1 > K2\n\n        return lower, upper\n\n    def optimize_gains(self, plant_model, cost_function, n_particles=30, n_iterations=100):\n        \"\"\"Optimize controller gains using PSO.\"\"\"\n\n        # Initialize PSO with theoretical bounds\n        pso = PSOOptimizer(\n            bounds=self.bounds,\n            n_particles=n_particles,\n            n_iterations=n_iterations\n        )\n\n        # Define fitness function\n        def fitness(gains):\n            try:\n                # Create controller with gains\n                controller = create_controller(self.controller_type, gains=gains)\n\n                # Validate stability before simulation\n                if not self._validate_stability(gains):\n                    return float('inf')\n\n                # Simulate and compute cost\n                cost = simulate_and_evaluate(controller, plant_model, cost_function)\n                return cost\n\n            except Exception:\n                return float('inf')\n\n        # Run optimization\n        optimal_gains, optimal_cost = pso.optimize(fitness)\n\n        return optimal_gains, optimal_cost",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8e8cf55"
  },
  {
    "id": "mathematical_foundations_8_80332481",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_numerical_implementation(controller, test_conditions):\n    \"\"\"Validate numerical properties of controller implementation.\"\"\"\n\n    results = {\n        'conditioning': [],\n        'numerical_drift': [],\n        'conservation_properties': []\n    }\n\n    for condition in test_conditions:\n        # Test condition number\n        condition_number = compute_control_conditioning(controller, condition)\n        results['conditioning'].append(condition_number)\n\n        # Test for numerical drift\n        drift = simulate_long_term_stability(controller, condition)\n        results['numerical_drift'].append(drift)\n\n        # Test conservation properties (energy, momentum)\n        conservation = check_conservation_properties(controller, condition)\n        results['conservation_properties'].append(conservation)\n\n    # Validation criteria\n    assert max(results['conditioning']) < 1e12, \"Poor numerical conditioning detected\"\n    assert max(results['numerical_drift']) < 1e-6, \"Numerical drift exceeds tolerance\"\n\n    return results",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80332481"
  },
  {
    "id": "mathematical_foundations_9_4d7db590",
    "file": "docs\\technical\\mathematical_foundations.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef formal_verification_suite(controller_type, gains):\n    \"\"\"Formal verification of mathematical properties.\"\"\"\n\n    verification_results = {\n        'stability_verified': False,\n        'convergence_verified': False,\n        'robustness_verified': False,\n        'implementation_verified': False\n    }\n\n    # Stability verification\n    try:\n        stability_certificate = verify_lyapunov_stability(controller_type, gains)\n        verification_results['stability_verified'] = stability_certificate.is_valid()\n    except Exception as e:\n        logger.warning(f\"Stability verification failed: {e}\")\n\n    # Convergence verification\n    try:\n        convergence_proof = verify_convergence_properties(controller_type, gains)\n        verification_results['convergence_verified'] = convergence_proof.is_valid()\n    except Exception as e:\n        logger.warning(f\"Convergence verification failed: {e}\")\n\n    # Robustness verification\n    try:\n        robustness_analysis = verify_robustness_margins(controller_type, gains)\n        verification_results['robustness_verified'] = robustness_analysis.is_sufficient()\n    except Exception as e:\n        logger.warning(f\"Robustness verification failed: {e}\")\n\n    return verification_results",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d7db590"
  },
  {
    "id": "pso_integration_workflows_1_e29c176f",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 1,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n)\n\nclass EnhancedPSOFactory:\n    \"\"\"Enhanced PSO-Factory integration with advanced optimization capabilities.\"\"\"\n\n    def __init__(self, config: PSOFactoryConfig, global_config_path: str = \"config.yaml\")\n    def create_enhanced_controller_factory(self) -> Callable\n    def create_enhanced_fitness_function(self, controller_factory: Callable) -> Callable\n    def optimize_controller(self) -> Dict[str, Any]\n    def get_optimization_diagnostics(self) -> Dict[str, Any]",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e29c176f"
  },
  {
    "id": "pso_integration_workflows_2_c292caf6",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass PSOFactoryConfig:\n    \"\"\"Configuration for PSO-Factory integration.\"\"\"\n    controller_type: ControllerType                    # Controller to optimize\n    population_size: int = 20                         # PSO swarm size\n    max_iterations: int = 50                          # Maximum iterations\n    convergence_threshold: float = 1e-6               # Convergence criteria\n    max_stagnation_iterations: int = 10               # Early stopping\n    enable_adaptive_bounds: bool = True               # Dynamic bounds\n    enable_gradient_guidance: bool = False            # Gradient hints\n    fitness_timeout: float = 10.0                     # Evaluation timeout [s]\n    use_robust_evaluation: bool = True                # Error recovery",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c292caf6"
  },
  {
    "id": "pso_integration_workflows_3_deb84d29",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 3,
    "code": "class ControllerType(Enum):\n    \"\"\"Controller types for PSO optimization.\"\"\"\n    CLASSICAL_SMC = \"classical_smc\"\n    ADAPTIVE_SMC = \"adaptive_smc\"\n    STA_SMC = \"sta_smc\"\n    HYBRID_SMC = \"hybrid_adaptive_sta_smc\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "deb84d29"
  },
  {
    "id": "pso_integration_workflows_4_c82b0bd4",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 4,
    "code": "from src.optimization.integration.pso_factory_bridge import (\n    EnhancedPSOFactory, PSOFactoryConfig, ControllerType\n)\n\n# Configure PSO optimization\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=20,\n    max_iterations=50\n)\n\n# Create PSO factory and optimize\npso_factory = EnhancedPSOFactory(pso_config, \"config.yaml\")\noptimization_result = pso_factory.optimize_controller()\n\n# Extract results\nif optimization_result['success']:\n    optimized_controller = optimization_result['controller']\n    best_gains = optimization_result['best_gains']\n    best_cost = optimization_result['best_cost']\n\n    print(f\"Optimization successful!\")\n    print(f\"Best gains: {best_gains}\")\n    print(f\"Best cost: {best_cost:.6f}\")\n\n    # Use optimized controller immediately\n    test_state = [0.0, 0.1, 0.05, 0.0, 0.0, 0.0]\n    control_output = optimized_controller.compute_control(test_state)\n    print(f\"Test control output: {control_output}\")\nelse:\n    print(f\"Optimization failed: {optimization_result['error']}\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82b0bd4"
  },
  {
    "id": "pso_integration_workflows_5_a13c3200",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Optimize STA-SMC with Issue #2 considerations\npso_config = PSOFactoryConfig(\n    controller_type=ControllerType.STA_SMC,\n    population_size=25,    # Larger population for better exploration\n    max_iterations=75      # More iterations for convergence\n)\n\npso_factory = EnhancedPSOFactory(pso_config)\nresult = pso_factory.optimize_controller()\n\nif result['success']:\n    # Verify reduced overshoot (Issue #2 resolution)\n    performance = result['performance_analysis']\n    print(f\"Converged: {performance['converged']}\")\n    print(f\"Improvement ratio: {performance['improvement_ratio']:.3f}\")\n\n    # Check optimized surface coefficients\n    gains = result['best_gains']\n    lambda1, lambda2 = gains[4], gains[5]  # \u03bb\u2081, \u03bb\u2082 coefficients\n    print(f\"Optimized surface coefficients: \u03bb\u2081={lambda1:.3f}, \u03bb\u2082={lambda2:.3f}\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a13c3200"
  },
  {
    "id": "pso_integration_workflows_6_8c12e8bb",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.optimization.integration.pso_factory_bridge import (\n    optimize_classical_smc, optimize_adaptive_smc, optimize_sta_smc\n)\n\n# Quick optimization for each controller type\nprint(\"Optimizing controllers...\")\n\nclassical_factory, classical_result = optimize_classical_smc()\nadaptive_factory, adaptive_result = optimize_adaptive_smc()\nsta_factory, sta_result = optimize_sta_smc()\n\n# Compare optimization results\nresults = {\n    'Classical SMC': classical_result['best_cost'],\n    'Adaptive SMC': adaptive_result['best_cost'],\n    'STA SMC': sta_result['best_cost']\n}\n\nprint(\"\\nOptimization Results:\")\nfor controller, cost in results.items():\n    print(f\"  {controller}: {cost:.6f}\")\n\n# Use optimized controllers\noptimized_controllers = {\n    'classical': classical_factory(),\n    'adaptive': adaptive_factory(),\n    'sta': sta_factory()\n}",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8c12e8bb"
  },
  {
    "id": "pso_integration_workflows_7_23192730",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced PSO configuration example\ncustom_pso_config = PSOFactoryConfig(\n    controller_type=ControllerType.ADAPTIVE_SMC,\n    population_size=30,              # Larger swarm for exploration\n    max_iterations=100,              # Extended optimization\n    convergence_threshold=1e-5,      # Strict convergence\n    max_stagnation_iterations=15,    # Patience for stagnation\n    enable_adaptive_bounds=True,     # Dynamic parameter bounds\n    fitness_timeout=15.0,           # Longer evaluation timeout\n    use_robust_evaluation=True      # Enhanced error handling\n)\n\npso_factory = EnhancedPSOFactory(custom_pso_config)\nresult = pso_factory.optimize_controller()\n\n# Detailed result analysis\nif result['success']:\n    print(\"=== Optimization Analysis ===\")\n\n    # Performance metrics\n    perf = result['performance_analysis']\n    print(f\"Converged: {perf['converged']}\")\n    print(f\"Final cost: {perf['final_cost']:.6f}\")\n    print(f\"Initial cost: {perf['initial_cost']:.6f}\")\n    print(f\"Improvement: {perf['improvement_ratio']:.1%}\")\n    print(f\"Iterations: {perf['iterations_completed']}\")\n\n    # Validation results\n    validation = result['validation_results']\n    print(f\"\\nValidation Status:\")\n    print(f\"  Gains valid: {validation['gains_valid']}\")\n    print(f\"  Controller stable: {validation['controller_stable']}\")\n    print(f\"  Performance acceptable: {validation['performance_acceptable']}\")\n\n    if validation['validation_errors']:\n        print(f\"  Warnings: {validation['validation_errors']}\")",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23192730"
  },
  {
    "id": "pso_integration_workflows_8_15b51efb",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Configure PSO for multi-objective optimization\nmulti_objective_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=40,              # Larger population for Pareto front\n    max_iterations=150,              # Extended search\n    convergence_threshold=1e-6,      # High precision\n    enable_adaptive_bounds=True,     # Dynamic exploration\n    fitness_timeout=20.0            # Longer evaluations\n)\n\npso_factory = EnhancedPSOFactory(multi_objective_config)\n\n# The enhanced fitness function automatically considers:\n# - State regulation performance\n# - Control effort minimization\n# - Control smoothness\n# - Stability margins\n# - Robustness to disturbances\n\nresult = pso_factory.optimize_controller()",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15b51efb"
  },
  {
    "id": "pso_integration_workflows_9_acb4f772",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 9,
    "code": "from src.controllers.factory import get_gain_bounds_for_pso, SMCType\n\n# Get controller-specific bounds\nsmc_type = SMCType.CLASSICAL\nbounds = get_gain_bounds_for_pso(smc_type)\nlower_bounds, upper_bounds = bounds\n\nprint(f\"Classical SMC optimization bounds:\")\nprint(f\"  Lower: {lower_bounds}\")\nprint(f\"  Upper: {upper_bounds}\")\n\n# Configure PSO with custom bounds\nconstrained_config = PSOFactoryConfig(\n    controller_type=ControllerType.CLASSICAL_SMC,\n    population_size=25,\n    max_iterations=60,\n    enable_adaptive_bounds=False  # Use fixed bounds\n)\n\npso_factory = EnhancedPSOFactory(constrained_config)\n\n# Factory automatically applies controller-specific bounds:\n# Classical SMC: [k1, k2, \u03bb1, \u03bb2, K, kd] bounds\n# - Position gains: [1.0, 30.0]\n# - Surface coefficients: [1.0, 20.0]\n# - Switching gain: [5.0, 50.0]\n# - Derivative gain: [0.1, 10.0]\n\nresult = pso_factory.optimize_controller()",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "acb4f772"
  },
  {
    "id": "pso_integration_workflows_10_926b1228",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO with adaptive parameters\nadaptive_config = PSOFactoryConfig(\n    controller_type=ControllerType.STA_SMC,\n    population_size=20,\n    max_iterations=80,\n    convergence_threshold=1e-5,\n    max_stagnation_iterations=12,\n    enable_adaptive_bounds=True,     # Key feature\n    enable_gradient_guidance=False,   # Pure PSO\n    use_robust_evaluation=True\n)\n\npso_factory = EnhancedPSOFactory(adaptive_config)\n\n# Adaptive bounds automatically:\n# - Narrow search ranges during convergence\n# - Expand ranges during stagnation\n# - Adjust based on swarm diversity\n\nresult = pso_factory.optimize_controller()\n\n# Monitor adaptive behavior\ndiagnostics = pso_factory.get_optimization_diagnostics()\nprint(f\"Adaptive bounds enabled: {diagnostics['configuration']['enable_adaptive_bounds']}\")",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "926b1228"
  },
  {
    "id": "pso_integration_workflows_11_91c25ace",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Automatic test scenarios (built into enhanced fitness function):\ntest_scenarios = [\n    {\n        'initial_state': [0.0, 0.1, 0.05, 0.0, 0.0, 0.0],  # Small disturbance\n        'sim_time': 2.0,\n        'weight': 1.0,\n        'description': 'small_disturbance'\n    },\n    {\n        'initial_state': [0.0, 0.5, 0.3, 0.0, 0.0, 0.0],   # Large angles\n        'sim_time': 3.0,\n        'weight': 1.5,     # Higher weight for challenging scenario\n        'description': 'large_angles'\n    },\n    {\n        'initial_state': [0.0, 0.2, 0.1, 0.0, 1.0, 0.5],   # High velocity\n        'sim_time': 2.5,\n        'weight': 1.2,\n        'description': 'high_velocity'\n    }\n]",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91c25ace"
  },
  {
    "id": "pso_integration_workflows_12_fddf8183",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef _evaluate_controller_performance(self, controller, gains):\n    \"\"\"Multi-scenario performance evaluation.\"\"\"\n\n    # For each test scenario:\n    for scenario in test_scenarios:\n        # Simulate controller performance\n        cost = self._simulate_scenario(controller, scenario)\n        total_cost += cost * scenario['weight']\n\n    # Cost components:\n    # - Position error: 10.0 * \u222b|state_error|\u00b2dt\n    # - Control effort: 0.1 * \u222b|u|\u00b2dt\n    # - Control rate: 0.05 * \u222b|du/dt|\u00b2dt\n    # - Stability penalty: penalties for instability\n\n    return total_cost / total_weight",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fddf8183"
  },
  {
    "id": "pso_integration_workflows_13_1a9e207c",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Configure PSO for robustness optimization\nrobust_config = PSOFactoryConfig(\n    controller_type=ControllerType.ADAPTIVE_SMC,\n    population_size=35,\n    max_iterations=120,\n    fitness_timeout=25.0,    # Longer timeout for robust evaluation\n    use_robust_evaluation=True\n)\n\npso_factory = EnhancedPSOFactory(robust_config)\n\n# Robust evaluation automatically includes:\n# - Multiple initial conditions\n# - Different simulation durations\n# - Varying disturbance levels\n# - Parameter uncertainty scenarios\n\nresult = pso_factory.optimize_controller()\n\nif result['success']:\n    # Analyze robustness metrics\n    validation = result['validation_results']\n    print(f\"Robustness Analysis:\")\n    print(f\"  All scenarios passed: {validation['performance_acceptable']}\")\n    print(f\"  Controller stability: {validation['controller_stable']}\")",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a9e207c"
  },
  {
    "id": "pso_integration_workflows_14_ccc3577e",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.optimization.integration.pso_factory_bridge import EnhancedPSOFactory\n\n# Create PSO factory with monitoring\npso_factory = EnhancedPSOFactory(pso_config)\n\n# Start optimization\nprint(\"Starting optimization with real-time monitoring...\")\nresult = pso_factory.optimize_controller()\n\n# Access monitoring statistics\nstats = pso_factory.validation_stats\nprint(f\"\\nOptimization Statistics:\")\nprint(f\"  Total fitness evaluations: {stats['fitness_evaluations']}\")\nprint(f\"  Failed evaluations: {stats['failed_evaluations']}\")\nprint(f\"  Parameter violations: {stats['parameter_violations']}\")\nprint(f\"  Convergence checks: {stats['convergence_checks']}\")\n\n# Calculate success metrics\nsuccess_rate = 1.0 - (stats['failed_evaluations'] / max(stats['fitness_evaluations'], 1))\nprint(f\"  Evaluation success rate: {success_rate:.1%}\")",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccc3577e"
  },
  {
    "id": "pso_integration_workflows_15_91a1ad22",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_convergence(optimization_result):\n    \"\"\"Analyze PSO convergence characteristics.\"\"\"\n\n    if not optimization_result['success']:\n        print(\"Optimization failed - no convergence analysis available\")\n        return\n\n    # Extract convergence data\n    performance = optimization_result['performance_analysis']\n\n    print(\"=== Convergence Analysis ===\")\n    print(f\"Converged: {performance['converged']}\")\n    print(f\"Convergence rate: {performance['convergence_rate']:.2e}\")\n    print(f\"Improvement ratio: {performance['improvement_ratio']:.1%}\")\n    print(f\"Cost reduction: {performance['cost_reduction']:.6f}\")\n    print(f\"Iterations completed: {performance['iterations_completed']}\")\n\n    # Convergence quality assessment\n    if performance['converged']:\n        if performance['convergence_rate'] < 1e-6:\n            quality = \"Excellent\"\n        elif performance['convergence_rate'] < 1e-4:\n            quality = \"Good\"\n        elif performance['convergence_rate'] < 1e-2:\n            quality = \"Fair\"\n        else:\n            quality = \"Poor\"\n\n        print(f\"Convergence quality: {quality}\")\n    else:\n        print(\"Warning: Optimization did not converge\")\n\n        # Suggest improvements\n        if performance['iterations_completed'] >= 100:\n            print(\"  Suggestion: Increase convergence threshold\")\n        else:\n            print(\"  Suggestion: Increase max_iterations\")\n\n# Example usage\nresult = pso_factory.optimize_controller()\nanalyze_convergence(result)",
    "lines": 44,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91a1ad22"
  },
  {
    "id": "pso_integration_workflows_16_f75dc78e",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef comprehensive_diagnostics(pso_factory, optimization_result):\n    \"\"\"Generate comprehensive optimization diagnostics.\"\"\"\n\n    print(\"=== Comprehensive PSO Diagnostics ===\")\n\n    # 1. Configuration summary\n    diagnostics = pso_factory.get_optimization_diagnostics()\n    config = diagnostics['configuration']\n\n    print(f\"\\nConfiguration:\")\n    print(f\"  Controller type: {config['controller_type']}\")\n    print(f\"  Population size: {config['population_size']}\")\n    print(f\"  Max iterations: {config['max_iterations']}\")\n    print(f\"  Convergence threshold: {config['convergence_threshold']}\")\n\n    # 2. Controller specifications\n    specs = diagnostics['controller_specs']\n    print(f\"\\nController Specifications:\")\n    print(f\"  Expected gains: {specs['n_gains']}\")\n    print(f\"  Bounds: {specs['bounds']}\")\n    print(f\"  Default gains: {specs['default_gains']}\")\n\n    # 3. Validation statistics\n    stats = diagnostics['validation_statistics']\n    print(f\"\\nValidation Statistics:\")\n    print(f\"  Fitness evaluations: {stats['fitness_evaluations']}\")\n    print(f\"  Failed evaluations: {stats['failed_evaluations']}\")\n    print(f\"  Parameter violations: {stats['parameter_violations']}\")\n\n    # 4. Optimization outcome\n    if optimization_result['success']:\n        print(f\"\\nOptimization Outcome:\")\n        print(f\"  Status: SUCCESS\")\n        print(f\"  Best cost: {optimization_result['best_cost']:.6f}\")\n        print(f\"  Best gains: {optimization_result['best_gains']}\")\n\n        # Performance analysis\n        perf = optimization_result['performance_analysis']\n        print(f\"  Converged: {perf['converged']}\")\n        print(f\"  Improvement: {perf['improvement_ratio']:.1%}\")\n\n        # Validation results\n        validation = optimization_result['validation_results']\n        print(f\"  Gains valid: {validation['gains_valid']}\")\n        print(f\"  Controller stable: {validation['controller_stable']}\")\n\n    else:\n        print(f\"\\nOptimization Outcome:\")\n        print(f\"  Status: FAILED\")\n        print(f\"  Error: {optimization_result.get('error', 'Unknown')}\")\n\n# Usage example\npso_factory = EnhancedPSOFactory(pso_config)\nresult = pso_factory.optimize_controller()\ncomprehensive_diagnostics(pso_factory, result)",
    "lines": 58,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f75dc78e"
  },
  {
    "id": "pso_integration_workflows_17_18c9e49f",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 17,
    "code": "def analyze_optimization_history(optimization_result):\n    \"\"\"Analyze optimization history and performance trends.\"\"\"\n\n    if not optimization_result['success']:\n        return\n\n    history = optimization_result.get('convergence_history', {})\n    cost_history = history.get('cost', [])\n\n    if len(cost_history) == 0:\n        print(\"No history available for analysis\")\n        return\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    costs = np.array(cost_history)\n    iterations = np.arange(len(costs))\n\n    # Plot convergence history\n    plt.figure(figsize=(12, 8))\n\n    plt.subplot(2, 2, 1)\n    plt.plot(iterations, costs, 'b-', linewidth=2)\n    plt.xlabel('Iteration')\n    plt.ylabel('Best Cost')\n    plt.title('PSO Convergence History')\n    plt.grid(True)\n\n    # Plot improvement rate\n    plt.subplot(2, 2, 2)\n    if len(costs) > 1:\n        improvement = np.diff(costs)\n        plt.plot(iterations[1:], improvement, 'r-', linewidth=1)\n        plt.xlabel('Iteration')\n        plt.ylabel('Cost Improvement')\n        plt.title('Cost Improvement Rate')\n        plt.grid(True)\n\n    # Plot convergence rate\n    plt.subplot(2, 2, 3)\n    window_size = min(10, len(costs) // 4)\n    if window_size > 1:\n        convergence_rate = np.array([\n            np.std(costs[max(0, i-window_size):i+1]) / max(np.mean(costs[max(0, i-window_size):i+1]), 1e-6)\n            for i in range(window_size, len(costs))\n        ])\n        plt.plot(iterations[window_size:], convergence_rate, 'g-', linewidth=2)\n        plt.xlabel('Iteration')\n        plt.ylabel('Convergence Rate')\n        plt.title('Convergence Rate (std/mean)')\n        plt.yscale('log')\n        plt.grid(True)\n\n    # Summary statistics\n    plt.subplot(2, 2, 4)\n    final_cost = costs[-1]\n    initial_cost = costs[0]\n    improvement_ratio = (initial_cost - final_cost) / max(initial_cost, 1e-6)\n\n    stats_text = f\"\"\"\n    Initial Cost: {initial_cost:.6f}\n    Final Cost: {final_cost:.6f}\n    Improvement: {improvement_ratio:.1%}\n    Iterations: {len(costs)}\n    \"\"\"\n\n    plt.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center')\n    plt.axis('off')\n    plt.title('Optimization Summary')\n\n    plt.tight_layout()\n    plt.savefig('pso_convergence_analysis.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    return {\n        'initial_cost': float(initial_cost),\n        'final_cost': float(final_cost),\n        'improvement_ratio': float(improvement_ratio),\n        'iterations': len(costs)\n    }\n\n# Usage example\nresult = pso_factory.optimize_controller()\nhistory_analysis = analyze_optimization_history(result)",
    "lines": 85,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "18c9e49f"
  },
  {
    "id": "pso_integration_workflows_18_4cb67a86",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef compare_controller_performance():\n    \"\"\"Compare optimized controllers across different types.\"\"\"\n\n    # Optimize all controller types\n    controller_types = [\n        ControllerType.CLASSICAL_SMC,\n        ControllerType.STA_SMC,\n        ControllerType.ADAPTIVE_SMC\n    ]\n\n    results = {}\n\n    for controller_type in controller_types:\n        print(f\"Optimizing {controller_type.value}...\")\n\n        pso_config = PSOFactoryConfig(\n            controller_type=controller_type,\n            population_size=20,\n            max_iterations=50\n        )\n\n        pso_factory = EnhancedPSOFactory(pso_config)\n        result = pso_factory.optimize_controller()\n\n        results[controller_type.value] = result\n\n    # Performance comparison\n    print(\"\\n=== Controller Performance Comparison ===\")\n    print(f\"{'Controller':<20} {'Best Cost':<12} {'Converged':<10} {'Improvement':<12}\")\n    print(\"-\" * 60)\n\n    for controller_name, result in results.items():\n        if result['success']:\n            best_cost = result['best_cost']\n            converged = result['performance_analysis']['converged']\n            improvement = result['performance_analysis']['improvement_ratio']\n\n            print(f\"{controller_name:<20} {best_cost:<12.6f} {str(converged):<10} {improvement:<12.1%}\")\n        else:\n            print(f\"{controller_name:<20} {'FAILED':<12} {'-':<10} {'-':<12}\")\n\n    return results\n\n# Run comparison\ncomparison_results = compare_controller_performance()",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4cb67a86"
  },
  {
    "id": "pso_integration_workflows_19_fbe88ee0",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 19,
    "code": "def production_optimization_pipeline(controller_type: str,\n                                   config_path: str = \"config.yaml\",\n                                   output_path: str = \"optimized_gains.json\"):\n    \"\"\"Production-ready PSO optimization pipeline.\"\"\"\n\n    import json\n    import logging\n    from datetime import datetime\n\n    # Setup logging\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    logger = logging.getLogger(__name__)\n\n    # Map string to enum\n    controller_type_map = {\n        'classical_smc': ControllerType.CLASSICAL_SMC,\n        'sta_smc': ControllerType.STA_SMC,\n        'adaptive_smc': ControllerType.ADAPTIVE_SMC,\n        'hybrid_adaptive_sta_smc': ControllerType.HYBRID_SMC\n    }\n\n    if controller_type not in controller_type_map:\n        raise ValueError(f\"Unknown controller type: {controller_type}\")\n\n    controller_enum = controller_type_map[controller_type]\n\n    try:\n        # Production PSO configuration\n        pso_config = PSOFactoryConfig(\n            controller_type=controller_enum,\n            population_size=25,              # Balanced exploration/exploitation\n            max_iterations=100,              # Sufficient for convergence\n            convergence_threshold=1e-6,      # High precision\n            max_stagnation_iterations=15,    # Prevent premature termination\n            enable_adaptive_bounds=True,     # Dynamic optimization\n            fitness_timeout=20.0,           # Generous timeout\n            use_robust_evaluation=True      # Production reliability\n        )\n\n        logger.info(f\"Starting production optimization for {controller_type}\")\n        logger.info(f\"Configuration: {pso_config}\")\n\n        # Create factory and optimize\n        pso_factory = EnhancedPSOFactory(pso_config, config_path)\n\n        start_time = datetime.now()\n        optimization_result = pso_factory.optimize_controller()\n        end_time = datetime.now()\n\n        optimization_time = (end_time - start_time).total_seconds()\n\n        if optimization_result['success']:\n            # Extract optimized parameters\n            best_gains = optimization_result['best_gains']\n            best_cost = optimization_result['best_cost']\n\n            # Validation results\n            validation = optimization_result['validation_results']\n            performance = optimization_result['performance_analysis']\n\n            # Production validation checks\n            production_ready = (\n                validation['gains_valid'] and\n                validation['controller_stable'] and\n                validation['performance_acceptable'] and\n                performance['converged']\n            )\n\n            # Prepare production data\n            production_data = {\n                'controller_type': controller_type,\n                'optimization_timestamp': start_time.isoformat(),\n                'optimization_duration_seconds': optimization_time,\n                'optimized_gains': best_gains,\n                'optimization_cost': best_cost,\n                'convergence_analysis': performance,\n                'validation_results': validation,\n                'production_ready': production_ready,\n                'optimization_configuration': {\n                    'population_size': pso_config.population_size,\n                    'max_iterations': pso_config.max_iterations,\n                    'convergence_threshold': pso_config.convergence_threshold\n                }\n            }\n\n            # Save results\n            with open(output_path, 'w') as f:\n                json.dump(production_data, f, indent=2)\n\n            logger.info(f\"Optimization completed successfully\")\n            logger.info(f\"Best cost: {best_cost:.6f}\")\n            logger.info(f\"Optimized gains: {best_gains}\")\n            logger.info(f\"Production ready: {production_ready}\")\n            logger.info(f\"Results saved to: {output_path}\")\n\n            if not production_ready:\n                logger.warning(\"Controller may not be production ready - review validation results\")\n\n            return optimization_result\n\n        else:\n            error_msg = optimization_result.get('error', 'Unknown error')\n            logger.error(f\"Optimization failed: {error_msg}\")\n\n            # Save failure information\n            failure_data = {\n                'controller_type': controller_type,\n                'optimization_timestamp': start_time.isoformat(),\n                'optimization_duration_seconds': optimization_time,\n                'status': 'FAILED',\n                'error': error_msg,\n                'optimization_stats': optimization_result.get('optimization_stats', {})\n            }\n\n            failure_path = output_path.replace('.json', '_failure.json')\n            with open(failure_path, 'w') as f:\n                json.dump(failure_data, f, indent=2)\n\n            logger.info(f\"Failure data saved to: {failure_path}\")\n\n            return None\n\n    except Exception as e:\n        logger.error(f\"Production optimization pipeline failed: {e}\")\n        raise\n\n# Usage examples\nclassical_result = production_optimization_pipeline('classical_smc', output_path='classical_gains.json')\nsta_result = production_optimization_pipeline('sta_smc', output_path='sta_gains.json')\nadaptive_result = production_optimization_pipeline('adaptive_smc', output_path='adaptive_gains.json')",
    "lines": 133,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbe88ee0"
  },
  {
    "id": "pso_integration_workflows_20_30bc08bc",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ndef batch_optimization_workflow(controller_types: List[str],\n                              optimization_configs: Dict[str, Dict] = None):\n    \"\"\"Batch optimization workflow for multiple controllers.\"\"\"\n\n    import concurrent.futures\n    import os\n    from datetime import datetime\n\n    if optimization_configs is None:\n        optimization_configs = {}\n\n    def optimize_single_controller(controller_type):\n        \"\"\"Optimize a single controller type.\"\"\"\n        try:\n            # Get custom config or use defaults\n            custom_config = optimization_configs.get(controller_type, {})\n\n            # Default configuration\n            default_config = {\n                'population_size': 25,\n                'max_iterations': 75,\n                'convergence_threshold': 1e-6,\n                'enable_adaptive_bounds': True,\n                'use_robust_evaluation': True\n            }\n\n            # Merge configurations\n            config_params = {**default_config, **custom_config}\n\n            controller_enum = {\n                'classical_smc': ControllerType.CLASSICAL_SMC,\n                'sta_smc': ControllerType.STA_SMC,\n                'adaptive_smc': ControllerType.ADAPTIVE_SMC,\n                'hybrid_adaptive_sta_smc': ControllerType.HYBRID_SMC\n            }[controller_type]\n\n            pso_config = PSOFactoryConfig(\n                controller_type=controller_enum,\n                **config_params\n            )\n\n            pso_factory = EnhancedPSOFactory(pso_config)\n            result = pso_factory.optimize_controller()\n\n            return controller_type, result\n\n        except Exception as e:\n            return controller_type, {'success': False, 'error': str(e)}\n\n    # Parallel optimization\n    print(f\"Starting batch optimization for {len(controller_types)} controllers...\")\n\n    results = {}\n    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n        # Submit optimization tasks\n        future_to_controller = {\n            executor.submit(optimize_single_controller, ct): ct\n            for ct in controller_types\n        }\n\n        # Collect results\n        for future in concurrent.futures.as_completed(future_to_controller):\n            controller_type = future_to_controller[future]\n            try:\n                controller_name, optimization_result = future.result()\n                results[controller_name] = optimization_result\n\n                if optimization_result['success']:\n                    cost = optimization_result['best_cost']\n                    print(f\"\u2705 {controller_name}: {cost:.6f}\")\n                else:\n                    error = optimization_result.get('error', 'Unknown')\n                    print(f\"\u274c {controller_name}: {error}\")\n\n            except Exception as e:\n                print(f\"\u274c {controller_type}: Exception - {e}\")\n                results[controller_type] = {'success': False, 'error': str(e)}\n\n    # Save batch results\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    batch_results_path = f\"batch_optimization_{timestamp}.json\"\n\n    with open(batch_results_path, 'w') as f:\n        json.dump(results, f, indent=2, default=str)\n\n    print(f\"\\nBatch optimization completed. Results saved to: {batch_results_path}\")\n\n    # Summary report\n    successful = sum(1 for r in results.values() if r['success'])\n    total = len(results)\n\n    print(f\"\\nBatch Summary:\")\n    print(f\"  Total controllers: {total}\")\n    print(f\"  Successful optimizations: {successful}\")\n    print(f\"  Failed optimizations: {total - successful}\")\n    print(f\"  Success rate: {successful/total:.1%}\")\n\n    return results\n\n# Usage example\ncontrollers_to_optimize = ['classical_smc', 'sta_smc', 'adaptive_smc']\n\n# Custom configurations for specific controllers\ncustom_configs = {\n    'sta_smc': {\n        'population_size': 30,      # Larger population for STA-SMC\n        'max_iterations': 100,      # More iterations for Issue #2 resolution\n        'convergence_threshold': 1e-5\n    },\n    'adaptive_smc': {\n        'population_size': 35,      # Complex parameter space\n        'max_iterations': 120\n    }\n}\n\nbatch_results = batch_optimization_workflow(controllers_to_optimize, custom_configs)",
    "lines": 119,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30bc08bc"
  },
  {
    "id": "pso_integration_workflows_21_4947f924",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef complete_research_workflow():\n    \"\"\"Complete research workflow demonstrating PSO-factory integration.\"\"\"\n\n    print(\"=== Complete Research Workflow ===\")\n\n    # Step 1: Baseline controllers\n    print(\"\\n1. Creating baseline controllers...\")\n\n    from src.controllers.factory import create_controller\n\n    baseline_controllers = {\n        'classical': create_controller('classical_smc', gains=[8.0, 6.0, 4.0, 3.0, 15.0, 2.0]),\n        'sta': create_controller('sta_smc', gains=[8.0, 4.0, 12.0, 6.0, 4.85, 3.43]),\n        'adaptive': create_controller('adaptive_smc', gains=[12.0, 10.0, 6.0, 5.0, 2.5])\n    }\n\n    print(f\"Created {len(baseline_controllers)} baseline controllers\")\n\n    # Step 2: PSO optimization\n    print(\"\\n2. Running PSO optimization...\")\n\n    optimization_results = {}\n\n    for controller_name in ['classical_smc', 'sta_smc', 'adaptive_smc']:\n        controller_enum = {\n            'classical_smc': ControllerType.CLASSICAL_SMC,\n            'sta_smc': ControllerType.STA_SMC,\n            'adaptive_smc': ControllerType.ADAPTIVE_SMC\n        }[controller_name]\n\n        pso_config = PSOFactoryConfig(\n            controller_type=controller_enum,\n            population_size=20,\n            max_iterations=60,\n            use_robust_evaluation=True\n        )\n\n        pso_factory = EnhancedPSOFactory(pso_config)\n        result = pso_factory.optimize_controller()\n\n        optimization_results[controller_name] = result\n\n        if result['success']:\n            cost = result['best_cost']\n            converged = result['performance_analysis']['converged']\n            print(f\"  {controller_name}: cost={cost:.6f}, converged={converged}\")\n        else:\n            print(f\"  {controller_name}: FAILED - {result.get('error', 'Unknown')}\")\n\n    # Step 3: Performance comparison\n    print(\"\\n3. Performance comparison...\")\n\n    comparison_data = []\n\n    for controller_name, result in optimization_results.items():\n        if result['success']:\n            comparison_data.append({\n                'controller': controller_name,\n                'cost': result['best_cost'],\n                'gains': result['best_gains'],\n                'converged': result['performance_analysis']['converged'],\n                'improvement': result['performance_analysis']['improvement_ratio']\n            })\n\n    # Sort by cost (lower is better)\n    comparison_data.sort(key=lambda x: x['cost'])\n\n    print(f\"{'Rank':<4} {'Controller':<15} {'Cost':<12} {'Converged':<10} {'Improvement':<12}\")\n    print(\"-\" * 55)\n\n    for i, data in enumerate(comparison_data, 1):\n        print(f\"{i:<4} {data['controller']:<15} {data['cost']:<12.6f} \"\n              f\"{str(data['converged']):<10} {data['improvement']:<12.1%}\")\n\n    # Step 4: Best controller analysis\n    if comparison_data:\n        best_controller = comparison_data[0]\n        print(f\"\\n4. Best controller analysis:\")\n        print(f\"  Controller: {best_controller['controller']}\")\n        print(f\"  Cost: {best_controller['cost']:.6f}\")\n        print(f\"  Gains: {best_controller['gains']}\")\n        print(f\"  Converged: {best_controller['converged']}\")\n        print(f\"  Improvement: {best_controller['improvement']:.1%}\")\n\n        # Create optimized controller\n        best_name = best_controller['controller']\n        best_gains = best_controller['gains']\n\n        optimized_controller = create_controller(best_name, gains=best_gains)\n\n        print(f\"  Optimized controller ready for deployment\")\n\n        return {\n            'baseline_controllers': baseline_controllers,\n            'optimization_results': optimization_results,\n            'best_controller': optimized_controller,\n            'comparison_data': comparison_data\n        }\n\n    else:\n        print(\"No successful optimizations\")\n        return None\n\n# Run complete workflow\nworkflow_results = complete_research_workflow()",
    "lines": 108,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4947f924"
  },
  {
    "id": "pso_integration_workflows_22_494c51ce",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ndef real_time_optimization_integration():\n    \"\"\"Demonstrate real-time optimization with live feedback.\"\"\"\n\n    import time\n    import threading\n    from queue import Queue\n\n    class OptimizationMonitor:\n        \"\"\"Real-time optimization monitoring.\"\"\"\n\n        def __init__(self):\n            self.progress_queue = Queue()\n            self.current_iteration = 0\n            self.current_best_cost = float('inf')\n            self.is_running = False\n\n        def update_progress(self, iteration, best_cost):\n            \"\"\"Update optimization progress.\"\"\"\n            self.current_iteration = iteration\n            self.current_best_cost = best_cost\n            self.progress_queue.put((iteration, best_cost))\n\n        def start_monitoring(self):\n            \"\"\"Start monitoring thread.\"\"\"\n            self.is_running = True\n            monitor_thread = threading.Thread(target=self._monitor_loop)\n            monitor_thread.daemon = True\n            monitor_thread.start()\n\n        def stop_monitoring(self):\n            \"\"\"Stop monitoring.\"\"\"\n            self.is_running = False\n\n        def _monitor_loop(self):\n            \"\"\"Monitoring loop.\"\"\"\n            while self.is_running:\n                try:\n                    if not self.progress_queue.empty():\n                        iteration, cost = self.progress_queue.get(timeout=0.1)\n                        print(f\"\\rIteration {iteration}: Best cost = {cost:.6f}\", end='', flush=True)\n                    time.sleep(0.1)\n                except:\n                    continue\n\n    # Create monitor\n    monitor = OptimizationMonitor()\n\n    # Configure PSO with monitoring integration\n    pso_config = PSOFactoryConfig(\n        controller_type=ControllerType.CLASSICAL_SMC,\n        population_size=20,\n        max_iterations=50,\n        use_robust_evaluation=True\n    )\n\n    print(\"Starting real-time PSO optimization...\")\n\n    # Start monitoring\n    monitor.start_monitoring()\n\n    try:\n        # Create factory and optimize\n        pso_factory = EnhancedPSOFactory(pso_config)\n\n        # Note: In a real implementation, you would integrate the monitor\n        # with the PSO algorithm's iteration callback\n\n        result = pso_factory.optimize_controller()\n\n        print(\"\\n\")  # New line after progress updates\n\n        if result['success']:\n            print(f\"Optimization completed successfully!\")\n            print(f\"Final cost: {result['best_cost']:.6f}\")\n            print(f\"Optimized gains: {result['best_gains']}\")\n\n            # Real-time validation\n            optimized_controller = result['controller']\n\n            print(\"\\nPerforming real-time validation...\")\n            test_states = [\n                [0.0, 0.1, 0.05, 0.0, 0.0, 0.0],\n                [0.0, 0.2, 0.1, 0.0, 0.0, 0.0],\n                [0.0, 0.3, 0.15, 0.0, 0.0, 0.0]\n            ]\n\n            for i, state in enumerate(test_states):\n                control_output = optimized_controller.compute_control(state)\n                if hasattr(control_output, 'u'):\n                    u = control_output.u\n                else:\n                    u = control_output\n                print(f\"  Test {i+1}: state={state[:3]}, control={u:.3f}\")\n\n            print(\"Real-time validation completed\")\n\n        else:\n            print(f\"Optimization failed: {result.get('error', 'Unknown')}\")\n\n    finally:\n        monitor.stop_monitoring()\n\n    return result\n\n# Run real-time optimization\nreal_time_result = real_time_optimization_integration()",
    "lines": 109,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "494c51ce"
  },
  {
    "id": "pso_integration_workflows_23_8714d2f1",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Guidelines for population size selection:\npopulation_guidelines = {\n    'small_problems': {\n        'gains_count': '\u2264 4',\n        'recommended_size': '15-20',\n        'reasoning': 'Sufficient diversity for low-dimensional search'\n    },\n    'medium_problems': {\n        'gains_count': '5-6',\n        'recommended_size': '20-30',\n        'reasoning': 'Balanced exploration/exploitation'\n    },\n    'large_problems': {\n        'gains_count': '> 6',\n        'recommended_size': '30-50',\n        'reasoning': 'Increased diversity for complex landscapes'\n    }\n}\n\ndef get_recommended_population_size(controller_type: ControllerType) -> int:\n    \"\"\"Get recommended population size for controller type.\"\"\"\n\n    gain_counts = {\n        ControllerType.CLASSICAL_SMC: 6,\n        ControllerType.STA_SMC: 6,\n        ControllerType.ADAPTIVE_SMC: 5,\n        ControllerType.HYBRID_SMC: 4\n    }\n\n    n_gains = gain_counts.get(controller_type, 6)\n\n    if n_gains <= 4:\n        return 20\n    elif n_gains <= 6:\n        return 25\n    else:\n        return 35",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8714d2f1"
  },
  {
    "id": "pso_integration_workflows_24_e3ab9ac5",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\ndef configure_convergence_criteria(controller_type: ControllerType,\n                                 optimization_goal: str) -> PSOFactoryConfig:\n    \"\"\"Configure convergence criteria based on optimization goals.\"\"\"\n\n    criteria_map = {\n        'fast_prototyping': {\n            'max_iterations': 30,\n            'convergence_threshold': 1e-4,\n            'max_stagnation_iterations': 8\n        },\n        'research_quality': {\n            'max_iterations': 75,\n            'convergence_threshold': 1e-5,\n            'max_stagnation_iterations': 12\n        },\n        'production_grade': {\n            'max_iterations': 100,\n            'convergence_threshold': 1e-6,\n            'max_stagnation_iterations': 15\n        }\n    }\n\n    criteria = criteria_map.get(optimization_goal, criteria_map['research_quality'])\n    population_size = get_recommended_population_size(controller_type)\n\n    return PSOFactoryConfig(\n        controller_type=controller_type,\n        population_size=population_size,\n        **criteria,\n        use_robust_evaluation=True,\n        enable_adaptive_bounds=True\n    )\n\n# Usage examples\nfast_config = configure_convergence_criteria(ControllerType.CLASSICAL_SMC, 'fast_prototyping')\nresearch_config = configure_convergence_criteria(ControllerType.STA_SMC, 'research_quality')\nproduction_config = configure_convergence_criteria(ControllerType.ADAPTIVE_SMC, 'production_grade')",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3ab9ac5"
  },
  {
    "id": "pso_integration_workflows_25_8d1802c0",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\ndef robust_pso_optimization(controller_type: ControllerType,\n                          max_retries: int = 3) -> Dict[str, Any]:\n    \"\"\"Robust PSO optimization with automatic retry logic.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            # Adjust configuration based on attempt\n            population_size = 20 + (attempt * 5)  # Increase diversity on retries\n            max_iterations = 50 + (attempt * 25)   # More patience on retries\n\n            pso_config = PSOFactoryConfig(\n                controller_type=controller_type,\n                population_size=population_size,\n                max_iterations=max_iterations,\n                convergence_threshold=1e-5,\n                use_robust_evaluation=True,\n                fitness_timeout=15.0 + (attempt * 5.0)  # Longer timeout on retries\n            )\n\n            pso_factory = EnhancedPSOFactory(pso_config)\n            result = pso_factory.optimize_controller()\n\n            if result['success']:\n                # Validate result quality\n                performance = result['performance_analysis']\n                validation = result['validation_results']\n\n                quality_checks = [\n                    performance['converged'],\n                    validation['gains_valid'],\n                    validation['controller_stable'],\n                    result['best_cost'] < 1000.0  # Reasonable cost threshold\n                ]\n\n                if all(quality_checks):\n                    print(f\"Optimization successful on attempt {attempt + 1}\")\n                    return result\n                else:\n                    print(f\"Attempt {attempt + 1}: Poor quality result, retrying...\")\n                    continue\n            else:\n                print(f\"Attempt {attempt + 1} failed: {result.get('error', 'Unknown')}\")\n                continue\n\n        except Exception as e:\n            print(f\"Attempt {attempt + 1} exception: {e}\")\n            continue\n\n    # All attempts failed\n    return {\n        'success': False,\n        'error': f'Optimization failed after {max_retries} attempts',\n        'controller_type': controller_type.value\n    }\n\n# Usage\nrobust_result = robust_pso_optimization(ControllerType.CLASSICAL_SMC, max_retries=3)",
    "lines": 60,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d1802c0"
  },
  {
    "id": "pso_integration_workflows_26_83c1a92b",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 26,
    "code": "def performance_optimized_workflow(controller_types: List[ControllerType],\n                                 parallel_execution: bool = True) -> Dict[str, Any]:\n    \"\"\"Performance-optimized PSO workflow.\"\"\"\n\n    import concurrent.futures\n    import multiprocessing\n\n    def optimize_with_caching(controller_type: ControllerType) -> Tuple[ControllerType, Dict]:\n        \"\"\"Optimize with result caching.\"\"\"\n\n        # Check for cached results\n        cache_key = f\"{controller_type.value}_optimized\"\n\n        # Configure for performance\n        pso_config = PSOFactoryConfig(\n            controller_type=controller_type,\n            population_size=20,        # Balanced size\n            max_iterations=60,         # Reasonable iterations\n            convergence_threshold=1e-5, # Good precision\n            fitness_timeout=10.0,      # Efficient timeout\n            use_robust_evaluation=True\n        )\n\n        pso_factory = EnhancedPSOFactory(pso_config)\n        result = pso_factory.optimize_controller()\n\n        return controller_type, result\n\n    results = {}\n\n    if parallel_execution and len(controller_types) > 1:\n        # Parallel execution\n        max_workers = min(len(controller_types), multiprocessing.cpu_count())\n\n        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n            future_to_type = {\n                executor.submit(optimize_with_caching, ct): ct\n                for ct in controller_types\n            }\n\n            for future in concurrent.futures.as_completed(future_to_type):\n                controller_type, result = future.result()\n                results[controller_type.value] = result\n    else:\n        # Sequential execution\n        for controller_type in controller_types:\n            controller_type_result, result = optimize_with_caching(controller_type)\n            results[controller_type.value] = result\n\n    return results\n\n# Usage\ncontroller_types = [ControllerType.CLASSICAL_SMC, ControllerType.STA_SMC, ControllerType.ADAPTIVE_SMC]\nperformance_results = performance_optimized_workflow(controller_types, parallel_execution=True)",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83c1a92b"
  },
  {
    "id": "pso_integration_workflows_27_9bb7b339",
    "file": "docs\\technical\\pso_integration_workflows.md",
    "index": 27,
    "code": "# example-metadata:\n# runnable: false\n\ndef comprehensive_validation_workflow(optimization_result: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Comprehensive validation workflow for optimized controllers.\"\"\"\n\n    if not optimization_result['success']:\n        return {'validation_status': 'FAILED', 'reason': 'Optimization failed'}\n\n    validation_report = {\n        'validation_status': 'PENDING',\n        'checks_performed': [],\n        'issues_found': [],\n        'recommendations': []\n    }\n\n    # 1. Basic validation checks\n    validation_report['checks_performed'].append('basic_validation')\n    basic_validation = optimization_result['validation_results']\n\n    if not basic_validation['gains_valid']:\n        validation_report['issues_found'].append('Invalid gains detected')\n\n    if not basic_validation['controller_stable']:\n        validation_report['issues_found'].append('Controller stability issues')\n\n    if not basic_validation['performance_acceptable']:\n        validation_report['issues_found'].append('Performance below acceptable threshold')\n\n    # 2. Convergence analysis\n    validation_report['checks_performed'].append('convergence_analysis')\n    performance = optimization_result['performance_analysis']\n\n    if not performance['converged']:\n        validation_report['issues_found'].append('PSO did not converge')\n        validation_report['recommendations'].append('Increase max_iterations or relax convergence_threshold')\n\n    if performance['improvement_ratio'] < 0.1:\n        validation_report['issues_found'].append('Low improvement ratio')\n        validation_report['recommendations'].append('Review optimization bounds or increase population size')\n\n    # 3. Gain analysis\n    validation_report['checks_performed'].append('gain_analysis')\n    gains = optimization_result['best_gains']\n\n    # Check for extreme values\n    if any(g > 100.0 for g in gains):\n        validation_report['issues_found'].append('Extremely high gains detected')\n        validation_report['recommendations'].append('Review optimization bounds')\n\n    if any(g < 0.1 for g in gains):\n        validation_report['issues_found'].append('Very low gains detected')\n        validation_report['recommendations'].append('Check minimum bounds')\n\n    # 4. Cost analysis\n    validation_report['checks_performed'].append('cost_analysis')\n    best_cost = optimization_result['best_cost']\n\n    if best_cost > 100.0:\n        validation_report['issues_found'].append('High optimization cost')\n        validation_report['recommendations'].append('Review controller performance or optimization scenarios')\n\n    # 5. Determine overall status\n    if len(validation_report['issues_found']) == 0:\n        validation_report['validation_status'] = 'PASSED'\n    elif len(validation_report['issues_found']) <= 2:\n        validation_report['validation_status'] = 'WARNING'\n    else:\n        validation_report['validation_status'] = 'FAILED'\n\n    # 6. Generate summary\n    validation_report['summary'] = {\n        'total_checks': len(validation_report['checks_performed']),\n        'issues_count': len(validation_report['issues_found']),\n        'recommendations_count': len(validation_report['recommendations']),\n        'overall_status': validation_report['validation_status']\n    }\n\n    return validation_report\n\n# Usage example\npso_config = PSOFactoryConfig(controller_type=ControllerType.CLASSICAL_SMC)\npso_factory = EnhancedPSOFactory(pso_config)\nresult = pso_factory.optimize_controller()\n\nvalidation_report = comprehensive_validation_workflow(result)\nprint(f\"Validation status: {validation_report['validation_status']}\")\nprint(f\"Issues found: {len(validation_report['issues_found'])}\")\nfor issue in validation_report['issues_found']:\n    print(f\"  - {issue}\")",
    "lines": 90,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bb7b339"
  },
  {
    "id": "benchmarking_framework_technical_guide_1_f3eaac18",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 1,
    "code": "# High-level workflow\nfrom src.benchmarks import run_trials, compute_all_metrics\nfrom src.benchmarks.statistics import compute_t_confidence_intervals\n\n# Execute trials\nmetrics_list, ci_results = run_trials(\n    controller_factory=create_controller,\n    cfg=config,\n    n_trials=30,\n    seed=42\n)\n\n# Confidence intervals automatically computed\nfor metric, (mean, ci_width) in ci_results.items():\n    print(f\"{metric}: {mean:.4f} \u00b1 {ci_width:.4f}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3eaac18"
  },
  {
    "id": "benchmarking_framework_technical_guide_2_69214df7",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# src/benchmarks/metrics/control_metrics.py\n\ndef compute_ise(t: np.ndarray, x: np.ndarray) -> float:\n    \"\"\"Compute Integral of Squared Error (ISE).\n\n    ISE = \u222b\u2080\u1d40 ||x(t)||\u00b2 dt\n\n    Physical Interpretation:\n        Measures cumulative deviation from desired trajectory.\n        Lower values indicate better tracking performance.\n\n    Control Engineering Context:\n        - Quadratic cost function component in optimal control\n        - Related to H\u2082 norm of closed-loop system\n        - Emphasizes large deviations more than small ones\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector, shape (N+1,)\n    x : np.ndarray\n        State trajectories, shape (B, N+1, S) for B batches, S states\n\n    Returns\n    -------\n    float\n        ISE value averaged across batch dimension\n\n    Examples\n    --------\n    >>> t = np.linspace(0, 5, 501)\n    >>> x = np.random.randn(10, 501, 6)  # 10 trials, 6 states\n    >>> ise = compute_ise(t, x)\n    >>> print(f\"ISE: {ise:.4f}\")\n    \"\"\"\n    dt = t[1] - t[0]\n\n    # Handle batched or single trajectory\n    if x.ndim == 3:  # Batched: (B, N, S)\n        squared_errors = np.sum(x**2, axis=2)  # Sum over states\n        ise_per_batch = np.sum(squared_errors, axis=1) * dt\n        return np.mean(ise_per_batch)\n    else:  # Single trajectory: (N, S)\n        squared_errors = np.sum(x**2, axis=1)\n        return np.sum(squared_errors) * dt\n\n\ndef compute_itae(t: np.ndarray, x: np.ndarray) -> float:\n    \"\"\"Compute Integral of Time-weighted Absolute Error (ITAE).\n\n    ITAE = \u222b\u2080\u1d40 t\u00b7||x(t)|| dt\n\n    Emphasizes errors occurring later in the trajectory.\n    Penalizes sustained deviations more heavily than transient errors.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    x : np.ndarray\n        State trajectories\n\n    Returns\n    -------\n    float\n        ITAE value\n\n    Notes\n    -----\n    ITAE is preferred for evaluating settling characteristics because:\n    - Late-stage errors receive higher penalty\n    - Encourages faster settling to equilibrium\n    - Better reflects control quality in stabilization tasks\n    \"\"\"\n    dt = t[1] - t[0]\n\n    if x.ndim == 3:\n        abs_errors = np.linalg.norm(x, axis=2)  # (B, N)\n        time_weighted = abs_errors * t[np.newaxis, :]\n        itae_per_batch = np.sum(time_weighted, axis=1) * dt\n        return np.mean(itae_per_batch)\n    else:\n        abs_errors = np.linalg.norm(x, axis=1)\n        time_weighted = abs_errors * t\n        return np.sum(time_weighted) * dt\n\n\ndef compute_rms_control(t: np.ndarray, u: np.ndarray) -> float:\n    \"\"\"Compute RMS (Root Mean Square) control effort.\n\n    RMS_u = \u221a(1/T \u222b\u2080\u1d40 u(t)\u00b2 dt)\n\n    Measures average control energy consumption.\n    Important for actuator sizing and power requirements.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    u : np.ndarray\n        Control history\n\n    Returns\n    -------\n    float\n        RMS control effort [Force]\n    \"\"\"\n    dt = t[1] - t[0]\n    T = t[-1] - t[0]\n\n    if u.ndim == 2:  # Batched\n        squared_control = u**2\n        integral = np.sum(squared_control, axis=1) * dt\n        rms_per_batch = np.sqrt(integral / T)\n        return np.mean(rms_per_batch)\n    else:\n        squared_control = u**2\n        integral = np.sum(squared_control) * dt\n        return np.sqrt(integral / T)\n\n\ndef compute_control_rate(t: np.ndarray, u: np.ndarray) -> float:\n    \"\"\"Compute RMS control rate (slew rate).\n\n    du_RMS = \u221a(1/T \u222b\u2080\u1d40 (du/dt)\u00b2 dt)\n\n    Measures control signal smoothness.\n    High values indicate chattering or aggressive switching.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    u : np.ndarray\n        Control history\n\n    Returns\n    -------\n    float\n        RMS control rate [Force/time]\n\n    Notes\n    -----\n    Critical for:\n    - Actuator wear and lifetime estimation\n    - Implementation feasibility (discrete-time constraints)\n    - Chattering quantification in sliding mode control\n    \"\"\"\n    dt = t[1] - t[0]\n\n    if u.ndim == 2:\n        du_dt = np.diff(u, axis=1) / dt\n        return compute_rms_control(t[:-1], du_dt)\n    else:\n        du_dt = np.diff(u) / dt\n        return compute_rms_control(t[:-1], du_dt)",
    "lines": 159,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69214df7"
  },
  {
    "id": "benchmarking_framework_technical_guide_3_edc43569",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 3,
    "code": "# src/benchmarks/metrics/stability_metrics.py\n\ndef compute_overshoot(x: np.ndarray, state_indices: List[int] = [1, 2]) -> float:\n    \"\"\"Compute maximum overshoot for angular states.\n\n    Overshoot = max_{t\u2208[0,T]} |\u03b8\u1d62(t)| for i \u2208 {1,2}\n\n    Safety-critical for physical systems.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        State trajectories, shape (B, N, S) or (N, S)\n    state_indices : list of int\n        Indices of angular states (default: [1, 2] for \u03b81, \u03b82)\n\n    Returns\n    -------\n    float\n        Maximum overshoot [radians]\n    \"\"\"\n    if x.ndim == 3:\n        angular_states = x[:, :, state_indices]  # (B, N, 2)\n        max_per_state = np.max(np.abs(angular_states), axis=1)  # (B, 2)\n        max_overshoot = np.max(max_per_state, axis=1)  # (B,)\n        return np.mean(max_overshoot)\n    else:\n        angular_states = x[:, state_indices]\n        return np.max(np.abs(angular_states))\n\n\ndef compute_settling_time(t: np.ndarray, x: np.ndarray,\n                          tolerance: float = 0.02) -> float:\n    \"\"\"Compute settling time to within tolerance of equilibrium.\n\n    Settling time: minimum t where ||x(\u03c4)|| < tolerance \u2200 \u03c4 > t\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    x : np.ndarray\n        State trajectories\n    tolerance : float\n        Settling tolerance (default: 0.02 = 2% of initial error)\n\n    Returns\n    -------\n    float\n        Settling time [seconds], or np.inf if never settles\n    \"\"\"\n    if x.ndim == 3:\n        errors = np.linalg.norm(x, axis=2)  # (B, N)\n        settling_times = []\n\n        for batch_errors in errors:\n            settled_mask = batch_errors < tolerance\n            if np.any(settled_mask):\n                # Find first index where it stays below tolerance\n                for i in range(len(settled_mask)):\n                    if np.all(settled_mask[i:]):\n                        settling_times.append(t[i])\n                        break\n                else:\n                    settling_times.append(np.inf)\n            else:\n                settling_times.append(np.inf)\n\n        return np.mean(settling_times)\n    else:\n        errors = np.linalg.norm(x, axis=1)\n        settled_mask = errors < tolerance\n\n        if np.any(settled_mask):\n            for i in range(len(settled_mask)):\n                if np.all(settled_mask[i:]):\n                    return t[i]\n        return np.inf\n\n\ndef compute_damping_ratio(x: np.ndarray, t: np.ndarray) -> float:\n    \"\"\"Estimate damping ratio from oscillatory response.\n\n    Uses logarithmic decrement method:\n        \u03b6 = ln(x_peak1 / x_peak2) / \u221a(4\u03c0\u00b2 + ln\u00b2(x_peak1 / x_peak2))\n\n    Parameters\n    ----------\n    x : np.ndarray\n        State response (typically angular states)\n    t : np.ndarray\n        Time vector\n\n    Returns\n    -------\n    float\n        Estimated damping ratio (0 = undamped, 1 = critically damped)\n    \"\"\"\n    from scipy.signal import find_peaks\n\n    # Find peaks in response\n    peaks, _ = find_peaks(np.abs(x))\n\n    if len(peaks) < 2:\n        return 1.0  # No oscillation = critically damped or overdamped\n\n    # Use first two peaks for logarithmic decrement\n    x1 = np.abs(x[peaks[0]])\n    x2 = np.abs(x[peaks[1]])\n\n    if x2 == 0:\n        return 1.0\n\n    delta = np.log(x1 / x2)  # Logarithmic decrement\n    zeta = delta / np.sqrt(4 * np.pi**2 + delta**2)\n\n    return min(zeta, 1.0)  # Cap at 1.0",
    "lines": 117,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "edc43569"
  },
  {
    "id": "benchmarking_framework_technical_guide_4_d56fe1fc",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# src/benchmarks/metrics/constraint_metrics.py\n\ndef count_control_violations(u: np.ndarray, max_force: float) -> int:\n    \"\"\"Count control saturation violations.\n\n    Violations = |{t : |u(t)| > u_max}|\n\n    Zero violations required for safe operation.\n\n    Parameters\n    ----------\n    u : np.ndarray\n        Control history\n    max_force : float\n        Maximum allowable control force\n\n    Returns\n    -------\n    int\n        Number of timesteps exceeding limit\n    \"\"\"\n    if u.ndim == 2:\n        violations_per_batch = np.sum(np.abs(u) > max_force, axis=1)\n        return int(np.mean(violations_per_batch))\n    else:\n        return int(np.sum(np.abs(u) > max_force))\n\n\ndef compute_violation_severity(u: np.ndarray, max_force: float) -> float:\n    \"\"\"Compute severity of constraint violations.\n\n    Severity = (1/N) \u03a3 max(0, |u(t)| - u_max)\n\n    Quantifies how far violations exceed limits.\n\n    Parameters\n    ----------\n    u : np.ndarray\n        Control history\n    max_force : float\n        Maximum allowable control force\n\n    Returns\n    -------\n    float\n        Average violation severity [Force]\n    \"\"\"\n    if u.ndim == 2:\n        excess = np.maximum(0, np.abs(u) - max_force)\n        return np.mean(np.mean(excess, axis=1))\n    else:\n        excess = np.maximum(0, np.abs(u) - max_force)\n        return np.mean(excess)",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d56fe1fc"
  },
  {
    "id": "benchmarking_framework_technical_guide_5_4d09dc2c",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 5,
    "code": "# src/benchmarks/metrics/__init__.py\n\nfrom .control_metrics import compute_ise, compute_itae, compute_rms_control, compute_control_rate\nfrom .stability_metrics import compute_overshoot, compute_settling_time, compute_damping_ratio\nfrom .constraint_metrics import count_control_violations, compute_violation_severity\n\n__all__ = [\n    'compute_all_metrics',\n    'compute_basic_metrics',\n    'compute_ise',\n    'compute_itae',\n    'compute_rms_control',\n    'compute_overshoot',\n    'count_control_violations'\n]\n\n\ndef compute_all_metrics(t: np.ndarray, x: np.ndarray, u: np.ndarray,\n                       max_force: float, include_advanced: bool = False) -> dict:\n    \"\"\"Compute all performance metrics for a simulation result.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    x : np.ndarray\n        State trajectories\n    u : np.ndarray\n        Control history\n    max_force : float\n        Maximum control force limit\n    include_advanced : bool\n        Include advanced metrics (settling time, damping ratio)\n\n    Returns\n    -------\n    dict\n        Dictionary of all computed metrics\n\n    Examples\n    --------\n    >>> metrics = compute_all_metrics(t, x, u, max_force=100.0)\n    >>> print(f\"ISE: {metrics['ise']:.4f}\")\n    >>> print(f\"Violations: {metrics['violations']}\")\n    \"\"\"\n    metrics = {\n        'ise': compute_ise(t, x),\n        'itae': compute_itae(t, x),\n        'rms_control': compute_rms_control(t, u),\n        'control_rate': compute_control_rate(t, u),\n        'overshoot': compute_overshoot(x),\n        'violations': count_control_violations(u, max_force),\n        'violation_severity': compute_violation_severity(u, max_force)\n    }\n\n    if include_advanced:\n        metrics['settling_time'] = compute_settling_time(t, x)\n        metrics['damping_ratio'] = compute_damping_ratio(x[:, 1], t)  # \u03b81 response\n\n    return metrics\n\n\ndef compute_basic_metrics(t: np.ndarray, x: np.ndarray, u: np.ndarray) -> dict:\n    \"\"\"Compute basic performance metrics (no max_force required).\n\n    Minimal metric set for quick analysis.\n    \"\"\"\n    return {\n        'ise': compute_ise(t, x),\n        'rms_control': compute_rms_control(t, u),\n        'overshoot': compute_overshoot(x)\n    }",
    "lines": 72,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d09dc2c"
  },
  {
    "id": "benchmarking_framework_technical_guide_6_fb6100b8",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# src/benchmarks/core/trial_runner.py\n\ndef run_multiple_trials(controller_factory: Callable,\n                       cfg: Any,\n                       n_trials: int = 30,\n                       seed: Optional[int] = None,\n                       progress_callback: Optional[Callable] = None) -> List[dict]:\n    \"\"\"Execute multiple simulation trials with different random seeds.\n\n    Implements Central Limit Theorem requirements (n \u2265 30) for statistical validity.\n\n    Parameters\n    ----------\n    controller_factory : callable\n        Function that returns a fresh controller instance\n    cfg : object\n        Configuration object with simulation parameters\n    n_trials : int\n        Number of trials (default: 30 for CLT compliance)\n    seed : int, optional\n        Base random seed for reproducibility\n    progress_callback : callable, optional\n        Callback function(current, total) for progress tracking\n\n    Returns\n    -------\n    list of dict\n        List of metric dictionaries, one per trial\n\n    Examples\n    --------\n    >>> def create_controller():\n    ...     return ClassicalSMC(gains=[10, 8, 15, 12, 50, 5], max_force=100)\n    ...\n    >>> metrics_list = run_multiple_trials(\n    ...     create_controller, config, n_trials=30, seed=42,\n    ...     progress_callback=lambda i, n: print(f\"Trial {i}/{n}\")\n    ... )\n    >>> ise_values = [m['ise'] for m in metrics_list]\n    >>> mean_ise = np.mean(ise_values)\n    \"\"\"\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    else:\n        rng = np.random.default_rng()\n\n    # Generate independent seeds for each trial\n    trial_seeds = rng.integers(0, 2**31-1, size=n_trials)\n\n    metrics_list = []\n\n    for i, trial_seed in enumerate(trial_seeds):\n        # Set seed for this trial\n        np.random.seed(trial_seed)\n\n        # Create fresh controller\n        controller = controller_factory()\n\n        # Run simulation\n        from src.core.simulation_runner import run_simulation\n        result = run_simulation(\n            controller=controller,\n            duration=cfg.simulation.duration,\n            dt=cfg.simulation.dt,\n            initial_state=cfg.simulation.initial_state\n        )\n\n        # Compute metrics\n        from src.benchmarks.metrics import compute_all_metrics\n        metrics = compute_all_metrics(\n            result['time'],\n            np.array(result['states']),\n            np.array(result['controls']),\n            max_force=cfg.controllers.max_force\n        )\n\n        metrics_list.append(metrics)\n\n        # Progress callback\n        if progress_callback:\n            progress_callback(i + 1, n_trials)\n\n    return metrics_list",
    "lines": 86,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb6100b8"
  },
  {
    "id": "benchmarking_framework_technical_guide_7_2e1ed949",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# src/benchmarks/statistics/confidence_intervals.py\n\ndef compute_t_confidence_intervals(metrics_list: List[dict],\n                                  confidence_level: float = 0.95) -> dict:\n    \"\"\"Compute t-distribution confidence intervals for all metrics.\n\n    Uses Student's t-distribution for small sample sizes (n < 100).\n\n    Parameters\n    ----------\n    metrics_list : list of dict\n        Metrics from multiple trials\n    confidence_level : float\n        Confidence level (default: 0.95 for 95% CI)\n\n    Returns\n    -------\n    dict\n        For each metric: {'mean': float, 'ci_width': float, 'ci_lower': float, 'ci_upper': float}\n\n    Examples\n    --------\n    >>> ci_results = compute_t_confidence_intervals(metrics_list)\n    >>> ise_mean = ci_results['ise']['mean']\n    >>> ise_ci = ci_results['ise']['ci_width']\n    >>> print(f\"ISE: {ise_mean:.4f} \u00b1 {ise_ci:.4f}\")\n    \"\"\"\n    from scipy import stats\n\n    # Extract metric names\n    metric_names = list(metrics_list[0].keys())\n\n    ci_results = {}\n\n    for metric in metric_names:\n        values = np.array([m[metric] for m in metrics_list])\n\n        n = len(values)\n        mean = np.mean(values)\n        std = np.std(values, ddof=1)  # Bessel's correction\n        sem = std / np.sqrt(n)  # Standard error of mean\n\n        # t-critical value\n        alpha = 1 - confidence_level\n        t_crit = stats.t.ppf(1 - alpha/2, df=n-1)\n\n        ci_width = t_crit * sem\n        ci_lower = mean - ci_width\n        ci_upper = mean + ci_width\n\n        ci_results[metric] = {\n            'mean': float(mean),\n            'std': float(std),\n            'ci_width': float(ci_width),\n            'ci_lower': float(ci_lower),\n            'ci_upper': float(ci_upper),\n            'n': n\n        }\n\n    return ci_results\n\n\ndef compute_bootstrap_confidence_intervals(metrics_list: List[dict],\n                                          confidence_level: float = 0.95,\n                                          n_bootstrap: int = 10000) -> dict:\n    \"\"\"Compute bootstrap confidence intervals (non-parametric).\n\n    Useful when metric distributions are non-normal.\n\n    Parameters\n    ----------\n    metrics_list : list of dict\n        Metrics from multiple trials\n    confidence_level : float\n        Confidence level\n    n_bootstrap : int\n        Number of bootstrap samples\n\n    Returns\n    -------\n    dict\n        Bootstrap CI results for each metric\n    \"\"\"\n    metric_names = list(metrics_list[0].keys())\n    ci_results = {}\n\n    for metric in metric_names:\n        values = np.array([m[metric] for m in metrics_list])\n\n        # Bootstrap resampling\n        bootstrap_means = []\n        for _ in range(n_bootstrap):\n            resample = np.random.choice(values, size=len(values), replace=True)\n            bootstrap_means.append(np.mean(resample))\n\n        bootstrap_means = np.array(bootstrap_means)\n\n        # Percentile method\n        alpha = 1 - confidence_level\n        ci_lower = np.percentile(bootstrap_means, 100 * alpha/2)\n        ci_upper = np.percentile(bootstrap_means, 100 * (1 - alpha/2))\n        mean = np.mean(values)\n        ci_width = (ci_upper - ci_lower) / 2\n\n        ci_results[metric] = {\n            'mean': float(mean),\n            'ci_width': float(ci_width),\n            'ci_lower': float(ci_lower),\n            'ci_upper': float(ci_upper),\n            'method': 'bootstrap'\n        }\n\n    return ci_results\n\n\ndef compare_controllers(metrics_a: List[dict], metrics_b: List[dict],\n                       metric_name: str = 'ise',\n                       alpha: float = 0.05) -> dict:\n    \"\"\"Compare two controllers using Welch's t-test.\n\n    Welch's t-test handles unequal variances between groups.\n\n    Parameters\n    ----------\n    metrics_a : list of dict\n        Metrics from controller A\n    metrics_b : list of dict\n        Metrics from controller B\n    metric_name : str\n        Metric to compare (e.g., 'ise')\n    alpha : float\n        Significance level (default: 0.05)\n\n    Returns\n    -------\n    dict\n        Test results: {\n            't_statistic': float,\n            'p_value': float,\n            'significant': bool,\n            'mean_a': float,\n            'mean_b': float,\n            'better_controller': str\n        }\n\n    Examples\n    --------\n    >>> comparison = compare_controllers(classical_metrics, adaptive_metrics, 'ise')\n    >>> if comparison['significant']:\n    ...     print(f\"{comparison['better_controller']} is significantly better (p={comparison['p_value']:.4f})\")\n    \"\"\"\n    from scipy import stats\n\n    values_a = np.array([m[metric_name] for m in metrics_a])\n    values_b = np.array([m[metric_name] for m in metrics_b])\n\n    # Welch's t-test (unequal variances)\n    t_stat, p_value = stats.ttest_ind(values_a, values_b, equal_var=False)\n\n    mean_a = np.mean(values_a)\n    mean_b = np.mean(values_b)\n\n    significant = p_value < alpha\n    better_controller = 'A' if mean_a < mean_b else 'B'\n\n    return {\n        't_statistic': float(t_stat),\n        'p_value': float(p_value),\n        'significant': bool(significant),\n        'mean_a': float(mean_a),\n        'mean_b': float(mean_b),\n        'better_controller': better_controller,\n        'effect_size': float(abs(mean_a - mean_b) / np.sqrt((np.var(values_a) + np.var(values_b)) / 2))\n    }",
    "lines": 177,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e1ed949"
  },
  {
    "id": "benchmarking_framework_technical_guide_8_cae40c90",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# src/benchmarks/statistical_benchmarks_v2.py\n\ndef run_trials(controller_factory: Callable,\n              cfg: Any,\n              n_trials: int = 30,\n              seed: Optional[int] = None,\n              randomise_physics: bool = False,\n              noise_std: float = 0.0) -> Tuple[List[dict], dict]:\n    \"\"\"Run statistical benchmark trials with confidence interval computation.\n\n    Backward-compatible interface with enhanced capabilities.\n\n    Parameters\n    ----------\n    controller_factory : callable\n        Function returning fresh controller instance\n    cfg : object\n        Configuration object\n    n_trials : int\n        Number of trials (\u226530 for CLT)\n    seed : int, optional\n        Random seed for reproducibility\n    randomise_physics : bool\n        Add physics parameter uncertainty\n    noise_std : float\n        Sensor noise standard deviation\n\n    Returns\n    -------\n    metrics_list : list of dict\n        Raw metrics from all trials\n    ci_results : dict\n        Confidence interval results for each metric\n\n    Examples\n    --------\n    >>> metrics_list, ci_results = run_trials(\n    ...     controller_factory=lambda: ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100),\n    ...     cfg=config,\n    ...     n_trials=30,\n    ...     seed=42\n    ... )\n    >>> for metric, stats in ci_results.items():\n    ...     print(f\"{metric}: {stats['mean']:.4f} \u00b1 {stats['ci_width']:.4f}\")\n    \"\"\"\n    from .core import run_multiple_trials\n    from .statistics import compute_t_confidence_intervals\n\n    # Execute trials\n    metrics_list = run_multiple_trials(\n        controller_factory,\n        cfg,\n        n_trials=n_trials,\n        seed=seed\n    )\n\n    # Compute confidence intervals\n    ci_results = compute_t_confidence_intervals(metrics_list)\n\n    return metrics_list, ci_results\n\n\ndef run_trials_with_advanced_statistics(controller_factory: Callable,\n                                        cfg: Any,\n                                        n_trials: int = 30,\n                                        confidence_level: float = 0.95,\n                                        use_bootstrap: bool = False,\n                                        **kwargs) -> Tuple[List[dict], dict]:\n    \"\"\"Run trials with advanced statistical analysis.\n\n    Enhanced version with non-parametric options.\n\n    Parameters\n    ----------\n    use_bootstrap : bool\n        Use bootstrap CI instead of t-distribution\n\n    Returns\n    -------\n    metrics_list : list of dict\n    analysis : dict\n        Extended analysis including distribution tests\n    \"\"\"\n    from .core import run_multiple_trials\n    from .statistics import (\n        compute_t_confidence_intervals,\n        compute_bootstrap_confidence_intervals\n    )\n\n    metrics_list = run_multiple_trials(controller_factory, cfg, n_trials, **kwargs)\n\n    if use_bootstrap:\n        ci_results = compute_bootstrap_confidence_intervals(metrics_list, confidence_level)\n    else:\n        ci_results = compute_t_confidence_intervals(metrics_list, confidence_level)\n\n    return metrics_list, ci_results\n\n\ndef compare_controllers(controller_a_factory: Callable,\n                       controller_b_factory: Callable,\n                       cfg: Any,\n                       n_trials: int = 30,\n                       metric: str = 'ise') -> dict:\n    \"\"\"Compare two controllers statistically.\n\n    Parameters\n    ----------\n    controller_a_factory : callable\n    controller_b_factory : callable\n    cfg : object\n    n_trials : int\n    metric : str\n        Metric for comparison\n\n    Returns\n    -------\n    dict\n        Comparison results with statistical significance\n    \"\"\"\n    from .core import run_multiple_trials\n    from .statistics import compare_controllers as compare_fn\n\n    metrics_a = run_multiple_trials(controller_a_factory, cfg, n_trials)\n    metrics_b = run_multiple_trials(controller_b_factory, cfg, n_trials)\n\n    return compare_fn(metrics_a, metrics_b, metric)",
    "lines": 130,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cae40c90"
  },
  {
    "id": "benchmarking_framework_technical_guide_9_3c4bdf2a",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 9,
    "code": "# benchmarks/integration/numerical_methods.py\n\nclass EulerIntegrator:\n    \"\"\"Forward Euler integration method.\n\n    First-order accurate: O(h)\n    \"\"\"\n\n    def __init__(self, dynamics):\n        self.dynamics = dynamics\n\n    def integrate(self, x0: np.ndarray, t_span: tuple, dt: float,\n                 controller: Optional[Any] = None) -> dict:\n        \"\"\"Integrate dynamics using Forward Euler.\n\n        Parameters\n        ----------\n        x0 : np.ndarray\n            Initial state\n        t_span : tuple\n            (t_start, t_end)\n        dt : float\n            Time step\n        controller : object, optional\n            Controller for closed-loop simulation\n\n        Returns\n        -------\n        dict\n            {\n                't': time vector,\n                'x': state history,\n                'u': control history (if controller provided)\n            }\n        \"\"\"\n        t_start, t_end = t_span\n        t = np.arange(t_start, t_end + dt, dt)\n        n_steps = len(t)\n\n        x = np.zeros((n_steps, len(x0)))\n        x[0] = x0\n\n        if controller:\n            u = np.zeros(n_steps - 1)\n\n        for i in range(n_steps - 1):\n            if controller:\n                result = controller.compute_control(x[i], {}, {})\n                u[i] = result.get('control_output', result.get('control', 0.0))\n                x_dot = self.dynamics.dynamics(x[i], u[i])\n            else:\n                x_dot = self.dynamics.dynamics(x[i], 0.0)\n\n            x[i+1] = x[i] + dt * x_dot\n\n        result = {'t': t, 'x': x}\n        if controller:\n            result['u'] = u\n\n        return result\n\n\nclass RK4Integrator:\n    \"\"\"Fourth-order Runge-Kutta integration.\n\n    Fourth-order accurate: O(h\u2074)\n    \"\"\"\n\n    def __init__(self, dynamics):\n        self.dynamics = dynamics\n\n    def integrate(self, x0: np.ndarray, t_span: tuple, dt: float,\n                 controller: Optional[Any] = None) -> dict:\n        \"\"\"Integrate using RK4 method.\"\"\"\n        t_start, t_end = t_span\n        t = np.arange(t_start, t_end + dt, dt)\n        n_steps = len(t)\n\n        x = np.zeros((n_steps, len(x0)))\n        x[0] = x0\n\n        if controller:\n            u = np.zeros(n_steps - 1)\n\n        for i in range(n_steps - 1):\n            if controller:\n                result = controller.compute_control(x[i], {}, {})\n                u[i] = result.get('control_output', result.get('control', 0.0))\n                u_current = u[i]\n            else:\n                u_current = 0.0\n\n            # RK4 stages\n            k1 = self.dynamics.dynamics(x[i], u_current)\n            k2 = self.dynamics.dynamics(x[i] + 0.5*dt*k1, u_current)\n            k3 = self.dynamics.dynamics(x[i] + 0.5*dt*k2, u_current)\n            k4 = self.dynamics.dynamics(x[i] + dt*k3, u_current)\n\n            x[i+1] = x[i] + (dt/6) * (k1 + 2*k2 + 2*k3 + k4)\n\n        result = {'t': t, 'x': x}\n        if controller:\n            result['u'] = u\n\n        return result\n\n\nclass AdaptiveRK45Integrator:\n    \"\"\"Adaptive Runge-Kutta 4-5 method (Dormand-Prince).\n\n    Variable step size for error control.\n    \"\"\"\n\n    def __init__(self, dynamics):\n        self.dynamics = dynamics\n\n    def integrate(self, x0: np.ndarray, t_span: tuple,\n                 rtol: float = 1e-6, atol: float = 1e-9,\n                 controller: Optional[Any] = None) -> dict:\n        \"\"\"Integrate using adaptive RK45.\"\"\"\n        from scipy.integrate import solve_ivp\n\n        if controller:\n            def dynamics_func(t, x):\n                result = controller.compute_control(x, {}, {})\n                u = result.get('control_output', result.get('control', 0.0))\n                return self.dynamics.dynamics(x, u)\n        else:\n            def dynamics_func(t, x):\n                return self.dynamics.dynamics(x, 0.0)\n\n        sol = solve_ivp(\n            dynamics_func,\n            t_span,\n            x0,\n            method='RK45',\n            rtol=rtol,\n            atol=atol\n        )\n\n        return {\n            't': sol.t,\n            'x': sol.y.T\n        }",
    "lines": 144,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c4bdf2a"
  },
  {
    "id": "benchmarking_framework_technical_guide_10_0520364e",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# benchmarks/analysis/accuracy_metrics.py\n\ndef compute_energy_conservation(t: np.ndarray, x: np.ndarray,\n                               physics_params: dict) -> dict:\n    \"\"\"Analyze energy conservation for Hamiltonian systems.\n\n    Parameters\n    ----------\n    t : np.ndarray\n        Time vector\n    x : np.ndarray\n        State trajectories\n    physics_params : dict\n        Physics parameters\n\n    Returns\n    -------\n    dict\n        {\n            'initial_energy': float,\n            'final_energy': float,\n            'max_drift': float,\n            'relative_drift': float\n        }\n    \"\"\"\n    def compute_energy(state):\n        # Kinetic energy\n        x_dot, theta1_dot, theta2_dot = state[3], state[4], state[5]\n        KE = 0.5 * physics_params['M'] * x_dot**2  # Cart\n        # ... (pendulum kinetic energy)\n\n        # Potential energy\n        theta1, theta2 = state[1], state[2]\n        PE = physics_params['m1'] * physics_params['g'] * physics_params['L1'] * (1 - np.cos(theta1))\n        # ... (second pendulum PE)\n\n        return KE + PE\n\n    energies = np.array([compute_energy(state) for state in x])\n\n    initial_energy = energies[0]\n    final_energy = energies[-1]\n    max_drift = np.max(np.abs(energies - initial_energy))\n    relative_drift = max_drift / initial_energy if initial_energy != 0 else np.inf\n\n    return {\n        'initial_energy': float(initial_energy),\n        'final_energy': float(final_energy),\n        'max_drift': float(max_drift),\n        'relative_drift': float(relative_drift),\n        'energies': energies\n    }\n\n\ndef estimate_convergence_order(integrator, x0: np.ndarray, t_span: tuple,\n                              dt_values: List[float]) -> dict:\n    \"\"\"Estimate numerical convergence order.\n\n    Uses Richardson extrapolation to estimate p in:\n        e_h = C\u00b7h^p\n\n    Parameters\n    ----------\n    integrator : object\n        Integration method instance\n    x0 : np.ndarray\n        Initial state\n    t_span : tuple\n        Time span\n    dt_values : list of float\n        Decreasing time steps for convergence analysis\n\n    Returns\n    -------\n    dict\n        {\n            'convergence_order': float,\n            'errors': list of float,\n            'dt_values': list of float\n        }\n    \"\"\"\n    # Get reference solution (finest dt)\n    ref_dt = min(dt_values) / 4\n    ref_result = integrator.integrate(x0, t_span, ref_dt)\n    ref_x_final = ref_result['x'][-1]\n\n    errors = []\n    for dt in dt_values:\n        result = integrator.integrate(x0, t_span, dt)\n        x_final = result['x'][-1]\n        error = np.linalg.norm(x_final - ref_x_final)\n        errors.append(error)\n\n    # Estimate convergence order: p = log(e_h1/e_h2) / log(h1/h2)\n    orders = []\n    for i in range(len(errors) - 1):\n        if errors[i+1] > 0:\n            order = np.log(errors[i] / errors[i+1]) / np.log(dt_values[i] / dt_values[i+1])\n            orders.append(order)\n\n    avg_order = np.mean(orders) if orders else np.nan\n\n    return {\n        'convergence_order': float(avg_order),\n        'errors': [float(e) for e in errors],\n        'dt_values': dt_values\n    }",
    "lines": 110,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0520364e"
  },
  {
    "id": "benchmarking_framework_technical_guide_11_5aa193e9",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 11,
    "code": "# benchmarks/comparison/method_comparison.py\n\nclass IntegrationMethodComparator:\n    \"\"\"Systematic comparison of integration methods.\"\"\"\n\n    def __init__(self, dynamics, physics_params: dict):\n        self.dynamics = dynamics\n        self.physics_params = physics_params\n\n    def compare_methods(self, methods: List[str], x0: np.ndarray,\n                       t_span: tuple, dt_values: List[float]) -> dict:\n        \"\"\"Compare multiple integration methods.\n\n        Parameters\n        ----------\n        methods : list of str\n            Method names: ['Euler', 'RK4', 'RK45']\n        x0 : np.ndarray\n            Initial state\n        t_span : tuple\n            Time span\n        dt_values : list of float\n            Time steps to test\n\n        Returns\n        -------\n        dict\n            Comparison results for all methods\n        \"\"\"\n        from benchmarks.integration import EulerIntegrator, RK4Integrator, AdaptiveRK45Integrator\n        from benchmarks.analysis import compute_energy_conservation, estimate_convergence_order\n\n        integrators = {\n            'Euler': EulerIntegrator(self.dynamics),\n            'RK4': RK4Integrator(self.dynamics),\n            'RK45': AdaptiveRK45Integrator(self.dynamics)\n        }\n\n        results = {}\n\n        for method_name in methods:\n            integrator = integrators[method_name]\n\n            # Convergence analysis\n            convergence = estimate_convergence_order(integrator, x0, t_span, dt_values)\n\n            # Energy conservation (for frictionless system)\n            result = integrator.integrate(x0, t_span, dt=min(dt_values))\n            energy_analysis = compute_energy_conservation(\n                result['t'], result['x'], self.physics_params\n            )\n\n            # Performance measurement\n            import time\n            start = time.time()\n            _ = integrator.integrate(x0, t_span, dt=min(dt_values))\n            elapsed = time.time() - start\n\n            results[method_name] = {\n                'convergence_order': convergence['convergence_order'],\n                'energy_drift': energy_analysis['relative_drift'],\n                'computation_time': elapsed,\n                'errors': convergence['errors']\n            }\n\n        return results",
    "lines": 66,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5aa193e9"
  },
  {
    "id": "benchmarking_framework_technical_guide_12_f63fa329",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 12,
    "code": "# tests/test_benchmarks/performance/test_controller_benchmarks.py\n\nimport pytest\nfrom src.controllers.smc.classic_smc import ClassicalSMC\n\nclass TestControllerPerformance:\n    \"\"\"Performance benchmarks for controller computations.\"\"\"\n\n    @pytest.mark.benchmark(group=\"control_computation\")\n    def test_classical_smc_performance(self, benchmark):\n        \"\"\"Benchmark classical SMC control computation speed.\"\"\"\n        controller = ClassicalSMC(\n            gains=[10, 8, 15, 12, 50, 5],\n            max_force=100,\n            boundary_layer=0.01\n        )\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        result = benchmark(controller.compute_control, state, {}, {})\n\n        # Performance criteria\n        stats = benchmark.stats\n        assert stats['mean'] < 1e-3  # <1ms average\n\n    @pytest.mark.benchmark(group=\"simulation\")\n    def test_full_simulation_performance(self, benchmark):\n        \"\"\"Benchmark end-to-end simulation performance.\"\"\"\n        from src.core.simulation_runner import run_simulation\n\n        controller = ClassicalSMC(\n            gains=[10, 8, 15, 12, 50, 5],\n            max_force=100,\n            boundary_layer=0.01\n        )\n\n        def simulate():\n            return run_simulation(\n                controller=controller,\n                duration=1.0,\n                dt=0.01,\n                initial_state=[0.1, 0.1, 0, 0, 0, 0]\n            )\n\n        result = benchmark(simulate)\n\n        # Throughput criteria (100 steps in <100ms)\n        assert benchmark.stats['mean'] < 0.1",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f63fa329"
  },
  {
    "id": "benchmarking_framework_technical_guide_13_0003d32a",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 13,
    "code": "# Example 1: Basic controller benchmarking\nfrom src.benchmarks import run_trials\nfrom src.controllers.smc.classic_smc import ClassicalSMC\n\nmetrics_list, ci_results = run_trials(\n    controller_factory=lambda: ClassicalSMC(\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100,\n        boundary_layer=0.01\n    ),\n    cfg=config,\n    n_trials=30,\n    seed=42\n)\n\nfor metric, stats in ci_results.items():\n    print(f\"{metric}: {stats['mean']:.4f} \u00b1 {stats['ci_width']:.4f}\")\n\n# Example 2: Controller comparison\nfrom src.benchmarks import compare_controllers\n\ncomparison = compare_controllers(\n    controller_a_factory=lambda: ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100),\n    controller_b_factory=lambda: AdaptiveSMC(gains=[10,8,15,12,0.5], max_force=100),\n    cfg=config,\n    n_trials=30,\n    metric='ise'\n)\n\nif comparison['significant']:\n    print(f\"Controller {comparison['better_controller']} is significantly better (p={comparison['p_value']:.4f})\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0003d32a"
  },
  {
    "id": "benchmarking_framework_technical_guide_14_ffdeb0fa",
    "file": "docs\\testing\\benchmarking_framework_technical_guide.md",
    "index": 14,
    "code": "# Example 1: Method comparison\nfrom benchmarks import IntegrationBenchmark\n\nbenchmark = IntegrationBenchmark()\nresults = benchmark.comprehensive_comparison()\n\nfor method, metrics in results.items():\n    print(f\"{method}:\")\n    print(f\"  Convergence order: {metrics['convergence_order']:.2f}\")\n    print(f\"  Energy drift: {metrics['energy_drift']:.2e}\")\n    print(f\"  Computation time: {metrics['computation_time']:.3f}s\")\n\n# Example 2: Energy conservation validation\nconservation = benchmark.validate_conservation_laws()\nprint(f\"Max energy drift: {conservation['max_drift']:.2e}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ffdeb0fa"
  },
  {
    "id": "testing_framework_technical_guide_1_9c71bdee",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 1,
    "code": "# tests/test_controllers/smc/algorithms/classical/test_classical_smc.py\nimport pytest\nimport numpy as np\nfrom src.controllers.smc.classic_smc import ClassicalSMC\n\nclass TestClassicalSMC:\n    \"\"\"Unit tests for Classical Sliding Mode Controller.\"\"\"\n\n    def test_initialization_valid_parameters(self):\n        \"\"\"Test controller initialization with valid parameters.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(\n            gains=gains,\n            max_force=100.0,\n            boundary_layer=0.01,\n            dt=0.01\n        )\n\n        assert controller.k1 == 10.0\n        assert controller.k2 == 8.0\n        assert controller.lam1 == 15.0\n        assert controller.lam2 == 12.0\n        assert controller.K == 50.0\n        assert controller.kd == 5.0\n        assert controller.max_force == 100.0\n        assert controller.boundary_layer == 0.01\n\n    def test_compute_control_valid_output(self):\n        \"\"\"Test that compute_control returns finite, bounded output.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n        result = controller.compute_control(state, {}, {})\n\n        control = result.get('control_output', result.get('control', result.get('u')))\n        assert control is not None\n        assert np.all(np.isfinite(control))\n        assert np.all(np.abs(control) <= 100.0)  # Within saturation\n\n    def test_gain_validation(self):\n        \"\"\"Test that invalid gains are rejected.\"\"\"\n        # Negative gain should raise ValueError\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, -8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0,\n                boundary_layer=0.01\n            )\n\n        # Zero gain should raise ValueError\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[0.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0,\n                boundary_layer=0.01\n            )",
    "lines": 57,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c71bdee"
  },
  {
    "id": "testing_framework_technical_guide_2_d9626283",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 2,
    "code": "# tests/integration/test_pso_controller_integration.py\nimport pytest\nfrom src.controllers.factory import SMCFactory, SMCType\nfrom src.optimizer.pso_optimizer import PSOTuner\n\nclass TestPSOControllerIntegration:\n    \"\"\"Integration tests for PSO optimization of SMC controllers.\"\"\"\n\n    def test_pso_optimization_classical_smc(self):\n        \"\"\"Test full PSO optimization pipeline for classical SMC.\"\"\"\n        # Setup\n        bounds = [(0.1, 50.0)] * 4 + [(1.0, 200.0), (0.0, 50.0)]\n        tuner = PSOTuner(\n            controller_type='classical_smc',\n            bounds=bounds,\n            n_particles=10,\n            iters=5  # Quick test\n        )\n\n        # Execute optimization\n        best_gains, best_cost = tuner.optimize()\n\n        # Validate results\n        assert len(best_gains) == 6\n        assert all(0.1 <= g <= 200.0 for g in best_gains)\n        assert best_cost < float('inf')\n        assert not np.isnan(best_cost)\n\n    def test_optimized_controller_performance(self):\n        \"\"\"Test that PSO-optimized controller stabilizes system.\"\"\"\n        # Load PSO-optimized gains\n        optimized_gains = [12.3, 9.1, 18.7, 14.2, 65.3, 7.8]\n\n        controller = SMCFactory.create_controller(\n            SMCType.CLASSICAL,\n            gains=optimized_gains,\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        # Simulate\n        from src.core.simulation_runner import run_simulation\n        result = run_simulation(\n            controller=controller,\n            duration=5.0,\n            dt=0.01,\n            initial_state=[0.1, 0.1, 0.0, 0.0, 0.0, 0.0]\n        )\n\n        # Performance criteria\n        final_state = result['states'][-1]\n        assert np.linalg.norm(final_state) < 0.01  # Stabilized to equilibrium",
    "lines": 52,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9626283"
  },
  {
    "id": "testing_framework_technical_guide_3_0fae65eb",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 3,
    "code": "# tests/test_controllers/smc/test_property_based_smc.py\nfrom hypothesis import given, strategies as st\nimport numpy as np\n\nclass TestSlidingSurfaceProperties:\n    \"\"\"Property-based tests for sliding surface mathematics.\"\"\"\n\n    @given(\n        k1=st.floats(min_value=0.1, max_value=50.0),\n        k2=st.floats(min_value=0.1, max_value=50.0),\n        lam1=st.floats(min_value=0.1, max_value=50.0),\n        lam2=st.floats(min_value=0.1, max_value=50.0)\n    )\n    def test_sliding_surface_linearity(self, k1, k2, lam1, lam2):\n        \"\"\"Test linearity property: s(x1 + x2) = s(x1) + s(x2).\"\"\"\n        gains = [k1, k2, lam1, lam2]\n        surface = LinearSlidingSurface(gains)\n\n        x1 = np.random.uniform(-1, 1, size=6)\n        x2 = np.random.uniform(-1, 1, size=6)\n\n        s1 = surface.compute(x1)\n        s2 = surface.compute(x2)\n        s_combined = surface.compute(x1 + x2)\n\n        # Linearity property within numerical precision\n        assert abs(s_combined - (s1 + s2)) < 1e-10\n\n    @given(\n        state=st.lists(\n            st.floats(min_value=-10.0, max_value=10.0),\n            min_size=6,\n            max_size=6\n        )\n    )\n    def test_controller_output_bounded(self, state):\n        \"\"\"Test that controller output is always bounded for finite input.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        state_array = np.array(state)\n\n        if np.all(np.isfinite(state_array)):\n            result = controller.compute_control(state_array, {}, {})\n            control = result.get('control_output', result.get('control'))\n\n            if control is not None:\n                # Control must be finite and within saturation limits\n                assert np.all(np.isfinite(control))\n                assert np.all(np.abs(control) <= 100.0)",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fae65eb"
  },
  {
    "id": "testing_framework_technical_guide_4_f1a969d0",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 4,
    "code": "# tests/test_benchmarks/performance/test_performance_benchmarks_deep.py\nimport pytest\n\nclass TestControllerPerformanceBenchmarks:\n    \"\"\"Performance benchmarks for controller computations.\"\"\"\n\n    @pytest.mark.benchmark\n    def test_classical_smc_compute_speed(self, benchmark):\n        \"\"\"Benchmark classical SMC control computation.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        result = benchmark(controller.compute_control, state, {}, {})\n\n        # Performance criteria\n        assert benchmark.stats['mean'] < 1e-4  # < 0.1 ms per control step\n        assert benchmark.stats['stddev'] < 1e-5  # Low variance\n\n    @pytest.mark.benchmark\n    def test_simulation_throughput(self, benchmark):\n        \"\"\"Benchmark end-to-end simulation throughput.\"\"\"\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        def run_short_simulation():\n            return run_simulation(\n                controller=controller,\n                duration=1.0,\n                dt=0.01,\n                initial_state=[0.1, 0.1, 0.0, 0.0, 0.0, 0.0]\n            )\n\n        result = benchmark(run_short_simulation)\n\n        # Throughput criteria (100 timesteps in <100ms)\n        assert benchmark.stats['mean'] < 0.1",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f1a969d0"
  },
  {
    "id": "testing_framework_technical_guide_5_2c1940a1",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# .coveragerc configuration\n[run]\nsource = src\nomit =\n    */tests/*\n    */conftest.py\n    */__init__.py\n\n[report]\nprecision = 2\nshow_missing = True\nskip_covered = False\n\n[html]\ndirectory = coverage_html_report\n\n[term]\nmissing = True\nskip_covered = False",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c1940a1"
  },
  {
    "id": "testing_framework_technical_guide_6_46143e4d",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 6,
    "code": "# tests/conftest.py\nfrom hypothesis import settings, Verbosity\n\n# CI profile: fast, deterministic\nsettings.register_profile(\"ci\", max_examples=50, deadline=500, verbosity=Verbosity.verbose)\n\n# Development profile: moderate testing\nsettings.register_profile(\"dev\", max_examples=100, deadline=1000)\n\n# Thorough profile: comprehensive property testing\nsettings.register_profile(\"thorough\", max_examples=1000, deadline=5000)\n\n# Load profile from environment or default to CI\nsettings.load_profile(os.getenv(\"HYPOTHESIS_PROFILE\", \"ci\"))",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "46143e4d"
  },
  {
    "id": "testing_framework_technical_guide_7_9dad6075",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 7,
    "code": "# tests/conftest.py\nimport pytest\nimport numpy as np\nfrom pathlib import Path\nfrom types import SimpleNamespace\n\n@pytest.fixture(scope=\"session\")\ndef config():\n    \"\"\"Load configuration from config.yaml for tests.\n\n    Provides session-scoped configuration to avoid repeated file I/O.\n    Backfills controller_defaults gains for core controllers.\n    \"\"\"\n    import yaml\n\n    raw = yaml.safe_load(Path(\"config.yaml\").read_text(encoding=\"utf-8\")) or {}\n\n    def _to_ns(obj):\n        \"\"\"Convert dict to SimpleNamespace for attribute access.\"\"\"\n        if isinstance(obj, dict):\n            return SimpleNamespace(**{k: _to_ns(v) for k, v in obj.items()})\n        return obj\n\n    cfg = _to_ns(raw)\n\n    # Backfill controller_defaults if missing\n    if not hasattr(cfg, \"controller_defaults\"):\n        cfg.controller_defaults = SimpleNamespace()\n\n    # Ensure all core controllers have default gains\n    defaults = {\n        \"classical_smc\": [10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n        \"adaptive_smc\": [10.0, 8.0, 15.0, 12.0, 0.5],\n        \"sta_smc\": [25.0, 10.0, 15.0, 12.0, 20.0, 15.0],\n        \"hybrid_adaptive_sta_smc\": [15.0, 12.0, 18.0, 15.0]\n    }\n\n    for ctrl_name, default_gains in defaults.items():\n        if not hasattr(cfg.controller_defaults, ctrl_name):\n            setattr(cfg.controller_defaults, ctrl_name, SimpleNamespace(gains=default_gains))\n\n    return cfg\n\n@pytest.fixture(scope=\"session\")\ndef physics_cfg(config):\n    \"\"\"Physics parameters from configuration.\"\"\"\n    return config.physics\n\n@pytest.fixture(scope=\"session\")\ndef dynamics_simplified(physics_cfg):\n    \"\"\"Session-scoped simplified dynamics model.\"\"\"\n    from src.core.dynamics import SimplifiedDynamics\n    return SimplifiedDynamics(physics_cfg)\n\n@pytest.fixture(scope=\"session\")\ndef dynamics_full(physics_cfg):\n    \"\"\"Session-scoped full nonlinear dynamics model.\"\"\"\n    from src.core.dynamics_full import FullNonlinearDynamics\n    return FullNonlinearDynamics(physics_cfg)",
    "lines": 59,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9dad6075"
  },
  {
    "id": "testing_framework_technical_guide_8_82d15d0e",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 8,
    "code": "@pytest.fixture\ndef initial_state():\n    \"\"\"Standard initial state for testing: small perturbation from equilibrium.\"\"\"\n    return np.array([0.0, 0.0, 0.1, 0.1, 0.0, 0.0])\n\n@pytest.fixture\ndef controller_gains_classical():\n    \"\"\"Standard classical SMC gains for testing.\"\"\"\n    return [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n\n@pytest.fixture\ndef make_classical_controller(controller_gains_classical):\n    \"\"\"Factory fixture for creating classical SMC controllers.\"\"\"\n    def _make(**kwargs):\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        default_params = {\n            'gains': controller_gains_classical,\n            'max_force': 100.0,\n            'boundary_layer': 0.01,\n            'dt': 0.01\n        }\n        default_params.update(kwargs)\n        return ClassicalSMC(**default_params)\n    return _make\n\n@pytest.fixture\ndef simulation_params():\n    \"\"\"Standard simulation parameters for testing.\"\"\"\n    return {\n        'duration': 5.0,\n        'dt': 0.01,\n        'max_force': 100.0\n    }",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82d15d0e"
  },
  {
    "id": "testing_framework_technical_guide_9_8a6f9633",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 9,
    "code": "# tests/conftest.py (top of file, before any imports)\n\"\"\"\nMatplotlib enforcement: headless tests with Agg backend and show-ban.\nThis file MUST be imported before any test that imports matplotlib.pyplot.\n\"\"\"\nimport os\nimport warnings\n\n# 1) Enforce Agg backend as early as possible\nos.environ.setdefault(\"MPLBACKEND\", \"Agg\")\n\nimport matplotlib\nmatplotlib.use(\"Agg\", force=True)\n\n# 2) Treat Matplotlib warnings as errors\nwarnings.filterwarnings(\"error\", message=r\".*Matplotlib.*\", category=UserWarning)\n\ndef pytest_sessionstart(session):\n    \"\"\"Verify Agg backend at session start.\"\"\"\n    backend = matplotlib.get_backend().lower()\n    assert backend == \"agg\", (\n        f\"Matplotlib backend is {backend!r}, expected 'agg'. \"\n        \"Ensure MPLBACKEND=Agg is set before matplotlib import.\"\n    )\n\n# 3) Runtime ban on plt.show()\nimport matplotlib.pyplot as plt\n\ndef _no_show(*args, **kwargs):\n    raise AssertionError(\n        \"plt.show() is banned in tests. Use savefig(), return the Figure, \"\n        \"or use image comparisons.\"\n    )\n\nplt.show = _no_show  # type: ignore[assignment]",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a6f9633"
  },
  {
    "id": "testing_framework_technical_guide_10_ba83c043",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 10,
    "code": "# tests/conftest.py\nimport random\nimport numpy as np\n\n@pytest.fixture(autouse=True)\ndef reset_random_seeds():\n    \"\"\"Reset random seeds before each test for reproducibility.\"\"\"\n    seed = 42\n    random.seed(seed)\n    np.random.seed(seed)\n    yield\n    # Cleanup: restore to random state\n    random.seed(None)\n    np.random.seed(None)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba83c043"
  },
  {
    "id": "testing_framework_technical_guide_11_ae68b95f",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 11,
    "code": "@pytest.fixture\ndef temp_output_dir(tmp_path):\n    \"\"\"Provide temporary directory for test outputs.\"\"\"\n    output_dir = tmp_path / \"test_outputs\"\n    output_dir.mkdir()\n    yield output_dir\n    # Cleanup handled automatically by pytest tmp_path",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae68b95f"
  },
  {
    "id": "testing_framework_technical_guide_12_e0082ee4",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 12,
    "code": "@pytest.fixture\ndef mock_psutil(monkeypatch):\n    \"\"\"Mock psutil for systems where it's unavailable.\"\"\"\n    try:\n        import psutil\n        yield psutil\n    except ImportError:\n        # Provide fallback mock\n        class MockProcess:\n            def memory_info(self):\n                return type('obj', (object,), {'rss': 1024 * 1024 * 100})()  # 100 MB\n\n        mock_psutil_module = type('obj', (object,), {\n            'Process': lambda pid: MockProcess()\n        })()\n\n        monkeypatch.setitem(__import__('sys').modules, 'psutil', mock_psutil_module)\n        yield mock_psutil_module",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0082ee4"
  },
  {
    "id": "testing_framework_technical_guide_13_cfa08199",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestClassicalSMCInitialization:\n    \"\"\"Test Classical SMC controller initialization.\"\"\"\n\n    def test_valid_initialization(self):\n        \"\"\"Test successful initialization with valid parameters.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(\n            gains=gains,\n            max_force=100.0,\n            boundary_layer=0.01,\n            dt=0.01\n        )\n\n        # Verify all parameters stored correctly\n        assert controller.k1 == 10.0\n        assert controller.k2 == 8.0\n        assert controller.lam1 == 15.0\n        assert controller.lam2 == 12.0\n        assert controller.K == 50.0\n        assert controller.kd == 5.0\n        assert controller.max_force == 100.0\n        assert controller.boundary_layer == 0.01\n        assert controller.dt == 0.01\n\n    def test_invalid_gains_negative(self):\n        \"\"\"Test that negative gains are rejected.\"\"\"\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, -8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0,\n                boundary_layer=0.01\n            )\n\n    def test_invalid_gains_zero(self):\n        \"\"\"Test that zero gains are rejected.\"\"\"\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[0.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0,\n                boundary_layer=0.01\n            )\n\n    def test_invalid_max_force(self):\n        \"\"\"Test that invalid max_force is rejected.\"\"\"\n        with pytest.raises(ValueError, match=\"max_force must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=-100.0,\n                boundary_layer=0.01\n            )\n\n    def test_invalid_boundary_layer(self):\n        \"\"\"Test that invalid boundary_layer is rejected.\"\"\"\n        with pytest.raises(ValueError, match=\"boundary_layer must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0,\n                boundary_layer=0.0\n            )",
    "lines": 62,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfa08199"
  },
  {
    "id": "testing_framework_technical_guide_14_34a0242a",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestClassicalSMCControlComputation:\n    \"\"\"Test Classical SMC control computation.\"\"\"\n\n    def test_compute_control_valid_output(self):\n        \"\"\"Test that compute_control returns valid, bounded output.\"\"\"\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n        result = controller.compute_control(state, {}, {})\n\n        control = result.get('control_output', result.get('control', result.get('u')))\n\n        # Validate output properties\n        assert control is not None\n        assert isinstance(control, (float, np.ndarray))\n        assert np.all(np.isfinite(control))\n        assert np.all(np.abs(control) <= 100.0)  # Within saturation\n\n    def test_compute_control_equilibrium(self):\n        \"\"\"Test control at equilibrium (should be near zero).\"\"\"\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        equilibrium = np.zeros(6)\n        result = controller.compute_control(equilibrium, {}, {})\n\n        control = result.get('control_output', result.get('control', result.get('u')))\n\n        # At equilibrium, control should be minimal\n        if control is not None:\n            assert np.abs(control) < 1.0  # Small control near equilibrium\n\n    def test_compute_control_large_deviation(self):\n        \"\"\"Test control with large state deviation (saturation).\"\"\"\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        large_state = np.array([1.0, 0.5, 0.8, 0.3, 0.5, 0.2])\n        result = controller.compute_control(large_state, {}, {})\n\n        control = result.get('control_output', result.get('control', result.get('u')))\n\n        # Large deviation should saturate control\n        if control is not None:\n            assert np.abs(control) == pytest.approx(100.0, abs=0.1)\n\n    def test_compute_control_deterministic(self):\n        \"\"\"Test that repeated calls produce identical results.\"\"\"\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        results = []\n        for _ in range(100):\n            result = controller.compute_control(state, {}, {})\n            control = result.get('control_output', result.get('control', result.get('u')))\n            if control is not None:\n                results.append(control)\n\n        results = np.array(results)\n\n        # All results should be identical (deterministic)\n        std_dev = np.std(results, axis=0)\n        assert np.all(std_dev < 1e-15)  # Machine precision",
    "lines": 81,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "34a0242a"
  },
  {
    "id": "testing_framework_technical_guide_15_3db3b9f4",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 15,
    "code": "class TestSimplifiedDynamics:\n    \"\"\"Test simplified double-inverted pendulum dynamics.\"\"\"\n\n    def test_initialization(self, physics_cfg):\n        \"\"\"Test dynamics initialization with physics configuration.\"\"\"\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        assert dynamics.M == physics_cfg.M\n        assert dynamics.m1 == physics_cfg.m1\n        assert dynamics.m2 == physics_cfg.m2\n        assert dynamics.L1 == physics_cfg.L1\n        assert dynamics.L2 == physics_cfg.L2\n        assert dynamics.g == physics_cfg.g\n\n    def test_dynamics_output_shape(self, dynamics_simplified):\n        \"\"\"Test that dynamics returns correct output shape.\"\"\"\n        state = np.array([0.0, 0.0, 0.1, 0.1, 0.0, 0.0])\n        control = 10.0\n\n        state_dot = dynamics_simplified.dynamics(state, control)\n\n        assert state_dot.shape == (6,)\n        assert np.all(np.isfinite(state_dot))\n\n    def test_equilibrium_dynamics(self, dynamics_simplified):\n        \"\"\"Test dynamics at equilibrium with zero control.\"\"\"\n        equilibrium = np.zeros(6)\n        control = 0.0\n\n        state_dot = dynamics_simplified.dynamics(equilibrium, control)\n\n        # At equilibrium with zero control, derivatives should be near zero\n        assert np.linalg.norm(state_dot) < 1e-6\n\n    def test_energy_conservation(self, dynamics_simplified):\n        \"\"\"Test energy conservation for conservative dynamics.\"\"\"\n        from src.utils.analysis.energy import compute_total_energy\n\n        state = np.array([0.0, 0.0, 0.1, 0.1, 0.0, 0.0])\n        control = 0.0  # No external input\n\n        # Integrate for short time\n        dt = 0.01\n        t_span = np.arange(0, 1.0, dt)\n        states = [state]\n\n        for _ in t_span[1:]:\n            state_dot = dynamics_simplified.dynamics(states[-1], control)\n            states.append(states[-1] + dt * state_dot)\n\n        states = np.array(states)\n\n        # Compute energy at each timestep\n        energies = [compute_total_energy(s, dynamics_simplified) for s in states]\n\n        # Energy should be approximately conserved (no friction)\n        energy_drift = np.max(np.abs(np.diff(energies)))\n        assert energy_drift < 0.01  # Small drift due to Euler integration",
    "lines": 58,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3db3b9f4"
  },
  {
    "id": "testing_framework_technical_guide_16_917bd52b",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 16,
    "code": "class TestSMCFactory:\n    \"\"\"Test SMC controller factory.\"\"\"\n\n    def test_create_classical_smc(self):\n        \"\"\"Test factory creation of classical SMC.\"\"\"\n        from src.controllers.factory import SMCFactory, SMCType\n\n        controller = SMCFactory.create_controller(\n            SMCType.CLASSICAL,\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        assert isinstance(controller, ClassicalSMC)\n        assert controller.max_force == 100.0\n\n    def test_create_all_controller_types(self):\n        \"\"\"Test factory can create all SMC types.\"\"\"\n        from src.controllers.factory import SMCFactory, SMCType\n\n        gain_configs = {\n            SMCType.CLASSICAL: [10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            SMCType.ADAPTIVE: [10.0, 8.0, 15.0, 12.0, 0.5],\n            SMCType.SUPER_TWISTING: [25.0, 10.0, 15.0, 12.0, 20.0, 15.0],\n            SMCType.HYBRID: [15.0, 12.0, 18.0, 15.0]\n        }\n\n        for smc_type, gains in gain_configs.items():\n            controller = SMCFactory.create_controller(\n                smc_type,\n                gains=gains,\n                max_force=100.0,\n                boundary_layer=0.01\n            )\n\n            assert controller is not None\n            assert hasattr(controller, 'compute_control')\n\n    def test_invalid_controller_type(self):\n        \"\"\"Test factory raises error for invalid controller type.\"\"\"\n        from src.controllers.factory import SMCFactory\n\n        with pytest.raises((ValueError, KeyError)):\n            SMCFactory.create_controller(\n                \"invalid_type\",\n                gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0\n            )",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "917bd52b"
  },
  {
    "id": "testing_framework_technical_guide_17_d7116cdf",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 17,
    "code": "class TestEndToEndSimulation:\n    \"\"\"Integration tests for complete simulation workflows.\"\"\"\n\n    def test_full_simulation_pipeline(self):\n        \"\"\"Test complete simulation from initialization to results.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.simulation_runner import run_simulation\n\n        # Setup\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        initial_state = [0.0, 0.0, 0.1, 0.1, 0.0, 0.0]\n\n        # Execute\n        result = run_simulation(\n            controller=controller,\n            duration=5.0,\n            dt=0.01,\n            initial_state=initial_state\n        )\n\n        # Validate\n        assert 'time' in result\n        assert 'states' in result\n        assert 'controls' in result\n        assert len(result['time']) == len(result['states'])\n        assert len(result['time']) == len(result['controls']) + 1\n\n        # Performance validation\n        final_state = result['states'][-1]\n        assert np.linalg.norm(final_state) < 0.05  # Stabilized\n\n    def test_simulation_with_disturbance(self):\n        \"\"\"Test simulation with external disturbance.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.simulation_runner import run_simulation\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        # Define disturbance function\n        def disturbance(t):\n            if 1.0 <= t <= 2.0:\n                return 20.0  # Impulse disturbance\n            return 0.0\n\n        result = run_simulation(\n            controller=controller,\n            duration=5.0,\n            dt=0.01,\n            initial_state=[0.0, 0.0, 0.1, 0.1, 0.0, 0.0],\n            disturbance=disturbance\n        )\n\n        # Controller should recover from disturbance\n        final_state = result['states'][-1]\n        assert np.linalg.norm(final_state) < 0.1  # Recovered",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d7116cdf"
  },
  {
    "id": "testing_framework_technical_guide_18_9fd60b0e",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 18,
    "code": "class TestPSOIntegration:\n    \"\"\"Integration tests for PSO optimization workflows.\"\"\"\n\n    def test_pso_optimization_workflow(self):\n        \"\"\"Test complete PSO optimization workflow.\"\"\"\n        from src.optimizer.pso_optimizer import PSOTuner\n\n        bounds = [(0.1, 50.0)] * 4 + [(1.0, 200.0), (0.0, 50.0)]\n\n        tuner = PSOTuner(\n            controller_type='classical_smc',\n            bounds=bounds,\n            n_particles=10,\n            iters=5\n        )\n\n        best_gains, best_cost = tuner.optimize()\n\n        # Validate optimization results\n        assert len(best_gains) == 6\n        assert all(bounds[i][0] <= best_gains[i] <= bounds[i][1] for i in range(6))\n        assert best_cost < float('inf')\n        assert not np.isnan(best_cost)\n\n    def test_optimized_gains_improve_performance(self):\n        \"\"\"Test that PSO-optimized gains improve performance.\"\"\"\n        from src.optimizer.pso_optimizer import PSOTuner\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.simulation_runner import run_simulation\n\n        # Initial (unoptimized) gains\n        initial_gains = [5.0, 5.0, 10.0, 10.0, 30.0, 2.0]\n\n        # Run PSO optimization\n        bounds = [(0.1, 50.0)] * 4 + [(1.0, 200.0), (0.0, 50.0)]\n        tuner = PSOTuner(\n            controller_type='classical_smc',\n            bounds=bounds,\n            n_particles=10,\n            iters=10\n        )\n        optimized_gains, _ = tuner.optimize()\n\n        # Compare performance\n        def evaluate_performance(gains):\n            controller = ClassicalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n            result = run_simulation(\n                controller=controller,\n                duration=5.0,\n                dt=0.01,\n                initial_state=[0.0, 0.0, 0.1, 0.1, 0.0, 0.0]\n            )\n            # ISE metric\n            states = np.array(result['states'])\n            return np.sum(np.sum(states**2, axis=1) * 0.01)\n\n        initial_ise = evaluate_performance(initial_gains)\n        optimized_ise = evaluate_performance(optimized_gains)\n\n        # PSO should improve (reduce) ISE\n        assert optimized_ise < initial_ise",
    "lines": 61,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9fd60b0e"
  },
  {
    "id": "testing_framework_technical_guide_19_ea7c5fff",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 19,
    "code": "class TestHILIntegration:\n    \"\"\"Integration tests for Hardware-in-the-Loop.\"\"\"\n\n    @pytest.mark.slow\n    def test_hil_plant_server_startup(self):\n        \"\"\"Test HIL plant server can start and accept connections.\"\"\"\n        from src.hil.plant_server import PlantServer\n        import threading\n        import time\n\n        server = PlantServer(port=5555)\n\n        # Start server in background thread\n        server_thread = threading.Thread(target=server.run, daemon=True)\n        server_thread.start()\n\n        time.sleep(1.0)  # Allow server to start\n\n        # Verify server is running\n        assert server.is_running()\n\n        # Cleanup\n        server.shutdown()\n\n    @pytest.mark.slow\n    def test_hil_controller_client_connection(self):\n        \"\"\"Test HIL controller client can connect to plant server.\"\"\"\n        from src.hil.plant_server import PlantServer\n        from src.hil.controller_client import ControllerClient\n        import threading\n        import time\n\n        # Start server\n        server = PlantServer(port=5556)\n        server_thread = threading.Thread(target=server.run, daemon=True)\n        server_thread.start()\n        time.sleep(1.0)\n\n        # Connect client\n        client = ControllerClient(host='localhost', port=5556)\n        connected = client.connect()\n\n        assert connected\n\n        # Cleanup\n        client.disconnect()\n        server.shutdown()",
    "lines": 47,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ea7c5fff"
  },
  {
    "id": "testing_framework_technical_guide_20_2abb4755",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n# tests/utils/assertions.py\n\ndef assert_stabilized(final_state, tolerance=0.05):\n    \"\"\"Assert that final state is stabilized to equilibrium.\"\"\"\n    error = np.linalg.norm(final_state)\n    assert error < tolerance, f\"System not stabilized: error={error:.4f} > {tolerance}\"\n\ndef assert_control_bounded(control_history, max_force):\n    \"\"\"Assert that all control values are within saturation limits.\"\"\"\n    violations = np.sum(np.abs(control_history) > max_force)\n    assert violations == 0, f\"Control violations: {violations} timesteps exceeded {max_force}N\"\n\ndef assert_lyapunov_decreasing(lyapunov_values):\n    \"\"\"Assert that Lyapunov function is non-increasing.\"\"\"\n    diffs = np.diff(lyapunov_values)\n    increasing = np.sum(diffs > 0)\n    assert increasing == 0, f\"Lyapunov not decreasing: {increasing} increases detected\"\n\ndef assert_convergence(states, final_tolerance=0.01, settling_time=5.0, dt=0.01):\n    \"\"\"Assert exponential convergence to equilibrium.\"\"\"\n    errors = np.linalg.norm(states, axis=1)\n    final_error = errors[-1]\n    settling_index = int(settling_time / dt)\n\n    assert final_error < final_tolerance, f\"Final error {final_error:.4f} > {final_tolerance}\"\n    assert np.all(errors[settling_index:] < final_tolerance), \"Not settled within settling time\"",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2abb4755"
  },
  {
    "id": "testing_framework_technical_guide_21_489a8275",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# tests/utils/generators.py\n\ndef generate_initial_conditions(n_samples=100, max_deviation=0.2):\n    \"\"\"Generate random initial conditions for robustness testing.\"\"\"\n    return np.random.uniform(\n        -max_deviation,\n        max_deviation,\n        size=(n_samples, 6)\n    )\n\ndef generate_physics_variations(base_params, uncertainty=0.1, n_samples=50):\n    \"\"\"Generate physics parameter variations for robustness testing.\"\"\"\n    variations = []\n    for _ in range(n_samples):\n        varied = {}\n        for param, value in base_params.items():\n            if isinstance(value, (int, float)):\n                variation = value * (1 + np.random.uniform(-uncertainty, uncertainty))\n                varied[param] = variation\n            else:\n                varied[param] = value\n        variations.append(varied)\n    return variations\n\ndef generate_disturbance_profiles(duration, dt, disturbance_types=['impulse', 'step', 'ramp']):\n    \"\"\"Generate disturbance profiles for testing.\"\"\"\n    profiles = {}\n\n    t = np.arange(0, duration, dt)\n\n    for dist_type in disturbance_types:\n        if dist_type == 'impulse':\n            profile = np.zeros_like(t)\n            impulse_index = len(t) // 2\n            profile[impulse_index] = 50.0\n        elif dist_type == 'step':\n            profile = np.where(t > duration/2, 20.0, 0.0)\n        elif dist_type == 'ramp':\n            profile = 10.0 * t / duration\n\n        profiles[dist_type] = profile\n\n    return profiles",
    "lines": 46,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "489a8275"
  },
  {
    "id": "testing_framework_technical_guide_22_6ddd410d",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\n# tests/mocks/mock_controller.py\n\nclass MockController:\n    \"\"\"Mock controller for testing simulation framework.\"\"\"\n\n    def __init__(self, control_value=0.0):\n        self.control_value = control_value\n        self.call_count = 0\n\n    def compute_control(self, state, state_vars, history):\n        self.call_count += 1\n        return {\n            'control_output': self.control_value,\n            'state_vars': state_vars,\n            'history': history\n        }\n\n    def initialize_history(self):\n        return {}\n\n\nclass MockDynamics:\n    \"\"\"Mock dynamics for testing controllers.\"\"\"\n\n    def __init__(self, dynamics_function=None):\n        self.dynamics_function = dynamics_function or (lambda state, control: np.zeros(6))\n\n    def dynamics(self, state, control):\n        return self.dynamics_function(state, control)",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ddd410d"
  },
  {
    "id": "testing_framework_technical_guide_23_78de44f9",
    "file": "docs\\testing\\testing_framework_technical_guide.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# tests/utils/error_injection.py\n\nclass ErrorInjector:\n    \"\"\"Inject errors for fault tolerance testing.\"\"\"\n\n    @staticmethod\n    def inject_nan(state, probability=0.1):\n        \"\"\"Randomly inject NaN values into state.\"\"\"\n        mask = np.random.random(state.shape) < probability\n        corrupted = state.copy()\n        corrupted[mask] = np.nan\n        return corrupted\n\n    @staticmethod\n    def inject_sensor_noise(state, std_dev=0.01):\n        \"\"\"Add Gaussian noise to state (sensor noise simulation).\"\"\"\n        noise = np.random.normal(0, std_dev, size=state.shape)\n        return state + noise\n\n    @staticmethod\n    def inject_latency(control_history, delay_steps=1):\n        \"\"\"Simulate actuator latency by delaying control application.\"\"\"\n        if len(control_history) <= delay_steps:\n            return 0.0\n        return control_history[-(delay_steps + 1)]",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "78de44f9"
  },
  {
    "id": "testing_workflows_best_practices_1_943fe2c8",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Step 1: RED - Write failing test\n# tests/test_controllers/smc/algorithms/classical/test_new_feature.py\n\ndef test_chattering_reduction_effectiveness():\n    \"\"\"Test that chattering reduction algorithm reduces control rate.\"\"\"\n    controller = ClassicalSMC(\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100,\n        boundary_layer=0.01,\n        chattering_reduction=True  # New feature\n    )\n\n    state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n    control_history = []\n    for _ in range(100):\n        result = controller.compute_control(state, {}, {})\n        control = result['control']\n        control_history.append(control)\n\n    # Calculate control rate\n    control_rate = np.std(np.diff(control_history))\n\n    # Should be significantly lower than baseline\n    assert control_rate < 5.0, f\"Chattering reduction ineffective: rate={control_rate}\"\n\n# Run test \u2192 FAILS (feature not implemented)\n# pytest tests/test_controllers/smc/algorithms/classical/test_new_feature.py -v",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "943fe2c8"
  },
  {
    "id": "testing_workflows_best_practices_2_d6eb61ea",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Step 2: GREEN - Implement minimal code to pass\n# src/controllers/smc/classic_smc.py\n\nclass ClassicalSMC:\n    def __init__(self, gains, max_force, boundary_layer=0.01, chattering_reduction=False):\n        self.gains = gains\n        self.max_force = max_force\n        self.boundary_layer = boundary_layer\n        self.chattering_reduction = chattering_reduction\n        self.last_control = 0.0\n\n    def compute_control(self, state, state_vars, history):\n        # ... existing SMC logic ...\n        control = u_eq + u_switch + u_derivative\n\n        if self.chattering_reduction:\n            # Simple low-pass filter\n            alpha = 0.8\n            control = alpha * self.last_control + (1 - alpha) * control\n\n        self.last_control = control\n\n        # Saturation\n        control = np.clip(control, -self.max_force, self.max_force)\n        return {'control': control}\n\n# Run test \u2192 PASSES",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6eb61ea"
  },
  {
    "id": "testing_workflows_best_practices_3_d509a87e",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Step 3: REFACTOR - Clean up implementation\nclass ChatteringReduction:\n    \"\"\"Encapsulate chattering reduction logic.\"\"\"\n\n    def __init__(self, alpha=0.8):\n        self.alpha = alpha\n        self.last_control = 0.0\n\n    def apply(self, control):\n        \"\"\"Apply low-pass filter to control signal.\"\"\"\n        filtered = self.alpha * self.last_control + (1 - self.alpha) * control\n        self.last_control = filtered\n        return filtered\n\n\nclass ClassicalSMC:\n    def __init__(self, gains, max_force, boundary_layer=0.01, chattering_reduction=False):\n        self.gains = gains\n        self.max_force = max_force\n        self.boundary_layer = boundary_layer\n\n        if chattering_reduction:\n            self.chattering_filter = ChatteringReduction()\n        else:\n            self.chattering_filter = None\n\n    def compute_control(self, state, state_vars, history):\n        # ... existing SMC logic ...\n        control = u_eq + u_switch + u_derivative\n\n        if self.chattering_filter:\n            control = self.chattering_filter.apply(control)\n\n        control = np.clip(control, -self.max_force, self.max_force)\n        return {'control': control}\n\n# Run test \u2192 STILL PASSES\n# Run full test suite \u2192 ALL PASS",
    "lines": 41,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d509a87e"
  },
  {
    "id": "testing_workflows_best_practices_4_49af3f21",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Step 1: Write interface tests FIRST\n# tests/test_controllers/smc/algorithms/adaptive_sta/test_adaptive_sta_interface.py\n\nclass TestAdaptiveSTAInterface:\n    \"\"\"Test interface compliance for Adaptive STA SMC.\"\"\"\n\n    def test_implements_controller_protocol(self):\n        \"\"\"Test controller implements required protocol.\"\"\"\n        from src.controllers.interfaces import ControllerProtocol\n\n        controller = AdaptiveSTASMC(\n            gains=[20, 15, 12, 10],\n            max_force=100,\n            adaptation_rate=0.5\n        )\n\n        assert isinstance(controller, ControllerProtocol)\n        assert hasattr(controller, 'compute_control')\n        assert callable(controller.compute_control)\n\n    def test_compute_control_signature(self):\n        \"\"\"Test compute_control has correct signature.\"\"\"\n        controller = AdaptiveSTASMC(gains=[20,15,12,10], max_force=100)\n\n        state = np.zeros(6)\n        result = controller.compute_control(state, {}, {})\n\n        assert isinstance(result, dict)\n        assert 'control' in result\n        assert isinstance(result['control'], (int, float, np.ndarray))\n\n# Step 2: Write functionality tests\nclass TestAdaptiveSTAFunctionality:\n    \"\"\"Test Adaptive STA SMC core functionality.\"\"\"\n\n    def test_adaptation_increases_gains_under_uncertainty(self):\n        \"\"\"Test adaptive mechanism increases gains when needed.\"\"\"\n        controller = AdaptiveSTASMC(\n            gains=[20, 15, 12, 10],\n            max_force=100,\n            adaptation_rate=0.5\n        )\n\n        # High uncertainty scenario\n        uncertain_state = np.array([0.5, 0.3, 0.2, 0.1, 0.05, 0.02])\n        initial_gains = controller.get_current_gains().copy()\n\n        # Run adaptation\n        for _ in range(50):\n            controller.compute_control(uncertain_state, {}, {})\n\n        adapted_gains = controller.get_current_gains()\n        assert np.any(adapted_gains > initial_gains), \"Gains should adapt upward\"\n\n# Step 3: Implement controller to pass tests\n# src/controllers/smc/algorithms/adaptive_sta/adaptive_sta_smc.py\n\nclass AdaptiveSTASMC:\n    \"\"\"Adaptive Super-Twisting Sliding Mode Controller.\"\"\"\n\n    def __init__(self, gains, max_force, adaptation_rate=0.5):\n        self.initial_gains = np.array(gains)\n        self.current_gains = self.initial_gains.copy()\n        self.max_force = max_force\n        self.adaptation_rate = adaptation_rate\n\n    def compute_control(self, state, state_vars, history):\n        # ... Super-twisting control logic ...\n        # ... Adaptive gain update ...\n        return {'control': control}\n\n    def get_current_gains(self):\n        return self.current_gains.copy()",
    "lines": 76,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49af3f21"
  },
  {
    "id": "testing_workflows_best_practices_5_ff17d6ea",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 5,
    "code": "# Level 1: Component-level tests\ndef test_sliding_surface_computation():\n    \"\"\"Test individual sliding surface computation.\"\"\"\n    from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n\n    surface = LinearSlidingSurface(gains=[5, 3, 4, 2])\n    state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n\n    s = surface.compute(state)\n    assert isinstance(s, float)\n    assert np.isfinite(s)\n\n# Level 2: Component integration tests\ndef test_sliding_surface_with_controller():\n    \"\"\"Test sliding surface integrated with controller.\"\"\"\n    from src.controllers.smc.classic_smc import ClassicalSMC\n\n    controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100)\n\n    state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n    result = controller.compute_control(state, {}, {})\n\n    assert 'control' in result\n    assert np.isfinite(result['control'])\n\n# Level 3: System-level integration tests\ndef test_controller_with_dynamics():\n    \"\"\"Test controller integrated with dynamics.\"\"\"\n    from src.controllers.smc.classic_smc import ClassicalSMC\n    from src.core.dynamics import SimplifiedDynamics\n\n    controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100)\n    dynamics = SimplifiedDynamics({'M': 1.0, 'm1': 0.1, 'm2': 0.1, 'L1': 0.5, 'L2': 0.5, 'g': 9.81})\n\n    state = np.array([0.0, 0.1, 0.1, 0.0, 0.0, 0.0])\n\n    for _ in range(100):\n        result = controller.compute_control(state, {}, {})\n        u = result['control']\n        x_dot = dynamics.dynamics(state, u)\n        state = state + 0.01 * x_dot\n\n    assert np.linalg.norm(state) < 0.5  # Partial stabilization\n\n# Level 4: End-to-end workflow tests\ndef test_complete_simulation_workflow():\n    \"\"\"Test complete simulation from initialization to results.\"\"\"\n    from src.core.simulation_runner import run_simulation\n\n    controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100)\n\n    result = run_simulation(\n        controller=controller,\n        duration=5.0,\n        dt=0.01,\n        initial_state=[0.0, 0.1, 0.1, 0.0, 0.0, 0.0]\n    )\n\n    assert 'time' in result\n    assert 'states' in result\n    assert len(result['time']) == len(result['states'])\n    assert np.linalg.norm(result['states'][-1]) < 0.05  # Full stabilization",
    "lines": 62,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ff17d6ea"
  },
  {
    "id": "testing_workflows_best_practices_6_475809d2",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Identify uncovered code\n# src/controllers/smc/classic_smc.py:89-92 not covered\n\n# Lines 89-92: Error handling for invalid state\nif np.any(np.isnan(state)):\n    raise ValueError(\"State contains NaN values\")\nif np.any(np.isinf(state)):\n    raise ValueError(\"State contains infinite values\")\n\n# Write test to cover this code\ndef test_nan_state_rejection():\n    \"\"\"Test that NaN states are rejected.\"\"\"\n    controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100)\n\n    nan_state = np.array([0.1, np.nan, 0.08, 0.02, 0.03, 0.01])\n\n    with pytest.raises(ValueError, match=\"NaN values\"):\n        controller.compute_control(nan_state, {}, {})\n\ndef test_inf_state_rejection():\n    \"\"\"Test that infinite states are rejected.\"\"\"\n    controller = ClassicalSMC(gains=[10,8,15,12,50,5], max_force=100)\n\n    inf_state = np.array([0.1, np.inf, 0.08, 0.02, 0.03, 0.01])\n\n    with pytest.raises(ValueError, match=\"infinite values\"):\n        controller.compute_control(inf_state, {}, {})\n\n# Run coverage again \u2192 Lines 89-92 now covered",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "475809d2"
  },
  {
    "id": "testing_workflows_best_practices_7_71733ccd",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Install mutpy\npip install mutpy\n\n# Run mutation testing\nmut.py --target src.controllers.smc.classic_smc --unit-test tests.test_controllers.smc.algorithms.classical.test_classical_smc --report-html mutation_report.html\n\n# Example mutation: Change + to -\n# Original: control = u_eq + u_switch\n# Mutant:   control = u_eq - u_switch\n\n# If tests still pass \u2192 weak test suite\n# If tests fail \u2192 strong test suite (mutation killed)\n\n# Target: >80% mutation score",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71733ccd"
  },
  {
    "id": "testing_workflows_best_practices_8_26d82617",
    "file": "docs\\testing\\testing_workflows_best_practices.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Metric 1: Test-to-Code Ratio\ntest_loc = count_lines_of_code('tests/')\nsrc_loc = count_lines_of_code('src/')\nratio = test_loc / src_loc\n\n# Target: 1.5-2.0 (150-200% test code)\nassert ratio >= 1.5, f\"Insufficient test coverage: ratio={ratio:.2f}\"\n\n# Metric 2: Average Test Execution Time\ntotal_time = pytest_duration\ntest_count = pytest_test_count\navg_time = total_time / test_count\n\n# Target: <100ms per test\nassert avg_time < 0.1, f\"Tests too slow: avg={avg_time*1000:.0f}ms\"\n\n# Metric 3: Test Flakiness\nflaky_tests = count_flaky_tests()  # Tests that intermittently fail\ntotal_tests = count_total_tests()\nflakiness_rate = flaky_tests / total_tests\n\n# Target: <1% flakiness\nassert flakiness_rate < 0.01, f\"Too many flaky tests: {flakiness_rate*100:.1f}%\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26d82617"
  },
  {
    "id": "validation_methodology_guide_1_9ff16470",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 1,
    "code": "# tests/validation/test_sliding_surface_properties.py\n\nimport pytest\nimport numpy as np\nfrom src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n\nclass TestSlidingSurfaceLinearity:\n    \"\"\"Validate linearity property of sliding surfaces.\"\"\"\n\n    def test_linearity_property(self):\n        \"\"\"Test \u03c3(x\u2081 + x\u2082) = \u03c3(x\u2081) + \u03c3(x\u2082) for linear surfaces.\"\"\"\n        gains = [5.0, 3.0, 4.0, 2.0]\n        surface = LinearSlidingSurface(gains)\n\n        # Generate test states\n        x1 = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n        x2 = np.array([0.2, 0.2, 0.2, 0.1, 0.1, 0.1])\n\n        # Compute sliding variables\n        s1 = surface.compute(x1)\n        s2 = surface.compute(x2)\n        s_combined = surface.compute(x1 + x2)\n\n        # Verify linearity: s(x1 + x2) = s(x1) + s(x2)\n        assert abs(s_combined - (s1 + s2)) < 1e-10, (\n            f\"Linearity violated: s({x1}+{x2}) = {s_combined}, \"\n            f\"but s({x1}) + s({x2}) = {s1 + s2}\"\n        )\n\n    @pytest.mark.parametrize(\"k1,k2,lam1,lam2\", [\n        (5.0, 3.0, 4.0, 2.0),\n        (10.0, 8.0, 15.0, 12.0),\n        (1.0, 1.0, 1.0, 1.0),\n    ])\n    def test_linearity_various_gains(self, k1, k2, lam1, lam2):\n        \"\"\"Test linearity for various gain combinations.\"\"\"\n        gains = [k1, k2, lam1, lam2]\n        surface = LinearSlidingSurface(gains)\n\n        for _ in range(100):\n            x1 = np.random.uniform(-1, 1, size=6)\n            x2 = np.random.uniform(-1, 1, size=6)\n\n            s1 = surface.compute(x1)\n            s2 = surface.compute(x2)\n            s_combined = surface.compute(x1 + x2)\n\n            assert abs(s_combined - (s1 + s2)) < 1e-10",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ff16470"
  },
  {
    "id": "validation_methodology_guide_2_babfdfb5",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestSlidingSurfaceHomogeneity:\n    \"\"\"Validate homogeneity property of sliding surfaces.\"\"\"\n\n    def test_homogeneity_property(self):\n        \"\"\"Test \u03c3(\u03b1\u00b7x) = \u03b1\u00b7\u03c3(x) for linear surfaces.\"\"\"\n        gains = [5.0, 3.0, 4.0, 2.0]\n        surface = LinearSlidingSurface(gains)\n\n        x = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n        alpha = 2.5\n\n        s_original = surface.compute(x)\n        s_scaled = surface.compute(alpha * x)\n\n        # Verify homogeneity: s(\u03b1\u00b7x) = \u03b1\u00b7s(x)\n        expected = alpha * s_original\n        assert abs(s_scaled - expected) < 1e-10, (\n            f\"Homogeneity violated: s({alpha}\u00b7x) = {s_scaled}, \"\n            f\"but {alpha}\u00b7s(x) = {expected}\"\n        )\n\n    def test_homogeneity_negative_scaling(self):\n        \"\"\"Test homogeneity with negative scalar.\"\"\"\n        gains = [5.0, 3.0, 4.0, 2.0]\n        surface = LinearSlidingSurface(gains)\n\n        x = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n        alpha = -1.5\n\n        s_original = surface.compute(x)\n        s_scaled = surface.compute(alpha * x)\n\n        assert abs(s_scaled - alpha * s_original) < 1e-10",
    "lines": 36,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "babfdfb5"
  },
  {
    "id": "validation_methodology_guide_3_90e80154",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestSlidingSurfaceGainSensitivity:\n    \"\"\"Validate gain sensitivity of sliding surfaces.\"\"\"\n\n    def test_proportional_gain_scaling(self):\n        \"\"\"Test that doubling gains doubles sliding variable.\"\"\"\n        gains1 = [5.0, 3.0, 4.0, 2.0]\n        gains2 = [10.0, 6.0, 8.0, 4.0]  # Doubled gains\n\n        surface1 = LinearSlidingSurface(gains1)\n        surface2 = LinearSlidingSurface(gains2)\n\n        state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05])\n\n        s1 = surface1.compute(state)\n        s2 = surface2.compute(state)\n\n        # Surface value should double with doubled gains\n        assert abs(s2 - 2 * s1) < 1e-10, (\n            f\"Gain sensitivity violated: s(2k) = {s2}, but 2\u00b7s(k) = {2*s1}\"\n        )\n\n    def test_zero_gains_zero_surface(self):\n        \"\"\"Test that zero gains produce zero sliding variable.\"\"\"\n        gains = [0.0, 0.0, 0.0, 0.0]\n        surface = LinearSlidingSurface(gains)\n\n        state = np.random.uniform(-1, 1, size=6)\n        s = surface.compute(state)\n\n        assert abs(s) < 1e-15, f\"Zero gains should produce zero surface, got {s}\"",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "90e80154"
  },
  {
    "id": "validation_methodology_guide_4_a3140306",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 4,
    "code": "# tests/validation/test_boundary_layer_properties.py\n\nclass TestBoundaryLayerContinuity:\n    \"\"\"Validate continuity of boundary layer switching functions.\"\"\"\n\n    def test_tanh_continuity_at_surface(self):\n        \"\"\"Test tanh switching function is continuous at \u03c3 = 0.\"\"\"\n        from src.controllers.smc.algorithms.classical.boundary_layer import BoundaryLayer\n\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"tanh\")\n\n        epsilon = 1e-8\n        switch_left = boundary_layer.compute(-epsilon)\n        switch_center = boundary_layer.compute(0.0)\n        switch_right = boundary_layer.compute(epsilon)\n\n        # Values should be very close at the boundary\n        assert abs(switch_left - switch_center) < 1e-6\n        assert abs(switch_right - switch_center) < 1e-6\n        assert abs(switch_center) < 1e-6  # tanh(0) = 0\n\n    def test_linear_continuity_at_surface(self):\n        \"\"\"Test linear (saturation) switching function continuity.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"linear\")\n\n        epsilon = 1e-8\n        switch_left = boundary_layer.compute(-epsilon)\n        switch_center = boundary_layer.compute(0.0)\n        switch_right = boundary_layer.compute(epsilon)\n\n        # Linear function is continuous\n        assert abs(switch_left - switch_center) < 1e-10\n        assert abs(switch_right - switch_center) < 1e-10",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a3140306"
  },
  {
    "id": "validation_methodology_guide_5_2cdad9ce",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestBoundaryLayerMonotonicity:\n    \"\"\"Validate monotonicity of switching functions.\"\"\"\n\n    def test_tanh_monotonicity(self):\n        \"\"\"Test tanh switching function is strictly increasing.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"tanh\")\n\n        s_values = np.linspace(-1, 1, 100)\n        switch_values = [boundary_layer.compute(s) for s in s_values]\n\n        # Verify strict monotonicity\n        for i in range(len(switch_values) - 1):\n            assert switch_values[i+1] >= switch_values[i], (\n                f\"Monotonicity violated at index {i}: \"\n                f\"switch({s_values[i+1]}) = {switch_values[i+1]} < \"\n                f\"switch({s_values[i]}) = {switch_values[i]}\"\n            )\n\n    def test_saturation_monotonicity(self):\n        \"\"\"Test saturation function is monotonic.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"linear\")\n\n        s_values = np.linspace(-2, 2, 200)\n        switch_values = [boundary_layer.compute(s) for s in s_values]\n\n        for i in range(len(switch_values) - 1):\n            assert switch_values[i+1] >= switch_values[i]",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2cdad9ce"
  },
  {
    "id": "validation_methodology_guide_6_f3d28d35",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nclass TestBoundaryLayerAsymptoticBehavior:\n    \"\"\"Validate asymptotic limits of switching functions.\"\"\"\n\n    def test_tanh_asymptotic_limits(self):\n        \"\"\"Test tanh approaches \u00b11 for large |\u03c3|.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"tanh\")\n\n        # Large positive \u03c3\n        switch_pos = boundary_layer.compute(10.0)\n        assert abs(switch_pos - 1.0) < 1e-3, (\n            f\"tanh should approach +1 for large positive \u03c3, got {switch_pos}\"\n        )\n\n        # Large negative \u03c3\n        switch_neg = boundary_layer.compute(-10.0)\n        assert abs(switch_neg - (-1.0)) < 1e-3, (\n            f\"tanh should approach -1 for large negative \u03c3, got {switch_neg}\"\n        )\n\n    def test_saturation_bounds(self):\n        \"\"\"Test saturation function is bounded by \u00b11.\"\"\"\n        boundary_layer = BoundaryLayer(thickness=0.1, method=\"linear\")\n\n        # Test many values\n        s_values = np.random.uniform(-100, 100, size=1000)\n        for s in s_values:\n            switch = boundary_layer.compute(s)\n            assert -1.0 <= switch <= 1.0, (\n                f\"Saturation violated: switch({s}) = {switch} not in [-1, 1]\"\n            )",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3d28d35"
  },
  {
    "id": "validation_methodology_guide_7_bbed43fd",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 7,
    "code": "# tests/validation/test_lyapunov_properties.py\n\nclass TestLyapunovFunctionProperties:\n    \"\"\"Validate Lyapunov function properties for stability analysis.\"\"\"\n\n    def test_positive_definiteness(self):\n        \"\"\"Test V(\u03c3) > 0 for \u03c3 \u2260 0, V(0) = 0.\"\"\"\n        from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n\n        gains = [5.0, 3.0, 4.0, 2.0]\n        surface = LinearSlidingSurface(gains)\n\n        # Test states\n        states = [\n            np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]),  # Non-zero\n            np.array([0.2, 0.1, 0.15, 0.05, 0.08, 0.03]),   # Non-zero\n            np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])        # Zero (equilibrium)\n        ]\n\n        for state in states:\n            s = surface.compute(state)\n            V = 0.5 * s**2  # Lyapunov candidate: V = \u00bd\u03c3\u00b2\n\n            if np.linalg.norm(state) < 1e-10:\n                # At equilibrium, V should be zero\n                assert V < 1e-15, f\"V(0) should be zero, got {V}\"\n            else:\n                # Away from equilibrium, V should be positive\n                assert V > 0, f\"V(\u03c3) should be positive for \u03c3 \u2260 0, got {V}\"\n\n    def test_lyapunov_decrease_property(self):\n        \"\"\"Test V\u0307(\u03c3) < 0 for \u03c3 \u2260 0 (Lyapunov decrease condition).\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.dynamics import SimplifiedDynamics\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        physics_cfg = {\n            'M': 1.0, 'm1': 0.1, 'm2': 0.1,\n            'L1': 0.5, 'L2': 0.5, 'g': 9.81\n        }\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        # Initial state away from equilibrium\n        state = np.array([0.0, 0.2, 0.15, 0.0, 0.0, 0.0])\n\n        V_values = []\n        for _ in range(100):\n            # Compute sliding variable\n            from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n            surface = LinearSlidingSurface([10.0, 8.0, 15.0, 12.0])\n            s = surface.compute(state)\n\n            V = 0.5 * s**2\n            V_values.append(V)\n\n            # Apply control and step dynamics\n            result = controller.compute_control(state, {}, {})\n            u = result.get('control_output', result.get('control', 0.0))\n            x_dot = dynamics.dynamics(state, u)\n            state = state + 0.01 * x_dot\n\n        # Verify Lyapunov decrease: V\u0307 < 0\n        V_derivative = np.diff(V_values)\n        positive_derivatives = np.sum(V_derivative > 0)\n\n        # Allow small violations due to numerical errors\n        violation_ratio = positive_derivatives / len(V_derivative)\n        assert violation_ratio < 0.05, (\n            f\"Lyapunov function should decrease monotonically, \"\n            f\"but increased {violation_ratio*100:.1f}% of the time\"\n        )",
    "lines": 76,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bbed43fd"
  },
  {
    "id": "validation_methodology_guide_8_83301779",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 8,
    "code": "class TestReachingLawSatisfaction:\n    \"\"\"Validate reaching law for sliding mode controllers.\"\"\"\n\n    def test_reaching_law_condition(self):\n        \"\"\"Test \u03c3\u00b7\u03c3\u0307 \u2264 -\u03b7|\u03c3| is satisfied.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.dynamics import SimplifiedDynamics\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        physics_cfg = {'M': 1.0, 'm1': 0.1, 'm2': 0.1, 'L1': 0.5, 'L2': 0.5, 'g': 9.81}\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        state = np.array([0.0, 0.2, 0.15, 0.0, 0.0, 0.0])\n\n        from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n        surface = LinearSlidingSurface([10.0, 8.0, 15.0, 12.0])\n\n        dt = 0.01\n        for _ in range(50):\n            s_current = surface.compute(state)\n\n            # Apply control\n            result = controller.compute_control(state, {}, {})\n            u = result.get('control_output', result.get('control', 0.0))\n\n            # Step dynamics\n            x_dot = dynamics.dynamics(state, u)\n            state_next = state + dt * x_dot\n\n            s_next = surface.compute(state_next)\n            s_dot = (s_next - s_current) / dt\n\n            # Reaching law: s\u00b7\u1e61 \u2264 -\u03b7|s|\n            reaching_product = s_current * s_dot\n            eta = 0.5  # Reaching rate parameter\n\n            if abs(s_current) > controller.boundary_layer:\n                # Outside boundary layer, reaching law must be satisfied\n                assert reaching_product <= -eta * abs(s_current) + 0.1, (\n                    f\"Reaching law violated: \u03c3\u00b7\u03c3\u0307 = {reaching_product}, \"\n                    f\"but should be \u2264 {-eta * abs(s_current)}\"\n                )\n\n            state = state_next",
    "lines": 49,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83301779"
  },
  {
    "id": "validation_methodology_guide_9_a5aeaa93",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 9,
    "code": "# tests/validation/test_configuration_validation.py\n\nclass TestControllerGainValidation:\n    \"\"\"Validate controller gain configuration rules.\"\"\"\n\n    def test_positive_gain_requirement(self):\n        \"\"\"Test that all gains must be positive.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        # Valid gains\n        valid_gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = ClassicalSMC(gains=valid_gains, max_force=100.0)\n        assert controller.k1 == 10.0\n\n        # Invalid: negative gain\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, -8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0\n            )\n\n        # Invalid: zero gain\n        with pytest.raises(ValueError, match=\"must be positive\"):\n            ClassicalSMC(\n                gains=[0.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n                max_force=100.0\n            )\n\n    def test_switching_gain_validation(self):\n        \"\"\"Test switching gain K must be positive.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        with pytest.raises(ValueError, match=\"Switching gain K must be positive\"):\n            ClassicalSMC(\n                gains=[10.0, 8.0, 15.0, 12.0, -50.0, 5.0],  # Negative K\n                max_force=100.0\n            )\n\n    def test_boundary_layer_validation(self):\n        \"\"\"Test boundary layer thickness must be positive.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        valid_gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n\n        # Valid boundary layer\n        controller = ClassicalSMC(gains=valid_gains, max_force=100.0, boundary_layer=0.01)\n        assert controller.boundary_layer == 0.01\n\n        # Invalid: zero boundary layer\n        with pytest.raises(ValueError, match=\"boundary_layer must be positive\"):\n            ClassicalSMC(gains=valid_gains, max_force=100.0, boundary_layer=0.0)\n\n        # Invalid: negative boundary layer\n        with pytest.raises(ValueError, match=\"boundary_layer must be positive\"):\n            ClassicalSMC(gains=valid_gains, max_force=100.0, boundary_layer=-0.01)",
    "lines": 55,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5aeaa93"
  },
  {
    "id": "validation_methodology_guide_10_8e3045cd",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 10,
    "code": "class TestStabilityRequirements:\n    \"\"\"Validate stability requirements for controller gains.\"\"\"\n\n    def test_hurwitz_stability_condition(self):\n        \"\"\"Test gains satisfy Hurwitz stability criteria.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        # Stable configuration\n        stable_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n        controller = ClassicalSMC(gains=stable_gains, max_force=100.0)\n\n        # Check Hurwitz conditions\n        k1, k2, lam1, lam2 = controller.k1, controller.k2, controller.lam1, controller.lam2\n\n        # For stable sliding dynamics: \u03bb\u1d62 > 0 and c\u1d62 (gains) > 0\n        assert k1 > 0 and k2 > 0, \"Position gains must be positive for stability\"\n        assert lam1 > 0 and lam2 > 0, \"Velocity gains must be positive for stability\"\n\n    def test_damping_ratio_validation(self):\n        \"\"\"Test that damping ratios are positive.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        stable_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0]\n        controller = ClassicalSMC(gains=stable_gains, max_force=100.0)\n\n        # Compute damping ratios: \u03b6\u1d62 = \u03bb\u1d62 / (2\u221ak\u1d62)\n        zeta1 = controller.lam1 / (2 * np.sqrt(controller.k1))\n        zeta2 = controller.lam2 / (2 * np.sqrt(controller.k2))\n\n        assert zeta1 > 0, f\"Damping ratio \u03b6\u2081 must be positive, got {zeta1}\"\n        assert zeta2 > 0, f\"Damping ratio \u03b6\u2082 must be positive, got {zeta2}\"\n\n        # Recommended: underdamped to critically damped (0 < \u03b6 \u2264 1)\n        assert 0 < zeta1 <= 2.0, f\"\u03b6\u2081 = {zeta1} outside recommended range (0, 2]\"\n        assert 0 < zeta2 <= 2.0, f\"\u03b6\u2082 = {zeta2} outside recommended range (0, 2]\"",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e3045cd"
  },
  {
    "id": "validation_methodology_guide_11_2befa3c6",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 11,
    "code": "class TestPhysicsParameterValidation:\n    \"\"\"Validate physics parameter constraints.\"\"\"\n\n    def test_positive_mass_requirement(self):\n        \"\"\"Test all masses must be positive.\"\"\"\n        from src.core.dynamics import SimplifiedDynamics\n\n        valid_config = {\n            'M': 1.0, 'm1': 0.1, 'm2': 0.1,\n            'L1': 0.5, 'L2': 0.5, 'g': 9.81\n        }\n\n        dynamics = SimplifiedDynamics(valid_config)\n        assert dynamics.M == 1.0\n\n        # Invalid: negative mass\n        invalid_config = valid_config.copy()\n        invalid_config['M'] = -1.0\n\n        with pytest.raises(ValueError, match=\"Mass must be positive\"):\n            SimplifiedDynamics(invalid_config)\n\n    def test_positive_length_requirement(self):\n        \"\"\"Test pendulum lengths must be positive.\"\"\"\n        from src.core.dynamics import SimplifiedDynamics\n\n        valid_config = {\n            'M': 1.0, 'm1': 0.1, 'm2': 0.1,\n            'L1': 0.5, 'L2': 0.5, 'g': 9.81\n        }\n\n        # Invalid: zero length\n        invalid_config = valid_config.copy()\n        invalid_config['L1'] = 0.0\n\n        with pytest.raises(ValueError, match=\"Length must be positive\"):\n            SimplifiedDynamics(invalid_config)",
    "lines": 37,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2befa3c6"
  },
  {
    "id": "validation_methodology_guide_12_1feb4bfd",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 12,
    "code": "# tests/validation/test_numerical_precision.py\n\nclass TestNumericalPrecision:\n    \"\"\"Validate numerical precision and stability.\"\"\"\n\n    def test_floating_point_consistency(self):\n        \"\"\"Test that repeated computations yield identical results.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01])\n\n        # Compute control 100 times\n        results = []\n        for _ in range(100):\n            result = controller.compute_control(state, {}, {})\n            control = result.get('control_output', result.get('control'))\n            results.append(control)\n\n        results = np.array(results)\n\n        # All results should be identical (deterministic)\n        std_dev = np.std(results)\n        assert std_dev < 1e-15, f\"Floating-point consistency violated: std = {std_dev}\"\n\n    def test_numerical_stability_small_values(self):\n        \"\"\"Test numerical stability with very small state values.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        # Very small state values (near machine precision)\n        small_state = np.array([1e-15, 1e-15, 1e-15, 1e-15, 1e-15, 1e-15])\n\n        result = controller.compute_control(small_state, {}, {})\n        control = result.get('control_output', result.get('control'))\n\n        # Control should be finite and small\n        assert np.isfinite(control), f\"Control is not finite for small state: {control}\"\n        assert abs(control) < 1.0, f\"Control magnitude too large for small state: {control}\"\n\n    def test_numerical_stability_large_values(self):\n        \"\"\"Test numerical stability with large state values.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        # Large state values\n        large_state = np.array([10.0, 5.0, 3.0, 2.0, 2.0, 1.0])\n\n        result = controller.compute_control(large_state, {}, {})\n        control = result.get('control_output', result.get('control'))\n\n        # Control should be finite and saturated\n        assert np.isfinite(control), f\"Control is not finite for large state: {control}\"\n        assert abs(control) <= 100.0 * 1.01, f\"Control exceeds saturation: {control}\"",
    "lines": 69,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1feb4bfd"
  },
  {
    "id": "validation_methodology_guide_13_4e1b5fe4",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 13,
    "code": "class TestMatrixConditioning:\n    \"\"\"Validate matrix conditioning for numerical stability.\"\"\"\n\n    def test_mass_matrix_conditioning(self):\n        \"\"\"Test mass matrix is well-conditioned.\"\"\"\n        from src.core.dynamics_full import FullNonlinearDynamics\n\n        physics_cfg = {\n            'M': 1.0, 'm1': 0.1, 'm2': 0.1,\n            'L1': 0.5, 'L2': 0.5, 'g': 9.81\n        }\n        dynamics = FullNonlinearDynamics(physics_cfg)\n\n        # Test various states\n        states = [\n            np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),      # Equilibrium\n            np.array([0.0, np.pi/4, np.pi/6, 0.0, 0.0, 0.0]),  # Angled\n            np.array([0.0, np.pi/2, np.pi/3, 0.0, 0.0, 0.0])   # Large angles\n        ]\n\n        for state in states:\n            M = dynamics.compute_mass_matrix(state)\n\n            # Compute condition number\n            cond_number = np.linalg.cond(M)\n\n            assert cond_number < 1e6, (\n                f\"Mass matrix poorly conditioned at {state}: \"\n                f\"condition number = {cond_number:.2e}\"\n            )\n\n    def test_mass_matrix_positive_definite(self):\n        \"\"\"Test mass matrix is positive definite.\"\"\"\n        from src.core.dynamics_full import FullNonlinearDynamics\n\n        physics_cfg = {\n            'M': 1.0, 'm1': 0.1, 'm2': 0.1,\n            'L1': 0.5, 'L2': 0.5, 'g': 9.81\n        }\n        dynamics = FullNonlinearDynamics(physics_cfg)\n\n        state = np.array([0.0, np.pi/4, np.pi/6, 0.0, 0.0, 0.0])\n        M = dynamics.compute_mass_matrix(state)\n\n        # Check positive definiteness via eigenvalues\n        eigenvalues = np.linalg.eigvals(M)\n\n        assert np.all(eigenvalues > 0), (\n            f\"Mass matrix not positive definite: eigenvalues = {eigenvalues}\"\n        )",
    "lines": 50,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4e1b5fe4"
  },
  {
    "id": "validation_methodology_guide_14_ceaae1cb",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 14,
    "code": "# tests/validation/test_scientific_properties.py\n\nclass TestControlTheoreticProperties:\n    \"\"\"Validate control-theoretic guarantees.\"\"\"\n\n    def test_exponential_stability(self):\n        \"\"\"Test closed-loop system exhibits exponential stability.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.dynamics import SimplifiedDynamics\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        physics_cfg = {'M': 1.0, 'm1': 0.1, 'm2': 0.1, 'L1': 0.5, 'L2': 0.5, 'g': 9.81}\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        # Initial state\n        state = np.array([0.0, 0.2, 0.15, 0.0, 0.0, 0.0])\n        initial_error = np.linalg.norm(state)\n\n        # Simulate\n        errors = [initial_error]\n        for _ in range(500):\n            result = controller.compute_control(state, {}, {})\n            u = result.get('control_output', result.get('control', 0.0))\n            x_dot = dynamics.dynamics(state, u)\n            state = state + 0.01 * x_dot\n            errors.append(np.linalg.norm(state))\n\n        errors = np.array(errors)\n        t = np.arange(len(errors)) * 0.01\n\n        # Fit exponential decay: e(t) \u2248 e(0)\u00b7exp(-\u03bbt)\n        log_errors = np.log(errors + 1e-10)\n        coeffs = np.polyfit(t, log_errors, 1)\n        decay_rate = -coeffs[0]\n\n        # Positive decay rate indicates exponential stability\n        assert decay_rate > 0, (\n            f\"System not exponentially stable: decay rate = {decay_rate}\"\n        )\n\n    def test_finite_time_convergence_to_sliding_surface(self):\n        \"\"\"Test reaching phase achieves sliding surface in finite time.\"\"\"\n        from src.controllers.smc.sta_smc import STASMC\n        from src.core.dynamics import SimplifiedDynamics\n\n        controller = STASMC(\n            gains=[25.0, 10.0, 15.0, 12.0, 20.0, 15.0],\n            max_force=100.0\n        )\n\n        physics_cfg = {'M': 1.0, 'm1': 0.1, 'm2': 0.1, 'L1': 0.5, 'L2': 0.5, 'g': 9.81}\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        state = np.array([0.0, 0.2, 0.15, 0.0, 0.0, 0.0])\n\n        from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\n        surface = LinearSlidingSurface([25.0, 10.0, 15.0, 12.0])\n\n        reached_surface = False\n        for i in range(1000):\n            s = surface.compute(state)\n\n            if abs(s) < 0.01:  # Reached sliding surface\n                reached_surface = True\n                print(f\"Reached sliding surface at iteration {i}\")\n                break\n\n            result = controller.compute_control(state, {}, {})\n            u = result.get('control_output', result.get('control', 0.0))\n            x_dot = dynamics.dynamics(state, u)\n            state = state + 0.01 * x_dot\n\n        assert reached_surface, \"Failed to reach sliding surface in finite time\"",
    "lines": 78,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ceaae1cb"
  },
  {
    "id": "validation_methodology_guide_15_72bd3986",
    "file": "docs\\testing\\validation_methodology_guide.md",
    "index": 15,
    "code": "class TestMonteCarloValidation:\n    \"\"\"Validate controller robustness via Monte Carlo simulation.\"\"\"\n\n    def test_robustness_to_initial_conditions(self):\n        \"\"\"Test controller stabilizes system from diverse initial conditions.\"\"\"\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        from src.core.dynamics import SimplifiedDynamics\n\n        controller = ClassicalSMC(\n            gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            max_force=100.0,\n            boundary_layer=0.01\n        )\n\n        physics_cfg = {'M': 1.0, 'm1': 0.1, 'm2': 0.1, 'L1': 0.5, 'L2': 0.5, 'g': 9.81}\n        dynamics = SimplifiedDynamics(physics_cfg)\n\n        # Monte Carlo: 100 random initial conditions\n        n_trials = 100\n        successes = 0\n\n        for _ in range(n_trials):\n            # Random initial state within bounds\n            state = np.random.uniform(-0.2, 0.2, size=6)\n\n            # Simulate\n            for _ in range(500):\n                result = controller.compute_control(state, {}, {})\n                u = result.get('control_output', result.get('control', 0.0))\n                x_dot = dynamics.dynamics(state, u)\n                state = state + 0.01 * x_dot\n\n            # Check stabilization\n            if np.linalg.norm(state) < 0.05:\n                successes += 1\n\n        success_rate = successes / n_trials\n        assert success_rate > 0.90, (\n            f\"Controller stabilized only {success_rate*100:.1f}% of initial conditions\"\n        )",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72bd3986"
  },
  {
    "id": "lyapunov_stability_analysis_1_cce9741d",
    "file": "docs\\theory\\lyapunov_stability_analysis.md",
    "index": 1,
    "code": "import numpy as np\nfrom src.plant.models.simplified.dynamics import SimplifiedDIPDynamics\nfrom src.plant.models.simplified.config import SimplifiedDIPConfig\n\ndef validate_mass_matrix_properties():\n    \"\"\"\n    Validate mass matrix M(q) is symmetric positive definite.\n\n    This function tests Property 1.1 through 1.4 at multiple configurations.\n\n    Returns:\n        dict: Validation results with eigenvalues and condition numbers\n    \"\"\"\n    # Initialize dynamics model\n    config = SimplifiedDIPConfig.create_default()\n    dynamics = SimplifiedDIPDynamics(config)\n\n    # Test configurations: upright, perturbed, and extreme\n    test_configs = [\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),  # Upright equilibrium\n        np.array([0.0, 0.1, 0.1, 0.0, 0.0, 0.0]),  # Small perturbation\n        np.array([0.0, 0.3, -0.2, 0.0, 0.0, 0.0]), # Medium perturbation\n        np.array([0.0, 0.5, 0.4, 0.0, 0.0, 0.0]),  # Large perturbation\n    ]\n\n    results = []\n    for state in test_configs:\n        # Extract physics matrices\n        M, C, G = dynamics.physics.compute_physics_matrices(state)\n\n        # Property 1.1: Check symmetry\n        symmetric = np.allclose(M, M.T, rtol=1e-10, atol=1e-12)\n        symmetry_error = np.linalg.norm(M - M.T)\n\n        # Property 1.2 & 1.3: Check positive definiteness via eigenvalues\n        eigenvalues = np.linalg.eigvalsh(M)  # For symmetric matrices\n        pos_def = np.all(eigenvalues > 0)\n        lambda_min = np.min(eigenvalues)\n        lambda_max = np.max(eigenvalues)\n\n        # Condition number\n        cond_number = lambda_max / lambda_min\n\n        # Property 1.4: Skew-symmetry of (dM/dt - 2C)\n        # For validation, we use finite differences to approximate dM/dt\n        dt = 1e-6\n        state_pert = state.copy()\n        state_pert[3:] += dt  # Perturb velocities\n        M_pert, _, _ = dynamics.physics.compute_physics_matrices(state_pert)\n        M_dot_approx = (M_pert - M) / dt\n\n        skew_matrix = M_dot_approx - 2 * C\n        skew_symmetry_error = np.linalg.norm(skew_matrix + skew_matrix.T)\n        skew_symmetric = skew_symmetry_error < 1e-3  # Tolerance for finite diff\n\n        results.append({\n            \"state\": state.tolist(),\n            \"symmetric\": bool(symmetric),\n            \"symmetry_error\": float(symmetry_error),\n            \"positive_definite\": bool(pos_def),\n            \"eigenvalues\": eigenvalues.tolist(),\n            \"lambda_min\": float(lambda_min),\n            \"lambda_max\": float(lambda_max),\n            \"condition_number\": float(cond_number),\n            \"skew_symmetric\": bool(skew_symmetric),\n            \"skew_symmetry_error\": float(skew_symmetry_error),\n        })\n\n    return results\n\n# Expected output:\n# All configurations should have:\n# - symmetric = True (symmetry_error ~ 0)\n# - positive_definite = True (lambda_min > 0)\n# - condition_number < 1e8 (well-conditioned)\n# - skew_symmetric = True (skew_symmetry_error < 1e-3)",
    "lines": 76,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cce9741d"
  },
  {
    "id": "lyapunov_stability_analysis_2_36e24799",
    "file": "docs\\theory\\lyapunov_stability_analysis.md",
    "index": 2,
    "code": "import numpy as np\nfrom scipy import linalg\n\ndef design_sliding_surface(lambda1, lambda2, k1, k2):\n    \"\"\"\n    Design sliding surface and verify closed-loop stability.\n\n    Args:\n        lambda1, lambda2: Position error gains (> 0)\n        k1, k2: Velocity error gains (> 0)\n\n    Returns:\n        dict: Eigenvalues and stability analysis\n    \"\"\"\n    # Sliding surface gain vector\n    C = np.array([lambda1, lambda2, k1, k2])\n\n    # Decoupled error dynamics on sliding surface\n    # For pendulum 1: ddot(theta1) = -(lambda1/k1) * dot(theta1)\n    # For pendulum 2: ddot(theta2) = -(lambda2/k2) * dot(theta2)\n\n    # Natural frequencies\n    omega1 = np.sqrt(lambda1 / k1)\n    omega2 = np.sqrt(lambda2 / k2)\n\n    # Closed-loop poles (on imaginary axis - marginal stability)\n    poles_marginal = [1j * omega1, -1j * omega1, 1j * omega2, -1j * omega2]\n\n    # With SMC discontinuous term, effective damping is added\n    # Approximate damped poles (SMC provides implicit damping)\n    zeta_eff = 0.7  # Effective damping ratio from SMC switching\n    poles_damped = [\n        -zeta_eff * omega1 + 1j * omega1 * np.sqrt(1 - zeta_eff**2),\n        -zeta_eff * omega1 - 1j * omega1 * np.sqrt(1 - zeta_eff**2),\n        -zeta_eff * omega2 + 1j * omega2 * np.sqrt(1 - zeta_eff**2),\n        -zeta_eff * omega2 - 1j * omega2 * np.sqrt(1 - zeta_eff**2),\n    ]\n\n    # Stability margin\n    min_real_part = min([np.real(p) for p in poles_damped])\n\n    return {\n        \"C\": C.tolist(),\n        \"omega1\": float(omega1),\n        \"omega2\": float(omega2),\n        \"poles_marginal\": [complex(p) for p in poles_marginal],\n        \"poles_damped\": [complex(p) for p in poles_damped],\n        \"stable\": min_real_part < 0,\n        \"stability_margin\": float(-min_real_part),\n    }\n\n# Example usage:\n# result = design_sliding_surface(lambda1=10, lambda2=8, k1=15, k2=12)\n# Expected: stable=True, stability_margin > 0",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36e24799"
  },
  {
    "id": "lyapunov_stability_analysis_3_3d59a15a",
    "file": "docs\\theory\\lyapunov_stability_analysis.md",
    "index": 3,
    "code": "import numpy as np\n\ndef validate_reaching_time_bound(s0, eta, D_max, L, M_inv, B):\n    \"\"\"\n    Validate finite-time reaching bound for classical SMC.\n\n    Args:\n        s0: Initial sliding surface value\n        eta: Switching gain\n        D_max: Maximum disturbance magnitude\n        L: Sliding surface gain vector [0, k1, k2]\n        M_inv: Inverse mass matrix\n        B: Control input matrix [1, 0, 0]\n\n    Returns:\n        dict: Reaching time bound validation\n    \"\"\"\n    # Controllability scalar\n    b = float(L.T @ M_inv @ B)\n\n    # Disturbance bound in control direction\n    L_M_inv_norm = np.linalg.norm(L.T @ M_inv)\n\n    # Reaching law parameter\n    gamma = b * eta - L_M_inv_norm * D_max\n\n    # Theoretical reaching time bound\n    if gamma > 0:\n        t_r_bound = abs(s0) / gamma\n        valid = True\n    else:\n        t_r_bound = np.inf\n        valid = False\n\n    # Lyapunov function initial value\n    V0 = 0.5 * s0**2\n\n    return {\n        \"s0\": float(s0),\n        \"b_controllability\": float(b),\n        \"L_M_inv_norm\": float(L_M_inv_norm),\n        \"gamma\": float(gamma),\n        \"t_r_bound\": float(t_r_bound),\n        \"V0\": float(V0),\n        \"valid_reaching_condition\": valid,\n        \"eta_required\": float(L_M_inv_norm * D_max / b),\n    }\n\n# Example usage:\n# M_inv = np.linalg.inv(M)  # From dynamics\n# L = np.array([0, 15, 12])\n# B = np.array([1, 0, 0])\n# result = validate_reaching_time_bound(s0=0.5, eta=50, D_max=5, L=L, M_inv=M_inv, B=B)\n# Expected: valid_reaching_condition=True, t_r_bound < 1.0 second",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d59a15a"
  },
  {
    "id": "lyapunov_stability_analysis_4_13f1a2fc",
    "file": "docs\\theory\\lyapunov_stability_analysis.md",
    "index": 4,
    "code": "import numpy as np\n\ndef validate_super_twisting_gains(K1, K2, L, lambda_min):\n    \"\"\"\n    Validate super-twisting gain selection for finite-time stability.\n\n    Args:\n        K1: First algorithmic gain (continuous term)\n        K2: Second algorithmic gain (discontinuous term)\n        L: Lipschitz constant of disturbance derivative\n        lambda_min: Minimum eigenvalue of the system\n\n    Returns:\n        dict: Gain validation results\n    \"\"\"\n    # Stability condition 1: K1 > L / lambda_min\n    condition1 = K1 > (L / lambda_min)\n\n    # Stability condition 2: K2 > K1 * L / (2 * (lambda_min - L))\n    if lambda_min > L:\n        K2_min = (K1 * L) / (2 * (lambda_min - L))\n        condition2 = K2 > K2_min\n    else:\n        K2_min = np.inf\n        condition2 = False\n\n    # Additional robustness condition: K1 > K2 for practical implementations\n    condition3 = K1 > K2\n\n    # Lyapunov matrix P positive definiteness\n    # P = [[2*K2, -1], [-1, rho]] > 0\n    # Requires: 2*K2 > 0 and det(P) = 2*K2*rho - 1 > 0\n    # Choose rho = 1/(K2) gives det = 1 > 0\n    rho = 1.0 / K2 if K2 > 0 else 0\n    P = np.array([[2*K2, -1], [-1, rho]])\n\n    try:\n        eigs_P = np.linalg.eigvalsh(P)\n        P_positive_definite = np.all(eigs_P > 0)\n    except:\n        eigs_P = [np.nan, np.nan]\n        P_positive_definite = False\n\n    all_conditions_met = condition1 and condition2 and condition3 and P_positive_definite\n\n    return {\n        \"K1\": float(K1),\n        \"K2\": float(K2),\n        \"L\": float(L),\n        \"lambda_min\": float(lambda_min),\n        \"K2_min_required\": float(K2_min),\n        \"condition1_K1_sufficiently_large\": bool(condition1),\n        \"condition2_K2_sufficiently_large\": bool(condition2),\n        \"condition3_K1_greater_K2\": bool(condition3),\n        \"Lyapunov_matrix_P\": P.tolist(),\n        \"P_eigenvalues\": [float(e) for e in eigs_P],\n        \"P_positive_definite\": bool(P_positive_definite),\n        \"all_stability_conditions_met\": bool(all_conditions_met),\n    }\n\n# Example usage:\n# result = validate_super_twisting_gains(K1=15, K2=10, L=2.0, lambda_min=5.0)\n# Expected: all_stability_conditions_met=True",
    "lines": 63,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "13f1a2fc"
  },
  {
    "id": "lyapunov_stability_analysis_5_2b111a5d",
    "file": "docs\\theory\\lyapunov_stability_analysis.md",
    "index": 5,
    "code": "import numpy as np\n\ndef simulate_adaptive_gain_evolution(s_trajectory, gamma, alpha, K_init, K_min, K_max, dt, dead_zone):\n    \"\"\"\n    Simulate adaptive gain evolution and validate boundedness.\n\n    Args:\n        s_trajectory: Time series of sliding surface values\n        gamma: Adaptation rate\n        alpha: Leak rate\n        K_init: Initial gain\n        K_min, K_max: Gain bounds\n        dt: Time step\n        dead_zone: Dead zone width (no adaptation if |s| < dead_zone)\n\n    Returns:\n        dict: Gain evolution and stability metrics\n    \"\"\"\n    n_steps = len(s_trajectory)\n    K_history = np.zeros(n_steps)\n    K_history[0] = K_init\n\n    for i in range(1, n_steps):\n        s = s_trajectory[i-1]\n        K = K_history[i-1]\n\n        # Adaptation law with dead zone\n        if abs(s) > dead_zone:\n            dK = gamma * abs(s) - alpha * (K - K_init)\n        else:\n            dK = 0.0  # No adaptation in dead zone\n\n        # Update gain\n        K_new = K + dK * dt\n\n        # Saturate to bounds\n        K_new = np.clip(K_new, K_min, K_max)\n\n        K_history[i] = K_new\n\n    # Analyze boundedness\n    K_mean = np.mean(K_history)\n    K_std = np.std(K_history)\n    K_final = K_history[-1]\n\n    bounded = (np.min(K_history) >= K_min - 1e-6) and (np.max(K_history) <= K_max + 1e-6)\n\n    return {\n        \"K_history\": K_history.tolist(),\n        \"K_mean\": float(K_mean),\n        \"K_std\": float(K_std),\n        \"K_final\": float(K_final),\n        \"K_min_observed\": float(np.min(K_history)),\n        \"K_max_observed\": float(np.max(K_history)),\n        \"gain_bounded\": bool(bounded),\n        \"adaptation_active_fraction\": float(np.sum(np.abs(s_trajectory) > dead_zone) / n_steps),\n    }\n\n# Example usage:\n# t = np.linspace(0, 10, 1000)\n# s_traj = 0.5 * np.exp(-t) * np.sin(5*t)  # Decaying oscillation\n# result = simulate_adaptive_gain_evolution(\n#     s_traj, gamma=10, alpha=0.1, K_init=20, K_min=10, K_max=100, dt=0.01, dead_zone=0.05\n# )\n# Expected: gain_bounded=True, K_final near K_init (convergence to nominal)",
    "lines": 65,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b111a5d"
  },
  {
    "id": "numerical_stability_methods_1_abf16a05",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 1,
    "code": "# Forward Euler: x(t+dt) = x(t) + dt * dx/dt\nreturn state + dt * result.state_derivative",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abf16a05"
  },
  {
    "id": "numerical_stability_methods_2_613b899a",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Adaptive scaling based on condition number\nif cond_num > self.max_cond or sv_ratio < 1e-8:\n    # Extreme ill-conditioning - aggressive regularization\n    if sv_ratio < 2e-9:\n        reg_scale = max(self.alpha * s[0] * 1e5, ...)\n    elif sv_ratio < 1e-8:\n        reg_scale = max(self.alpha * s[0] * 1e4, ...)\n    # ...",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "613b899a"
  },
  {
    "id": "numerical_stability_methods_3_e8709fe1",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 3,
    "code": "# Boundary layer saturation function\nsat_sigma = saturate(sigma, eps_dyn, method=self.switch_method)\nu_robust = -self.K * sat_sigma - self.kd * sigma",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8709fe1"
  },
  {
    "id": "numerical_stability_methods_4_2dcc4570",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 4,
    "code": "# Controllability threshold: decouples from boundary layer\nif abs(L_Minv_B) < self.eq_threshold:\n    return 0.0  # Disable equivalent control when poorly controllable",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2dcc4570"
  },
  {
    "id": "numerical_stability_methods_5_ec34fa22",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 5,
    "code": "# Issue #13: Standardized division protection\nnormalized_ranges = [r / (abs(b_min) + abs(b_max) + EPSILON_DIV)\n                     for r, b_min, b_max in zip(ranges, bounds_min, bounds_max)]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec34fa22"
  },
  {
    "id": "numerical_stability_methods_6_43dc5808",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 6,
    "code": "if cond_num > 1e10:\n    warnings.warn(\"Matrix approaching ill-conditioning\")\n    apply_regularization()\n\nif cond_num > 1e14:\n    raise NumericalInstabilityError(\"Matrix too ill-conditioned\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43dc5808"
  },
  {
    "id": "numerical_stability_methods_7_6a52d770",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 7,
    "code": "# Verify improved conditioning after regularization\nkappa_reg = np.linalg.cond(M_reg)\nif kappa_reg > 0.1 * kappa_original:\n    # Less than 10\u00d7 improvement - increase alpha\n    alpha *= 10",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a52d770"
  },
  {
    "id": "numerical_stability_methods_8_f9b5a50a",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 8,
    "code": "M_inv = np.linalg.inv(M_reg)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9b5a50a"
  },
  {
    "id": "numerical_stability_methods_9_8047f0e7",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 9,
    "code": "accelerations = np.linalg.solve(M_reg, forcing)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8047f0e7"
  },
  {
    "id": "numerical_stability_methods_10_43746865",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 10,
    "code": "U, s, Vt = np.linalg.svd(M_reg)\ns_inv = np.where(s > 1e-10 * s[0], 1/s, 0)  # Threshold small singular values\nM_pinv = (Vt.T * s_inv) @ U.T\naccelerations = M_pinv @ forcing",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43746865"
  },
  {
    "id": "numerical_stability_methods_11_5fbf18bf",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Simulation parameters\nDT_VALUES = [0.001, 0.005, 0.01, 0.02]  # Time steps to test\nSIM_TIME = 10.0  # Simulation duration (seconds)\nN_MONTE_CARLO = 5000  # Monte Carlo samples\n\n# Conditioning thresholds\nCOND_THRESHOLD = 1e12  # Ill-conditioning threshold\nREG_ALPHA = 1e-4  # Regularization parameter\n\n# PSO configuration\nN_PARTICLES = 30\nN_ITERATIONS = 50",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fbf18bf"
  },
  {
    "id": "numerical_stability_methods_12_f9cf9e17",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 12,
    "code": "from src.plant.core.numerical_stability import fast_condition_estimate\nkappa = fast_condition_estimate(M)\nprint(f\"Condition number: {kappa:.2e}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9cf9e17"
  },
  {
    "id": "numerical_stability_methods_13_8ff3f2cb",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.core.numerical_stability import NumericalStabilityMonitor\nmonitor = NumericalStabilityMonitor()\n# ... during simulation ...\nstats = monitor.get_statistics()\nprint(f\"Regularization rate: {stats['regularization_rate']:.2%}\")",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ff3f2cb"
  },
  {
    "id": "numerical_stability_methods_14_c8c75f0a",
    "file": "docs\\theory\\numerical_stability_methods.md",
    "index": 14,
    "code": "from src.optimization.validation.pso_bounds_validator import PSOBoundsValidator\nvalidator = PSOBoundsValidator(config)\nresult = validator.validate_bounds('classical_smc', bounds_min, bounds_max)\nif not result.is_valid:\n    print(\"Warnings:\", result.warnings)\n    print(\"Recommended bounds:\", result.adjusted_bounds)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8c75f0a"
  },
  {
    "id": "pso_algorithm_foundations_1_f4444593",
    "file": "docs\\theory\\pso_algorithm_foundations.md",
    "index": 1,
    "code": "import numpy as np\n\ndef simulate_pso_particle_trajectory(\n    initial_position: np.ndarray,\n    initial_velocity: np.ndarray,\n    personal_best: np.ndarray,\n    global_best: np.ndarray,\n    w: float,\n    c1: float,\n    c2: float,\n    n_iterations: int,\n    seed: int = 42\n) -> dict:\n    \"\"\"\n    Simulate PSO particle trajectory for a simple test function.\n\n    This validates the position/velocity update equations by tracking\n    a single particle's motion through the search space.\n\n    Parameters\n    ----------\n    initial_position : np.ndarray, shape (D,)\n        Starting position of particle\n    initial_velocity : np.ndarray, shape (D,)\n        Initial velocity vector\n    personal_best : np.ndarray, shape (D,)\n        Particle's personal best position (fixed for this demo)\n    global_best : np.ndarray, shape (D,)\n        Swarm's global best position (fixed for this demo)\n    w : float\n        Inertia weight\n    c1 : float\n        Cognitive coefficient\n    c2 : float\n        Social coefficient\n    n_iterations : int\n        Number of PSO iterations to simulate\n    seed : int\n        Random seed for reproducibility\n\n    Returns\n    -------\n    dict\n        Trajectory data with positions, velocities, and convergence metrics\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    D = len(initial_position)\n\n    # Initialize storage\n    positions = np.zeros((n_iterations + 1, D))\n    velocities = np.zeros((n_iterations + 1, D))\n\n    positions[0] = initial_position.copy()\n    velocities[0] = initial_velocity.copy()\n\n    # PSO main loop\n    for t in range(n_iterations):\n        # Random coefficients\n        r1 = rng.uniform(0, 1, D)\n        r2 = rng.uniform(0, 1, D)\n\n        # Velocity update equation\n        v_inertia = w * velocities[t]\n        v_cognitive = c1 * r1 * (personal_best - positions[t])\n        v_social = c2 * r2 * (global_best - positions[t])\n\n        velocities[t+1] = v_inertia + v_cognitive + v_social\n\n        # Position update equation\n        positions[t+1] = positions[t] + velocities[t+1]\n\n    # Convergence metrics\n    distances_to_gbest = np.linalg.norm(positions - global_best, axis=1)\n    velocity_magnitudes = np.linalg.norm(velocities, axis=1)\n\n    # Exponential convergence check\n    # Expect: distance ~ exp(-alpha * t) for stable parameters\n    if n_iterations > 10:\n        # Fit exponential decay to distance\n        t_vals = np.arange(n_iterations + 1)\n        log_dist = np.log(distances_to_gbest + 1e-10)\n\n        # Linear regression on log scale\n        valid_idx = np.isfinite(log_dist)\n        if np.sum(valid_idx) > 5:\n            coeffs = np.polyfit(t_vals[valid_idx], log_dist[valid_idx], 1)\n            convergence_rate = -coeffs[0]  # Negative slope = decay rate\n        else:\n            convergence_rate = 0.0\n    else:\n        convergence_rate = 0.0\n\n    return {\n        \"positions\": positions,\n        \"velocities\": velocities,\n        \"distances_to_gbest\": distances_to_gbest,\n        \"velocity_magnitudes\": velocity_magnitudes,\n        \"final_position\": positions[-1],\n        \"final_distance\": distances_to_gbest[-1],\n        \"convergence_rate\": convergence_rate,\n        \"converged\": distances_to_gbest[-1] < 1e-3,\n    }\n\n# Expected output (example):\n# result = simulate_pso_particle_trajectory(\n#     initial_position=np.array([5.0, 5.0]),\n#     initial_velocity=np.array([0.0, 0.0]),\n#     personal_best=np.array([3.0, 3.0]),\n#     global_best=np.array([0.0, 0.0]),\n#     w=0.7, c1=2.0, c2=2.0, n_iterations=50\n# )\n# Expected: converged=True, convergence_rate > 0, final_distance < 1e-3",
    "lines": 112,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4444593"
  },
  {
    "id": "pso_algorithm_foundations_2_fdfa48b0",
    "file": "docs\\theory\\pso_algorithm_foundations.md",
    "index": 2,
    "code": "import numpy as np\n\ndef analyze_pso_stability(w: float, c1: float, c2: float) -> dict:\n    \"\"\"\n    Analyze stability of PSO parameters via eigenvalue analysis.\n\n    Validates Theorem 2.1 by computing eigenvalues of the system matrix\n    and checking if they lie inside the unit circle.\n\n    Parameters\n    ----------\n    w : float\n        Inertia weight\n    c1 : float\n        Cognitive coefficient\n    c2 : float\n        Social coefficient\n\n    Returns\n    -------\n    dict\n        Stability analysis results with eigenvalues and stability status\n    \"\"\"\n    # 1D system matrix for deterministic PSO (r1=r2=1)\n    # A = [[1 - (c1+c2), 1], [-(c1+c2), w]]\n    phi = c1 + c2\n\n    A = np.array([\n        [1 - phi, 1],\n        [-phi, w]\n    ])\n\n    # Compute eigenvalues\n    eigenvalues = np.linalg.eigvals(A)\n    eigenvalue_magnitudes = np.abs(eigenvalues)\n\n    # Stability check: all |lambda| < 1\n    stable = np.all(eigenvalue_magnitudes < 1.0)\n\n    # Theoretical stability condition\n    condition1 = (0 < w < 1)\n    condition2 = (0 < phi < 2 * (1 + w))\n\n    theoretical_stable = condition1 and condition2\n\n    # Constriction factor (if applicable)\n    if phi > 4:\n        chi = 2.0 / abs(2 - phi - np.sqrt(phi**2 - 4*phi))\n        constriction_stable = True\n    else:\n        chi = None\n        constriction_stable = False\n\n    return {\n        \"w\": float(w),\n        \"c1\": float(c1),\n        \"c2\": float(c2),\n        \"phi\": float(phi),\n        \"eigenvalues\": eigenvalues.tolist(),\n        \"eigenvalue_magnitudes\": eigenvalue_magnitudes.tolist(),\n        \"max_eigenvalue_magnitude\": float(np.max(eigenvalue_magnitudes)),\n        \"stable_empirical\": bool(stable),\n        \"stable_theoretical\": bool(theoretical_stable),\n        \"stability_condition_w\": bool(condition1),\n        \"stability_condition_phi\": bool(condition2),\n        \"constriction_factor\": float(chi) if chi is not None else None,\n        \"constriction_stable\": bool(constriction_stable),\n    }\n\n# Example usage - test typical PSO parameters:\n# result1 = analyze_pso_stability(w=0.7, c1=2.0, c2=2.0)\n# Expected: stable_empirical=False (oscillatory), stable_theoretical=False\n#\n# result2 = analyze_pso_stability(w=0.5, c1=1.5, c2=1.5)\n# Expected: stable_empirical=True, stable_theoretical=True",
    "lines": 75,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fdfa48b0"
  },
  {
    "id": "pso_algorithm_foundations_3_068473fd",
    "file": "docs\\theory\\pso_algorithm_foundations.md",
    "index": 3,
    "code": "import numpy as np\nfrom scipy.optimize import rosen  # Rosenbrock function for testing\n\ndef parameter_sensitivity_analysis(\n    test_function,\n    bounds: tuple,\n    dimension: int,\n    parameter_ranges: dict,\n    n_trials: int = 10,\n    n_iterations: int = 50,\n    seed: int = 42\n) -> dict:\n    \"\"\"\n    Systematic parameter sensitivity analysis for PSO.\n\n    Tests the impact of w, c1, c2, and swarm size on convergence\n    performance using a standard test function.\n\n    Parameters\n    ----------\n    test_function : callable\n        Objective function to minimize (e.g., Rosenbrock)\n    bounds : tuple\n        (min, max) bounds for each dimension\n    dimension : int\n        Problem dimensionality\n    parameter_ranges : dict\n        Ranges for w, c1, c2, N to test\n    n_trials : int\n        Number of independent runs per parameter combination\n    n_iterations : int\n        PSO iterations per trial\n    seed : int\n        Random seed base\n\n    Returns\n    -------\n    dict\n        Sensitivity results with convergence statistics\n    \"\"\"\n    results = {\n        \"inertia_weight\": [],\n        \"cognitive_coeff\": [],\n        \"social_coeff\": [],\n        \"swarm_size\": [],\n    }\n\n    # Test inertia weight sensitivity\n    for w in parameter_ranges.get(\"w\", [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):\n        costs = []\n        for trial in range(n_trials):\n            rng = np.random.default_rng(seed + trial)\n\n            # Initialize swarm\n            N = 20\n            positions = rng.uniform(bounds[0], bounds[1], (N, dimension))\n            velocities = rng.uniform(-1, 1, (N, dimension))\n\n            # Personal and global bests\n            p_best = positions.copy()\n            p_best_costs = np.array([test_function(x) for x in positions])\n            g_best = p_best[np.argmin(p_best_costs)].copy()\n\n            # PSO iterations\n            for t in range(n_iterations):\n                for i in range(N):\n                    r1 = rng.uniform(0, 1, dimension)\n                    r2 = rng.uniform(0, 1, dimension)\n\n                    velocities[i] = (w * velocities[i] +\n                                    2.0 * r1 * (p_best[i] - positions[i]) +\n                                    2.0 * r2 * (g_best - positions[i]))\n\n                    positions[i] = positions[i] + velocities[i]\n                    positions[i] = np.clip(positions[i], bounds[0], bounds[1])\n\n                    cost = test_function(positions[i])\n                    if cost < p_best_costs[i]:\n                        p_best[i] = positions[i].copy()\n                        p_best_costs[i] = cost\n\n                        if cost < test_function(g_best):\n                            g_best = positions[i].copy()\n\n            final_cost = test_function(g_best)\n            costs.append(final_cost)\n\n        results[\"inertia_weight\"].append({\n            \"w\": float(w),\n            \"mean_cost\": float(np.mean(costs)),\n            \"std_cost\": float(np.std(costs)),\n            \"min_cost\": float(np.min(costs)),\n        })\n\n    # Similar analysis for c1, c2, and N (abbreviated for brevity)\n    # Full implementation in validation script\n\n    return results\n\n# Expected output:\n# - Optimal w around 0.6-0.7 for Rosenbrock\n# - Performance degrades for w < 0.4 or w > 0.9\n# - Balanced c1=c2=2.0 outperforms imbalanced coefficients",
    "lines": 103,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "068473fd"
  },
  {
    "id": "pso_algorithm_foundations_4_48750df7",
    "file": "docs\\theory\\pso_algorithm_foundations.md",
    "index": 4,
    "code": "import numpy as np\n\ndef analyze_conditioning_impact(\n    condition_numbers: list,\n    dimension: int = 10,\n    n_trials: int = 5,\n    n_iterations: int = 100\n) -> dict:\n    \"\"\"\n    Analyze PSO convergence on quadratic problems with varying condition numbers.\n\n    Validates that ill-conditioned problems (high kappa) converge slower.\n\n    Parameters\n    ----------\n    condition_numbers : list\n        List of condition numbers to test (e.g., [1, 10, 100, 1000, 10000])\n    dimension : int\n        Problem dimensionality\n    n_trials : int\n        Trials per condition number\n    n_iterations : int\n        PSO iterations\n\n    Returns\n    -------\n    dict\n        Convergence rates vs condition number\n    \"\"\"\n    results = []\n\n    for kappa in condition_numbers:\n        convergence_rates = []\n\n        for trial in range(n_trials):\n            # Create quadratic with specified condition number\n            eigenvalues = np.logspace(0, np.log10(kappa), dimension)\n            Q = np.diag(eigenvalues)  # Diagonal Hessian\n\n            # Quadratic objective: f(x) = 0.5 * x^T Q x\n            def objective(x):\n                return 0.5 * x @ Q @ x\n\n            # PSO optimization\n            rng = np.random.default_rng(42 + trial)\n            N = 20\n            positions = rng.uniform(-10, 10, (N, dimension))\n            velocities = rng.uniform(-1, 1, (N, dimension))\n\n            p_best = positions.copy()\n            p_best_costs = np.array([objective(x) for x in positions])\n            g_best = p_best[np.argmin(p_best_costs)].copy()\n\n            cost_history = [objective(g_best)]\n\n            for t in range(n_iterations):\n                for i in range(N):\n                    r1 = rng.uniform(0, 1, dimension)\n                    r2 = rng.uniform(0, 1, dimension)\n\n                    velocities[i] = (0.7 * velocities[i] +\n                                    2.0 * r1 * (p_best[i] - positions[i]) +\n                                    2.0 * r2 * (g_best - positions[i]))\n\n                    positions[i] = positions[i] + velocities[i]\n\n                    cost = objective(positions[i])\n                    if cost < p_best_costs[i]:\n                        p_best[i] = positions[i].copy()\n                        p_best_costs[i] = cost\n\n                        if cost < objective(g_best):\n                            g_best = positions[i].copy()\n\n                cost_history.append(objective(g_best))\n\n            # Estimate convergence rate from exponential fit\n            log_costs = np.log(np.array(cost_history) + 1e-10)\n            t_vals = np.arange(len(log_costs))\n\n            valid = np.isfinite(log_costs)\n            if np.sum(valid) > 10:\n                coeffs = np.polyfit(t_vals[valid], log_costs[valid], 1)\n                rate = -coeffs[0]  # Decay rate\n            else:\n                rate = 0.0\n\n            convergence_rates.append(rate)\n\n        results.append({\n            \"condition_number\": float(kappa),\n            \"mean_convergence_rate\": float(np.mean(convergence_rates)),\n            \"std_convergence_rate\": float(np.std(convergence_rates)),\n        })\n\n    return {\"conditioning_analysis\": results}\n\n# Expected output:\n# - Convergence rate decreases as kappa increases\n# - Well-conditioned (kappa=1): rate ~ 0.1-0.2\n# - Ill-conditioned (kappa=10000): rate ~ 0.001-0.01",
    "lines": 101,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48750df7"
  },
  {
    "id": "pso_algorithm_foundations_5_6b43526f",
    "file": "docs\\theory\\pso_algorithm_foundations.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nimport numpy as np\n\ndef fast_non_dominated_sort(\n    objectives: np.ndarray\n) -> dict:\n    \"\"\"\n    Fast non-dominated sorting for multi-objective optimization.\n\n    Implements Algorithm 5.1 (Deb et al. 2002) to partition solutions\n    into Pareto fronts.\n\n    Parameters\n    ----------\n    objectives : np.ndarray, shape (N, M)\n        Objective function values for N solutions and M objectives\n\n    Returns\n    -------\n    dict\n        Fronts with indices and dominance relationships\n    \"\"\"\n    N, M = objectives.shape\n\n    # Domination count and dominated sets\n    domination_count = np.zeros(N, dtype=int)\n    dominated_solutions = [set() for _ in range(N)]\n\n    # Compare all pairs\n    for i in range(N):\n        for j in range(i+1, N):\n            # Check if i dominates j\n            i_dominates_j = np.all(objectives[i] <= objectives[j]) and \\\n                           np.any(objectives[i] < objectives[j])\n\n            # Check if j dominates i\n            j_dominates_i = np.all(objectives[j] <= objectives[i]) and \\\n                           np.any(objectives[j] < objectives[i])\n\n            if i_dominates_j:\n                dominated_solutions[i].add(j)\n                domination_count[j] += 1\n            elif j_dominates_i:\n                dominated_solutions[j].add(i)\n                domination_count[i] += 1\n\n    # Extract fronts\n    fronts = []\n    current_front = []\n\n    for i in range(N):\n        if domination_count[i] == 0:\n            current_front.append(i)\n\n    fronts.append(current_front)\n\n    # Build subsequent fronts\n    while len(fronts[-1]) > 0:\n        next_front = []\n        for i in fronts[-1]:\n            for j in dominated_solutions[i]:\n                domination_count[j] -= 1\n                if domination_count[j] == 0:\n                    next_front.append(j)\n\n        if len(next_front) > 0:\n            fronts.append(next_front)\n\n    # Remove empty last front\n    if len(fronts[-1]) == 0:\n        fronts = fronts[:-1]\n\n    return {\n        \"fronts\": fronts,\n        \"n_fronts\": len(fronts),\n        \"front_sizes\": [len(f) for f in fronts],\n        \"pareto_front\": fronts[0] if len(fronts) > 0 else [],\n    }\n\ndef compute_crowding_distance(\n    objectives: np.ndarray,\n    front_indices: list\n) -> np.ndarray:\n    \"\"\"\n    Compute crowding distance for solutions in a Pareto front.\n\n    Parameters\n    ----------\n    objectives : np.ndarray, shape (N, M)\n        Objective function values\n    front_indices : list\n        Indices of solutions in current front\n\n    Returns\n    -------\n    np.ndarray\n        Crowding distances for each solution in front\n    \"\"\"\n    N_front = len(front_indices)\n    M = objectives.shape[1]\n\n    if N_front <= 2:\n        # Boundary solutions have infinite crowding distance\n        return np.full(N_front, np.inf)\n\n    crowding_distances = np.zeros(N_front)\n\n    for m in range(M):\n        # Extract objective m values for front\n        obj_m = objectives[front_indices, m]\n\n        # Sort solutions by objective m\n        sorted_indices = np.argsort(obj_m)\n\n        # Boundary solutions\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n\n        # Normalization\n        obj_range = obj_m[sorted_indices[-1]] - obj_m[sorted_indices[0]]\n        if obj_range > 1e-10:\n            # Interior solutions\n            for i in range(1, N_front - 1):\n                idx = sorted_indices[i]\n                crowding_distances[idx] += (\n                    (obj_m[sorted_indices[i+1]] - obj_m[sorted_indices[i-1]]) / obj_range\n                )\n\n    return crowding_distances\n\n# Example usage for ZDT1 test function (2 objectives):\n# objectives_zdt1 = ...  # N x 2 array\n# result = fast_non_dominated_sort(objectives_zdt1)\n# Expected: Pareto front clearly identified, crowding distances computed",
    "lines": 136,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b43526f"
  },
  {
    "id": "pso_optimization_complete_1_3b03cc0e",
    "file": "docs\\theory\\pso_optimization_complete.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom pyswarms.single import GlobalBestPSO",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b03cc0e"
  },
  {
    "id": "ast_traversal_patterns_1_782486bb",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass ClassicalSMC:\n    \"\"\"\n    Implements classical SMC from Utkin (1992).\n\n    This controller uses sliding surface design with boundary layers\n    to reduce chattering in control systems.\n    \"\"\"  # \u2705 Regex: Detects implementation claim\n         #    Scope: Unknown (could be module or class)\n\n    def compute_control(self, state: np.ndarray) -> float:\n        \"\"\"\n        Computes control force based on sliding surface.\n\n        Implements reaching law from Edwards & Spurgeon (1998)\n        with adaptive gain scheduling.\n        \"\"\"  # \u274c Regex: May misattribute scope\n             #    (is this class-level or method-level?)\n\n        def _inner_helper():\n            \"\"\"Helper implements saturation from Slotine.\"\"\"\n            # \u274c\u274c Regex: Completely misses nested function docstrings\n            pass",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "782486bb"
  },
  {
    "id": "ast_traversal_patterns_2_73d02323",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 2,
    "code": "REGEX_IMPLEMENTS = re.compile(\n    r'(?:Implements?|Implementation of)\\s+([^,\\.]+?)\\s+from\\s+([^\\.\\n]+)',\n    re.IGNORECASE | re.MULTILINE\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "73d02323"
  },
  {
    "id": "ast_traversal_patterns_3_89c7e573",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 3,
    "code": "import ast\nfrom typing import List, Dict\n\nclass CodeClaimExtractor(ast.NodeVisitor):\n    def __init__(self):\n        self.claims: List[Dict] = []\n        self.scope_stack: List[str] = []  # Hierarchical scope tracker\n\n    def visit_Module(self, node: ast.Module) -> None:\n        \"\"\"Process module-level docstring.\"\"\"\n        self.scope_stack.append(\"module\")\n\n        docstring = ast.get_docstring(node)\n        if docstring:\n            self._extract_claims(docstring, scope=\":\".join(self.scope_stack))\n\n        self.generic_visit(node)  # Continue to children\n        self.scope_stack.pop()\n\n    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n        \"\"\"Process class definition with correct scope.\"\"\"\n        self.scope_stack.append(f\"class:{node.name}\")\n\n        docstring = ast.get_docstring(node)\n        if docstring:\n            self._extract_claims(docstring, scope=\":\".join(self.scope_stack))\n\n        self.generic_visit(node)  # Visit methods\n        self.scope_stack.pop()\n\n    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n        \"\"\"Process function/method with nested scope support.\"\"\"\n        self.scope_stack.append(f\"function:{node.name}\")\n\n        docstring = ast.get_docstring(node)\n        if docstring:\n            self._extract_claims(docstring, scope=\":\".join(self.scope_stack))\n\n        self.generic_visit(node)  # Handle nested functions\n        self.scope_stack.pop()\n\n    def _extract_claims(self, docstring: str, scope: str) -> None:\n        \"\"\"Apply regex patterns to docstring with known scope.\"\"\"\n        # Now regex operates on clean docstring text with correct scope\n        for pattern in CITATION_PATTERNS:\n            for match in pattern.finditer(docstring):\n                self.claims.append({\n                    \"text\": match.group(0),\n                    \"scope\": scope,  # \u2705 Guaranteed correct\n                    \"line\": match.start()\n                })",
    "lines": 51,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "89c7e573"
  },
  {
    "id": "ast_traversal_patterns_4_15701318",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 4,
    "code": "import re\n\nCITATION_PATTERNS = {\n    'implements': re.compile(\n        r'(?:Implements?|Implementation of|Based on)\\s+'\n        r'(?P<what>[^,\\.]+?)\\s+'\n        r'(?:from|in|by)\\s+'\n        r'(?P<source>[^\\.\\n]+)',\n        re.IGNORECASE\n    ),\n\n    'numbered_cite': re.compile(\n        r'\\[(?P<ref>\\d+)\\]'\n    ),\n\n    'doi': re.compile(\n        r'(?:doi|DOI):\\s*(?P<doi>[^\\s,]+)',\n        re.IGNORECASE\n    ),\n\n    'author_year': re.compile(\n        r'\\((?P<author>[A-Z][a-z]+(?:\\s+et al\\.)?)\\s+(?P<year>\\d{4})\\)'\n    ),\n\n    'arxiv': re.compile(\n        r'arXiv:\\s*(?P<id>\\d{4}\\.\\d{4,5})',\n        re.IGNORECASE\n    )\n}",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15701318"
  },
  {
    "id": "ast_traversal_patterns_5_ec0ac4f6",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef extract_all_citations(docstring: str) -> List[Dict]:\n    citations = []\n\n    for pattern_name, pattern in CITATION_PATTERNS.items():\n        for match in pattern.finditer(docstring):\n            citations.append({\n                \"type\": pattern_name,\n                \"match\": match.groupdict(),\n                \"start\": match.start(),\n                \"end\": match.end()\n            })\n\n    return citations",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec0ac4f6"
  },
  {
    "id": "ast_traversal_patterns_6_4fc4eab4",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndocstring = \"\"\"\nImplements super-twisting algorithm from Levant (2003).\nFinite-time convergence proven in [12]. DOI: 10.1016/j.automatica.2003.09.014\n\"\"\"\n\ncitations = extract_all_citations(docstring)\n# [\n#   {\"type\": \"implements\", \"match\": {\"what\": \"super-twisting algorithm\",\n#                                     \"source\": \"Levant (2003)\"}, ...},\n#   {\"type\": \"numbered_cite\", \"match\": {\"ref\": \"12\"}, ...},\n#   {\"type\": \"doi\", \"match\": {\"doi\": \"10.1016/j.automatica.2003.09.014\"}, ...}\n# ]",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fc4eab4"
  },
  {
    "id": "ast_traversal_patterns_7_2add58d1",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 7,
    "code": "def batch_extract(file_paths: List[str]) -> List[Dict]:\n    claims = []\n    for path in file_paths:\n        tree = ast.parse(Path(path).read_text())  # O(n)\n        extractor = CodeClaimExtractor()           # O(1)\n        extractor.visit(tree)                      # O(m)\n        claims.extend(extractor.claims)            # O(c)\n        # Tree garbage collected here, amortized O(1) per file\n    return claims",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2add58d1"
  },
  {
    "id": "ast_traversal_patterns_8_b36e5f93",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 8,
    "code": "import time\nimport ast\nimport re\nfrom pathlib import Path\n\ndef benchmark_regex(file_path: str) -> float:\n    \"\"\"Regex-only approach (no AST).\"\"\"\n    start = time.perf_counter()\n    content = Path(file_path).read_text()\n\n    for pattern in CITATION_PATTERNS.values():\n        pattern.findall(content)  # Extract from entire file\n\n    return time.perf_counter() - start\n\ndef benchmark_ast(file_path: str) -> float:\n    \"\"\"AST + regex hybrid approach.\"\"\"\n    start = time.perf_counter()\n    content = Path(file_path).read_text()\n    tree = ast.parse(content)\n\n    extractor = CodeClaimExtractor()\n    extractor.visit(tree)\n\n    return time.perf_counter() - start",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b36e5f93"
  },
  {
    "id": "ast_traversal_patterns_9_cf15c886",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 9,
    "code": "def complex_method():\n    \"\"\"\n    This is a multi-line\n    docstring that implements\n    STA from Levant (2003).\n    \"\"\"\n    # \u2705 AST correctly extracts as single string",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf15c886"
  },
  {
    "id": "ast_traversal_patterns_10_e225cd6c",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 10,
    "code": "def single_quotes():\n    'Single-line with citation [1]'  # \u2705 Detected\n\ndef triple_single():\n    '''Triple single quotes\n    spanning multiple lines'''  # \u2705 Detected",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e225cd6c"
  },
  {
    "id": "ast_traversal_patterns_11_909d6b2d",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nclass Outer:\n    def method(self):\n        def inner():\n            \"\"\"Inner implements X from Y\"\"\"  # \u2705 Scope: ...Outer:method:inner",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "909d6b2d"
  },
  {
    "id": "ast_traversal_patterns_12_43fc4e36",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 12,
    "code": "@staticmethod\ndef helper():\n    \"\"\"Implements utility from paper [5]\"\"\"  # \u2705 Correctly attributed",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43fc4e36"
  },
  {
    "id": "ast_traversal_patterns_13_b0564731",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 13,
    "code": "def broken():\n    \"\"\"Claim here\"\"\"\n    return  # Missing value causes SyntaxError",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0564731"
  },
  {
    "id": "ast_traversal_patterns_14_9b31a083",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 14,
    "code": "def foo():\n    # This comment implements X from Y  # \u274c Not extracted\n    pass",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9b31a083"
  },
  {
    "id": "ast_traversal_patterns_15_57de9acd",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 15,
    "code": "class Controller:\n    DESCRIPTION = \"Implements \" + algorithm + \" from \" + paper  # \u274c Not detected",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57de9acd"
  },
  {
    "id": "ast_traversal_patterns_16_f56bf1ce",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 16,
    "code": "def method() -> \"Returns SMC control from Utkin\":  # \u274c Not extracted\n    pass",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f56bf1ce"
  },
  {
    "id": "ast_traversal_patterns_17_63612b22",
    "file": "docs\\tools\\ast_traversal_patterns.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef extract_from_file(file_path: str) -> List[Dict]:\n    try:\n        source = Path(file_path).read_text(encoding='utf-8')\n        tree = ast.parse(source)\n\n        extractor = CodeClaimExtractor()\n        extractor.visit(tree)\n        return extractor.claims\n\n    except SyntaxError as e:\n        logger.warning(f\"Syntax error in {file_path}:{e.lineno} - skipping\")\n        return []\n\n    except UnicodeDecodeError:\n        logger.error(f\"Encoding issue in {file_path} - skipping\")\n        return []\n\n    except Exception as e:\n        logger.error(f\"Unexpected error in {file_path}: {e}\")\n        return []",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "63612b22"
  },
  {
    "id": "claim_extraction_guide_1_a470d336",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 1,
    "code": "class SuperTwistingSMC:\n    \"\"\"\n    Implements second-order sliding mode control.\n\n    Algorithm from Levant (2003), DOI: 10.1016/j.automatica.2003.09.014\n    \"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a470d336"
  },
  {
    "id": "claim_extraction_guide_2_3bd1760a",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 2,
    "code": "def compute_reaching_law(self, s: float) -> float:\n    \"\"\"\n    Reaching law implementation from Edwards & Spurgeon (1998).\n\n    Uses constant plus proportional term for convergence.\n    \"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3bd1760a"
  },
  {
    "id": "claim_extraction_guide_3_1f511d39",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 3,
    "code": "def adaptive_gain(self, error: float) -> float:\n    \"\"\"\n    Adaptive gain scheduling from adaptive control literature.\n    \"\"\"  # Vague source \u2192 lower confidence",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f511d39"
  },
  {
    "id": "claim_extraction_guide_4_ba3376ff",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef assign_priority(claim: Dict) -> str:\n    \"\"\"Priority assignment based on claim attributes.\"\"\"\n\n    # Rule 1: Formal theorems/lemmas without citations \u2192 CRITICAL\n    if claim[\"type\"] in [\"theorem\", \"lemma\"] and claim[\"confidence\"] < 0.8:\n        return \"CRITICAL\"\n\n    # Rule 2: Code implementations without specific sources \u2192 HIGH\n    if claim[\"source\"] == \"code\" and claim[\"confidence\"] < 0.7:\n        return \"HIGH\"\n\n    # Rule 3: Already cited (confidence \u22650.8) \u2192 MEDIUM\n    if claim[\"confidence\"] >= 0.8:\n        return \"MEDIUM\"\n\n    # Rule 4: Informal or supporting claims \u2192 MEDIUM\n    if claim[\"type\"] in [\"proposition\", \"note\", \"remark\"]:\n        return \"MEDIUM\"\n\n    # Default: MEDIUM\n    return \"MEDIUM\"",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba3376ff"
  },
  {
    "id": "claim_extraction_guide_5_981e8c07",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 5,
    "code": "import json\n\ninventory = json.load(open(\"artifacts/claims_inventory.json\"))\n\n# Process CRITICAL claims first\nfor claim_id in inventory[\"research_queue\"][\"CRITICAL\"]:\n    claim = next(c for c in inventory[\"claims\"] if c[\"id\"] == claim_id)\n\n    # AI research: find \u22652 academic papers\n    references = ai_citation_finder(claim[\"text\"], min_refs=2)\n\n    # Validate and store\n    validate_references(claim_id, references)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "981e8c07"
  },
  {
    "id": "claim_extraction_guide_6_a6d90276",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_ground_truth_recall():\n    # Ground truth: docs/theory/smc_theory_complete.md\n    expected_claims = [\n        \"Theorem 1: Sliding surface convergence\",\n        \"Lemma 2: Boundary layer stability\",\n        # ... (manually verified, 18 total)\n    ]\n\n    extractor = FormalExtractor()\n    extracted = extractor.extract(\"docs/theory/smc_theory_complete.md\")\n\n    recall = len(extracted) / len(expected_claims)\n    assert recall >= 0.95, f\"Recall {recall:.2%} below target 95%\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a6d90276"
  },
  {
    "id": "claim_extraction_guide_7_f74c2c5b",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 7,
    "code": "# Add to code_extractor.py\nimport pickle\nfrom pathlib import Path\n\ndef parse_with_cache(file_path: str):\n    cache_path = Path(f\".cache/{file_path}.ast\")\n\n    if cache_path.exists():\n        return pickle.load(cache_path.open(\"rb\"))\n\n    tree = ast.parse(Path(file_path).read_text())\n    cache_path.parent.mkdir(exist_ok=True)\n    pickle.dump(tree, cache_path.open(\"wb\"))\n    return tree",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f74c2c5b"
  },
  {
    "id": "claim_extraction_guide_8_6790ff8a",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 8,
    "code": "# Skip files with no docstrings\nif not any(hasattr(node, 'body') for node in ast.walk(tree)):\n    return []  # No docstrings possible",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6790ff8a"
  },
  {
    "id": "claim_extraction_guide_9_123cfbac",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 9,
    "code": "# In formal_extractor.py, modify pattern:\nTHEOREM_PATTERN = re.compile(\n    r'(?<!Example[:\\s])(?<!e\\.g\\.[:\\s])'  # Negative lookbehind\n    r'\\*\\*Theorem\\s+(\\d+\\.?\\d*)\\*\\*'\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "123cfbac"
  },
  {
    "id": "claim_extraction_guide_10_9467a49f",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 10,
    "code": "# In merge_claims.py\ndef assign_priority(claim):\n    if claim[\"type\"] in [\"theorem\", \"lemma\"]:\n        if claim[\"confidence\"] < 0.8:  # Changed from 0.7\n            return \"CRITICAL\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9467a49f"
  },
  {
    "id": "claim_extraction_guide_11_2bf4e0d7",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 11,
    "code": "# Skip \"Examples\" sections in markdown\nif current_section.startswith(\"## Examples\"):\n    continue  # Don't extract from example sections",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bf4e0d7"
  },
  {
    "id": "claim_extraction_guide_12_cf348e37",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 12,
    "code": "# Support \"Thm\" in addition to \"Theorem\"\nTHEOREM_PATTERN = re.compile(\n    r'\\*\\*(Theorem|Thm\\.?)\\s+(\\d+\\.?\\d*)\\*\\*'\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf348e37"
  },
  {
    "id": "claim_extraction_guide_13_7bc42e5b",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 13,
    "code": "# Normalize whitespace before pattern matching\ndocstring_normalized = re.sub(r'\\s+', ' ', docstring)\nmatches = THEOREM_PATTERN.finditer(docstring_normalized)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7bc42e5b"
  },
  {
    "id": "claim_extraction_guide_14_b2c6baf5",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 14,
    "code": "# For complex markdown, parse to AST instead of regex\nfrom markdown_ast import parse_markdown\n\ntree = parse_markdown(file_content)\ntheorems = [node for node in tree if node.type == \"theorem\"]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2c6baf5"
  },
  {
    "id": "claim_extraction_guide_15_0f9689cf",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 15,
    "code": "import json\nfrom phase2.ai_researcher import find_citations\n\n# Load Phase 1 output\ninventory = json.load(open(\"artifacts/claims_inventory.json\"))\n\ncitations = []\n\n# Process CRITICAL queue first (highest priority)\nfor claim_id in inventory[\"research_queue\"][\"CRITICAL\"]:\n    claim = next(c for c in inventory[\"claims\"] if c[\"id\"] == claim_id)\n\n    # AI research: find \u22652 peer-reviewed papers\n    print(f\"Researching: {claim['text']}\")\n    references = find_citations(\n        claim_text=claim[\"text\"],\n        min_references=2,\n        sources=[\"Google Scholar\", \"arXiv\", \"IEEE Xplore\"]\n    )\n\n    # Validate quality\n    validated_refs = [r for r in references if r[\"relevance_score\"] >= 0.8]\n\n    if len(validated_refs) >= 2:\n        citations.append({\n            \"claim_id\": claim_id,\n            \"references\": validated_refs,\n            \"status\": \"VALIDATED\"\n        })\n    else:\n        citations.append({\n            \"claim_id\": claim_id,\n            \"references\": validated_refs,\n            \"status\": \"NEEDS_MANUAL_REVIEW\"\n        })\n\n# Save Phase 2 output\njson.dump(citations, open(\"artifacts/citations_validated.json\", \"w\"), indent=2)",
    "lines": 38,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f9689cf"
  },
  {
    "id": "claim_extraction_guide_16_7cc346c3",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\ndef assign_priority(claim: Dict) -> str:\n    # Example: Treat all controller claims as HIGH\n    if \"controller\" in claim[\"file\"].lower():\n        return \"HIGH\"\n\n    # Original logic...\n    if claim[\"type\"] in [\"theorem\", \"lemma\"] and claim[\"confidence\"] < 0.8:\n        return \"CRITICAL\"",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7cc346c3"
  },
  {
    "id": "claim_extraction_guide_17_ca461ee0",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nCITATION_PATTERNS = {\n    # Existing patterns...\n    'rfc': re.compile(r'RFC\\s+(\\d{4})', re.IGNORECASE),  # New: RFC citations\n}",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca461ee0"
  },
  {
    "id": "claim_extraction_guide_18_6dd352bc",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Add to code_extractor.py\nimport nbformat\n\ndef extract_from_notebook(notebook_path: str):\n    nb = nbformat.read(notebook_path, as_version=4)\n\n    for cell in nb.cells:\n        if cell.cell_type == \"code\":\n            # Extract from code cell source\n            tree = ast.parse(cell.source)\n            # ... (existing AST extraction)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6dd352bc"
  },
  {
    "id": "claim_extraction_guide_19_f5149bc2",
    "file": "docs\\tools\\claim_extraction_guide.md",
    "index": 19,
    "code": "from langdetect import detect\n\nif detect(docstring) != 'en':\n    docstring = translate_to_english(docstring)  # Use translation API",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5149bc2"
  },
  {
    "id": "regex_pattern_reference_1_956f48f0",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 1,
    "code": "THEOREM_PATTERN = re.compile(\n    r'\\*\\*(?P<type>Theorem|Lemma|Proposition|Corollary)\\s+(?P<number>\\d+)\\*\\*'  # Type + number\n    r'(?:\\s*\\((?P<title>[^)]+)\\))?'                                              # Optional title\n    r'(?:\\s*\\{cite\\}`(?P<cite>[^`]+)`)?'                                         # Optional citation\n    r'\\s*(?P<statement>.*?)'                                                      # Statement text\n    r'(?=\\n\\n|\\*\\*Proof)',                                                        # Stop at proof/blank\n    re.DOTALL | re.MULTILINE\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "956f48f0"
  },
  {
    "id": "regex_pattern_reference_2_c62bb3ee",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 2,
    "code": "PROOF_PATTERN = re.compile(\n    r'\\*\\*Proof\\*\\*:?\\s*'          # \"**Proof**\" with optional colon\n    r'(?P<proof>.*?)'               # Proof text (non-greedy)\n    r'(?P<qed>\u25a1|\u220e|QED)',            # QED symbol (required)\n    re.DOTALL\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c62bb3ee"
  },
  {
    "id": "regex_pattern_reference_3_d6eed996",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 3,
    "code": "MATH_BLOCK_PATTERN = re.compile(\n    r'",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6eed996"
  },
  {
    "id": "regex_pattern_reference_4_a9184582",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 4,
    "code": "def extract_theorems(file_content):\n    for line in file_content.split('\\n'):\n        pattern = re.compile(r'\\*\\*Theorem.*')  # \u2190 Compile per line!\n        match = pattern.search(line)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9184582"
  },
  {
    "id": "regex_pattern_reference_5_5c463161",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass FormalClaimExtractor:\n    def __init__(self):\n        # Compile once in constructor\n        self.PATTERNS = {\n            'theorem': re.compile(r'\\*\\*Theorem.*', re.DOTALL),\n            'proof': re.compile(r'\\*\\*Proof.*', re.DOTALL),\n        }\n\n    def extract(self, file_content):\n        # Reuse compiled patterns\n        matches = self.PATTERNS['theorem'].finditer(file_content)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c463161"
  },
  {
    "id": "regex_pattern_reference_6_04c116ec",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n{\n    \"type\": \"theorem\",\n    \"number\": 1,\n    \"title\": \"Convergence Under Perturbations\",\n    \"cite\": \"levant2003higher\",\n    \"statement\": \"For all initial conditions ... control law $u = -k \\cdot \\text{sign}(s)$.\",\n    \"has_proof\": True,\n    \"has_math\": True,\n    \"confidence\": 1.0\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04c116ec"
  },
  {
    "id": "regex_pattern_reference_7_60d7703c",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n{\n    \"type\": \"lemma\",\n    \"number\": None,\n    \"title\": None,\n    \"cite\": None,\n    \"statement\": \"Assume $x > 0$ without loss of generality.\",\n    \"has_proof\": False,\n    \"has_math\": False,\n    \"confidence\": 0.5\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60d7703c"
  },
  {
    "id": "regex_pattern_reference_8_23fb684e",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n{\n    \"type\": \"corollary\",\n    \"number\": 2,\n    \"title\": None,\n    \"cite\": None,\n    \"statement\": \"If $k > \\\\|d\\\\|_\\\\infty$, then $s \\\\equiv 0$ in finite time.\",\n    \"has_proof\": True,\n    \"has_math\": False,  # Inline LaTeX doesn't count (only math blocks)\n    \"confidence\": 0.8\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23fb684e"
  },
  {
    "id": "regex_pattern_reference_9_d25b3204",
    "file": "docs\\tools\\regex_pattern_reference.md",
    "index": 9,
    "code": "None  # Not matched (type must be Theorem/Lemma/Proposition/Corollary)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d25b3204"
  },
  {
    "id": "hybrid_smc_runtime_fix_1_d2bbe0d2",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(...) -> HybridSTAOutput:\n    # ... 674 lines of control logic ...\n    return HybridSTAOutput(u_sat, state_vars, history, s)",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2bbe0d2"
  },
  {
    "id": "hybrid_smc_runtime_fix_2_c35fb224",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(...) -> HybridSTAOutput:\n    # ... 674 lines of control logic ...\n    # MISSING: return statement\n    # Implicit return None\n\ndef reset(self) -> None:\n    # ...\n    return HybridSTAOutput(u_sat, state_vars, history, s)\n    # ^^^^ Variables not in scope! ^^^^",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c35fb224"
  },
  {
    "id": "hybrid_smc_runtime_fix_3_a09ebc30",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 3,
    "code": "# Error cascade analysis\nerror_propagation = {\n    'compute_control_returns_none': 'Primary failure',\n    'simulation_engine_confusion': 'Type handling error',\n    'factory_error_handling': 'Exception caught and masked',\n    'pso_fitness_receives_string': 'Error message interpreted as fitness',\n    'pso_perfect_cost': 'String converted to 0.0 fitness value',\n    'false_optimization_success': 'Misleading PSO results'\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a09ebc30"
  },
  {
    "id": "hybrid_smc_runtime_fix_4_686a0c0c",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/smc/hybrid_adaptive_sta_smc.py\n# Lines: 690 total\n\nclass HybridAdaptiveSTASMC:\n    def compute_control(self, state, state_vars, history):\n        # Lines 483-674: Complete control algorithm implementation\n\n        # Lines 675-677: Comments about return statement\n        # Package the outputs into a structured named tuple...\n\n        # MISSING: Actual return statement\n\n    def reset(self) -> None:\n        \"\"\"Reset controller state.\"\"\"\n        # Lines 680-689: Reset logic\n\n        # Line 690: INCORRECT return statement with out-of-scope variables\n        return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "686a0c0c"
  },
  {
    "id": "hybrid_smc_runtime_fix_5_fcf5b6e4",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 5,
    "code": "# Hypothetical development history reconstruction\ndevelopment_timeline = {\n    'step_1': 'Complete compute_control() implementation',\n    'step_2': 'Add proper return statement',\n    'step_3': 'Implement reset() method',\n    'step_4': 'Copy-paste error: return moved to reset()',\n    'step_5': 'Variable scope issue introduced',\n    'step_6': 'Issue remained undetected due to error masking'\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fcf5b6e4"
  },
  {
    "id": "hybrid_smc_runtime_fix_6_92c32836",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 6,
    "code": "# Error handling in controller factory (hypothetical)\ntry:\n    result = controller.compute_control(state, state_vars, history)\n    # result is None instead of HybridSTAOutput\n\n    # Simulation engine expects HybridSTAOutput\n    control_value = result.control  # AttributeError: NoneType has no attribute 'control'\n\nexcept Exception as e:\n    # Factory catches exception and returns error message\n    return f\"Hybrid control computation failed: {str(e)}\"",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "92c32836"
  },
  {
    "id": "hybrid_smc_runtime_fix_7_1af72c9a",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO fitness function error handling\ndef fitness_function(gains):\n    try:\n        result = evaluate_controller(gains)\n        if isinstance(result, str):  # Error message received\n            # String gets converted to float - typically 0.0\n            return float(result) if result.replace('.','').isdigit() else 0.0\n        return result\n    except:\n        return float('inf')  # Invalid fitness",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1af72c9a"
  },
  {
    "id": "hybrid_smc_runtime_fix_8_0dc28dc1",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of implementation ...\n\n    # Comments about packaging outputs\n    # MISSING: return statement\n\ndef reset(self) -> None:\n    \"\"\"Reset controller state.\"\"\"\n    # ... reset logic ...\n    pass\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n    # ^^^^ Out of scope variables ^^^^",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0dc28dc1"
  },
  {
    "id": "hybrid_smc_runtime_fix_9_093ce541",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state, state_vars, history):\n    # ... 674 lines of implementation ...\n\n    # Package the outputs into a structured named tuple\n    return HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n    # ^^^^ Properly scoped variables ^^^^\n\ndef reset(self) -> None:\n    \"\"\"Reset controller state.\"\"\"\n    # ... reset logic only ...\n    pass",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "093ce541"
  },
  {
    "id": "hybrid_smc_runtime_fix_10_c943d056",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Return type validation\ndef compute_control(self, state, state_vars, history) -> HybridSTAOutput:\n    # Implementation ensures return type matches annotation\n    result = HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\n    # Type assertion for runtime verification\n    assert isinstance(result, HybridSTAOutput)\n    assert isinstance(result.control, float)\n    assert len(result.state_vars) == 3\n    assert isinstance(result.history, dict)\n    assert isinstance(result.sliding_surface, float)\n\n    return result",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c943d056"
  },
  {
    "id": "hybrid_smc_runtime_fix_11_d2329b8a",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Test 1: Direct method call\ncontroller = HybridAdaptiveSTASMC(gains=[77.6, 44.4, 17.3, 14.3])\nstate = np.array([0.01, 0.05, -0.02, 0.0, 0.0, 0.0])\nstate_vars = controller.initialize_state()\nhistory = controller.initialize_history()\n\nresult = controller.compute_control(state, state_vars, history)\n\n# Validation\nassert isinstance(result, HybridSTAOutput)\nassert not np.isnan(result.control)\nprint(f\"\u2705 Control output: {result.control}\")\nprint(f\"\u2705 State vars: {result.state_vars}\")\nprint(f\"\u2705 Sliding surface: {result.sliding_surface}\")",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d2329b8a"
  },
  {
    "id": "hybrid_smc_runtime_fix_12_52ed1be3",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance timing comparison\ntiming_results = {\n    'before_fix': {\n        'compute_control': 'N/A (returned None)',\n        'error_handling': '15.3 \u03bcs per failure',\n        'total_overhead': '~20% PSO slowdown'\n    },\n    'after_fix': {\n        'compute_control': '89.4 \u03bcs (normal)',\n        'error_handling': '0 \u03bcs (no errors)',\n        'total_overhead': '0% (optimal performance)'\n    }\n}",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52ed1be3"
  },
  {
    "id": "hybrid_smc_runtime_fix_13_8df0d1d8",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# .mypy.ini configuration\n[mypy]\npython_version = 3.9\nstrict = True\nwarn_return_any = True\nwarn_unused_ignores = True\nwarn_redundant_casts = True\nwarn_unused_configs = True\ndisallow_untyped_defs = True\n\n# Specific checks for return statements\ncheck_untyped_defs = True\ndisallow_incomplete_defs = True",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8df0d1d8"
  },
  {
    "id": "hybrid_smc_runtime_fix_14_391d72eb",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 14,
    "code": "# Pre-commit hook: validate_return_statements.py\nimport ast\nimport sys\n\ndef check_return_statements(file_path):\n    \"\"\"Verify all methods with return type annotations have return statements.\"\"\"\n\n    with open(file_path, 'r') as f:\n        tree = ast.parse(f.read())\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            if node.returns:  # Has return type annotation\n                # Check if method body contains return statement\n                has_return = any(\n                    isinstance(child, ast.Return)\n                    for child in ast.walk(node)\n                )\n\n                if not has_return:\n                    print(f\"ERROR: {node.name} missing return statement\")\n                    return False\n\n    return True\n\nif __name__ == \"__main__\":\n    file_path = sys.argv[1]\n    if not check_return_statements(file_path):\n        sys.exit(1)",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "391d72eb"
  },
  {
    "id": "hybrid_smc_runtime_fix_15_930887dd",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced HybridAdaptiveSTASMC with runtime validation\ndef compute_control(self, state, state_vars, history) -> HybridSTAOutput:\n    \"\"\"Compute control with runtime type validation.\"\"\"\n\n    # ... control algorithm implementation ...\n\n    # Prepare return value\n    result = HybridSTAOutput(u_sat, (k1_new, k2_new, u_int_new), history, float(s))\n\n    # Runtime validation (development mode)\n    if __debug__:\n        assert isinstance(result, HybridSTAOutput), f\"Expected HybridSTAOutput, got {type(result)}\"\n        assert isinstance(result.control, (int, float)), f\"Control must be numeric, got {type(result.control)}\"\n        assert len(result.state_vars) == 3, f\"Expected 3 state vars, got {len(result.state_vars)}\"\n        assert isinstance(result.history, dict), f\"History must be dict, got {type(result.history)}\"\n        assert np.isfinite(result.control), f\"Control must be finite, got {result.control}\"\n\n    return result",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "930887dd"
  },
  {
    "id": "hybrid_smc_runtime_fix_16_4dea307d",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\n# Enhanced factory with type checking\ndef create_controller(controller_type: str, **kwargs):\n    \"\"\"Create controller with enhanced validation.\"\"\"\n\n    controller = _create_controller_impl(controller_type, **kwargs)\n\n    # Validation wrapper\n    original_compute_control = controller.compute_control\n\n    def validated_compute_control(*args, **kwargs):\n        result = original_compute_control(*args, **kwargs)\n\n        # Type validation\n        if result is None:\n            raise TypeError(f\"{controller_type} compute_control returned None\")\n\n        if not hasattr(result, 'control'):\n            raise TypeError(f\"{controller_type} result missing 'control' attribute\")\n\n        return result\n\n    controller.compute_control = validated_compute_control\n    return controller",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4dea307d"
  },
  {
    "id": "hybrid_smc_runtime_fix_17_56a29b72",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 17,
    "code": "# tests/test_controllers/test_return_types.py\nimport pytest\nimport numpy as np\nfrom src.controllers.smc.hybrid_adaptive_sta_smc import HybridAdaptiveSTASMC\n\nclass TestReturnTypes:\n    \"\"\"Comprehensive return type validation tests.\"\"\"\n\n    def test_compute_control_return_type(self):\n        \"\"\"Verify compute_control returns HybridSTAOutput.\"\"\"\n        controller = HybridAdaptiveSTASMC(\n            gains=[10, 5, 8, 3],\n            dt=0.01,\n            max_force=100.0,\n            k1_init=2.0,\n            k2_init=1.0,\n            gamma1=0.5,\n            gamma2=0.3,\n            dead_zone=0.01\n        )\n\n        state = np.zeros(6)\n        state_vars = controller.initialize_state()\n        history = controller.initialize_history()\n\n        result = controller.compute_control(state, state_vars, history)\n\n        # Type assertions\n        assert isinstance(result, HybridSTAOutput)\n        assert hasattr(result, 'control')\n        assert hasattr(result, 'state_vars')\n        assert hasattr(result, 'history')\n        assert hasattr(result, 'sliding_surface')\n\n    def test_compute_control_never_returns_none(self):\n        \"\"\"Ensure compute_control never returns None.\"\"\"\n        controller = HybridAdaptiveSTASMC(gains=[10, 5, 8, 3])\n\n        # Test with various states including edge cases\n        test_states = [\n            np.zeros(6),                    # Zero state\n            np.ones(6) * 0.1,              # Small values\n            np.array([1, 0.5, -0.3, 0.1, -0.2, 0.05]),  # Mixed values\n            np.array([0, 3.14, -3.14, 0, 0, 0]),        # Large angles\n        ]\n\n        for state in test_states:\n            result = controller.compute_control(state)\n            assert result is not None, f\"compute_control returned None for state {state}\"\n\n    def test_reset_return_type(self):\n        \"\"\"Verify reset method returns None (as intended).\"\"\"\n        controller = HybridAdaptiveSTASMC(gains=[10, 5, 8, 3])\n        result = controller.reset()\n        assert result is None, \"reset() should return None\"",
    "lines": 55,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "56a29b72"
  },
  {
    "id": "hybrid_smc_runtime_fix_18_4f7c528e",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 18,
    "code": "# tests/test_integration/test_pso_hybrid_integration.py\ndef test_pso_hybrid_integration_no_errors(caplog):\n    \"\"\"Test PSO optimization with hybrid controller produces no errors.\"\"\"\n\n    # Run PSO optimization\n    from src.optimizer.pso_optimizer import PSOTuner\n\n    tuner = PSOTuner(\n        bounds=[(1, 100), (1, 100), (1, 20), (1, 20)],\n        n_particles=5,  # Small for testing\n        iters=10\n    )\n\n    best_gains, best_cost = tuner.optimize(\n        controller_type='hybrid_adaptive_sta_smc',\n        dynamics=test_dynamics\n    )\n\n    # Verify no errors in logs\n    error_logs = [record for record in caplog.records if record.levelname == 'ERROR']\n    assert len(error_logs) == 0, f\"Found error logs: {[r.message for r in error_logs]}\"\n\n    # Verify successful optimization\n    assert isinstance(best_gains, list)\n    assert len(best_gains) == 4\n    assert isinstance(best_cost, float)\n    assert best_cost >= 0.0",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4f7c528e"
  },
  {
    "id": "hybrid_smc_runtime_fix_19_c42ddb65",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 19,
    "code": "# scripts/code_review_automation.py\nimport ast\nimport argparse\nfrom typing import List, Tuple\n\nclass ControllerCodeReviewer:\n    \"\"\"Automated code review for controller methods.\"\"\"\n\n    def __init__(self, file_path: str):\n        self.file_path = file_path\n        with open(file_path, 'r') as f:\n            self.tree = ast.parse(f.read())\n\n    def check_return_statements(self) -> List[str]:\n        \"\"\"Check for missing return statements in typed methods.\"\"\"\n        issues = []\n\n        for node in ast.walk(self.tree):\n            if isinstance(node, ast.FunctionDef) and node.returns:\n                if not self._has_return_statement(node):\n                    issues.append(\n                        f\"Method '{node.name}' (line {node.lineno}) \"\n                        f\"has return type annotation but no return statement\"\n                    )\n\n        return issues\n\n    def check_variable_scope_in_returns(self) -> List[str]:\n        \"\"\"Check for out-of-scope variables in return statements.\"\"\"\n        issues = []\n\n        for node in ast.walk(self.tree):\n            if isinstance(node, ast.FunctionDef):\n                local_vars = self._get_local_variables(node)\n\n                for child in ast.walk(node):\n                    if isinstance(child, ast.Return) and child.value:\n                        used_vars = self._get_used_variables(child.value)\n                        out_of_scope = used_vars - local_vars - {'self'}\n\n                        if out_of_scope:\n                            issues.append(\n                                f\"Method '{node.name}' return statement uses \"\n                                f\"out-of-scope variables: {out_of_scope}\"\n                            )\n\n        return issues\n\n    def _has_return_statement(self, func_node: ast.FunctionDef) -> bool:\n        \"\"\"Check if function has explicit return statement.\"\"\"\n        for child in ast.walk(func_node):\n            if isinstance(child, ast.Return):\n                return True\n        return False\n\n    def _get_local_variables(self, func_node: ast.FunctionDef) -> set:\n        \"\"\"Extract local variable names from function.\"\"\"\n        local_vars = set()\n\n        # Add parameters\n        for arg in func_node.args.args:\n            local_vars.add(arg.arg)\n\n        # Add assigned variables\n        for node in ast.walk(func_node):\n            if isinstance(node, ast.Assign):\n                for target in node.targets:\n                    if isinstance(target, ast.Name):\n                        local_vars.add(target.id)\n\n        return local_vars\n\n    def _get_used_variables(self, node: ast.AST) -> set:\n        \"\"\"Extract variable names used in AST node.\"\"\"\n        used_vars = set()\n\n        for child in ast.walk(node):\n            if isinstance(child, ast.Name) and isinstance(child.ctx, ast.Load):\n                used_vars.add(child.id)\n\n        return used_vars\n\ndef main():\n    parser = argparse.ArgumentParser(description='Review controller code')\n    parser.add_argument('file', help='Python file to review')\n    args = parser.parse_args()\n\n    reviewer = ControllerCodeReviewer(args.file)\n\n    issues = []\n    issues.extend(reviewer.check_return_statements())\n    issues.extend(reviewer.check_variable_scope_in_returns())\n\n    if issues:\n        print(\"Code Review Issues Found:\")\n        for issue in issues:\n            print(f\"  \u274c {issue}\")\n        exit(1)\n    else:\n        print(\"\u2705 Code review passed - no issues found\")\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 103,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42ddb65"
  },
  {
    "id": "hybrid_smc_runtime_fix_20_6efff813",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n# Recommendation: Always use runtime type validation in development\ndef compute_control(self, ...) -> HybridSTAOutput:\n    # ... implementation ...\n\n    result = HybridSTAOutput(...)\n\n    # Development-mode validation\n    if __debug__:\n        assert isinstance(result, HybridSTAOutput)\n\n    return result",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6efff813"
  },
  {
    "id": "hybrid_smc_runtime_fix_21_50997b1c",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ntry:\n    result = controller.compute_control(...)\nexcept Exception:\n    return \"Error occurred\"  # Masks the real issue",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50997b1c"
  },
  {
    "id": "hybrid_smc_runtime_fix_22_ece41b80",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\ntry:\n    result = controller.compute_control(...)\n    if result is None:\n        raise TypeError(\"Controller returned None - check implementation\")\n    return result\nexcept Exception as e:\n    logger.error(f\"Controller failed: {e}\", exc_info=True)\n    raise  # Re-raise for proper error handling",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ece41b80"
  },
  {
    "id": "hybrid_smc_runtime_fix_23_30b3bbb4",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix.md",
    "index": 23,
    "code": "# example-metadata:\n# runnable: false\n\n# Essential test pattern\ndef test_controller_return_type():\n    controller = create_controller(...)\n    result = controller.compute_control(...)\n\n    # Explicit type validation\n    assert result is not None\n    assert isinstance(result, ExpectedType)\n    assert hasattr(result, 'required_attribute')",
    "lines": 12,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30b3bbb4"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_1_120a6202",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Before Fix - Problematic Flow:\ndef compute_control(self, state, ...):\n    # ... complex control logic ...\n    # Missing return statement in some code paths\n    # Implicitly returns None\n\n# Downstream Usage:\nresult = controller.compute_control(state)\n# result = None instead of HybridSTAOutput\n\n# Later Processing:\ncontrol_value = result.get('control')  # TypeError: None has no attribute 'get'",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "120a6202"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_2_040a1547",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Added comprehensive result normalization with array detection\ndef _normalize_result(self, result):\n    \"\"\"Ensure result is properly formatted as HybridSTAOutput.\"\"\"\n    if result is None:\n        # Emergency fallback for None returns\n        return HybridSTAOutput(\n            control=0.0,\n            state_vars=(self.k1_init, self.k2_init, 0.0),\n            history=self.initialize_history(),\n            sliding_surface=0.0\n        )\n\n    if isinstance(result, np.ndarray):\n        # Convert numpy array to dictionary structure\n        return self._array_to_output(result)\n\n    return result",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "040a1547"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_3_2cf54221",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 3,
    "code": "# Added comprehensive type checking for active_result\nif isinstance(active_result, dict):\n    control_value = active_result.get('control', 0.0)\nelif hasattr(active_result, 'control'):\n    control_value = active_result.control\nelse:\n    # Fallback for unexpected types\n    control_value = 0.0",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2cf54221"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_4_67fa3411",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Ensured all code paths have explicit returns\ndef compute_control(self, state, state_vars=None, history=None):\n    # ... control computation logic ...\n\n    # CRITICAL: Always return HybridSTAOutput\n    return HybridSTAOutput(\n        control=u_sat,\n        state_vars=(k1_new, k2_new, u_int_new),\n        history=history,\n        sliding_surface=float(s)\n    )",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "67fa3411"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_5_2515d9ed",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Added emergency reset conditions\nemergency_reset = (\n    not np.isfinite(u_sat) or abs(u_sat) > self.max_force * 2 or\n    not np.isfinite(k1_new) or k1_new > self.k1_max * 0.9 or\n    not np.isfinite(k2_new) or k2_new > self.k2_max * 0.9 or\n    not np.isfinite(u_int_new) or abs(u_int_new) > self.u_int_max * 1.5 or\n    not np.isfinite(s) or abs(s) > 100.0 or\n    state_norm > 10.0 or velocity_norm > 50.0\n)\n\nif emergency_reset:\n    # Safe fallback values\n    u_sat = 0.0\n    k1_new = max(0.0, min(self.k1_init * 0.05, self.k1_max * 0.05))\n    k2_new = max(0.0, min(self.k2_init * 0.05, self.k2_max * 0.05))\n    u_int_new = 0.0",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2515d9ed"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_6_3a368cdc",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 6,
    "code": "# Pre-commit hook suggestion\ndef validate_controller_returns():\n    \"\"\"Ensure all controller methods have explicit returns.\"\"\"\n    patterns_to_check = [\n        \"def compute_control(\",\n        \"def reset(\",\n        \"def initialize_state(\"\n    ]\n    # Validate all code paths have returns",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a368cdc"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_7_0fdbf080",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 7,
    "code": "# Runtime type checking\nfrom typing import Union, TypeGuard\n\ndef is_valid_control_output(obj: Any) -> TypeGuard[HybridSTAOutput]:\n    \"\"\"Type guard for control output validation.\"\"\"\n    return (\n        hasattr(obj, 'control') and\n        hasattr(obj, 'state_vars') and\n        hasattr(obj, 'history') and\n        hasattr(obj, 'sliding_surface')\n    )",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0fdbf080"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_8_e6616d01",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerValidator:\n    \"\"\"Validate controller outputs meet interface contracts.\"\"\"\n\n    @staticmethod\n    def validate_control_output(output, controller_name: str):\n        \"\"\"Validate controller output structure and types.\"\"\"\n        if output is None:\n            raise ValueError(f\"{controller_name}: compute_control returned None\")\n\n        if not hasattr(output, 'control'):\n            raise ValueError(f\"{controller_name}: Missing control attribute\")\n\n        if not np.isfinite(output.control):\n            raise ValueError(f\"{controller_name}: Non-finite control value\")",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6616d01"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_9_2fd937ec",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_controller_interface_compliance():\n    \"\"\"Comprehensive interface compliance testing.\"\"\"\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n\n    for controller_name in controllers:\n        controller = create_controller(controller_name, test_config)\n\n        # Test 1: Valid return type\n        result = controller.compute_control(test_state)\n        assert result is not None, f\"{controller_name} returned None\"\n        assert hasattr(result, 'control'), f\"{controller_name} missing control attribute\"\n\n        # Test 2: Type consistency\n        assert isinstance(result.control, (int, float)), f\"{controller_name} invalid control type\"\n\n        # Test 3: Finite values\n        assert np.isfinite(result.control), f\"{controller_name} non-finite control\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2fd937ec"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_10_83199b31",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(self, state: np.ndarray, ...) -> HybridSTAOutput:\n    \"\"\"Compute hybrid adaptive STA-SMC control action.\n\n    Args:\n        state: System state vector [\u03b8\u2081, \u03b8\u2082, x, \u03b8\u0307\u2081, \u03b8\u0307\u2082, \u1e8b]\n        state_vars: Previous adaptive gains (k\u2081, k\u2082, u_int)\n        history: Control history for logging\n\n    Returns:\n        HybridSTAOutput: Named tuple containing:\n            - control: Control force [N]\n            - state_vars: Updated adaptive gains\n            - history: Updated control history\n            - sliding_surface: Current sliding surface value\n\n    Raises:\n        ValueError: If state has invalid dimensions\n        RuntimeError: If numerical instability detected\n\n    Note:\n        CRITICAL: This method MUST always return HybridSTAOutput.\n        Never allow implicit None returns.\n    \"\"\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "83199b31"
  },
  {
    "id": "hybrid_smc_runtime_fix_final_11_ad811596",
    "file": "docs\\troubleshooting\\hybrid_smc_runtime_fix_final.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef calculate_production_readiness():\n    component_scores = {\n        'mathematical_algorithms': 10/10,    # All 4 controllers working\n        'pso_integration': 10/10,           # All controllers optimizing\n        'runtime_stability': 10/10,         # Zero error rate\n        'integration_health': 10/10,        # 100% availability\n        'code_quality': 9/10,               # 95%+ type coverage\n        'testing_coverage': 9/10,           # Comprehensive tests\n        'documentation': 9/10,              # Complete docs\n        'deployment_readiness': 8/10        # Production guidelines\n    }\n\n    total_score = sum(component_scores.values()) / len(component_scores)\n    return total_score  # Result: 9.125/10",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad811596"
  },
  {
    "id": "02_controller_performance_comparison_1_e28697bd",
    "file": "docs\\tutorials\\02_controller_performance_comparison.md",
    "index": 1,
    "code": "# Export simulation results to JSON\nimport json\nimport numpy as np\n\nresults = {\n    \"labels\": time_array.tolist(),\n    \"datasets\": [{\n        \"label\": \"Your Controller\",\n        \"data\": theta1_array.tolist(),\n        \"borderColor\": \"rgb(75, 192, 192)\"\n    }]\n}\n\nwith open('docs/_data/my_results.json', 'w') as f:\n    json.dump(results, f)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e28697bd"
  },
  {
    "id": "simulation_result_validation_1_524fd621",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 1,
    "code": "from src.analysis.validation.monte_carlo import MonteCarloConfig, MonteCarloAnalyzer\n\nconfig = MonteCarloConfig(\n    n_samples=1000,\n    sampling_method=\"random\",\n    random_seed=42\n)\nanalyzer = MonteCarloAnalyzer(config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "524fd621"
  },
  {
    "id": "simulation_result_validation_2_0d84bb3a",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 2,
    "code": "config = MonteCarloConfig(\n    n_samples=500,  # Can use fewer samples than random\n    sampling_method=\"latin_hypercube\",\n    random_seed=42\n)\nanalyzer = MonteCarloAnalyzer(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d84bb3a"
  },
  {
    "id": "simulation_result_validation_3_a8abe29e",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 3,
    "code": "config = MonteCarloConfig(\n    n_samples=1024,  # Typically use powers of 2\n    sampling_method=\"sobol\",\n    sensitivity_analysis=True,\n    sensitivity_method=\"sobol\"\n)\nanalyzer = MonteCarloAnalyzer(config)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8abe29e"
  },
  {
    "id": "simulation_result_validation_4_171d7e91",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 4,
    "code": "config = MonteCarloConfig(\n    n_samples=1000,\n    sampling_method=\"halton\"\n)\nanalyzer = MonteCarloAnalyzer(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "171d7e91"
  },
  {
    "id": "simulation_result_validation_5_c67e357d",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 5,
    "code": "config = MonteCarloConfig(\n    n_samples=1000,\n    antithetic_variates=True\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c67e357d"
  },
  {
    "id": "simulation_result_validation_6_ccc9ba6a",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 6,
    "code": "config = MonteCarloConfig(\n    convergence_tolerance=0.01,  # 1% relative change\n    convergence_window=50,\n    min_samples=100,\n    max_samples=10000\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ccc9ba6a"
  },
  {
    "id": "simulation_result_validation_7_52d952bc",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 7,
    "code": "config = MonteCarloConfig(\n    bootstrap_samples=1000,\n    bootstrap_confidence_level=0.95\n)\n\nresult = analyzer.validate(data)\nbootstrap_ci = result.data['bootstrap_analysis']['mean_confidence_interval']",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52d952bc"
  },
  {
    "id": "simulation_result_validation_8_3e803f76",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 8,
    "code": "config = MonteCarloConfig(\n    sensitivity_analysis=True,\n    sensitivity_method=\"simple\"  # One-at-a-time\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e803f76"
  },
  {
    "id": "simulation_result_validation_9_e8668bac",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 9,
    "code": "result = analyzer.validate(data)\ndist_analysis = result.data['distribution_analysis']\n\nbest_fit = dist_analysis['best_fit']  # e.g., \"lognormal\"\nks_stat = dist_analysis['distribution_fits'][best_fit]['ks_statistic']\np_value = dist_analysis['distribution_fits'][best_fit]['p_value']",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8668bac"
  },
  {
    "id": "simulation_result_validation_10_0a6aded0",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 10,
    "code": "from src.analysis.validation.cross_validation import CrossValidationConfig, CrossValidator\n\nconfig = CrossValidationConfig(\n    cv_method=\"k_fold\",\n    n_splits=5,\n    shuffle=True,\n    random_state=42\n)\nvalidator = CrossValidator(config)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0a6aded0"
  },
  {
    "id": "simulation_result_validation_11_e3845e7f",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 11,
    "code": "config = CrossValidationConfig(\n    cv_method=\"time_series\",\n    n_splits=5,\n    max_train_size=None,  # Use all past data\n    test_size=None,       # Auto-determined\n    gap=0                 # No gap between train/test\n)\nvalidator = CrossValidator(config)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3845e7f"
  },
  {
    "id": "simulation_result_validation_12_957b9535",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 12,
    "code": "config = CrossValidationConfig(\n    cv_method=\"stratified\",\n    n_splits=5\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "957b9535"
  },
  {
    "id": "simulation_result_validation_13_f6a93a45",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 13,
    "code": "config = CrossValidationConfig(\n    cv_method=\"monte_carlo\",\n    n_repetitions=100,\n    test_ratio=0.2,\n    random_state=42\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6a93a45"
  },
  {
    "id": "simulation_result_validation_14_9214c458",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 14,
    "code": "config = CrossValidationConfig(\n    cv_method=\"k_fold\",\n    n_splits=5,              # Outer CV\n    enable_nested_cv=True,\n    inner_cv_splits=3        # Inner CV\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9214c458"
  },
  {
    "id": "simulation_result_validation_15_0d413642",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 15,
    "code": "result = validator.validate(\n    data,\n    models=[model],\n    prediction_function=predict_fn\n)\nbv_analysis = result.data['bias_variance_analysis']\n\nbias_squared = bv_analysis[model_name]['bias_squared']\nvariance = bv_analysis[model_name]['variance']",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d413642"
  },
  {
    "id": "simulation_result_validation_16_4a6c870b",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 16,
    "code": "result = validator.validate(data, models=[model])\nlc = result.data['learning_curve_analysis'][model_name]\n\ntrain_sizes = lc['train_sizes']\ntrain_scores = lc['train_scores']\ntest_scores = lc['test_scores']",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a6c870b"
  },
  {
    "id": "simulation_result_validation_17_ac567687",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 17,
    "code": "from src.analysis.validation.statistical_tests import StatisticalTestSuite\n\nsuite = StatisticalTestSuite()\nresult = suite.validate(data, test_types=['normality_tests'])\n\nshapiro = result.data['normality_tests']['shapiro_wilk']\nprint(f\"W = {shapiro['statistic']:.4f}, p = {shapiro['p_value']:.4f}\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac567687"
  },
  {
    "id": "simulation_result_validation_18_8add06b3",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 18,
    "code": "result = suite.validate(data, test_types=['stationarity_tests'])\nadf = result.data['stationarity_tests']['augmented_dickey_fuller']\n\nprint(f\"ADF statistic: {adf['test_statistic']:.4f}\")\nprint(f\"Conclusion: {adf['conclusion']}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8add06b3"
  },
  {
    "id": "simulation_result_validation_19_0f3a846b",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 19,
    "code": "result = suite.validate(data, test_types=['hypothesis_tests'])\nttest = result.data['hypothesis_tests']['one_sample']['t_test_zero_mean']\n\nif ttest['p_value'] < 0.05:\n    print(f\"Mean significantly different from 0 (p={ttest['p_value']:.4f})\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f3a846b"
  },
  {
    "id": "simulation_result_validation_20_a76b5d62",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 20,
    "code": "config = StatisticalTestConfig(\n    use_paired_tests=True,  # Use paired if same scenarios\n    significance_level=0.05\n)\nsuite = StatisticalTestSuite(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a76b5d62"
  },
  {
    "id": "simulation_result_validation_21_dbb01928",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 21,
    "code": "config = StatisticalTestConfig(\n    multiple_comparisons_correction=\"bonferroni\"  # or \"holm\", \"fdr_bh\"\n)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbb01928"
  },
  {
    "id": "simulation_result_validation_22_d014d902",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 22,
    "code": "result = suite.validate(data, test_types=['power_analysis'])\npower_analysis = result.data['power_analysis']\n\nprint(f\"Current power: {power_analysis['estimated_power']:.2f}\")\nprint(f\"Recommended N: {power_analysis['recommended_sample_size']}\")\n\nif not power_analysis['power_adequate']:\n    print(\"\u26a0 Insufficient power - need more data\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d014d902"
  },
  {
    "id": "simulation_result_validation_23_3fe72c23",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 23,
    "code": "result = suite.validate(\n    data,\n    compare_groups=[group2],\n    test_types=['effect_size_analysis']\n)\n\neffect_size = result.data['effect_size_analysis']\ncohens_d = effect_size['cohens_d_group_0']['value']\ninterpretation = effect_size['cohens_d_group_0']['interpretation']",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3fe72c23"
  },
  {
    "id": "simulation_result_validation_24_e07a0e64",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 24,
    "code": "from src.analysis.validation.benchmarking import BenchmarkConfig, BenchmarkSuite\n\nconfig = BenchmarkConfig(\n    metrics_to_compare=[\"settling_time\", \"overshoot\", \"control_effort\"],\n    primary_metric=\"settling_time\"\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e07a0e64"
  },
  {
    "id": "simulation_result_validation_25_abe10c0e",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 25,
    "code": "benchmark = BenchmarkSuite(config)\n\nresult = benchmark.validate(\n    data=None,\n    methods=[controller_A, controller_B, controller_C],\n    simulation_function=run_simulation,\n    test_cases=[scenario1, scenario2, scenario3]\n)\n\nsig_tests = result.data['statistical_significance_testing']\nranking = result.data['ranking_analysis']['final_ranking']",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abe10c0e"
  },
  {
    "id": "simulation_result_validation_26_c6390c50",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 26,
    "code": "for comparison, test in sig_tests['corrected_tests'].items():\n    if test['corrected_significant']:\n        print(f\"{comparison}: Significant difference (p={test['corrected_p_value']:.4f})\")\n    else:\n        print(f\"{comparison}: No significant difference\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6390c50"
  },
  {
    "id": "simulation_result_validation_27_1c5e907c",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 27,
    "code": "robustness = result.data['robustness_comparison']\n\nfor method_name, metrics in robustness['robustness_metrics'].items():\n    cv = metrics['settling_time']['coefficient_of_variation']\n    score = metrics['settling_time']['robustness_score']\n    print(f\"{method_name}: CV={cv:.3f}, Robustness Score={score:.3f}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c5e907c"
  },
  {
    "id": "simulation_result_validation_28_76382945",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 28,
    "code": "ranking = robustness['robustness_ranking']\nprint(f\"Most robust: {ranking[0][0]} (score={ranking[0][1]:.3f})\")",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76382945"
  },
  {
    "id": "simulation_result_validation_29_4f9d8dd8",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 29,
    "code": "config = BenchmarkConfig(\n    measure_computation_time=True,\n    measure_memory_usage=True\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4f9d8dd8"
  },
  {
    "id": "simulation_result_validation_30_345d51f3",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 30,
    "code": "# example-metadata:\n# runnable: false\n\nranking = result.data['performance_comparison']['method_ranking']\n# [(method1, score1), (method2, score2), ...]",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "345d51f3"
  },
  {
    "id": "simulation_result_validation_31_905b3900",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 31,
    "code": "ranking = result.data['ranking_analysis']\nborda_scores = ranking['borda_scores']\nfinal_ranking = ranking['final_ranking']",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "905b3900"
  },
  {
    "id": "simulation_result_validation_32_c1dcccb4",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 32,
    "code": "weights = {'settling_time': 0.3, 'overshoot': 0.5, 'control_effort': 0.2}\n\n# Compute weighted scores\nfor method_name, method_data in performance_data.items():\n    score = sum(weights[m] * normalize(method_data[m]) for m in weights)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c1dcccb4"
  },
  {
    "id": "simulation_result_validation_33_36f4c7da",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 33,
    "code": "# After fitting (e.g., lognormal)\nfrom scipy import stats\n\ndist_params = result.data['distribution_analysis']['distribution_fits']['lognormal']['parameters']\ndist = stats.lognorm(*dist_params)\n\n# Probability of exceeding threshold\nprob_exceed = 1 - dist.cdf(threshold)\nprint(f\"P(settling time > 3s) = {prob_exceed:.4f}\")\n\n# 95th percentile\npercentile_95 = dist.ppf(0.95)\nprint(f\"95% of scenarios have settling time < {percentile_95:.2f}s\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36f4c7da"
  },
  {
    "id": "simulation_result_validation_34_8d21a3f0",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 34,
    "code": "risk_analysis = result.data['risk_analysis']\n\nvar_5 = risk_analysis['value_at_risk']['var_5']    # 5th percentile\ncvar_5 = risk_analysis['conditional_value_at_risk']['cvar_5']\n\nprint(f\"Worst 5% scenarios: VaR={var_5:.2f}, CVaR={cvar_5:.2f}\")",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d21a3f0"
  },
  {
    "id": "simulation_result_validation_35_e94d1f84",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 35,
    "code": "extreme = risk_analysis['extreme_value_analysis']\n\n# 100-year return level\nreturn_100 = extreme['return_levels']['100_year']\nprint(f\"Once-in-100-scenarios worst-case: {return_100:.2f}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e94d1f84"
  },
  {
    "id": "simulation_result_validation_36_ba80b18e",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 36,
    "code": "from src.analysis.validation.cross_validation import CrossValidator\n\nvalidator = CrossValidator(CrossValidationConfig(\n    cv_method=\"monte_carlo\",\n    n_repetitions=50,\n    test_ratio=0.2\n))\n\n# For each CV split:\n#   - Optimize on training scenarios\n#   - Evaluate on test scenarios\n#   - Record generalization gap\n\ncv_result = validator.validate(\n    scenarios,\n    models=[pso_optimized_controller],\n    prediction_function=simulate_controller\n)\n\ngeneralization_gap = (\n    cv_result.data['monte_carlo_validation']['training_score'] -\n    cv_result.data['monte_carlo_validation']['test_score']\n)\n\nif generalization_gap > threshold:\n    print(\"\u26a0 Overfitting detected - need more diverse training scenarios\")",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba80b18e"
  },
  {
    "id": "simulation_result_validation_37_b637ee21",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 37,
    "code": "config = CrossValidationConfig(\n    cv_method=\"time_series\",\n    n_splits=5,\n    max_train_size=100,  # Limit adaptation window\n    gap=10               # Predict 10 steps ahead\n)\n\n# Each fold:\n#   - Controller adapts on [t\u2080, t\u2081]\n#   - Performance evaluated on [t\u2081+gap, t\u2082]",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b637ee21"
  },
  {
    "id": "simulation_result_validation_38_f3dff2a9",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 38,
    "code": "# example-metadata:\n# runnable: false\n\nconfig = BenchmarkConfig(\n    measure_computation_time=True,\n    n_trials=100\n)\n\nbenchmark = BenchmarkSuite(config)\nresult = benchmark.validate(...)\n\ncomp_time = result.data['simulation_benchmarks'][scenario][method]['computational_analysis']\n\nmean_time = comp_time['mean_computation_time']\nstd_time = comp_time['std_computation_time']\nworst_case_time = comp_time['mean_computation_time'] + 3*comp_time['std_computation_time']\n\nif worst_case_time < control_period:\n    print(\"\u2713 Real-time feasible\")\nelse:\n    print(\"\u2717 Timing constraint violated\")",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3dff2a9"
  },
  {
    "id": "simulation_result_validation_39_1e25430e",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 39,
    "code": "# Always check power\nresult = suite.validate(data, test_types=['power_analysis'])\nif not result.data['power_analysis']['power_adequate']:\n    print(f\"\u26a0 Need {result.data['power_analysis']['recommended_sample_size']} samples\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e25430e"
  },
  {
    "id": "simulation_result_validation_40_07bab2db",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 40,
    "code": "config = StatisticalTestConfig(\n    multiple_comparisons_correction=\"holm\"  # Use Holm or FDR\n)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07bab2db"
  },
  {
    "id": "simulation_result_validation_41_5da7bcac",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 41,
    "code": "# Always report effect size\nif test['p_value'] < 0.05:\n    effect_size = compute_cohens_d(group1, group2)\n    if abs(effect_size) < 0.2:\n        print(\"\u26a0 Statistically significant but negligible effect\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5da7bcac"
  },
  {
    "id": "simulation_result_validation_42_135a8cf1",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 42,
    "code": "# For time series, ALWAYS use time series CV\nconfig = CrossValidationConfig(\n    cv_method=\"time_series\"  # Not \"k_fold\"!\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "135a8cf1"
  },
  {
    "id": "simulation_result_validation_43_50f20dff",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 43,
    "code": "# Check normality first\nnormality = suite.validate(data, test_types=['normality_tests'])\n\nif normality_rejected:\n    # Use non-parametric test\n    use_mann_whitney_u()  # Instead of t-test\n    # OR transform data\n    log_data = np.log(data)\n    # OR use bootstrap CI",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50f20dff"
  },
  {
    "id": "simulation_result_validation_44_eb8599d6",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 44,
    "code": "# Use nested CV for unbiased evaluation\nconfig = CrossValidationConfig(\n    enable_nested_cv=True,\n    n_splits=5,\n    inner_cv_splits=3\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb8599d6"
  },
  {
    "id": "simulation_result_validation_45_1dcf328a",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 45,
    "code": "import matplotlib.pyplot as plt\n\n# Show distribution, not just mean\nplt.violinplot([data_A, data_B])\nplt.boxplot([data_A, data_B])\n\n# Show confidence intervals\nplt.errorbar(x, means, yerr=confidence_intervals)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1dcf328a"
  },
  {
    "id": "simulation_result_validation_46_f2b6bf3d",
    "file": "docs\\validation\\simulation_result_validation.md",
    "index": 46,
    "code": "# example-metadata:\n# runnable: false\n\n# Monte Carlo + Cross-Validation + Statistical Tests\nmc_result = mc_analyzer.validate(...)\ncv_result = cv_validator.validate(...)\nstat_result = stat_suite.validate(...)\n\n# If all agree \u2192 high confidence\n# If diverge \u2192 investigate why",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2b6bf3d"
  },
  {
    "id": "validation_examples_1_ea8e68de",
    "file": "docs\\validation\\validation_examples.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Required imports (add to your script)\nimport numpy as np\nfrom src.analysis.validation.monte_carlo import MonteCarloConfig, MonteCarloAnalyzer\nfrom src.analysis.validation.cross_validation import CrossValidationConfig, CrossValidator\nfrom src.analysis.validation.statistical_tests import StatisticalTestConfig, StatisticalTestSuite\nfrom src.analysis.validation.benchmarking import BenchmarkConfig, BenchmarkSuite",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ea8e68de"
  },
  {
    "id": "validation_examples_2_75843a69",
    "file": "docs\\validation\\validation_examples.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nMonte Carlo Stability Validation for Sliding Mode Controller\n============================================================\n\nThis script validates controller stability under parameter uncertainty\nusing Latin Hypercube Sampling for efficient coverage.\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom src.analysis.validation.monte_carlo import MonteCarloConfig, MonteCarloAnalyzer\nfrom src.controllers.smc_classical import ClassicalSMC  # Example controller\nfrom src.simulation.double_inverted_pendulum import DoubleInvertedPendulum\n\n# Set random seed for reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n\ndef simulate_stability_check(params: dict, **kwargs) -> dict:\n    \"\"\"\n    Simulate controller for given parameter set.\n\n    Parameters\n    ----------\n    params : dict\n        System parameters: {'mass': float, 'length': float, 'friction': float}\n\n    Returns\n    -------\n    dict\n        Performance metrics: {'stable': bool, 'settling_time': float,\n                              'max_angle': float, 'final_error': float}\n    \"\"\"\n    # Extract parameters\n    mass = params['mass']\n    length = params['length']\n    friction = params['friction']\n\n    # Create system with perturbed parameters\n    system = DoubleInvertedPendulum(\n        m1=mass, m2=mass,  # Assume both pendulums have same mass uncertainty\n        L1=length, L2=length,\n        b=friction\n    )\n\n    # Create controller with nominal gains\n    controller = ClassicalSMC(\n        gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n        boundary_layer_width=0.1\n    )\n\n    # Simulation parameters\n    dt = 0.01  # 10ms time step\n    t_sim = 5.0  # 5 second simulation\n    n_steps = int(t_sim / dt)\n\n    # Initial condition: small perturbation\n    state = np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])  # [\u03b81, \u03b82, x, \u03b8\u03071, \u03b8\u03072, \u1e8b]\n    target = np.zeros(6)  # Upright equilibrium\n\n    # Tracking arrays\n    angles = []\n    times = []\n\n    # Simulate\n    for step in range(n_steps):\n        t = step * dt\n\n        # Compute control\n        u = controller.compute_control(state, target, dt)\n\n        # Apply control and step system\n        state = system.step(u, dt, state)\n\n        # Record\n        angles.append(max(abs(state[0]), abs(state[1])))  # Max angle deviation\n        times.append(t)\n\n        # Check for instability (angle > 30 degrees)\n        if max(abs(state[0]), abs(state[1])) > np.radians(30):\n            # System went unstable\n            return {\n                'stable': False,\n                'settling_time': np.inf,\n                'max_angle': max(abs(state[0]), abs(state[1])),\n                'final_error': np.inf\n            }\n\n    # Analyze stability\n    angles = np.array(angles)\n\n    # Settling time: time to reach and stay within \u00b12 degrees\n    settling_threshold = np.radians(2.0)\n    settled = angles < settling_threshold\n\n    if np.any(settled):\n        # Find first time settled\n        first_settled = np.where(settled)[0][0]\n        # Check if stays settled for at least 0.5s\n        if first_settled < n_steps - 50:  # 50 steps = 0.5s\n            if np.all(angles[first_settled:] < settling_threshold):\n                settling_time = times[first_settled]\n            else:\n                settling_time = np.inf  # Oscillatory, never truly settles\n        else:\n            settling_time = times[first_settled]\n    else:\n        settling_time = np.inf\n\n    # Final error\n    final_error = angles[-1]\n\n    # Max angle reached\n    max_angle = np.max(angles)\n\n    # Stable if settles within simulation time\n    stable = settling_time < t_sim\n\n    return {\n        'stable': stable,\n        'settling_time': settling_time if stable else np.inf,\n        'max_angle': float(max_angle),\n        'final_error': float(final_error)\n    }\n\n\ndef main():\n    \"\"\"Main validation script.\"\"\"\n\n    print(\"=\" * 70)\n    print(\"Monte Carlo Stability Validation\")\n    print(\"=\" * 70)\n\n    # Configure Monte Carlo analysis\n    config = MonteCarloConfig(\n        n_samples=500,  # 500 samples for good coverage\n        sampling_method=\"latin_hypercube\",  # LHS for efficient space coverage\n        random_seed=RANDOM_SEED,\n        confidence_level=0.95,\n        convergence_tolerance=0.01,\n        min_samples=100,\n        max_samples=1000,\n        parallel_processing=True,\n        max_workers=4\n    )\n\n    # Define parameter uncertainty distributions\n    parameter_distributions = {\n        'mass': {\n            'type': 'uniform',\n            'low': 0.9,   # -10% nominal (assume nominal = 1.0 kg)\n            'high': 1.1   # +10% nominal\n        },\n        'length': {\n            'type': 'uniform',\n            'low': 0.95,  # -5% nominal (assume nominal = 1.0 m)\n            'high': 1.05  # +5% nominal\n        },\n        'friction': {\n            'type': 'uniform',\n            'low': 0.05,   # Low friction\n            'high': 0.15   # High friction\n        }\n    }\n\n    # Create analyzer\n    analyzer = MonteCarloAnalyzer(config)\n\n    print(\"\\n1. Running Monte Carlo simulations...\")\n    print(f\"   Sampling method: {config.sampling_method}\")\n    print(f\"   Number of samples: {config.n_samples}\")\n    print(f\"   Parameter ranges:\")\n    print(f\"     - Mass: {parameter_distributions['mass']}\")\n    print(f\"     - Length: {parameter_distributions['length']}\")\n    print(f\"     - Friction: {parameter_distributions['friction']}\")\n\n    # Run validation\n    result = analyzer.validate(\n        data=[],  # No existing data\n        simulation_function=simulate_stability_check,\n        parameter_distributions=parameter_distributions\n    )\n\n    # Extract results\n    if result.status.name == 'SUCCESS':\n        mc_results = result.data['monte_carlo_simulation']\n        stats = mc_results['statistical_summary']\n        convergence = mc_results['convergence_analysis']\n\n        print(\"\\n2. Results:\")\n        print(\"-\" * 70)\n\n        # Stability success rate\n        n_successful = mc_results['n_successful_simulations']\n        print(f\"\\n   Successful simulations: {n_successful}/{config.n_samples}\")\n\n        # Stability rate\n        if 'stable' in stats:\n            stable_stats = stats['stable']\n            stability_rate = stable_stats['mean']\n            print(f\"\\n   \u2713 STABILITY RATE: {stability_rate*100:.1f}%\")\n\n            if stability_rate < 0.95:\n                print(f\"     \u26a0 WARNING: Stability rate below 95% threshold!\")\n                print(f\"     Controller may not be robust enough.\")\n            else:\n                print(f\"     \u2713 Controller meets 95% stability requirement\")\n\n        # Settling time statistics\n        if 'settling_time' in stats:\n            settling_stats = stats['settling_time']\n            print(f\"\\n   Settling Time Statistics:\")\n            print(f\"     Mean:   {settling_stats['mean']:.3f} s\")\n            print(f\"     Std:    {settling_stats['std']:.3f} s\")\n            print(f\"     Median: {settling_stats['median']:.3f} s\")\n            print(f\"     Min:    {settling_stats['min']:.3f} s\")\n            print(f\"     Max:    {settling_stats['max']:.3f} s\")\n\n            # Confidence interval\n            if 'confidence_interval' in settling_stats:\n                ci = settling_stats['confidence_interval']\n                print(f\"     95% CI: [{ci['lower']:.3f}, {ci['upper']:.3f}] s\")\n\n        # Max angle statistics\n        if 'max_angle' in stats:\n            angle_stats = stats['max_angle']\n            print(f\"\\n   Maximum Angle Deviation:\")\n            print(f\"     Mean:   {np.degrees(angle_stats['mean']):.2f}\u00b0\")\n            print(f\"     95th percentile: {np.degrees(angle_stats.get('percentile_95', 0)):.2f}\u00b0\")\n\n            if np.degrees(angle_stats.get('percentile_95', 0)) > 25:\n                print(f\"     \u26a0 WARNING: 95th percentile angle exceeds 25\u00b0\")\n\n        # Convergence analysis\n        print(f\"\\n3. Convergence Analysis:\")\n        print(f\"   Converged: {convergence['converged']}\")\n        if convergence['converged']:\n            print(f\"   Convergence point: {convergence['convergence_point']} samples\")\n        else:\n            print(f\"   \u26a0 May need more samples for full convergence\")\n\n        # Distribution analysis\n        if 'distribution_analysis' in result.data:\n            dist_analysis = result.data['distribution_analysis']\n            if 'best_fit' in dist_analysis and dist_analysis['best_fit']:\n                print(f\"\\n4. Distribution Fitting:\")\n                print(f\"   Best fit: {dist_analysis['best_fit']}\")\n\n                best_dist = dist_analysis['distribution_fits'][dist_analysis['best_fit']]\n                print(f\"   K-S statistic: {best_dist['ks_statistic']:.4f}\")\n                print(f\"   p-value: {best_dist['p_value']:.4f}\")\n\n        # Risk analysis\n        if 'risk_analysis' in result.data:\n            risk = result.data['risk_analysis']\n            print(f\"\\n5. Risk Analysis (Settling Time):\")\n\n            if 'value_at_risk' in risk:\n                var = risk['value_at_risk']\n                print(f\"   VaR (5%):  {var.get('var_5', 'N/A')} s  (worst 5% scenarios)\")\n                print(f\"   VaR (10%): {var.get('var_10', 'N/A')} s  (worst 10% scenarios)\")\n\n            if 'conditional_value_at_risk' in risk:\n                cvar = risk['conditional_value_at_risk']\n                print(f\"   CVaR (5%): {cvar.get('cvar_5', 'N/A')} s  (avg of worst 5%)\")\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"VALIDATION CONCLUSION:\")\n\n        # Overall assessment\n        if 'stable' in stats and stats['stable']['mean'] >= 0.95:\n            print(\"\u2713 Controller PASSES stability validation\")\n            print(\"  - Stability rate \u2265 95%\")\n            print(\"  - Ready for hardware-in-the-loop testing\")\n        else:\n            print(\"\u2717 Controller FAILS stability validation\")\n            print(\"  - Stability rate < 95%\")\n            print(\"  - Recommendation: Increase control gains or add robustness\")\n\n        print(\"=\" * 70)\n\n    else:\n        print(f\"\\n\u2717 Validation FAILED: {result.message}\")\n        if 'error_details' in result.data:\n            print(f\"   Error: {result.data['error_details']}\")\n\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 293,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75843a69"
  },
  {
    "id": "validation_examples_3_aef5f0eb",
    "file": "docs\\validation\\validation_examples.md",
    "index": 3,
    "code": "# Conservative (\u00b120% uncertainty)\nparameter_distributions = {\n    'mass': {'type': 'uniform', 'low': 0.8, 'high': 1.2},\n    'length': {'type': 'uniform', 'low': 0.8, 'high': 1.2},\n    'friction': {'type': 'uniform', 'low': 0.0, 'high': 0.2}\n}",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aef5f0eb"
  },
  {
    "id": "validation_examples_4_cdb022aa",
    "file": "docs\\validation\\validation_examples.md",
    "index": 4,
    "code": "parameter_distributions = {\n    'mass': {'type': 'normal', 'mean': 1.0, 'std': 0.05},\n    'length': {'type': 'normal', 'mean': 1.0, 'std': 0.025}\n}",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cdb022aa"
  },
  {
    "id": "validation_examples_5_dcee3132",
    "file": "docs\\validation\\validation_examples.md",
    "index": 5,
    "code": "config = MonteCarloConfig(\n    n_samples=1024,  # Power of 2 for Sobol\n    sampling_method=\"sobol\",\n    sensitivity_analysis=True,\n    sensitivity_method=\"sobol\"\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcee3132"
  },
  {
    "id": "validation_examples_6_122ce138",
    "file": "docs\\validation\\validation_examples.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nCross-Validation for PSO Hyperparameter Selection\n==================================================\n\nThis script uses Monte Carlo cross-validation to select PSO hyperparameters\nthat produce controller gains with best generalization performance.\n\"\"\"\n\nimport numpy as np\nfrom typing import Dict, Any, Callable\nfrom src.analysis.validation.cross_validation import CrossValidationConfig, CrossValidator\nfrom src.optimization.algorithms.pso_swarm import PSOSwarm  # Example PSO\nfrom src.controllers.smc_classical import ClassicalSMC\n\n# Random seed for reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n\ndef optimize_controller_with_pso(pso_config: Dict[str, Any],\n                                 training_scenarios: np.ndarray) -> Dict[str, float]:\n    \"\"\"\n    Optimize controller gains using PSO with given hyperparameters.\n\n    Parameters\n    ----------\n    pso_config : dict\n        PSO hyperparameters: {'pop_size': int, 'w': float, 'c1': float, 'c2': float}\n    training_scenarios : np.ndarray\n        Training scenarios for optimization\n\n    Returns\n    -------\n    dict\n        Optimized controller gains\n    \"\"\"\n    # Extract PSO hyperparameters\n    pop_size = pso_config.get('pop_size', 30)\n    w = pso_config.get('w', 0.7)\n    c1 = pso_config.get('c1', 1.5)\n    c2 = pso_config.get('c2', 1.5)\n\n    # Define search space for controller gains\n    # [lambda1, lambda2, eta1, eta2, k, phi]\n    bounds = np.array([\n        [5.0, 20.0],    # lambda1\n        [5.0, 20.0],    # lambda2\n        [10.0, 30.0],   # eta1\n        [10.0, 30.0],   # eta2\n        [30.0, 70.0],   # k\n        [1.0, 10.0]     # phi (boundary layer)\n    ])\n\n    # Create PSO optimizer\n    pso = PSOSwarm(\n        pop_size=pop_size,\n        dim=len(bounds),\n        bounds=bounds,\n        w=w,\n        c1=c1,\n        c2=c2,\n        max_iter=50  # Limited iterations for CV efficiency\n    )\n\n    # Define objective function (simplified)\n    def objective(gains):\n        \"\"\"Objective: minimize average settling time on training scenarios.\"\"\"\n        total_cost = 0.0\n        for scenario in training_scenarios:\n            # Simulate controller with these gains\n            controller = ClassicalSMC(gains=gains)\n            # ... simulate and compute settling time ...\n            # (Simplified - in practice would run full simulation)\n            settling_time = 2.0 + 0.5 * np.random.randn()  # Placeholder\n            total_cost += settling_time\n        return total_cost / len(training_scenarios)\n\n    # Run PSO optimization\n    best_gains, best_cost = pso.optimize(objective)\n\n    return {\n        'lambda1': best_gains[0],\n        'lambda2': best_gains[1],\n        'eta1': best_gains[2],\n        'eta2': best_gains[3],\n        'k': best_gains[4],\n        'phi': best_gains[5]\n    }\n\n\ndef evaluate_controller_performance(controller_gains: Dict[str, float],\n                                   test_scenarios: np.ndarray) -> float:\n    \"\"\"\n    Evaluate controller on test scenarios.\n\n    Parameters\n    ----------\n    controller_gains : dict\n        Controller gains to evaluate\n    test_scenarios : np.ndarray\n        Test scenarios\n\n    Returns\n    -------\n    float\n        Average performance score (negative MSE for minimization)\n    \"\"\"\n    # Create controller with optimized gains\n    gains = [controller_gains['lambda1'], controller_gains['lambda2'],\n             controller_gains['eta1'], controller_gains['eta2'],\n             controller_gains['k'], controller_gains['phi']]\n\n    controller = ClassicalSMC(gains=gains)\n\n    # Evaluate on test scenarios\n    total_performance = 0.0\n    for scenario in test_scenarios:\n        # Simulate and compute performance\n        # (Simplified - in practice would run full simulation)\n        settling_time = 2.0 + 0.3 * np.random.randn()  # Placeholder\n        total_performance -= settling_time  # Negative for minimization\n\n    return total_performance / len(test_scenarios)\n\n\nclass PSO_CV_Predictor:\n    \"\"\"Wrapper for PSO hyperparameter configuration as a 'model' for CV.\"\"\"\n\n    def __init__(self, pso_config: Dict[str, Any]):\n        self.pso_config = pso_config\n        self.controller_gains = None\n\n    def fit(self, X_train, y_train):\n        \"\"\"Train: optimize controller with this PSO config.\"\"\"\n        # X_train contains training scenarios\n        self.controller_gains = optimize_controller_with_pso(\n            self.pso_config,\n            X_train\n        )\n        return self\n\n    def predict(self, X_test):\n        \"\"\"Predict: evaluate optimized controller on test scenarios.\"\"\"\n        if self.controller_gains is None:\n            raise ValueError(\"Must fit before predict\")\n\n        # Evaluate on each test scenario\n        predictions = []\n        for scenario in X_test:\n            # Return predicted performance\n            score = evaluate_controller_performance(\n                self.controller_gains,\n                scenario.reshape(1, -1)\n            )\n            predictions.append(score)\n\n        return np.array(predictions)\n\n\ndef main():\n    \"\"\"Main cross-validation script.\"\"\"\n\n    print(\"=\" * 70)\n    print(\"PSO Hyperparameter Selection via Cross-Validation\")\n    print(\"=\" * 70)\n\n    # Generate synthetic scenario data (in practice, use real scenarios)\n    # Each scenario is a vector of initial conditions and parameters\n    n_scenarios = 100\n    scenario_dim = 10  # 10 features per scenario\n    scenarios = np.random.randn(n_scenarios, scenario_dim)\n\n    # Define PSO hyperparameter configurations to compare\n    pso_configs = [\n        {'name': 'Small-Explorative', 'pop_size': 20, 'w': 0.9, 'c1': 2.0, 'c2': 1.0},\n        {'name': 'Standard', 'pop_size': 30, 'w': 0.7, 'c1': 1.5, 'c2': 1.5},\n        {'name': 'Large-Exploitative', 'pop_size': 50, 'w': 0.4, 'c1': 1.0, 'c2': 2.0},\n        {'name': 'Adaptive', 'pop_size': 30, 'w': 0.5, 'c1': 1.8, 'c2': 1.2}\n    ]\n\n    print(f\"\\n1. Configuration:\")\n    print(f\"   Number of scenarios: {n_scenarios}\")\n    print(f\"   PSO configurations to compare: {len(pso_configs)}\")\n    for i, cfg in enumerate(pso_configs, 1):\n        print(f\"   {i}. {cfg['name']}: pop={cfg['pop_size']}, w={cfg['w']}, \"\n              f\"c1={cfg['c1']}, c2={cfg['c2']}\")\n\n    # Configure cross-validation\n    cv_config = CrossValidationConfig(\n        cv_method=\"monte_carlo\",  # Random train-test splits\n        n_repetitions=50,         # 50 random splits for robust estimate\n        test_ratio=0.2,           # 80% train, 20% test\n        random_state=RANDOM_SEED,\n        paired_tests=True,        # Same splits for all configs (paired comparison)\n        significance_level=0.05\n    )\n\n    validator = CrossValidator(cv_config)\n\n    print(f\"\\n2. Cross-Validation Setup:\")\n    print(f\"   Method: {cv_config.cv_method}\")\n    print(f\"   Repetitions: {cv_config.n_repetitions}\")\n    print(f\"   Train-test split: {1-cv_config.test_ratio:.0%}-{cv_config.test_ratio:.0%}\")\n\n    # Create model objects\n    models = [PSO_CV_Predictor(cfg) for cfg in pso_configs]\n\n    print(f\"\\n3. Running cross-validation...\")\n    print(f\"   (This may take several minutes...)\")\n\n    # Prepare dummy targets (CV framework expects targets)\n    # In practice, these would be performance scores\n    y = np.random.randn(n_scenarios)  # Placeholder\n\n    # Run cross-validation\n    result = validator.validate(\n        data=scenarios,\n        models=models,\n        target_variable=None,  # Will use y directly\n        feature_variables=None  # Will use all columns\n    )\n\n    # Extract results\n    if result.status.name == 'SUCCESS':\n        print(\"\\n4. Results:\")\n        print(\"-\" * 70)\n\n        # Monte Carlo CV results\n        if 'monte_carlo_validation' in result.data:\n            mc_cv = result.data['monte_carlo_validation']\n\n            print(\"\\n   Cross-Validation Scores:\")\n            cv_scores = []\n            for i, cfg in enumerate(pso_configs):\n                model_key = f'model_{i}'\n                if model_key in mc_cv:\n                    scores = mc_cv[model_key]\n                    print(f\"\\n   {cfg['name']}:\")\n                    print(f\"     Mean CV score:   {scores['mean_score']:.4f}\")\n                    print(f\"     Std CV score:    {scores['std_score']:.4f}\")\n                    print(f\"     Median CV score: {scores['median_score']:.4f}\")\n\n                    if 'confidence_interval' in scores:\n                        ci = scores['confidence_interval']\n                        print(f\"     95% CI: [{ci['lower']:.4f}, {ci['upper']:.4f}]\")\n\n                    cv_scores.append((cfg['name'], scores['mean_score'], scores['std_score']))\n\n        # Model comparison\n        if 'model_comparison' in result.data:\n            comparison = result.data['model_comparison']\n\n            print(\"\\n5. Statistical Comparison:\")\n\n            if 'pairwise_comparisons' in comparison:\n                print(\"\\n   Pairwise Tests (after multiple comparison correction):\")\n                for comp_key, comp_result in comparison['pairwise_comparisons'].items():\n                    if comp_result['significant']:\n                        better = comp_result['better_method']\n                        p_val = comp_result['p_value']\n                        diff = comp_result['difference']\n                        print(f\"     {comp_key}: {better} is significantly better \"\n                              f\"(p={p_val:.4f}, \u0394={diff:.4f})\")\n\n            if 'model_ranking' in comparison:\n                print(\"\\n   Overall Ranking:\")\n                for rank, (cfg_name, score) in enumerate(comparison['model_ranking'], 1):\n                    # Map back to config names\n                    model_idx = int(cfg_name.split('_')[1])\n                    actual_name = pso_configs[model_idx]['name']\n                    print(f\"     {rank}. {actual_name:20s} (score: {score:.4f})\")\n\n        # Bias-variance analysis\n        if 'bias_variance_analysis' in result.data:\n            bv_analysis = result.data['bias_variance_analysis']\n\n            print(\"\\n6. Bias-Variance Analysis:\")\n            for i, cfg in enumerate(pso_configs):\n                model_key = f'model_{i}'\n                if model_key in bv_analysis:\n                    bv = bv_analysis[model_key]\n                    print(f\"\\n   {cfg['name']}:\")\n                    print(f\"     Bias\u00b2:    {bv['bias_squared']:.6f}\")\n                    print(f\"     Variance: {bv['variance']:.6f}\")\n\n                    # Interpretation\n                    ratio = bv['bias_variance_ratio']\n                    if ratio > 2.0:\n                        print(f\"     \u26a0 High bias - underfitting (consider larger population)\")\n                    elif ratio < 0.5:\n                        print(f\"     \u26a0 High variance - overfitting (consider regularization)\")\n                    else:\n                        print(f\"     \u2713 Good balance\")\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"RECOMMENDATION:\")\n\n        # Find best configuration\n        if 'model_ranking' in result.data['model_comparison']:\n            best_model_key, best_score = result.data['model_comparison']['model_ranking'][0]\n            best_idx = int(best_model_key.split('_')[1])\n            best_config = pso_configs[best_idx]\n\n            print(f\"\\n\u2713 RECOMMENDED PSO Configuration: {best_config['name']}\")\n            print(f\"  Parameters:\")\n            print(f\"    - Population size: {best_config['pop_size']}\")\n            print(f\"    - Inertia weight (w): {best_config['w']}\")\n            print(f\"    - Cognitive coeff (c1): {best_config['c1']}\")\n            print(f\"    - Social coeff (c2): {best_config['c2']}\")\n            print(f\"  Mean CV score: {best_score:.4f}\")\n            print(f\"\\n  This configuration showed best generalization across {cv_config.n_repetitions} random splits.\")\n\n        print(\"=\" * 70)\n\n    else:\n        print(f\"\\n\u2717 Cross-validation FAILED: {result.message}\")\n\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 323,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "122ce138"
  },
  {
    "id": "validation_examples_7_916f9a05",
    "file": "docs\\validation\\validation_examples.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nStatistical Comparison of Three SMC Variants\n=============================================\n\nThis script performs rigorous statistical comparison of controller\nperformance using parametric and non-parametric tests with effect size analysis.\n\"\"\"\n\nimport numpy as np\nfrom src.analysis.validation.statistical_tests import StatisticalTestConfig, StatisticalTestSuite\nfrom scipy import stats\n\n# Random seed\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n\ndef simulate_controller_trials(controller_type: str, n_trials: int = 30) -> np.ndarray:\n    \"\"\"\n    Simulate controller performance over multiple trials.\n\n    Parameters\n    ----------\n    controller_type : str\n        One of 'classical', 'super_twisting', 'adaptive'\n    n_trials : int\n        Number of trials to run\n\n    Returns\n    -------\n    np.ndarray\n        Settling times for each trial\n    \"\"\"\n    # Simulate realistic settling times with different characteristics\n    if controller_type == 'classical':\n        # Classical SMC: moderate performance, moderate variance\n        mean_settling = 2.5\n        std_settling = 0.4\n        settling_times = np.random.normal(mean_settling, std_settling, n_trials)\n\n    elif controller_type == 'super_twisting':\n        # Super-Twisting: best performance, low variance (finite-time convergence)\n        mean_settling = 1.8\n        std_settling = 0.25\n        settling_times = np.random.normal(mean_settling, std_settling, n_trials)\n\n    elif controller_type == 'adaptive':\n        # Adaptive: good mean but higher variance (adaptation uncertainty)\n        mean_settling = 2.1\n        std_settling = 0.5\n        settling_times = np.random.normal(mean_settling, std_settling, n_trials)\n    else:\n        raise ValueError(f\"Unknown controller type: {controller_type}\")\n\n    # Ensure positive values\n    settling_times = np.abs(settling_times)\n\n    return settling_times\n\n\ndef compute_effect_size_cohens_d(group1: np.ndarray, group2: np.ndarray) -> dict:\n    \"\"\"\n    Compute Cohen's d effect size.\n\n    Returns\n    -------\n    dict\n        Effect size, interpretation, and metadata\n    \"\"\"\n    mean1 = np.mean(group1)\n    mean2 = np.mean(group2)\n    std1 = np.std(group1, ddof=1)\n    std2 = np.std(group2, ddof=1)\n    n1 = len(group1)\n    n2 = len(group2)\n\n    # Pooled standard deviation\n    pooled_std = np.sqrt(((n1-1)*std1**2 + (n2-1)*std2**2) / (n1 + n2 - 2))\n\n    # Cohen's d\n    d = (mean1 - mean2) / pooled_std\n\n    # Interpretation\n    abs_d = abs(d)\n    if abs_d < 0.2:\n        interpretation = \"negligible\"\n    elif abs_d < 0.5:\n        interpretation = \"small\"\n    elif abs_d < 0.8:\n        interpretation = \"medium\"\n    else:\n        interpretation = \"large\"\n\n    return {\n        'd': d,\n        'abs_d': abs_d,\n        'interpretation': interpretation,\n        'mean_diff': mean1 - mean2,\n        'pooled_std': pooled_std\n    }\n\n\ndef main():\n    \"\"\"Main statistical comparison script.\"\"\"\n\n    print(\"=\" * 70)\n    print(\"Statistical Comparison of Controller Performance\")\n    print(\"=\" * 70)\n\n    # Configuration\n    n_trials = 30  # 30 trials per controller\n    alpha = 0.05   # 5% significance level\n\n    print(f\"\\n1. Experimental Setup:\")\n    print(f\"   Controllers: Classical SMC, Super-Twisting SMC, Adaptive SMC\")\n    print(f\"   Trials per controller: {n_trials}\")\n    print(f\"   Significance level: {alpha}\")\n    print(f\"   Metric: Settling time (seconds)\")\n\n    # Run simulations\n    print(f\"\\n2. Collecting performance data...\")\n\n    classical_data = simulate_controller_trials('classical', n_trials)\n    supertwisting_data = simulate_controller_trials('super_twisting', n_trials)\n    adaptive_data = simulate_controller_trials('adaptive', n_trials)\n\n    controllers = {\n        'Classical SMC': classical_data,\n        'Super-Twisting SMC': supertwisting_data,\n        'Adaptive SMC': adaptive_data\n    }\n\n    # Descriptive statistics\n    print(f\"\\n3. Descriptive Statistics:\")\n    print(\"-\" * 70)\n\n    for name, data in controllers.items():\n        print(f\"\\n   {name}:\")\n        print(f\"     Mean:   {np.mean(data):.3f} s\")\n        print(f\"     Std:    {np.std(data, ddof=1):.3f} s\")\n        print(f\"     Median: {np.median(data):.3f} s\")\n        print(f\"     Min:    {np.min(data):.3f} s\")\n        print(f\"     Max:    {np.max(data):.3f} s\")\n        print(f\"     CV:     {np.std(data,ddof=1)/np.mean(data)*100:.1f}%\")\n\n    # Test assumptions\n    print(f\"\\n4. Assumption Testing:\")\n    print(\"-\" * 70)\n\n    suite = StatisticalTestSuite(StatisticalTestConfig(\n        significance_level=alpha,\n        normality_tests=['shapiro', 'anderson']\n    ))\n\n    # Test normality for each controller\n    print(\"\\n   Normality Tests (Shapiro-Wilk):\")\n    normality_ok = {}\n    for name, data in controllers.items():\n        result = suite.validate(data, test_types=['normality_tests'])\n        if result.status.name == 'SUCCESS':\n            shapiro = result.data['normality_tests']['shapiro_wilk']\n            p_val = shapiro['p_value']\n            normal = p_val > alpha\n            normality_ok[name] = normal\n\n            status = \"\u2713 Normal\" if normal else \"\u2717 Non-normal\"\n            print(f\"     {name:20s}: W={shapiro['statistic']:.4f}, \"\n                  f\"p={p_val:.4f} {status}\")\n\n    # Test homogeneity of variances (Levene's test)\n    print(\"\\n   Homogeneity of Variance (Levene's test):\")\n    levene_stat, levene_p = stats.levene(classical_data, supertwisting_data, adaptive_data)\n    homoscedastic = levene_p > alpha\n    print(f\"     F={levene_stat:.4f}, p={levene_p:.4f}\")\n    if homoscedastic:\n        print(f\"     \u2713 Equal variances assumption satisfied\")\n    else:\n        print(f\"     \u26a0 Unequal variances - will use Welch's test\")\n\n    # Pairwise comparisons\n    print(f\"\\n5. Pairwise Comparisons:\")\n    print(\"-\" * 70)\n\n    comparisons = [\n        ('Classical SMC', 'Super-Twisting SMC', classical_data, supertwisting_data),\n        ('Classical SMC', 'Adaptive SMC', classical_data, adaptive_data),\n        ('Super-Twisting SMC', 'Adaptive SMC', supertwisting_data, adaptive_data)\n    ]\n\n    # Bonferroni correction for multiple comparisons\n    alpha_corrected = alpha / len(comparisons)\n    print(f\"\\n   Multiple comparison correction: Bonferroni\")\n    print(f\"   Corrected significance level: \u03b1={alpha_corrected:.4f}\")\n\n    significant_pairs = []\n\n    for name1, name2, data1, data2 in comparisons:\n        print(f\"\\n   {name1} vs {name2}:\")\n\n        # Independent t-test (Welch's if unequal variances)\n        equal_var = homoscedastic\n        t_stat, t_p = stats.ttest_ind(data1, data2, equal_var=equal_var)\n\n        test_type = \"Independent t-test\" if equal_var else \"Welch's t-test\"\n        print(f\"     {test_type}:\")\n        print(f\"       t={t_stat:.4f}, p={t_p:.4f}\")\n\n        significant = t_p < alpha_corrected\n        if significant:\n            print(f\"       \u2713 SIGNIFICANT (p < {alpha_corrected:.4f})\")\n            significant_pairs.append((name1, name2))\n        else:\n            print(f\"       \u2717 Not significant\")\n\n        # Mann-Whitney U test (non-parametric alternative)\n        u_stat, u_p = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n        print(f\"     Mann-Whitney U test (non-parametric):\")\n        print(f\"       U={u_stat:.1f}, p={u_p:.4f}\")\n\n        # Effect size (Cohen's d)\n        effect_size = compute_effect_size_cohens_d(data1, data2)\n        print(f\"     Effect Size (Cohen's d):\")\n        print(f\"       d={effect_size['d']:.3f} ({effect_size['interpretation']})\")\n        print(f\"       Mean difference: {effect_size['mean_diff']:.3f} s\")\n\n        # Confidence interval for mean difference\n        ci_lower, ci_upper = stats.t.interval(\n            0.95,\n            len(data1) + len(data2) - 2,\n            loc=np.mean(data1) - np.mean(data2),\n            scale=effect_size['pooled_std'] * np.sqrt(1/len(data1) + 1/len(data2))\n        )\n        print(f\"       95% CI for difference: [{ci_lower:.3f}, {ci_upper:.3f}] s\")\n\n    # One-way ANOVA\n    print(f\"\\n6. Omnibus Test (One-Way ANOVA):\")\n    print(\"-\" * 70)\n\n    f_stat, anova_p = stats.f_oneway(classical_data, supertwisting_data, adaptive_data)\n    print(f\"   F={f_stat:.4f}, p={anova_p:.6f}\")\n\n    if anova_p < alpha:\n        print(f\"   \u2713 SIGNIFICANT: At least one controller differs\")\n    else:\n        print(f\"   \u2717 Not significant: No evidence of difference\")\n\n    # Kruskal-Wallis (non-parametric alternative)\n    h_stat, kw_p = stats.kruskal(classical_data, supertwisting_data, adaptive_data)\n    print(f\"\\n   Kruskal-Wallis test (non-parametric):\")\n    print(f\"   H={h_stat:.4f}, p={kw_p:.6f}\")\n\n    # Power analysis\n    print(f\"\\n7. Power Analysis:\")\n    print(\"-\" * 70)\n\n    for name1, name2, data1, data2 in comparisons:\n        effect_size = compute_effect_size_cohens_d(data1, data2)\n        d = abs(effect_size['d'])\n\n        # Calculate power (simplified - using normal approximation)\n        from scipy.stats import norm\n        n = len(data1)  # Assume equal sample sizes\n        ncp = d * np.sqrt(n / 2)  # Non-centrality parameter\n\n        # Two-tailed test power\n        z_crit = norm.ppf(1 - alpha_corrected/2)\n        power = 1 - norm.cdf(z_crit - ncp) + norm.cdf(-z_crit - ncp)\n\n        print(f\"\\n   {name1} vs {name2}:\")\n        print(f\"     Effect size (d): {d:.3f}\")\n        print(f\"     Sample size (n): {n}\")\n        print(f\"     Power: {power:.3f} ({power*100:.1f}%)\")\n\n        if power < 0.8:\n            # Calculate required sample size for 80% power\n            z_beta = norm.ppf(0.8)\n            n_req = 2 * ((z_crit + z_beta) / d)**2\n            print(f\"     \u26a0 Low power - recommend n={int(np.ceil(n_req))} for 80% power\")\n        else:\n            print(f\"     \u2713 Adequate power (\u226580%)\")\n\n    # Summary and recommendations\n    print(f\"\\n\" + \"=\" * 70)\n    print(\"CONCLUSIONS:\")\n    print(\"=\" * 70)\n\n    print(f\"\\n1. Statistical Significance:\")\n    if significant_pairs:\n        print(f\"   Significant differences found (\u03b1={alpha_corrected:.4f}):\")\n        for name1, name2 in significant_pairs:\n            print(f\"     - {name1} vs {name2}\")\n    else:\n        print(f\"   No significant differences detected\")\n\n    print(f\"\\n2. Effect Sizes:\")\n    for name1, name2, data1, data2 in comparisons:\n        effect_size = compute_effect_size_cohens_d(data1, data2)\n        print(f\"   {name1} vs {name2}:\")\n        print(f\"     Cohen's d = {effect_size['d']:.3f} ({effect_size['interpretation']})\")\n\n    print(f\"\\n3. Practical Recommendations:\")\n\n    # Rank controllers\n    mean_times = {name: np.mean(data) for name, data in controllers.items()}\n    ranked = sorted(mean_times.items(), key=lambda x: x[1])\n\n    print(f\"   Performance ranking (by mean settling time):\")\n    for rank, (name, mean_time) in enumerate(ranked, 1):\n        print(f\"     {rank}. {name:20s}: {mean_time:.3f} s\")\n\n    best_controller = ranked[0][0]\n    print(f\"\\n   \u2713 RECOMMENDED: {best_controller}\")\n    print(f\"     - Fastest mean settling time\")\n\n    # Check if best is significantly better than others\n    best_data = controllers[best_controller]\n    significant_improvement = False\n    for name, data in controllers.items():\n        if name != best_controller:\n            t_stat, t_p = stats.ttest_ind(best_data, data, equal_var=False)\n            if t_p < alpha_corrected:\n                effect_size = compute_effect_size_cohens_d(best_data, data)\n                print(f\"     - Significantly better than {name} \"\n                      f\"(p={t_p:.4f}, d={abs(effect_size['d']):.3f})\")\n                significant_improvement = True\n\n    if not significant_improvement:\n        print(f\"     \u26a0 Note: Improvement not statistically significant\")\n        print(f\"       Consider cost-benefit analysis for deployment\")\n\n    print(\"=\" * 70)\n\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 338,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "916f9a05"
  },
  {
    "id": "validation_examples_8_35c6a23b",
    "file": "docs\\validation\\validation_examples.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n\"\"\"\nUncertainty Quantification for Settling Time Predictions\n=========================================================\n\nThis script demonstrates comprehensive uncertainty quantification including:\n- Bootstrap confidence intervals\n- Distribution fitting\n- Risk analysis (VaR, CVaR)\n- Probabilistic guarantees\n\"\"\"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom src.analysis.validation.monte_carlo import MonteCarloConfig, MonteCarloAnalyzer\n\n# Random seed\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n\ndef generate_settling_time_data(n_samples: int = 200) -> np.ndarray:\n    \"\"\"\n    Generate realistic settling time data (log-normal distribution).\n\n    Parameters\n    ----------\n    n_samples : int\n        Number of samples\n\n    Returns\n    -------\n    np.ndarray\n        Settling times in seconds\n    \"\"\"\n    # Log-normal distribution (realistic for settling times - positive skew)\n    # ln(T) ~ N(\u03bc, \u03c3\u00b2)\n    mu = 0.7  # log-scale mean\n    sigma = 0.3  # log-scale std\n\n    settling_times = np.random.lognormal(mu, sigma, n_samples)\n\n    return settling_times\n\n\ndef main():\n    \"\"\"Main uncertainty quantification script.\"\"\"\n\n    print(\"=\" * 70)\n    print(\"Uncertainty Quantification for Settling Time\")\n    print(\"=\" * 70)\n\n    # Safety requirement\n    SAFETY_THRESHOLD = 3.0  # seconds\n    REQUIRED_CONFIDENCE = 0.99  # 99% confidence\n\n    print(f\"\\n1. Safety Requirement:\")\n    print(f\"   Settling time must be < {SAFETY_THRESHOLD}s with {REQUIRED_CONFIDENCE*100}% confidence\")\n\n    # Generate data\n    n_samples = 200\n    print(f\"\\n2. Collecting experimental data...\")\n    print(f\"   Number of test runs: {n_samples}\")\n\n    settling_times = generate_settling_time_data(n_samples)\n\n    # Basic statistics\n    print(f\"\\n3. Descriptive Statistics:\")\n    print(\"-\" * 70)\n    print(f\"   Mean:     {np.mean(settling_times):.3f} s\")\n    print(f\"   Std:      {np.std(settling_times, ddof=1):.3f} s\")\n    print(f\"   Median:   {np.median(settling_times):.3f} s\")\n    print(f\"   Min:      {np.min(settling_times):.3f} s\")\n    print(f\"   Max:      {np.max(settling_times):.3f} s\")\n    print(f\"   Range:    {np.max(settling_times) - np.min(settling_times):.3f} s\")\n\n    # Percentiles\n    print(f\"\\n   Percentiles:\")\n    percentiles = [5, 25, 50, 75, 95, 99]\n    for p in percentiles:\n        value = np.percentile(settling_times, p)\n        print(f\"     {p:2d}%: {value:.3f} s\")\n\n    # Bootstrap confidence intervals\n    print(f\"\\n4. Bootstrap Confidence Intervals:\")\n    print(\"-\" * 70)\n\n    n_bootstrap = 10000\n    bootstrap_means = []\n    bootstrap_medians = []\n    bootstrap_stds = []\n    bootstrap_95th = []\n\n    for _ in range(n_bootstrap):\n        bootstrap_sample = np.random.choice(settling_times, size=len(settling_times), replace=True)\n        bootstrap_means.append(np.mean(bootstrap_sample))\n        bootstrap_medians.append(np.median(bootstrap_sample))\n        bootstrap_stds.append(np.std(bootstrap_sample, ddof=1))\n        bootstrap_95th.append(np.percentile(bootstrap_sample, 95))\n\n    # Compute bootstrap CIs\n    ci_level = 0.95\n    alpha = 1 - ci_level\n\n    mean_ci = [\n        np.percentile(bootstrap_means, 100 * alpha/2),\n        np.percentile(bootstrap_means, 100 * (1 - alpha/2))\n    ]\n\n    median_ci = [\n        np.percentile(bootstrap_medians, 100 * alpha/2),\n        np.percentile(bootstrap_medians, 100 * (1 - alpha/2))\n    ]\n\n    percentile_95_ci = [\n        np.percentile(bootstrap_95th, 100 * alpha/2),\n        np.percentile(bootstrap_95th, 100 * (1 - alpha/2))\n    ]\n\n    print(f\"   Bootstrap iterations: {n_bootstrap}\")\n    print(f\"   Confidence level: {ci_level*100}%\")\n    print(f\"\\n   Mean settling time:\")\n    print(f\"     Point estimate: {np.mean(settling_times):.3f} s\")\n    print(f\"     95% CI: [{mean_ci[0]:.3f}, {mean_ci[1]:.3f}] s\")\n    print(f\"     CI width: {mean_ci[1] - mean_ci[0]:.3f} s\")\n\n    print(f\"\\n   Median settling time:\")\n    print(f\"     Point estimate: {np.median(settling_times):.3f} s\")\n    print(f\"     95% CI: [{median_ci[0]:.3f}, {median_ci[1]:.3f}] s\")\n\n    print(f\"\\n   95th percentile:\")\n    print(f\"     Point estimate: {np.percentile(settling_times, 95):.3f} s\")\n    print(f\"     95% CI: [{percentile_95_ci[0]:.3f}, {percentile_95_ci[1]:.3f}] s\")\n\n    # Distribution fitting\n    print(f\"\\n5. Distribution Fitting:\")\n    print(\"-\" * 70)\n\n    distributions = {\n        'Normal': stats.norm,\n        'Lognormal': stats.lognorm,\n        'Gamma': stats.gamma,\n        'Exponential': stats.expon\n    }\n\n    fit_results = {}\n\n    for dist_name, dist in distributions.items():\n        try:\n            # Fit distribution\n            if dist_name == 'Exponential':\n                params = dist.fit(settling_times, floc=0)\n            else:\n                params = dist.fit(settling_times)\n\n            # Kolmogorov-Smirnov test\n            ks_stat, ks_p = stats.kstest(settling_times, lambda x: dist.cdf(x, *params))\n\n            # AIC (Akaike Information Criterion)\n            log_likelihood = np.sum(dist.logpdf(settling_times, *params))\n            aic = 2 * len(params) - 2 * log_likelihood\n\n            fit_results[dist_name] = {\n                'params': params,\n                'ks_stat': ks_stat,\n                'ks_p': ks_p,\n                'aic': aic\n            }\n\n            print(f\"\\n   {dist_name}:\")\n            print(f\"     K-S statistic: {ks_stat:.4f}\")\n            print(f\"     p-value: {ks_p:.4f}\")\n            print(f\"     AIC: {aic:.2f}\")\n\n            if ks_p > 0.05:\n                print(f\"     \u2713 Cannot reject (good fit)\")\n            else:\n                print(f\"     \u2717 Reject (poor fit)\")\n\n        except Exception as e:\n            print(f\"\\n   {dist_name}: Fitting failed ({str(e)})\")\n\n    # Best fit (lowest AIC)\n    valid_fits = {k: v for k, v in fit_results.items() if 'aic' in v}\n    if valid_fits:\n        best_fit_name = min(valid_fits.keys(), key=lambda k: valid_fits[k]['aic'])\n        best_fit = valid_fits[best_fit_name]\n\n        print(f\"\\n   Best fit (lowest AIC): {best_fit_name}\")\n        print(f\"     AIC = {best_fit['aic']:.2f}\")\n\n    # Risk analysis\n    print(f\"\\n6. Risk Analysis:\")\n    print(\"-\" * 70)\n\n    # Value at Risk (VaR)\n    risk_levels = [0.01, 0.05, 0.10]\n\n    print(f\"\\n   Value at Risk (VaR):\")\n    for alpha_risk in risk_levels:\n        var = np.percentile(settling_times, (1-alpha_risk)*100)\n        print(f\"     VaR({alpha_risk*100:.0f}%): {var:.3f} s  (top {alpha_risk*100}% worst cases)\")\n\n    # Conditional Value at Risk (CVaR / Expected Shortfall)\n    print(f\"\\n   Conditional Value at Risk (CVaR / Expected Shortfall):\")\n    for alpha_risk in risk_levels:\n        var = np.percentile(settling_times, (1-alpha_risk)*100)\n        tail_values = settling_times[settling_times >= var]\n        cvar = np.mean(tail_values) if len(tail_values) > 0 else var\n        print(f\"     CVaR({alpha_risk*100:.0f}%): {cvar:.3f} s  (avg of worst {alpha_risk*100}%)\")\n\n    # Safety validation\n    print(f\"\\n7. Safety Validation:\")\n    print(\"-\" * 70)\n\n    # Empirical probability\n    n_exceeds = np.sum(settling_times > SAFETY_THRESHOLD)\n    prob_exceed_empirical = n_exceeds / len(settling_times)\n\n    print(f\"\\n   Empirical Analysis:\")\n    print(f\"     Samples exceeding {SAFETY_THRESHOLD}s: {n_exceeds}/{len(settling_times)}\")\n    print(f\"     Empirical P(T > {SAFETY_THRESHOLD}s) = {prob_exceed_empirical:.4f} ({prob_exceed_empirical*100:.2f}%)\")\n\n    # Bootstrap confidence interval for exceedance probability\n    bootstrap_probs = []\n    for _ in range(n_bootstrap):\n        bootstrap_sample = np.random.choice(settling_times, size=len(settling_times), replace=True)\n        prob = np.sum(bootstrap_sample > SAFETY_THRESHOLD) / len(bootstrap_sample)\n        bootstrap_probs.append(prob)\n\n    prob_ci = [\n        np.percentile(bootstrap_probs, 2.5),\n        np.percentile(bootstrap_probs, 97.5)\n    ]\n\n    print(f\"     95% CI for P(T > {SAFETY_THRESHOLD}s): [{prob_ci[0]:.4f}, {prob_ci[1]:.4f}]\")\n\n    # Fitted distribution probability\n    if valid_fits:\n        best_dist = distributions[best_fit_name]\n        prob_exceed_fitted = 1 - best_dist.cdf(SAFETY_THRESHOLD, *best_fit['params'])\n\n        print(f\"\\n   Fitted {best_fit_name} Distribution:\")\n        print(f\"     P(T > {SAFETY_THRESHOLD}s) = {prob_exceed_fitted:.4f} ({prob_exceed_fitted*100:.2f}%)\")\n\n        # Required confidence\n        prob_within = 1 - prob_exceed_fitted\n        print(f\"     P(T \u2264 {SAFETY_THRESHOLD}s) = {prob_within:.4f} ({prob_within*100:.2f}%)\")\n\n        if prob_within >= REQUIRED_CONFIDENCE:\n            print(f\"     \u2713 PASSES safety requirement ({prob_within*100:.1f}% \u2265 {REQUIRED_CONFIDENCE*100}%)\")\n        else:\n            print(f\"     \u2717 FAILS safety requirement ({prob_within*100:.1f}% < {REQUIRED_CONFIDENCE*100}%)\")\n\n            # Calculate required improvement\n            target_percentile = best_dist.ppf(REQUIRED_CONFIDENCE, *best_fit['params'])\n            print(f\"\\n     To meet {REQUIRED_CONFIDENCE*100}% confidence:\")\n            print(f\"       Target: {REQUIRED_CONFIDENCE*100}% percentile = {target_percentile:.3f} s\")\n            print(f\"       Required: {target_percentile:.3f}s < {SAFETY_THRESHOLD}s\")\n\n            if target_percentile >= SAFETY_THRESHOLD:\n                improvement_needed = target_percentile - SAFETY_THRESHOLD\n                print(f\"       \u26a0 Need to improve {REQUIRED_CONFIDENCE*100}% percentile by {improvement_needed:.3f}s\")\n\n    # Extreme value analysis\n    print(f\"\\n8. Extreme Value Analysis:\")\n    print(\"-\" * 70)\n\n    # Block maxima method\n    block_size = 20\n    n_blocks = len(settling_times) // block_size\n    block_maxima = [np.max(settling_times[i*block_size:(i+1)*block_size]) for i in range(n_blocks)]\n\n    # Fit GEV distribution to block maxima\n    try:\n        gev_params = stats.genextreme.fit(block_maxima)\n\n        print(f\"   Block Maxima Method:\")\n        print(f\"     Block size: {block_size}\")\n        print(f\"     Number of blocks: {n_blocks}\")\n        print(f\"     GEV parameters: \u03be={gev_params[0]:.3f}, \u03bc={gev_params[1]:.3f}, \u03c3={gev_params[2]:.3f}\")\n\n        # Return levels\n        return_periods = [10, 50, 100]\n        print(f\"\\n     Return Levels:\")\n        for period in return_periods:\n            return_level = stats.genextreme.ppf(1 - 1/period, *gev_params)\n            print(f\"       {period}-run worst-case: {return_level:.3f} s\")\n\n    except Exception as e:\n        print(f\"   Extreme value analysis failed: {str(e)}\")\n\n    # Summary\n    print(f\"\\n\" + \"=\" * 70)\n    print(\"UNCERTAINTY QUANTIFICATION SUMMARY:\")\n    print(\"=\" * 70)\n\n    print(f\"\\n1. Point Estimates:\")\n    print(f\"   Mean: {np.mean(settling_times):.3f} s\")\n    print(f\"   95th percentile: {np.percentile(settling_times, 95):.3f} s\")\n    print(f\"   99th percentile: {np.percentile(settling_times, 99):.3f} s\")\n\n    print(f\"\\n2. Uncertainty (95% CI):\")\n    print(f\"   Mean: [{mean_ci[0]:.3f}, {mean_ci[1]:.3f}] s\")\n    print(f\"   95th percentile: [{percentile_95_ci[0]:.3f}, {percentile_95_ci[1]:.3f}] s\")\n\n    print(f\"\\n3. Distributional Model:\")\n    if valid_fits:\n        print(f\"   Best fit: {best_fit_name}\")\n        print(f\"   Goodness-of-fit p-value: {best_fit['ks_p']:.4f}\")\n\n    print(f\"\\n4. Safety Assessment:\")\n    print(f\"   Threshold: {SAFETY_THRESHOLD}s\")\n    print(f\"   Required confidence: {REQUIRED_CONFIDENCE*100}%\")\n    if valid_fits:\n        if prob_within >= REQUIRED_CONFIDENCE:\n            print(f\"   \u2713 PASSES: {prob_within*100:.1f}% of scenarios meet requirement\")\n        else:\n            print(f\"   \u2717 FAILS: Only {prob_within*100:.1f}% meet requirement\")\n\n    print(f\"\\n5. Recommendations:\")\n    if prob_within >= REQUIRED_CONFIDENCE:\n        print(f\"   \u2713 Controller ready for safety-critical deployment\")\n        print(f\"   \u2713 Uncertainty adequately quantified\")\n    else:\n        print(f\"   \u2717 Further controller improvement needed\")\n        print(f\"   \u25a1 Option 1: Tune controller for better worst-case performance\")\n        print(f\"   \u25a1 Option 2: Increase safety threshold\")\n        print(f\"   \u25a1 Option 3: Accept lower confidence level (if acceptable)\")\n\n    print(\"=\" * 70)\n\n\nif __name__ == \"__main__\":\n    main()",
    "lines": 338,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "35c6a23b"
  },
  {
    "id": "PHASE_3_1_COMPLETION_REPORT_1_f383ab1d",
    "file": "docs\\visualization\\PHASE_3_1_COMPLETION_REPORT.md",
    "index": 1,
    "code": "ITERATION_PATTERN = r'(\\d+)/(\\d+),\\s*best_cost=([\\d.e+\\-]+)(?:\\s|$)'\nFINAL_COST_PATTERN = r'Optimization finished.*best cost:\\s*([\\d.]+),\\s*best pos:\\s*\\[([\\d.,\\s]+)\\]'\nTOTAL_TIME_PATTERN = r'Optimization completed in\\s*([\\d.]+)s'",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f383ab1d"
  },
  {
    "id": "PHASE_3_1_COMPLETION_REPORT_2_6545bcee",
    "file": "docs\\visualization\\PHASE_3_1_COMPLETION_REPORT.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Parse log \u2192 list of dictionaries\ndata_rows = [{'iteration': i, 'cost': c, 'timestamp': ts}, ...]\n\n# 2. Create DataFrame\ndf = pd.DataFrame(data_rows)\n\n# 3. Sort and calculate derived metrics\ndf = df.sort_values('iteration').reset_index(drop=True)\ndf['improvement'] = df['cost'].shift(1) - df['cost']\n\n# 4. Compute convergence thresholds\ntarget_90 = initial_cost - 0.90 * (initial_cost - best_cost)\niters_90 = df[df['cost'] <= target_90]['iteration'].min()",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6545bcee"
  },
  {
    "id": "PHASE_3_1_COMPLETION_REPORT_3_467d71b5",
    "file": "docs\\visualization\\PHASE_3_1_COMPLETION_REPORT.md",
    "index": 3,
    "code": "import pandas as pd\nimport numpy as np\n\n# DataFrame creation from log data\ndf = pd.DataFrame(data_rows)\n\n# Sorting and indexing\ndf = df.sort_values('iteration').reset_index(drop=True)\n\n# Time series calculations\ndf['elapsed_seconds'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()\n\n# Rolling statistics\ndf['improvement'] = df['cost'].shift(1) - df['cost']",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "467d71b5"
  },
  {
    "id": "PHASE_3_1_COMPLETION_REPORT_4_c5611c48",
    "file": "docs\\visualization\\PHASE_3_1_COMPLETION_REPORT.md",
    "index": 4,
    "code": "import numpy as np\n\n# NaN handling for missing timestamps\ndf['elapsed_seconds'] = np.nan\n\n# Array operations for thresholds\ntarget_90 = initial_cost - 0.90 * (initial_cost - best_cost)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5611c48"
  },
  {
    "id": "complete_integration_guide_1_b3fbebe3",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 1,
    "code": "# Python API usage\nfrom src.controllers.factory import create_controller\nfrom src.core.simulation_runner import run_simulation\n\n# Create controller\ncontroller = create_controller(\n    'classical_smc',\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0\n)\n\n# Run simulation\nresults = run_simulation(\n    controller=controller,\n    duration=10.0,\n    dt=0.01,\n    plot=True\n)\n\n# Analyze performance\nprint(f\"Settling time: {results.metrics.settling_time:.2f}s\")\nprint(f\"Overshoot: {results.metrics.overshoot:.1f}%\")\nprint(f\"Control effort: {results.metrics.control_effort:.2f}N\u00b2\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3fbebe3"
  },
  {
    "id": "complete_integration_guide_2_1c5e39b3",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 2,
    "code": "# Monitor adaptation process\nfrom src.utils.monitoring import AdaptationMonitor\n\nmonitor = AdaptationMonitor()\ncontroller = create_controller('adaptive_smc', gains=[10, 8, 15, 12, 0.5])\n\n# Run with monitoring\nresults = run_simulation_with_monitoring(\n    controller=controller,\n    monitor=monitor,\n    duration=15.0  # Longer to observe adaptation\n)\n\n# Plot adaptation history\nmonitor.plot_adaptation_evolution()\nmonitor.save_adaptation_data('adaptation_log.json')",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c5e39b3"
  },
  {
    "id": "complete_integration_guide_3_2995872e",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 3,
    "code": "# Analyze chattering characteristics\nfrom src.utils.analysis import ChatteringAnalyzer\n\ncontroller = create_controller('sta_smc', gains=[25, 10, 15, 12, 20, 15])\nresults = run_simulation(controller=controller, duration=10.0)\n\nanalyzer = ChatteringAnalyzer()\nchattering_metrics = analyzer.analyze(results.control_history)\n\nprint(f\"Chattering index: {chattering_metrics.index:.4f}\")\nprint(f\"High-frequency content: {chattering_metrics.hf_content:.2f}%\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2995872e"
  },
  {
    "id": "complete_integration_guide_4_975605ae",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 4,
    "code": "# Demonstrate hybrid capabilities\nfrom src.controllers.smc.hybrid_adaptive_sta_smc import HybridAdaptiveSTASMC\n\ncontroller = HybridAdaptiveSTASMC(\n    gains=[77.6216, 44.449, 17.3134, 14.25],  # PSO-optimized\n    dt=0.01,\n    max_force=100.0,\n    enable_equivalent=True,\n    use_relative_surface=False,  # Absolute coordinates\n    k1_init=2.0,\n    k2_init=1.0,\n    gamma1=0.5,\n    gamma2=0.3\n)\n\n# Monitor hybrid operation\nresults = run_simulation_with_diagnostics(\n    controller=controller,\n    duration=10.0,\n    diagnostics=['adaptation', 'surface', 'modes']\n)\n\n# Generate hybrid analysis report\ngenerate_hybrid_analysis_report(results, 'hybrid_analysis.pdf')",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "975605ae"
  },
  {
    "id": "complete_integration_guide_5_70a1c2bd",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/custom_batch_optimization.py\nfrom src.optimizer.pso_optimizer import PSOTuner\nfrom src.controllers.factory import get_controller_types\n\ndef optimize_all_controllers():\n    \"\"\"Optimize all available controllers.\"\"\"\n\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n    results = {}\n\n    for controller_type in controllers:\n        print(f\"\\n\ud83d\ude80 Optimizing {controller_type}...\")\n\n        # Get controller-specific PSO bounds\n        bounds = get_pso_bounds(controller_type)\n\n        # Create PSO tuner\n        tuner = PSOTuner(\n            bounds=bounds,\n            n_particles=20,\n            iters=200,\n            options={'c1': 2.0, 'c2': 2.0, 'w': 0.7}\n        )\n\n        # Optimize\n        best_gains, best_cost = tuner.optimize(\n            controller_type=controller_type,\n            dynamics=dynamics_model,\n            seed=42\n        )\n\n        results[controller_type] = {\n            'gains': best_gains,\n            'cost': best_cost,\n            'convergence': tuner.cost_history\n        }\n\n        print(f\"\u2705 {controller_type}: Cost = {best_cost:.6f}\")\n\n    return results\n\nif __name__ == \"__main__\":\n    results = optimize_all_controllers()\n    save_optimization_results(results, 'complete_optimization_results.json')",
    "lines": 47,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "70a1c2bd"
  },
  {
    "id": "complete_integration_guide_6_5af23439",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 6,
    "code": "# Multi-objective optimization for competing requirements\nfrom src.optimizer.multi_objective_pso import MultiObjectivePSOTuner\n\ndef multi_objective_optimization():\n    \"\"\"Optimize for multiple competing objectives.\"\"\"\n\n    objectives = {\n        'tracking_performance': 0.4,  # Weight: 40%\n        'control_effort': 0.3,        # Weight: 30%\n        'robustness': 0.3             # Weight: 30%\n    }\n\n    tuner = MultiObjectivePSOTuner(\n        bounds=get_pso_bounds('hybrid_adaptive_sta_smc'),\n        objectives=objectives,\n        n_particles=30,\n        iters=300\n    )\n\n    pareto_front = tuner.optimize_pareto_front()\n    return pareto_front",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5af23439"
  },
  {
    "id": "complete_integration_guide_7_fc404825",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Adaptive PSO with time-varying parameters\npso_config = {\n    'n_particles': 25,\n    'iters': 250,\n    'options': {\n        'c1': lambda t: 2.5 - 1.5 * t / 250,  # Decreasing cognitive\n        'c2': lambda t: 0.5 + 2.0 * t / 250,  # Increasing social\n        'w': lambda t: 0.9 - 0.5 * t / 250    # Decreasing inertia\n    }\n}",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc404825"
  },
  {
    "id": "complete_integration_guide_8_709b02b6",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 8,
    "code": "# scripts/detailed_controller_comparison.py\nfrom src.utils.comparison import ControllerComparator\n\ndef comprehensive_comparison():\n    \"\"\"Perform comprehensive controller comparison.\"\"\"\n\n    # Controllers to compare\n    controllers_config = {\n        'classical_smc': {\n            'gains': [10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n            'color': 'blue',\n            'label': 'Classical SMC'\n        },\n        'adaptive_smc': {\n            'gains': [10.0, 8.0, 15.0, 12.0, 0.5],\n            'color': 'green',\n            'label': 'Adaptive SMC'\n        },\n        'sta_smc': {\n            'gains': [25.0, 10.0, 15.0, 12.0, 20.0, 15.0],\n            'color': 'red',\n            'label': 'STA SMC'\n        },\n        'hybrid_adaptive_sta_smc': {\n            'gains': [77.6216, 44.449, 17.3134, 14.25],\n            'color': 'purple',\n            'label': 'Hybrid SMC'\n        }\n    }\n\n    # Test scenarios\n    test_scenarios = [\n        {'name': 'nominal', 'disturbance': None, 'uncertainty': 0.0},\n        {'name': 'disturbance', 'disturbance': 'step_10N', 'uncertainty': 0.0},\n        {'name': 'uncertainty', 'disturbance': None, 'uncertainty': 0.2},\n        {'name': 'combined', 'disturbance': 'sine_5N_1Hz', 'uncertainty': 0.15}\n    ]\n\n    comparator = ControllerComparator()\n\n    for scenario in test_scenarios:\n        print(f\"\\n\ud83d\udcca Testing scenario: {scenario['name']}\")\n\n        results = comparator.compare_controllers(\n            controllers_config=controllers_config,\n            scenario=scenario,\n            duration=10.0,\n            monte_carlo_runs=25\n        )\n\n        # Generate scenario report\n        comparator.generate_scenario_report(\n            results=results,\n            scenario=scenario,\n            output_file=f\"comparison_{scenario['name']}.pdf\"\n        )\n\n    # Generate overall comparison\n    comparator.generate_master_comparison(\n        output_file=\"master_controller_comparison.pdf\"\n    )\n\nif __name__ == \"__main__\":\n    comprehensive_comparison()",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "709b02b6"
  },
  {
    "id": "complete_integration_guide_9_3800e027",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Statistical validation of controller performance\nfrom src.utils.statistics import MonteCarloAnalyzer\n\ndef statistical_performance_analysis():\n    \"\"\"Perform statistical analysis of controller performance.\"\"\"\n\n    analyzer = MonteCarloAnalyzer(n_runs=100)\n\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n    statistics = {}\n\n    for controller_type in controllers:\n        print(f\"\ud83d\udcc8 Analyzing {controller_type}...\")\n\n        # Run Monte Carlo analysis\n        results = analyzer.analyze_controller(\n            controller_type=controller_type,\n            test_conditions={\n                'initial_disturbance': 'random_uniform_0.1',\n                'parameter_uncertainty': 0.1,\n                'measurement_noise': 0.01\n            }\n        )\n\n        statistics[controller_type] = {\n            'settling_time': {\n                'mean': results.settling_time.mean(),\n                'std': results.settling_time.std(),\n                'confidence_interval': results.settling_time_ci_95\n            },\n            'overshoot': {\n                'mean': results.overshoot.mean(),\n                'std': results.overshoot.std(),\n                'confidence_interval': results.overshoot_ci_95\n            },\n            'control_effort': {\n                'mean': results.control_effort.mean(),\n                'std': results.control_effort.std(),\n                'confidence_interval': results.control_effort_ci_95\n            }\n        }\n\n    # Statistical comparison tests\n    comparison_results = analyzer.statistical_comparison(statistics)\n\n    return statistics, comparison_results",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3800e027"
  },
  {
    "id": "complete_integration_guide_10_49fd8181",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 10,
    "code": "# Statistical hypothesis testing for controller comparison\nfrom scipy import stats\nimport numpy as np\n\ndef hypothesis_testing_analysis():\n    \"\"\"Perform hypothesis testing for controller superiority.\"\"\"\n\n    # Null hypothesis: No significant difference between controllers\n    # Alternative: Hybrid SMC performs significantly better\n\n    controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n    performance_data = collect_performance_data(controllers, n_runs=50)\n\n    # Perform pairwise t-tests\n    test_results = {}\n\n    for i, controller_a in enumerate(controllers):\n        for j, controller_b in enumerate(controllers[i+1:], i+1):\n            # Two-sample t-test\n            t_stat, p_value = stats.ttest_ind(\n                performance_data[controller_a]['settling_time'],\n                performance_data[controller_b]['settling_time'],\n                equal_var=False  # Welch's t-test\n            )\n\n            test_results[f\"{controller_a}_vs_{controller_b}\"] = {\n                't_statistic': t_stat,\n                'p_value': p_value,\n                'significant': p_value < 0.05,\n                'effect_size': cohen_d(\n                    performance_data[controller_a]['settling_time'],\n                    performance_data[controller_b]['settling_time']\n                )\n            }\n\n    return test_results",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49fd8181"
  },
  {
    "id": "complete_integration_guide_11_8113361e",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 11,
    "code": "# Real-time monitoring setup\nfrom src.utils.monitoring import RealTimeMonitor\nfrom src.core.real_time_controller import RealTimeController\n\ndef real_time_integration():\n    \"\"\"Set up real-time control with monitoring.\"\"\"\n\n    # Create real-time controller\n    rt_controller = RealTimeController(\n        controller_type='hybrid_adaptive_sta_smc',\n        control_frequency=1000,  # 1 kHz\n        max_jitter=0.001  # 1ms max jitter\n    )\n\n    # Set up monitoring\n    monitor = RealTimeMonitor(\n        metrics=['latency', 'jitter', 'deadline_misses', 'cpu_usage'],\n        alert_thresholds={\n            'latency': 0.005,      # 5ms warning\n            'jitter': 0.002,       # 2ms warning\n            'deadline_miss_rate': 0.01,  # 1% warning\n            'cpu_usage': 0.8       # 80% warning\n        }\n    )\n\n    # Run real-time control loop\n    rt_controller.run_with_monitoring(\n        monitor=monitor,\n        duration=60.0,  # 1 minute test\n        safety_checks=True\n    )\n\n    # Generate real-time performance report\n    monitor.generate_performance_report('realtime_performance.pdf')",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8113361e"
  },
  {
    "id": "complete_integration_guide_12_0c6198f9",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 12,
    "code": "# Distributed control system\nfrom src.distributed import ControllerNode, CoordinatorNode\n\ndef distributed_control_setup():\n    \"\"\"Set up distributed control architecture.\"\"\"\n\n    # Coordinator node\n    coordinator = CoordinatorNode(\n        port=8000,\n        controllers=['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc'],\n        load_balancing='performance_based'\n    )\n\n    # Controller nodes\n    nodes = []\n    for i, controller_type in enumerate(['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']):\n        node = ControllerNode(\n            node_id=f\"node_{i}\",\n            controller_type=controller_type,\n            coordinator_address=\"localhost:8000\",\n            port=8001 + i\n        )\n        nodes.append(node)\n\n    # Start distributed system\n    coordinator.start()\n    for node in nodes:\n        node.start()\n\n    return coordinator, nodes",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c6198f9"
  },
  {
    "id": "complete_integration_guide_13_0d1841db",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 13,
    "code": "# Adaptive controller selection based on performance\nfrom src.utils.adaptive_selection import ControllerSelector\n\nclass AdaptiveControllerSystem:\n    \"\"\"System that adaptively selects best controller.\"\"\"\n\n    def __init__(self):\n        self.controllers = {\n            'classical_smc': create_controller('classical_smc'),\n            'adaptive_smc': create_controller('adaptive_smc'),\n            'sta_smc': create_controller('sta_smc'),\n            'hybrid_adaptive_sta_smc': create_controller('hybrid_adaptive_sta_smc')\n        }\n\n        self.selector = ControllerSelector(\n            performance_window=100,  # Evaluate over 100 samples\n            switching_threshold=0.1,  # 10% performance improvement\n            switching_cooldown=50    # Minimum 50 samples between switches\n        )\n\n    def adaptive_control_loop(self, duration: float):\n        \"\"\"Run adaptive control with automatic controller selection.\"\"\"\n\n        current_controller = 'hybrid_adaptive_sta_smc'  # Start with best\n        performance_history = []\n\n        for t in simulation_time_steps(duration):\n            state = get_system_state()\n\n            # Compute control with current controller\n            control = self.controllers[current_controller].compute_control(state)\n\n            # Apply control\n            apply_control(control)\n\n            # Monitor performance\n            performance = self.selector.evaluate_performance(state, control)\n            performance_history.append(performance)\n\n            # Check if controller switch needed\n            if self.selector.should_switch(performance_history):\n                new_controller = self.selector.select_best_controller(\n                    self.controllers,\n                    current_state=state,\n                    performance_history=performance_history\n                )\n\n                if new_controller != current_controller:\n                    print(f\"\ud83d\udd04 Switching from {current_controller} to {new_controller}\")\n                    current_controller = new_controller\n\n        return performance_history",
    "lines": 52,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d1841db"
  },
  {
    "id": "complete_integration_guide_14_d4dbfc82",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Validate safety systems\nfrom src.safety import SafetyValidator\n\ndef validate_safety_systems():\n    \"\"\"Validate all safety mechanisms.\"\"\"\n\n    validator = SafetyValidator()\n\n    safety_tests = [\n        'emergency_stop',\n        'actuator_saturation',\n        'state_bounds_checking',\n        'numerical_stability',\n        'fault_detection',\n        'graceful_degradation'\n    ]\n\n    results = {}\n    for test in safety_tests:\n        print(f\"\ud83d\udee1\ufe0f Testing {test}...\")\n        result = validator.run_safety_test(test)\n        results[test] = result\n\n        if not result.passed:\n            print(f\"\u274c SAFETY TEST FAILED: {test}\")\n            print(f\"   Details: {result.details}\")\n            return False\n\n        print(f\"\u2705 {test} passed\")\n\n    print(\"\\n\ud83d\udee1\ufe0f All safety tests passed - system ready for deployment\")\n    return True",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4dbfc82"
  },
  {
    "id": "complete_integration_guide_15_a7ba9159",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# scripts/deploy_production.py\nimport argparse\nimport logging\nfrom src.production import ProductionManager\n\ndef deploy_production_system():\n    \"\"\"Deploy production-ready control system.\"\"\"\n\n    # Set up production logging\n    logging.basicConfig(\n        level=logging.WARNING,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.FileHandler('production.log'),\n            logging.StreamHandler()\n        ]\n    )\n\n    # Initialize production manager\n    manager = ProductionManager(\n        config_file='config/production.yaml',\n        safety_mode=True,\n        monitoring=True\n    )\n\n    # Pre-deployment checks\n    if not manager.run_pre_deployment_checks():\n        logging.error(\"Pre-deployment checks failed\")\n        return False\n\n    # Deploy system\n    try:\n        manager.deploy_system()\n        logging.info(\"Production system deployed successfully\")\n\n        # Start monitoring\n        manager.start_monitoring()\n\n        # Run production control loop\n        manager.run_production_loop()\n\n    except Exception as e:\n        logging.error(f\"Production deployment failed: {e}\")\n        manager.emergency_shutdown()\n        return False\n\n    return True\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Deploy production control system')\n    parser.add_argument('--config', default='config/production.yaml', help='Production config file')\n    parser.add_argument('--dry-run', action='store_true', help='Perform dry run without actual deployment')\n    args = parser.parse_args()\n\n    if args.dry_run:\n        print(\"\ud83e\uddea Performing dry run...\")\n        # Validate configuration and check dependencies\n        validate_production_config(args.config)\n    else:\n        print(\"\ud83d\ude80 Deploying production system...\")\n        deploy_production_system()",
    "lines": 64,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7ba9159"
  },
  {
    "id": "complete_integration_guide_16_acba88c5",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 16,
    "code": "# Debug PSO optimization problems\nfrom src.utils.debugging import PSODebugger\n\ndef debug_pso_optimization():\n    \"\"\"Debug PSO optimization issues.\"\"\"\n\n    debugger = PSODebugger()\n\n    # Common PSO issues and solutions\n    issues = {\n        'slow_convergence': {\n            'symptoms': ['high iteration count', 'plateau in cost'],\n            'solutions': ['increase particles', 'adjust cognitive/social parameters', 'check bounds']\n        },\n        'premature_convergence': {\n            'symptoms': ['early plateau', 'low diversity'],\n            'solutions': ['increase inertia', 'add mutation', 'diversify initialization']\n        },\n        'no_convergence': {\n            'symptoms': ['cost increases', 'unstable behavior'],\n            'solutions': ['check fitness function', 'validate bounds', 'reduce parameter count']\n        }\n    }\n\n    # Automated diagnosis\n    diagnosis = debugger.diagnose_pso_issues(\n        controller_type='hybrid_adaptive_sta_smc',\n        pso_history=load_pso_history(),\n        known_issues=issues\n    )\n\n    return diagnosis",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "acba88c5"
  },
  {
    "id": "complete_integration_guide_17_2a6c175a",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 17,
    "code": "# Continuous system health monitoring\nfrom src.monitoring import SystemHealthMonitor\n\nclass HealthMonitoringWorkflow:\n    \"\"\"Comprehensive system health monitoring.\"\"\"\n\n    def __init__(self):\n        self.monitor = SystemHealthMonitor(\n            check_interval=10.0,  # 10 seconds\n            alert_thresholds={\n                'cpu_usage': 0.8,\n                'memory_usage': 0.9,\n                'control_latency': 0.01,\n                'error_rate': 0.05\n            }\n        )\n\n    def start_monitoring(self):\n        \"\"\"Start continuous health monitoring.\"\"\"\n\n        health_checks = [\n            'controller_responsiveness',\n            'memory_usage',\n            'cpu_utilization',\n            'network_connectivity',\n            'sensor_data_quality',\n            'actuator_functionality',\n            'safety_system_status'\n        ]\n\n        self.monitor.start_continuous_monitoring(health_checks)\n\n    def generate_health_report(self):\n        \"\"\"Generate comprehensive health report.\"\"\"\n\n        report = self.monitor.generate_health_report()\n\n        # System status summary\n        print(f\"\ud83c\udfe5 System Health Report\")\n        print(f\"Overall Status: {'\u2705 HEALTHY' if report.overall_healthy else '\u274c ISSUES DETECTED'}\")\n        print(f\"Uptime: {report.uptime}\")\n        print(f\"Last Check: {report.last_check}\")\n\n        # Component health\n        for component, status in report.component_health.items():\n            status_icon = \"\u2705\" if status.healthy else \"\u274c\"\n            print(f\"{status_icon} {component}: {status.message}\")\n\n        return report",
    "lines": 49,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a6c175a"
  },
  {
    "id": "complete_integration_guide_18_c5e13cbd",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Template for new controller development\nfrom src.controllers.base import BaseController\nfrom typing import Tuple, Dict, Any, List\nimport numpy as np\n\nclass NewControllerTemplate(BaseController):\n    \"\"\"Template for implementing new controllers.\"\"\"\n\n    n_gains: int = 4  # Define number of tunable parameters\n\n    def __init__(self, gains: List[float], dt: float, max_force: float, **kwargs):\n        \"\"\"Initialize new controller.\"\"\"\n\n        # Parameter validation\n        if len(gains) != self.n_gains:\n            raise ValueError(f\"Expected {self.n_gains} gains, got {len(gains)}\")\n\n        # Store parameters\n        self.gains = gains\n        self.dt = dt\n        self.max_force = max_force\n\n        # Initialize controller-specific parameters\n        self._initialize_controller_parameters(**kwargs)\n\n    def compute_control(self, state: np.ndarray,\n                       state_vars: Tuple[Any, ...] = None,\n                       history: Dict[str, List[Any]] = None) -> ControllerOutput:\n        \"\"\"Compute control output.\"\"\"\n\n        # Input validation\n        if not np.all(np.isfinite(state)):\n            return self._safe_control_output()\n\n        # Initialize state variables if needed\n        if state_vars is None:\n            state_vars = self.initialize_state()\n\n        if history is None:\n            history = self.initialize_history()\n\n        # Implement control algorithm here\n        control_output = self._compute_control_algorithm(state, state_vars, history)\n\n        # Apply safety constraints\n        control_output = self._apply_safety_constraints(control_output)\n\n        # Update history\n        self._update_history(history, state, control_output)\n\n        return ControllerOutput(\n            control=control_output,\n            state_vars=state_vars,\n            history=history\n        )\n\n    def _compute_control_algorithm(self, state, state_vars, history):\n        \"\"\"Implement specific control algorithm.\"\"\"\n        # TODO: Implement control law\n        raise NotImplementedError(\"Implement control algorithm\")\n\n    def validate_gains(self, gains: np.ndarray) -> np.ndarray:\n        \"\"\"Validate controller gains for PSO optimization.\"\"\"\n        # TODO: Implement gain validation logic\n        return np.ones(gains.shape[0], dtype=bool)",
    "lines": 68,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5e13cbd"
  },
  {
    "id": "complete_integration_guide_19_ec58caa8",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 19,
    "code": "# Comprehensive testing for new controllers\nimport pytest\nfrom hypothesis import given, strategies as st\n\nclass TestNewController:\n    \"\"\"Comprehensive test suite for new controller.\"\"\"\n\n    def test_controller_initialization(self):\n        \"\"\"Test controller initialization.\"\"\"\n        controller = NewControllerTemplate(\n            gains=[1.0, 2.0, 3.0, 4.0],\n            dt=0.01,\n            max_force=100.0\n        )\n        assert controller.n_gains == 4\n        assert controller.gains == [1.0, 2.0, 3.0, 4.0]\n\n    @given(st.lists(st.floats(min_value=-10, max_value=10), min_size=6, max_size=6))\n    def test_control_computation_stability(self, state_values):\n        \"\"\"Test control computation with random states.\"\"\"\n        controller = NewControllerTemplate(gains=[1, 2, 3, 4])\n        state = np.array(state_values)\n\n        result = controller.compute_control(state)\n\n        # Basic stability checks\n        assert result is not None\n        assert np.isfinite(result.control)\n        assert abs(result.control) <= controller.max_force\n\n    def test_pso_integration(self):\n        \"\"\"Test PSO optimization integration.\"\"\"\n        from src.optimizer.pso_optimizer import PSOTuner\n\n        bounds = [(0.1, 10.0)] * 4  # Bounds for 4 gains\n        tuner = PSOTuner(bounds=bounds, n_particles=10, iters=20)\n\n        best_gains, best_cost = tuner.optimize(\n            controller_type='new_controller_template',\n            dynamics=test_dynamics\n        )\n\n        assert len(best_gains) == 4\n        assert best_cost >= 0.0",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec58caa8"
  },
  {
    "id": "complete_integration_guide_20_c2888158",
    "file": "docs\\workflows\\complete_integration_guide.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n# Comprehensive integration testing\nfrom src.testing import IntegrationTestSuite\n\nclass ComprehensiveIntegrationTests:\n    \"\"\"Complete integration test suite.\"\"\"\n\n    def __init__(self):\n        self.test_suite = IntegrationTestSuite()\n\n    def run_complete_integration_tests(self):\n        \"\"\"Run all integration tests.\"\"\"\n\n        test_categories = [\n            'controller_factory_integration',\n            'pso_optimization_integration',\n            'simulation_engine_integration',\n            'safety_system_integration',\n            'monitoring_system_integration',\n            'configuration_system_integration'\n        ]\n\n        results = {}\n        for category in test_categories:\n            print(f\"\ud83e\uddea Running {category}...\")\n            results[category] = self.test_suite.run_test_category(category)\n\n        # Generate integration test report\n        self.test_suite.generate_integration_report(results)\n\n        return results\n\n    def test_controller_interoperability(self):\n        \"\"\"Test that all controllers work with all system components.\"\"\"\n\n        controllers = ['classical_smc', 'adaptive_smc', 'sta_smc', 'hybrid_adaptive_sta_smc']\n        components = ['simulation_engine', 'pso_optimizer', 'monitoring_system', 'safety_system']\n\n        compatibility_matrix = {}\n\n        for controller in controllers:\n            compatibility_matrix[controller] = {}\n            for component in components:\n                try:\n                    result = self.test_suite.test_component_compatibility(controller, component)\n                    compatibility_matrix[controller][component] = result.passed\n                except Exception as e:\n                    compatibility_matrix[controller][component] = False\n\n        return compatibility_matrix",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2888158"
  },
  {
    "id": "configuration_1_2fa7a6af",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 1,
    "code": "from src.config import load_config\n\n# Load from default config.yaml\nconfig = load_config('config.yaml')\n\n# Access configuration sections\nphysics = config.dip_params\ncontrollers = config.controllers\nsimulation = config.simulation\npso = config.pso",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2fa7a6af"
  },
  {
    "id": "configuration_2_e8e418b4",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 2,
    "code": "try:\n    config = load_config('config.yaml')\n    print(\"Configuration valid!\")\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e8e418b4"
  },
  {
    "id": "configuration_3_44a4c728",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 3,
    "code": "# Reject any extra fields not in schema\nconfig = load_config('config.yaml', allow_unknown=False)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "44a4c728"
  },
  {
    "id": "configuration_4_329ad02b",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 4,
    "code": "# Load different configs for different scenarios\nconfig_baseline = load_config('config.yaml')\nconfig_challenging = load_config('config_challenging.yaml')\nconfig_hil = load_config('config_hil.yaml')\n\n# Use appropriate config for each scenario\nif scenario == 'baseline':\n    runner = SimulationRunner(config_baseline)\nelif scenario == 'challenging':\n    runner = SimulationRunner(config_challenging)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "329ad02b"
  },
  {
    "id": "configuration_5_71480bbf",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 5,
    "code": "import yaml\nfrom src.config.schemas import DIPParams, SimulationConfig\n\n# Load only specific sections\nwith open('config.yaml', 'r') as f:\n    config_dict = yaml.safe_load(f)\n\n# Create partial config objects\nphysics = DIPParams(**config_dict['dip_params'])\nsim_settings = SimulationConfig(**config_dict['simulation'])",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71480bbf"
  },
  {
    "id": "configuration_6_ab42550e",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass DIPParams:\n    \"\"\"Double-inverted pendulum physics parameters.\"\"\"\n    m0: float = 1.5      # Cart mass (kg)\n    m1: float = 0.5      # First pendulum mass (kg)\n    m2: float = 0.75     # Second pendulum mass (kg)\n    l1: float = 0.5      # First pendulum length (m)\n    l2: float = 0.75     # Second pendulum length (m)\n    I1: Optional[float] = None  # Auto-calculate if None\n    I2: Optional[float] = None\n    b0: float = 0.1      # Cart friction\n    b1: float = 0.01     # Pendulum 1 friction\n    b2: float = 0.01     # Pendulum 2 friction\n    g: float = 9.81      # Gravity (m/s\u00b2)\n\n    def __post_init__(self):\n        \"\"\"Auto-calculate inertias if not provided.\"\"\"\n        if self.I1 is None:\n            self.I1 = (1/3) * self.m1 * self.l1**2\n        if self.I2 is None:\n            self.I2 = (1/3) * self.m2 * self.l2**2",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab42550e"
  },
  {
    "id": "configuration_7_3800875d",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass ClassicalSMCConfig:\n    \"\"\"Classical SMC configuration.\"\"\"\n    gains: List[float] = Field(..., min_items=6, max_items=6)\n    max_force: float = Field(..., gt=0)\n    boundary_layer: float = Field(default=0.01, gt=0)\n\n@dataclass\nclass AdaptiveSMCConfig:\n    \"\"\"Adaptive SMC configuration.\"\"\"\n    gains: List[float] = Field(..., min_items=5, max_items=5)\n    max_force: float = Field(..., gt=0)\n    adaptation_rate: float = Field(..., gt=0)\n    leak_rate: float = Field(default=0.1, ge=0)\n    rate_limit: float = Field(default=10.0, gt=0)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3800875d"
  },
  {
    "id": "configuration_8_ce9afdf4",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass SimulationConfig:\n    \"\"\"Simulation parameters.\"\"\"\n    duration: float = Field(..., gt=0)\n    dt: float = Field(..., gt=0, le=0.1)\n    use_full_dynamics: bool = False",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce9afdf4"
  },
  {
    "id": "configuration_9_8965fae3",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 9,
    "code": "from src.config.schemas import (\n    DIPParams, ClassicalSMCConfig, SimulationConfig, Config\n)\n\n# Create physics parameters\nphysics = DIPParams(\n    m0=1.5, m1=0.5, m2=0.75,\n    l1=0.5, l2=0.75,\n    b0=0.1, b1=0.01, b2=0.01,\n    g=9.81\n)\n\n# Create controller config\ncontroller_cfg = ClassicalSMCConfig(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Create simulation config\nsim_cfg = SimulationConfig(\n    duration=5.0,\n    dt=0.01,\n    use_full_dynamics=False\n)\n\n# Assemble complete config\nfull_config = Config(\n    dip_params=physics,\n    controllers={'classical_smc': controller_cfg},\n    simulation=sim_cfg\n)",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8965fae3"
  },
  {
    "id": "configuration_10_fad8256f",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 10,
    "code": "# Load base config\nbase_config = load_config('config.yaml')\n\n# Override specific parameters\nbase_config.simulation.duration = 10.0  # Run for 10 seconds\nbase_config.simulation.use_full_dynamics = True  # Use full dynamics\nbase_config.dip_params.m1 = 0.75  # Increase first pendulum mass\n\n# Use modified config\nrunner = SimulationRunner(base_config)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fad8256f"
  },
  {
    "id": "configuration_11_2d4f62e1",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 11,
    "code": "def merge_configs(base_config, override_config):\n    \"\"\"Merge two configurations, with override taking precedence.\"\"\"\n    import copy\n    merged = copy.deepcopy(base_config)\n\n    # Override physics params if specified\n    if override_config.dip_params is not None:\n        merged.dip_params = override_config.dip_params\n\n    # Override simulation settings\n    if override_config.simulation is not None:\n        merged.simulation = override_config.simulation\n\n    # Merge controller configs\n    for ctrl_name, ctrl_config in override_config.controllers.items():\n        merged.controllers[ctrl_name] = ctrl_config\n\n    return merged\n\n# Usage\nbase = load_config('config.yaml')\noverride = load_config('config_override.yaml')\nfinal_config = merge_configs(base, override)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d4f62e1"
  },
  {
    "id": "configuration_12_6351071d",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 12,
    "code": "import os\nfrom src.config import load_config\n\n# Use environment variable for config selection\nconfig_file = os.getenv('DIP_CONFIG', 'config.yaml')\nconfig = load_config(config_file)\n\n# Override parameters from environment\nif os.getenv('DIP_FULL_DYNAMICS'):\n    config.simulation.use_full_dynamics = True\n\nif os.getenv('DIP_DURATION'):\n    config.simulation.duration = float(os.getenv('DIP_DURATION'))",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6351071d"
  },
  {
    "id": "configuration_13_f26e61cb",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass PSOConfig:\n    \"\"\"PSO configuration with sensible defaults.\"\"\"\n    n_particles: int = 30\n    iters: int = 100\n    w: float = 0.7298        # Canonical PSO inertia\n    c1: float = 1.49618      # Cognitive coefficient\n    c2: float = 1.49618      # Social coefficient\n\n    def __post_init__(self):\n        \"\"\"Validate PSO parameters.\"\"\"\n        if self.n_particles < 10:\n            raise ValueError(\"Swarm too small (min 10 particles)\")\n        if self.iters < 20:\n            raise ValueError(\"Too few iterations (min 20)\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f26e61cb"
  },
  {
    "id": "configuration_14_529974fd",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_physics_params(params: DIPParams):\n    \"\"\"Validate physical constraints.\"\"\"\n    # Positive masses\n    if params.m0 <= 0 or params.m1 <= 0 or params.m2 <= 0:\n        raise ValueError(\"Masses must be positive\")\n\n    # Positive lengths\n    if params.l1 <= 0 or params.l2 <= 0:\n        raise ValueError(\"Lengths must be positive\")\n\n    # Reasonable gravity\n    if not (9.0 <= params.g <= 10.0):\n        raise ValueError(\"Gravity should be ~9.81 m/s\u00b2\")\n\n    # Friction coefficients non-negative\n    if params.b0 < 0 or params.b1 < 0 or params.b2 < 0:\n        raise ValueError(\"Friction coefficients must be non-negative\")\n\n    return True",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "529974fd"
  },
  {
    "id": "configuration_15_fffa513e",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n# development.yaml\nsimulation:\n  duration: 2.0              # Shorter for faster iteration\n  dt: 0.01\n  use_full_dynamics: false   # Simplified for speed\n\npso:\n  n_particles: 20            # Smaller swarm for speed\n  iters: 50\n\n# production.yaml\nsimulation:\n  duration: 10.0             # Full simulation\n  dt: 0.001                  # Fine timestep for accuracy\n  use_full_dynamics: true    # Full nonlinear dynamics\n\npso:\n  n_particles: 50            # Larger swarm for better results\n  iters: 200",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fffa513e"
  },
  {
    "id": "configuration_16_39bac9f9",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 16,
    "code": "import os\n\nenv = os.getenv('ENVIRONMENT', 'development')\nconfig_file = f'config_{env}.yaml'\nconfig = load_config(config_file)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "39bac9f9"
  },
  {
    "id": "configuration_17_ef5fec4a",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# scenarios/baseline.yaml\ninitial_conditions:\n  theta1_0: 0.1    # 5.7 degrees\n  theta2_0: 0.15   # 8.6 degrees\n\n# scenarios/challenging.yaml\ninitial_conditions:\n  theta1_0: 0.3    # 17 degrees\n  theta2_0: 0.4    # 23 degrees\n\n# scenarios/extreme.yaml\ninitial_conditions:\n  theta1_0: 0.5    # 28 degrees\n  theta2_0: 0.6    # 34 degrees",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef5fec4a"
  },
  {
    "id": "configuration_18_745e39d3",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 18,
    "code": "scenarios = ['baseline', 'challenging', 'extreme']\nresults = {}\n\nfor scenario in scenarios:\n    config = load_config(f'scenarios/{scenario}.yaml')\n    runner = SimulationRunner(config)\n    results[scenario] = runner.run(controller)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "745e39d3"
  },
  {
    "id": "configuration_19_dcb4df10",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 19,
    "code": "try:\n    config = load_config('config.yaml')\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n    # Check specific fields\n    # Fix config.yaml\n    # Reload",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dcb4df10"
  },
  {
    "id": "configuration_20_2de5bc5a",
    "file": "docs\\guides\\api\\configuration.md",
    "index": 20,
    "code": "# Use strict validation to catch typos\nconfig = load_config('config.yaml', allow_unknown=False)\n# Will raise error if unknown fields present",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2de5bc5a"
  },
  {
    "id": "controllers_1_51e84d3b",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 1,
    "code": "from src.controllers import create_controller, create_smc_for_pso\n\n# Option 1: Full configuration (recommended for general use)\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config.controllers.classical_smc\n)\n\n# Option 2: PSO-optimized (recommended for optimization workflows)\ncontroller = create_smc_for_pso(\n    smc_type=SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51e84d3b"
  },
  {
    "id": "controllers_2_f90fc26a",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 2,
    "code": "from src.controllers import SMCType\n\n# Available controller types\nSMCType.CLASSICAL           # Classical sliding mode control\nSMCType.SUPER_TWISTING      # Super-twisting algorithm (STA)\nSMCType.ADAPTIVE            # Adaptive SMC with online gain tuning\nSMCType.HYBRID              # Hybrid Adaptive STA-SMC",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f90fc26a"
  },
  {
    "id": "controllers_3_7a9dcda3",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 3,
    "code": "from src.config import load_config\nfrom src.controllers import create_controller\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller with full configuration\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=config.controllers.classical_smc\n)\n\n# Alternatively, specify config inline\nfrom src.config.schemas import ClassicalSMCConfig\n\ncontroller = create_controller(\n    controller_type='classical_smc',\n    config=ClassicalSMCConfig(\n        gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n        max_force=100.0,\n        boundary_layer=0.01\n    )\n)",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7a9dcda3"
  },
  {
    "id": "controllers_4_804b6ba2",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 4,
    "code": "from src.controllers import create_smc_for_pso, SMCType\n\n# Minimal PSO-friendly creation\ncontroller = create_smc_for_pso(\n    smc_type=SMCType.CLASSICAL,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01  # Optional parameter\n)\n\n# Used in PSO fitness function\ndef fitness_function(gains_array):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains_array)\n    result = simulate(controller)\n    return result['cost']",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "804b6ba2"
  },
  {
    "id": "controllers_5_b556a425",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 5,
    "code": "from src.controllers import get_gain_bounds_for_pso\n\n# Get recommended bounds for each controller type\nbounds_classical = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50), (1.0, 200), (0.0, 50)]\n\nbounds_adaptive = get_gain_bounds_for_pso(SMCType.ADAPTIVE)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50), (0.01, 10)]\n\n# Use with PSO\nfrom src.optimizer import PSOTuner\n\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=bounds_classical,\n    n_particles=30,\n    iters=100\n)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b556a425"
  },
  {
    "id": "controllers_6_b2fb16db",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 6,
    "code": "from src.controllers import validate_smc_gains\n\n# Validate gains before simulation\ngains = [10, 8, 15, 12, 50, 5]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, gains)\n\nif not is_valid:\n    raise ValueError(\"Invalid gains for Classical SMC\")\n\n# Validation checks:\n# - Correct number of gains for controller type\n# - All gains positive (except epsilon can be 0)\n# - Gains within physical bounds",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2fb16db"
  },
  {
    "id": "controllers_7_b2fc45f4",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 7,
    "code": "from src.controllers import create_controller\n\ncontroller = create_controller(\n    'classical_smc',\n    config=config.controllers.classical_smc\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b2fc45f4"
  },
  {
    "id": "controllers_8_bb7c6e21",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 8,
    "code": "from src.controllers import create_smc_for_pso, SMCType\nimport numpy as np\n\n# Create controller\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)\n\n# Compute control\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])  # [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]\nstate_vars = {}\nhistory = controller.initialize_history()\n\ncontrol, state_vars, history = controller.compute_control(state, state_vars, history)\nprint(f\"Control force: {control:.2f} N\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb7c6e21"
  },
  {
    "id": "controllers_9_c33a6f60",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 9,
    "code": "controller = create_controller(\n    'sta_smc',\n    config=config.controllers.sta_smc\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c33a6f60"
  },
  {
    "id": "controllers_10_6e11897a",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Create super-twisting controller\ncontroller = create_smc_for_pso(\n    SMCType.SUPER_TWISTING,\n    gains=[25, 10, 15, 12, 20, 15],\n    max_force=100.0,\n    dt=0.01  # Required for STA integration\n)\n\n# STA maintains internal state for integration\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])\nstate_vars = {}\nhistory = controller.initialize_history()\n\n# First call initializes integrator\ncontrol1, state_vars, history = controller.compute_control(state, state_vars, history)\n\n# Subsequent calls use integrated state\ncontrol2, state_vars, history = controller.compute_control(state, state_vars, history)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e11897a"
  },
  {
    "id": "controllers_11_644eca38",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 11,
    "code": "controller = create_controller(\n    'adaptive_smc',\n    config=config.controllers.adaptive_smc\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "644eca38"
  },
  {
    "id": "controllers_12_2c56d8da",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Create adaptive controller\ncontroller = create_smc_for_pso(\n    SMCType.ADAPTIVE,\n    gains=[10, 8, 15, 12, 0.5],  # Only 5 gains\n    max_force=100.0\n)\n\n# Adaptive SMC tracks gain evolution\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])\nstate_vars = {}\nhistory = controller.initialize_history()\n\n# Gains adapt during simulation\nfor i in range(1000):\n    control, state_vars, history = controller.compute_control(state, state_vars, history)\n\n    # Monitor adapted gains\n    if 'adapted_gains' in state_vars:\n        print(f\"Step {i}: Adapted gains = {state_vars['adapted_gains']}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c56d8da"
  },
  {
    "id": "controllers_13_25701a9c",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 13,
    "code": "controller = create_controller(\n    'hybrid_adaptive_sta_smc',\n    config=config.controllers.hybrid_adaptive_sta_smc\n)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25701a9c"
  },
  {
    "id": "controllers_14_a3155070",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Create hybrid controller\ncontroller = create_smc_for_pso(\n    SMCType.HYBRID,\n    gains=[15, 12, 18, 15],  # Only 4 gains\n    max_force=100.0,\n    dt=0.01\n)\n\n# Hybrid combines STA integration with adaptation\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])\nstate_vars = {}\nhistory = controller.initialize_history()\n\ncontrol, state_vars, history = controller.compute_control(state, state_vars, history)\n\n# Monitor both STA state and adapted gains\nprint(f\"Control: {control:.2f} N\")\nprint(f\"STA state: {state_vars.get('sta_integrator_state', 'N/A')}\")\nprint(f\"Adapted gains: {state_vars.get('adapted_gains', 'N/A')}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a3155070"
  },
  {
    "id": "controllers_15_6d0f2c7d",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 15,
    "code": "# my_custom_controller.py\nimport numpy as np\nfrom src.controllers.base import BaseController\n\nclass TerminalSMC(BaseController):\n    \"\"\"Terminal sliding mode controller with finite-time convergence.\"\"\"\n\n    def __init__(self, gains, max_force=100.0, alpha=0.5):\n        \"\"\"\n        Parameters\n        ----------\n        gains : list[float]\n            [k1, k2, \u03bb1, \u03bb2, K, p, q] where p/q < 1\n        max_force : float\n            Control saturation limit\n        alpha : float\n            Terminal attractor exponent\n        \"\"\"\n        super().__init__(max_force=max_force)\n\n        if len(gains) != 7:\n            raise ValueError(\"Terminal SMC requires 7 gains\")\n\n        self.k1, self.k2, self.lam1, self.lam2 = gains[:4]\n        self.K, self.p, self.q = gains[4:]\n        self.alpha = alpha\n\n    def compute_control(self, state, state_vars, history):\n        \"\"\"Compute terminal SMC control law.\"\"\"\n        x, dx, theta1, dtheta1, theta2, dtheta2 = state\n\n        # Terminal sliding surface\n        s = (self.k1 * theta1 + self.k2 * dtheta1 +\n             self.lam1 * theta2 + self.lam2 * dtheta2)\n\n        # Terminal attractor term\n        terminal_term = np.sign(s) * np.abs(s)**(self.p / self.q)\n\n        # Control law\n        u = -self.K * (s + self.alpha * terminal_term)\n\n        # Saturate\n        u = np.clip(u, -self.max_force, self.max_force)\n\n        # Update history\n        history['sliding_surface'].append(s)\n        history['control'].append(u)\n\n        return u, state_vars, history\n\n    def initialize_history(self):\n        \"\"\"Initialize history tracking.\"\"\"\n        return {\n            'sliding_surface': [],\n            'control': []\n        }",
    "lines": 56,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d0f2c7d"
  },
  {
    "id": "controllers_16_93ea6f80",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 16,
    "code": "# In src/controllers/factory/__init__.py\nfrom .my_custom_controller import TerminalSMC\n\n_CONTROLLER_REGISTRY = {\n    'classical_smc': ClassicalSMC,\n    'sta_smc': SuperTwistingSMC,\n    'adaptive_smc': AdaptiveSMC,\n    'hybrid_adaptive_sta_smc': HybridAdaptiveSTASMC,\n    'terminal_smc': TerminalSMC,  # Add custom controller\n}",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93ea6f80"
  },
  {
    "id": "controllers_17_32220862",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 17,
    "code": "from my_custom_controller import TerminalSMC\n\n# Direct instantiation\ncontroller = TerminalSMC(\n    gains=[10, 8, 15, 12, 50, 5, 7],\n    max_force=100.0,\n    alpha=0.5\n)\n\n# Or via factory (if registered)\nfrom src.controllers import create_controller\n\ncontroller = create_controller(\n    'terminal_smc',\n    config=terminal_smc_config\n)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32220862"
  },
  {
    "id": "controllers_18_e73503c7",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 18,
    "code": "# tests/test_controllers/test_terminal_smc.py\nimport pytest\nimport numpy as np\nfrom my_custom_controller import TerminalSMC\n\ndef test_initialization():\n    \"\"\"Test controller initializes correctly.\"\"\"\n    controller = TerminalSMC(gains=[10, 8, 15, 12, 50, 5, 7])\n    assert controller.K == 50.0\n    assert controller.p == 5.0\n    assert controller.q == 7.0\n\ndef test_compute_control():\n    \"\"\"Test control computation.\"\"\"\n    controller = TerminalSMC(gains=[10, 8, 15, 12, 50, 5, 7])\n    state = np.array([0, 0, 0.1, 0, 0.15, 0])\n\n    control, state_vars, history = controller.compute_control(\n        state, {}, controller.initialize_history()\n    )\n\n    assert isinstance(control, (float, np.floating))\n    assert abs(control) <= 100.0  # Saturation check\n\ndef test_saturation():\n    \"\"\"Test control saturates at max_force.\"\"\"\n    controller = TerminalSMC(gains=[10, 8, 15, 12, 500, 5, 7], max_force=100.0)\n    state = np.array([0, 0, 0.5, 0, 0.6, 0])  # Large errors\n\n    control, _, _ = controller.compute_control(state, {}, controller.initialize_history())\n\n    assert abs(control) == 100.0",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e73503c7"
  },
  {
    "id": "controllers_19_51f9a47d",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 19,
    "code": "from src.config import load_config\nfrom src.controllers import create_controller\nfrom src.core import SimulationRunner\n\nconfig = load_config('config.yaml')\ncontroller = create_controller('classical_smc', config=config.controllers.classical_smc)\nrunner = SimulationRunner(config)\n\nresult = runner.run(controller)\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51f9a47d"
  },
  {
    "id": "controllers_20_cfbaab78",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 20,
    "code": "from src.controllers import SMCType, create_smc_for_pso\n\ncontrollers = {\n    'Classical': create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'STA': create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15], dt=0.01),\n    'Adaptive': create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n    'Hybrid': create_smc_for_pso(SMCType.HYBRID, [15, 12, 18, 15], dt=0.01),\n}\n\nfor name, controller in controllers.items():\n    result = runner.run(controller)\n    print(f\"{name}: ISE={result['metrics']['ise']:.4f}\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfbaab78"
  },
  {
    "id": "controllers_21_e7f721cf",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 21,
    "code": "from src.optimizer import PSOTuner\nfrom src.controllers import SMCType, get_gain_bounds_for_pso\n\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\ntuner = PSOTuner(controller_type=SMCType.CLASSICAL, bounds=bounds)\n\nbest_gains, best_cost = tuner.optimize()\n\n# Use optimized controller\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, best_gains)\nresult = runner.run(controller)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e7f721cf"
  },
  {
    "id": "controllers_22_538cc473",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 22,
    "code": "# Classical and STA: 6 gains\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5])\n\n# Adaptive: 5 gains\ncontroller = create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5])\n\n# Hybrid: 4 gains\ncontroller = create_smc_for_pso(SMCType.HYBRID, [15, 12, 18, 15])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "538cc473"
  },
  {
    "id": "controllers_23_189ff3c4",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 23,
    "code": "# Before: Saturates\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 500, 5], max_force=100)\n\n# After: Reduced gains\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5], max_force=100)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "189ff3c4"
  },
  {
    "id": "controllers_24_a0192d99",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 24,
    "code": "# Classical with larger boundary layer\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 10])  # \u03b5=10\n\n# Or switch to STA for inherently smooth control\ncontroller = create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15], dt=0.01)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0192d99"
  },
  {
    "id": "controllers_25_5fc8ee15",
    "file": "docs\\guides\\api\\controllers.md",
    "index": 25,
    "code": "# Must specify dt for STA and Hybrid controllers\ncontroller = create_smc_for_pso(SMCType.SUPER_TWISTING, gains, dt=0.01)\ncontroller = create_smc_for_pso(SMCType.HYBRID, gains, dt=0.01)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fc8ee15"
  },
  {
    "id": "optimization_1_f9c4216d",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 1,
    "code": "from src.optimizer import PSOTuner\nfrom src.controllers import SMCType, get_gain_bounds_for_pso\n\n# Get recommended bounds for controller type\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Initialize tuner\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=bounds,\n    n_particles=30,        # Swarm size\n    iters=100,            # Number of iterations\n    config=config         # Simulation configuration\n)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9c4216d"
  },
  {
    "id": "optimization_2_6c36d362",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 2,
    "code": "# Run optimization\nbest_gains, best_cost = tuner.optimize()\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Best cost: {best_cost:.4f}\")\n\n# Create optimized controller\nfrom src.controllers import create_smc_for_pso\n\noptimized_controller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=best_gains,\n    max_force=100.0\n)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c36d362"
  },
  {
    "id": "optimization_3_0b56fd43",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 3,
    "code": "# Enable convergence tracking\nhistory = tuner.optimize(track_convergence=True)\n\nbest_gains = history['best_gains']\nbest_cost = history['best_cost']\nconvergence = history['convergence']\n\n# Plot convergence\nimport matplotlib.pyplot as plt\n\nplt.plot(convergence)\nplt.xlabel('Iteration')\nplt.ylabel('Best Cost')\nplt.title('PSO Convergence')\nplt.grid(True)\nplt.show()",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0b56fd43"
  },
  {
    "id": "optimization_4_e9ca948e",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 4,
    "code": "import json\n\n# Save optimized gains\nresults = {\n    'controller_type': 'classical_smc',\n    'gains': best_gains.tolist(),\n    'cost': float(best_cost),\n    'optimization_params': {\n        'n_particles': 30,\n        'iters': 100,\n        'bounds': bounds\n    }\n}\n\nwith open('optimized_gains.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\n# Load and use\nwith open('optimized_gains.json', 'r') as f:\n    loaded = json.load(f)\n\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=loaded['gains'],\n    max_force=100.0\n)",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e9ca948e"
  },
  {
    "id": "optimization_5_aeca6cb1",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 5,
    "code": "def default_cost_function(gains):\n    \"\"\"Default: Minimize ISE for angle tracking.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n    return result['metrics']['ise']",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aeca6cb1"
  },
  {
    "id": "optimization_6_f32090c1",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 6,
    "code": "def settling_time_cost(gains):\n    \"\"\"Optimize for fast settling.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n\n    # Penalize slow settling\n    settling_time = result['metrics']['settling_time']\n    if settling_time > 3.0:\n        return 1000.0 + settling_time  # Large penalty\n\n    return settling_time",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f32090c1"
  },
  {
    "id": "optimization_7_2de42b24",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 7,
    "code": "def energy_efficient_cost(gains):\n    \"\"\"Optimize for energy efficiency.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n\n    # Total control energy\n    control_effort = result['metrics']['control_effort']\n    return control_effort",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2de42b24"
  },
  {
    "id": "optimization_8_099b135f",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_objective_cost(gains, w_ise=0.6, w_energy=0.3, w_time=0.1):\n    \"\"\"Balance tracking, energy, and speed.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n\n    # Normalize metrics\n    ise_normalized = result['metrics']['ise'] / 10.0\n    energy_normalized = result['metrics']['control_effort'] / 5000.0\n    time_normalized = result['metrics']['settling_time'] / 5.0\n\n    # Weighted sum\n    total_cost = (w_ise * ise_normalized +\n                  w_energy * energy_normalized +\n                  w_time * time_normalized)\n\n    return total_cost\n\n# Use with tuner\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=bounds,\n    cost_function=multi_objective_cost\n)",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "099b135f"
  },
  {
    "id": "optimization_9_353f20fb",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef constrained_cost(gains):\n    \"\"\"Enforce stability constraints.\"\"\"\n    # Constraint: First gain must be larger than second\n    if gains[0] <= gains[1]:\n        return float('inf')\n\n    # Constraint: Switching gain must be significant\n    if gains[4] < 10.0:\n        return float('inf')\n\n    # Evaluate if valid\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n    return result['metrics']['ise']",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "353f20fb"
  },
  {
    "id": "optimization_10_8d4b11be",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef penalty_based_cost(gains):\n    \"\"\"Use penalties for soft constraints.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n\n    cost = result['metrics']['ise']\n\n    # Penalty for excessive control saturation\n    if result['metrics']['saturation_percentage'] > 20.0:\n        penalty = result['metrics']['saturation_percentage'] * 0.5\n        cost += penalty\n\n    # Penalty for overshoot\n    max_theta = max(result['metrics']['max_theta1'], result['metrics']['max_theta2'])\n    if max_theta > 0.3:  # 17 degrees\n        cost += (max_theta - 0.3) * 100\n\n    return cost",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8d4b11be"
  },
  {
    "id": "optimization_11_d781b936",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef robust_cost(gains):\n    \"\"\"Optimize for robustness across scenarios.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n\n    scenarios = [\n        np.array([0, 0, 0.1, 0, 0.15, 0]),   # Nominal\n        np.array([0, 0, 0.2, 0, 0.25, 0]),   # Large angles\n        np.array([0.1, 0, 0.15, 0, 0.2, 0]), # Cart offset\n        np.array([0, 0, -0.1, 0, -0.15, 0]), # Negative angles\n    ]\n\n    costs = []\n    for ic in scenarios:\n        result = runner.run(controller, initial_state=ic)\n        costs.append(result['metrics']['ise'])\n\n    # Worst-case optimization\n    return max(costs)\n\n    # Or average-case\n    # return np.mean(costs)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d781b936"
  },
  {
    "id": "optimization_12_b3dc80a3",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 12,
    "code": "from src.controllers import get_gain_bounds_for_pso\n\n# Get recommended bounds for each controller type\nbounds_classical = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50), (1.0, 200), (0.0, 50)]\n#           k1      k2      \u03bb1      \u03bb2      K          \u03b5\n\nbounds_adaptive = get_gain_bounds_for_pso(SMCType.ADAPTIVE)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50), (0.01, 10)]\n#           k1      k2      \u03bb1      \u03bb2      \u03b3 (adaptation rate)\n\nbounds_sta = get_gain_bounds_for_pso(SMCType.SUPER_TWISTING)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50), (1.0, 100), (1.0, 100)]\n#           k1      k2      \u03bb1      \u03bb2      \u03b1          \u03b2\n\nbounds_hybrid = get_gain_bounds_for_pso(SMCType.HYBRID)\n# Returns: [(0.1, 50), (0.1, 50), (0.1, 50), (0.1, 50)]\n#           k1      k2      \u03bb1      \u03bb2",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3dc80a3"
  },
  {
    "id": "optimization_13_c5e5c0f6",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Instead of wide bounds [0.1, 50]\nwide_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Use narrower bounds based on prior knowledge\nnarrow_bounds = [\n    (5.0, 15.0),   # k1: expect around 10\n    (5.0, 15.0),   # k2: expect around 10\n    (10.0, 20.0),  # \u03bb1: expect around 15\n    (8.0, 16.0),   # \u03bb2: expect around 12\n    (30.0, 70.0),  # K: expect around 50\n    (1.0, 10.0),   # \u03b5: expect around 5\n]\n\ntuner = PSOTuner(SMCType.CLASSICAL, bounds=narrow_bounds)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5e5c0f6"
  },
  {
    "id": "optimization_14_cba566a8",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 14,
    "code": "# Ensure stability margins\nphysics_constrained_bounds = [\n    (0.1, 50),     # k1 > 0 (positive definite)\n    (0.1, 50),     # k2 > 0\n    (0.1, 50),     # \u03bb1 > 0\n    (0.1, 50),     # \u03bb2 > 0\n    (10.0, 200),   # K: minimum switching gain for robustness\n    (0.1, 50),     # \u03b5: minimum boundary layer to prevent chattering\n]",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cba566a8"
  },
  {
    "id": "optimization_15_acba2f81",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 15,
    "code": "from src.controllers import validate_smc_gains\n\n# Check if gains are within valid range\ncandidate_gains = [10, 8, 15, 12, 50, 5]\nis_valid = validate_smc_gains(SMCType.CLASSICAL, candidate_gains)\n\nif not is_valid:\n    print(\"Invalid gains detected!\")\n\n# Validate bounds themselves\ndef validate_bounds(bounds, controller_type):\n    \"\"\"Ensure bounds are physically meaningful.\"\"\"\n    n_expected = {\n        SMCType.CLASSICAL: 6,\n        SMCType.ADAPTIVE: 5,\n        SMCType.SUPER_TWISTING: 6,\n        SMCType.HYBRID: 4\n    }\n\n    if len(bounds) != n_expected[controller_type]:\n        raise ValueError(f\"Expected {n_expected[controller_type]} bounds\")\n\n    for i, (low, high) in enumerate(bounds):\n        if low >= high:\n            raise ValueError(f\"Bound {i}: low ({low}) >= high ({high})\")\n        if low <= 0:\n            raise ValueError(f\"Bound {i}: non-positive lower bound\")\n\n    return True",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "acba2f81"
  },
  {
    "id": "optimization_16_9e0c9b27",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 16,
    "code": "from concurrent.futures import ProcessPoolExecutor\nimport numpy as np\n\ndef optimize_controller(controller_type):\n    \"\"\"Optimize a single controller type.\"\"\"\n    bounds = get_gain_bounds_for_pso(controller_type)\n    tuner = PSOTuner(controller_type, bounds, n_particles=30, iters=100)\n    best_gains, best_cost = tuner.optimize()\n    return controller_type, best_gains, best_cost\n\n# Optimize all controllers in parallel\ncontroller_types = [\n    SMCType.CLASSICAL,\n    SMCType.ADAPTIVE,\n    SMCType.SUPER_TWISTING,\n    SMCType.HYBRID\n]\n\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    futures = [executor.submit(optimize_controller, ct) for ct in controller_types]\n    results = [future.result() for future in futures]\n\nfor ctrl_type, gains, cost in results:\n    print(f\"{ctrl_type}: Cost={cost:.4f}, Gains={gains}\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9e0c9b27"
  },
  {
    "id": "optimization_17_890591ea",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\ndef tune_pso_hyperparameters():\n    \"\"\"Find best PSO settings for your problem.\"\"\"\n    best_overall_cost = float('inf')\n    best_config = None\n\n    # Grid search over PSO parameters\n    for n_particles in [20, 30, 50]:\n        for w in [0.5, 0.7, 0.9]:\n            for c1 in [1.0, 1.5, 2.0]:\n                c2 = c1  # Keep symmetric\n\n                tuner = PSOTuner(\n                    SMCType.CLASSICAL,\n                    bounds=bounds,\n                    n_particles=n_particles,\n                    iters=50,\n                    w=w,\n                    c1=c1,\n                    c2=c2\n                )\n\n                _, cost = tuner.optimize()\n\n                if cost < best_overall_cost:\n                    best_overall_cost = cost\n                    best_config = {\n                        'n_particles': n_particles,\n                        'w': w,\n                        'c1': c1,\n                        'c2': c2\n                    }\n\n    return best_config, best_overall_cost\n\noptimal_pso_config, best_cost = tune_pso_hyperparameters()\nprint(f\"Optimal PSO config: {optimal_pso_config}\")",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "890591ea"
  },
  {
    "id": "optimization_18_31a0f61d",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\ndef diagnose_convergence(history):\n    \"\"\"Analyze PSO convergence quality.\"\"\"\n    convergence = history['convergence']\n\n    # Check if converged\n    final_cost = convergence[-1]\n    improvement = convergence[0] - convergence[-1]\n    improvement_percent = (improvement / convergence[0]) * 100\n\n    # Detect premature convergence (plateau early)\n    plateau_start = None\n    for i in range(len(convergence) - 10):\n        if np.std(convergence[i:i+10]) < 0.01 * final_cost:\n            plateau_start = i\n            break\n\n    diagnostics = {\n        'converged': improvement_percent > 20,\n        'improvement_percent': improvement_percent,\n        'final_cost': final_cost,\n        'plateau_start': plateau_start,\n        'early_plateau': plateau_start is not None and plateau_start < len(convergence) * 0.3\n    }\n\n    return diagnostics\n\n# Use diagnostics\nhistory = tuner.optimize(track_convergence=True)\ndiag = diagnose_convergence(history)\n\nif diag['early_plateau']:\n    print(\"Warning: PSO converged prematurely. Try:\")\n    print(\"  - Increase swarm diversity (larger w)\")\n    print(\"  - Increase swarm size (more particles)\")\n    print(\"  - Widen search bounds\")",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "31a0f61d"
  },
  {
    "id": "optimization_19_702248a1",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 19,
    "code": "def pareto_optimization(gains):\n    \"\"\"Return multiple objectives for Pareto analysis.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = runner.run(controller)\n\n    return {\n        'ise': result['metrics']['ise'],\n        'energy': result['metrics']['control_effort'],\n        'time': result['metrics']['settling_time']\n    }\n\n# Run PSO multiple times with different weights\npareto_front = []\nweight_combinations = [\n    (0.8, 0.1, 0.1),  # Prioritize ISE\n    (0.5, 0.4, 0.1),  # Balance ISE and energy\n    (0.3, 0.3, 0.4),  # Prioritize settling time\n]\n\nfor w_ise, w_energy, w_time in weight_combinations:\n    cost_fn = lambda g: multi_objective_cost(g, w_ise, w_energy, w_time)\n    tuner = PSOTuner(SMCType.CLASSICAL, bounds, cost_function=cost_fn)\n    gains, _ = tuner.optimize()\n\n    metrics = pareto_optimization(gains)\n    pareto_front.append({\n        'gains': gains,\n        'weights': (w_ise, w_energy, w_time),\n        'metrics': metrics\n    })\n\n# Visualize Pareto front\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\nise_vals = [p['metrics']['ise'] for p in pareto_front]\nenergy_vals = [p['metrics']['energy'] for p in pareto_front]\ntime_vals = [p['metrics']['time'] for p in pareto_front]\n\nax.scatter(ise_vals, energy_vals, time_vals)\nax.set_xlabel('ISE')\nax.set_ylabel('Energy')\nax.set_zlabel('Settling Time')\nplt.title('Pareto Front: Multi-Objective Optimization')\nplt.show()",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "702248a1"
  },
  {
    "id": "optimization_20_0ec01594",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 20,
    "code": "from src.config import load_config\nfrom src.optimizer import PSOTuner\nfrom src.controllers import SMCType, get_gain_bounds_for_pso, create_smc_for_pso\nfrom src.core import SimulationRunner\n\n# Setup\nconfig = load_config('config.yaml')\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Optimize\ntuner = PSOTuner(SMCType.CLASSICAL, bounds, n_particles=30, iters=100, config=config)\nbest_gains, best_cost = tuner.optimize()\n\n# Validate\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, best_gains)\nrunner = SimulationRunner(config)\nresult = runner.run(controller)\n\nprint(f\"Optimized Cost: {best_cost:.4f}\")\nprint(f\"Validation ISE: {result['metrics']['ise']:.4f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ec01594"
  },
  {
    "id": "optimization_21_c5e1f4b0",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Coarse optimization with wide bounds\ninitial_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\ntuner_coarse = PSOTuner(SMCType.CLASSICAL, initial_bounds, n_particles=50, iters=50)\ncoarse_gains, _ = tuner_coarse.optimize()\n\n# Fine optimization with narrow bounds around coarse solution\nrefined_bounds = [(g*0.8, g*1.2) for g in coarse_gains]\ntuner_fine = PSOTuner(SMCType.CLASSICAL, refined_bounds, n_particles=30, iters=100)\nfine_gains, fine_cost = tuner_fine.optimize()\n\nprint(f\"Coarse gains: {coarse_gains}\")\nprint(f\"Fine gains: {fine_gains}\")\nprint(f\"Final cost: {fine_cost:.4f}\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5e1f4b0"
  },
  {
    "id": "optimization_22_d119d5e7",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\n# Define robust cost function\ndef robust_cost(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    worst_case = 0.0\n\n    for theta_scale in [0.5, 1.0, 1.5, 2.0]:\n        ic = np.array([0, 0, 0.1*theta_scale, 0, 0.15*theta_scale, 0])\n        result = runner.run(controller, initial_state=ic)\n        worst_case = max(worst_case, result['metrics']['ise'])\n\n    return worst_case\n\n# Optimize for worst-case performance\ntuner = PSOTuner(SMCType.CLASSICAL, bounds, cost_function=robust_cost)\nrobust_gains, _ = tuner.optimize()",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d119d5e7"
  },
  {
    "id": "optimization_23_8353eb78",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 23,
    "code": "# Problem complexity vs swarm size\nproblem_dimensions = len(bounds)\n\nif problem_dimensions <= 4:\n    n_particles = 20  # Hybrid controller (4 gains)\nelif problem_dimensions <= 6:\n    n_particles = 30  # Classical/STA (6 gains)\nelse:\n    n_particles = 50  # Complex problems",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8353eb78"
  },
  {
    "id": "optimization_24_90b194f0",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\n# Iteration count based on convergence needs\ntuner_fast = PSOTuner(..., iters=50)    # Quick prototyping\ntuner_standard = PSOTuner(..., iters=100)  # Standard optimization\ntuner_thorough = PSOTuner(..., iters=200)  # Publication-quality",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "90b194f0"
  },
  {
    "id": "optimization_25_1a90f274",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# Expensive to evaluate one controller at a time\ndef slow_cost(gains):\n    for ic in scenarios:  # Sequential\n        result = runner.run(controller, initial_state=ic)\n    return ...\n\n# Fast: Evaluate all scenarios in parallel\ndef fast_cost(gains):\n    from src.core.vector_sim import run_batch_simulation\n    results = run_batch_simulation(controller, dynamics, scenarios, sim_params)\n    return ...",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a90f274"
  },
  {
    "id": "optimization_26_c54cfc97",
    "file": "docs\\guides\\api\\optimization.md",
    "index": 26,
    "code": "if not validate_smc_gains(controller_type, gains):\n       return float('inf')",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c54cfc97"
  },
  {
    "id": "plant-models_1_3a26618d",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 1,
    "code": "state = np.array([\n    x,        # Cart position (m)\n    dx,       # Cart velocity (m/s)\n    theta1,   # First pendulum angle (rad, 0 = upright)\n    dtheta1,  # First pendulum angular velocity (rad/s)\n    theta2,   # Second pendulum angle (rad, 0 = upright)\n    dtheta2   # Second pendulum angular velocity (rad/s)\n])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a26618d"
  },
  {
    "id": "plant-models_2_5e16d855",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 2,
    "code": "from src.core.dynamics import SimplifiedDynamics\nfrom src.config import load_config\n\nconfig = load_config('config.yaml')\nconfig.simulation.use_full_dynamics = False\n\ndynamics = SimplifiedDynamics(config.dip_params)\n\n# Compute state derivatives\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])\ncontrol = 50.0\nstate_dot = dynamics.compute_dynamics(state, control)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e16d855"
  },
  {
    "id": "plant-models_3_0262ccd8",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 3,
    "code": "from src.core.dynamics_full import FullDynamics\n\nconfig.simulation.use_full_dynamics = True\ndynamics = FullDynamics(config.dip_params)\n\nstate_dot = dynamics.compute_dynamics(state, control)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0262ccd8"
  },
  {
    "id": "plant-models_4_670643f5",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 4,
    "code": "from src.config import load_config\n\nconfig = load_config('config.yaml')\nphysics = config.dip_params\n\nprint(f\"Cart mass: {physics.m0} kg\")\nprint(f\"Pendulum lengths: {physics.l1}, {physics.l2} m\")\nprint(f\"Gravity: {physics.g} m/s\u00b2\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "670643f5"
  },
  {
    "id": "plant-models_5_4c463379",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 5,
    "code": "from src.config.schemas import DIPParams\n\n# Define custom parameters\ncustom_params = DIPParams(\n    m0=2.0,      # Heavier cart\n    m1=0.3,      # Lighter first pendulum\n    m2=0.5,      # Lighter second pendulum\n    l1=0.4,      # Shorter first link\n    l2=0.6,      # Shorter second link\n    b0=0.2,      # Higher cart friction\n    b1=0.02,     # Higher joint friction\n    b2=0.02,\n    g=9.81\n)\n\n# Inertias auto-calculated: I = (1/3) * m * l\u00b2\nprint(f\"I1 (auto): {custom_params.I1:.4f} kg\u22c5m\u00b2\")\nprint(f\"I2 (auto): {custom_params.I2:.4f} kg\u22c5m\u00b2\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c463379"
  },
  {
    "id": "plant-models_6_6060394f",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 6,
    "code": "def analyze_mass_sensitivity():\n    \"\"\"Test controller sensitivity to mass variations.\"\"\"\n    base_params = config.dip_params\n    m1_values = np.linspace(0.3, 0.8, 20)\n    ise_results = []\n\n    for m1 in m1_values:\n        # Create modified parameters\n        modified_params = DIPParams(\n            m0=base_params.m0,\n            m1=m1,  # Vary first pendulum mass\n            m2=base_params.m2,\n            l1=base_params.l1,\n            l2=base_params.l2\n        )\n\n        # Run simulation\n        dynamics = FullDynamics(modified_params)\n        runner = SimulationRunner(config, dynamics_model=dynamics)\n        result = runner.run(controller)\n        ise_results.append(result['metrics']['ise'])\n\n    return m1_values, ise_results\n\nm1_vals, ise_vals = analyze_mass_sensitivity()\n\nimport matplotlib.pyplot as plt\nplt.plot(m1_vals, ise_vals)\nplt.xlabel('First Pendulum Mass m\u2081 (kg)')\nplt.ylabel('ISE')\nplt.title('Controller Sensitivity to Mass Variation')\nplt.grid(True)\nplt.show()",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6060394f"
  },
  {
    "id": "plant-models_7_070ce28b",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 7,
    "code": "from src.core.dynamics_full import FullDynamics\nimport numpy as np\n\nclass CoulombFrictionDynamics(FullDynamics):\n    \"\"\"Full dynamics with Coulomb friction model.\"\"\"\n\n    def __init__(self, params, mu_coulomb=0.2):\n        \"\"\"\n        Parameters\n        ----------\n        params : DIPParams\n            Physics parameters\n        mu_coulomb : float\n            Coulomb friction coefficient\n        \"\"\"\n        super().__init__(params)\n        self.mu_coulomb = mu_coulomb\n\n    def compute_dynamics(self, state, control):\n        \"\"\"Compute state derivatives with Coulomb friction.\"\"\"\n        x, dx, theta1, dtheta1, theta2, dtheta2 = state\n\n        # Coulomb friction force\n        F_coulomb = self.mu_coulomb * self.params.m0 * self.params.g * np.sign(dx)\n\n        # Apply Coulomb friction to control input\n        effective_control = control - F_coulomb\n\n        # Use parent class dynamics with modified control\n        return super().compute_dynamics(state, effective_control)",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "070ce28b"
  },
  {
    "id": "plant-models_8_05fca37b",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass DisturbedDynamics(FullDynamics):\n    \"\"\"Dynamics with external disturbance.\"\"\"\n\n    def __init__(self, params, disturbance_magnitude=10.0):\n        super().__init__(params)\n        self.disturbance_magnitude = disturbance_magnitude\n\n    def compute_dynamics(self, state, control, time=0.0):\n        \"\"\"Add time-varying disturbance.\"\"\"\n        # Sinusoidal disturbance\n        disturbance = self.disturbance_magnitude * np.sin(2 * np.pi * time)\n\n        # Apply to control\n        disturbed_control = control + disturbance\n\n        return super().compute_dynamics(state, disturbed_control)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "05fca37b"
  },
  {
    "id": "plant-models_9_9ed5b89e",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 9,
    "code": "# Create custom dynamics\ncustom_dynamics = CoulombFrictionDynamics(config.dip_params, mu_coulomb=0.3)\n\n# Use with simulation runner\nrunner = SimulationRunner(config, dynamics_model=custom_dynamics)\nresult = runner.run(controller)\n\nprint(f\"ISE with Coulomb friction: {result['metrics']['ise']:.4f}\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ed5b89e"
  },
  {
    "id": "plant-models_10_212bb50b",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_custom_dynamics(dynamics):\n    \"\"\"Ensure custom dynamics satisfy basic properties.\"\"\"\n    state = np.array([0, 0, 0.1, 0, 0.15, 0])\n    control = 0.0\n\n    # Test 1: State derivative has correct shape\n    state_dot = dynamics.compute_dynamics(state, control)\n    assert state_dot.shape == (6,), \"State derivative shape mismatch\"\n\n    # Test 2: No NaN or Inf\n    assert np.all(np.isfinite(state_dot)), \"Invalid values in state derivative\"\n\n    # Test 3: Energy conservation (no control, no friction)\n    # ... implement energy check\n\n    print(\"Custom dynamics validation passed!\")\n\nvalidate_custom_dynamics(custom_dynamics)",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "212bb50b"
  },
  {
    "id": "plant-models_11_08deecd3",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Optimize with simplified dynamics (fast)\nconfig.simulation.use_full_dynamics = False\ndynamics_simple = SimplifiedDynamics(config.dip_params)\nrunner_simple = SimulationRunner(config, dynamics_model=dynamics_simple)\n\ntuner = PSOTuner(SMCType.CLASSICAL, bounds, config=config)\nbest_gains, _ = tuner.optimize()\n\n# Validate with full dynamics (accurate)\nconfig.simulation.use_full_dynamics = True\ndynamics_full = FullDynamics(config.dip_params)\nrunner_full = SimulationRunner(config, dynamics_model=dynamics_full)\n\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, best_gains)\nresult = runner_full.run(controller)\n\nprint(f\"Validation ISE: {result['metrics']['ise']:.4f}\")",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "08deecd3"
  },
  {
    "id": "plant-models_12_0922ec1f",
    "file": "docs\\guides\\api\\plant-models.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Compare simplified vs full dynamics\nresults_comparison = {}\n\nfor model_name, dynamics in [\n    ('Simplified', SimplifiedDynamics(config.dip_params)),\n    ('Full', FullDynamics(config.dip_params))\n]:\n    runner = SimulationRunner(config, dynamics_model=dynamics)\n    result = runner.run(controller)\n    results_comparison[model_name] = result\n\n# Analyze differences\nfor model, result in results_comparison.items():\n    print(f\"{model}: ISE={result['metrics']['ise']:.4f}, \"\n          f\"Settling={result['metrics']['settling_time']:.2f}s\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0922ec1f"
  },
  {
    "id": "README_1_2b70669a",
    "file": "docs\\guides\\api\\README.md",
    "index": 1,
    "code": "from src.controllers import create_controller, SMCType\n\ncontroller = create_controller('classical_smc', config=config.controllers.classical_smc)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b70669a"
  },
  {
    "id": "README_2_15a50f0f",
    "file": "docs\\guides\\api\\README.md",
    "index": 2,
    "code": "from src.core import SimulationRunner\n\nrunner = SimulationRunner(config)\nresult = runner.run(controller)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "15a50f0f"
  },
  {
    "id": "README_3_a5fd9437",
    "file": "docs\\guides\\api\\README.md",
    "index": 3,
    "code": "from src.optimizer import PSOTuner\n\ntuner = PSOTuner(controller_type=SMCType.CLASSICAL, bounds=bounds)\nbest_gains, best_cost = tuner.optimize()",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a5fd9437"
  },
  {
    "id": "README_4_2438cd55",
    "file": "docs\\guides\\api\\README.md",
    "index": 4,
    "code": "from src.config import load_config\n\nconfig = load_config('config.yaml')",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2438cd55"
  },
  {
    "id": "README_5_4628e342",
    "file": "docs\\guides\\api\\README.md",
    "index": 5,
    "code": "from src.core import DoubleInvertedPendulum\n\ndynamics = DoubleInvertedPendulum(m0=1.0, m1=0.1, m2=0.1, l1=0.5, l2=0.5)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4628e342"
  },
  {
    "id": "README_6_ff61445c",
    "file": "docs\\guides\\api\\README.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.utils import validate_state, saturation, PerformanceMonitor",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ff61445c"
  },
  {
    "id": "README_7_713f6114",
    "file": "docs\\guides\\api\\README.md",
    "index": 7,
    "code": "from src.config import load_config\nfrom src.controllers import create_controller\nfrom src.core import SimulationRunner\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('classical_smc', config=config.controllers.classical_smc)\n\n# Run simulation\nrunner = SimulationRunner(config)\nresult = runner.run(controller)\n\n# Access results\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "713f6114"
  },
  {
    "id": "README_8_47d01767",
    "file": "docs\\guides\\api\\README.md",
    "index": 8,
    "code": "from src.optimizer import PSOTuner\nfrom src.controllers import get_gain_bounds_for_pso, SMCType\n\n# Get bounds for controller type\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Create PSO tuner\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=bounds,\n    n_particles=30,\n    iters=100\n)\n\n# Optimize\nbest_gains, best_cost = tuner.optimize()",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "47d01767"
  },
  {
    "id": "README_9_e09b9fb4",
    "file": "docs\\guides\\api\\README.md",
    "index": 9,
    "code": "from src.config.schemas import SimulationConfig\n\n# Programmatic configuration\nconfig = SimulationConfig(\n    duration=5.0,\n    dt=0.01,\n    initial_conditions=[0, 0, 0.1, 0, 0.15, 0]\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e09b9fb4"
  },
  {
    "id": "simulation_1_f13a7b52",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 1,
    "code": "from src.core import SimulationRunner\nfrom src.config import load_config\n\nconfig = load_config('config.yaml')\nrunner = SimulationRunner(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f13a7b52"
  },
  {
    "id": "simulation_2_421bb8ed",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 2,
    "code": "from src.controllers import create_smc_for_pso, SMCType\n\n# Create controller\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)\n\n# Run simulation\nresult = runner.run(controller)\n\n# Access results\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")\nprint(f\"Final state: {result['state'][-1]}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "421bb8ed"
  },
  {
    "id": "simulation_3_8a56f490",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nresult = {\n    't': np.ndarray,          # Time vector, shape (N+1,)\n    'state': np.ndarray,      # State trajectories, shape (N+1, 6)\n                              # [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082] at each timestep\n    'control': np.ndarray,    # Control inputs, shape (N+1,)\n    'metrics': {\n        'ise': float,         # Integral of Squared Error\n        'itae': float,        # Integral of Time-weighted Absolute Error\n        'max_theta1': float,  # Maximum first pendulum angle (rad)\n        'max_theta2': float,  # Maximum second pendulum angle (rad)\n        'control_effort': float,  # Total control energy\n        'settling_time': float    # Time to settle within 2% of target\n    },\n    'stability': {\n        'converged': bool,    # Did system stabilize?\n        'final_error': float  # Final tracking error\n    }\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a56f490"
  },
  {
    "id": "simulation_4_84faf8cc",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 4,
    "code": "import numpy as np\n\n# Override initial conditions\ncustom_ic = np.array([\n    0.0,    # x (cart position)\n    0.0,    # dx (cart velocity)\n    0.2,    # \u03b8\u2081 (first pendulum angle, rad)\n    0.0,    # d\u03b8\u2081 (first pendulum angular velocity)\n    0.25,   # \u03b8\u2082 (second pendulum angle, rad)\n    0.0     # d\u03b8\u2082 (second pendulum angular velocity)\n])\n\nresult = runner.run(controller, initial_state=custom_ic)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84faf8cc"
  },
  {
    "id": "simulation_5_1788eb0e",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 5,
    "code": "# Run for 10 seconds instead of config value\nresult = runner.run(controller, duration=10.0)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1788eb0e"
  },
  {
    "id": "simulation_6_e46a1a7f",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 6,
    "code": "def progress_callback(t, state, control):\n    \"\"\"Called at each timestep.\"\"\"\n    print(f\"t={t:.2f}s, \u03b8\u2081={state[2]:.3f} rad, u={control:.2f} N\")\n\nresult = runner.run(controller, callback=progress_callback)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e46a1a7f"
  },
  {
    "id": "simulation_7_61750975",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 7,
    "code": "from src.core.exceptions import NumericalInstabilityError, ControlSaturationError\n\ntry:\n    result = runner.run(controller)\nexcept NumericalInstabilityError as e:\n    print(f\"Simulation became unstable: {e}\")\n    # Try smaller timestep\n    runner.dt = 0.005\n    result = runner.run(controller)\nexcept ControlSaturationError as e:\n    print(f\"Control saturated: {e}\")\n    # Reduce gains or increase max_force",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61750975"
  },
  {
    "id": "simulation_8_f867daf4",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 8,
    "code": "from src.core.dynamics import SimplifiedDynamics\nfrom src.config import load_config\n\nconfig = load_config('config.yaml')\ndynamics = SimplifiedDynamics(config.dip_params)\n\n# Compute derivatives\nstate = np.array([0, 0, 0.1, 0, 0.15, 0])\ncontrol = 50.0\nstate_dot = dynamics.compute_dynamics(state, control)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f867daf4"
  },
  {
    "id": "simulation_9_62fb0f60",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 9,
    "code": "from src.core.dynamics_full import FullDynamics\n\ndynamics = FullDynamics(config.dip_params)\nstate_dot = dynamics.compute_dynamics(state, control)\n\n# Full dynamics includes:\n# - Exact sin(\u03b8), cos(\u03b8)\n# - Full Coriolis and centrifugal terms\n# - Nonlinear inertia matrix",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62fb0f60"
  },
  {
    "id": "simulation_10_1f6b6e30",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 10,
    "code": "state = [\n    x,        # Cart position (m)\n    dx,       # Cart velocity (m/s)\n    theta1,   # First pendulum angle (rad, 0 = upright)\n    dtheta1,  # First pendulum angular velocity (rad/s)\n    theta2,   # Second pendulum angle (rad, 0 = upright)\n    dtheta2   # Second pendulum angular velocity (rad/s)\n]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f6b6e30"
  },
  {
    "id": "simulation_11_48ac191a",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 11,
    "code": "from src.core.dynamics import BaseDynamics\nimport numpy as np\n\nclass FrictionEnhancedDynamics(BaseDynamics):\n    \"\"\"Dynamics with enhanced friction model.\"\"\"\n\n    def __init__(self, params, friction_model='coulomb'):\n        super().__init__(params)\n        self.friction_model = friction_model\n\n    def compute_dynamics(self, state, control):\n        \"\"\"\n        Compute state derivatives with enhanced friction.\n\n        Parameters\n        ----------\n        state : np.ndarray, shape (6,)\n            Current state [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]\n        control : float\n            Control force (N)\n\n        Returns\n        -------\n        state_dot : np.ndarray, shape (6,)\n            State derivatives\n        \"\"\"\n        x, dx, theta1, dtheta1, theta2, dtheta2 = state\n\n        # Apply friction model\n        if self.friction_model == 'coulomb':\n            friction = self._coulomb_friction(dx)\n        elif self.friction_model == 'viscous':\n            friction = self._viscous_friction(dx)\n        else:\n            friction = 0.0\n\n        # Base dynamics computation\n        base_dynamics = super().compute_dynamics(state, control)\n\n        # Add friction effects\n        state_dot = base_dynamics.copy()\n        state_dot[1] -= friction  # Apply friction to cart velocity\n\n        return state_dot\n\n    def _coulomb_friction(self, velocity):\n        \"\"\"Coulomb friction model.\"\"\"\n        mu_c = 0.2  # Coulomb friction coefficient\n        return mu_c * np.sign(velocity)\n\n    def _viscous_friction(self, velocity):\n        \"\"\"Viscous friction model.\"\"\"\n        b = 0.5  # Viscous friction coefficient\n        return b * velocity",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48ac191a"
  },
  {
    "id": "simulation_12_fedf5487",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 12,
    "code": "# Create custom dynamics\ncustom_dynamics = FrictionEnhancedDynamics(config.dip_params, friction_model='coulomb')\n\n# Use with simulation runner\nrunner = SimulationRunner(config, dynamics_model=custom_dynamics)\nresult = runner.run(controller)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fedf5487"
  },
  {
    "id": "simulation_13_fe798ada",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 13,
    "code": "from src.core.simulation_context import SimulationContext\n\ncontext = SimulationContext(\n    config=config,\n    controller=controller,\n    dynamics=dynamics,\n    initial_state=np.array([0, 0, 0.1, 0, 0.15, 0])\n)\n\n# Context provides:\n# - Consistent logging\n# - Safety guards\n# - Performance monitoring\n# - Error recovery",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe798ada"
  },
  {
    "id": "simulation_14_abeba36a",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 14,
    "code": "# Automatic instability detection\nif context.is_numerically_unstable(state):\n    print(\"Warning: Numerical instability detected\")\n    context.attempt_recovery()",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abeba36a"
  },
  {
    "id": "simulation_15_322965eb",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 15,
    "code": "# Track saturation events\nif context.is_saturated(control, max_force=100.0):\n    context.log_saturation_event(time=t, control=control)\n\n# Get saturation statistics\nstats = context.get_saturation_stats()\nprint(f\"Saturated {stats['count']} times ({stats['percentage']:.1f}%)\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "322965eb"
  },
  {
    "id": "simulation_16_9f3a5e35",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 16,
    "code": "# Enable detailed logging\ncontext.enable_logging(level='DEBUG', log_file='simulation.log')\n\n# Monitor performance\ncontext.start_performance_monitor()\nresult = runner.run(controller)\nperf_stats = context.get_performance_stats()\n\nprint(f\"Execution time: {perf_stats['total_time']:.3f}s\")\nprint(f\"Average timestep: {perf_stats['avg_step_time']:.6f}s\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f3a5e35"
  },
  {
    "id": "simulation_17_dbaa6e66",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 17,
    "code": "from src.core.vector_sim import run_batch_simulation\nimport numpy as np\n\n# Define multiple initial conditions\nn_trials = 100\ninitial_conditions = np.random.uniform(\n    low=[-0.1, 0, -0.2, 0, -0.25, 0],\n    high=[0.1, 0, 0.2, 0, 0.25, 0],\n    size=(n_trials, 6)\n)\n\n# Run batch simulation (Numba-accelerated)\nbatch_results = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    initial_conditions=initial_conditions,\n    sim_params={\n        'duration': 5.0,\n        'dt': 0.01,\n        'max_force': 100.0\n    }\n)\n\n# Results shape: (n_trials, n_timesteps, n_states)\nprint(f\"Batch results shape: {batch_results.shape}\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbaa6e66"
  },
  {
    "id": "simulation_18_8a89e7fb",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\n# Monte Carlo simulation for statistical analysis\nn_samples = 1000\n\n# Sample initial conditions from distribution\nic_mean = np.array([0, 0, 0.1, 0, 0.15, 0])\nic_std = np.array([0.05, 0, 0.05, 0, 0.05, 0])\ninitial_conditions = np.random.normal(ic_mean, ic_std, size=(n_samples, 6))\n\n# Run batch\nbatch_results = run_batch_simulation(controller, dynamics, initial_conditions, sim_params)\n\n# Compute statistics\nise_values = np.sum(batch_results[:, :, 2:4]**2, axis=(1, 2))  # ISE for \u03b8\u2081, \u03b8\u2082\nmean_ise = np.mean(ise_values)\nstd_ise = np.std(ise_values)\npercentile_95 = np.percentile(ise_values, 95)\n\nprint(f\"ISE: {mean_ise:.4f} \u00b1 {std_ise:.4f}\")\nprint(f\"95th percentile: {percentile_95:.4f}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a89e7fb"
  },
  {
    "id": "simulation_19_5ad7fc17",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 19,
    "code": "# Batch evaluation for PSO fitness function\ndef batch_fitness_function(gains_array):\n    \"\"\"Evaluate controller on multiple scenarios.\"\"\"\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains_array)\n\n    # Test scenarios\n    scenarios = [\n        np.array([0, 0, 0.1, 0, 0.15, 0]),   # Nominal\n        np.array([0, 0, 0.2, 0, 0.25, 0]),   # Large angles\n        np.array([0.1, 0, 0.15, 0, 0.2, 0]), # Cart offset\n    ]\n    initial_conditions = np.array(scenarios)\n\n    # Run batch\n    results = run_batch_simulation(controller, dynamics, initial_conditions, sim_params)\n\n    # Compute average performance\n    ise = np.mean(np.sum(results[:, :, 2:4]**2, axis=(1, 2)))\n    return ise\n\n# Use with PSO\nfrom src.optimizer import PSOTuner\n\ntuner = PSOTuner(\n    controller_type=SMCType.CLASSICAL,\n    bounds=get_gain_bounds_for_pso(SMCType.CLASSICAL),\n    cost_function=batch_fitness_function\n)\nbest_gains, best_cost = tuner.optimize()",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ad7fc17"
  },
  {
    "id": "simulation_20_059d42ff",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n# First call compiles the function (slow)\nbatch_results = run_batch_simulation(...)  # ~2 seconds\n\n# Subsequent calls use compiled code (fast)\nbatch_results = run_batch_simulation(...)  # ~0.1 seconds",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "059d42ff"
  },
  {
    "id": "simulation_21_43170c6f",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Too small: Compilation overhead dominates\nrun_batch_simulation(..., n_trials=10)  # Not efficient\n\n# Optimal: Amortize compilation cost\nrun_batch_simulation(..., n_trials=100)  # Good\n\n# Too large: Memory issues\nrun_batch_simulation(..., n_trials=10000)  # May run out of RAM",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "43170c6f"
  },
  {
    "id": "simulation_22_b99d4cb3",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 22,
    "code": "from src.config import load_config\nfrom src.controllers import create_controller\nfrom src.core import SimulationRunner\nfrom src.utils.visualization import plot_results\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('classical_smc', config=config.controllers.classical_smc)\n\n# Initialize simulation\nrunner = SimulationRunner(config)\n\n# Run simulation\nresult = runner.run(controller)\n\n# Visualize\nplot_results(result)\n\n# Analyze\nprint(f\"Performance Metrics:\")\nprint(f\"  ISE: {result['metrics']['ise']:.4f}\")\nprint(f\"  Settling Time: {result['metrics']['settling_time']:.2f}s\")\nprint(f\"  Max \u03b8\u2081: {result['metrics']['max_theta1']:.3f} rad\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b99d4cb3"
  },
  {
    "id": "simulation_23_abbcf2da",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 23,
    "code": "# Compare multiple controllers\ncontrollers = {\n    'Classical': create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'STA': create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15], dt=0.01),\n    'Adaptive': create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n}\n\nresults = {}\nfor name, ctrl in controllers.items():\n    results[name] = runner.run(ctrl)\n    print(f\"{name}: ISE={results[name]['metrics']['ise']:.4f}\")\n\n# Statistical comparison\nfrom src.utils.analysis import compare_controllers\ncomparison = compare_controllers(results)\nprint(comparison.summary())",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abbcf2da"
  },
  {
    "id": "simulation_24_2b839bdd",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 24,
    "code": "# Test sensitivity to initial conditions\ntheta1_values = np.linspace(0.05, 0.3, 20)\nise_results = []\n\nfor theta1 in theta1_values:\n    ic = np.array([0, 0, theta1, 0, theta1*1.5, 0])\n    result = runner.run(controller, initial_state=ic)\n    ise_results.append(result['metrics']['ise'])\n\n# Plot sensitivity\nimport matplotlib.pyplot as plt\nplt.plot(np.degrees(theta1_values), ise_results)\nplt.xlabel('Initial \u03b8\u2081 (degrees)')\nplt.ylabel('ISE')\nplt.title('Controller Sensitivity to Initial Conditions')\nplt.show()",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b839bdd"
  },
  {
    "id": "simulation_25_97939488",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 25,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO optimization: Use simplified dynamics for speed\nconfig.simulation.use_full_dynamics = False\nrunner = SimulationRunner(config)\ntuner = PSOTuner(..., simulation_runner=runner)\nbest_gains = tuner.optimize()  # Fast iterations\n\n# Final validation: Use full dynamics for accuracy\nconfig.simulation.use_full_dynamics = True\nrunner = SimulationRunner(config)\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, best_gains)\nfinal_result = runner.run(controller)  # Accurate validation",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "97939488"
  },
  {
    "id": "simulation_26_c822c41e",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 26,
    "code": "# Coarse timestep for prototyping (faster)\nconfig.simulation.dt = 0.01  # 10ms\nrunner = SimulationRunner(config)\n\n# Fine timestep for accuracy (slower)\nconfig.simulation.dt = 0.001  # 1ms\nrunner_accurate = SimulationRunner(config)\n\n# Adaptive timestep (future feature)\n# runner = SimulationRunner(config, adaptive_dt=True, dt_min=0.0001, dt_max=0.01)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c822c41e"
  },
  {
    "id": "simulation_27_d1efc62a",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 27,
    "code": "# Sequential (slow)\nresults = []\nfor ic in initial_conditions:\n    result = runner.run(controller, initial_state=ic)\n    results.append(result)\n\n# Batch (fast, Numba-accelerated)\nbatch_results = run_batch_simulation(controller, dynamics, initial_conditions, sim_params)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d1efc62a"
  },
  {
    "id": "simulation_28_10c23bc0",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 28,
    "code": "config.simulation.dt = 0.005  # Reduce from 0.01 to 0.005",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10c23bc0"
  },
  {
    "id": "simulation_29_71356755",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 29,
    "code": "config.simulation.use_full_dynamics = True",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71356755"
  },
  {
    "id": "simulation_30_becbe044",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 30,
    "code": "controller = create_smc_for_pso(SMCType.CLASSICAL, [5, 4, 8, 6, 25, 3])  # Halved gains",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "becbe044"
  },
  {
    "id": "simulation_31_d0988f9f",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 31,
    "code": "config.simulation.use_full_dynamics = False",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0988f9f"
  },
  {
    "id": "simulation_32_3946e036",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 32,
    "code": "config.simulation.dt = 0.02  # Increase from 0.01",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3946e036"
  },
  {
    "id": "simulation_33_76cb2a86",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 33,
    "code": "# example-metadata:\n# runnable: false\n\n   batch_results = run_batch_simulation(...)  # Numba acceleration",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76cb2a86"
  },
  {
    "id": "simulation_34_1f5cbc3a",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 34,
    "code": "print(f\"Initial state: {config.initial_conditions}\")",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f5cbc3a"
  },
  {
    "id": "simulation_35_ffdfac0f",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 35,
    "code": "print(f\"Using full dynamics: {config.simulation.use_full_dynamics}\")",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ffdfac0f"
  },
  {
    "id": "simulation_36_45ee2add",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 36,
    "code": "from src.utils.validation import validate_physics_params\n   validate_physics_params(config.dip_params)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "45ee2add"
  },
  {
    "id": "simulation_37_2b69822d",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 37,
    "code": "# example-metadata:\n# runnable: false\n\n   # Instead of 10000 trials\n   batch_size = 1000\n   results = run_batch_simulation(..., initial_conditions=ic[:batch_size])",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b69822d"
  },
  {
    "id": "simulation_38_34e6972d",
    "file": "docs\\guides\\api\\simulation.md",
    "index": 38,
    "code": "initial_conditions = initial_conditions.astype(np.float64)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "34e6972d"
  },
  {
    "id": "utilities_1_8c9f5296",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 1,
    "code": "from src.utils.validation import validate_state\n\nstate = np.array([0.1, 0.05, 0.2, 0.1, 0.25, 0.15])\n\n# Basic validation\nis_valid = validate_state(state)\n\n# With bounds checking\nis_valid = validate_state(\n    state,\n    x_bounds=(-1.0, 1.0),        # Cart position limits\n    theta_bounds=(-0.5, 0.5),    # Angle limits (rad)\n    velocity_bounds=(-2.0, 2.0)  # Velocity limits\n)\n\nif not is_valid:\n    print(\"State violates constraints!\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8c9f5296"
  },
  {
    "id": "utilities_2_e3e7ebc3",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 2,
    "code": "from src.utils.validation import check_numerical_health\n\nstate = np.array([0.1, 0.05, 0.2, 0.1, 0.25, 0.15])\n\nhealth = check_numerical_health(state)\n\nif not health['is_finite']:\n    print(\"State contains NaN or Inf!\")\nif not health['is_bounded']:\n    print(\"State values unreasonably large!\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3e7ebc3"
  },
  {
    "id": "utilities_3_9a7169d3",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 3,
    "code": "from src.utils.validation import validate_physics_params\n\nparams = config.dip_params\n\ntry:\n    validate_physics_params(params)\n    print(\"Physics parameters valid\")\nexcept ValueError as e:\n    print(f\"Invalid parameters: {e}\")\n\n# Checks:\n# - Masses > 0\n# - Lengths > 0\n# - Friction coefficients \u2265 0\n# - Gravity \u2248 9.81 m/s\u00b2\n# - Inertias > 0",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a7169d3"
  },
  {
    "id": "utilities_4_c1704d31",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 4,
    "code": "from src.utils.validation import validate_controller_gains\n\ngains = [10, 8, 15, 12, 50, 5]\ncontroller_type = 'classical_smc'\n\nis_valid = validate_controller_gains(gains, controller_type)\n\n# Checks:\n# - Correct number of gains\n# - All gains positive (where required)\n# - Gains within reasonable bounds",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c1704d31"
  },
  {
    "id": "utilities_5_3216e76b",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 5,
    "code": "from src.utils.validation import sanitize_input\n\n# Clean and validate user input\nuser_input = \"  10.5, 8.0, 15.2, 12.1, 50.0, 5.5  \"\ngains = sanitize_input(user_input, expected_length=6)\n\n# Returns: [10.5, 8.0, 15.2, 12.1, 50.0, 5.5]",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3216e76b"
  },
  {
    "id": "utilities_6_ed1f8d33",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 6,
    "code": "from src.utils.control import saturate\n\ncontrol = 150.0\nmax_force = 100.0\n\n# Hard saturation\nsaturated = saturate(control, max_force)\n# Returns: 100.0\n\n# Symmetric saturation\nsaturated = saturate(control, -max_force, max_force)\n\n# Soft saturation (smooth)\nfrom src.utils.control import soft_saturate\n\nsoft_sat = soft_saturate(control, max_force, smoothness=0.1)\n# Smooth transition near limits",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed1f8d33"
  },
  {
    "id": "utilities_7_bc1910dd",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 7,
    "code": "from src.utils.control import apply_deadzone\n\ncontrol = 2.5\ndeadzone_threshold = 5.0\n\n# Linear deadzone\noutput = apply_deadzone(control, deadzone_threshold)\n# Returns: 0.0 (below threshold)\n\ncontrol = 7.5\noutput = apply_deadzone(control, deadzone_threshold)\n# Returns: 2.5 (7.5 - 5.0)\n\n# Smooth deadzone\nfrom src.utils.control import smooth_deadzone\n\noutput = smooth_deadzone(control, deadzone_threshold, smoothness=0.5)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc1910dd"
  },
  {
    "id": "utilities_8_ff133966",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 8,
    "code": "from src.utils.control import smooth_sign\n\ns = 0.5  # Sliding surface value\nepsilon = 0.01  # Boundary layer\n\n# Standard sign (discontinuous)\nsign_output = np.sign(s)  # Returns: 1.0\n\n# Smooth sign (continuous)\nsmooth_output = smooth_sign(s, epsilon)\n# Returns: tanh(s/epsilon)\n\n# Linear approximation in boundary layer\nfrom src.utils.control import linear_sign\n\nlinear_output = linear_sign(s, epsilon)\n# Returns: s/epsilon if |s| < epsilon, else sign(s)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ff133966"
  },
  {
    "id": "utilities_9_239f7af1",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 9,
    "code": "from src.utils.control import LowPassFilter\n\n# Create filter\nlpf = LowPassFilter(cutoff_freq=10.0, dt=0.01)\n\n# Filter control signal\ncontrols = []\nfor i in range(len(control_sequence)):\n    filtered = lpf.update(control_sequence[i])\n    controls.append(filtered)\n\n# Reset filter\nlpf.reset()",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "239f7af1"
  },
  {
    "id": "utilities_10_6fc6846a",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 10,
    "code": "from src.utils.control import MovingAverageFilter\n\nmaf = MovingAverageFilter(window_size=10)\n\nfor control in control_sequence:\n    smoothed = maf.update(control)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fc6846a"
  },
  {
    "id": "utilities_11_ed827d5f",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 11,
    "code": "from src.utils.monitoring import PerformanceMonitor\n\nmonitor = PerformanceMonitor(dt=0.01)\n\n# Start monitoring\nmonitor.start()\n\n# During simulation\nfor t, state, control in simulation_loop:\n    monitor.update(t, state, control)\n\n    # Check metrics\n    if monitor.get_current_ise() > 100:\n        print(\"Warning: High ISE detected\")\n\n# Get final statistics\nstats = monitor.get_statistics()\nprint(f\"ISE: {stats['ise']:.4f}\")\nprint(f\"Max theta: {stats['max_theta']:.3f} rad\")\nprint(f\"Settling time: {stats['settling_time']:.2f} s\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed827d5f"
  },
  {
    "id": "utilities_12_c8d47ef3",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 12,
    "code": "from src.utils.monitoring import MemoryMonitor\n\nmem_monitor = MemoryMonitor(threshold_mb=500)\n\n# Check memory periodically\nwhile running:\n    if alert := mem_monitor.check():\n        print(alert)  # \"Alert: 550MB > 500MB\"\n        # Clean up\n        history = controller.initialize_history()\n        import gc\n        gc.collect()",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8d47ef3"
  },
  {
    "id": "utilities_13_aa22a314",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 13,
    "code": "from src.utils.monitoring import LatencyMonitor\n\nlatency_monitor = LatencyMonitor(dt=0.01, deadline=0.01)\n\nfor timestep in range(n_steps):\n    start = latency_monitor.start()\n\n    # Compute control\n    control = controller.compute_control(state, state_vars, history)\n\n    # Check if deadline met\n    missed = latency_monitor.end(start)\n    if missed:\n        print(f\"Deadline miss at step {timestep}\")\n\n# Get statistics\nstats = latency_monitor.get_stats()\nprint(f\"Average latency: {stats['avg_latency']:.4f} s\")\nprint(f\"Deadline misses: {stats['miss_count']}/{n_steps}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa22a314"
  },
  {
    "id": "utilities_14_18f64394",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 14,
    "code": "from src.utils.monitoring import SaturationMonitor\n\nsat_monitor = SaturationMonitor(max_force=100.0)\n\nfor control in control_sequence:\n    sat_monitor.update(control)\n\n# Get saturation statistics\nstats = sat_monitor.get_statistics()\nprint(f\"Saturation percentage: {stats['saturation_percentage']:.1f}%\")\nprint(f\"Total saturated steps: {stats['saturated_count']}\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "18f64394"
  },
  {
    "id": "utilities_15_6afa4d60",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 15,
    "code": "from src.utils.analysis import compute_metrics\n\nresult = {\n    't': t,\n    'state': state_trajectory,\n    'control': control_sequence\n}\n\nmetrics = compute_metrics(result)\n\nprint(f\"ISE: {metrics['ise']:.4f}\")\nprint(f\"ITAE: {metrics['itae']:.4f}\")\nprint(f\"RMS Control: {metrics['rms_control']:.4f}\")\nprint(f\"Settling Time: {metrics['settling_time']:.2f} s\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6afa4d60"
  },
  {
    "id": "utilities_16_614ff1c8",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 16,
    "code": "from src.utils.analysis import (\n    compute_ise, compute_itae, compute_overshoot,\n    compute_settling_time, compute_control_effort\n)\n\n# Individual metrics\nise = compute_ise(t, state[:, 2:4])  # ISE for \u03b8\u2081, \u03b8\u2082\nitae = compute_itae(t, state[:, 2:4])\novershoot = compute_overshoot(state[:, 2])  # First pendulum\nsettling = compute_settling_time(t, state[:, 2], threshold=0.02)\nenergy = compute_control_effort(t, control)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "614ff1c8"
  },
  {
    "id": "utilities_17_1aea0d62",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 17,
    "code": "from src.utils.analysis import compute_confidence_interval\n\n# Monte Carlo results\nise_values = [result['metrics']['ise'] for result in monte_carlo_results]\n\nmean, ci_lower, ci_upper = compute_confidence_interval(\n    ise_values,\n    confidence=0.95\n)\n\nprint(f\"ISE: {mean:.4f} [{ci_lower:.4f}, {ci_upper:.4f}] (95% CI)\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1aea0d62"
  },
  {
    "id": "utilities_18_d9a2d3d4",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 18,
    "code": "from src.utils.analysis import compare_controllers_statistical\n\n# Compare two controller results\ncontroller_a_results = monte_carlo_results_a\ncontroller_b_results = monte_carlo_results_b\n\ncomparison = compare_controllers_statistical(\n    controller_a_results,\n    controller_b_results,\n    metric='ise'\n)\n\nprint(f\"t-statistic: {comparison['t_statistic']:.4f}\")\nprint(f\"p-value: {comparison['p_value']:.4f}\")\n\nif comparison['p_value'] < 0.05:\n    print(\"Statistically significant difference\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9a2d3d4"
  },
  {
    "id": "utilities_19_48b724df",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 19,
    "code": "from src.utils.analysis import profile_simulation\n\ndef run_simulation():\n    return runner.run(controller)\n\nprofile = profile_simulation(run_simulation, n_runs=100)\n\nprint(f\"Average time: {profile['mean_time']:.4f} s\")\nprint(f\"Std dev: {profile['std_time']:.4f} s\")\nprint(f\"Min time: {profile['min_time']:.4f} s\")\nprint(f\"Max time: {profile['max_time']:.4f} s\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48b724df"
  },
  {
    "id": "utilities_20_61746b9c",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 20,
    "code": "from src.utils.visualization import plot_results\n\n# Plot state trajectories and control\nfig, axes = plot_results(result, show=True)\n\n# Customize plots\nfig, axes = plot_results(\n    result,\n    plot_types=['state', 'control', 'phase'],\n    figsize=(15, 10),\n    show=False\n)\nplt.savefig('simulation_results.png', dpi=300)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61746b9c"
  },
  {
    "id": "utilities_21_53164341",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 21,
    "code": "from src.utils.visualization import (\n    plot_state_trajectory,\n    plot_control_signal,\n    plot_phase_portrait,\n    plot_sliding_surface\n)\n\n# State trajectory\nfig1 = plot_state_trajectory(result['t'], result['state'])\n\n# Control signal\nfig2 = plot_control_signal(result['t'], result['control'], max_force=100)\n\n# Phase portrait\nfig3 = plot_phase_portrait(\n    result['state'][:, 2],  # theta1\n    result['state'][:, 3]   # dtheta1\n)\n\n# Sliding surface\nif 'sliding_surface' in result:\n    fig4 = plot_sliding_surface(result['t'], result['sliding_surface'])",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53164341"
  },
  {
    "id": "utilities_22_5ad31fce",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 22,
    "code": "from src.utils.visualization import DIPAnimator\n\nanimator = DIPAnimator(config.dip_params)\n\n# Create animation\nanim = animator.animate(\n    result['t'],\n    result['state'],\n    save_path='simulation.mp4',\n    fps=30\n)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ad31fce"
  },
  {
    "id": "utilities_23_d9f916c6",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 23,
    "code": "from src.utils.visualization import plot_controller_comparison\n\nresults_dict = {\n    'Classical SMC': result_classical,\n    'STA-SMC': result_sta,\n    'Adaptive SMC': result_adaptive\n}\n\nfig = plot_controller_comparison(\n    results_dict,\n    metrics=['ise', 'settling_time', 'control_effort']\n)\nplt.savefig('controller_comparison.png')",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9f916c6"
  },
  {
    "id": "utilities_24_0405292f",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 24,
    "code": "from src.utils.validation import (\n    validate_physics_params,\n    validate_controller_gains,\n    validate_state\n)\n\n# Validate configuration\ntry:\n    validate_physics_params(config.dip_params)\n    validate_controller_gains(gains, controller_type)\n    validate_state(initial_state)\n    print(\"\u2705 All validation passed\")\nexcept ValueError as e:\n    print(f\"\u274c Validation failed: {e}\")\n    sys.exit(1)\n\n# Proceed with simulation\nresult = runner.run(controller)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0405292f"
  },
  {
    "id": "utilities_25_00d4745d",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 25,
    "code": "from src.utils.monitoring import PerformanceMonitor\nfrom src.utils.analysis import compute_metrics\nfrom src.utils.visualization import plot_results\n\n# Run with monitoring\nmonitor = PerformanceMonitor(dt=0.01)\nmonitor.start()\n\nresult = runner.run(controller)\n\n# Analyze\nmetrics = compute_metrics(result)\nmonitor_stats = monitor.get_statistics()\n\n# Visualize\nplot_results(result, show=True)\n\n# Report\nprint(f\"Performance Metrics:\")\nprint(f\"  ISE: {metrics['ise']:.4f}\")\nprint(f\"  Settling Time: {metrics['settling_time']:.2f} s\")\nprint(f\"  Saturation: {monitor_stats['saturation_percentage']:.1f}%\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "00d4745d"
  },
  {
    "id": "utilities_26_2bbb9488",
    "file": "docs\\guides\\api\\utilities.md",
    "index": 26,
    "code": "from src.utils.analysis import (\n    compute_confidence_interval,\n    compare_controllers_statistical\n)\n\n# Run Monte Carlo\nn_trials = 100\nresults = []\n\nfor i in range(n_trials):\n    ic = np.random.normal(ic_mean, ic_std)\n    result = runner.run(controller, initial_state=ic)\n    results.append(result)\n\n# Compute statistics\nise_values = [r['metrics']['ise'] for r in results]\nmean_ise, ci_lower, ci_upper = compute_confidence_interval(ise_values)\n\nprint(f\"ISE: {mean_ise:.4f} [{ci_lower:.4f}, {ci_upper:.4f}]\")\n\n# Compare with baseline\nif baseline_results:\n    comparison = compare_controllers_statistical(results, baseline_results)\n    print(f\"Improvement: {comparison['improvement_percent']:.1f}%\")\n    print(f\"p-value: {comparison['p_value']:.4f}\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bbb9488"
  },
  {
    "id": "optimization-workflows_1_685939dd",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef minimal_settling_time_cost(metrics, config):\n    \"\"\"\n    Custom cost emphasizing fast settling.\n\n    Hard constraints:\n    - Overshoot < 10%\n    - Peak control < max_force\n\n    Soft objective:\n    - Minimize settling time\n    \"\"\"\n    # Hard constraints (return infinite cost if violated)\n    if metrics['overshoot'] > 10.0:\n        return float('inf')  # Infeasible\n\n    if metrics.get('max_control', 0) > config.get('max_force', 100.0):\n        return float('inf')  # Actuator limit violated\n\n    # Primary objective: settling time\n    cost = 0.7 * metrics['settling_time']\n\n    # Secondary objectives\n    cost += 0.2 * metrics['ise']\n    cost += 0.1 * metrics['control_effort'] / 100.0  # Normalize\n\n    return cost",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "685939dd"
  },
  {
    "id": "optimization-workflows_2_37c73273",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 2,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\nfrom custom_cost import minimal_settling_time_cost\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create PSO tuner with custom cost\ntuner = PSOTuner(\n    controller_type='classical_smc',\n    config=config,\n    cost_function=minimal_settling_time_cost  # Custom!\n)\n\n# Run optimization\nbest_gains, best_cost = tuner.optimize()\n\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Final cost: {best_cost:.4f}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37c73273"
  },
  {
    "id": "optimization-workflows_3_e3e16e6a",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 3,
    "code": "def pareto_cost(metrics, config, alpha=0.5):\n    \"\"\"\n    Pareto front exploration: performance vs efficiency.\n\n    alpha=0.0: Pure efficiency (low control effort)\n    alpha=1.0: Pure performance (low ISE)\n    alpha=0.5: Balanced trade-off\n    \"\"\"\n    # Normalize metrics to [0, 1] range\n    performance_cost = metrics['ise'] / 2.0  # Assume ISE < 2.0\n    efficiency_cost = metrics['control_effort'] / 500.0  # Assume effort < 500\n\n    # Weighted combination\n    cost = alpha * performance_cost + (1 - alpha) * efficiency_cost\n\n    return cost\n\n# Run PSO for multiple alpha values\nalphas = [0.1, 0.3, 0.5, 0.7, 0.9]\npareto_solutions = []\n\nfor alpha in alphas:\n    custom_cost = lambda m, c: pareto_cost(m, c, alpha=alpha)\n\n    tuner = PSOTuner(\n        controller_type='classical_smc',\n        config=config,\n        cost_function=custom_cost\n    )\n\n    gains, cost = tuner.optimize()\n\n    # Re-evaluate to get actual metrics\n    result = evaluate_controller(gains)\n\n    pareto_solutions.append({\n        'alpha': alpha,\n        'gains': gains,\n        'ise': result['metrics']['ise'],\n        'control_effort': result['metrics']['control_effort']\n    })\n\n# Plot Pareto front\nimport matplotlib.pyplot as plt\n\nise_values = [sol['ise'] for sol in pareto_solutions]\neffort_values = [sol['control_effort'] for sol in pareto_solutions]\n\nplt.plot(ise_values, effort_values, 'bo-')\nplt.xlabel('ISE (Performance)')\nplt.ylabel('Control Effort (Energy)')\nplt.title('Pareto Front: Performance vs Efficiency')\nplt.grid(True)\nplt.show()",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3e16e6a"
  },
  {
    "id": "optimization-workflows_4_fbd1b1f8",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef constrained_cost(metrics, config):\n    \"\"\"\n    Cost function with strict constraints.\n    \"\"\"\n    # Constraint 1: Settling time < 5 seconds\n    if metrics['settling_time'] > 5.0:\n        penalty = 1000 * (metrics['settling_time'] - 5.0)\n        return penalty  # Heavy penalty\n\n    # Constraint 2: Overshoot < 5%\n    if metrics['overshoot'] > 5.0:\n        penalty = 1000 * (metrics['overshoot'] - 5.0)\n        return penalty\n\n    # Constraint 3: Control effort < 200\n    if metrics['control_effort'] > 200.0:\n        penalty = 1000 * (metrics['control_effort'] - 200.0)\n        return penalty\n\n    # All constraints satisfied, minimize ISE\n    return metrics['ise']",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fbd1b1f8"
  },
  {
    "id": "optimization-workflows_5_a7c7099d",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 5,
    "code": "import matplotlib.pyplot as plt\nimport json\n\n# Load PSO results (if history is saved)\nwith open('optimized_gains.json') as f:\n    data = json.load(f)\n\nif 'pso_history' in data:\n    iterations = data['pso_history']['iterations']\n    best_costs = data['pso_history']['best_costs']\n    mean_costs = data['pso_history']['mean_costs']\n\n    # Plot convergence\n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(iterations, best_costs, 'b-', linewidth=2, label='Global Best')\n    ax.plot(iterations, mean_costs, 'r--', linewidth=1, label='Swarm Mean')\n    ax.set_xlabel('Iteration')\n    ax.set_ylabel('Cost')\n    ax.set_title('PSO Convergence')\n    ax.legend()\n    ax.grid(True)\n    ax.set_yscale('log')  # Log scale for better visibility\n    plt.show()",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7c7099d"
  },
  {
    "id": "optimization-workflows_6_3133788f",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Check if swarm collapsed\nif 'pso_history' in data:\n    final_best = best_costs[-1]\n    final_mean = mean_costs[-1]\n\n    diversity_ratio = final_mean / final_best\n\n    if diversity_ratio < 1.05:  # Within 5%\n        print(\"WARNING: Swarm collapsed (premature convergence)\")\n        print(f\"  Best:  {final_best:.4f}\")\n        print(f\"  Mean:  {final_mean:.4f}\")\n        print(f\"  Ratio: {diversity_ratio:.3f}\")\n    else:\n        print(\"OK: Swarm maintains diversity\")",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3133788f"
  },
  {
    "id": "optimization-workflows_7_48152560",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 7,
    "code": "# Check cost volatility\ncost_changes = np.diff(best_costs)\nvolatility = np.std(cost_changes)\n\nif volatility > 0.1 * np.mean(best_costs):\n    print(\"WARNING: High convergence volatility\")\n    print(f\"  Volatility: {volatility:.4f}\")",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48152560"
  },
  {
    "id": "optimization-workflows_8_9a01c4ba",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef multi_start_pso(n_restarts=3):\n    \"\"\"\n    Run PSO multiple times with different initializations.\n    \"\"\"\n    best_overall_cost = float('inf')\n    best_overall_gains = None\n\n    for restart in range(n_restarts):\n        print(f\"\\nRestart {restart + 1}/{n_restarts}\")\n\n        # Different seed for each restart\n        seed = 42 + restart * 100\n\n        tuner = PSOTuner(\n            controller_type='classical_smc',\n            config=config,\n            seed=seed\n        )\n\n        gains, cost = tuner.optimize()\n\n        print(f\"  Best cost: {cost:.4f}\")\n\n        if cost < best_overall_cost:\n            best_overall_cost = cost\n            best_overall_gains = gains\n\n    print(f\"\\nBest across all restarts: {best_overall_cost:.4f}\")\n    return best_overall_gains, best_overall_cost",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a01c4ba"
  },
  {
    "id": "optimization-workflows_9_1c0680d3",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 9,
    "code": "import multiprocessing as mp\nfrom functools import partial\n\ndef run_pso_trial(seed, controller_type, config):\n    \"\"\"Run single PSO trial.\"\"\"\n    tuner = PSOTuner(\n        controller_type=controller_type,\n        config=config,\n        seed=seed\n    )\n\n    gains, cost = tuner.optimize()\n\n    return {\n        'seed': seed,\n        'gains': gains,\n        'cost': cost\n    }\n\n# Define seeds\nseeds = [42, 123, 456, 789, 1337]\n\n# Run in parallel\nwith mp.Pool(5) as pool:\n    run_func = partial(\n        run_pso_trial,\n        controller_type='classical_smc',\n        config=config\n    )\n    results = pool.map(run_func, seeds)\n\n# Find best\nbest_result = min(results, key=lambda x: x['cost'])\n\nprint(f\"Best cost: {best_result['cost']:.4f}\")\nprint(f\"Best seed: {best_result['seed']}\")\nprint(f\"Best gains: {best_result['gains']}\")",
    "lines": 37,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c0680d3"
  },
  {
    "id": "optimization-workflows_10_4867c0a9",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 10,
    "code": "import pickle\nimport os\n\ndef pso_with_checkpointing(checkpoint_interval=10):\n    \"\"\"\n    Run PSO with periodic checkpoints.\n    \"\"\"\n    checkpoint_file = 'pso_checkpoint.pkl'\n\n    # Load checkpoint if exists\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'rb') as f:\n            checkpoint = pickle.load(f)\n        print(f\"Resuming from iteration {checkpoint['iteration']}\")\n        start_iter = checkpoint['iteration']\n        best_gains = checkpoint['best_gains']\n        best_cost = checkpoint['best_cost']\n    else:\n        start_iter = 0\n        best_gains = None\n        best_cost = float('inf')\n\n    # Run PSO (pseudo-code, adapt to your PSO implementation)\n    for iteration in range(start_iter, 100):\n        # PSO update step\n        gains, cost = pso_step(iteration)\n\n        if cost < best_cost:\n            best_cost = cost\n            best_gains = gains\n\n        # Checkpoint every N iterations\n        if (iteration + 1) % checkpoint_interval == 0:\n            checkpoint = {\n                'iteration': iteration + 1,\n                'best_gains': best_gains,\n                'best_cost': best_cost\n            }\n            with open(checkpoint_file, 'wb') as f:\n                pickle.dump(checkpoint, f)\n            print(f\"Checkpoint saved at iteration {iteration + 1}\")\n\n    # Clean up checkpoint\n    if os.path.exists(checkpoint_file):\n        os.remove(checkpoint_file)\n\n    return best_gains, best_cost",
    "lines": 47,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4867c0a9"
  },
  {
    "id": "optimization-workflows_11_31e900d0",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 11,
    "code": "# Test cost function manually\ntest_gains = [10, 8, 15, 12, 50, 5]\nresult = evaluate_controller(test_gains)\ncost = compute_cost(result['metrics'], config)\nprint(f\"Test cost: {cost:.4f}\")\n\n# Try different gains, ensure cost changes",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "31e900d0"
  },
  {
    "id": "optimization-workflows_12_f8e45b42",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 12,
    "code": "# Verify bounds allow good solutions\nprint(\"Parameter bounds:\")\nfor i, bounds in enumerate(config.pso.bounds):\n    print(f\"  Gain {i+1}: [{bounds[0]}, {bounds[1]}]\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8e45b42"
  },
  {
    "id": "optimization-workflows_13_ca455bdf",
    "file": "docs\\guides\\how-to\\optimization-workflows.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Check gains for physical plausibility\nwith open('optimized_gains.json') as f:\n    gains = json.load(f)['gains']\n\nprint(\"Optimized gains:\")\nprint(f\"  k1 (should be positive): {gains[0]:.2f}\")\nprint(f\"  k2 (should be positive): {gains[1]:.2f}\")\nprint(f\"  \u03bb1 (should be positive): {gains[2]:.2f}\")\nprint(f\"  \u03bb2 (should be positive): {gains[3]:.2f}\")\nprint(f\"  K (should be >> 0):      {gains[4]:.2f}\")\nprint(f\"  \u03b5 (should be small):     {gains[5]:.4f}\")\n\n# If gains are at bounds, widen search",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ca455bdf"
  },
  {
    "id": "result-analysis_1_651b58c4",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 1,
    "code": "import json\nimport numpy as np\n\n# Load saved results\nwith open('results_classical.json') as f:\n    data = json.load(f)\n\n# Extract metrics\nmetrics = data['metrics']\nprint(f\"ISE:              {metrics['ise']:.4f}\")\nprint(f\"ITAE:             {metrics['itae']:.4f}\")\nprint(f\"Settling Time:    {metrics['settling_time']:.2f} s\")\nprint(f\"Peak Overshoot:   {metrics['overshoot']:.2f}%\")\nprint(f\"Control Effort:   {metrics['control_effort']:.2f}\")\n\n# Extract trajectories\ntime = np.array(data['time'])\nstate = np.array(data['state'])\ncontrol = np.array(data['control'])\n\n# Separate states\ncart_pos = state[:, 0]\ncart_vel = state[:, 1]\ntheta1 = state[:, 2]\ndtheta1 = state[:, 3]\ntheta2 = state[:, 4]\ndtheta2 = state[:, 5]",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "651b58c4"
  },
  {
    "id": "result-analysis_2_30d07160",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 2,
    "code": "# Manual ISE calculation\ndef compute_ise(time, state):\n    \"\"\"Compute ISE from state trajectory.\"\"\"\n    dt = time[1] - time[0]  # Assume uniform sampling\n    error_norm = np.linalg.norm(state, axis=1)\n    ise = np.sum(error_norm**2) * dt\n    return ise\n\nise_manual = compute_ise(time, state)\nprint(f\"ISE (manual): {ise_manual:.4f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "30d07160"
  },
  {
    "id": "result-analysis_3_8fd21e22",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 3,
    "code": "def compute_itae(time, state):\n    \"\"\"Compute ITAE from state trajectory.\"\"\"\n    dt = time[1] - time[0]\n    error_norm = np.linalg.norm(state, axis=1)\n    itae = np.sum(time * np.abs(error_norm)) * dt\n    return itae\n\nitae_manual = compute_itae(time, state)\nprint(f\"ITAE (manual): {itae_manual:.4f}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8fd21e22"
  },
  {
    "id": "result-analysis_4_d1804572",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 4,
    "code": "# Analyze control effort components\ncontrol_array = np.array(control)\npeak_control = np.max(np.abs(control_array))\nmean_control = np.mean(np.abs(control_array))\nrms_control = np.sqrt(np.mean(control_array**2))\n\nprint(f\"Peak Control: {peak_control:.2f} N\")\nprint(f\"Mean Control: {mean_control:.2f} N\")\nprint(f\"RMS Control:  {rms_control:.2f} N\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d1804572"
  },
  {
    "id": "result-analysis_5_39b7be61",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 5,
    "code": "import json\nimport numpy as np\nfrom scipy import stats\n\n# Load results from two controllers\nwith open('results_classical.json') as f:\n    classical = json.load(f)\n\nwith open('results_sta.json') as f:\n    sta = json.load(f)\n\n# Extract ISE values\nise_classical = classical['metrics']['ise']\nise_sta = sta['metrics']['ise']\n\n# Compute improvement\nimprovement = (ise_classical - ise_sta) / ise_classical * 100\nprint(f\"ISE Improvement: {improvement:.1f}%\")\nprint(f\"Classical SMC: {ise_classical:.4f}\")\nprint(f\"STA-SMC:       {ise_sta:.4f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "39b7be61"
  },
  {
    "id": "result-analysis_6_79f9efa5",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Load multiple trials\nn_trials = 50\nise_classical_trials = []\nise_sta_trials = []\n\nfor i in range(n_trials):\n    with open(f'results_classical_trial_{i}.json') as f:\n        ise_classical_trials.append(json.load(f)['metrics']['ise'])\n\n    with open(f'results_sta_trial_{i}.json') as f:\n        ise_sta_trials.append(json.load(f)['metrics']['ise'])\n\n# Convert to arrays\nise_classical_trials = np.array(ise_classical_trials)\nise_sta_trials = np.array(ise_sta_trials)\n\n# Compute summary statistics\nprint(\"Classical SMC:\")\nprint(f\"  Mean ISE: {np.mean(ise_classical_trials):.4f}\")\nprint(f\"  Std ISE:  {np.std(ise_classical_trials):.4f}\")\nprint(f\"  Min ISE:  {np.min(ise_classical_trials):.4f}\")\nprint(f\"  Max ISE:  {np.max(ise_classical_trials):.4f}\")\n\nprint(\"\\nSTA-SMC:\")\nprint(f\"  Mean ISE: {np.mean(ise_sta_trials):.4f}\")\nprint(f\"  Std ISE:  {np.std(ise_sta_trials):.4f}\")\nprint(f\"  Min ISE:  {np.min(ise_sta_trials):.4f}\")\nprint(f\"  Max ISE:  {np.max(ise_sta_trials):.4f}\")",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "79f9efa5"
  },
  {
    "id": "result-analysis_7_3ca70ea6",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 7,
    "code": "from scipy import stats\n\n# Perform Welch's t-test\nt_stat, p_value = stats.ttest_ind(\n    ise_classical_trials,\n    ise_sta_trials,\n    equal_var=False  # Welch's t-test\n)\n\nprint(f\"\\nWelch's t-test:\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_value:.6f}\")\n\nif p_value < 0.05:\n    print(\"  Result: Statistically significant difference (p < 0.05)\")\nelse:\n    print(\"  Result: No statistically significant difference\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3ca70ea6"
  },
  {
    "id": "result-analysis_8_7849c7c8",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Compute Cohen's d (effect size)\nmean_diff = np.mean(ise_classical_trials) - np.mean(ise_sta_trials)\npooled_std = np.sqrt(\n    (np.std(ise_classical_trials)**2 + np.std(ise_sta_trials)**2) / 2\n)\ncohens_d = mean_diff / pooled_std\n\nprint(f\"\\nEffect Size (Cohen's d): {cohens_d:.4f}\")\nprint(f\"  Interpretation: \", end=\"\")\nif abs(cohens_d) < 0.2:\n    print(\"Small effect\")\nelif abs(cohens_d) < 0.5:\n    print(\"Medium effect\")\nelse:\n    print(\"Large effect\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7849c7c8"
  },
  {
    "id": "result-analysis_9_f2a14ea7",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# 95% Confidence Interval for mean ISE\nconfidence_level = 0.95\nalpha = 1 - confidence_level\n\n# Classical SMC\nci_classical = stats.t.interval(\n    confidence_level,\n    len(ise_classical_trials) - 1,\n    loc=np.mean(ise_classical_trials),\n    scale=stats.sem(ise_classical_trials)\n)\n\n# STA-SMC\nci_sta = stats.t.interval(\n    confidence_level,\n    len(ise_sta_trials) - 1,\n    loc=np.mean(ise_sta_trials),\n    scale=stats.sem(ise_sta_trials)\n)\n\nprint(f\"\\n95% Confidence Intervals:\")\nprint(f\"  Classical SMC: [{ci_classical[0]:.4f}, {ci_classical[1]:.4f}]\")\nprint(f\"  STA-SMC:       [{ci_sta[0]:.4f}, {ci_sta[1]:.4f}]\")",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2a14ea7"
  },
  {
    "id": "result-analysis_10_bc43e49c",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 10,
    "code": "from scipy.stats import bootstrap\n\n# Bootstrap confidence interval (more robust, no normality assumption)\ndef compute_mean(data, axis):\n    return np.mean(data, axis=axis)\n\n# Classical SMC bootstrap CI\nbootstrap_result_classical = bootstrap(\n    (ise_classical_trials,),\n    compute_mean,\n    n_resamples=10000,\n    confidence_level=0.95,\n    method='percentile'\n)\n\nprint(f\"\\nBootstrap 95% CI (Classical): \"\n      f\"[{bootstrap_result_classical.confidence_interval.low:.4f}, \"\n      f\"{bootstrap_result_classical.confidence_interval.high:.4f}]\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bc43e49c"
  },
  {
    "id": "result-analysis_11_a0015d3b",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 11,
    "code": "import matplotlib.pyplot as plt\n\n# Load data\nwith open('results_classical.json') as f:\n    data = json.load(f)\n\ntime = np.array(data['time'])\nstate = np.array(data['state'])\ncontrol = np.array(data['control'])\n\n# Create figure\nfig, axes = plt.subplots(3, 1, figsize=(12, 9))\n\n# Pendulum angles\naxes[0].plot(time, state[:, 2], 'b-', linewidth=2, label='\u03b8\u2081 (first pendulum)')\naxes[0].plot(time, state[:, 4], 'r-', linewidth=2, label='\u03b8\u2082 (second pendulum)')\naxes[0].axhline(0, color='k', linestyle='--', linewidth=0.5)\naxes[0].set_ylabel('Angle (rad)', fontsize=12)\naxes[0].legend(fontsize=10)\naxes[0].grid(True, alpha=0.3)\n\n# Angular velocities\naxes[1].plot(time, state[:, 3], 'b-', linewidth=2, label='d\u03b8\u2081')\naxes[1].plot(time, state[:, 5], 'r-', linewidth=2, label='d\u03b8\u2082')\naxes[1].axhline(0, color='k', linestyle='--', linewidth=0.5)\naxes[1].set_ylabel('Angular Velocity (rad/s)', fontsize=12)\naxes[1].legend(fontsize=10)\naxes[1].grid(True, alpha=0.3)\n\n# Control signal\naxes[2].plot(time, control, 'g-', linewidth=2)\naxes[2].axhline(100, color='r', linestyle='--', label='Max force')\naxes[2].axhline(-100, color='r', linestyle='--')\naxes[2].set_xlabel('Time (s)', fontsize=12)\naxes[2].set_ylabel('Control Force (N)', fontsize=12)\naxes[2].legend(fontsize=10)\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('state_trajectories.png', dpi=300)\nplt.savefig('state_trajectories.pdf')\nplt.show()",
    "lines": 42,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0015d3b"
  },
  {
    "id": "result-analysis_12_233e5081",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ncontrollers = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\ncolors = ['blue', 'red', 'green', 'purple']\nlabels = ['Classical', 'Super-Twisting', 'Adaptive', 'Hybrid']\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nfor ctrl, color, label in zip(controllers, colors, labels):\n    with open(f'results_{ctrl}.json') as f:\n        data = json.load(f)\n\n    time = np.array(data['time'])\n    state = np.array(data['state'])\n\n    # Plot first pendulum angle\n    ax.plot(time, state[:, 2], color=color, linewidth=2, label=label)\n\nax.axhline(0, color='k', linestyle='--', linewidth=0.5)\nax.set_xlabel('Time (s)', fontsize=14)\nax.set_ylabel('\u03b8\u2081 (rad)', fontsize=14)\nax.set_title('Controller Comparison: First Pendulum Angle', fontsize=16)\nax.legend(fontsize=12)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('controller_comparison.png', dpi=300)\nplt.show()",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "233e5081"
  },
  {
    "id": "result-analysis_13_9b031965",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# First pendulum phase portrait\naxes[0].plot(state[:, 2], state[:, 3], 'b-', linewidth=1.5)\naxes[0].plot(state[0, 2], state[0, 3], 'go', markersize=10, label='Start')\naxes[0].plot(state[-1, 2], state[-1, 3], 'ro', markersize=10, label='End')\naxes[0].set_xlabel('\u03b8\u2081 (rad)', fontsize=12)\naxes[0].set_ylabel('d\u03b8\u2081 (rad/s)', fontsize=12)\naxes[0].set_title('First Pendulum Phase Portrait', fontsize=14)\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Second pendulum phase portrait\naxes[1].plot(state[:, 4], state[:, 5], 'r-', linewidth=1.5)\naxes[1].plot(state[0, 4], state[0, 5], 'go', markersize=10, label='Start')\naxes[1].plot(state[-1, 4], state[-1, 5], 'ro', markersize=10, label='End')\naxes[1].set_xlabel('\u03b8\u2082 (rad)', fontsize=12)\naxes[1].set_ylabel('d\u03b8\u2082 (rad/s)', fontsize=12)\naxes[1].set_title('Second Pendulum Phase Portrait', fontsize=14)\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('phase_portraits.png', dpi=300)\nplt.show()",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9b031965"
  },
  {
    "id": "result-analysis_14_4a37255d",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 14,
    "code": "import pandas as pd\n\n# Load metrics from all controllers\nmetrics_data = []\nfor ctrl, label in zip(controllers, labels):\n    with open(f'results_{ctrl}.json') as f:\n        data = json.load(f)\n        metrics_data.append({\n            'Controller': label,\n            'ISE': data['metrics']['ise'],\n            'Settling Time': data['metrics']['settling_time'],\n            'Overshoot': data['metrics']['overshoot']\n        })\n\ndf = pd.DataFrame(metrics_data)\n\n# Create bar chart\nfig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# ISE\naxes[0].bar(df['Controller'], df['ISE'], color=colors)\naxes[0].set_ylabel('ISE', fontsize=12)\naxes[0].set_title('Tracking Accuracy (ISE)', fontsize=14)\naxes[0].grid(axis='y', alpha=0.3)\n\n# Settling Time\naxes[1].bar(df['Controller'], df['Settling Time'], color=colors)\naxes[1].set_ylabel('Time (s)', fontsize=12)\naxes[1].set_title('Settling Time', fontsize=14)\naxes[1].grid(axis='y', alpha=0.3)\n\n# Overshoot\naxes[2].bar(df['Controller'], df['Overshoot'], color=colors)\naxes[2].set_ylabel('Overshoot (%)', fontsize=12)\naxes[2].set_title('Peak Overshoot', fontsize=14)\naxes[2].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('metrics_comparison.png', dpi=300)\nplt.show()",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4a37255d"
  },
  {
    "id": "result-analysis_15_a39fb522",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 15,
    "code": "import pandas as pd\n\n# Load data\nwith open('results_classical.json') as f:\n    data = json.load(f)\n\n# Create DataFrame\ndf = pd.DataFrame({\n    'time': data['time'],\n    'cart_pos': np.array(data['state'])[:, 0],\n    'cart_vel': np.array(data['state'])[:, 1],\n    'theta1': np.array(data['state'])[:, 2],\n    'dtheta1': np.array(data['state'])[:, 3],\n    'theta2': np.array(data['state'])[:, 4],\n    'dtheta2': np.array(data['state'])[:, 5],\n    'control': data['control']\n})\n\n# Save to CSV\ndf.to_csv('simulation_results.csv', index=False)\nprint(\"Exported to simulation_results.csv\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a39fb522"
  },
  {
    "id": "result-analysis_16_a0a7e1f2",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 16,
    "code": "from scipy.io import savemat\n\n# Prepare data for MATLAB\nmatlab_data = {\n    'time': np.array(data['time']),\n    'state': np.array(data['state']),\n    'control': np.array(data['control']),\n    'metrics': {\n        'ISE': data['metrics']['ise'],\n        'ITAE': data['metrics']['itae'],\n        'settling_time': data['metrics']['settling_time']\n    }\n}\n\n# Save to .mat file\nsavemat('simulation_results.mat', matlab_data)\nprint(\"Exported to simulation_results.mat\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0a7e1f2"
  },
  {
    "id": "result-analysis_17_609e7577",
    "file": "docs\\guides\\how-to\\result-analysis.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Create metrics table for LaTeX\nmetrics_table = []\nfor ctrl, label in zip(controllers, labels):\n    with open(f'results_{ctrl}.json') as f:\n        metrics = json.load(f)['metrics']\n        metrics_table.append([\n            label,\n            f\"{metrics['ise']:.4f}\",\n            f\"{metrics['itae']:.4f}\",\n            f\"{metrics['settling_time']:.2f}\",\n            f\"{metrics['overshoot']:.2f}\"\n        ])\n\n# Generate LaTeX\nlatex = r\"\"\"\\begin{table}[h]\n\\centering\n\\caption{Controller Performance Comparison}\n\\begin{tabular}{lcccc}\n\\hline\nController & ISE & ITAE & Settling Time (s) & Overshoot (\\%) \\\\\n\\hline\n\"\"\"\n\nfor row in metrics_table:\n    latex += \" & \".join(row) + r\" \\\\\" + \"\\n\"\n\nlatex += r\"\"\"\\hline\n\\end{tabular}\n\\end{table}\"\"\"\n\nprint(latex)\n\n# Save to file\nwith open('metrics_table.tex', 'w') as f:\n    f.write(latex)",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "609e7577"
  },
  {
    "id": "running-simulations_1_b6224e1b",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 1,
    "code": "import json\n\n# Load results\nwith open('baseline.json') as f:\n    data = json.load(f)\n\n# Access metrics\nprint(f\"ISE: {data['metrics']['ise']:.4f}\")\nprint(f\"Settling Time: {data['metrics']['settling_time']:.2f}s\")\n\n# Access controller type\nprint(f\"Controller: {data['controller_type']}\")\n\n# Access gains used\nprint(f\"Gains: {data['gains']}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b6224e1b"
  },
  {
    "id": "running-simulations_2_5be788a7",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 2,
    "code": "from src.controllers.factory import create_controller\nfrom src.core.simulation_runner import SimulationRunner\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller(\n    'classical_smc',\n    config=config.controllers.classical_smc\n)\n\n# Initialize simulation runner\nrunner = SimulationRunner(config)\n\n# Run simulation\nresult = runner.run(controller)\n\n# Access results\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")\nprint(f\"Settling Time: {result['metrics']['settling_time']:.2f}s\")\n\n# Access trajectories\nimport numpy as np\ntime = np.array(result['time'])\nstate = np.array(result['state'])\ncontrol = np.array(result['control'])\n\n# Extract specific states\ntheta1 = state[:, 2]  # First pendulum angle\ntheta2 = state[:, 4]  # Second pendulum angle",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5be788a7"
  },
  {
    "id": "running-simulations_3_f001e8b2",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 3,
    "code": "from src.controllers import create_smc_for_pso, SMCType\nfrom src.plant.models.dynamics import DoubleInvertedPendulum\nimport numpy as np\n\n# Initialize system\ndt = 0.01\nduration = 5.0\nsteps = int(duration / dt)\n\n# Create dynamics model\ndynamics = DoubleInvertedPendulum(\n    m0=1.0, m1=0.1, m2=0.1,\n    l1=0.5, l2=0.5,\n    g=9.81\n)\n\n# Create controller\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)\n\n# Initialize state\nstate = np.array([0.0, 0.0, 0.1, 0.0, 0.15, 0.0])\nstate_vars = {}\nhistory = controller.initialize_history()\n\n# Storage\ntime_log = []\nstate_log = []\ncontrol_log = []\n\n# Simulation loop\nfor i in range(steps):\n    # Compute control\n    u, state_vars, history = controller.compute_control(\n        state, state_vars, history\n    )\n\n    # Apply dynamics (using RK4 or Euler)\n    state = dynamics.step(state, u, dt)  # Your integration method\n\n    # Log data\n    time_log.append(i * dt)\n    state_log.append(state.copy())\n    control_log.append(u)\n\n# Convert to arrays\ntime_array = np.array(time_log)\nstate_array = np.array(state_log)\ncontrol_array = np.array(control_log)\n\nprint(f\"Final state: {state_array[-1]}\")",
    "lines": 54,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f001e8b2"
  },
  {
    "id": "running-simulations_4_c587443a",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 4,
    "code": "import multiprocessing as mp\nfrom functools import partial\n\ndef run_single_simulation(ic, controller_gains):\n    \"\"\"Run simulation with specific initial condition.\"\"\"\n    config = load_config('config.yaml')\n    config.simulation.initial_conditions = ic\n\n    controller = create_controller(\n        'classical_smc',\n        config=config.controllers.classical_smc,\n        gains=controller_gains\n    )\n\n    runner = SimulationRunner(config)\n    result = runner.run(controller)\n\n    return result['metrics']['ise']\n\n# Define initial conditions\ninitial_conditions = [\n    [0, 0, 0.1, 0, 0.15, 0],\n    [0, 0, 0.2, 0, 0.25, 0],\n    [0, 0, 0.3, 0, 0.35, 0],\n]\n\n# Define gains\ngains = [10, 8, 15, 12, 50, 5]\n\n# Run in parallel\nwith mp.Pool(4) as pool:\n    run_func = partial(run_single_simulation, controller_gains=gains)\n    ise_results = pool.map(run_func, initial_conditions)\n\nprint(f\"Mean ISE: {np.mean(ise_results):.4f}\")\nprint(f\"Std ISE: {np.std(ise_results):.4f}\")",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c587443a"
  },
  {
    "id": "running-simulations_5_aa39cb8a",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 5,
    "code": "# In Jupyter notebook\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom src.controllers.factory import create_controller\nfrom src.core.simulation_runner import SimulationRunner\nfrom src.config import load_config\n\n# Load config\nconfig = load_config('config.yaml')\n\n# Run simulation\ncontroller = create_controller('classical_smc', config=config.controllers.classical_smc)\nrunner = SimulationRunner(config)\nresult = runner.run(controller)\n\n# Plot results inline\nfig, axes = plt.subplots(3, 1, figsize=(12, 8))\n\ntime = result['time']\nstate = np.array(result['state'])\ncontrol = result['control']\n\n# Pendulum angles\naxes[0].plot(time, state[:, 2], label='\u03b8\u2081')\naxes[0].plot(time, state[:, 4], label='\u03b8\u2082')\naxes[0].set_ylabel('Angle (rad)')\naxes[0].legend()\naxes[0].grid()\n\n# Angular velocities\naxes[1].plot(time, state[:, 3], label='d\u03b8\u2081')\naxes[1].plot(time, state[:, 5], label='d\u03b8\u2082')\naxes[1].set_ylabel('Angular Velocity (rad/s)')\naxes[1].legend()\naxes[1].grid()\n\n# Control signal\naxes[2].plot(time, control)\naxes[2].set_xlabel('Time (s)')\naxes[2].set_ylabel('Control Force (N)')\naxes[2].grid()\n\nplt.tight_layout()\nplt.show()\n\n# Display metrics\nprint(f\"ISE: {result['metrics']['ise']:.4f}\")\nprint(f\"Settling Time: {result['metrics']['settling_time']:.2f}s\")",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa39cb8a"
  },
  {
    "id": "running-simulations_6_37bb84a6",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 6,
    "code": "# In custom loop\nif i % 10 == 0:  # Store every 10th sample\n    time_log.append(i * dt)\n    state_log.append(state.copy())\n    control_log.append(u)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37bb84a6"
  },
  {
    "id": "running-simulations_7_1e13ddd7",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 7,
    "code": "import multiprocessing as mp\nimport subprocess\n\ndef run_simulation(params):\n    \"\"\"Run simulation with specific parameters.\"\"\"\n    ctrl, ic_idx, ic = params\n    cmd = [\n        'python', 'simulate.py',\n        '--ctrl', ctrl,\n        '--override', f'simulation.initial_conditions={ic}',\n        '--save', f'results_{ctrl}_ic{ic_idx}.json'\n    ]\n    subprocess.run(cmd, check=True)\n    return f'results_{ctrl}_ic{ic_idx}.json'\n\n# Define parameter combinations\ncontrollers = ['classical_smc', 'sta_smc', 'adaptive_smc', 'hybrid_adaptive_sta_smc']\ninitial_conditions = [\n    [0, 0, 0.1, 0, 0.15, 0],\n    [0, 0, 0.2, 0, 0.25, 0],\n]\n\n# Create all combinations\nexperiments = [\n    (ctrl, i, ic)\n    for ctrl in controllers\n    for i, ic in enumerate(initial_conditions)\n]\n\n# Run in parallel (4 processes)\nwith mp.Pool(4) as pool:\n    result_files = pool.map(run_simulation, experiments)\n\nprint(f\"Generated {len(result_files)} result files\")",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e13ddd7"
  },
  {
    "id": "running-simulations_8_f64ba638",
    "file": "docs\\guides\\how-to\\running-simulations.md",
    "index": 8,
    "code": "from scipy.integrate import solve_ivp\n\ndef dip_dynamics(t, state, controller, state_vars, history):\n    \"\"\"Dynamics function for scipy ODE solver.\"\"\"\n    u, state_vars, history = controller.compute_control(state, state_vars, history)\n\n    # Compute state derivatives (use your dynamics model)\n    dstate = dynamics.compute_derivatives(state, u)\n\n    return dstate\n\n# Solve using RK45 (adaptive)\nsolution = solve_ivp(\n    lambda t, s: dip_dynamics(t, s, controller, state_vars, history),\n    t_span=(0, 5.0),\n    y0=initial_state,\n    method='RK45',\n    rtol=1e-6,\n    atol=1e-9\n)\n\ntime = solution.t\nstate = solution.y.T",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f64ba638"
  },
  {
    "id": "testing-validation_1_639bfc36",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 1,
    "code": "# tests/test_controllers/test_my_controller.py\nimport pytest\nimport numpy as np\nfrom src.controllers.my_controller import MyController\n\n\nclass TestMyController:\n    \"\"\"Unit tests for MyController.\"\"\"\n\n    def test_initialization(self):\n        \"\"\"Test controller initializes correctly.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 5.0]\n        controller = MyController(gains=gains, max_force=100.0)\n\n        assert controller.gains == gains\n        assert controller.max_force == 100.0\n\n    def test_invalid_gain_count(self):\n        \"\"\"Test ValueError raised for wrong number of gains.\"\"\"\n        gains = [10.0, 8.0]  # Too few\n        with pytest.raises(ValueError, match=\"6 gains\"):\n            MyController(gains=gains, max_force=100.0)\n\n    def test_compute_control(self):\n        \"\"\"Test control computation.\"\"\"\n        controller = MyController(\n            gains=[10, 8, 15, 12, 50, 5],\n            max_force=100.0\n        )\n\n        state = np.array([0, 0, 0.1, 0, 0.15, 0])\n        control, state_vars, history = controller.compute_control(\n            state, {}, {}\n        )\n\n        # Check control is computed\n        assert isinstance(control, (float, np.floating))\n\n        # Check bounds\n        assert abs(control) <= 100.0\n\n    def test_control_saturation(self):\n        \"\"\"Test control saturates at max_force.\"\"\"\n        controller = MyController(\n            gains=[10, 8, 15, 12, 500.0, 5.0],  # Very high K\n            max_force=100.0\n        )\n\n        state = np.array([0, 0, 0.5, 0, 0.6, 0])  # Large errors\n        control, _, _ = controller.compute_control(state, {}, {})\n\n        assert abs(control) == 100.0  # Should saturate\n\n    def test_equilibrium(self):\n        \"\"\"Test zero control at equilibrium.\"\"\"\n        controller = MyController(\n            gains=[10, 8, 15, 12, 50, 5],\n            max_force=100.0\n        )\n\n        state = np.zeros(6)  # Perfect equilibrium\n        control, _, _ = controller.compute_control(state, {}, {})\n\n        assert abs(control) < 1e-6  # Nearly zero",
    "lines": 64,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "639bfc36"
  },
  {
    "id": "testing-validation_2_fd82c291",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.parametrize(\"gains,expected_valid\", [\n    ([10, 8, 15, 12, 50, 5], True),   # Valid\n    ([0, 8, 15, 12, 50, 5], False),   # k1 = 0 invalid\n    ([-10, 8, 15, 12, 50, 5], False), # Negative gain\n])\ndef test_gain_validation(gains, expected_valid):\n    \"\"\"Test gain validation with multiple cases.\"\"\"\n    if expected_valid:\n        controller = MyController(gains=gains, max_force=100.0)\n        assert controller.gains == gains\n    else:\n        with pytest.raises(ValueError):\n            MyController(gains=gains, max_force=100.0)",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd82c291"
  },
  {
    "id": "testing-validation_3_9cec4a27",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 3,
    "code": "# In conftest.py\nimport pytest\nfrom src.config import load_config\n\n@pytest.fixture\ndef config():\n    \"\"\"Load test configuration.\"\"\"\n    return load_config('config.yaml')\n\n@pytest.fixture\ndef classical_controller(config):\n    \"\"\"Create classical SMC controller.\"\"\"\n    from src.controllers import create_smc_for_pso, SMCType\n    return create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100.0\n    )\n\n# In test file\ndef test_with_fixture(classical_controller):\n    \"\"\"Test using pre-configured controller.\"\"\"\n    state = np.array([0, 0, 0.1, 0, 0.15, 0])\n    control, _, _ = classical_controller.compute_control(state, {}, {})\n    assert abs(control) <= 100.0",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9cec4a27"
  },
  {
    "id": "testing-validation_4_aaba82f5",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 4,
    "code": "# tests/test_integration/test_end_to_end.py\ndef test_full_simulation():\n    \"\"\"Test complete simulation workflow.\"\"\"\n    from src.controllers.factory import create_controller\n    from src.core.simulation_runner import SimulationRunner\n    from src.config import load_config\n\n    # Load config\n    config = load_config('config.yaml')\n\n    # Create controller\n    controller = create_controller(\n        'classical_smc',\n        config=config.controllers.classical_smc\n    )\n\n    # Run simulation\n    runner = SimulationRunner(config)\n    result = runner.run(controller)\n\n    # Validate results\n    assert 'metrics' in result\n    assert 'time' in result\n    assert 'state' in result\n    assert 'control' in result\n\n    # Check stability (state remains bounded)\n    state = np.array(result['state'])\n    assert np.all(np.abs(state) < 10.0), \"State diverged\"\n\n    # Check settling time reasonable\n    assert result['metrics']['settling_time'] < 10.0",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aaba82f5"
  },
  {
    "id": "testing-validation_5_8594641f",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 5,
    "code": "def validate_controller(controller_name, gains):\n    \"\"\"\n    Comprehensive controller validation.\n\n    Returns: dict with validation results\n    \"\"\"\n    from src.controllers import create_smc_for_pso, SMCType\n    from src.core.simulation_runner import SimulationRunner\n    from src.config import load_config\n\n    results = {\n        'controller': controller_name,\n        'gains': gains,\n        'tests_passed': [],\n        'tests_failed': []\n    }\n\n    config = load_config('config.yaml')\n\n    # Test 1: Initialization\n    try:\n        controller = create_smc_for_pso(\n            SMCType[controller_name.upper()],\n            gains=gains,\n            max_force=100.0\n        )\n        results['tests_passed'].append('Initialization')\n    except Exception as e:\n        results['tests_failed'].append(f'Initialization: {e}')\n        return results\n\n    # Test 2: Equilibrium stability\n    try:\n        state = np.zeros(6)\n        control, _, _ = controller.compute_control(state, {}, {})\n        if abs(control) < 1e-3:\n            results['tests_passed'].append('Equilibrium stability')\n        else:\n            results['tests_failed'].append(f'Equilibrium: control={control:.4f}')\n    except Exception as e:\n        results['tests_failed'].append(f'Equilibrium: {e}')\n\n    # Test 3: Full simulation\n    try:\n        runner = SimulationRunner(config)\n        result = runner.run(controller)\n\n        if result['metrics']['settling_time'] < 10.0:\n            results['tests_passed'].append('Settling time < 10s')\n        else:\n            results['tests_failed'].append(\n                f'Settling time: {result[\"metrics\"][\"settling_time\"]:.2f}s'\n            )\n\n        state_final = np.array(result['state'])\n        if np.all(np.abs(state_final) < 10.0):\n            results['tests_passed'].append('State remains bounded')\n        else:\n            results['tests_failed'].append('State diverged')\n\n    except Exception as e:\n        results['tests_failed'].append(f'Simulation: {e}')\n\n    return results\n\n\n# Run validation\nvalidation = validate_controller('CLASSICAL', [10, 8, 15, 12, 50, 5])\n\nprint(f\"\\n{validation['controller']} Validation:\")\nprint(f\"  Passed: {len(validation['tests_passed'])}\")\nprint(f\"  Failed: {len(validation['tests_failed'])}\")\n\nif validation['tests_failed']:\n    print(\"\\nFailed tests:\")\n    for test in validation['tests_failed']:\n        print(f\"  - {test}\")",
    "lines": 77,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8594641f"
  },
  {
    "id": "testing-validation_6_dbbc0f17",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 6,
    "code": "def test_robustness_to_mass_variation():\n    \"\"\"Test controller with \u00b130% mass variation.\"\"\"\n    from src.plant.models.dynamics import DoubleInvertedPendulum\n\n    masses = [0.7, 0.85, 1.0, 1.15, 1.3]  # \u00b130% variation\n    results = []\n\n    for m0 in masses:\n        # Create dynamics with varied mass\n        dynamics = DoubleInvertedPendulum(\n            m0=m0, m1=0.1, m2=0.1,\n            l1=0.5, l2=0.5\n        )\n\n        # Create controller\n        controller = create_smc_for_pso(\n            SMCType.CLASSICAL,\n            gains=[10, 8, 15, 12, 50, 5],\n            max_force=100.0\n        )\n\n        # Run simulation\n        result = simulate_with_dynamics(controller, dynamics)\n\n        results.append({\n            'm0': m0,\n            'ise': result['metrics']['ise'],\n            'settling_time': result['metrics']['settling_time']\n        })\n\n    # Check robustness\n    ise_values = [r['ise'] for r in results]\n    ise_variance = np.std(ise_values) / np.mean(ise_values)\n\n    print(f\"\\nRobustness Analysis (Mass Variation):\")\n    for r in results:\n        print(f\"  m0={r['m0']:.2f}: ISE={r['ise']:.4f}, \"\n              f\"Settling={r['settling_time']:.2f}s\")\n\n    print(f\"\\nISE Coefficient of Variation: {ise_variance:.3f}\")\n\n    # Robustness criterion: CV < 0.3\n    assert ise_variance < 0.3, \"Controller not robust to mass variation\"",
    "lines": 43,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbbc0f17"
  },
  {
    "id": "testing-validation_7_5f8bf522",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 7,
    "code": "# tests/test_benchmarks/test_controller_performance.py\nimport pytest\nimport numpy as np\nfrom src.controllers import create_smc_for_pso, SMCType\n\ndef test_classical_smc_benchmark(benchmark):\n    \"\"\"Benchmark classical SMC control computation.\"\"\"\n    controller = create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100.0\n    )\n\n    state = np.array([0, 0, 0.1, 0, 0.15, 0])\n    state_vars = {}\n    history = controller.initialize_history()\n\n    # Benchmark the control computation\n    result = benchmark(\n        controller.compute_control,\n        state, state_vars, history\n    )\n\n    # Verify result is valid\n    control, _, _ = result\n    assert abs(control) <= 100.0\n\ndef test_full_simulation_benchmark(benchmark):\n    \"\"\"Benchmark full simulation.\"\"\"\n    from src.controllers.factory import create_controller\n    from src.core.simulation_runner import SimulationRunner\n    from src.config import load_config\n\n    config = load_config('config.yaml')\n    controller = create_controller(\n        'classical_smc',\n        config=config.controllers.classical_smc\n    )\n    runner = SimulationRunner(config)\n\n    # Benchmark full simulation\n    result = benchmark(runner.run, controller)\n\n    # Verify completion\n    assert 'metrics' in result",
    "lines": 45,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5f8bf522"
  },
  {
    "id": "testing-validation_8_8cf51222",
    "file": "docs\\guides\\how-to\\testing-validation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Write failing test\ndef test_new_feature():\n    controller = MyController(...)\n    result = controller.new_feature()\n    assert result == expected_value\n\n# 2. Implement to pass test\nclass MyController:\n    def new_feature(self):\n        # Implementation\n        return expected_value\n\n# 3. Refactor if needed",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8cf51222"
  },
  {
    "id": "pso-theory_1_b4e37518",
    "file": "docs\\guides\\theory\\pso-theory.md",
    "index": 1,
    "code": "N_particles = 30           # Sufficient for 4-6 gains\nmax_iters = 100            # Balance speed and quality\nw = 0.7298                 # Constriction factor\nc1 = c2 = 1.49618          # Balanced cognitive/social",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4e37518"
  },
  {
    "id": "tutorial-01-first-simulation_1_54173d9a",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 1,
    "code": "state = [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "54173d9a"
  },
  {
    "id": "tutorial-01-first-simulation_2_a0a4662f",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 2,
    "code": "# For each state variable:\nfinal_value = x[-1]\nthreshold = 0.02 * abs(final_value)\nsettling_idx = np.where(abs(x - final_value) > threshold)[0]\nsettling_time = t[settling_idx[-1]] if len(settling_idx) > 0 else 0",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0a4662f"
  },
  {
    "id": "tutorial-01-first-simulation_3_8e277ef0",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 3,
    "code": "# For first pendulum angle \u03b8\u2081:\nfinal_angle = theta1[-1]  # ~0 rad\npeak_angle = np.max(np.abs(theta1))\novershoot = (peak_angle - abs(final_angle)) / abs(final_angle) * 100",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e277ef0"
  },
  {
    "id": "tutorial-01-first-simulation_4_b0141412",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 4,
    "code": "# Average error in last 20% of simulation\nsteady_state_region = x[int(0.8*len(x)):]\nsteady_state_error = np.mean(np.abs(steady_state_region - desired_state))",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b0141412"
  },
  {
    "id": "tutorial-01-first-simulation_5_38a8fe6f",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 5,
    "code": "rms_control = np.sqrt(np.mean(u**2))",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38a8fe6f"
  },
  {
    "id": "tutorial-01-first-simulation_6_b60c15f4",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 6,
    "code": "# Compute sliding surface value\ns = 5.0*theta1 + 5.0*dtheta1 + 5.0*theta2 + 0.5*dtheta2\n\n# Plot sliding surface over time\nplt.plot(t, s)\nplt.xlabel('Time (s)')\nplt.ylabel('Sliding Surface s')\nplt.title('Sliding Surface Evolution')\nplt.grid(True)\nplt.show()",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b60c15f4"
  },
  {
    "id": "tutorial-01-first-simulation_7_51ec6cd9",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 7,
    "code": "u = -K \u00b7 tanh(s / \u03b5)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "51ec6cd9"
  },
  {
    "id": "tutorial-01-first-simulation_8_e1162938",
    "file": "docs\\guides\\tutorials\\tutorial-01-first-simulation.md",
    "index": 8,
    "code": "# Random initial angles: \u00b10.2 rad\ninitial_conditions = np.random.uniform(\n    low=[0, 0, -0.2, 0, -0.2, 0],\n    high=[0, 0, 0.2, 0, 0.2, 0],\n    size=(10, 6)\n)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e1162938"
  },
  {
    "id": "tutorial-01-validation-report_1_dd554ce6",
    "file": "docs\\guides\\tutorials\\tutorial-01-validation-report.md",
    "index": 1,
    "code": "from scripts.analysis.compute_performance_metrics import compute_all_metrics\n\n# After simulation\nmetrics = compute_all_metrics(t, x, u)\nprint(metrics)\n\n# Output:\n# Performance Metrics:\n#   Settling Time:       2.45 s\n#   Max Overshoot:       3.2 %\n#   Steady-State Error:  0.008 rad (0.46\u00b0)\n#   RMS Control Effort:  12.4 N\n#   Peak Control:        45.3 N\n#   Control Saturation:  0.0%",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd554ce6"
  },
  {
    "id": "tutorial-01-validation-report_2_6d8ae4ac",
    "file": "docs\\guides\\tutorials\\tutorial-01-validation-report.md",
    "index": 2,
    "code": "from scripts.analysis.compute_performance_metrics import compute_all_metrics\n\n# After running simulation (t, x, u arrays)\nmetrics = compute_all_metrics(t, x, u)\n\n# Display metrics\nprint(metrics)\n\n# Validate against expected ranges\nfrom scripts.analysis.compute_performance_metrics import validate_against_expected\nvalidation = validate_against_expected(metrics)\n\nif all(validation.values()):\n    print(\"All metrics within expected ranges!\")\nelse:\n    print(\"Some metrics outside expected ranges:\")\n    for metric, passed in validation.items():\n        if not passed:\n            print(f\"  - {metric}\")\n\n# Export to JSON\nimport json\nwith open('metrics.json', 'w') as f:\n    json.dump(metrics.to_dict(), f, indent=2)",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d8ae4ac"
  },
  {
    "id": "tutorial-02-controller-comparison_1_9604faed",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 1,
    "code": "import json\nimport numpy as np\n\n# Load all results\nresults = {\n    'classical': json.load(open('results_classical.json')),\n    'sta': json.load(open('results_sta.json')),\n    'adaptive': json.load(open('results_adaptive.json')),\n    'hybrid': json.load(open('results_hybrid.json'))\n}\n\n# Compare key metrics\nfor name, data in results.items():\n    print(f\"\\n{name.upper()} SMC:\")\n    print(f\"  ISE:              {data['metrics']['ise']:.4f}\")\n    print(f\"  ITAE:             {data['metrics']['itae']:.4f}\")\n    print(f\"  Settling Time:    {data['metrics']['settling_time']:.2f} s\")\n    print(f\"  Peak Overshoot:   {data['metrics']['overshoot']:.2f}%\")\n    print(f\"  Control Effort:   {data['metrics']['control_effort']:.2f}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9604faed"
  },
  {
    "id": "tutorial-02-controller-comparison_2_9a5e0190",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 2,
    "code": "def compute_chattering_index(u, dt):\n    \"\"\"Chattering index = average absolute derivative of control signal.\"\"\"\n    du_dt = np.diff(u) / dt\n    return np.mean(np.abs(du_dt))\n\n# Compare chattering across controllers\nfor name, data in results.items():\n    u = np.array(data['control'])\n    chattering = compute_chattering_index(u, dt=0.01)\n    print(f\"{name:15s} chattering index: {chattering:.2f} N/s\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a5e0190"
  },
  {
    "id": "tutorial-02-controller-comparison_3_72cbf137",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 3,
    "code": "# Example verification\nalpha = 20.0\nbeta = 15.0\nL_max = 10.0  # Estimated maximum disturbance gradient\n\nassert alpha > L_max, \"\u03b1 must exceed disturbance Lipschitz constant\"\nassert beta > (5 * L_max**2) / (4 * alpha), \"\u03b2 violates stability condition\"",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72cbf137"
  },
  {
    "id": "tutorial-02-controller-comparison_4_0537ad6a",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 4,
    "code": "# Track adaptive gain evolution\nadapted_gains = data['state_vars']['adaptive_gain']\nimport matplotlib.pyplot as plt\n\nplt.plot(data['time'], adapted_gains)\nplt.xlabel('Time (s)')\nplt.ylabel('Adaptive Gain K(t)')\nplt.title('Gain Adaptation Trajectory')\nplt.grid()\nplt.show()",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0537ad6a"
  },
  {
    "id": "tutorial-02-controller-comparison_5_5247bdc8",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nboundary_layers = [0.001, 0.01, 0.1]\nchattering_indices = []\n\nfor bl in boundary_layers:\n    data = json.load(open(f'bl_{bl}.json'))\n    u = np.array(data['control'])\n    chattering = compute_chattering_index(u, dt=0.01)\n    chattering_indices.append(chattering)\n\n# Plot results\nplt.plot(boundary_layers, chattering_indices, 'o-', label='Classical SMC')\nplt.axhline(sta_chattering, color='red', linestyle='--', label='STA-SMC')\nplt.xlabel('Boundary Layer \u03b5')\nplt.ylabel('Chattering Index (N/s)')\nplt.xscale('log')\nplt.legend()\nplt.grid()\nplt.show()",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5247bdc8"
  },
  {
    "id": "tutorial-02-controller-comparison_6_a51c3590",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 6,
    "code": "from controllers import get_gain_bounds_for_pso, SMCType\n   bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n   print(\"Recommended gain bounds:\", bounds)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a51c3590"
  },
  {
    "id": "tutorial-02-controller-comparison_7_5434c04f",
    "file": "docs\\guides\\tutorials\\tutorial-02-controller-comparison.md",
    "index": 7,
    "code": "# Check if adaptation is occurring\ndata = json.load(open('results_adaptive.json'))\ngain_trajectory = data['state_vars']['adaptive_gain']\n\nif np.std(gain_trajectory) < 0.1:\n    print(\"WARNING: Adaptation not occurring\")\n    print(f\"Final gain: {gain_trajectory[-1]:.2f}\")\n    print(f\"Initial gain: {gain_trajectory[0]:.2f}\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5434c04f"
  },
  {
    "id": "tutorial-03-pso-optimization_1_0800e52d",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 1,
    "code": "# Velocity update\nv[i] = w\u00b7v[i] + c1\u00b7r1\u00b7(pbest[i] - x[i]) + c2\u00b7r2\u00b7(gbest - x[i])\n       \u2191        \u2191                         \u2191\n       inertia  cognitive component       social component\n\n# Position update\nx[i] = x[i] + v[i]",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0800e52d"
  },
  {
    "id": "tutorial-03-pso-optimization_2_aa43d91a",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 2,
    "code": "cost = w1\u00b7ISE + w2\u00b7ITAE + w3\u00b7control_effort + w4\u00b7overshoot_penalty",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa43d91a"
  },
  {
    "id": "tutorial-03-pso-optimization_3_8b4bfc6a",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 3,
    "code": "import json\n\nbaseline = json.load(open('baseline_classical.json'))\noptimized = json.load(open('optimized_classical_results.json'))\n\nprint(\"Performance Improvement:\")\nprint(f\"ISE:        {baseline['metrics']['ise']:.4f} \u2192 {optimized['metrics']['ise']:.4f} \"\n      f\"({(1 - optimized['metrics']['ise']/baseline['metrics']['ise'])*100:.1f}% better)\")\nprint(f\"Settling:   {baseline['metrics']['settling_time']:.2f}s \u2192 {optimized['metrics']['settling_time']:.2f}s\")\nprint(f\"Overshoot:  {baseline['metrics']['overshoot']:.2f}% \u2192 {optimized['metrics']['overshoot']:.2f}%\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b4bfc6a"
  },
  {
    "id": "tutorial-03-pso-optimization_4_063b2d9f",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 4,
    "code": "import json\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load PSO log (if saved during optimization)\npso_data = json.load(open('optimized_classical_gains.json'))\n\n# Extract cost history\nif 'pso_history' in pso_data:\n    iterations = pso_data['pso_history']['iterations']\n    best_costs = pso_data['pso_history']['best_costs']\n    mean_costs = pso_data['pso_history']['mean_costs']\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(iterations, best_costs, 'b-', linewidth=2, label='Global Best')\n    plt.plot(iterations, mean_costs, 'r--', linewidth=1, label='Swarm Mean')\n    plt.xlabel('Iteration')\n    plt.ylabel('Cost')\n    plt.title('PSO Convergence: Classical SMC')\n    plt.legend()\n    plt.grid(True)\n    plt.semilogy()  # Log scale for better visibility\n    plt.show()",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "063b2d9f"
  },
  {
    "id": "tutorial-03-pso-optimization_5_6ff386b7",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nscenarios = ['small', 'large', 'cart', 'velocity']\nresults = {}\n\nfor scenario in scenarios:\n    data = json.load(open(f'test_{scenario}.json'))\n    results[scenario] = {\n        'ise': data['metrics']['ise'],\n        'settling': data['metrics']['settling_time'],\n        'stable': data['metrics']['settling_time'] < 10.0  # Stability criterion\n    }\n\n# Print summary\nprint(\"Robustness Validation:\")\nfor scenario, metrics in results.items():\n    status = \"\u2713\" if metrics['stable'] else \"\u2717\"\n    print(f\"{status} {scenario:10s}: ISE={metrics['ise']:.3f}, Settling={metrics['settling']:.2f}s\")",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ff386b7"
  },
  {
    "id": "tutorial-03-pso-optimization_6_802010cf",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef custom_cost_function(metrics: dict, config: dict) -> float:\n    \"\"\"\n    Custom cost emphasizing settling time with hard constraints.\n\n    Returns float('inf') if constraints violated.\n    \"\"\"\n    # Hard constraints (return infinite cost if violated)\n    if metrics['overshoot'] > 10.0:  # Max 10% overshoot\n        return float('inf')\n\n    if metrics['max_control'] > 100.0:  # Actuator limit\n        return float('inf')\n\n    # Primary objective: settling time\n    cost = 0.6 * metrics['settling_time']\n\n    # Secondary objectives\n    cost += 0.2 * metrics['ise']\n    cost += 0.1 * metrics['control_effort'] / 100.0  # Normalize\n    cost += 0.1 * metrics['overshoot'] / 10.0        # Normalize\n\n    return cost",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "802010cf"
  },
  {
    "id": "tutorial-03-pso-optimization_7_589d326d",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 7,
    "code": "from src.optimizer.pso_optimizer import PSOTuner\nfrom custom_cost import custom_cost_function\n\ntuner = PSOTuner(\n    controller_factory=controller_factory,\n    config=config,\n    cost_function=custom_cost_function  # Custom cost\n)\n\nbest_gains, best_cost = tuner.optimize()",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "589d326d"
  },
  {
    "id": "tutorial-03-pso-optimization_8_453c9ce8",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 8,
    "code": "from pyswarms.single import GlobalBestPSO\nimport numpy as np\n\ndef multi_objective_cost(gains_array):\n    \"\"\"\n    Returns tuple: (performance_cost, energy_cost)\n    PSO will optimize weighted sum, but we track both.\n    \"\"\"\n    # Run simulation with candidate gains\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains_array)\n    result = simulate(controller, duration=5.0, dt=0.01)\n\n    # Compute both objectives\n    performance_cost = result['metrics']['ise'] + result['metrics']['itae']\n    energy_cost = result['metrics']['control_effort']\n\n    # Weighted sum for PSO (user-defined trade-off)\n    alpha = 0.7  # Performance weight\n    combined_cost = alpha * performance_cost + (1 - alpha) * energy_cost\n\n    return combined_cost, performance_cost, energy_cost\n\n# Run PSO and track Pareto front\npareto_solutions = []\n\nfor alpha in [0.1, 0.3, 0.5, 0.7, 0.9]:  # Different trade-offs\n    # Re-run PSO with different alpha\n    best_gains, best_cost = run_pso_with_alpha(alpha)\n    pareto_solutions.append({\n        'alpha': alpha,\n        'gains': best_gains,\n        'performance': performance_cost,\n        'energy': energy_cost\n    })\n\n# Visualize Pareto front\nimport matplotlib.pyplot as plt\n\nperf = [s['performance'] for s in pareto_solutions]\nenergy = [s['energy'] for s in pareto_solutions]\n\nplt.plot(perf, energy, 'bo-')\nplt.xlabel('Performance Cost (ISE + ITAE)')\nplt.ylabel('Energy Cost')\nplt.title('Pareto Front: Performance vs Energy Trade-off')\nplt.grid(True)\nplt.show()",
    "lines": 47,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "453c9ce8"
  },
  {
    "id": "tutorial-03-pso-optimization_9_b3309252",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 9,
    "code": "# Start with large swarm, reduce over time to save computation\ninitial_swarm = 50\nfinal_swarm = 20\n\nfor iter in range(100):\n    current_swarm_size = int(initial_swarm - (initial_swarm - final_swarm) * iter / 100)\n    # Run PSO iteration with current_swarm_size",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3309252"
  },
  {
    "id": "tutorial-03-pso-optimization_10_fa2c799f",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Check if any particles are improving\npso_log = json.load(open('optimized_gains.json'))\nif 'pso_history' in pso_log:\n    costs = pso_log['pso_history']['best_costs']\n    improvement = (costs[0] - costs[-1]) / costs[0] * 100\n    print(f\"Total improvement: {improvement:.1f}%\")\n\n    if improvement < 5:\n        print(\"WARNING: Minimal improvement. Possible causes:\")\n        print(\"1. Bounds too narrow (local minimum)\")\n        print(\"2. Cost function not sensitive to gain changes\")\n        print(\"3. Default gains already near-optimal\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fa2c799f"
  },
  {
    "id": "tutorial-03-pso-optimization_11_3e059f57",
    "file": "docs\\guides\\tutorials\\tutorial-03-pso-optimization.md",
    "index": 11,
    "code": "if max(abs(state)) > 10.0:  # Detect divergence\n       return float('inf')     # Penalize heavily",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e059f57"
  },
  {
    "id": "tutorial-04-custom-controller_1_b8532d45",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass MyCustomController:\n    def __init__(self, gains, max_force, **kwargs):\n        \"\"\"Initialize controller with gains and parameters.\"\"\"\n        pass\n\n    def compute_control(self, state, state_vars, history):\n        \"\"\"\n        Compute control signal for current state.\n\n        Parameters\n        ----------\n        state : np.ndarray\n            State vector [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]\n        state_vars : dict\n            Controller-specific internal state\n        history : dict\n            Historical data for multi-step algorithms\n\n        Returns\n        -------\n        control : float\n            Control input (force applied to cart)\n        state_vars : dict\n            Updated internal state\n        history : dict\n            Updated history\n        \"\"\"\n        pass\n\n    def initialize_history(self) -> dict:\n        \"\"\"Initialize history buffer for controller.\"\"\"\n        return {}\n\n    def cleanup(self):\n        \"\"\"Clean up resources (optional).\"\"\"\n        pass",
    "lines": 39,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b8532d45"
  },
  {
    "id": "tutorial-04-custom-controller_2_1caf58bc",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n#======================================================================================\\\\\\\n#======================== src/controllers/smc/terminal_smc.py ========================\\\\\\\n#======================================================================================\\\\\\\n\n\"\"\"\nTerminal Sliding Mode Controller for double-inverted pendulum.\n\nImplements nonlinear terminal sliding surface for finite-time convergence.\n\"\"\"\n\nimport numpy as np\nimport logging\nimport weakref\nfrom typing import TYPE_CHECKING, List, Tuple, Dict, Optional, Union, Sequence\n\nfrom ...utils import saturate, TerminalSMCOutput\n\nif TYPE_CHECKING:\n    from ...plant.models.dynamics import DoubleInvertedPendulum\n\nlogger = logging.getLogger(__name__)\n\n\nclass TerminalSMC:\n    \"\"\"\n    Terminal Sliding Mode Controller with finite-time convergence.\n\n    Uses nonlinear terminal sliding surface with fractional exponents\n    to achieve faster convergence than classical SMC.\n\n    Parameters\n    ----------\n    gains : array-like\n        [k1, k2, \u03bb1, \u03bb2, K, \u03b1, \u03b2]\n        - k1, k2, \u03bb1, \u03bb2: sliding surface gains (positive)\n        - K: switching gain (positive)\n        - \u03b1, \u03b2: terminal exponents in (0, 1) for finite-time convergence\n    max_force : float\n        Maximum control force (N)\n    boundary_layer : float\n        Boundary layer thickness for chattering reduction\n    dynamics_model : DoubleInvertedPendulum, optional\n        Dynamics model for equivalent control (if None, uses robust control only)\n    singularity_epsilon : float, default=1e-3\n        Small value to avoid singularity when velocities near zero\n    \"\"\"\n\n    def __init__(\n        self,\n        gains: Union[Sequence[float], np.ndarray],\n        max_force: float,\n        boundary_layer: float,\n        dynamics_model: Optional[\"DoubleInvertedPendulum\"] = None,\n        singularity_epsilon: float = 1e-3,\n        switch_method: str = \"tanh\",\n    ):\n        # Validate gain count\n        if len(gains) != 7:\n            raise ValueError(\n                f\"Terminal SMC requires 7 gains [k1,k2,\u03bb1,\u03bb2,K,\u03b1,\u03b2], got {len(gains)}\"\n            )\n\n        # Extract and validate gains\n        self.k1, self.k2, self.lam1, self.lam2, self.K, self.alpha, self.beta = gains\n\n        # Validate gain constraints\n        if self.k1 <= 0 or self.k2 <= 0 or self.lam1 <= 0 or self.lam2 <= 0:\n            raise ValueError(\"Surface gains k1, k2, \u03bb1, \u03bb2 must be positive\")\n\n        if self.K <= 0:\n            raise ValueError(\"Switching gain K must be positive\")\n\n        if not (0 < self.alpha < 1):\n            raise ValueError(f\"Terminal exponent \u03b1 must be in (0,1), got {self.alpha}\")\n\n        if not (0 < self.beta < 1):\n            raise ValueError(f\"Terminal exponent \u03b2 must be in (0,1), got {self.beta}\")\n\n        # Store parameters\n        self.max_force = max_force\n        self.boundary_layer = boundary_layer\n        self.singularity_epsilon = singularity_epsilon\n        self.switch_method = switch_method\n\n        # Store dynamics model reference (weakref to avoid circular reference)\n        if dynamics_model is not None:\n            self._dynamics_ref = weakref.ref(dynamics_model)\n        else:\n            self._dynamics_ref = lambda: None\n\n        logger.info(\n            f\"Initialized Terminal SMC: gains={gains}, max_force={max_force}, \"\n            f\"boundary_layer={boundary_layer}\"\n        )\n\n    @property\n    def dyn(self):\n        \"\"\"Access dynamics model via weakref.\"\"\"\n        if self._dynamics_ref is not None:\n            return self._dynamics_ref()\n        return None\n\n    def compute_sliding_surface(self, state: np.ndarray) -> float:\n        \"\"\"\n        Compute terminal sliding surface.\n\n        s = k\u2081\u00b7\u03b8\u2081 + k\u2082\u00b7sign(d\u03b8\u2081)\u00b7|d\u03b8\u2081|^\u03b1 + \u03bb\u2081\u00b7\u03b8\u2082 + \u03bb\u2082\u00b7sign(d\u03b8\u2082)\u00b7|d\u03b8\u2082|^\u03b2\n\n        Parameters\n        ----------\n        state : np.ndarray\n            [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]\n\n        Returns\n        -------\n        s : float\n            Sliding surface value\n        \"\"\"\n        _, _, theta1, dtheta1, theta2, dtheta2 = state\n\n        # Terminal terms with singularity avoidance\n        # Add small epsilon to avoid division by zero\n        term1 = np.sign(dtheta1) * np.abs(dtheta1 + self.singularity_epsilon) ** self.alpha\n        term2 = np.sign(dtheta2) * np.abs(dtheta2 + self.singularity_epsilon) ** self.beta\n\n        # Sliding surface\n        s = self.k1 * theta1 + self.k2 * term1 + self.lam1 * theta2 + self.lam2 * term2\n\n        return s\n\n    def switching_function(self, s: float) -> float:\n        \"\"\"\n        Continuous approximation to sign function.\n\n        Parameters\n        ----------\n        s : float\n            Sliding surface value\n\n        Returns\n        -------\n        switch : float\n            Switching function output in [-1, 1]\n        \"\"\"\n        if self.switch_method == \"tanh\":\n            return np.tanh(s / self.boundary_layer)\n        elif self.switch_method == \"linear\":\n            return saturate(s / self.boundary_layer, -1.0, 1.0)\n        else:\n            raise ValueError(f\"Unknown switch method: {self.switch_method}\")\n\n    def compute_control(\n        self,\n        state: np.ndarray,\n        state_vars: Optional[Dict] = None,\n        history: Optional[Dict] = None,\n    ) -> Tuple[float, Dict, Dict]:\n        \"\"\"\n        Compute terminal SMC control law.\n\n        Parameters\n        ----------\n        state : np.ndarray\n            State vector [x, dx, \u03b8\u2081, d\u03b8\u2081, \u03b8\u2082, d\u03b8\u2082]\n        state_vars : dict, optional\n            Controller internal state (unused for terminal SMC)\n        history : dict, optional\n            Historical data (unused for terminal SMC)\n\n        Returns\n        -------\n        control : float\n            Control input (force)\n        state_vars : dict\n            Updated state variables\n        history : dict\n            Updated history\n        \"\"\"\n        # Initialize if None\n        if state_vars is None:\n            state_vars = {}\n        if history is None:\n            history = self.initialize_history()\n\n        # Compute sliding surface\n        s = self.compute_sliding_surface(state)\n\n        # Compute switching function\n        switch = self.switching_function(s)\n\n        # Control law: u = -K\u00b7switch(s)\n        # (Simplified: no equivalent control for tutorial simplicity)\n        control = -self.K * switch\n\n        # Saturate to max force\n        control = saturate(control, -self.max_force, self.max_force)\n\n        # Log for debugging\n        logger.debug(f\"Terminal SMC: s={s:.4f}, switch={switch:.4f}, u={control:.4f}\")\n\n        return control, state_vars, history\n\n    def initialize_history(self) -> Dict:\n        \"\"\"Initialize empty history (terminal SMC is memoryless).\"\"\"\n        return {}\n\n    def cleanup(self):\n        \"\"\"Clean up resources.\"\"\"\n        self._dynamics_ref = None\n        logger.debug(\"Terminal SMC cleaned up\")\n\n    def __del__(self):\n        \"\"\"Destructor for automatic cleanup.\"\"\"\n        self.cleanup()",
    "lines": 217,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1caf58bc"
  },
  {
    "id": "tutorial-04-custom-controller_3_fd312276",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 3,
    "code": "@dataclass(frozen=True)\nclass TerminalSMCOutput:\n    \"\"\"Output from Terminal SMC controller.\"\"\"\n\n    control: float\n    sliding_surface: float\n    switching_function: float\n    terminal_term1: float  # sign(d\u03b8\u2081)\u00b7|d\u03b8\u2081|^\u03b1\n    terminal_term2: float  # sign(d\u03b8\u2082)\u00b7|d\u03b8\u2082|^\u03b2",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd312276"
  },
  {
    "id": "tutorial-04-custom-controller_4_c1ff0a67",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nfrom ..smc.terminal_smc import TerminalSMC  # Add import\n\nclass SMCType(str, Enum):\n    CLASSICAL = \"classical\"\n    ADAPTIVE = \"adaptive\"\n    SUPER_TWISTING = \"super_twisting\"\n    HYBRID = \"hybrid\"\n    TERMINAL = \"terminal\"  # New controller type\n\n# Update GAIN_SPECIFICATIONS\nGAIN_SPECIFICATIONS = {\n    # ... existing specs ...\n    SMCType.TERMINAL: GainSpecification(\n        controller_type=SMCType.TERMINAL,\n        n_gains=7,\n        gain_names=[\"k1\", \"k2\", \"lambda1\", \"lambda2\", \"K\", \"alpha\", \"beta\"],\n        bounds=[(0.1, 50.0), (0.1, 50.0), (0.1, 50.0), (0.1, 50.0),\n                (1.0, 200.0), (0.1, 0.9), (0.1, 0.9)],\n        description=\"Terminal SMC with nonlinear sliding surface\"\n    ),\n}\n\n# Update create_controller method\n@staticmethod\ndef create_controller(\n    controller_type: SMCType,\n    config: SMCConfig,\n    dynamics_model: Optional[Any] = None,\n) -> Any:\n    \"\"\"Create SMC controller instance.\"\"\"\n\n    # ... existing code ...\n\n    elif controller_type == SMCType.TERMINAL:\n        from ..smc.terminal_smc import TerminalSMC\n        return TerminalSMC(\n            gains=config.gains,\n            max_force=config.max_force,\n            boundary_layer=config.boundary_layer,\n            dynamics_model=dynamics_model,\n            singularity_epsilon=getattr(config, 'singularity_epsilon', 1e-3),\n            switch_method=getattr(config, 'switch_method', 'tanh'),\n        )\n\n    # ... rest of code ...",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c1ff0a67"
  },
  {
    "id": "tutorial-04-custom-controller_5_340d92e6",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 5,
    "code": "import pytest\nimport numpy as np\nfrom src.controllers.smc.terminal_smc import TerminalSMC\n\n\nclass TestTerminalSMC:\n    \"\"\"Unit tests for Terminal SMC controller.\"\"\"\n\n    def test_initialization_valid_gains(self):\n        \"\"\"Test controller initializes with valid gains.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 0.5, 0.7]\n        controller = TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        assert controller.k1 == 10.0\n        assert controller.alpha == 0.5\n        assert controller.beta == 0.7\n\n    def test_initialization_invalid_gain_count(self):\n        \"\"\"Test ValueError raised for wrong number of gains.\"\"\"\n        gains = [10.0, 8.0, 15.0]  # Only 3 gains\n        with pytest.raises(ValueError, match=\"7 gains\"):\n            TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n    def test_initialization_invalid_exponents(self):\n        \"\"\"Test ValueError for invalid terminal exponents.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 1.5, 0.7]  # \u03b1 > 1\n        with pytest.raises(ValueError, match=\"must be in\"):\n            TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n    def test_sliding_surface_computation(self):\n        \"\"\"Test sliding surface calculation.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 0.5, 0.7]\n        controller = TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        state = np.array([0.0, 0.0, 0.1, 0.0, 0.15, 0.0])\n        s = controller.compute_sliding_surface(state)\n\n        # s = k1\u00b7\u03b81 + k2\u00b70 + \u03bb1\u00b7\u03b82 + \u03bb2\u00b70 = 10*0.1 + 15*0.15 = 3.25\n        assert abs(s - 3.25) < 0.01\n\n    def test_control_computation(self):\n        \"\"\"Test control signal computation.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 0.5, 0.7]\n        controller = TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        state = np.array([0.0, 0.0, 0.1, 0.0, 0.15, 0.0])\n        control, state_vars, history = controller.compute_control(state, {}, {})\n\n        # Control should be computed and bounded\n        assert isinstance(control, (float, np.floating))\n        assert abs(control) <= 100.0  # max_force\n\n    def test_control_saturation(self):\n        \"\"\"Test control saturation at max_force.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 500.0, 0.5, 0.7]  # Very high K\n        controller = TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n\n        state = np.array([0.0, 0.0, 0.5, 0.0, 0.6, 0.0])  # Large errors\n        control, _, _ = controller.compute_control(state, {}, {})\n\n        # Control should saturate at max_force\n        assert abs(control) == 100.0\n\n    def test_cleanup(self):\n        \"\"\"Test resource cleanup.\"\"\"\n        gains = [10.0, 8.0, 15.0, 12.0, 50.0, 0.5, 0.7]\n        controller = TerminalSMC(gains=gains, max_force=100.0, boundary_layer=0.01)\n        controller.cleanup()\n\n        # Dynamics reference should be None after cleanup\n        assert controller._dynamics_ref is None",
    "lines": 71,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "340d92e6"
  },
  {
    "id": "tutorial-04-custom-controller_6_a0c705f5",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_equivalent_control(self, state: np.ndarray) -> float:\n    \"\"\"\n    Compute model-based equivalent control.\n\n    For terminal SMC, this requires computing:\n    u_eq = - (L\u00b7M\u207b\u00b9\u00b7B)\u207b\u00b9 \u00b7 (L\u00b7M\u207b\u00b9\u00b7C + ds/dt)\n\n    where s is the terminal sliding surface.\n    \"\"\"\n    if self.dyn is None:\n        return 0.0  # No model available\n\n    # Get system matrices\n    M = self.dyn.mass_matrix(state)\n    C = self.dyn.coriolis_centrifugal(state)\n    B = self.dyn.control_matrix()\n\n    # Compute L (gradient of sliding surface w.r.t. state)\n    L = self.compute_surface_gradient(state)\n\n    # Solve for u_eq (requires matrix operations)\n    try:\n        M_inv = np.linalg.inv(M)\n        LMB = L @ M_inv @ B\n        if abs(LMB) < 1e-6:  # Singularity check\n            return 0.0\n\n        u_eq = -(1 / LMB) * (L @ M_inv @ C)\n        return saturate(u_eq, -self.max_force, self.max_force)\n\n    except np.linalg.LinAlgError:\n        return 0.0  # Fallback to robust control only",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0c705f5"
  },
  {
    "id": "tutorial-04-custom-controller_7_48137744",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef __init__(self, ...):\n    # ... existing code ...\n    self.use_integral = True\n    self.k_integral = 2.0  # Integral gain\n\ndef compute_control(self, state, state_vars, history):\n    # Initialize integral term if not present\n    if 'integral_s' not in state_vars:\n        state_vars['integral_s'] = 0.0\n\n    # Compute sliding surface\n    s = self.compute_sliding_surface(state)\n\n    # Update integral term\n    dt = 0.01  # Get from config\n    state_vars['integral_s'] += s * dt\n\n    # Control law with integral term\n    control = -self.K * self.switching_function(s) - self.k_integral * state_vars['integral_s']\n\n    # Saturate\n    control = saturate(control, -self.max_force, self.max_force)\n\n    return control, state_vars, history",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48137744"
  },
  {
    "id": "tutorial-04-custom-controller_8_6bced852",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef __init__(self, gains, ...):\n    # Check count\n    if len(gains) != expected_count:\n        raise ValueError(f\"Expected {expected_count} gains, got {len(gains)}\")\n\n    # Check bounds\n    if any(g < 0 for g in gains[:4]):  # Surface gains must be positive\n        raise ValueError(\"Surface gains must be non-negative\")\n\n    # Check constraints (e.g., exponents in (0,1))\n    if not (0 < alpha < 1):\n        raise ValueError(f\"Exponent \u03b1 must be in (0,1), got {alpha}\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6bced852"
  },
  {
    "id": "tutorial-04-custom-controller_9_652e9e10",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 9,
    "code": "# Bad: Division by zero\nterm = dtheta ** alpha\n\n# Good: Add small epsilon\nterm = np.sign(dtheta) * (np.abs(dtheta) + 1e-6) ** alpha",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "652e9e10"
  },
  {
    "id": "tutorial-04-custom-controller_10_e56f9f2b",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 10,
    "code": "try:\n    M_inv = np.linalg.inv(M)\nexcept np.linalg.LinAlgError:\n    logger.warning(\"Singular matrix, using robust control only\")\n    return 0.0  # Fallback",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e56f9f2b"
  },
  {
    "id": "tutorial-04-custom-controller_11_1fcb28d8",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nimport logging\nlogger = logging.getLogger(__name__)\n\ndef compute_control(self, state, ...):\n    s = self.compute_sliding_surface(state)\n    logger.debug(f\"Sliding surface: s={s:.4f}\")\n\n    control = ...\n    logger.debug(f\"Control output: u={control:.4f}\")\n\n    return control, state_vars, history",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1fcb28d8"
  },
  {
    "id": "tutorial-04-custom-controller_12_f330f694",
    "file": "docs\\guides\\tutorials\\tutorial-04-custom-controller.md",
    "index": 12,
    "code": "def cleanup(self):\n    \"\"\"Explicit cleanup for long-running processes.\"\"\"\n    self._dynamics_ref = None\n    logger.debug(f\"{self.__class__.__name__} cleaned up\")\n\ndef __del__(self):\n    \"\"\"Automatic cleanup on garbage collection.\"\"\"\n    self.cleanup()",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f330f694"
  },
  {
    "id": "tutorial-05-research-workflow_1_316ae179",
    "file": "docs\\guides\\tutorials\\tutorial-05-research-workflow.md",
    "index": 1,
    "code": "#!/usr/bin/env python\n\"\"\"\nMonte Carlo robustness study: Classical vs Hybrid Adaptive STA-SMC.\n\nRuns N trials for each controller \u00d7 scenario combination with random seeds.\n\"\"\"\n\nimport numpy as np\nimport subprocess\nimport json\nimport yaml\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Configuration\nN_TRIALS = 50  # Monte Carlo sample size\nCONTROLLERS = ['classical_smc', 'hybrid_adaptive_sta_smc']\nSCENARIOS_FILE = 'experiments/robustness_study/scenarios.yaml'\nRESULTS_DIR = Path('experiments/robustness_study/results')\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# Load scenarios\nwith open(SCENARIOS_FILE) as f:\n    scenarios_config = yaml.safe_load(f)\nscenarios = scenarios_config['scenarios']\n\n# Main experiment loop\nresults = []\n\nfor controller in CONTROLLERS:\n    print(f\"\\n{'='*60}\")\n    print(f\"Running trials for {controller}\")\n    print(f\"{'='*60}\")\n\n    for scenario_name, scenario in scenarios.items():\n        print(f\"\\nScenario: {scenario['name']}\")\n\n        for trial in tqdm(range(N_TRIALS), desc=\"Trials\"):\n            # Unique seed for reproducibility\n            seed = hash((controller, scenario_name, trial)) % (2**31)\n\n            # Construct simulation command\n            cmd = [\n                'python', 'simulate.py',\n                '--ctrl', controller,\n                '--seed', str(seed),\n                '--override', f\"dip_params.m0={scenario['parameters']['m0']}\",\n                '--override', f\"dip_params.m1={scenario['parameters']['m1']}\",\n                '--override', f\"dip_params.m2={scenario['parameters']['m2']}\",\n                '--override', f\"simulation.initial_conditions={scenario['initial_conditions']}\",\n                '--save', f\"{RESULTS_DIR}/{controller}_{scenario_name}_{trial}.json\"\n            ]\n\n            # Run simulation\n            try:\n                subprocess.run(cmd, check=True, capture_output=True)\n\n                # Load results\n                result_file = f\"{RESULTS_DIR}/{controller}_{scenario_name}_{trial}.json\"\n                with open(result_file) as f:\n                    data = json.load(f)\n\n                # Extract metrics\n                results.append({\n                    'controller': controller,\n                    'scenario': scenario_name,\n                    'trial': trial,\n                    'seed': seed,\n                    'ise': data['metrics']['ise'],\n                    'itae': data['metrics']['itae'],\n                    'settling_time': data['metrics']['settling_time'],\n                    'overshoot': data['metrics']['overshoot'],\n                    'control_effort': data['metrics']['control_effort'],\n                    'm0': scenario['parameters']['m0'],\n                    'm1': scenario['parameters']['m1'],\n                    'm2': scenario['parameters']['m2'],\n                })\n\n            except subprocess.CalledProcessError as e:\n                print(f\"ERROR in trial {trial}: {e}\")\n                continue\n\n# Save raw results\ndf = pd.DataFrame(results)\ndf.to_csv(f\"{RESULTS_DIR}/monte_carlo_results.csv\", index=False)\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Experiment complete!\")\nprint(f\"Total trials: {len(results)}\")\nprint(f\"Results saved to: {RESULTS_DIR}/monte_carlo_results.csv\")\nprint(f\"{'='*60}\")",
    "lines": 92,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "316ae179"
  },
  {
    "id": "tutorial-05-research-workflow_2_19020d06",
    "file": "docs\\guides\\tutorials\\tutorial-05-research-workflow.md",
    "index": 2,
    "code": "#!/usr/bin/env python\n\"\"\"Analyze Monte Carlo results with statistical rigor.\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\n\n# Load results\ndf = pd.read_csv('experiments/robustness_study/results/monte_carlo_results.csv')\n\n# Compute summary statistics per controller \u00d7 scenario\nsummary = df.groupby(['controller', 'scenario']).agg({\n    'ise': ['mean', 'std', 'min', 'max'],\n    'settling_time': ['mean', 'std'],\n    'control_effort': ['mean', 'std']\n}).round(4)\n\nprint(\"Summary Statistics:\")\nprint(summary)\nprint(\"\\n\")\n\n# Compute robustness index (coefficient of variation across scenarios)\nrobustness = df.groupby(['controller', 'trial']).agg({\n    'ise': 'std'  # Standard deviation across scenarios (lower = more robust)\n})\n\nrobustness_summary = robustness.groupby('controller').agg({\n    'ise': ['mean', 'std']\n})\n\nprint(\"Robustness Index (ISE std dev across scenarios):\")\nprint(robustness_summary)\nprint(\"\\n\")\n\n# Statistical hypothesis testing: Welch's t-test (unequal variances)\nclassical_robustness = robustness.loc['classical_smc']['ise'].values\nhybrid_robustness = robustness.loc['hybrid_adaptive_sta_smc']['ise'].values\n\nt_stat, p_value = stats.ttest_ind(classical_robustness, hybrid_robustness, equal_var=False)\n\nprint(f\"Welch's t-test:\")\nprint(f\"  H\u2080: No difference in robustness\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value: {p_value:.6f}\")\nprint(f\"  Significant (\u03b1=0.05): {'YES' if p_value < 0.05 else 'NO'}\")\nprint(\"\\n\")\n\n# Effect size (Cohen's d)\npooled_std = np.sqrt((classical_robustness.std()**2 + hybrid_robustness.std()**2) / 2)\ncohens_d = (classical_robustness.mean() - hybrid_robustness.mean()) / pooled_std\n\nprint(f\"Effect Size (Cohen's d): {cohens_d:.4f}\")\nprint(f\"  Interpretation: \", end=\"\")\nif abs(cohens_d) < 0.2:\n    print(\"Small effect\")\nelif abs(cohens_d) < 0.5:\n    print(\"Medium effect\")\nelse:\n    print(\"Large effect\")\nprint(\"\\n\")\n\n# 95% Confidence intervals\nci_classical = stats.t.interval(0.95, len(classical_robustness)-1,\n                                 loc=classical_robustness.mean(),\n                                 scale=classical_robustness.std()/np.sqrt(len(classical_robustness)))\nci_hybrid = stats.t.interval(0.95, len(hybrid_robustness)-1,\n                              loc=hybrid_robustness.mean(),\n                              scale=hybrid_robustness.std()/np.sqrt(len(hybrid_robustness)))\n\nprint(f\"95% Confidence Intervals (Robustness Index):\")\nprint(f\"  Classical SMC: [{ci_classical[0]:.4f}, {ci_classical[1]:.4f}]\")\nprint(f\"  Hybrid SMC:    [{ci_hybrid[0]:.4f}, {ci_hybrid[1]:.4f}]\")",
    "lines": 74,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19020d06"
  },
  {
    "id": "tutorial-05-research-workflow_3_b9785050",
    "file": "docs\\guides\\tutorials\\tutorial-05-research-workflow.md",
    "index": 3,
    "code": "#!/usr/bin/env python\n\"\"\"Generate publication-quality figures.\"\"\"\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set publication style\nsns.set_context(\"paper\", font_scale=1.5)\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.family'] = 'serif'\n\n# Load data\ndf = pd.read_csv('experiments/robustness_study/results/monte_carlo_results.csv')\n\n# Figure 1: Box plots - ISE across scenarios\nfig, ax = plt.subplots()\ndf_pivot = df.pivot_table(values='ise', index='scenario', columns='controller')\n\ndf_pivot.plot(kind='bar', ax=ax, color=['tab:blue', 'tab:orange'])\nax.set_ylabel('ISE')\nax.set_xlabel('Parameter Scenario')\nax.set_title('Controller Performance Under Parameter Uncertainty')\nax.legend(['Classical SMC', 'Hybrid Adaptive STA-SMC'])\nax.grid(axis='y')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('experiments/robustness_study/figures/fig1_ise_comparison.pdf', dpi=300)\nplt.savefig('experiments/robustness_study/figures/fig1_ise_comparison.png', dpi=300)\nprint(\"Saved: fig1_ise_comparison.pdf\")\n\n# Figure 2: Violin plots - Distribution comparison\nfig, ax = plt.subplots()\nsns.violinplot(data=df, x='scenario', y='ise', hue='controller', split=True, ax=ax)\nax.set_ylabel('ISE')\nax.set_xlabel('Parameter Scenario')\nax.set_title('ISE Distribution Comparison')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('experiments/robustness_study/figures/fig2_distribution.pdf', dpi=300)\nprint(\"Saved: fig2_distribution.pdf\")\n\n# Figure 3: Robustness index comparison\nrobustness = df.groupby(['controller', 'trial']).agg({'ise': 'std'}).reset_index()\n\nfig, ax = plt.subplots()\nsns.boxplot(data=robustness, x='controller', y='ise', ax=ax)\nax.set_ylabel('Robustness Index\\n(ISE std dev across scenarios)')\nax.set_xlabel('Controller Type')\nax.set_title('Robustness Comparison (Lower is Better)')\nax.set_xticklabels(['Classical SMC', 'Hybrid Adaptive STA-SMC'])\nplt.tight_layout()\nplt.savefig('experiments/robustness_study/figures/fig3_robustness_index.pdf', dpi=300)\nprint(\"Saved: fig3_robustness_index.pdf\")\n\nprint(\"\\nAll figures saved to: experiments/robustness_study/figures/\")",
    "lines": 57,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9785050"
  },
  {
    "id": "tutorial-05-research-workflow_4_c0850d67",
    "file": "docs\\guides\\tutorials\\tutorial-05-research-workflow.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python\n\"\"\"Generate automated research report.\"\"\"\n\nimport pandas as pd\nimport yaml\n\n# Load results and metadata\ndf = pd.read_csv('experiments/robustness_study/results/monte_carlo_results.csv')\nwith open('experiments/robustness_study/metadata.yaml') as f:\n    metadata = yaml.safe_load(f)\n\n# Generate markdown report\nreport = f\"\"\"\n# {metadata['study']['title']}\n\n**Authors:** {', '.join(metadata['study']['authors'])}\n**Date:** {metadata['study']['date']}\n**Version:** {metadata['study']['version']}\n\n---\n\n## Abstract\n\nThis study compares the robustness of Classical SMC and Hybrid Adaptive STA-SMC\ncontrollers under mass parameter uncertainty for a double-inverted pendulum system.\nMonte Carlo simulations (N={metadata['methods']['monte_carlo']['n_trials']}) were\nconducted across 5 parameter variation scenarios. Results indicate Hybrid Adaptive\nSTA-SMC achieves {improvement:.1f}% better robustness (p < 0.001, Cohen's d = {cohens_d:.2f}).\n\n## Methodology\n\n### Controllers Tested\n{chr(10).join(f\"- **{c['name']}**: {c['implementation']}\" for c in metadata['methods']['controllers'])}\n\n### Experimental Scenarios\n{chr(10).join(f\"- {var}\" for var in metadata['methods']['scenarios']['parameter_variations'])}\n\n### Statistical Analysis\n- Hypothesis Test: {metadata['statistical_analysis']['hypothesis_test']}\n- Significance Level: \u03b1 = {metadata['statistical_analysis']['significance_level']}\n- Effect Size Metric: {metadata['statistical_analysis']['effect_size']}\n\n## Results\n\n### Summary Statistics\n{{summary_table}}\n\n### Hypothesis Test Results\n{{hypothesis_results}}\n\n## Conclusions\n\n{{conclusions}}\n\n## Reproducibility\nAll code, data, and configurations are available in `experiments/robustness_study/`.\nRandom seeds logged for each trial. Framework version: {metadata['reproducibility']['framework_version']}.\n\n---\n\"\"\"\n\n# Fill in results (placeholder for actual computation)\n# ... (run analysis and populate results)\n\n# Save report\nwith open('experiments/robustness_study/REPORT.md', 'w') as f:\n    f.write(report)\n\nprint(\"Report generated: experiments/robustness_study/REPORT.md\")",
    "lines": 72,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c0850d67"
  },
  {
    "id": "batch-simulation-workflow_1_10648a23",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 1,
    "code": "from src.simulation.engines.vector_sim import simulate\nimport numpy as np\n\n# Single simulation\ninitial_state = np.array([0, 0.1, 0.05, 0, 0, 0])  # Small perturbation\ncontrols = np.zeros(500)  # Zero control, 5 seconds\nresult = simulate(initial_state, controls, dt=0.01, horizon=500)\n# Shape: (501, 6) - includes initial state\n\n# Batch simulation (10 trials)\nbatch_size = 10\ninitial_states = np.zeros((batch_size, 6))\ninitial_states[:, 1] = np.linspace(-0.1, 0.1, batch_size)  # Vary theta1\ninitial_states[:, 2] = np.linspace(-0.05, 0.05, batch_size)  # Vary theta2\n\ncontrols_batch = np.zeros((batch_size, 500))  # Zero control for all\n\nresults_batch = simulate(initial_states, controls_batch, dt=0.01, horizon=500)\n# Shape: (10, 501, 6) - batch dimension first",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10648a23"
  },
  {
    "id": "batch-simulation-workflow_2_eb59a47d",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 2,
    "code": "from src.simulation.orchestrators.batch import BatchOrchestrator\nfrom src.controllers.factory import create_controller\nimport numpy as np\n\n# Initialize orchestrator\norchestrator = BatchOrchestrator()\n\n# Batch execution\nbatch_size = 50\ninitial_states = np.random.normal(0, 0.1, (batch_size, 6))\ncontrols = np.zeros((batch_size, 500))\n\nresult_container = orchestrator.execute(\n    initial_state=initial_states,\n    control_inputs=controls,\n    dt=0.01,\n    horizon=500,\n    safety_guards=True,  # Enable per-simulation guards\n    stop_fn=None         # Optional early stopping\n)\n\n# Access results\nstates = result_container.get_states()  # (batch_size, 501, 6)\ntimes = result_container.get_times()    # (501,)",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb59a47d"
  },
  {
    "id": "batch-simulation-workflow_3_c1636492",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 3,
    "code": "from src.simulation.results.containers import BatchResultContainer\n\n# Assume result_container from orchestrator.execute()\n\n# Access individual trial\ntrial_0_states = result_container.get_states(batch_index=0)  # (501, 6)\ntrial_0_times = result_container.get_times(batch_index=0)    # (501,)\n\n# Access all trials\nall_states = result_container.get_states()  # (batch_size, 501, 6)\nall_times = result_container.get_times()     # (501,) - shared across batch\n\n# Metadata\nbatch_count = result_container.get_batch_count()  # int",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c1636492"
  },
  {
    "id": "batch-simulation-workflow_4_f8747ed6",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 4,
    "code": "import numpy as np\nfrom src.simulation.engines.vector_sim import simulate\nfrom src.controllers.factory import create_controller\n\n# Monte Carlo setup\nn_trials = 1000\ndt = 0.01\nduration = 10.0\nhorizon = int(duration / dt)\n\n# Random initial conditions (normal distribution)\ninitial_states = np.zeros((n_trials, 6))\ninitial_states[:, 0] = np.random.normal(0, 0.05, n_trials)     # x\ninitial_states[:, 1] = np.random.normal(0, 0.1, n_trials)      # theta1\ninitial_states[:, 2] = np.random.normal(0, 0.1, n_trials)      # theta2\ninitial_states[:, 3] = np.random.normal(0, 0.01, n_trials)     # xdot\ninitial_states[:, 4] = np.random.normal(0, 0.05, n_trials)     # theta1dot\ninitial_states[:, 5] = np.random.normal(0, 0.05, n_trials)     # theta2dot\n\n# Controller (classical SMC)\ncontroller = create_controller('classical_smc')\n\n# Generate control inputs (requires custom loop for closed-loop)\n# Note: For true closed-loop batch, need custom implementation\n# This example shows structure\n\n# Simplified: open-loop control for demonstration\ncontrols = np.zeros((n_trials, horizon))  # Would compute from feedback\n\n# Run batch simulation\nresults = simulate(initial_states, controls, dt, horizon,\n                   energy_limits=100.0,  # Energy guard\n                   state_bounds=([-5, -np.pi, -np.pi, -10, -10, -10],\n                                 [5, np.pi, np.pi, 10, 10, 10]))\n\n# Statistical analysis\nfinal_states = results[:, -1, :]  # (n_trials, 6)\nfinal_theta1 = final_states[:, 1]\nfinal_theta2 = final_states[:, 2]\n\nprint(f\"Monte Carlo Results ({n_trials} trials):\")\nprint(f\"  Final theta1 - Mean: {final_theta1.mean():.4f}, Std: {final_theta1.std():.4f}\")\nprint(f\"  Final theta2 - Mean: {final_theta2.mean():.4f}, Std: {final_theta2.std():.4f}\")\nprint(f\"  Success rate (|theta| < 0.1): {(np.abs(final_theta1) < 0.1).mean()*100:.1f}%\")",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8747ed6"
  },
  {
    "id": "batch-simulation-workflow_5_cb24d1c0",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 5,
    "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# From Monte Carlo results above\nfinal_states = results[:, -1, :]\n\n# Compute statistics\ndef analyze_monte_carlo(final_states, state_names):\n    stats = {}\n    for i, name in enumerate(state_names):\n        values = final_states[:, i]\n        stats[name] = {\n            'mean': values.mean(),\n            'std': values.std(),\n            'min': values.min(),\n            'max': values.max(),\n            'p95': np.percentile(values, 95),\n            'p05': np.percentile(values, 5)\n        }\n    return stats\n\nstate_names = ['x', 'theta1', 'theta2', 'xdot', 'theta1dot', 'theta2dot']\nstats = analyze_monte_carlo(final_states, state_names)\n\n# Print summary\nfor name, s in stats.items():\n    print(f\"{name:10s}: {s['mean']:8.4f} \u00b1 {s['std']:.4f}  \"\n          f\"[{s['min']:8.4f}, {s['max']:8.4f}]  \"\n          f\"(5%-95%: [{s['p05']:7.4f}, {s['p95']:7.4f}])\")\n\n# Plot distributions\nfig, axes = plt.subplots(2, 3, figsize=(12, 6))\naxes = axes.flat\n\nfor i, name in enumerate(state_names):\n    axes[i].hist(final_states[:, i], bins=50, alpha=0.7, edgecolor='black')\n    axes[i].set_xlabel(name)\n    axes[i].set_ylabel('Count')\n    axes[i].axvline(stats[name]['mean'], color='red', linestyle='--', label='Mean')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.savefig('monte_carlo_distributions.png', dpi=150)",
    "lines": 43,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cb24d1c0"
  },
  {
    "id": "batch-simulation-workflow_6_6297fb33",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\nimport numpy as np\nfrom src.simulation.engines.vector_sim import simulate\nfrom src.controllers.factory import create_controller\n\n# Parameter sweep: vary k1 and k2 gains\nk1_values = np.linspace(5, 30, 10)\nk2_values = np.linspace(5, 30, 10)\n\n# Create grid\nk1_grid, k2_grid = np.meshgrid(k1_values, k2_values)\ncombinations = np.column_stack([k1_grid.ravel(), k2_grid.ravel()])\nn_combinations = combinations.shape[0]  # 100 combinations\n\n# Fixed initial condition\ninitial_state = np.array([0, 0.2, 0.15, 0, 0, 0])  # Significant perturbation\ninitial_states = np.tile(initial_state, (n_combinations, 1))\n\n# For each combination, need to create controller and simulate\n# (Simplified structure - actual implementation needs custom loop)\n\nsettling_times = np.zeros(n_combinations)\novershoot = np.zeros(n_combinations)\n\nfor i, (k1, k2) in enumerate(combinations):\n    # Create controller with gains\n    gains = [k1, k2, 10.0, 5.0, 20.0, 1.0]  # Example gains\n    controller = create_controller('classical_smc', gains=gains)\n\n    # Simulate (would need closed-loop control)\n    # controls = ... (compute from controller)\n    # result = simulate(initial_state, controls, 0.01, 500)\n\n    # Compute metrics\n    # settling_times[i] = compute_settling_time(result)\n    # overshoot[i] = compute_overshoot(result)\n    pass  # Placeholder\n\n# Reshape for heatmap\nsettling_times_grid = settling_times.reshape(k1_grid.shape)\n\n# Plot heatmap\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nplt.contourf(k1_grid, k2_grid, settling_times_grid, levels=20, cmap='viridis')\nplt.colorbar(label='Settling Time (s)')\nplt.xlabel('k1 Gain')\nplt.ylabel('k2 Gain')\nplt.title('Controller Gain Sweep: Settling Time')\nplt.savefig('parameter_sweep_heatmap.png', dpi=150)",
    "lines": 53,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6297fb33"
  },
  {
    "id": "batch-simulation-workflow_7_52a455e1",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 7,
    "code": "import numpy as np\n\n# Estimate memory usage\ndef estimate_memory(batch_size, horizon, state_dim=6):\n    \"\"\"Estimate memory usage for batch simulation.\"\"\"\n    bytes_per_float = 8  # np.float64\n\n    # States array: (batch_size, horizon+1, state_dim)\n    states_size = batch_size * (horizon + 1) * state_dim * bytes_per_float\n\n    # Controls array: (batch_size, horizon)\n    controls_size = batch_size * horizon * bytes_per_float\n\n    # Times array: (horizon+1,)\n    times_size = (horizon + 1) * bytes_per_float\n\n    total_bytes = states_size + controls_size + times_size\n    total_mb = total_bytes / 1024 / 1024\n\n    return total_mb\n\n# Example\nbatch_sizes = [10, 100, 1000, 10000]\nhorizon = 1000  # 10 seconds @ dt=0.01\n\nfor bs in batch_sizes:\n    mem = estimate_memory(bs, horizon)\n    print(f\"Batch size {bs:5d}: {mem:8.2f} MB\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52a455e1"
  },
  {
    "id": "batch-simulation-workflow_8_14217138",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Instead of batch_size=10000\nbatch_size = 1000\nn_chunks = 10\n\nall_results = []\nfor chunk in range(n_chunks):\n    chunk_results = simulate(initial_states[chunk*batch_size:(chunk+1)*batch_size], ...)\n    all_results.append(chunk_results)\n\nresults = np.concatenate(all_results, axis=0)",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "14217138"
  },
  {
    "id": "batch-simulation-workflow_9_bfbd753a",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 9,
    "code": "# Warm-up run (trigger Numba JIT)\n_ = simulate(np.zeros((10, 6)), np.zeros((10, 100)), 0.01, 100)\n\n# Then run actual simulation\nresults = simulate(initial_states, controls, dt, horizon)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfbd753a"
  },
  {
    "id": "batch-simulation-workflow_10_694cf5c1",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Check convergence of mean estimate\ndef check_convergence(samples, window=100):\n    \"\"\"Check if mean estimate has converged.\"\"\"\n    means = [samples[:i].mean() for i in range(window, len(samples), window)]\n    relative_change = np.abs(np.diff(means) / means[:-1])\n    return relative_change.max() < 0.01  # 1% threshold\n\n# Example\ntheta1_samples = results[:, -1, 1]\nconverged = check_convergence(theta1_samples)\nprint(f\"Convergence: {'\u2713' if converged else '\u2717'}\")",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "694cf5c1"
  },
  {
    "id": "batch-simulation-workflow_11_ee1f5920",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Coarse sweep first\nk1_coarse = np.linspace(5, 30, 5)\nk2_coarse = np.linspace(5, 30, 5)\n\n# Run coarse sweep...\n# Identify best region\n\n# Refine around best point\nk1_best, k2_best = 15.0, 20.0  # Example\nk1_fine = np.linspace(k1_best-5, k1_best+5, 20)\nk2_fine = np.linspace(k2_best-5, k2_best+5, 20)\n\n# Run fine sweep in refined region...",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee1f5920"
  },
  {
    "id": "batch-simulation-workflow_12_dd5ce851",
    "file": "docs\\guides\\workflows\\batch-simulation-workflow.md",
    "index": 12,
    "code": "# Vector simulation\nfrom src.simulation.engines.vector_sim import simulate\nresults = simulate(initial_states, controls, dt, horizon, **options)\n\n# Batch orchestrator\nfrom src.simulation.orchestrators.batch import BatchOrchestrator\norchestrator = BatchOrchestrator()\ncontainer = orchestrator.execute(initial_state, control_inputs, dt, horizon, **kwargs)\n\n# Result containers\nfrom src.simulation.results.containers import BatchResultContainer\nstates = container.get_states(batch_index=None)  # All or specific trial\ntimes = container.get_times(batch_index=None)\ncount = container.get_batch_count()",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dd5ce851"
  },
  {
    "id": "hil-workflow_1_a70ed913",
    "file": "docs\\guides\\workflows\\hil-workflow.md",
    "index": 1,
    "code": "import struct\nimport zlib\n\n# For command packet\npayload = struct.pack(\"!I d\", sequence_num, control_force)\ncrc = zlib.crc32(payload) & 0xFFFFFFFF\npacket = payload + struct.pack(\"!I\", crc)\n\n# For state packet\npayload = struct.pack(\"!I 6d\", sequence_num, x, theta1, theta2, xdot, theta1dot, theta2dot)\ncrc = zlib.crc32(payload) & 0xFFFFFFFF\npacket = payload + struct.pack(\"!I\", crc)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a70ed913"
  },
  {
    "id": "hil-workflow_2_a393191d",
    "file": "docs\\guides\\workflows\\hil-workflow.md",
    "index": 2,
    "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Load HIL results\ndata = np.load('out/hil_results.npz', allow_pickle=True)\n\nprint(\"Metadata:\", data['meta'].item())\nprint(\"Duration:\", data['t'][-1], \"seconds\")\nprint(\"Steps:\", len(data['t']))\n\n# Extract data\nt = data['t']         # Time vector (1001,)\nx = data['x']         # State trajectory (1001, 6)\nu = data['u']         # Control signal (1000,)\n\n# Plot state trajectory\nfig, axes = plt.subplots(3, 1, figsize=(10, 8))\n\naxes[0].plot(t, x[:, 0])\naxes[0].set_ylabel('Cart Position (m)')\naxes[0].grid(True)\n\naxes[1].plot(t, x[:, 1], label='Pendulum 1')\naxes[1].plot(t, x[:, 2], label='Pendulum 2')\naxes[1].set_ylabel('Angle (rad)')\naxes[1].legend()\naxes[1].grid(True)\n\naxes[2].plot(t[:-1], u)\naxes[2].set_ylabel('Control Force (N)')\naxes[2].set_xlabel('Time (s)')\naxes[2].grid(True)\n\nplt.tight_layout()\nplt.savefig('hil_results.png', dpi=150)\nplt.show()",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a393191d"
  },
  {
    "id": "hil-workflow_3_56d0e90b",
    "file": "docs\\guides\\workflows\\hil-workflow.md",
    "index": 3,
    "code": "import numpy as np\n\ndata = np.load('out/hil_results.npz', allow_pickle=True)\nmeta = data['meta'].item()\n\n# Network configuration\nprint(f\"Plant: {meta['plant_ip']}:{meta['plant_port']}\")\nprint(f\"Controller: {meta['controller_ip']}:{meta['controller_port']}\")\nprint(f\"Control loop rate: {1/meta['dt']:.0f} Hz\")\nprint(f\"Total steps: {meta['steps']}\")\n\n# Data integrity check\nt = data['t']\nx = data['x']\nu = data['u']\n\nprint(f\"\\nData Integrity:\")\nprint(f\"  Time points: {len(t)} (expected {meta['steps']+1})\")\nprint(f\"  State samples: {x.shape[0]} (expected {meta['steps']+1})\")\nprint(f\"  Control samples: {u.shape[0]} (expected {meta['steps']})\")\nprint(f\"  NaN in state: {np.isnan(x).any()}\")\nprint(f\"  NaN in control: {np.isnan(u).any()}\")\nprint(f\"  Inf in state: {np.isinf(x).any()}\")\nprint(f\"  Inf in control: {np.isinf(u).any()}\")\n\n# Timing analysis\ndt_actual = np.diff(t)\ndt_mean = dt_actual.mean()\ndt_std = dt_actual.std()\nprint(f\"\\nTiming Analysis:\")\nprint(f\"  Target dt: {meta['dt']:.4f} s\")\nprint(f\"  Actual dt (mean): {dt_mean:.4f} s\")\nprint(f\"  Actual dt (std): {dt_std:.6f} s\")\nprint(f\"  Timing jitter: {dt_std/dt_mean*100:.2f}%\")",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "56d0e90b"
  },
  {
    "id": "hil-workflow_4_e6ac5102",
    "file": "docs\\guides\\workflows\\hil-workflow.md",
    "index": 4,
    "code": "# simulate.py now sets PYTHONPATH for client subprocess\nclient_env = os.environ.copy()\nclient_env[\"PYTHONPATH\"] = str(REPO_ROOT)\nclient_proc = subprocess.Popen(client_cmd, cwd=str(REPO_ROOT), env=client_env)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e6ac5102"
  },
  {
    "id": "hil-workflow_5_f4a5cd2d",
    "file": "docs\\guides\\workflows\\hil-workflow.md",
    "index": 5,
    "code": "# Real-time monitoring script\nimport numpy as np\nimport time\n\nwhile True:\n    try:\n        data = np.load('out/hil_results.npz', allow_pickle=True)\n        u = data['u']\n\n        # Check control limits\n        u_max = np.max(np.abs(u))\n        if u_max > 100:  # Force limit\n            print(f\"WARNING: Control force {u_max:.2f}N exceeds limit!\")\n\n        time.sleep(1.0)\n    except FileNotFoundError:\n        pass",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f4a5cd2d"
  },
  {
    "id": "monte-carlo-validation-quickstart_1_668e7aa5",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n#!/usr/bin/env python\n\"\"\"Quick Monte Carlo validation: 10 trials \u00d7 2 controllers \u00d7 1 scenario.\"\"\"\n\nimport numpy as np\nimport subprocess\nimport json\nfrom pathlib import Path\n\n# Configuration\nN_TRIALS = 10  # Quick test (use 50+ for publication)\nCONTROLLERS = ['classical_smc', 'sta_smc']\nDURATION = 5.0  # Seconds\nRESULTS_DIR = Path('monte_carlo_quick_test')\nRESULTS_DIR.mkdir(exist_ok=True)\n\n# Run trials\nresults = []\nfor controller in CONTROLLERS:\n    print(f\"\\\\nRunning {controller}...\")\n    for trial in range(N_TRIALS):\n        seed = 1000 + trial  # Reproducible seeds\n\n        # Run simulation\n        cmd = [\n            'python', 'simulate.py',\n            '--controller', controller,\n            '--duration', str(DURATION),\n            '--seed', str(seed),\n            '--no-plot'  # Suppress plotting for batch runs\n        ]\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n\n            # Parse output (example - adjust to actual output format)\n            # Assuming simulate.py prints metrics in JSON format\n            # In practice, you'd capture metrics from simulation results\n\n            results.append({\n                'controller': controller,\n                'trial': trial,\n                'seed': seed,\n                # Placeholder metrics - replace with actual parsing\n                'ise': np.random.uniform(0.1, 0.5),  # Example\n                'settling_time': np.random.uniform(2.0, 4.0),  # Example\n            })\n\n            print(f\"  Trial {trial+1}/{N_TRIALS} complete\")\n\n        except subprocess.CalledProcessError as e:\n            print(f\"  Trial {trial} failed: {e}\")\n            continue\n\n# Save results\nimport pandas as pd\ndf = pd.DataFrame(results)\ndf.to_csv(RESULTS_DIR / 'results.csv', index=False)\nprint(f\"\\\\nResults saved to: {RESULTS_DIR / 'results.csv'}\")\nprint(df.groupby('controller')[['ise', 'settling_time']].describe())",
    "lines": 62,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "668e7aa5"
  },
  {
    "id": "monte-carlo-validation-quickstart_2_dc7d5fd6",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 2,
    "code": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# Load results\ndf = pd.read_csv('monte_carlo_quick_test/results.csv')\n\ndef compute_statistics(data, metric='ise', confidence=0.95):\n    \"\"\"Compute mean, std, and confidence interval.\"\"\"\n    mean = data[metric].mean()\n    std = data[metric].std()\n    n = len(data)\n    se = std / np.sqrt(n)  # Standard error\n\n    # Confidence interval (t-distribution)\n    alpha = 1 - confidence\n    t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n    ci_lower = mean - t_critical * se\n    ci_upper = mean + t_critical * se\n\n    return {\n        'mean': mean,\n        'std': std,\n        'se': se,\n        'ci_lower': ci_lower,\n        'ci_upper': ci_upper,\n        'n': n\n    }\n\n# Compute for each controller\nfor controller in df['controller'].unique():\n    data = df[df['controller'] == controller]\n    stats_ise = compute_statistics(data, metric='ise')\n\n    print(f\"\\\\n{controller}:\")\n    print(f\"  ISE: {stats_ise['mean']:.4f} \u00b1 {stats_ise['std']:.4f}\")\n    print(f\"  95% CI: [{stats_ise['ci_lower']:.4f}, {stats_ise['ci_upper']:.4f}]\")\n    print(f\"  Samples: {stats_ise['n']}\")",
    "lines": 38,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dc7d5fd6"
  },
  {
    "id": "monte-carlo-validation-quickstart_3_8b619f36",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 3,
    "code": "from scipy.stats import ttest_ind\n\n# Load data\ndf = pd.read_csv('monte_carlo_quick_test/results.csv')\n\nclassical = df[df['controller'] == 'classical_smc']['ise'].values\nsta = df[df['controller'] == 'sta_smc']['ise'].values\n\n# Welch's t-test (unequal variances)\nt_stat, p_value = ttest_ind(classical, sta, equal_var=False)\n\n# Effect size (Cohen's d)\npooled_std = np.sqrt((classical.std()**2 + sta.std()**2) / 2)\ncohens_d = (classical.mean() - sta.mean()) / pooled_std\n\n# Interpret results\nalpha = 0.05\nsignificant = p_value < alpha\n\nprint(\"\\\\nHypothesis Test Results:\")\nprint(f\"  H\u2080: No difference between controllers\")\nprint(f\"  H\u2081: Controllers have different performance\")\nprint(f\"  \\\\n  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value: {p_value:.4f}\")\nprint(f\"  Significance level (\u03b1): {alpha}\")\nprint(f\"  Result: {'REJECT H\u2080' if significant else 'FAIL TO REJECT H\u2080'} (p {'<' if significant else '>='} {alpha})\")\nprint(f\"  \\\\n  Effect size (Cohen's d): {cohens_d:.4f}\")\nprint(f\"  Interpretation: {interpret_cohens_d(cohens_d)}\")\n\ndef interpret_cohens_d(d):\n    \"\"\"Interpret Cohen's d effect size.\"\"\"\n    abs_d = abs(d)\n    if abs_d < 0.2:\n        return \"Negligible\"\n    elif abs_d < 0.5:\n        return \"Small\"\n    elif abs_d < 0.8:\n        return \"Medium\"\n    else:\n        return \"Large\"",
    "lines": 40,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b619f36"
  },
  {
    "id": "monte-carlo-validation-quickstart_4_c5b4fccd",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 4,
    "code": "from statsmodels.stats.power import ttest_power\n\n# Calculate required sample size for desired power\neffect_size = 0.68  # From Cohen's d above\nalpha = 0.05\npower = 0.80  # Desired power (80%)\n\n# Compute required sample size per group\nfrom statsmodels.stats.power import tt_solve_power\n\nrequired_n = tt_solve_power(\n    effect_size=effect_size,\n    alpha=alpha,\n    power=power,\n    alternative='two-sided'\n)\n\nprint(f\"\\\\nPower Analysis:\")\nprint(f\"  Effect size (d): {effect_size}\")\nprint(f\"  Significance level (\u03b1): {alpha}\")\nprint(f\"  Desired power: {power}\")\nprint(f\"  Required sample size per group: {np.ceil(required_n):.0f}\")\nprint(f\"  \\\\n  Current sample size: 10\")\nprint(f\"  Recommendation: Increase to {np.ceil(required_n):.0f} trials per controller\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5b4fccd"
  },
  {
    "id": "monte-carlo-validation-quickstart_5_f20d8bf7",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 5,
    "code": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Load data\ndf = pd.read_csv('monte_carlo_quick_test/results.csv')\n\n# Compute statistics for each controller\ncontrollers = df['controller'].unique()\nstats_data = []\n\nfor ctrl in controllers:\n    data = df[df['controller'] == ctrl]['ise'].values\n    mean = data.mean()\n    ci = stats.t.interval(0.95, len(data)-1,\n                           loc=mean,\n                           scale=stats.sem(data))\n    stats_data.append({\n        'controller': ctrl,\n        'mean': mean,\n        'ci_lower': ci[0],\n        'ci_upper': ci[1]\n    })\n\nstats_df = pd.DataFrame(stats_data)\n\n# Plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\nx = np.arange(len(controllers))\nmeans = stats_df['mean'].values\nci_errors = np.array([stats_df['mean'] - stats_df['ci_lower'],\n                       stats_df['ci_upper'] - stats_df['mean']])\n\nax.bar(x, means, alpha=0.7, color=['blue', 'orange'])\nax.errorbar(x, means, yerr=ci_errors, fmt='none', ecolor='black',\n             capsize=5, capthick=2, label='95% CI')\n\nax.set_xlabel('Controller')\nax.set_ylabel('ISE (Integral Squared Error)')\nax.set_title('Controller Performance Comparison\\\\n(N=10 trials, 95% confidence intervals)')\nax.set_xticks(x)\nax.set_xticklabels(controllers, rotation=15)\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('monte_carlo_quick_test/performance_comparison.png', dpi=150)\nprint(\"\\\\nPlot saved: monte_carlo_quick_test/performance_comparison.png\")",
    "lines": 48,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f20d8bf7"
  },
  {
    "id": "monte-carlo-validation-quickstart_6_6026507f",
    "file": "docs\\guides\\workflows\\monte-carlo-validation-quickstart.md",
    "index": 6,
    "code": "#!/usr/bin/env python\n\"\"\"Complete Monte Carlo validation workflow with statistical analysis.\"\"\"\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Step 1: Run Monte Carlo (assume already completed)\n# Results in: monte_carlo_quick_test/results.csv\n\n# Step 2: Load and validate data\ndf = pd.read_csv('monte_carlo_quick_test/results.csv')\nprint(f\"Loaded {len(df)} trials\")\nprint(f\"Controllers: {df['controller'].unique()}\")\nprint(f\"Metrics: {[col for col in df.columns if col not in ['controller', 'trial', 'seed']]}\")\n\n# Step 3: Descriptive statistics\nprint(\"\\\\n\" + \"=\"*60)\nprint(\"DESCRIPTIVE STATISTICS\")\nprint(\"=\"*60)\nprint(df.groupby('controller').agg({\n    'ise': ['count', 'mean', 'std', 'min', 'max']\n}).round(4))\n\n# Step 4: Hypothesis testing\nprint(\"\\\\n\" + \"=\"*60)\nprint(\"HYPOTHESIS TESTING\")\nprint(\"=\"*60)\n\nclassical = df[df['controller'] == 'classical_smc']['ise'].values\nsta = df[df['controller'] == 'sta_smc']['ise'].values\n\nt_stat, p_value = stats.ttest_ind(classical, sta, equal_var=False)\nprint(f\"Welch's t-test:\")\nprint(f\"  t = {t_stat:.4f}, p = {p_value:.4f}\")\nprint(f\"  Result: {'Significant' if p_value < 0.05 else 'Not significant'} at \u03b1=0.05\")\n\n# Step 5: Effect size\npooled_std = np.sqrt((classical.std()**2 + sta.std()**2) / 2)\ncohens_d = abs(classical.mean() - sta.mean()) / pooled_std\nprint(f\"\\\\nCohen's d: {cohens_d:.4f} ({interpret_cohens_d(cohens_d)})\")\n\n# Step 6: Confidence intervals\nfor ctrl in df['controller'].unique():\n    data = df[df['controller'] == ctrl]['ise']\n    ci = stats.t.interval(0.95, len(data)-1, loc=data.mean(), scale=stats.sem(data))\n    print(f\"\\\\n{ctrl}:\")\n    print(f\"  Mean: {data.mean():.4f}\")\n    print(f\"  95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n\n# Step 7: Visualization\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Box plot\ndf.boxplot(column='ise', by='controller', ax=axes[0])\naxes[0].set_title('ISE Distribution by Controller')\naxes[0].set_xlabel('Controller')\naxes[0].set_ylabel('ISE')\n\n# Bar plot with CI\ncontrollers = df['controller'].unique()\nmeans = [df[df['controller'] == c]['ise'].mean() for c in controllers]\ncis = [stats.t.interval(0.95, len(df[df['controller'] == c])-1,\n                         loc=df[df['controller'] == c]['ise'].mean(),\n                         scale=stats.sem(df[df['controller'] == c]['ise']))\n       for c in controllers]\nci_errors = np.array([[m - ci[0], ci[1] - m] for m, ci in zip(means, cis)]).T\n\nx = np.arange(len(controllers))\naxes[1].bar(x, means, alpha=0.7)\naxes[1].errorbar(x, means, yerr=ci_errors, fmt='none', ecolor='black', capsize=5)\naxes[1].set_xlabel('Controller')\naxes[1].set_ylabel('Mean ISE')\naxes[1].set_title('Mean ISE with 95% CI')\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(controllers)\naxes[1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('monte_carlo_quick_test/analysis_summary.png', dpi=150)\nprint(\"\\\\nPlot saved: monte_carlo_quick_test/analysis_summary.png\")\n\ndef interpret_cohens_d(d):\n    abs_d = abs(d)\n    if abs_d < 0.2: return \"Negligible\"\n    elif abs_d < 0.5: return \"Small\"\n    elif abs_d < 0.8: return \"Medium\"\n    else: return \"Large\"",
    "lines": 89,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6026507f"
  },
  {
    "id": "pso-optimization-workflow_1_2801c79b",
    "file": "docs\\guides\\workflows\\pso-optimization-workflow.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nParticle  1: [23.67, 14.29,  8.87, 3.55,  6.52, 2.93]\nParticle  2: [23.31, 24.01,  3.02, 2.36, 19.80, 2.78]\nParticle  3: [20.03, 25.04,  5.55, 1.29, 28.62, 0.24]\nParticle  4: [25.17, 19.69,  8.06, 1.90, 48.59, 2.68]\n...\nParticle 40: [19.75,  4.97,  3.12, 2.21, 48.38, 1.81]",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2801c79b"
  },
  {
    "id": "pso-optimization-workflow_2_439b2411",
    "file": "docs\\guides\\workflows\\pso-optimization-workflow.md",
    "index": 2,
    "code": "# Velocity update\nv[i] = w\u00b7v[i] + c1\u00b7r1\u00b7(pbest[i] - x[i]) + c2\u00b7r2\u00b7(gbest - x[i])\n     = 0.7\u00b7v[i] + 2.0\u00b7r1\u00b7(pbest[i] - x[i]) + 2.0\u00b7r2\u00b7(gbest - x[i])\n\n# Position update\nx[i] = x[i] + v[i]\nx[i] = clamp(x[i], lower_bounds, upper_bounds)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "439b2411"
  },
  {
    "id": "pso-sta-smc_1_6236f8b0",
    "file": "docs\\guides\\workflows\\pso-sta-smc.md",
    "index": 1,
    "code": "default_gains = [\n    8.0,   # K1: Algorithmic gain\n    4.0,   # K2: Algorithmic gain\n    12.0,  # k1: Surface gain\n    6.0,   # k2: Surface gain\n    4.85,  # \u03bb1: Surface coefficient\n    3.43   # \u03bb2: Surface coefficient\n]",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6236f8b0"
  },
  {
    "id": "pso-sta-smc_2_109f53a6",
    "file": "docs\\guides\\workflows\\pso-sta-smc.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\noptimized_gains = [\n    23.67,  # K1: 2.96\u00d7 increase \u2192 stronger convergence\n    13.29,  # K2: 3.32\u00d7 increase \u2192 better robustness\n    8.87,   # k1: 0.74\u00d7 (decreased) \u2192 less aggressive surface\n    3.55,   # k2: 0.59\u00d7 (decreased) \u2192 smoother dynamics\n    6.52,   # \u03bb1: 1.34\u00d7 increase \u2192 moderate damping\n    2.93    # \u03bb2: 0.85\u00d7 (decreased) \u2192 refined tuning\n]\n\n# Saved to: optimized_gains_sta_smc_phase53.json\n# Best Cost: 0.000000",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "109f53a6"
  },
  {
    "id": "pso-sta-smc_3_324dfd14",
    "file": "docs\\guides\\workflows\\pso-sta-smc.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Load optimized gains\nwith open('optimized_gains_sta_smc_phase53.json', 'r') as f:\n    gains = json.load(f)['sta_smc']\n\nK1, K2 = gains[0], gains[1]\nratio = K2 / K1\n\nprint(f\"K1 = {K1:.2f}\")\nprint(f\"K2 = {K2:.2f}\")\nprint(f\"K2/K1 = {ratio:.3f}\")\n\nif ratio > 0.5:\n    print(\"\u2705 Stability condition satisfied (K2 > 0.5\u00b7K1)\")\nelse:\n    print(\"\u274c WARNING: Stability condition violated!\")",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "324dfd14"
  },
  {
    "id": "pso-sta-smc_4_dabd2393",
    "file": "docs\\guides\\workflows\\pso-sta-smc.md",
    "index": 4,
    "code": "# Add constraint to PSO\n# Ensure K2 > 0.5\u00b7K1 during optimization\n\n# Or post-process gains\nif K2 < 0.5 * K1:\n    K2 = 0.55 * K1  # Add 10% safety margin",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dabd2393"
  },
  {
    "id": "pso-sta-smc_5_8614716e",
    "file": "docs\\guides\\workflows\\pso-sta-smc.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef sta_smc_cost_function(gains):\n    \"\"\"\n    Custom cost for STA-SMC optimization.\n\n    Objectives:\n    1. Minimize ISE (performance)\n    2. Minimize control effort (energy)\n    3. Minimize control rate (smoothness)\n    4. Ensure stability (K2 > 0.5\u00b7K1)\n    \"\"\"\n    K1, K2, k1, k2, lambda1, lambda2 = gains\n\n    # Stability penalty\n    if K2 < 0.5 * K1:\n        penalty = 1000.0  # Large penalty\n    else:\n        penalty = 0.0\n\n    # Run simulation\n    result = simulate_with_gains(gains)\n\n    # Multi-objective cost\n    cost = (\n        1.0 * result['ise'] +           # Performance\n        0.01 * result['control_effort'] + # Energy\n        0.001 * result['control_rate'] +  # Smoothness\n        penalty                           # Stability\n    )\n\n    return cost",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8614716e"
  },
  {
    "id": "CODE_QUALITY_ANALYSIS_PLAN_1_f03ed829",
    "file": "docs\\mcp-debugging\\workflows\\CODE_QUALITY_ANALYSIS_PLAN.md",
    "index": 1,
    "code": "# MCP Tool Call Pattern\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_ruff\",\n  \"args\": {\n    \"file_path\": \"D:\\\\Projects\\\\main\\\\src\\\\controllers\\\\classical_smc.py\",\n    \"fix\": false  # Initial analysis pass\n  }\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f03ed829"
  },
  {
    "id": "CODE_QUALITY_ANALYSIS_PLAN_2_53996fb7",
    "file": "docs\\mcp-debugging\\workflows\\CODE_QUALITY_ANALYSIS_PLAN.md",
    "index": 2,
    "code": "# MCP Tool Call Pattern\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_vulture\",\n  \"args\": {\n    \"directory\": \"D:\\\\Projects\\\\main\\\\src\\\\controllers\",\n    \"min_confidence\": 80  # Only high-confidence findings\n  }\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53996fb7"
  },
  {
    "id": "CODE_QUALITY_ANALYSIS_PLAN_3_06b515d4",
    "file": "docs\\mcp-debugging\\workflows\\CODE_QUALITY_ANALYSIS_PLAN.md",
    "index": 3,
    "code": "# MCP Tool Call Pattern (after manual review of auto-fix candidates)\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_ruff\",\n  \"args\": {\n    \"file_path\": \"D:\\\\Projects\\\\main\\\\src\\\\controllers\\\\classical_smc.py\",\n    \"fix\": true  # Apply automatic fixes\n  }\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "06b515d4"
  },
  {
    "id": "complete-debugging-workflow_1_3d9e3908",
    "file": "docs\\mcp-debugging\\workflows\\complete-debugging-workflow.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Add to src/utils/numerical_stability.py\n\ndef safe_matrix_inverse(M: np.ndarray, eps: float = 1e-10) -> np.ndarray:\n    \"\"\"\n    Compute matrix inverse with regularization for ill-conditioned matrices.\n\n    Args:\n        M: Input matrix\n        eps: Regularization parameter\n\n    Returns:\n        Regularized inverse\n    \"\"\"\n    cond_num = np.linalg.cond(M)\n    if cond_num > 1e8:\n        # Use SVD-based pseudo-inverse\n        return np.linalg.pinv(M, rcond=eps)\n    else:\n        # Standard inversion with small ridge\n        return np.linalg.inv(M + eps * np.eye(M.shape[0]))",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d9e3908"
  },
  {
    "id": "VALIDATION_WORKFLOW_1_4fe27ffc",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude via MCP:\n\"Use mcp-analyzer to run RUFF linting on src/controllers/classical_smc.py\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_ruff\",\n  \"args\": {\n    \"file_path\": \"D:\\\\Projects\\\\main\\\\src\\\\controllers\\\\classical_smc.py\",\n    \"fix\": false\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fe27ffc"
  },
  {
    "id": "VALIDATION_WORKFLOW_2_6007ce0f",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use mcp-analyzer to find dead code in src/utils/validation/\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_vulture\",\n  \"args\": {\n    \"directory\": \"D:\\\\Projects\\\\main\\\\src\\\\utils\\\\validation\",\n    \"min_confidence\": 80\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6007ce0f"
  },
  {
    "id": "VALIDATION_WORKFLOW_3_ce0ee108",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use mcp-analyzer to auto-fix RUFF issues in classical_smc.py\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_ruff\",\n  \"args\": {\n    \"file_path\": \"D:\\\\Projects\\\\main\\\\src\\\\controllers\\\\classical_smc.py\",\n    \"fix\": true\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce0ee108"
  },
  {
    "id": "VALIDATION_WORKFLOW_4_eb0266e0",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use numpy-mcp to calculate the condition number of the inertia matrix:\n[[1.5, 0.2], [0.2, 0.8]]\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"numpy-mcp\",\n  \"tool\": \"statistical_analysis\",\n  \"args\": {\n    \"matrix\": [[1.5, 0.2], [0.2, 0.8]]\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb0266e0"
  },
  {
    "id": "VALIDATION_WORKFLOW_5_0d5bfd6b",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use numpy-mcp to compute eigenvalues of system matrix A:\n[[0, 1], [-2, -3]]\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"numpy-mcp\",\n  \"tool\": \"eigen_decomposition\",\n  \"args\": {\n    \"matrix\": [[0, 1], [-2, -3]]\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d5bfd6b"
  },
  {
    "id": "VALIDATION_WORKFLOW_6_2bb42ee6",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use numpy-mcp to analyze these PSO fitness values:\n[150.2, 145.8, 142.1, 140.5, 139.8, 139.3, 139.1, 139.0]\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"numpy-mcp\",\n  \"tool\": \"statistical_analysis\",\n  \"args\": {\n    \"data\": [150.2, 145.8, 142.1, 140.5, 139.8, 139.3, 139.1, 139.0]\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb42ee6"
  },
  {
    "id": "VALIDATION_WORKFLOW_7_32ae05d5",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use pandas-mcp to calculate average fitness by controller type from the PSO results\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"pandas-mcp\",\n  \"tool\": \"run_pandas_code\",\n  \"args\": {\n    \"code\": \"import pandas as pd\\ndf = pd.DataFrame(pso_data)\\nresult = df.groupby('controller_type')['best_fitness'].agg(['mean', 'std', 'min', 'max'])\"\n  }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "32ae05d5"
  },
  {
    "id": "VALIDATION_WORKFLOW_8_dca504b8",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use pandas-mcp to create a bar chart comparing average fitness by controller type\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"pandas-mcp\",\n  \"tool\": \"generate_chartjs\",\n  \"args\": {\n    \"data\": {\n      \"columns\": [\n        {\"name\": \"Controller\", \"type\": \"string\", \"examples\": [\"classical_smc\", \"adaptive_smc\", \"hybrid_adaptive\", \"sta_smc\"]},\n        {\"name\": \"Average Fitness\", \"type\": \"number\", \"examples\": [142.3, 138.7, 136.2, 140.5]}\n      ]\n    },\n    \"chart_types\": [\"bar\"],\n    \"title\": \"PSO Performance by Controller Type\"\n  }\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dca504b8"
  },
  {
    "id": "VALIDATION_WORKFLOW_9_75fc359f",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use pytest-mcp to list the last 5 test failures\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"pytest-mcp\",\n  \"tool\": \"list_failures\",\n  \"args\": {\n    \"last\": 5\n  }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75fc359f"
  },
  {
    "id": "VALIDATION_WORKFLOW_10_9978287c",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use mcp-analyzer to lint the failing test file tests/test_controllers/test_classical_smc.py\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"mcp-analyzer\",\n  \"tool\": \"run_ruff\",\n  \"args\": {\n    \"file_path\": \"D:\\\\Projects\\\\main\\\\tests\\\\test_controllers\\\\test_classical_smc.py\",\n    \"fix\": false\n  }\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9978287c"
  },
  {
    "id": "VALIDATION_WORKFLOW_11_5383e50e",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Ask Claude:\n\"Use pytest-mcp to analyze failure patterns grouped by test name\"\n\n# Expected MCP tool call:\n{\n  \"server\": \"pytest-mcp\",\n  \"tool\": \"get_patterns\",\n  \"args\": {\n    \"groupby\": \"test_name\"\n  }\n}",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5383e50e"
  },
  {
    "id": "VALIDATION_WORKFLOW_12_2342282b",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 12,
    "code": "list_failures({ last: 10 })",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2342282b"
  },
  {
    "id": "VALIDATION_WORKFLOW_13_473984d7",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 13,
    "code": "run_pandas_code({\n  code: \"df = pd.DataFrame(pso_data); result = df['gbest_fitness'].diff().mean()\"\n})\n# Output: Average improvement per iteration: 0.0012 (very slow!)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "473984d7"
  },
  {
    "id": "VALIDATION_WORKFLOW_14_87ff1224",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 14,
    "code": "eigen_decomposition({\n  matrix: controller_gain_matrix\n})\n# Output: Condition number: 1.2e8 (ill-conditioned!)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "87ff1224"
  },
  {
    "id": "VALIDATION_WORKFLOW_15_6a5fa70e",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 15,
    "code": "run_ruff({\n  file_path: \"src/controllers/classical_smc.py\"\n})\n# Output: 5 issues found, 3 auto-fixable",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6a5fa70e"
  },
  {
    "id": "VALIDATION_WORKFLOW_16_c39c833a",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 16,
    "code": "read_file({ path: \"config/pso_config.yaml\" })\n# Increase swarm_size from 20 to 40\n# Add diversity_threshold: 0.01",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c39c833a"
  },
  {
    "id": "VALIDATION_WORKFLOW_17_75eb1340",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 17,
    "code": "read_file({ path: \"src/controllers/classical_smc.py\" })\n# Add: np.linalg.pinv(M + 1e-8 * np.eye(M.shape[0]))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75eb1340"
  },
  {
    "id": "VALIDATION_WORKFLOW_18_f0ab6a5c",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 18,
    "code": "# example-metadata:\n# runnable: false\n\nrun_ruff({ file_path: \"...\", fix: true })",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0ab6a5c"
  },
  {
    "id": "VALIDATION_WORKFLOW_19_f335ee9f",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 19,
    "code": "track_test({ name: \"test_stability\" })\n# Output: PASSED (3/3 runs)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f335ee9f"
  },
  {
    "id": "VALIDATION_WORKFLOW_20_4c576501",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\n# Pandas: Analyze new run\n# NumPy: Verify condition number < 1e6",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c576501"
  },
  {
    "id": "VALIDATION_WORKFLOW_21_6c0a5865",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\n# Verify tool parameters match schema\n# Check server README for correct parameter format\n# Ensure file paths are absolute\n# Confirm database/files exist before querying",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6c0a5865"
  },
  {
    "id": "VALIDATION_WORKFLOW_22_12216ff0",
    "file": "docs\\mcp-debugging\\workflows\\VALIDATION_WORKFLOW.md",
    "index": 22,
    "code": "# example-metadata:\n# runnable: false\n\n# Validate data format between servers\n# Ensure output of Server A matches input of Server B\n# Check for encoding issues (UTF-8 vs ASCII)\n# Verify JSON structure compatibility",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "12216ff0"
  },
  {
    "id": "00_master_roadmap_1_d882ca7d",
    "file": "docs\\plans\\citation_system\\00_master_roadmap.md",
    "index": 1,
    "code": "# Mitigation: Exponential backoff with checkpoint recovery\nif response.status == 429:\n    sleep_time = min(2 ** retry_count, 300)  # Cap at 5 minutes\n    await asyncio.sleep(sleep_time)\n\n    # Save checkpoint every 50 claims\n    if claim_count % 50 == 0:\n        save_checkpoint(f'checkpoint_{claim_count}.json')",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d882ca7d"
  },
  {
    "id": "00_master_roadmap_2_8a23f5e4",
    "file": "docs\\plans\\citation_system\\00_master_roadmap.md",
    "index": 2,
    "code": "# Mitigation: Adjust confidence thresholds\nCRITICAL_THRESHOLD = 0.9  # Increase from 0.8\nmanual_review_queue = [c for c in claims if c['confidence'] < CRITICAL_THRESHOLD]\n# Expected: Reduce false positives from 15% to <10%",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a23f5e4"
  },
  {
    "id": "00_master_roadmap_3_1936d7a8",
    "file": "docs\\plans\\citation_system\\00_master_roadmap.md",
    "index": 3,
    "code": "# Mitigation: Session state auto-save (already in CLAUDE.md)\nfrom .dev_tools.session_manager import update_session_context, finalize_session\n\n# Every major milestone\nupdate_session_context(\n    current_task=\"Phase 2: Researching claims 250-300\",\n    phase=\"ai_research\",\n    last_checkpoint=\"research_checkpoint_250.json\"\n)\n\n# When approaching limit\nfinalize_session(\"Phase 2: 300/500 claims researched\")\n# Next session: Auto-resume from checkpoint",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1936d7a8"
  },
  {
    "id": "01_initial_analysis_1_07a76395",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 1,
    "code": "\"\"\"\nAdding a small, positive constant to the diagonal of a symmetric matrix is a\nwell\u2011known regularisation technique: in the context of covariance matrices,\nLeung and colleagues recommend \"adding a small, positive constant to the\ndiagonal\" to ensure the matrix is invertible.\n\"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07a76395"
  },
  {
    "id": "01_initial_analysis_2_cc07c868",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 2,
    "code": "\"\"\"\nSuper-Twisting Sliding Mode Controller (STA-SMC).\n\nImplements the second-order sliding mode algorithm from Levant [1] with\nfinite-time convergence guarantees proven by Moreno and Osorio [2].\n\"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc07c868"
  },
  {
    "id": "01_initial_analysis_3_85be2093",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 3,
    "code": "\"\"\"\nThe boundary\u2011layer approximation attenuates chattering at the cost of\nintroducing a finite steady\u2011state tracking error; for example, a discussion\nof chattering reduction methods emphasises that the boundary\u2011layer method\n\"reduces chattering but leads to a finite steady state error\".\n\"\"\"",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85be2093"
  },
  {
    "id": "01_initial_analysis_4_73363f44",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef assign_priority(claim: Dict) -> str:\n    \"\"\"\n    CRITICAL: Uncited formal theorems/lemmas (scientific credibility risk)\n    HIGH: Uncited implementation claims (reproducibility risk)\n    MEDIUM: Already cited OR informal claims (lower impact)\n    \"\"\"\n\n    if (claim['category'] == 'theoretical' and\n        claim['type'] in ['theorem', 'lemma', 'proposition'] and\n        not claim['has_citation']):\n        return 'CRITICAL'  # ~29 claims\n\n    if (claim['category'] == 'implementation' and\n        claim['type'] == 'implementation' and\n        not claim['has_citation']):\n        return 'HIGH'  # ~136 claims\n\n    return 'MEDIUM'  # ~335 claims",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "73363f44"
  },
  {
    "id": "01_initial_analysis_5_52e4db01",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass AgentSelectionStrategy:\n    \"\"\"\n    Decision framework for optimal agent configuration.\n    \"\"\"\n\n    EXISTING_AGENTS = {\n        'integration_coordinator': {\n            'skills': ['cross-domain orchestration', 'system health',\n                      'config validation', 'debugging across components'],\n            'match_score': 0.25  # For citation system\n        },\n        'documentation_expert': {\n            'skills': ['LaTeX math', 'Sphinx docs', 'scientific writing',\n                      'citation systems', 'mathematical notation'],\n            'match_score': 0.35  # For citation system\n        },\n        'pso_optimization_engineer': {\n            'skills': ['PSO tuning', 'convergence analysis'],\n            'match_score': 0.10  # Low relevance\n        },\n        'control_systems_specialist': {\n            'skills': ['SMC design', 'stability analysis'],\n            'match_score': 0.15  # Domain knowledge only\n        }\n    }\n\n    def should_create_new(self, requirements: Set[str]) -> bool:\n        \"\"\"\n        Create new agent if:\n        1. Skill gap > 30% (best match < 0.7)\n        2. Workload > 40 hours AND parallelizable\n        3. CLAUDE.md mandates specialist\n        \"\"\"\n\n        best_match = max(agent['match_score']\n                        for agent in self.EXISTING_AGENTS.values())\n\n        skill_gap = 1.0 - best_match\n\n        # Citation system: best_match = 0.35 (Doc Expert)\n        # skill_gap = 0.65 (65% of requirements not covered)\n\n        if skill_gap > 0.30:\n            return True, \"SKILL_GAP\"\n\n        return False, \"REUSE_SUFFICIENT\"",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52e4db01"
  },
  {
    "id": "01_initial_analysis_6_fe3705f1",
    "file": "docs\\plans\\citation_system\\01_initial_analysis.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef integrate_artifacts(agent_outputs: List[Dict]) -> Dict:\n    \"\"\"\n    Merge outputs from multiple agents.\n\n    Conflict resolution priority:\n    1. Domain expert wins (NEW agent for research quality)\n    2. Higher confidence wins (confidence > 0.8 overrides < 0.8)\n    3. More specific wins (file-level > directory-level)\n    4. Manual review (flag for human if unresolvable)\n    \"\"\"\n\n    merged = {'changes': [], 'conflicts': []}\n\n    by_file = defaultdict(list)\n    for output in agent_outputs:\n        for change in output['changes']:\n            by_file[change['file']].append((output['metadata']['agent_name'], change))\n\n    for file_path, changes in by_file.items():\n        if len(changes) > 1:\n            # Conflict detected\n            winner = max(changes, key=lambda x: (\n                DOMAIN_PRIORITY.get(x[0], 0),  # NEW agent > DOC > INT\n                x[1].get('confidence', 0.0)\n            ))\n            merged['changes'].append(winner[1])\n            merged['conflicts'].append({\n                'file': file_path,\n                'resolution': f\"Used {winner[0]} (domain + confidence)\"\n            })\n        else:\n            merged['changes'].append(changes[0][1])\n\n    return merged",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe3705f1"
  },
  {
    "id": "02_phase1_claim_extraction_1_38b14156",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass MonolithicExtractor:  # \u274c Don't do this\n    def extract_all(self, files):\n        # 2000+ lines mixing docs + code + math\n        # Result: Unmaintainable, low precision",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "38b14156"
  },
  {
    "id": "02_phase1_claim_extraction_2_1c6be2f8",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass FormalClaimExtractor:    # \u2705 Specialized, 200 lines, 95% precision\nclass CodeClaimExtractor:      # \u2705 Specialized, 180 lines, 85% precision\nclass ClaimDatabaseMerger:     # \u2705 Integration, 100 lines, conflict resolution",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c6be2f8"
  },
  {
    "id": "02_phase1_claim_extraction_3_75bc9d24",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 3,
    "code": "import re\nfrom dataclasses import dataclass\nfrom typing import List, Optional\n\n@dataclass\nclass FormalClaim:\n    id: str\n    type: str  # \"theorem\", \"lemma\", \"proposition\", \"corollary\"\n    number: Optional[int]\n    statement: str\n    proof: Optional[str]\n    file_path: str\n    line_number: int\n    has_citation: bool\n    confidence: float\n\nclass FormalClaimExtractor:\n    PATTERNS = {\n        'theorem_numbered': re.compile(\n            r'\\*\\*(?P<type>Theorem|Lemma|Proposition|Corollary)\\s+(?P<number>\\d+)\\*\\*'\n            r'(?:\\s*\\((?P<title>[^)]+)\\))?'  # Optional title\n            r'(?:\\s*\\{cite\\}`(?P<cite>[^`]+)`)?'  # Existing citation\n            r'\\s*(?P<statement>.*?)'  # Statement text\n            r'(?=\\n\\n|\\*\\*Proof)',  # Stop at proof or blank line\n            re.DOTALL | re.MULTILINE\n        ),\n        'proof_block': re.compile(\n            r'\\*\\*Proof\\*\\*:?\\s*(?P<proof>.*?)(?P<qed>\u25a1|\u220e|QED)',\n            re.DOTALL\n        ),\n        'math_block': re.compile(r'",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75bc9d24"
  },
  {
    "id": "02_phase1_claim_extraction_4_5e242cae",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef _calculate_confidence(match, has_cite, has_proof, has_math):\n    \"\"\"\n    Calculate extraction confidence [0, 1].\n\n    Boosters (cumulative):\n    - Numbered (e.g., \"Theorem 1\"): +0.2\n    - Has citation {cite}: +0.2\n    - Has proof block: +0.1\n    - Has LaTeX math: +0.1\n\n    Expected distribution:\n    - High (0.8-1.0): 60% of formal claims\n    - Medium (0.5-0.8): 35%\n    - Low (0.0-0.5): 5% (manual review)\n    \"\"\"\n    score = 0.5\n    if match.group('number'): score += 0.2\n    if has_cite: score += 0.2\n    if has_proof: score += 0.1\n    if has_math: score += 0.1\n    return min(max(score, 0.0), 1.0)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e242cae"
  },
  {
    "id": "02_phase1_claim_extraction_5_58cb54ba",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass FormalClaim:\n    # Identity\n    id: str                    # \"FORMAL-THEOREM-001\"\n    type: str                  # \"theorem\", \"lemma\", \"proposition\"\n    number: Optional[int]      # Theorem number (if numbered)\n\n    # Content\n    statement: str             # Full theorem statement\n    proof: Optional[str]       # Associated proof (if found)\n    math_blocks: List[str]     # Extracted LaTeX math\n\n    # Location\n    file_path: str             # Relative path from project root\n    line_number: int           # Line where claim starts\n    section_header: str        # Containing section (e.g., \"Super-Twisting Algorithm\")\n\n    # Context (for AI research)\n    context_before: List[str]  # 5 lines before\n    context_after: List[str]   # 5 lines after\n\n    # Metadata\n    has_citation: bool         # Already has {cite}?\n    confidence: float          # Extraction confidence [0, 1]\n    suggested_keywords: List[str]  # For AI research queries",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "58cb54ba"
  },
  {
    "id": "02_phase1_claim_extraction_6_d563700d",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_extract_numbered_theorem():\n    text = \"\"\"\n    **Theorem 1** (Convergence)\n\n    The system converges in finite time.\n\n    **Proof**: Trivial. \u25a1\n    \"\"\"\n\n    claims = extractor.extract_from_text(text)\n\n    assert len(claims) == 1\n    assert claims[0].type == \"theorem\"\n    assert claims[0].number == 1\n    assert claims[0].proof is not None\n    assert claims[0].confidence >= 0.8\n\ndef test_citation_detection():\n    text = \"\"\"\n    **Theorem 2** {cite}`levant2003higher`\n\n    Super-twisting guarantees convergence.\n    \"\"\"\n\n    claims = extractor.extract_from_text(text)\n    assert claims[0].has_citation == True\n    assert claims[0].confidence >= 0.9",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d563700d"
  },
  {
    "id": "02_phase1_claim_extraction_7_81bf3854",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 7,
    "code": "import ast\n\nclass CodeClaimExtractor(ast.NodeVisitor):\n    def __init__(self, file_path: Path):\n        self.file_path = file_path\n        self.claims = []\n        self.current_scope = []  # Stack: [\"module\", \"class:ClassName\", \"function:method\"]\n\n    def visit_Module(self, node: ast.Module):\n        docstring = ast.get_docstring(node)\n        if docstring:\n            self._extract_from_docstring(docstring, \"module\", 1)\n        self.generic_visit(node)\n\n    def visit_ClassDef(self, node: ast.ClassDef):\n        self.current_scope.append(f\"class:{node.name}\")\n        docstring = ast.get_docstring(node)\n        if docstring:\n            scope = ':'.join(self.current_scope)\n            self._extract_from_docstring(docstring, scope, node.lineno)\n        self.generic_visit(node)\n        self.current_scope.pop()\n\n    def _extract_from_docstring(self, docstring: str, scope: str, line: int):\n        # Pattern matching for implementation claims\n        for match in self.PATTERNS['implements'].finditer(docstring):\n            claim = CodeClaim(\n                id=f\"CODE-IMPL-{len(self.claims)+1:03d}\",\n                algorithm_name=match.group('what').strip(),\n                source_attribution=match.group('source').strip(),\n                scope=scope,\n                file_path=str(self.file_path),\n                line_number=line,\n                has_citation=self._has_proper_citation(docstring),\n                confidence=0.8\n            )\n            self.claims.append(claim)",
    "lines": 37,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "81bf3854"
  },
  {
    "id": "02_phase1_claim_extraction_8_a1651c80",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nPATTERNS = {\n    'implements': re.compile(\n        r'(?:Implements?|Implementation of|Based on)\\s+'\n        r'(?P<what>[^,\\.]+?)\\s+'\n        r'(?:from|in|by)\\s+'\n        r'(?P<source>[^\\.\\n]+)',\n        re.IGNORECASE\n    ),\n    'numbered_cite': re.compile(r'\\[(\\d+)\\]'),\n    'doi': re.compile(r'(?:doi:|https://doi\\.org/)([^\\s]+)', re.IGNORECASE),\n    'author_year': re.compile(r'\\(([A-Z][a-z]+(?:\\s+et\\s+al\\.)?)\\s+(\\d{4})\\)')\n}",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a1651c80"
  },
  {
    "id": "02_phase1_claim_extraction_9_2e94f962",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass\nclass CodeClaim:\n    id: str\n    type: str  # \"implementation\", \"doi_reference\", \"algorithm_reference\"\n    scope: str  # \"module\" | \"class:ClassName\" | \"function:method_name\"\n    claim_text: str\n    algorithm_name: Optional[str]\n    source_attribution: Optional[str]\n    file_path: str\n    line_number: int\n    has_citation: bool\n    citation_format: Optional[str]  # \"numbered\", \"doi\", \"author_year\", \"none\"\n    confidence: float",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e94f962"
  },
  {
    "id": "02_phase1_claim_extraction_10_55dd791c",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 10,
    "code": "def merge_claims():\n    formal = json.load(open('artifacts/formal_claims.json'))\n    code = json.load(open('artifacts/code_claims.json'))\n\n    all_claims = formal['claims'] + code['claims']",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55dd791c"
  },
  {
    "id": "02_phase1_claim_extraction_11_268b1aa7",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef assign_priority(claim: Dict) -> str:\n    \"\"\"\n    CRITICAL: Uncited formal theorems/lemmas (scientific risk)\n    HIGH: Uncited implementation claims (reproducibility risk)\n    MEDIUM: Already cited OR informal claims\n    \"\"\"\n\n    if (claim.get('category') == 'theoretical' and\n        claim.get('type') in ['theorem', 'lemma', 'proposition'] and\n        not claim.get('has_citation')):\n        return 'CRITICAL'  # ~29 claims\n\n    if (claim.get('category') == 'implementation' and\n        not claim.get('has_citation')):\n        return 'HIGH'  # ~136 claims\n\n    return 'MEDIUM'  # ~335 claims",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "268b1aa7"
  },
  {
    "id": "02_phase1_claim_extraction_12_19bf2c42",
    "file": "docs\\plans\\citation_system\\02_phase1_claim_extraction.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef deduplicate_claims(claims: List[Dict]) -> List[Dict]:\n    \"\"\"\n    Remove near-duplicates using Jaccard similarity.\n\n    Strategy:\n    1. Generate signature from key terms\n    2. Compare pairwise (Jaccard similarity)\n    3. Merge if similarity > 0.8\n    4. Keep higher-confidence version\n    \"\"\"\n\n    deduplicated = []\n\n    for claim in claims:\n        signature = _generate_signature(claim)\n\n        # Check against existing\n        is_duplicate = False\n        for existing in deduplicated:\n            similarity = _calculate_similarity(claim, existing)\n\n            if similarity > 0.8:\n                is_duplicate = True\n                if claim['confidence'] > existing['confidence']:\n                    deduplicated.remove(existing)\n                    deduplicated.append(claim)\n                break\n\n        if not is_duplicate:\n            deduplicated.append(claim)\n\n    return deduplicated\n\ndef _generate_signature(claim: Dict) -> str:\n    \"\"\"Extract key technical terms (sorted for consistency).\"\"\"\n    text = claim.get('claim_text', claim.get('statement', ''))\n    terms = [w.lower() for w in text.split() if len(w) > 3]\n    return '|'.join(sorted(set(terms[:10])))\n\ndef _calculate_similarity(claim1: Dict, claim2: Dict) -> float:\n    \"\"\"Jaccard similarity of key terms.\"\"\"\n    sig1 = set(_generate_signature(claim1).split('|'))\n    sig2 = set(_generate_signature(claim2).split('|'))\n    intersection = sig1 & sig2\n    union = sig1 | sig2\n    return len(intersection) / len(union) if union else 0.0",
    "lines": 49,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19bf2c42"
  },
  {
    "id": "week_1_completion_report_1_8a1fddb4",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Syntax highlighting style\npygments_style = 'monokai'  # Dark theme for code\n\n# Literalinclude defaults\nhighlight_options = {\n    'linenos': True,          # Show line numbers\n    'linenostart': 1,         # Start from line 1\n}\n\n# Extensions\nextensions = [\n    'sphinx.ext.autodoc',\n    'sphinx_copybutton',      # Copy code button\n    'myst_parser',            # Markdown support\n    'sphinx_design',          # Design elements\n]",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a1fddb4"
  },
  {
    "id": "week_1_completion_report_2_5c8c590f",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 2,
    "code": "def extract_docstring(self, tree: ast.Module) -> Optional[str]:\n    \"\"\"Extract module docstring from AST.\"\"\"\n    docstring = ast.get_docstring(tree)\n    if docstring:\n        return self._clean_docstring(docstring)\n    return None",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c8c590f"
  },
  {
    "id": "week_1_completion_report_3_c2024301",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 3,
    "code": "def _get_relative_path(self, source_file: Path, doc_file: Path) -> str:\n    \"\"\"Calculate relative path from doc to source.\"\"\"\n    try:\n        relative = os.path.relpath(source_file, doc_file.parent)\n        return relative.replace('\\\\', '/')  # Normalize to forward slashes\n    except ValueError:\n        return str(source_file)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c2024301"
  },
  {
    "id": "week_1_completion_report_4_172bb85d",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 4,
    "code": "# Use safe ASCII preview to avoid UnicodeEncodeError on Windows\npreview = content[:500].encode('ascii', errors='replace').decode('ascii')\nprint(preview)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "172bb85d"
  },
  {
    "id": "week_1_completion_report_5_9a021e7c",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 5,
    "code": "@dataclass\nclass ValidationResult:\n    \"\"\"Result of a validation check.\"\"\"\n    passed: bool\n    message: str\n    details: List[str] = None",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9a021e7c"
  },
  {
    "id": "week_1_completion_report_6_82301690",
    "file": "docs\\plans\\documentation\\week_1_completion_report.md",
    "index": 6,
    "code": "preview = content[:500].encode('ascii', errors='replace').decode('ascii')",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82301690"
  },
  {
    "id": "week_1_foundation_automation_1_5fcca0b0",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 1,
    "code": "# Key features to implement:\n- Auto-scan src/ directory recursively (316 Python files)\n- Extract module/class/function structure using AST parsing\n- Generate markdown templates with literalinclude directives\n- Extract existing docstrings for initial content\n- Create hierarchical navigation (toctrees)\n- Generate module index pages (14 modules)\n- Validate file paths and cross-references",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fcca0b0"
  },
  {
    "id": "week_1_foundation_automation_2_672333a0",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nextensions = [\n    'sphinx.ext.autodoc',           # Existing\n    'sphinx.ext.napoleon',          # Existing\n    'sphinx.ext.viewcode',          # Existing\n    'sphinx.ext.literalinclude',    # NEW - Embed source code\n    'sphinx.ext.githubpages',       # Existing\n    'myst_parser',                  # Existing (Markdown support)\n    'sphinx_copybutton',            # NEW - Copy code button\n    'sphinx_togglebutton',          # NEW - Collapsible code blocks\n    'sphinx_design',                # NEW - Better UI components\n]",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "672333a0"
  },
  {
    "id": "week_1_foundation_automation_3_b75cb6a1",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# docs/conf.py additions\n\n# Pygments style for code highlighting\npygments_style = 'monokai'  # Options: monokai, github, default, etc.\npygments_dark_style = 'monokai'\n\n# Literalinclude options\nliteralinclude_default_options = {\n    'linenos': True,           # Always show line numbers\n    'emphasize-lines': '',     # Can be customized per file\n    'dedent': 0,               # Auto-dedent code blocks\n    'language': 'python',      # Default language\n    'encoding': 'utf-8',       # File encoding\n}",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b75cb6a1"
  },
  {
    "id": "week_1_foundation_automation_4_1ea81838",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 4,
    "code": "# Toggle button for collapsible code\ntogglebutton_hint = \"Click to show/hide code\"\ntogglebutton_hint_hide = \"Click to hide code\"",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1ea81838"
  },
  {
    "id": "week_1_foundation_automation_5_4fe71ab6",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 5,
    "code": "# Copy button for code blocks\ncopybutton_prompt_text = r\">>> |\\.\\.\\. |\\$ \"\ncopybutton_prompt_is_regexp = True",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fe71ab6"
  },
  {
    "id": "week_1_foundation_automation_6_f07a6672",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 6,
    "code": "# Enable linking to specific lines\nhtml_context = {\n    'github_user': 'theSadeQ',\n    'github_repo': 'dip-smc-pso',\n    'github_version': 'main',\n    'doc_path': 'docs',\n}",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f07a6672"
  },
  {
    "id": "week_1_foundation_automation_7_ae3f4cba",
    "file": "docs\\plans\\documentation\\week_1_foundation_automation.md",
    "index": 7,
    "code": "html_theme = 'furo'  # Or current theme\n\nhtml_theme_options = {\n    'light_code_highlight': 'monokai',\n    'dark_code_highlight': 'monokai',\n    'code_font_size': '0.9em',\n    'enable_code_folding': True,\n    'show_toc_level': 3,\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae3f4cba"
  },
  {
    "id": "week_1_quality_analysis_1_5c8c590f",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 1,
    "code": "def extract_docstring(self, tree: ast.Module) -> Optional[str]:\n    \"\"\"Extract module docstring from AST.\"\"\"\n    docstring = ast.get_docstring(tree)\n    if docstring:\n        return self._clean_docstring(docstring)\n    return None",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c8c590f"
  },
  {
    "id": "week_1_quality_analysis_2_ae0a985f",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 2,
    "code": "def _get_relative_path(self, source_file: Path, doc_file: Path) -> str:\n    \"\"\"Calculate relative path from doc to source.\"\"\"\n    try:\n        relative = os.path.relpath(source_file, doc_file.parent)\n        return relative.replace('\\\\', '/')  # Normalize\n    except ValueError:\n        return str(source_file)  # Fallback",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae0a985f"
  },
  {
    "id": "week_1_quality_analysis_3_172bb85d",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 3,
    "code": "# Use safe ASCII preview to avoid UnicodeEncodeError on Windows\npreview = content[:500].encode('ascii', errors='replace').decode('ascii')\nprint(preview)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "172bb85d"
  },
  {
    "id": "week_1_quality_analysis_4_61f79f3a",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Generator fallback\ntry:\n    relative = os.path.relpath(source_file, doc_file.parent)\nexcept ValueError:\n    return str(source_file)\n\n# Validation detailed reporting\n@dataclass\nclass ValidationResult:\n    passed: bool\n    message: str\n    details: List[str] = None",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61f79f3a"
  },
  {
    "id": "week_1_quality_analysis_5_0106e176",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass DocumentationGenerator:\n    # Core functionality\n    def generate_all()         # Main entry point\n    def _scan_files()         # File discovery\n    def _parse_file()         # AST parsing\n    def _format_content()     # Formatting\n    def _write_file()         # Output",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0106e176"
  },
  {
    "id": "week_1_quality_analysis_6_e50415a3",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 6,
    "code": "def extract_docstring(self, tree: ast.Module) -> Optional[str]:\n    \"\"\"Extract module docstring from AST.\n\n    Args:\n        tree: Parsed AST tree\n\n    Returns:\n        Cleaned docstring or None if not found\n    \"\"\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e50415a3"
  },
  {
    "id": "week_1_quality_analysis_7_0c45879c",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef _parse_file(self, filepath: Path) -> Dict[str, Any]:\n    \"\"\"Parse Python file and extract information.\"\"\"\n    ...\n\ndef validate_literalinclude_paths(self) -> ValidationResult:\n    \"\"\"Validate all literalinclude directive paths.\"\"\"\n    ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c45879c"
  },
  {
    "id": "week_1_quality_analysis_8_b292fd83",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\nclass DocumentationValidator:\n    def validate_literalinclude_paths(self) -> ValidationResult:\n        ...\n\n    def validate_coverage(self) -> ValidationResult:\n        ...\n\n    def validate_toctree(self) -> ValidationResult:\n        ...\n\n    def validate_syntax(self) -> ValidationResult:\n        ...",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b292fd83"
  },
  {
    "id": "week_1_quality_analysis_9_2b836db6",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 9,
    "code": "def validate_latex_syntax(self) -> ValidationResult:\n    \"\"\"Validate LaTeX mathematical notation.\"\"\"\n    # Implementation here\n    return ValidationResult(passed=True, message=\"LaTeX syntax valid\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b836db6"
  },
  {
    "id": "week_1_quality_analysis_10_68a44b7c",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 10,
    "code": "# Validates source files exist\nif not source_file.exists():\n    continue\n\n# Validates relative paths\ntry:\n    relative = os.path.relpath(source_file, doc_file.parent)\nexcept ValueError:\n    return str(source_file)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68a44b7c"
  },
  {
    "id": "week_1_quality_analysis_11_94fe7b16",
    "file": "docs\\plans\\documentation\\week_1_quality_analysis.md",
    "index": 11,
    "code": "# Validates paths resolve correctly\nif not source_file.exists():\n    invalid_paths.append((doc_file, directive, source_file))",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94fe7b16"
  },
  {
    "id": "week_2_completion_summary_1_c6afe63a",
    "file": "docs\\plans\\documentation\\week_2_completion_summary.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\n\ncontroller = create_controller(\n    'classical_smc',\n    gains=[20.0, 15.0, 12.0, 8.0, 35.0, 5.0],\n    config=config\n)\n\nresult = controller.compute_control(state, (), {})\nu = result.u  # Saturated control input",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6afe63a"
  },
  {
    "id": "week_2_completion_summary_2_07fbacb5",
    "file": "docs\\plans\\documentation\\week_2_completion_summary.md",
    "index": 2,
    "code": "if abs(sigma) <= self.dead_zone:\n    dK = 0.0  # Freeze inside dead zone\nelse:\n    dK = self.gamma * abs(sigma) - self.leak_rate * (K_prev - self.K_init)\n\nK_new = K_prev + dK * self.dt\nK_new = np.clip(K_new, self.K_min, self.K_max)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07fbacb5"
  },
  {
    "id": "week_2_completion_summary_3_abeb9d23",
    "file": "docs\\plans\\documentation\\week_2_completion_summary.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Enterprise Factory\ncontroller = create_controller('classical_smc', config, gains=[...])\n\n# Clean SMC Factory\ncontroller = SMCFactory.create_from_gains(\n    SMCType.CLASSICAL,\n    gains=[...],\n    max_force=100.0\n)\n\n# PSO Integration\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, gains_array)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "abeb9d23"
  },
  {
    "id": "week_2_completion_summary_4_80a5c3ea",
    "file": "docs\\plans\\documentation\\week_2_completion_summary.md",
    "index": 4,
    "code": "# Saturation with configurable slope\nu_switch = -K * saturate(sigma, epsilon=0.01, method='tanh', slope=3.0)\n\n# Dead zone for adaptation freeze\nif abs(sigma) <= dead_zone:\n    dK = 0.0\n\n# Safe operations\nu_gain = safe_divide(error, velocity, epsilon=1e-12)\nu_sta = -K1 * safe_sqrt(abs(sigma)) * smooth_sign(sigma)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80a5c3ea"
  },
  {
    "id": "week_2_controllers_module_1_1851d36d",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 1,
    "code": "from controllers import SMCType\n\nSMCType.CLASSICAL\nSMCType.ADAPTIVE\nSMCType.SUPER_TWISTING\nSMCType.HYBRID",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1851d36d"
  },
  {
    "id": "week_2_controllers_module_2_dfe8d907",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 2,
    "code": "from controllers import create_smc_for_pso, get_gain_bounds_for_pso\n\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, gains)\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dfe8d907"
  },
  {
    "id": "week_2_controllers_module_3_52309bae",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 3,
    "code": "sat(s/\u03b5) = tanh(s/\u03b5)",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "52309bae"
  },
  {
    "id": "week_2_controllers_module_4_a63c7c89",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 4,
    "code": "sat(s/\u03b5) = { s/\u03b5 if |s| \u2264 \u03b5, sign(s) otherwise }",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a63c7c89"
  },
  {
    "id": "week_2_controllers_module_5_fd4bb5ed",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 5,
    "code": "M_reg = M + \u03b1\u00b7I",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fd4bb5ed"
  },
  {
    "id": "week_2_controllers_module_6_cd03de40",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 6,
    "code": "from src.controllers.smc import ClassicalSMC\n\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cd03de40"
  },
  {
    "id": "week_2_controllers_module_7_1e7710ec",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 7,
    "code": "from controllers import create_smc_for_pso, SMCType\n\ncontroller = create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e7710ec"
  },
  {
    "id": "week_2_controllers_module_8_222cfa4d",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 8,
    "code": "def fitness_function(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    performance = evaluate(controller)\n    return performance",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "222cfa4d"
  },
  {
    "id": "week_2_controllers_module_9_b444b379",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 9,
    "code": "from src.core.vector_sim import run_batch_simulation\n\nresults = run_batch_simulation(\n    controller, dynamics, initial_conditions, sim_params\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b444b379"
  },
  {
    "id": "week_2_controllers_module_10_9f09c448",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 10,
    "code": "test_scenarios = [\n    {\"name\": \"nominal\", \"x0\": nominal_state},\n    {\"name\": \"disturbed\", \"x0\": disturbed_state},\n    {\"name\": \"uncertain\", \"params\": varied_params}\n]",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9f09c448"
  },
  {
    "id": "week_2_controllers_module_11_6896a75e",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 11,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials\n\nmetrics_list, ci_results = run_trials(\n    controller_factory, config, n_trials=30\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6896a75e"
  },
  {
    "id": "week_2_controllers_module_12_5594cccf",
    "file": "docs\\plans\\documentation\\week_2_controllers_module.md",
    "index": 12,
    "code": "python scripts/docs/validate_code_docs.py --check-paths",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5594cccf"
  },
  {
    "id": "week_3_optimization_simulation_1_e62b0b6f",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 1,
    "code": "J(g) = w\u2081\u00b7ISE(g) + w\u2082\u00b7chattering(g) + w\u2083\u00b7control_effort(g)\n\nwhere:\n  ISE(g) = \u222b\u2080\u1d40 ||x(t;g)||\u00b2 dt\n  chattering(g) = \u222b\u2080\u1d40 |u\u0307(t;g)| dt\n  control_effort(g) = \u222b\u2080\u1d40 u\u00b2(t;g) dt",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e62b0b6f"
  },
  {
    "id": "week_3_optimization_simulation_2_f811156f",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Richardson extrapolation\ndef estimate_convergence_order(method, x0, t_span, dt_values):\n    errors = []\n    for dt in dt_values:\n        x_h = method.integrate(x0, t_span, dt)\n        x_ref = method.integrate(x0, t_span, dt/10)  # Fine reference\n        errors.append(norm(x_h[-1] - x_ref[-1]))\n\n    # Fit log(error) vs log(dt)\n    order = polyfit(log(dt_values), log(errors), 1)[0]\n    return order",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f811156f"
  },
  {
    "id": "week_3_optimization_simulation_3_9ca0abf3",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 3,
    "code": "BaseOptimizer (ABC)\n  \u251c\u2500\u2500 SwarmOptimizer (ABC)\n  \u2502   \u251c\u2500\u2500 PSOCore\n  \u2502   \u251c\u2500\u2500 AdaptivePSO\n  \u2502   \u2514\u2500\u2500 MultiObjectivePSO\n  \u251c\u2500\u2500 EvolutionaryOptimizer (ABC)\n  \u2502   \u251c\u2500\u2500 GeneticAlgorithm\n  \u2502   \u2514\u2500\u2500 DifferentialEvolution\n  \u2514\u2500\u2500 BayesianOptimizer",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ca0abf3"
  },
  {
    "id": "week_3_optimization_simulation_4_c800f21b",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 4,
    "code": "# Inertia term\nvelocity = self.inertia * velocity\n\n# Cognitive component (personal best attraction)\ncognitive = self.c1 * rand(0,1) * (pbest - position)\nvelocity += cognitive\n\n# Social component (global best attraction)\nsocial = self.c2 * rand(0,1) * (gbest - position)\nvelocity += social",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c800f21b"
  },
  {
    "id": "week_3_optimization_simulation_5_566612f4",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef evaluate_fitness(self, gains):\n    # Create controller from gains\n    controller = self.factory.create(gains)\n\n    # Run simulation\n    result = self.simulator.run(controller)\n\n    # Compute multi-objective fitness\n    fitness = (\n        self.w1 * result.ise +\n        self.w2 * result.chattering_index +\n        self.w3 * result.control_effort\n    )\n\n    return fitness",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "566612f4"
  },
  {
    "id": "week_3_optimization_simulation_6_cba35344",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 6,
    "code": "from src.optimization.algorithms.swarm import PSOCore\nfrom src.controllers.factory import SMCFactory\n\n# Define bounds\nbounds = [\n    (0.1, 50.0),  # k1\n    (0.1, 50.0),  # k2\n    (0.1, 50.0),  # \u03bb1\n    (0.1, 50.0),  # \u03bb2\n    (1.0, 200.0), # K\n    (0.0, 50.0),  # kd\n]\n\n# Create optimizer\noptimizer = PSOCore(\n    factory=SMCFactory,\n    bounds=bounds,\n    n_particles=30,\n    max_iters=100\n)\n\n# Run optimization\nresult = optimizer.optimize()\n\nprint(f\"Best gains: {result.best_position}\")\nprint(f\"Best fitness: {result.best_fitness}\")\nprint(f\"Convergence iteration: {result.convergence_iter}\")",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cba35344"
  },
  {
    "id": "week_3_optimization_simulation_7_740d093e",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 7,
    "code": "def compute_ise(states):\n    \"\"\"Integral of Squared Error.\"\"\"\n    return np.trapz(states**2, dx=dt)\n\ndef compute_itae(time, states):\n    \"\"\"Integral of Time-weighted Absolute Error.\"\"\"\n    return np.trapz(time * np.abs(states), dx=dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "740d093e"
  },
  {
    "id": "week_3_optimization_simulation_8_d94635ac",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 8,
    "code": "def compute_chattering_index(control_signal, dt):\n    \"\"\"Total variation of control signal.\"\"\"\n    control_derivative = np.diff(control_signal) / dt\n    return np.sum(np.abs(control_derivative)) * dt",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d94635ac"
  },
  {
    "id": "week_3_optimization_simulation_9_44ebd9a4",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 9,
    "code": "def compute_control_effort(control_signal, dt):\n    \"\"\"L2 norm of control signal.\"\"\"\n    return np.trapz(control_signal**2, dx=dt)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "44ebd9a4"
  },
  {
    "id": "week_3_optimization_simulation_10_aeeba4cd",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nclass MultiObjectiveFitness:\n    def __init__(self, weights):\n        self.w_ise = weights['ise']\n        self.w_chattering = weights['chattering']\n        self.w_effort = weights['effort']\n        self.w_violations = weights['violations']\n\n    def evaluate(self, simulation_result):\n        J = (\n            self.w_ise * simulation_result.ise +\n            self.w_chattering * simulation_result.chattering_index +\n            self.w_effort * simulation_result.control_effort +\n            self.w_violations * simulation_result.constraint_violations\n        )\n        return J",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aeeba4cd"
  },
  {
    "id": "week_3_optimization_simulation_11_159a17f6",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 11,
    "code": "def pareto_front(objectives):\n    \"\"\"Compute non-dominated solutions.\"\"\"\n    is_pareto = np.ones(len(objectives), dtype=bool)\n    for i, obj_i in enumerate(objectives):\n        for j, obj_j in enumerate(objectives):\n            if i != j and dominates(obj_j, obj_i):\n                is_pareto[i] = False\n                break\n    return objectives[is_pareto]",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "159a17f6"
  },
  {
    "id": "week_3_optimization_simulation_12_a0a2c1de",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef penalized_fitness(gains, base_fitness):\n    \"\"\"Add penalty for constraint violations.\"\"\"\n    penalty = 0.0\n\n    # Stability constraint: positive gains\n    if any(g <= 0 for g in gains[:5]):\n        penalty += 1e6\n\n    # Switching gain constraint: K > disturbance\n    if gains[4] < 10.0:  # Minimum K\n        penalty += 1e4 * (10.0 - gains[4])\n\n    return base_fitness + penalty",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a0a2c1de"
  },
  {
    "id": "week_3_optimization_simulation_13_c5d47b40",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef plot_fitness_landscape(optimizer, fixed_gains, vary_indices):\n    \"\"\"Visualize fitness function in 2D slice.\"\"\"\n    k1_range = np.linspace(0.1, 50, 50)\n    k2_range = np.linspace(0.1, 50, 50)\n\n    fitness_grid = np.zeros((len(k1_range), len(k2_range)))\n\n    for i, k1 in enumerate(k1_range):\n        for j, k2 in enumerate(k2_range):\n            gains = fixed_gains.copy()\n            gains[vary_indices[0]] = k1\n            gains[vary_indices[1]] = k2\n            fitness_grid[i, j] = optimizer.evaluate_fitness(gains)\n\n    plt.contourf(k1_range, k2_range, fitness_grid)\n    plt.xlabel(f'Gain {vary_indices[0]}')\n    plt.ylabel(f'Gain {vary_indices[1]}')\n    plt.colorbar(label='Fitness')",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5d47b40"
  },
  {
    "id": "week_3_optimization_simulation_14_82facea2",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Define optimization problem\nproblem = OptimizationProblem(\n    controller_type='classical_smc',\n    bounds=[(0.1, 50)] * 6,\n    objectives=['ise', 'chattering', 'effort'],\n    weights=[0.5, 0.3, 0.2]\n)\n\n# 2. Create optimizer\noptimizer = PSOCore(\n    problem=problem,\n    n_particles=30,\n    max_iters=100\n)\n\n# 3. Run optimization\nresult = optimizer.optimize()\n\n# 4. Validate with full dynamics\nfinal_controller = create_controller(\n    'classical_smc',\n    gains=result.best_position,\n    dynamics_model='full'\n)\n\nvalidation_result = simulate(final_controller, duration=10.0)\n\n# 5. Save optimized gains\nsave_gains(result.best_position, 'optimized_classical_smc.json')",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82facea2"
  },
  {
    "id": "week_3_optimization_simulation_15_28e20430",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\ndef run(self, controller, dynamics, duration, dt):\n    # Initialize state\n    x = self.initial_state\n    t = 0.0\n    history = {'t': [], 'x': [], 'u': []}\n\n    while t < duration:\n        # Compute control\n        u = controller.compute_control(x, history)\n\n        # Integrate dynamics\n        x_next = self.integrator.step(x, u, dynamics, dt)\n\n        # Safety checks\n        if self.check_divergence(x_next):\n            raise SimulationDivergenceError()\n\n        # Record history\n        history['t'].append(t)\n        history['x'].append(x)\n        history['u'].append(u)\n\n        # Update state\n        x = x_next\n        t += dt\n\n    return SimulationResult(history)",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "28e20430"
  },
  {
    "id": "week_3_optimization_simulation_16_c3bc1c96",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 16,
    "code": "# example-metadata:\n# runnable: false\n\nclass SimulationContext:\n    \"\"\"Centralized simulation state and configuration.\"\"\"\n\n    state: np.ndarray           # Current state [6,]\n    time: float                 # Current time\n    controller_vars: Dict       # Controller internal state\n    dynamics_params: Dict       # Physics parameters\n    history: StateHistory       # Trajectory recording\n\n    def update(self, x_next, u, dt):\n        \"\"\"Thread-safe state update.\"\"\"\n        with self._lock:\n            self.state = x_next\n            self.time += dt\n            self.history.append(self.state, u)",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3bc1c96"
  },
  {
    "id": "week_3_optimization_simulation_17_b9e55e5a",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Configure simulation\nconfig = SimulationConfig(\n    duration=5.0,\n    dt=0.01,\n    integrator='rk4',\n    initial_state=np.array([0.1, 0.05, 0.0, 0.0, 0.0, 0.0])\n)\n\n# 2. Create components\ndynamics = FullNonlinearDynamics(physics_params)\ncontroller = create_controller('classical_smc', gains=[...])\n\n# 3. Run simulation\nrunner = SimulationRunner(config)\nresult = runner.run(controller, dynamics)\n\n# 4. Analyze results\nprint(f\"ISE: {result.ise}\")\nprint(f\"Settling time: {result.settling_time}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9e55e5a"
  },
  {
    "id": "week_3_optimization_simulation_18_4e613079",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 18,
    "code": "def compute_derivative(self, x, u):\n    \"\"\"Simplified linearized dynamics.\"\"\"\n    \u03b81, \u03b82, x_pos, \u03c91, \u03c92, v = x\n\n    # Linearized equations (small angle approximation)\n    \u03c91_dot = (g/L1) * \u03b81 + (u/I1) * x_pos\n    \u03c92_dot = (g/L2) * \u03b82 + coupling_term\n    v_dot = u / m_total\n\n    return np.array([\u03c91, \u03c92, v, \u03c91_dot, \u03c92_dot, v_dot])",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4e613079"
  },
  {
    "id": "week_3_optimization_simulation_19_734137ce",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 19,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_mass_matrix(self, q):\n    \"\"\"\n    M(q) \u2208 \u211d\u00b3\u02e3\u00b3 - Configuration-dependent mass matrix\n\n    Derivation from kinetic energy:\n    T = \u00bdq\u0307\u1d40M(q)q\u0307\n    \"\"\"\n    \u03b81, \u03b82, x = q\n\n    m1, m2, L1, L2 = self.params\n\n    # Diagonal terms\n    M11 = self.I1 + m1*L1**2 + m2*(L1**2 + L2**2 + 2*L1*L2*np.cos(\u03b82))\n    M22 = self.I2 + m2*L2**2\n    M33 = self.m_total\n\n    # Off-diagonal coupling terms\n    M12 = m2*(L2**2 + L1*L2*np.cos(\u03b82))\n    M13 = (m1 + m2)*L1*np.cos(\u03b81) + m2*L2*np.cos(\u03b82)\n    M23 = m2*L2*np.cos(\u03b82)\n\n    M = np.array([\n        [M11, M12, M13],\n        [M12, M22, M23],\n        [M13, M23, M33]\n    ])\n\n    return M",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "734137ce"
  },
  {
    "id": "week_3_optimization_simulation_20_27190a22",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 20,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_coriolis(self, q, qdot):\n    \"\"\"\n    C(q,q\u0307)q\u0307 - Velocity-dependent forces\n\n    Christoffel symbols of second kind:\n    C\u1d62\u2c7c\u2096 = \u00bd(\u2202M\u1d62\u2c7c/\u2202q\u2096 + \u2202M\u1d62\u2096/\u2202q\u2c7c - \u2202M\u2c7c\u2096/\u2202q\u1d62)\n    \"\"\"\n    \u03b81, \u03b82, x = q\n    \u03c91, \u03c92, v = qdot\n\n    # Centrifugal force from \u03b82 rotation\n    C12 = -m2*L1*L2*np.sin(\u03b82)*\u03c92\n    C21 = m2*L1*L2*np.sin(\u03b82)*\u03c91\n\n    # Coupling terms\n    C13 = -(m1 + m2)*L1*np.sin(\u03b81)*\u03c91 - m2*L2*np.sin(\u03b82)*\u03c92\n\n    C = np.array([\n        [0, C12, C13],\n        [C21, 0, 0],\n        [0, 0, 0]\n    ])\n\n    return C @ qdot",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "27190a22"
  },
  {
    "id": "week_3_optimization_simulation_21_a8bf3c95",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 21,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_gravity(self, q):\n    \"\"\"\n    G(q) - Potential energy gradient\n\n    V = -m\u2081gL\u2081cos\u03b8\u2081 - m\u2082g(L\u2081cos\u03b8\u2081 + L\u2082cos\u03b8\u2082)\n    G\u1d62 = \u2202V/\u2202q\u1d62\n    \"\"\"\n    \u03b81, \u03b82, x = q\n\n    G1 = -(m1 + m2)*g*L1*np.sin(\u03b81) - m2*g*L2*np.sin(\u03b82)\n    G2 = -m2*g*L2*np.sin(\u03b82)\n    G3 = 0.0\n\n    return np.array([G1, G2, G3])",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8bf3c95"
  },
  {
    "id": "week_3_optimization_simulation_22_df8f58ac",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 22,
    "code": "Method    | dt=0.01 | dt=0.005 | dt=0.001 | Order\n----------|---------|----------|----------|-------\nEuler     | 1e-3    | 5e-4     | 1e-4     | 1.0\nRK4       | 1e-7    | 6e-9     | 1e-11    | 4.0\nRK45      | 1e-9    | 1e-11    | 1e-13    | 5.0",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "df8f58ac"
  },
  {
    "id": "week_3_optimization_simulation_23_12847172",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 23,
    "code": "Method    | Function Evals | Relative Cost\n----------|----------------|---------------\nEuler     | 1 per step     | 1x\nRK4       | 4 per step     | 4x\nRK45      | 6 per step (avg)| 6x (adaptive)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "12847172"
  },
  {
    "id": "week_3_optimization_simulation_24_2c0e799f",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 24,
    "code": "# example-metadata:\n# runnable: false\n\n@numba.jit(nopython=True, parallel=True)\ndef batch_integrate(x0_batch, gains_batch, duration, dt):\n    \"\"\"\n    Vectorized simulation for PSO fitness evaluation.\n\n    Args:\n        x0_batch: Initial states (B, 6)\n        gains_batch: Controller gains (B, N_gains)\n        duration: Simulation time\n        dt: Timestep\n\n    Returns:\n        metrics_batch: Performance metrics (B, N_metrics)\n    \"\"\"\n    B = x0_batch.shape[0]\n    N = int(duration / dt)\n    metrics = np.zeros((B, 3))  # ISE, chattering, effort\n\n    for b in numba.prange(B):  # Parallel loop\n        x = x0_batch[b]\n        ise = 0.0\n        chattering = 0.0\n        effort = 0.0\n\n        for i in range(N):\n            u = compute_control_vectorized(x, gains_batch[b])\n            x_next = rk4_step_vectorized(x, u, dt)\n\n            ise += np.sum(x**2) * dt\n            if i > 0:\n                chattering += np.abs(u - u_prev)\n            effort += u**2 * dt\n\n            x = x_next\n            u_prev = u\n\n        metrics[b] = [ise, chattering, effort]\n\n    return metrics",
    "lines": 42,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c0e799f"
  },
  {
    "id": "week_3_optimization_simulation_25_b4f8b318",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 25,
    "code": "from src.core.vector_sim import batch_simulate\n\n# Generate initial conditions\nx0_batch = np.random.randn(30, 6) * 0.1\n\n# Swarm positions (gains)\ngains_batch = swarm.positions  # (30, 6)\n\n# Batch fitness evaluation\nmetrics_batch = batch_simulate(x0_batch, gains_batch, 5.0, 0.01)\n\n# Extract fitness values\nfitness = np.sum(metrics_batch * weights, axis=1)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4f8b318"
  },
  {
    "id": "week_3_optimization_simulation_26_bfea7133",
    "file": "docs\\plans\\documentation\\week_3_optimization_simulation.md",
    "index": 26,
    "code": "# example-metadata:\n# runnable: false\n\n# Complete runnable script\nfrom src.optimization import PSOCore\nfrom src.controllers.factory import create_controller\n\n# ... (full implementation)\n\nif __name__ == '__main__':\n    main()",
    "lines": 11,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfea7133"
  },
  {
    "id": "ci_agent_framework_1_fabdb25b",
    "file": "docs\\plans\\orchestration\\ci_agent_framework.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass AgentSelectionStrategy:\n    \"\"\"\n    Decision framework for optimal agent configuration.\n    \"\"\"\n\n    def should_reuse(self, issue_requirements: Set[str]) -> Dict[str, float]:\n        \"\"\"\n        Calculate skill match scores for existing agents.\n\n        Returns: {agent_name: match_score (0.0-1.0)}\n        \"\"\"\n        scores = {}\n\n        for agent_name, agent_spec in self.EXISTING_AGENTS.items():\n            agent_skills = set(agent_spec['skills'])\n\n            # Jaccard similarity\n            intersection = issue_requirements & agent_skills\n            union = issue_requirements | agent_skills\n\n            scores[agent_name] = len(intersection) / len(union) if union else 0.0\n\n        return scores\n\n    def should_create_new(self, best_match_score: float,\n                         workload_estimate: int) -> Dict[str, Any]:\n        \"\"\"\n        Create new agent if:\n        1. Skill gap > 30% (best_match < 0.7)\n        2. Throughput gap: workload > 4 hours AND parallelizable\n        3. Policy gap: CLAUDE.md mandates specialist\n        \"\"\"\n\n        if best_match_score < 0.7:\n            return {\n                'create': True,\n                'reason': 'SKILL_GAP',\n                'blocking': True,\n                'justification': f'No existing agent covers >70% of required skills'\n            }\n\n        if workload_estimate > 240:  # 4 hours\n            return {\n                'create': True,\n                'reason': 'THROUGHPUT_GAP',\n                'blocking': False,  # Can proceed slower\n                'justification': f'{workload_estimate}min workload benefits from parallelization'\n            }\n\n        return {'create': False}",
    "lines": 53,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fabdb25b"
  },
  {
    "id": "ci_agent_framework_2_b4e81766",
    "file": "docs\\plans\\orchestration\\ci_agent_framework.md",
    "index": 2,
    "code": "issue_requirements = {\n    'citation_extraction',      # NEW SKILL (0% match)\n    'academic_search',          # NEW SKILL (0% match)\n    'BibTeX_management',       # NEW SKILL (0% match)\n    'scientific_writing',      # Documentation Expert (100% match)\n    'API_integration',         # NEW SKILL (0% match)\n    'cross_reference_validation' # Integration Coordinator (80% match)\n}",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4e81766"
  },
  {
    "id": "ci_agent_framework_3_13802a88",
    "file": "docs\\plans\\orchestration\\ci_agent_framework.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef integrate_artifacts(agent_outputs: List[Dict]) -> Dict:\n    \"\"\"\n    Reconcile multiple agent outputs.\n\n    Conflict resolution order:\n    1. Domain expert wins (Control Specialist > Integration Coordinator for SMC)\n    2. Higher confidence wins (confidence > 0.8 overrides < 0.8)\n    3. More specific wins (file-level > directory-level)\n    4. Manual review required (flag for human)\n    \"\"\"\n\n    DOMAIN_PRIORITY = {\n        'Academic Research Automation Engineer': 90,\n        'Control Systems Specialist': 80,\n        'PSO Optimization Engineer': 70,\n        'Documentation Expert': 60,\n        'Integration Coordinator': 50\n    }\n\n    merged = {\n        'changes': [],\n        'conflicts': []\n    }\n\n    # Group changes by file\n    by_file = defaultdict(list)\n    for output in agent_outputs:\n        for change in output['changes']:\n            by_file[change['file']].append((output['metadata']['agent_name'], change))\n\n    # Detect and resolve conflicts\n    for file_path, changes in by_file.items():\n        if len(changes) > 1:\n            # Multiple agents modified same file - resolve conflict\n            winner = max(changes, key=lambda x: (\n                DOMAIN_PRIORITY.get(x[0], 0),  # Domain expert priority\n                x[1].get('confidence', 0.0)     # Confidence tiebreaker\n            ))\n\n            merged['changes'].append(winner[1])\n            merged['conflicts'].append({\n                'file': file_path,\n                'agents': [c[0] for c in changes],\n                'resolution': f\"Used {winner[0]} (domain priority + confidence)\"\n            })\n        else:\n            merged['changes'].append(changes[0][1])\n\n    return merged",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "13802a88"
  },
  {
    "id": "core_data_structures_1_a394b47b",
    "file": "docs\\reference\\analysis\\core_data_structures.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "core_data_structures_2_2923c213",
    "file": "docs\\reference\\analysis\\core_data_structures.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "core_data_structures_3_3e7c9992",
    "file": "docs\\reference\\analysis\\core_data_structures.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "core_data_structures_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\core_data_structures.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "core_data_structures_5_a29f2215",
    "file": "docs\\reference\\analysis\\core_data_structures.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "core_interfaces_1_8e5a1de2",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass Analyzer(Protocol):\n    def analyze(self, data: Data) -> Result:\n        ...",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e5a1de2"
  },
  {
    "id": "core_interfaces_2_a394b47b",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 2,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "core_interfaces_3_2923c213",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 3,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "core_interfaces_4_3e7c9992",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 4,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "core_interfaces_5_f0d4b49d",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 5,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "core_interfaces_6_a29f2215",
    "file": "docs\\reference\\analysis\\core_interfaces.md",
    "index": 6,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "core_metrics_1_a394b47b",
    "file": "docs\\reference\\analysis\\core_metrics.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "core_metrics_2_2923c213",
    "file": "docs\\reference\\analysis\\core_metrics.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "core_metrics_3_3e7c9992",
    "file": "docs\\reference\\analysis\\core_metrics.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "core_metrics_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\core_metrics.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "core_metrics_5_a29f2215",
    "file": "docs\\reference\\analysis\\core_metrics.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "fault_detection_fdi_1_377f2b06",
    "file": "docs\\reference\\analysis\\fault_detection_fdi.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "fault_detection_fdi_2_02ccf172",
    "file": "docs\\reference\\analysis\\fault_detection_fdi.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "fault_detection_fdi_3_058eb1d2",
    "file": "docs\\reference\\analysis\\fault_detection_fdi.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "fault_detection_fdi_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\fault_detection_fdi.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "fault_detection_fdi_5_b1085bc9",
    "file": "docs\\reference\\analysis\\fault_detection_fdi.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "fault_detection_fdi_system_1_377f2b06",
    "file": "docs\\reference\\analysis\\fault_detection_fdi_system.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "fault_detection_fdi_system_2_02ccf172",
    "file": "docs\\reference\\analysis\\fault_detection_fdi_system.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "fault_detection_fdi_system_3_058eb1d2",
    "file": "docs\\reference\\analysis\\fault_detection_fdi_system.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "fault_detection_fdi_system_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\fault_detection_fdi_system.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "fault_detection_fdi_system_5_b1085bc9",
    "file": "docs\\reference\\analysis\\fault_detection_fdi_system.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "fault_detection_residual_generators_1_377f2b06",
    "file": "docs\\reference\\analysis\\fault_detection_residual_generators.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "fault_detection_residual_generators_2_02ccf172",
    "file": "docs\\reference\\analysis\\fault_detection_residual_generators.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "fault_detection_residual_generators_3_058eb1d2",
    "file": "docs\\reference\\analysis\\fault_detection_residual_generators.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "fault_detection_residual_generators_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\fault_detection_residual_generators.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "fault_detection_residual_generators_5_b1085bc9",
    "file": "docs\\reference\\analysis\\fault_detection_residual_generators.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "fault_detection_threshold_adapters_1_377f2b06",
    "file": "docs\\reference\\analysis\\fault_detection_threshold_adapters.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "fault_detection_threshold_adapters_2_02ccf172",
    "file": "docs\\reference\\analysis\\fault_detection_threshold_adapters.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "fault_detection_threshold_adapters_3_058eb1d2",
    "file": "docs\\reference\\analysis\\fault_detection_threshold_adapters.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "fault_detection_threshold_adapters_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\fault_detection_threshold_adapters.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "fault_detection_threshold_adapters_5_b1085bc9",
    "file": "docs\\reference\\analysis\\fault_detection_threshold_adapters.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "fault_detection___init___1_48be409f",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass FDISystem:\n    def generate_residual(y, u) -> r\n    def adapt_threshold(r) -> tau\n    def detect_fault(r, tau) -> bool\n    def isolate_fault(r, signatures) -> fault_id",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48be409f"
  },
  {
    "id": "fault_detection___init___2_377f2b06",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 2,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "fault_detection___init___3_02ccf172",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 3,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "fault_detection___init___4_058eb1d2",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 4,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "fault_detection___init___5_e39c1ae8",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 5,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "fault_detection___init___6_b1085bc9",
    "file": "docs\\reference\\analysis\\fault_detection___init__.md",
    "index": 6,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "performance_control_analysis_1_a394b47b",
    "file": "docs\\reference\\analysis\\performance_control_analysis.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "performance_control_analysis_2_2923c213",
    "file": "docs\\reference\\analysis\\performance_control_analysis.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "performance_control_analysis_3_3e7c9992",
    "file": "docs\\reference\\analysis\\performance_control_analysis.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "performance_control_analysis_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\performance_control_analysis.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "performance_control_analysis_5_a29f2215",
    "file": "docs\\reference\\analysis\\performance_control_analysis.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "performance_control_metrics_1_a394b47b",
    "file": "docs\\reference\\analysis\\performance_control_metrics.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "performance_control_metrics_2_2923c213",
    "file": "docs\\reference\\analysis\\performance_control_metrics.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "performance_control_metrics_3_3e7c9992",
    "file": "docs\\reference\\analysis\\performance_control_metrics.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "performance_control_metrics_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\performance_control_metrics.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "performance_control_metrics_5_a29f2215",
    "file": "docs\\reference\\analysis\\performance_control_metrics.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "performance_robustness_1_a394b47b",
    "file": "docs\\reference\\analysis\\performance_robustness.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "performance_robustness_2_2923c213",
    "file": "docs\\reference\\analysis\\performance_robustness.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "performance_robustness_3_3e7c9992",
    "file": "docs\\reference\\analysis\\performance_robustness.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "performance_robustness_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\performance_robustness.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "performance_robustness_5_a29f2215",
    "file": "docs\\reference\\analysis\\performance_robustness.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "performance_stability_analysis_1_a394b47b",
    "file": "docs\\reference\\analysis\\performance_stability_analysis.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "performance_stability_analysis_2_2923c213",
    "file": "docs\\reference\\analysis\\performance_stability_analysis.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "performance_stability_analysis_3_3e7c9992",
    "file": "docs\\reference\\analysis\\performance_stability_analysis.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "performance_stability_analysis_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\performance_stability_analysis.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "performance_stability_analysis_5_a29f2215",
    "file": "docs\\reference\\analysis\\performance_stability_analysis.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "reports___init___1_377f2b06",
    "file": "docs\\reference\\analysis\\reports___init__.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "reports___init___2_02ccf172",
    "file": "docs\\reference\\analysis\\reports___init__.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "reports___init___3_058eb1d2",
    "file": "docs\\reference\\analysis\\reports___init__.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "reports___init___4_e39c1ae8",
    "file": "docs\\reference\\analysis\\reports___init__.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "reports___init___5_b1085bc9",
    "file": "docs\\reference\\analysis\\reports___init__.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "validation_cross_validation_1_a394b47b",
    "file": "docs\\reference\\analysis\\validation_cross_validation.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "validation_cross_validation_2_2923c213",
    "file": "docs\\reference\\analysis\\validation_cross_validation.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "validation_cross_validation_3_3e7c9992",
    "file": "docs\\reference\\analysis\\validation_cross_validation.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "validation_cross_validation_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\validation_cross_validation.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "validation_cross_validation_5_a29f2215",
    "file": "docs\\reference\\analysis\\validation_cross_validation.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "validation_metrics_1_a394b47b",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "validation_metrics_2_2923c213",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "validation_metrics_3_3e7c9992",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "validation_metrics_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "validation_metrics_5_a29f2215",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "validation_metrics_6_f8e398c9",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 6,
    "code": "from src.benchmarks.metrics import compute_all_metrics\nfrom src.simulation.engines.simulation_runner import run_simulation\nfrom src.controllers.factory import create_smc_for_pso, SMCType\nfrom src.plant.models.simplified import SimplifiedDynamics\n\n# Run simulation\ncontroller = create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5])\ndynamics = SimplifiedDynamics()\n\nresult = run_simulation(\n    controller=controller,\n    dynamics_model=dynamics,\n    initial_state=[0.1, 0.05, 0, 0, 0, 0],\n    sim_time=10.0,\n    dt=0.01\n)\n\n# Compute comprehensive metrics\nmetrics = compute_all_metrics(\n    t=result.time,\n    x=result.states,\n    u=result.control,\n    max_force=100.0,\n    include_advanced=True\n)\n\n# Access metrics\nprint(\"Control Performance:\")\nprint(f\"  ISE: {metrics['ise']:.4f}\")\nprint(f\"  ITAE: {metrics['itae']:.4f}\")\nprint(f\"  RMS Control: {metrics['rms_control']:.4f}\")\n\nprint(\"\nStability Analysis:\")\nprint(f\"  Settling Time: {metrics['settling_time']:.3f}s\")\nprint(f\"  Overshoot: {metrics['overshoot']:.2f}%\")\nprint(f\"  Damping Ratio: {metrics['damping_ratio']:.3f}\")\n\nprint(\"\nConstraint Violations:\")\nprint(f\"  Saturation Count: {metrics['saturation_count']}\")\nprint(f\"  Saturation Severity: {metrics['saturation_severity']:.4f}\")",
    "lines": 42,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f8e398c9"
  },
  {
    "id": "validation_metrics_7_d8c1b4a6",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 7,
    "code": "from src.benchmarks.metrics.control_metrics import compute_ise, compute_itae\nfrom src.benchmarks.metrics.stability_metrics import compute_overshoot, compute_settling_time\nfrom src.benchmarks.metrics.constraint_metrics import count_control_violations\n\n# Control metrics\nise = compute_ise(result.time, result.states)\nitae = compute_itae(result.time, result.states)\n\n# Stability metrics\novershoot = compute_overshoot(result.states[:, 0])  # First angle\nsettling_time = compute_settling_time(result.time, result.states, threshold=0.02)\n\n# Constraint violations\nviolations, severity, peak = count_control_violations(result.control, max_force=100.0)\n\nprint(f\"ISE: {ise:.4f}, ITAE: {itae:.4f}\")\nprint(f\"Overshoot: {overshoot:.2f}%, Settling: {settling_time:.3f}s\")\nprint(f\"Violations: {violations}, Severity: {severity:.4f}, Peak: {peak:.2f}\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d8c1b4a6"
  },
  {
    "id": "validation_metrics_8_61ebc07c",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 8,
    "code": "import numpy as np\n\ndef compute_chattering_index(u, dt):\n    \"\"\"Quantify control chattering.\"\"\"\n    # Total variation of control signal\n    tv = np.sum(np.abs(np.diff(u))) * dt\n    return tv\n\nchattering = compute_chattering_index(result.control, dt=0.01)\nprint(f\"Chattering Index: {chattering:.4f}\")\n\n# Compare chattering across controllers\ncontrollers = {\n    'Classical': create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'STA': create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15]),\n}\n\nchattering_results = {}\nfor name, ctrl in controllers.items():\n    result = run_simulation(ctrl, dynamics, [0.1, 0.05, 0, 0, 0, 0], 10.0, 0.01)\n    chattering_results[name] = compute_chattering_index(result.control, 0.01)\n\nfor name, ci in chattering_results.items():\n    print(f\"{name} Chattering: {ci:.4f}\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "61ebc07c"
  },
  {
    "id": "validation_metrics_9_a129f5f4",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\n# Track energy conservation (for unforced natural dynamics)\ndef compute_energy_drift(result, dynamics):\n    \"\"\"Measure energy drift as validation check.\"\"\"\n    energies = [dynamics.compute_total_energy(x) for x in result.states]\n    initial_energy = energies[0]\n    drift = np.abs(np.array(energies) - initial_energy) / initial_energy * 100\n    max_drift = np.max(drift)\n    mean_drift = np.mean(drift)\n    return {'max_drift_%': max_drift, 'mean_drift_%': mean_drift}\n\nenergy_metrics = compute_energy_drift(result, dynamics)\nprint(f\"Energy drift: {energy_metrics['max_drift_%']:.3f}% (max), \"\n      f\"{energy_metrics['mean_drift_%']:.3f}% (mean)\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a129f5f4"
  },
  {
    "id": "validation_metrics_10_736e3622",
    "file": "docs\\reference\\analysis\\validation_metrics.md",
    "index": 10,
    "code": "from src.benchmarks.metrics import compute_all_metrics\n\n# Compute metrics for multiple trials\ntrials_results = []  # List of simulation results from multiple runs\n\nmetrics_collection = []\nfor result in trials_results:\n    metrics = compute_all_metrics(result.time, result.states, result.control, 100.0)\n    metrics_collection.append(metrics)\n\n# Aggregate statistics\nimport pandas as pd\ndf = pd.DataFrame(metrics_collection)\n\nprint(\"Metric Statistics Across Trials:\")\nprint(df[['ise', 'settling_time', 'overshoot', 'rms_control']].describe())",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "736e3622"
  },
  {
    "id": "validation_monte_carlo_1_a394b47b",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "validation_monte_carlo_2_2923c213",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "validation_monte_carlo_3_3e7c9992",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "validation_monte_carlo_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "validation_monte_carlo_5_a29f2215",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "validation_monte_carlo_6_d482dad6",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 6,
    "code": "from src.analysis.validation.monte_carlo import MonteCarloValidator\nfrom src.controllers.factory import create_smc_for_pso, SMCType\n\n# Define controller\ncontroller_factory = lambda: create_smc_for_pso(\n    SMCType.CLASSICAL,\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0\n)\n\n# Configure uncertainty model (\u00b120% on masses, \u00b110% on lengths)\nuncertainty = {\n    'cart_mass': {'type': 'uniform', 'range': (-0.2, 0.2)},\n    'pole1_mass': {'type': 'uniform', 'range': (-0.2, 0.2)},\n    'pole2_mass': {'type': 'uniform', 'range': (-0.2, 0.2)},\n    'pole1_length': {'type': 'uniform', 'range': (-0.1, 0.1)},\n    'pole2_length': {'type': 'uniform', 'range': (-0.1, 0.1)},\n}\n\n# Run Monte Carlo validation\nvalidator = MonteCarloValidator(\n    controller_factory=controller_factory,\n    uncertainty_model=uncertainty,\n    n_samples=100,\n    seed=42\n)\n\nresults = validator.run()\n\n# Analyze robustness\nprint(f\"Success Rate: {results['success_rate']*100:.1f}%\")\nprint(f\"Mean ISE: {results['mean_ise']:.4f}\")\nprint(f\"Worst-case ISE: {results['worst_case_ise']:.4f}\")\nprint(f\"95th Percentile ISE: {results['percentile_95_ise']:.4f}\")",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d482dad6"
  },
  {
    "id": "validation_monte_carlo_7_f20aa49b",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 7,
    "code": "import numpy as np\n\n# Define correlated uncertainties (masses tend to vary together)\nmean_params = np.array([1.0, 0.1, 0.05])  # cart, pole1, pole2 masses\ncov_matrix = np.array([\n    [0.04, 0.01, 0.005],   # cart mass variance and covariances\n    [0.01, 0.004, 0.002],  # pole1 mass\n    [0.005, 0.002, 0.001]  # pole2 mass\n])\n\n# Gaussian Monte Carlo\nvalidator = MonteCarloValidator(\n    controller_factory=controller_factory,\n    uncertainty_model={\n        'masses': {\n            'type': 'gaussian',\n            'mean': mean_params,\n            'cov': cov_matrix\n        }\n    },\n    n_samples=200\n)\n\nresults = validator.run()\n\n# Visualize uncertainty propagation\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.hist(results['ise_samples'], bins=30, alpha=0.7, edgecolor='black')\nplt.xlabel('ISE')\nplt.ylabel('Frequency')\nplt.title('Performance Distribution under Uncertainty')\n\nplt.subplot(1, 2, 2)\nplt.scatter(results['param_samples'][:, 0], results['ise_samples'], alpha=0.5)\nplt.xlabel('Cart Mass Perturbation')\nplt.ylabel('ISE')\nplt.title('Sensitivity to Cart Mass')\nplt.tight_layout()\nplt.show()",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f20aa49b"
  },
  {
    "id": "validation_monte_carlo_8_39f16ebd",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 8,
    "code": "from src.analysis.validation.monte_carlo import LatinHypercubeSampler\n\n# High-dimensional uncertainty (all 8 physics parameters)\nuncertainty_full = {\n    'cart_mass': (-0.2, 0.2),\n    'pole1_mass': (-0.2, 0.2),\n    'pole2_mass': (-0.2, 0.2),\n    'pole1_length': (-0.1, 0.1),\n    'pole2_length': (-0.1, 0.1),\n    'friction_cart': (-0.3, 0.3),\n    'friction_pole1': (-0.3, 0.3),\n    'friction_pole2': (-0.3, 0.3),\n}\n\n# Latin Hypercube Sampling (more efficient than random for high dimensions)\nsampler = LatinHypercubeSampler(uncertainty_full, n_samples=150, seed=42)\nparam_samples = sampler.generate()\n\n# Run validation with LHS samples\nvalidator = MonteCarloValidator(\n    controller_factory=controller_factory,\n    param_samples=param_samples  # Pre-generated samples\n)\n\nresults = validator.run()\n\n# Analyze which parameters drive failures\nfailure_params = param_samples[~results['stability_mask']]\nprint(f\"Failure modes analysis:\")\nprint(f\"  Cart mass range in failures: [{failure_params[:, 0].min():.3f}, {failure_params[:, 0].max():.3f}]\")\nprint(f\"  Pole1 length range in failures: [{failure_params[:, 3].min():.3f}, {failure_params[:, 3].max():.3f}]\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "39f16ebd"
  },
  {
    "id": "validation_monte_carlo_9_f93a91b7",
    "file": "docs\\reference\\analysis\\validation_monte_carlo.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ncontrollers = {\n    'Classical': lambda: create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'Adaptive': lambda: create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n}\n\nuncertainty = {\n    'cart_mass': {'type': 'uniform', 'range': (-0.3, 0.3)},  # Aggressive uncertainty\n    'pole1_mass': {'type': 'uniform', 'range': (-0.3, 0.3)},\n}\n\nrobustness_results = {}\nfor name, factory in controllers.items():\n    validator = MonteCarloValidator(factory, uncertainty, n_samples=200)\n    robustness_results[name] = validator.run()\n\n# Compare success rates\nfor name, res in robustness_results.items():\n    print(f\"{name}:\")\n    print(f\"  Success Rate: {res['success_rate']*100:.1f}%\")\n    print(f\"  Mean ISE (successful): {res['mean_ise']:.4f}\")\n    print(f\"  Worst-case ISE: {res['worst_case_ise']:.4f}\")",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f93a91b7"
  },
  {
    "id": "validation_statistical_benchmarks_1_a394b47b",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "validation_statistical_benchmarks_2_2923c213",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "validation_statistical_benchmarks_3_3e7c9992",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "validation_statistical_benchmarks_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "validation_statistical_benchmarks_5_a29f2215",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "validation_statistical_benchmarks_6_a463bacf",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 6,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials\nfrom src.controllers.factory import create_smc_for_pso, SMCType\n\n# Define controller factory\ndef controller_factory():\n    return create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100.0\n    )\n\n# Configure benchmarking\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\n\n# Run trials with statistical analysis\nmetrics_list, ci_results = run_trials(\n    controller_factory,\n    config,\n    n_trials=30,\n    confidence_level=0.95\n)\n\n# Access results\nprint(f\"Mean ISE: {ci_results['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{ci_results['ise']['ci_lower']:.4f}, {ci_results['ise']['ci_upper']:.4f}]\")\nprint(f\"Std Dev: {ci_results['ise']['std']:.4f}\")",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a463bacf"
  },
  {
    "id": "validation_statistical_benchmarks_7_c6e47dd8",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 7,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials_with_advanced_statistics\n\n# Run with bootstrap CI (non-parametric, no normality assumption)\nmetrics_list, analysis = run_trials_with_advanced_statistics(\n    controller_factory,\n    config,\n    n_trials=50,\n    confidence_level=0.99,\n    use_bootstrap=True,\n    n_bootstrap=10000\n)\n\n# Bootstrap results more robust for non-normal distributions\nprint(f\"Bootstrap 99% CI for settling time:\")\nprint(f\"  [{analysis['settling_time']['bootstrap_ci'][0]:.3f}, \"\n      f\"{analysis['settling_time']['bootstrap_ci'][1]:.3f}]\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6e47dd8"
  },
  {
    "id": "validation_statistical_benchmarks_8_7145987c",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 8,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import compare_controllers\n\n# Define two controllers\ndef classical_factory():\n    return create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5])\n\ndef adaptive_factory():\n    return create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5])\n\n# Statistical comparison\ncomparison = compare_controllers(\n    controller_a_factory=classical_factory,\n    controller_b_factory=adaptive_factory,\n    config=config,\n    n_trials=40\n)\n\n# Interpret results\nfor metric, result in comparison.items():\n    print(f\"\n{metric.upper()}:\")\n    print(f\"  Classical: {result['mean_a']:.4f} \u00b1 {result['std_a']:.4f}\")\n    print(f\"  Adaptive:  {result['mean_b']:.4f} \u00b1 {result['std_b']:.4f}\")\n    print(f\"  p-value:   {result['p_value']:.4e}\")\n\n    if result['p_value'] < 0.05:\n        better = 'Classical' if result['mean_a'] < result['mean_b'] else 'Adaptive'\n        print(f\"  \u2192 {better} is significantly better (p < 0.05)\")\n    else:\n        print(f\"  \u2192 No significant difference (p \u2265 0.05)\")",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7145987c"
  },
  {
    "id": "validation_statistical_benchmarks_9_57117aee",
    "file": "docs\\reference\\analysis\\validation_statistical_benchmarks.md",
    "index": 9,
    "code": "from src.benchmarks.core import run_multiple_trials\n\ncontrollers = {\n    'Classical': lambda: create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'Adaptive': lambda: create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n    'STA': lambda: create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15]),\n    'Hybrid': lambda: create_smc_for_pso(SMCType.HYBRID, [15, 12, 18, 15])\n}\n\nresults = {}\nfor name, factory in controllers.items():\n    metrics_list, ci_results = run_trials(factory, config, n_trials=30)\n    results[name] = ci_results\n\n# Compare ISE across all controllers\nimport pandas as pd\ncomparison_df = pd.DataFrame({\n    name: {\n        'ISE': r['ise']['mean'],\n        'ISE_CI': f\"[{r['ise']['ci_lower']:.3f}, {r['ise']['ci_upper']:.3f}]\",\n        'Settling Time': r['settling_time']['mean']\n    }\n    for name, r in results.items()\n}).T\n\nprint(comparison_df)",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57117aee"
  },
  {
    "id": "validation_statistical_tests_1_a394b47b",
    "file": "docs\\reference\\analysis\\validation_statistical_tests.md",
    "index": 1,
    "code": "from src.analysis import Analyzer\n\n# Initialize analyzer\nanalyzer = Analyzer(config)\nresult = analyzer.analyze(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a394b47b"
  },
  {
    "id": "validation_statistical_tests_2_2923c213",
    "file": "docs\\reference\\analysis\\validation_statistical_tests.md",
    "index": 2,
    "code": "# Compute confidence intervals\nfrom src.analysis.validation import compute_confidence_interval\n\nci = compute_confidence_interval(samples, confidence=0.95)\nprint(f\"95% CI: [{ci.lower:.3f}, {ci.upper:.3f}]\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2923c213"
  },
  {
    "id": "validation_statistical_tests_3_3e7c9992",
    "file": "docs\\reference\\analysis\\validation_statistical_tests.md",
    "index": 3,
    "code": "# Compute comprehensive metrics\nfrom src.analysis.performance import compute_all_metrics\n\nmetrics = compute_all_metrics(\n    time=t,\n    state=x,\n    control=u,\n    reference=r\n)\nprint(f\"ISE: {metrics.ise:.2f}, ITAE: {metrics.itae:.2f}\")",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e7c9992"
  },
  {
    "id": "validation_statistical_tests_4_f0d4b49d",
    "file": "docs\\reference\\analysis\\validation_statistical_tests.md",
    "index": 4,
    "code": "# Analyze multiple trials\nresults = []\nfor trial in range(n_trials):\n    result = run_simulation(trial_seed=trial)\n    results.append(analyzer.analyze(result))\n\n# Aggregate statistics\nmean_performance = np.mean([r.performance for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0d4b49d"
  },
  {
    "id": "validation_statistical_tests_5_a29f2215",
    "file": "docs\\reference\\analysis\\validation_statistical_tests.md",
    "index": 5,
    "code": "# Parameter sensitivity analysis\nfrom src.analysis.performance import sensitivity_analysis\n\nsensitivity = sensitivity_analysis(\n    system=plant,\n    parameters={'mass': (0.8, 1.2), 'length': (0.9, 1.1)},\n    metric=compute_stability_margin\n)\nprint(f\"Most sensitive: {sensitivity.most_sensitive_param}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a29f2215"
  },
  {
    "id": "visualization_analysis_plots_1_377f2b06",
    "file": "docs\\reference\\analysis\\visualization_analysis_plots.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "visualization_analysis_plots_2_02ccf172",
    "file": "docs\\reference\\analysis\\visualization_analysis_plots.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "visualization_analysis_plots_3_058eb1d2",
    "file": "docs\\reference\\analysis\\visualization_analysis_plots.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "visualization_analysis_plots_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\visualization_analysis_plots.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "visualization_analysis_plots_5_b1085bc9",
    "file": "docs\\reference\\analysis\\visualization_analysis_plots.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "visualization_diagnostic_plots_1_377f2b06",
    "file": "docs\\reference\\analysis\\visualization_diagnostic_plots.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "visualization_diagnostic_plots_2_02ccf172",
    "file": "docs\\reference\\analysis\\visualization_diagnostic_plots.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "visualization_diagnostic_plots_3_058eb1d2",
    "file": "docs\\reference\\analysis\\visualization_diagnostic_plots.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "visualization_diagnostic_plots_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\visualization_diagnostic_plots.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "visualization_diagnostic_plots_5_b1085bc9",
    "file": "docs\\reference\\analysis\\visualization_diagnostic_plots.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "visualization_report_generator_1_377f2b06",
    "file": "docs\\reference\\analysis\\visualization_report_generator.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "visualization_report_generator_2_02ccf172",
    "file": "docs\\reference\\analysis\\visualization_report_generator.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "visualization_report_generator_3_058eb1d2",
    "file": "docs\\reference\\analysis\\visualization_report_generator.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "visualization_report_generator_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\visualization_report_generator.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "visualization_report_generator_5_b1085bc9",
    "file": "docs\\reference\\analysis\\visualization_report_generator.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "visualization_statistical_plots_1_377f2b06",
    "file": "docs\\reference\\analysis\\visualization_statistical_plots.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "visualization_statistical_plots_2_02ccf172",
    "file": "docs\\reference\\analysis\\visualization_statistical_plots.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "visualization_statistical_plots_3_058eb1d2",
    "file": "docs\\reference\\analysis\\visualization_statistical_plots.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "visualization_statistical_plots_4_e39c1ae8",
    "file": "docs\\reference\\analysis\\visualization_statistical_plots.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "visualization_statistical_plots_5_b1085bc9",
    "file": "docs\\reference\\analysis\\visualization_statistical_plots.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "visualization___init___1_17929f51",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 1,
    "code": "default_style < user_style < local_override",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17929f51"
  },
  {
    "id": "visualization___init___2_f925bae8",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass Visualizer:\n    def plot_time_series(data) -> Figure\n    def plot_phase_portrait(states) -> Figure\n    def plot_statistics(metrics) -> Figure",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f925bae8"
  },
  {
    "id": "visualization___init___3_377f2b06",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 3,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "visualization___init___4_02ccf172",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 4,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "visualization___init___5_058eb1d2",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 5,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "visualization___init___6_e39c1ae8",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 6,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "visualization___init___7_b1085bc9",
    "file": "docs\\reference\\analysis\\visualization___init__.md",
    "index": 7,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "__init___1_377f2b06",
    "file": "docs\\reference\\analysis\\__init__.md",
    "index": 1,
    "code": "from src.analysis import Component\n\n# Initialize component\ncomponent = Component(config)\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "377f2b06"
  },
  {
    "id": "__init___2_02ccf172",
    "file": "docs\\reference\\analysis\\__init__.md",
    "index": 2,
    "code": "# Configure with custom parameters\nconfig = {\n    'threshold': 0.05,\n    'method': 'adaptive'\n}\ncomponent = Component(config)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02ccf172"
  },
  {
    "id": "__init___3_058eb1d2",
    "file": "docs\\reference\\analysis\\__init__.md",
    "index": 3,
    "code": "# Complete analysis workflow\nfrom src.analysis import analyze\n\nresults = analyze(\n    data=sensor_data,\n    method='enhanced',\n    visualization=True\n)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "058eb1d2"
  },
  {
    "id": "__init___4_e39c1ae8",
    "file": "docs\\reference\\analysis\\__init__.md",
    "index": 4,
    "code": "# FDI system usage\nfrom src.analysis.fault_detection import FDISystem\n\nfdi = FDISystem(config)\nresidual = fdi.generate_residual(y, u)\nfault = fdi.detect(residual)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e39c1ae8"
  },
  {
    "id": "__init___5_b1085bc9",
    "file": "docs\\reference\\analysis\\__init__.md",
    "index": 5,
    "code": "# Generate analysis plots\nfrom src.analysis.visualization import AnalysisPlotter\n\nplotter = AnalysisPlotter(style='professional')\nfig = plotter.plot_time_series(data)\nfig.savefig('analysis.pdf')",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1085bc9"
  },
  {
    "id": "statistical_benchmarks_v2_1_a463bacf",
    "file": "docs\\reference\\benchmarks\\statistical_benchmarks_v2.md",
    "index": 1,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials\nfrom src.controllers.factory import create_smc_for_pso, SMCType\n\n# Define controller factory\ndef controller_factory():\n    return create_smc_for_pso(\n        SMCType.CLASSICAL,\n        gains=[10, 8, 15, 12, 50, 5],\n        max_force=100.0\n    )\n\n# Configure benchmarking\nfrom src.config import load_config\nconfig = load_config(\"config.yaml\")\n\n# Run trials with statistical analysis\nmetrics_list, ci_results = run_trials(\n    controller_factory,\n    config,\n    n_trials=30,\n    confidence_level=0.95\n)\n\n# Access results\nprint(f\"Mean ISE: {ci_results['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{ci_results['ise']['ci_lower']:.4f}, {ci_results['ise']['ci_upper']:.4f}]\")\nprint(f\"Std Dev: {ci_results['ise']['std']:.4f}\")",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a463bacf"
  },
  {
    "id": "statistical_benchmarks_v2_2_c6e47dd8",
    "file": "docs\\reference\\benchmarks\\statistical_benchmarks_v2.md",
    "index": 2,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import run_trials_with_advanced_statistics\n\n# Run with bootstrap CI (non-parametric, no normality assumption)\nmetrics_list, analysis = run_trials_with_advanced_statistics(\n    controller_factory,\n    config,\n    n_trials=50,\n    confidence_level=0.99,\n    use_bootstrap=True,\n    n_bootstrap=10000\n)\n\n# Bootstrap results more robust for non-normal distributions\nprint(f\"Bootstrap 99% CI for settling time:\")\nprint(f\"  [{analysis['settling_time']['bootstrap_ci'][0]:.3f}, \"\n      f\"{analysis['settling_time']['bootstrap_ci'][1]:.3f}]\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6e47dd8"
  },
  {
    "id": "statistical_benchmarks_v2_3_7145987c",
    "file": "docs\\reference\\benchmarks\\statistical_benchmarks_v2.md",
    "index": 3,
    "code": "from src.benchmarks.statistical_benchmarks_v2 import compare_controllers\n\n# Define two controllers\ndef classical_factory():\n    return create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5])\n\ndef adaptive_factory():\n    return create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5])\n\n# Statistical comparison\ncomparison = compare_controllers(\n    controller_a_factory=classical_factory,\n    controller_b_factory=adaptive_factory,\n    config=config,\n    n_trials=40\n)\n\n# Interpret results\nfor metric, result in comparison.items():\n    print(f\"\n{metric.upper()}:\")\n    print(f\"  Classical: {result['mean_a']:.4f} \u00b1 {result['std_a']:.4f}\")\n    print(f\"  Adaptive:  {result['mean_b']:.4f} \u00b1 {result['std_b']:.4f}\")\n    print(f\"  p-value:   {result['p_value']:.4e}\")\n\n    if result['p_value'] < 0.05:\n        better = 'Classical' if result['mean_a'] < result['mean_b'] else 'Adaptive'\n        print(f\"  \u2192 {better} is significantly better (p < 0.05)\")\n    else:\n        print(f\"  \u2192 No significant difference (p \u2265 0.05)\")",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7145987c"
  },
  {
    "id": "statistical_benchmarks_v2_4_57117aee",
    "file": "docs\\reference\\benchmarks\\statistical_benchmarks_v2.md",
    "index": 4,
    "code": "from src.benchmarks.core import run_multiple_trials\n\ncontrollers = {\n    'Classical': lambda: create_smc_for_pso(SMCType.CLASSICAL, [10, 8, 15, 12, 50, 5]),\n    'Adaptive': lambda: create_smc_for_pso(SMCType.ADAPTIVE, [10, 8, 15, 12, 0.5]),\n    'STA': lambda: create_smc_for_pso(SMCType.SUPER_TWISTING, [25, 10, 15, 12, 20, 15]),\n    'Hybrid': lambda: create_smc_for_pso(SMCType.HYBRID, [15, 12, 18, 15])\n}\n\nresults = {}\nfor name, factory in controllers.items():\n    metrics_list, ci_results = run_trials(factory, config, n_trials=30)\n    results[name] = ci_results\n\n# Compare ISE across all controllers\nimport pandas as pd\ncomparison_df = pd.DataFrame({\n    name: {\n        'ISE': r['ise']['mean'],\n        'ISE_CI': f\"[{r['ise']['ci_lower']:.3f}, {r['ise']['ci_upper']:.3f}]\",\n        'Settling Time': r['settling_time']['mean']\n    }\n    for name, r in results.items()\n}).T\n\nprint(comparison_df)",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "57117aee"
  },
  {
    "id": "adaptive-smc_1_4acb2114",
    "file": "docs\\reference\\controllers\\adaptive-smc.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('adaptive_smc', config)\n\n# Simulation loop\nfor t, state in simulation:\n    u = controller.compute_control(state, reference, t)\n\n    # Monitor adaptive gains\n    current_gain = controller.get_adaptive_gain()\n    print(f\"Adaptive gain: {current_gain:.3f}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4acb2114"
  },
  {
    "id": "base_controller_interface_1_0c76fb59",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass ControllerProtocol(Protocol):\n    def compute_control(\n        self,\n        state: np.ndarray,\n        state_vars: Dict[str, Any],\n        history: Dict[str, Any]\n    ) -> Tuple[float, Dict[str, Any], Dict[str, Any]]:\n        ...\n\n    def initialize_history(self) -> Dict[str, Any]:\n        ...",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c76fb59"
  },
  {
    "id": "base_controller_interface_2_7ee44670",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass Controller(ABC):\n    def compute_control(\n        self,\n        state: np.ndarray,  # Can accept more general types in subclasses\n        ...\n    ) -> ...:\n        ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ee44670"
  },
  {
    "id": "base_controller_interface_3_8629c237",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nclass Controller(ABC):\n    def compute_control(...) -> Tuple[float, Dict, Dict]:  # Subclasses can return more specific types\n        ...",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8629c237"
  },
  {
    "id": "base_controller_interface_4_272a77c2",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 4,
    "code": "class Controller(ABC):\n    @abstractmethod\n    def compute_control(self, state, state_vars, history):\n        \"\"\"Subclasses MUST implement this.\"\"\"\n        pass\n\n    def reset(self):\n        \"\"\"Default implementation (optional override).\"\"\"\n        return self.initialize_history()",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "272a77c2"
  },
  {
    "id": "base_controller_interface_5_d908d35c",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 5,
    "code": "# No type checking - relies on runtime behavior\ndef simulate(controller):\n    u = controller.compute_control(state, {}, {})  # Hope it works!",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d908d35c"
  },
  {
    "id": "base_controller_interface_6_9ccfdec1",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 6,
    "code": "def simulate(controller: ControllerProtocol):\n    u = controller.compute_control(state, {}, {})  # Type-safe!",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ccfdec1"
  },
  {
    "id": "base_controller_interface_7_032af9bf",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_control(\n    self,\n    state: np.ndarray,\n    state_vars: Dict[str, Any],\n    history: Dict[str, Any]\n) -> Tuple[float, Dict[str, Any], Dict[str, Any]]:\n    # Extract previous state\n    K = state_vars.get('K', self.K_initial)\n\n    # Update state (e.g., adaptation)\n    K_new = K + self.gamma * abs(s) * self.dt\n\n    # Return new state\n    return u, {'K': K_new}, history",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "032af9bf"
  },
  {
    "id": "base_controller_interface_8_59885c63",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 8,
    "code": "def compute_control(self, state, state_vars, history):\n    # Append to history\n    history['states'].append(state)\n    history['times'].append(t)\n\n    # Compute derivative from history\n    if len(history['states']) >= 2:\n        derivative = (state - history['states'][-2]) / self.dt\n\n    return u, state_vars, history",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "59885c63"
  },
  {
    "id": "base_controller_interface_9_6836d675",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 9,
    "code": "class HybridAdaptiveSMC(AdaptiveSMC, SuperTwistingSMC):\n    pass\n\n# MRO: HybridAdaptiveSMC \u2192 AdaptiveSMC \u2192 SuperTwistingSMC \u2192 Controller \u2192 ABC",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6836d675"
  },
  {
    "id": "base_controller_interface_10_0df3464a",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.controllers.base.controller_interface import ControllerProtocol\nimport numpy as np\n\ndef simulate(controller: ControllerProtocol, duration: float):\n    \"\"\"Simulate with any controller implementing the protocol.\"\"\"\n\n    # Initialize\n    state_vars = {}\n    history = controller.initialize_history()\n\n    # Simulation loop\n    state = np.array([0.1, 0.0, 0.05, 0.1, 0.02, 0.05])\n\n    for t in np.arange(0, duration, 0.01):\n        u, state_vars, history = controller.compute_control(\n            state, state_vars, history\n        )\n        # ... integrate dynamics\n\n    return history\n\n# Works with ANY controller implementing ControllerProtocol\nfrom src.controllers import ClassicalSMC, AdaptiveSMC\n\nclassical = ClassicalSMC(gains=[10, 8, 15, 12, 50, 0.01])\nadaptive = AdaptiveSMC(gains=[10, 8, 15, 12, 0.5])\n\nresult_classical = simulate(classical, duration=5.0)\nresult_adaptive = simulate(adaptive, duration=5.0)",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0df3464a"
  },
  {
    "id": "base_controller_interface_11_c5fc3f08",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# Duck typing (no type checking)\ndef simulate_duck(controller):  # No type hint\n    u = controller.compute_control(state, {}, {})  # Hope it works!\n    return u\n\n# Explicit protocol (type-safe)\ndef simulate_protocol(controller: ControllerProtocol):\n    u, _, _ = controller.compute_control(state, {}, {})  # mypy validates!\n    return u\n\n# mypy catches errors at compile time:\n# simulate_protocol(None)  # Error: None doesn't implement ControllerProtocol\n# simulate_protocol(\"foo\")  # Error: str doesn't implement ControllerProtocol",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5fc3f08"
  },
  {
    "id": "base_controller_interface_12_480c1e9c",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 12,
    "code": "# Base class behavior\nfrom src.controllers.base import Controller\n\ndef reset_controller(controller: Controller):\n    \"\"\"Works with any Controller subclass.\"\"\"\n    history = controller.reset()\n    return history\n\n# Works for all subclasses\nclassical = ClassicalSMC(gains=[10, 8, 15, 12, 50, 0.01])\nadaptive = AdaptiveSMC(gains=[10, 8, 15, 12, 0.5])\n\nhistory_classical = reset_controller(classical)  # Works\nhistory_adaptive = reset_controller(adaptive)    # Works\n\n# Substitutability guaranteed by LSP",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "480c1e9c"
  },
  {
    "id": "base_controller_interface_13_c5b924a5",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Controller with internal state (e.g., adaptation)\nclass AdaptiveController(Controller):\n    def compute_control(self, state, state_vars, history):\n        # Extract previous state\n        K = state_vars.get('K', self.K_initial)\n        integral = state_vars.get('integral', 0.0)\n\n        # Compute control\n        s = self.compute_sliding_surface(state)\n        K_new = K + self.gamma * abs(s) * self.dt\n        integral_new = integral + s * self.dt\n\n        u = -K_new * np.tanh(s / self.epsilon)\n\n        # Return updated state\n        return u, {'K': K_new, 'integral': integral_new}, history\n\n# State is fully captured in state_vars\nstate_vars = {}\nfor i in range(100):\n    u, state_vars, history = controller.compute_control(state, state_vars, history)\n    # state_vars contains full controller state for reproducibility",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5b924a5"
  },
  {
    "id": "base_controller_interface_14_2d2d3687",
    "file": "docs\\reference\\controllers\\base_controller_interface.md",
    "index": 14,
    "code": "from src.controllers.base.controller_interface import Controller\nfrom abc import ABC\n\nclass MyCustomSMC(Controller):\n    \"\"\"Custom SMC implementation.\"\"\"\n\n    def __init__(self, gains, max_force):\n        self.gains = gains\n        self.max_force = max_force\n\n    def compute_control(self, state, state_vars, history):\n        # Custom control law\n        theta1, theta2 = state[2], state[4]\n        theta1_dot, theta2_dot = state[3], state[5]\n\n        # Custom sliding surface\n        s = self.gains[0] * theta1 + self.gains[1] * theta1_dot\n\n        # Custom switching law\n        u = -self.gains[2] * np.sign(s)\n        u = np.clip(u, -self.max_force, self.max_force)\n\n        return u, state_vars, history\n\n    def initialize_history(self):\n        return {'states': [], 'times': []}\n\n# Use custom controller with existing simulation infrastructure\ncustom_controller = MyCustomSMC(gains=[10.0, 5.0, 50.0], max_force=100.0)\nresult = simulate(custom_controller, duration=5.0)  # Works!",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2d2d3687"
  },
  {
    "id": "base_control_primitives_1_5dcabf2f",
    "file": "docs\\reference\\controllers\\base_control_primitives.md",
    "index": 1,
    "code": "from src.controllers.base.control_primitives import saturate\n\n# Apply saturation to control signal\nu_raw = 150.0  # Exceeds actuator limit\nu_max = 100.0\n\nu = saturate(u_raw, u_max)\nprint(f\"Saturated control: {u:.1f} N\")  # 100.0 N\n\n# Vectorized saturation\nu_raw_array = np.array([150.0, 50.0, -120.0, 30.0])\nu_array = saturate(u_raw_array, u_max)\nprint(f\"Saturated controls: {u_array}\")  # [100, 50, -100, 30]",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5dcabf2f"
  },
  {
    "id": "base_control_primitives_2_6f72a2b3",
    "file": "docs\\reference\\controllers\\base_control_primitives.md",
    "index": 2,
    "code": "from src.controllers.base.control_primitives import rate_limit\n\n# Current and previous control\nu_current = 80.0\nu_previous = 40.0\ndt = 0.01  # Time step\nu_dot_max = 1000.0  # N/s\n\n# Apply rate limiting\nu_limited = rate_limit(u_current, u_previous, u_dot_max, dt)\n\n# Maximum allowed change: 1000 * 0.01 = 10 N\n# Requested change: 80 - 40 = 40 N\n# Limited change: 10 N\nprint(f\"Rate-limited control: {u_limited:.1f} N\")  # 50.0 N",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6f72a2b3"
  },
  {
    "id": "base_control_primitives_3_237b1ae2",
    "file": "docs\\reference\\controllers\\base_control_primitives.md",
    "index": 3,
    "code": "from src.controllers.base.control_primitives import anti_windup_back_calculation\n\n# PID-like controller with integral term\nintegral = 5.0  # Accumulated integral error\nu_raw = 150.0   # Requested control\nu_max = 100.0\n\n# Saturated control\nu_sat = saturate(u_raw, u_max)  # 100.0 N\n\n# Back-calculation anti-windup\nT_i = 1.0  # Integration time constant\nintegral_correction = (u_sat - u_raw) / T_i  # Negative (reduces integral)\n\nintegral_new = integral + integral_correction * dt\nprint(f\"Integral before: {integral:.3f}\")\nprint(f\"Integral after:  {integral_new:.3f}\")  # Reduced",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "237b1ae2"
  },
  {
    "id": "base_control_primitives_4_6289ba54",
    "file": "docs\\reference\\controllers\\base_control_primitives.md",
    "index": 4,
    "code": "from src.controllers.base.control_primitives import low_pass_filter\n\n# Noisy control signal\nu_noisy = 50.0 + 5.0 * np.random.randn()\n\n# Filter parameters\nomega_c = 20.0  # Cutoff frequency (rad/s)\ndt = 0.01\ntau = 1.0 / omega_c  # Time constant\n\n# Apply filter\nu_filtered_prev = 48.0  # Previous filtered value\nu_filtered = low_pass_filter(u_noisy, u_filtered_prev, tau, dt)\n\nprint(f\"Noisy control:    {u_noisy:.2f} N\")\nprint(f\"Filtered control: {u_filtered:.2f} N\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6289ba54"
  },
  {
    "id": "base_control_primitives_5_5a91ca15",
    "file": "docs\\reference\\controllers\\base_control_primitives.md",
    "index": 5,
    "code": "from src.controllers.base.control_primitives import (\n    saturate, rate_limit, low_pass_filter, deadband\n)\n\n# Control pipeline\nclass ControlPipeline:\n    def __init__(self, u_max, u_dot_max, tau_filter, deadband_threshold):\n        self.u_max = u_max\n        self.u_dot_max = u_dot_max\n        self.tau = tau_filter\n        self.deadband = deadband_threshold\n        self.u_prev = 0.0\n        self.u_filtered_prev = 0.0\n\n    def process(self, u_raw, dt):\n        # 1. Deadband (ignore small errors)\n        u1 = deadband(u_raw, self.deadband)\n\n        # 2. Rate limiting (prevent slew violations)\n        u2 = rate_limit(u1, self.u_prev, self.u_dot_max, dt)\n\n        # 3. Saturation (enforce actuator limits)\n        u3 = saturate(u2, self.u_max)\n\n        # 4. Low-pass filter (reduce high-frequency content)\n        u4 = low_pass_filter(u3, self.u_filtered_prev, self.tau, dt)\n\n        # Update history\n        self.u_prev = u3  # Before filtering for rate limiting\n        self.u_filtered_prev = u4\n\n        return u4\n\n# Usage\npipeline = ControlPipeline(\n    u_max=100.0,\n    u_dot_max=1000.0,\n    tau_filter=0.05,\n    deadband_threshold=0.5\n)\n\nu_raw = -75.0  # Raw controller output\nu_final = pipeline.process(u_raw, dt=0.01)\nprint(f\"Final control: {u_final:.2f} N\")",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a91ca15"
  },
  {
    "id": "classical-smc_1_a9482c59",
    "file": "docs\\reference\\controllers\\classical-smc.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('classical_smc', config)\n\n# Compute control (in simulation loop)\nu = controller.compute_control(state, reference, time)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9482c59"
  },
  {
    "id": "factory_pso_integration_1_ec884476",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_fitness_function(\n    ctrl_type: SMCType,\n    config: Config\n) -> Callable[[np.ndarray], float]:\n    \"\"\"Returns fitness function for PSO.\"\"\"\n\n    def fitness(gains: np.ndarray) -> float:\n        # Create controller with candidate gains\n        controller = create_smc_for_pso(ctrl_type, gains)\n\n        # Simulate\n        result = simulate(controller, config)\n\n        # Compute cost\n        return compute_cost(result)\n\n    return fitness",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec884476"
  },
  {
    "id": "factory_pso_integration_2_91d54e1e",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 2,
    "code": "def batch_fitness(\n    gains_population: np.ndarray,  # Shape: (n_particles, n_gains)\n    ctrl_type: SMCType\n) -> np.ndarray:  # Shape: (n_particles,)\n    \"\"\"Evaluate all particles in parallel.\"\"\"\n    controllers = [create_smc_for_pso(ctrl_type, g) for g in gains_population]\n    results = batch_simulate(controllers, config)\n    return np.array([compute_cost(r) for r in results])",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91d54e1e"
  },
  {
    "id": "factory_pso_integration_3_5dc25f06",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 3,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType, get_gain_bounds_for_pso\nfrom src.optimizer.pso_optimizer import PSOTuner\n\n# Get parameter bounds for Classical SMC\nbounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Define fitness function\ndef fitness_function(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = simulate(controller, duration=5.0)\n    return result.itae + 0.1 * result.rms_control\n\n# Initialize PSO\npso = PSOTuner(\n    n_particles=30,\n    bounds=bounds,\n    fitness_function=fitness_function\n)\n\n# Optimize\nbest_gains, best_fitness = pso.optimize(max_iterations=50)\nprint(f\"Optimal gains: {best_gains}\")\nprint(f\"Best fitness:  {best_fitness:.4f}\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5dc25f06"
  },
  {
    "id": "factory_pso_integration_4_e57923db",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Multi-objective cost function\ndef multi_objective_fitness(gains):\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n    result = simulate(controller, duration=5.0)\n\n    # Weighted sum of objectives\n    w_itae = 1.0     # Tracking error\n    w_control = 0.1  # Control effort\n    w_chat = 0.05    # Chattering\n    w_viol = 10.0    # Constraint violations\n\n    cost = (w_itae * result.itae +\n            w_control * result.rms_control +\n            w_chat * result.chattering_index +\n            w_viol * result.violation_count)\n\n    return cost\n\npso = PSOTuner(\n    n_particles=30,\n    bounds=bounds,\n    fitness_function=multi_objective_fitness\n)\n\nbest_gains, best_cost = pso.optimize(max_iterations=100)",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e57923db"
  },
  {
    "id": "factory_pso_integration_5_e5c0756f",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# PSO with convergence callback\ndef convergence_callback(iteration, best_fitness, diversity):\n    print(f\"Iteration {iteration:3d}: \"\n          f\"Fitness={best_fitness:.4f}, \"\n          f\"Diversity={diversity:.4f}\")\n\n    # Early stopping if fitness stagnant\n    if iteration > 20:\n        fitness_history = pso.get_fitness_history()\n        improvement = abs(fitness_history[-1] - fitness_history[-10]) / fitness_history[-10]\n        if improvement < 1e-4:\n            print(\"Early stopping: convergence detected\")\n            return True  # Stop optimization\n    return False\n\npso = PSOTuner(\n    n_particles=30,\n    bounds=bounds,\n    fitness_function=fitness_function,\n    convergence_callback=convergence_callback\n)\n\nbest_gains, _ = pso.optimize(max_iterations=200)",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e5c0756f"
  },
  {
    "id": "factory_pso_integration_6_a7a57da6",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 6,
    "code": "# Fitness with constraint penalties\ndef constrained_fitness(gains):\n    # Create controller\n    controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n\n    # Validate gains first (cheap check)\n    from src.controllers.smc.core.gain_validation import validate_all_criteria\n\n    validation_config = {\n        'u_max': 100.0,\n        'omega_s': 2*np.pi*100,\n        'Delta_max': 20.0,\n        'u_eq_max': 80.0,\n    }\n\n    results = validate_all_criteria(gains, validation_config)\n\n    # Heavy penalty for invalid gains\n    if not all(results.values()):\n        return 1e6  # Return worst fitness\n\n    # Simulate only if gains valid\n    result = simulate(controller, duration=5.0)\n    return result.itae\n\npso = PSOTuner(n_particles=30, bounds=bounds, fitness_function=constrained_fitness)\nbest_gains, _ = pso.optimize(max_iterations=100)",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7a57da6"
  },
  {
    "id": "factory_pso_integration_7_69cc90cf",
    "file": "docs\\reference\\controllers\\factory_pso_integration.md",
    "index": 7,
    "code": "from joblib import Parallel, delayed\n\n# Parallel fitness evaluation\ndef batch_fitness(gains_population):\n    \"\"\"Evaluate all particles in parallel.\"\"\"\n\n    def eval_single(gains):\n        controller = create_smc_for_pso(SMCType.CLASSICAL, gains)\n        result = simulate(controller, duration=5.0)\n        return result.itae\n\n    # Parallel execution (8 cores)\n    fitness_values = Parallel(n_jobs=8)(\n        delayed(eval_single)(gains) for gains in gains_population\n    )\n\n    return np.array(fitness_values)\n\n# PSO with batch evaluation\npso = PSOTuner(\n    n_particles=30,\n    bounds=bounds,\n    fitness_function=batch_fitness,  # Pass batch function\n    batch_mode=True\n)\n\nbest_gains, _ = pso.optimize(max_iterations=50)\nprint(f\"Speedup: ~8x using parallel evaluation\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "69cc90cf"
  },
  {
    "id": "factory_smc_factory_1_9bd0be21",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 1,
    "code": "class SMCType(Enum):\n    CLASSICAL = \"classical\"\n    ADAPTIVE = \"adaptive\"\n    SUPER_TWISTING = \"sta\"\n    HYBRID = \"hybrid\"",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9bd0be21"
  },
  {
    "id": "factory_smc_factory_2_293745ea",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(ctrl_type: SMCType, ...) -> Controller:\n    ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "293745ea"
  },
  {
    "id": "factory_smc_factory_3_54c251d5",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 3,
    "code": "_controller_registry: Dict[SMCType, Callable] = {}\n\ndef register_controller(ctrl_type: SMCType, factory_fn: Callable):\n    _controller_registry[ctrl_type] = factory_fn",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "54c251d5"
  },
  {
    "id": "factory_smc_factory_4_26cdcab7",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 4,
    "code": "_registry_lock = threading.Lock()\n\nwith _registry_lock:\n    _controller_registry[ctrl_type] = factory_fn",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "26cdcab7"
  },
  {
    "id": "factory_smc_factory_5_3f5f6d34",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_controller(\n    ctrl_type: SMCType,\n    gains: List[float],\n    dynamics_model: Optional[DynamicsModel] = None,  # Injected\n    config: Optional[Config] = None  # Injected\n) -> Controller:\n    ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f5f6d34"
  },
  {
    "id": "factory_smc_factory_6_2a672826",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 6,
    "code": "@dataclass\nclass GainSpecification:\n    n_gains: int\n    bounds: List[Tuple[float, float]]\n    gain_names: List[str]\n    description: str",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a672826"
  },
  {
    "id": "factory_smc_factory_7_030ca56a",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 7,
    "code": "def validate_gains(ctrl_type: SMCType, gains: List[float]) -> bool:\n    spec = get_gain_specification(ctrl_type)\n    if len(gains) != spec.n_gains:\n        return False\n    return all(lb <= g <= ub for g, (lb, ub) in zip(gains, spec.bounds))",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "030ca56a"
  },
  {
    "id": "factory_smc_factory_8_d4934547",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n@dataclass(frozen=True)\nclass SMCConfig:\n    gains: List[float]\n    max_force: float\n    dt: float\n    boundary_layer: float = 0.01\n\n    def __post_init__(self):\n        # Validation logic\n        if self.max_force <= 0:\n            raise ValueError(\"max_force must be positive\")",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d4934547"
  },
  {
    "id": "factory_smc_factory_9_8a12191e",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\nclass SMCConfigBuilder:\n    def __init__(self):\n        self._config = {}\n\n    def with_gains(self, gains: List[float]):\n        self._config['gains'] = gains\n        return self\n\n    def with_max_force(self, max_force: float):\n        self._config['max_force'] = max_force\n        return self\n\n    def build(self) -> SMCConfig:\n        return SMCConfig(**self._config)",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a12191e"
  },
  {
    "id": "factory_smc_factory_10_e14d9a98",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 10,
    "code": "config = (SMCConfigBuilder()\n    .with_gains([10, 8, 15, 12, 50, 5])\n    .with_max_force(100.0)\n    .build())",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e14d9a98"
  },
  {
    "id": "factory_smc_factory_11_53186df2",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 11,
    "code": "from src.controllers.factory import SMCType, create_controller\n\n# Create classical SMC controller\ncontroller = create_controller(\n    ctrl_type=SMCType.CLASSICAL,\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 0.01],\n    max_force=100.0,\n    dt=0.01\n)\n\n# Use controller\nstate = np.array([0.1, 0.0, 0.05, 0.1, 0.02, 0.05])\nu, state_vars, history = controller.compute_control(state, {}, {})\nprint(f\"Control output: {u:.2f} N\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "53186df2"
  },
  {
    "id": "factory_smc_factory_12_23576859",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 12,
    "code": "from src.controllers.factory import SMCFactory, SMCConfig\n\n# Create configuration dataclass\nconfig = SMCConfig(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 0.01],\n    max_force=100.0,\n    dt=0.01,\n    boundary_layer=0.01\n)\n\n# Factory ensures type safety\ncontroller = SMCFactory.create_controller(SMCType.CLASSICAL, config)\n\n# mypy validates this at compile time!",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23576859"
  },
  {
    "id": "factory_smc_factory_13_2f34615f",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 13,
    "code": "from src.controllers.factory import SMCFactory, SMCType\n\n# Get gain requirements for each controller type\nfor ctrl_type in SMCType:\n    spec = SMCFactory.get_gain_specification(ctrl_type)\n    print(f\"\\n{ctrl_type.value}:\")\n    print(f\"  Number of gains: {spec.n_gains}\")\n    print(f\"  Gain names:      {spec.gain_names}\")\n    print(f\"  Bounds:          {spec.bounds}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2f34615f"
  },
  {
    "id": "factory_smc_factory_14_979c35a7",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 14,
    "code": "from src.controllers.factory.core.registry import ControllerRegistry\n\n# View registered controllers\nregistry = ControllerRegistry()\nregistered_types = registry.list_controllers()\n\nprint(\"Registered Controllers:\")\nfor ctrl_type in registered_types:\n    factory_fn = registry.get_factory(ctrl_type)\n    print(f\"  {ctrl_type.value}: {factory_fn.__name__}\")\n\n# Register custom controller (plugin architecture)\ndef create_custom_smc(config):\n    return CustomSMC(**config)\n\nregistry.register(SMCType.CUSTOM, create_custom_smc)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "979c35a7"
  },
  {
    "id": "factory_smc_factory_15_6bccd42a",
    "file": "docs\\reference\\controllers\\factory_smc_factory.md",
    "index": 15,
    "code": "from src.controllers.factory import create_all_smc_controllers\n\n# Gains for each controller type\ngains_dict = {\n    \"classical\": [10, 8, 15, 12, 50, 0.01],\n    \"adaptive\": [10, 8, 15, 12, 0.5],\n    \"sta\": [25, 10, 15, 12, 20, 15],\n    \"hybrid\": [15, 12, 18, 15]\n}\n\n# Create all controllers for comparison\ncontrollers = create_all_smc_controllers(\n    gains_dict,\n    max_force=100.0,\n    dt=0.01\n)\n\n# Simulate each controller\nresults = {}\nfor ctrl_name, controller in controllers.items():\n    result = simulate(controller, duration=5.0)\n    results[ctrl_name] = result\n    print(f\"{ctrl_name}: ITAE={result.itae:.3f}\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6bccd42a"
  },
  {
    "id": "hybrid-adaptive-smc_1_5abef066",
    "file": "docs\\reference\\controllers\\hybrid-adaptive-smc.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('hybrid_adaptive_sta_smc', config)\n\n# Simulation loop\nfor t, state in simulation:\n    u = controller.compute_control(state, reference, t)\n\n    # Monitor adaptive gains\n    k1, k2 = controller.get_adaptive_gains()\n    print(f\"Adaptive gains: k1={k1:.3f}, k2={k2:.3f}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5abef066"
  },
  {
    "id": "smc_algorithms_adaptive_adaptation_law_1_a4dd4cc8",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_adaptation_law.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.adaptive import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4dd4cc8"
  },
  {
    "id": "smc_algorithms_adaptive_adaptation_law_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_adaptation_law.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_adaptive_adaptation_law_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_adaptation_law.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_adaptive_adaptation_law_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_adaptation_law.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_adaptive_adaptation_law_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_adaptation_law.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_adaptive_controller_1_a4dd4cc8",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.adaptive import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4dd4cc8"
  },
  {
    "id": "smc_algorithms_adaptive_controller_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_adaptive_controller_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_adaptive_controller_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_adaptive_controller_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_adaptive_controller_6_1dbaae5e",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 6,
    "code": "from src.controllers.smc.algorithms.adaptive import ModularAdaptiveSMC\nfrom src.controllers.smc.algorithms.adaptive.config import AdaptiveSMCConfig\n\n# Configure adaptive controller\nconfig = AdaptiveSMCConfig(\n    surface_gains=[10.0, 8.0, 15.0, 12.0],  # [k1, k2, \u03bb1, \u03bb2]\n    initial_switching_gain=25.0,             # K\u2080\n    adaptation_rate=5.0,                     # \u03b3\n    leakage_term=0.1,                        # \u03c3\n    max_force=100.0\n)\n\ncontroller = ModularAdaptiveSMC(config, dynamics=dynamics)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1dbaae5e"
  },
  {
    "id": "smc_algorithms_adaptive_controller_7_b9014a92",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 7,
    "code": "from src.core.simulation_runner import SimulationRunner\nfrom src.plant.models.simplified import SimplifiedDynamics\n\n# Create simulation with adaptive controller\ndynamics = SimplifiedDynamics()\nrunner = SimulationRunner(controller, dynamics)\n\n# Run with uncertainty\nresult = runner.run(\n    initial_state=[0.1, 0.05, 0, 0, 0, 0],\n    duration=10.0,\n    dt=0.01\n)\n\n# Analyze gain adaptation\nadaptive_gains = result.history['adaptive_gain']\nprint(f\"Final adapted gain: {adaptive_gains[-1]:.2f}\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9014a92"
  },
  {
    "id": "smc_algorithms_adaptive_controller_8_575f37bd",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 8,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\nfrom src.optimizer.pso_optimizer import PSOTuner\n\n# Adaptive SMC has 5 gains: [k1, k2, \u03bb1, \u03bb2, K\u2080]\nbounds = [\n    (0.1, 50.0),   # k1\n    (0.1, 50.0),   # k2\n    (0.1, 50.0),   # \u03bb1\n    (0.1, 50.0),   # \u03bb2\n    (1.0, 100.0)   # K\u2080\n]\n\n# Create controller factory\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.ADAPTIVE, gains, max_force=100.0)\n\n# Run PSO optimization\ntuner = PSOTuner(bounds, controller_factory)\nbest_gains, best_fitness = tuner.optimize(n_particles=30, iters=100)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "575f37bd"
  },
  {
    "id": "smc_algorithms_adaptive_controller_9_8b41f166",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_controller.md",
    "index": 9,
    "code": "from src.controllers.smc.algorithms.adaptive.adaptation_law import AdaptationLaw\n\n# Experiment with different adaptation strategies\nadaptation = AdaptationLaw(\n    gamma=5.0,        # Fast adaptation\n    sigma=0.1,        # Low leakage\n    K_min=1.0,        # Minimum gain bound\n    K_max=200.0       # Maximum gain bound\n)\n\n# Test adaptation response\nfor uncertainty in [5.0, 10.0, 20.0]:\n    adapted_gain = adaptation.update(surface=0.1, uncertainty=uncertainty, dt=0.01)\n    print(f\"Uncertainty={uncertainty}: K={adapted_gain:.2f}\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b41f166"
  },
  {
    "id": "smc_algorithms_adaptive_parameter_estimation_1_a4dd4cc8",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_parameter_estimation.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.adaptive import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4dd4cc8"
  },
  {
    "id": "smc_algorithms_adaptive_parameter_estimation_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_parameter_estimation.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_adaptive_parameter_estimation_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_parameter_estimation.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_adaptive_parameter_estimation_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_parameter_estimation.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_adaptive_parameter_estimation_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_adaptive_parameter_estimation.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_classical_boundary_layer_1_1aeb95ae",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_boundary_layer.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.classical import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1aeb95ae"
  },
  {
    "id": "smc_algorithms_classical_boundary_layer_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_boundary_layer.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_classical_boundary_layer_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_boundary_layer.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_classical_boundary_layer_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_boundary_layer.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_classical_boundary_layer_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_boundary_layer.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_classical_controller_1_1aeb95ae",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.classical import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1aeb95ae"
  },
  {
    "id": "smc_algorithms_classical_controller_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_classical_controller_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_classical_controller_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_classical_controller_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_classical_controller_6_50ac89f1",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 6,
    "code": "from src.controllers.smc.algorithms.classical import ClassicalSMC\nfrom src.controllers.smc.algorithms.classical.config import ClassicalSMCConfig\n\n# Configure controller\nconfig = ClassicalSMCConfig(\n    surface_gains=[10.0, 8.0, 15.0, 12.0],  # [k1, k2, \u03bb1, \u03bb2]\n    switching_gain=50.0,                     # K\n    derivative_gain=5.0,                     # kd\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Create controller\ncontroller = ClassicalSMC(config)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50ac89f1"
  },
  {
    "id": "smc_algorithms_classical_controller_7_91652f9a",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 7,
    "code": "from src.core.simulation_runner import SimulationRunner\nfrom src.plant.models.simplified import SimplifiedDynamics\n\n# Create simulation components\ndynamics = SimplifiedDynamics()\nrunner = SimulationRunner(controller, dynamics)\n\n# Run simulation\nresult = runner.run(\n    initial_state=[0.1, 0.05, 0, 0, 0, 0],  # [\u03b81, \u03b82, \u03b8\u03071, \u03b8\u03072, x, \u1e8b]\n    duration=5.0,\n    dt=0.01\n)\n\n# Analyze results\nprint(f\"Settling time: {result.metrics.settling_time:.2f}s\")\nprint(f\"Overshoot: {result.metrics.overshoot:.1f}%\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "91652f9a"
  },
  {
    "id": "smc_algorithms_classical_controller_8_b836790b",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 8,
    "code": "from src.controllers.factory import create_smc_for_pso, get_gain_bounds_for_pso\nfrom src.controllers.factory import SMCType\nfrom src.optimizer.pso_optimizer import PSOTuner\n\n# Get optimization bounds\nlower_bounds, upper_bounds = get_gain_bounds_for_pso(SMCType.CLASSICAL)\n\n# Define controller factory\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.CLASSICAL, gains, max_force=100.0)\n\n# Configure PSO\npso_tuner = PSOTuner(\n    controller_factory=controller_factory,\n    bounds=(lower_bounds, upper_bounds),\n    n_particles=30,\n    max_iter=50\n)\n\n# Optimize\nbest_gains, best_cost = pso_tuner.optimize()\nprint(f\"Optimized gains: {best_gains}\")\nprint(f\"Best fitness: {best_cost:.4f}\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b836790b"
  },
  {
    "id": "smc_algorithms_classical_controller_9_1648f548",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 9,
    "code": "from src.controllers.smc.algorithms.classical.boundary_layer import BoundaryLayer\n\n# Experiment with different chattering reduction methods\nboundary_layer = BoundaryLayer(\n    epsilon=0.01,\n    method='tanh',  # 'tanh', 'linear', 'sigmoid'\n    slope=3.0       # Steepness parameter for tanh\n)\n\n# Custom configuration\nconfig = ClassicalSMCConfig(\n    surface_gains=[10.0, 8.0, 15.0, 12.0],\n    switching_gain=50.0,\n    derivative_gain=5.0,\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\ncontroller = ClassicalSMC(config)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1648f548"
  },
  {
    "id": "smc_algorithms_classical_controller_10_b618888e",
    "file": "docs\\reference\\controllers\\smc_algorithms_classical_controller.md",
    "index": 10,
    "code": "from src.utils.monitoring.latency import LatencyMonitor\n\n# Monitor control loop timing\nmonitor = LatencyMonitor(dt=0.01)\n\nstart = monitor.start()\ncontrol, state_vars, history = controller.compute_control(state, state_vars, history)\nmissed_deadlines = monitor.end(start)\n\nif missed_deadlines > 0:\n    print(f\"Warning: {missed_deadlines} deadline misses detected!\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b618888e"
  },
  {
    "id": "smc_algorithms_hybrid_controller_1_8f6fc937",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.hybrid import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f6fc937"
  },
  {
    "id": "smc_algorithms_hybrid_controller_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_hybrid_controller_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_hybrid_controller_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_hybrid_controller_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_hybrid_controller_6_6b53741f",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 6,
    "code": "from src.controllers.smc.algorithms.hybrid import ModularHybridSMC\nfrom src.controllers.smc.algorithms.hybrid.config import HybridSMCConfig\n\n# Configure hybrid controller\nconfig = HybridSMCConfig(\n    surface_gains=[15.0, 12.0, 18.0, 15.0],\n    proportional_gain=25.0,\n    integral_gain=18.0,\n    derivative_gain=6.0,\n    max_force=100.0,\n    switching_threshold=0.05  # Mode switching sensitivity\n)\n\ncontroller = ModularHybridSMC(config, dynamics_model=dynamics)",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b53741f"
  },
  {
    "id": "smc_algorithms_hybrid_controller_7_5b05ff32",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 7,
    "code": "from src.core.simulation_runner import SimulationRunner\nfrom src.plant.models.simplified import SimplifiedDynamics\n\ndynamics = SimplifiedDynamics()\nrunner = SimulationRunner(controller, dynamics)\n\nresult = runner.run(\n    initial_state=[0.2, 0.15, 0, 0, 0, 0],  # Large disturbance\n    duration=15.0,\n    dt=0.01\n)\n\n# Analyze mode switching history\nmode_history = result.controller_history['active_mode']\nswitches = np.diff(mode_history).nonzero()[0]\nprint(f\"Mode switches: {len(switches)} times\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5b05ff32"
  },
  {
    "id": "smc_algorithms_hybrid_controller_8_3a843889",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 8,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\n\n# Hybrid SMC has 4 gains (surface only, internal switching)\nbounds = [\n    (1.0, 50.0),   # k1\n    (1.0, 50.0),   # k2\n    (1.0, 50.0),   # \u03bb1\n    (1.0, 50.0),   # \u03bb2\n]\n\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.HYBRID, gains, max_force=100.0)\n\n# Optimize for robustness\ntuner = PSOTuner(bounds, controller_factory, metric='robustness_index')\nbest_gains, best_robustness = tuner.optimize(n_particles=35, iters=120)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a843889"
  },
  {
    "id": "smc_algorithms_hybrid_controller_9_552c1991",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_controller.md",
    "index": 9,
    "code": "from src.controllers.factory import create_all_smc_controllers\n\ngains_dict = {\n    \"classical\": [10, 8, 15, 12, 50, 5],\n    \"adaptive\": [10, 8, 15, 12, 25],\n    \"sta\": [25, 10, 15, 12, 20, 15],\n    \"hybrid\": [15, 12, 18, 15]\n}\n\ncontrollers = create_all_smc_controllers(gains_dict, max_force=100.0)\n\n# Benchmark all controllers\nfrom src.benchmarks import run_comprehensive_comparison\ncomparison = run_comprehensive_comparison(\n    controllers=controllers,\n    scenarios='standard',\n    metrics='all'\n)\n\ncomparison.generate_report('controller_comparison.pdf')",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "552c1991"
  },
  {
    "id": "smc_algorithms_hybrid_switching_logic_1_8f6fc937",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_switching_logic.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.hybrid import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f6fc937"
  },
  {
    "id": "smc_algorithms_hybrid_switching_logic_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_switching_logic.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_hybrid_switching_logic_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_switching_logic.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_hybrid_switching_logic_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_switching_logic.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_hybrid_switching_logic_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_hybrid_switching_logic.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_1_772f0457",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.super_twisting import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "772f0457"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_6_2b531194",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 6,
    "code": "from src.controllers.smc.algorithms.super_twisting import ModularSuperTwistingSMC\nfrom src.controllers.smc.algorithms.super_twisting.config import SuperTwistingSMCConfig\n\n# Configure super-twisting controller\nconfig = SuperTwistingSMCConfig(\n    surface_gains=[25.0, 10.0, 15.0, 12.0],  # Higher gains for robustness\n    proportional_gain=20.0,                   # K\u2081\n    integral_gain=15.0,                       # K\u2082\n    derivative_gain=5.0,                      # kd\n    max_force=100.0\n)\n\ncontroller = ModularSuperTwistingSMC(config, dynamics=dynamics)",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b531194"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_7_d9eb7371",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 7,
    "code": "from src.core.simulation_runner import SimulationRunner\nfrom src.plant.models.full import FullDynamics\n\n# Use full dynamics for realistic chattering assessment\ndynamics = FullDynamics()\nrunner = SimulationRunner(controller, dynamics)\n\nresult = runner.run(\n    initial_state=[0.15, 0.1, 0, 0, 0, 0],\n    duration=10.0,\n    dt=0.001  # High frequency for chattering detection\n)\n\n# Analyze chattering index\nchattering = runner.compute_chattering_index(result.control_history)\nprint(f\"Chattering index: {chattering:.4f} (lower is better)\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9eb7371"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_8_3e3b299b",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 8,
    "code": "from src.controllers.factory import create_smc_for_pso, SMCType\n\n# STA requires 6 gains: [k1, k2, \u03bb1, \u03bb2, K\u2081, K\u2082]\n# STA stability: K\u2081 > K\u2082 for finite-time convergence\nbounds = [\n    (1.0, 50.0),    # k1\n    (1.0, 50.0),    # k2\n    (1.0, 50.0),    # \u03bb1\n    (1.0, 50.0),    # \u03bb2\n    (10.0, 100.0),  # K\u2081 (proportional)\n    (5.0, 50.0),    # K\u2082 (integral)\n]\n\ndef controller_factory(gains):\n    return create_smc_for_pso(SMCType.SUPER_TWISTING, gains, max_force=100.0)\n\n# Optimize for convergence time\ntuner = PSOTuner(bounds, controller_factory, metric='convergence_time')\nbest_gains, best_time = tuner.optimize(n_particles=40, iters=150)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3e3b299b"
  },
  {
    "id": "smc_algorithms_super_twisting_controller_9_c6c654f8",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_controller.md",
    "index": 9,
    "code": "import numpy as np\n\n# Theoretical convergence time: t_c \u2248 2|s(0)|/(K\u2081\u221aK\u2082)\nK1, K2 = 20.0, 15.0\ns0 = 0.1\n\ntheoretical_time = 2 * abs(s0) / (K1 * np.sqrt(K2))\nprint(f\"Theoretical convergence: {theoretical_time:.3f}s\")\n\n# Run simulation and measure actual convergence\nresult = runner.run(initial_state=[0.1, 0, 0, 0, 0, 0], duration=5.0)\nactual_time = np.argmax(np.abs(result.surface_history) < 0.01) * 0.01\nprint(f\"Actual convergence: {actual_time:.3f}s\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6c654f8"
  },
  {
    "id": "smc_algorithms_super_twisting_twisting_algorithm_1_772f0457",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_twisting_algorithm.md",
    "index": 1,
    "code": "from src.controllers.smc.algorithms.super_twisting import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "772f0457"
  },
  {
    "id": "smc_algorithms_super_twisting_twisting_algorithm_2_e757136e",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_twisting_algorithm.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "smc_algorithms_super_twisting_twisting_algorithm_3_c82c49cc",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_twisting_algorithm.md",
    "index": 3,
    "code": "# Use in complete control loop\ncontroller = create_controller(ctrl_type, config)\nresult = simulate(controller, duration=5.0)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c82c49cc"
  },
  {
    "id": "smc_algorithms_super_twisting_twisting_algorithm_4_1528e342",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_twisting_algorithm.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(state)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1528e342"
  },
  {
    "id": "smc_algorithms_super_twisting_twisting_algorithm_5_3b29909a",
    "file": "docs\\reference\\controllers\\smc_algorithms_super_twisting_twisting_algorithm.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"ITAE: {metrics.itae:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b29909a"
  },
  {
    "id": "smc_core_equivalent_control_1_423f9923",
    "file": "docs\\reference\\controllers\\smc_core_equivalent_control.md",
    "index": 1,
    "code": "from src.controllers.smc.core.equivalent_control import EquivalentControl\nfrom src.plant.models.simplified import SimplifiedDIPDynamics\n\n# Initialize dynamics model\ndynamics = SimplifiedDIPDynamics()\n\n# Initialize equivalent control module\neq_control = EquivalentControl(\n    dynamics_model=dynamics,\n    surface_gains=[10.0, 8.0, 15.0, 12.0]  # \u03bb1, c1, \u03bb2, c2\n)\n\n# Compute equivalent control for current state\nstate = np.array([0.1, 0.0, 0.05, 0.1, 0.02, 0.05])\nu_eq = eq_control.compute(state)\nprint(f\"Equivalent control: {u_eq:.2f} N\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "423f9923"
  },
  {
    "id": "smc_core_equivalent_control_2_7edf1e95",
    "file": "docs\\reference\\controllers\\smc_core_equivalent_control.md",
    "index": 2,
    "code": "# Check matrix conditioning before inversion\nM = dynamics.compute_mass_matrix(state)\ncond_number = np.linalg.cond(M)\n\nprint(f\"Condition number of M: {cond_number:.2e}\")\n\nif cond_number > 1e6:\n    print(\"Warning: Ill-conditioned matrix, increasing regularization\")\n    eq_control.set_regularization(alpha=1e-4)\nelse:\n    print(\"Matrix well-conditioned\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7edf1e95"
  },
  {
    "id": "smc_core_equivalent_control_3_c035af58",
    "file": "docs\\reference\\controllers\\smc_core_equivalent_control.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Adaptive regularization based on conditioning\ndef adaptive_regularization(cond_number):\n    if cond_number < 1e3:\n        return 1e-6  # Minimal regularization\n    elif cond_number < 1e6:\n        return 1e-5  # Moderate regularization\n    else:\n        return 1e-4  # Strong regularization\n\nalpha = adaptive_regularization(cond_number)\neq_control.set_regularization(alpha=alpha)\nprint(f\"Using regularization: \u03b1={alpha:.2e}\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c035af58"
  },
  {
    "id": "smc_core_equivalent_control_4_76b4d150",
    "file": "docs\\reference\\controllers\\smc_core_equivalent_control.md",
    "index": 4,
    "code": "from src.utils.control.saturation import saturate\n\n# Compute equivalent control (model-based)\nu_eq = eq_control.compute(state)\n\n# Compute sliding surface\ns = surface.compute(state)\n\n# Compute switching control (robustness)\nK_sw = 50.0  # Switching gain\nepsilon = 0.01  # Boundary layer\nu_sw = -K_sw * saturate(s, epsilon, method='tanh')\n\n# Total control\nu_total = u_eq + u_sw\n\n# Apply actuator limits\nu_max = 100.0\nu = np.clip(u_total, -u_max, u_max)\n\nprint(f\"u_eq={u_eq:.2f}, u_sw={u_sw:.2f}, u_total={u:.2f}\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76b4d150"
  },
  {
    "id": "smc_core_equivalent_control_5_bfe4c3f9",
    "file": "docs\\reference\\controllers\\smc_core_equivalent_control.md",
    "index": 5,
    "code": "import time\n\n# Benchmark equivalent control computation\nn_iterations = 1000\nstart = time.time()\n\nfor _ in range(n_iterations):\n    u_eq = eq_control.compute(state)\n\nelapsed = time.time() - start\ntime_per_call = (elapsed / n_iterations) * 1e6  # microseconds\n\nprint(f\"Equivalent control time: {time_per_call:.2f} \u03bcs per call\")\nprint(f\"Can achieve ~{1e6 / time_per_call:.0f} Hz control rate\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfe4c3f9"
  },
  {
    "id": "smc_core_gain_validation_1_f5ced5b2",
    "file": "docs\\reference\\controllers\\smc_core_gain_validation.md",
    "index": 1,
    "code": "from src.controllers.smc.core.gain_validation import validate_hurwitz_criterion\n\n# Test gains\ngains = [10.0, 8.0, 15.0, 12.0, 50.0, 0.01]  # c1, c2, \u03bb1, \u03bb2, K, \u03b5\n\nis_hurwitz = validate_hurwitz_criterion(gains)\n\nif is_hurwitz:\n    print(\"Gains satisfy Hurwitz criterion (stable sliding surface)\")\nelse:\n    print(\"Warning: Gains violate Hurwitz criterion\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5ced5b2"
  },
  {
    "id": "smc_core_gain_validation_2_8f05423a",
    "file": "docs\\reference\\controllers\\smc_core_gain_validation.md",
    "index": 2,
    "code": "from src.controllers.smc.core.gain_validation import check_control_authority\n\n# Controller parameters\nc1, c2, lambda1, lambda2, K, epsilon = gains\nu_max = 100.0  # Maximum actuator force (N)\n\n# Estimate peak equivalent control (worst case)\nu_eq_max = 80.0  # From dynamics analysis\n\n# Check if total control fits within limits\nu_total_max = u_eq_max + K\nmargin = u_max - u_total_max\n\nprint(f\"u_eq_max: {u_eq_max:.1f} N\")\nprint(f\"K:        {K:.1f} N\")\nprint(f\"u_total:  {u_total_max:.1f} N\")\nprint(f\"u_max:    {u_max:.1f} N\")\nprint(f\"Margin:   {margin:.1f} N ({100*margin/u_max:.1f}%)\")\n\nif margin < 0.1 * u_max:\n    print(\"Warning: Insufficient control authority margin\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f05423a"
  },
  {
    "id": "smc_core_gain_validation_3_fc145e2f",
    "file": "docs\\reference\\controllers\\smc_core_gain_validation.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Compute natural frequencies\nomega_n1 = np.sqrt(c1 / lambda1)\nomega_n2 = np.sqrt(c2 / lambda2)\n\n# Sampling frequency (Hz)\nf_s = 100  # Hz\nomega_s = 2 * np.pi * f_s  # rad/s\n\n# Check Nyquist criterion\nif omega_n1 < omega_s / 5 and omega_n2 < omega_s / 5:\n    print(f\"\u2713 Frequencies safe: \u03c9_n1={omega_n1:.2f}, \u03c9_n2={omega_n2:.2f} rad/s\")\nelse:\n    print(f\"\u2717 Aliasing risk: \u03c9_n1={omega_n1:.2f}, \u03c9_n2={omega_n2:.2f} rad/s\")\n\n# Check lower bound (avoid drift)\nif omega_n1 > 0.5 and omega_n2 > 0.5:\n    print(\"\u2713 Frequencies above DC drift threshold\")\nelse:\n    print(\"\u2717 Frequencies too low, drift risk\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc145e2f"
  },
  {
    "id": "smc_core_gain_validation_4_f62516d6",
    "file": "docs\\reference\\controllers\\smc_core_gain_validation.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Model uncertainty bound\nDelta_max = 20.0  # N (maximum disturbance/uncertainty)\n\n# Compute robustness margin\nmargin_percent = 100 * (K - Delta_max) / K\n\nprint(f\"Switching gain K:      {K:.1f} N\")\nprint(f\"Uncertainty \u0394_max:     {Delta_max:.1f} N\")\nprint(f\"Robustness margin:     {margin_percent:.1f}%\")\n\nif margin_percent < 20:\n    print(\"Warning: Insufficient robustness margin (< 20%)\")\n    K_recommended = Delta_max / 0.8  # 20% margin\n    print(f\"Recommended K:         {K_recommended:.1f} N\")",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f62516d6"
  },
  {
    "id": "smc_core_gain_validation_5_8cd54c2c",
    "file": "docs\\reference\\controllers\\smc_core_gain_validation.md",
    "index": 5,
    "code": "from src.controllers.smc.core.gain_validation import validate_all_criteria\n\n# Validation configuration\nvalidation_config = {\n    'u_max': 100.0,         # Actuator limit (N)\n    'omega_s': 2*np.pi*100, # Sampling frequency (rad/s)\n    'Delta_max': 20.0,      # Uncertainty bound (N)\n    'u_eq_max': 80.0,       # Peak equivalent control (N)\n}\n\n# Run all validation checks\nresults = validate_all_criteria(gains, validation_config)\n\nprint(\"\\nValidation Results:\")\nprint(\"=\" * 50)\nfor criterion, passed in results.items():\n    status = \"\u2713 PASS\" if passed else \"\u2717 FAIL\"\n    print(f\"{criterion:30s}: {status}\")\n\nif all(results.values()):\n    print(\"\\n\u2713 All validation criteria passed\")\nelse:\n    print(\"\\n\u2717 Some validation criteria failed\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8cd54c2c"
  },
  {
    "id": "smc_core_sliding_surface_1_454bcbef",
    "file": "docs\\reference\\controllers\\smc_core_sliding_surface.md",
    "index": 1,
    "code": "from src.controllers.smc.core.sliding_surface import LinearSlidingSurface\nimport numpy as np\n\n# Define gains (c1, c2, \u03bb1, \u03bb2)\ngains = [10.0, 8.0, 15.0, 12.0]\nsurface = LinearSlidingSurface(gains)\n\n# Compute surface value for state\nstate = np.array([0.1, 0.0, 0.05, 0.1, 0.02, 0.05])  # [x, \u1e8b, \u03b8\u2081, \u03b8\u0307\u2081, \u03b8\u2082, \u03b8\u0307\u2082]\ns = surface.compute(state)\nprint(f\"Sliding surface value: {s:.4f}\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "454bcbef"
  },
  {
    "id": "smc_core_sliding_surface_2_4c8fdff9",
    "file": "docs\\reference\\controllers\\smc_core_sliding_surface.md",
    "index": 2,
    "code": "# Compute surface derivative ds/dt\nstate_dot = np.array([0.0, 0.0, 0.1, -0.5, 0.05, -0.3])\ns_dot = surface.compute_derivative(state, state_dot)\nprint(f\"Surface derivative: {s_dot:.4f}\")\n\n# Check sliding condition\nif abs(s) < 0.01 and s * s_dot < 0:\n    print(\"Sliding mode reached and maintained\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c8fdff9"
  },
  {
    "id": "smc_core_sliding_surface_3_053537c1",
    "file": "docs\\reference\\controllers\\smc_core_sliding_surface.md",
    "index": 3,
    "code": "from src.controllers.smc.core.sliding_surface import validate_sliding_surface_gains\n\n# Valid gains (all positive)\ngains_valid = [10.0, 8.0, 15.0, 12.0]\nis_valid = validate_sliding_surface_gains(gains_valid)\nprint(f\"Valid gains: {is_valid}\")  # True\n\n# Invalid gains (c2 negative)\ngains_invalid = [10.0, -8.0, 15.0, 12.0]\ntry:\n    surface_bad = LinearSlidingSurface(gains_invalid)\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "053537c1"
  },
  {
    "id": "smc_core_sliding_surface_4_1076cf90",
    "file": "docs\\reference\\controllers\\smc_core_sliding_surface.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Compute characteristic frequencies\nc1, c2, lambda1, lambda2 = gains\nomega_n1 = np.sqrt(c1 / lambda1)  # rad/s\nomega_n2 = np.sqrt(c2 / lambda2)  # rad/s\n\nprint(f\"Natural frequency 1: {omega_n1:.2f} rad/s\")\nprint(f\"Natural frequency 2: {omega_n2:.2f} rad/s\")\n\n# Check Nyquist criterion (sampling frequency 100 Hz)\nomega_s = 2 * np.pi * 100  # rad/s\nif omega_n1 < omega_s / 5 and omega_n2 < omega_s / 5:\n    print(\"Frequencies safe for 100 Hz sampling\")",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1076cf90"
  },
  {
    "id": "smc_core_sliding_surface_5_a8ef97a1",
    "file": "docs\\reference\\controllers\\smc_core_sliding_surface.md",
    "index": 5,
    "code": "from src.controllers.smc.core.sliding_surface import HigherOrderSlidingSurface\n\n# Define 6 gains for 2nd order surface\ngains_ho = [25.0, 10.0, 15.0, 12.0, 20.0, 15.0]\nsurface_ho = HigherOrderSlidingSurface(gains_ho)\n\n# Compute surface and its derivative\ns_ho = surface_ho.compute(state)\ns_dot_ho = surface_ho.compute_derivative(state, state_dot)\n\nprint(f\"Higher-order surface: s={s_ho:.4f}, \u1e61={s_dot_ho:.4f}\")",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8ef97a1"
  },
  {
    "id": "smc_core_switching_functions_1_036e65c0",
    "file": "docs\\reference\\controllers\\smc_core_switching_functions.md",
    "index": 1,
    "code": "from src.utils.control.saturation import saturate\nimport numpy as np\n\n# Sliding surface value\ns = 0.05  # rad\n\n# Boundary layer parameters\nepsilon = 0.01  # rad\nbeta = 3.0  # Slope parameter\n\n# Compute tanh switching\nu_sw = saturate(s, epsilon, method='tanh', slope=beta)\nprint(f\"Switching control: {u_sw:.4f}\")\n\n# For s >> epsilon, u_sw \u2192 1.0\n# For s << -epsilon, u_sw \u2192 -1.0\n# For |s| < epsilon, smooth transition",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "036e65c0"
  },
  {
    "id": "smc_core_switching_functions_2_4fd93888",
    "file": "docs\\reference\\controllers\\smc_core_switching_functions.md",
    "index": 2,
    "code": "import matplotlib.pyplot as plt\n\n# Time series\nt = np.linspace(0, 5, 5000)\ns_trajectory = 0.02 * np.sin(10 * t) + 0.005 * np.random.randn(len(t))\n\n# Different switching methods\nu_sign = np.sign(s_trajectory)\nu_sat = np.clip(s_trajectory / epsilon, -1, 1)\nu_tanh = np.tanh(beta * s_trajectory / epsilon)\n\n# Compute chattering index (control derivative)\nchat_sign = np.sum(np.abs(np.diff(u_sign)))\nchat_sat = np.sum(np.abs(np.diff(u_sat)))\nchat_tanh = np.sum(np.abs(np.diff(u_tanh)))\n\nprint(f\"Chattering index (sign):  {chat_sign:.1f}\")\nprint(f\"Chattering index (sat):   {chat_sat:.1f}\")\nprint(f\"Chattering index (tanh):  {chat_tanh:.1f}\")  # Lowest",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fd93888"
  },
  {
    "id": "smc_core_switching_functions_3_6fab49ad",
    "file": "docs\\reference\\controllers\\smc_core_switching_functions.md",
    "index": 3,
    "code": "# Test different slope parameters\nslopes = [1.0, 3.0, 5.0, 10.0, 20.0]\n\nfor beta in slopes:\n    u = saturate(s, epsilon, method='tanh', slope=beta)\n\n    # Estimate effective switching sharpness\n    s_test = np.linspace(-3*epsilon, 3*epsilon, 100)\n    u_test = saturate(s_test, epsilon, method='tanh', slope=beta)\n    sharpness = np.mean(np.abs(np.diff(u_test))) / (6 * epsilon / 100)\n\n    print(f\"\u03b2={beta:4.1f}: u={u:6.4f}, sharpness={sharpness:.3f}\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fab49ad"
  },
  {
    "id": "smc_core_switching_functions_4_5227a471",
    "file": "docs\\reference\\controllers\\smc_core_switching_functions.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef dead_zone_switching(s, epsilon, delta, K):\n    \"\"\"Switching with dead zone to avoid chattering near origin.\"\"\"\n    if abs(s) < delta:\n        return 0.0\n    else:\n        return -K * saturate(s, epsilon, method='tanh')\n\n# Parameters\ndelta = 0.1 * epsilon  # Dead zone 10% of boundary layer\nK = 50.0\n\nu_sw = dead_zone_switching(s, epsilon, delta, K)\nprint(f\"Switching with dead zone: {u_sw:.2f} N\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5227a471"
  },
  {
    "id": "smc_core_switching_functions_5_8e73fd0e",
    "file": "docs\\reference\\controllers\\smc_core_switching_functions.md",
    "index": 5,
    "code": "from scipy import signal\n\n# Create transfer function for tanh switching\n# Approximation: linearize around s=0\n# tanh(\u03b2s/\u03b5) \u2248 (\u03b2/\u03b5)s for small s\ngain_linear = beta / epsilon\n\n# Frequency response\nfrequencies = np.logspace(-1, 3, 100)  # 0.1 to 1000 rad/s\nw, mag, phase = signal.bode((gain_linear, [1, 0]), frequencies)\n\n# Plot\nplt.subplot(2, 1, 1)\nplt.semilogx(w, mag)\nplt.ylabel('Magnitude (dB)')\nplt.title(f'Tanh Switching (\u03b2={beta}, \u03b5={epsilon})')\n\nplt.subplot(2, 1, 2)\nplt.semilogx(w, phase)\nplt.ylabel('Phase (deg)')\nplt.xlabel('Frequency (rad/s)')\nplt.show()",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e73fd0e"
  },
  {
    "id": "super-twisting-smc_1_aa74195a",
    "file": "docs\\reference\\controllers\\super-twisting-smc.md",
    "index": 1,
    "code": "from src.controllers.factory import create_controller\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config('config.yaml')\n\n# Create controller\ncontroller = create_controller('sta_smc', config)\n\n# Compute control (in simulation loop)\nu = controller.compute_control(state, reference, time)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aa74195a"
  },
  {
    "id": "hil_controller_client_1_645788ce",
    "file": "docs\\reference\\interfaces\\hil_controller_client.md",
    "index": 1,
    "code": "from src.interfaces.hil import HILControllerClient\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Connect to HIL server\nclient = HILControllerClient(\n    cfg=config,\n    plant_addr=(\"127.0.0.1\", 5555),\n    bind_addr=(\"127.0.0.1\", 0),  # Auto-assign port\n    dt=0.01,\n    steps=5000,\n    results_path=\"hil_results.json\"\n)\n\n# Run HIL simulation\nclient.run()\n\nprint(\"HIL simulation complete, results saved to hil_results.json\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "645788ce"
  },
  {
    "id": "hil_controller_client_2_ab2ae924",
    "file": "docs\\reference\\interfaces\\hil_controller_client.md",
    "index": 2,
    "code": "from src.interfaces.hil import HILControllerClient\nfrom src.controllers import ClassicalSMC\n\n# Create custom controller\ncontroller = ClassicalSMC(\n    gains=[10, 8, 15, 12, 50, 5],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Client with custom controller\nclient = HILControllerClient(\n    cfg=config,\n    plant_addr=(\"192.168.1.100\", 5555),  # Remote server\n    bind_addr=(\"0.0.0.0\", 6666),\n    dt=0.01,\n    steps=10000\n)\n\n# Override controller\nclient._controller = controller\n\n# Run simulation\nclient.run()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ab2ae924"
  },
  {
    "id": "hil_controller_client_3_48f771c8",
    "file": "docs\\reference\\interfaces\\hil_controller_client.md",
    "index": 3,
    "code": "from src.interfaces.hil import HILControllerClient\nimport time\n\n# Client with aggressive timeout\nclient = HILControllerClient(\n    cfg=config,\n    plant_addr=(\"127.0.0.1\", 5555),\n    bind_addr=(\"127.0.0.1\", 0),\n    dt=0.01,\n    steps=5000,\n    recv_timeout_s=0.5  # 500 ms timeout\n)\n\n# Monitor fallback activations\nfallback_count = 0\noriginal_run = client.run\n\ndef monitored_run():\n    global fallback_count\n    # Count timeout events\n    try:\n        original_run()\n    except TimeoutError:\n        fallback_count += 1\n        print(f\"Fallback controller activated: {fallback_count} times\")\n\nclient.run = monitored_run\nclient.run()\n\nprint(f\"Total fallback activations: {fallback_count}\")",
    "lines": 30,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "48f771c8"
  },
  {
    "id": "hil_controller_client_4_1411797f",
    "file": "docs\\reference\\interfaces\\hil_controller_client.md",
    "index": 4,
    "code": "from src.interfaces.hil import HILControllerClient\nimport time\n\n# Latency tracking\nlatencies = []\n\n# Override communication for measurement\noriginal_send_receive = client._send_receive\n\ndef measured_send_receive(msg):\n    start = time.time()\n    result = original_send_receive(msg)\n    latency = (time.time() - start) * 1000  # ms\n    latencies.append(latency)\n    return result\n\nclient._send_receive = measured_send_receive\nclient.run()\n\n# Analyze latencies\nprint(f\"Mean latency: {np.mean(latencies):.2f} ms\")\nprint(f\"P95 latency: {np.percentile(latencies, 95):.2f} ms\")\nprint(f\"P99 latency: {np.percentile(latencies, 99):.2f} ms\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1411797f"
  },
  {
    "id": "hil_controller_client_5_e96ddbf2",
    "file": "docs\\reference\\interfaces\\hil_controller_client.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.interfaces.hil import HILControllerClient\nimport time\n\ndef run_client_with_retry(max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            client = HILControllerClient(\n                cfg=config,\n                plant_addr=(\"127.0.0.1\", 5555),\n                bind_addr=(\"127.0.0.1\", 0),\n                dt=0.01,\n                steps=5000\n            )\n            client.run()\n            print(f\"Success on attempt {attempt + 1}\")\n            return\n        except ConnectionError as e:\n            print(f\"Connection failed (attempt {attempt + 1}): {e}\")\n            if attempt < max_retries - 1:\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f\"Retrying in {wait_time} seconds...\")\n                time.sleep(wait_time)\n\n    print(\"All retry attempts failed\")\n\nrun_client_with_retry()",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e96ddbf2"
  },
  {
    "id": "hil_data_logging_1_419187d4",
    "file": "docs\\reference\\interfaces\\hil_data_logging.md",
    "index": 1,
    "code": "from src.interfaces.hil.data_logging import DataLogger\n\n# Create logger\nlogger = DataLogger(\n    output_path=\"hil_data.csv\",\n    format=\"csv\",\n    sample_rate=100.0  # 100 Hz\n)\n\n# Simulation with logging\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n\n    # Log data\n    logger.log(time=t, state=state, control=control)\n\n# Close logger\nlogger.close()\nprint(\"Data saved to hil_data.csv\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "419187d4"
  },
  {
    "id": "hil_data_logging_2_3f4e844f",
    "file": "docs\\reference\\interfaces\\hil_data_logging.md",
    "index": 2,
    "code": "from src.interfaces.hil.data_logging import HDF5Logger\n\n# HDF5 logger with compression\nlogger = HDF5Logger(\n    output_path=\"hil_data.h5\",\n    compression=\"gzip\",\n    compression_opts=9  # Maximum compression\n)\n\n# Create datasets\nlogger.create_dataset(\"time\", dtype=np.float64)\nlogger.create_dataset(\"state\", shape=(6,), dtype=np.float64)\nlogger.create_dataset(\"control\", dtype=np.float64)\n\n# Log simulation data\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n\n    logger.append(\"time\", t)\n    logger.append(\"state\", state)\n    logger.append(\"control\", control)\n\nlogger.close()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3f4e844f"
  },
  {
    "id": "hil_data_logging_3_fad946e4",
    "file": "docs\\reference\\interfaces\\hil_data_logging.md",
    "index": 3,
    "code": "from src.interfaces.hil.data_logging import EventLogger\n\n# Event-based logger\nlogger = EventLogger(\n    output_path=\"events.csv\",\n    threshold=0.1  # Log when state changes > 0.1\n)\n\nlast_state = None\n\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n\n    # Check if significant change\n    if last_state is not None:\n        state_change = np.linalg.norm(state - last_state)\n        if state_change > logger.threshold:\n            logger.log(time=t, state=state)\n\n    last_state = state\n\nlogger.close()\nprint(f\"Logged {logger.event_count} events\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fad946e4"
  },
  {
    "id": "hil_data_logging_4_8462e84c",
    "file": "docs\\reference\\interfaces\\hil_data_logging.md",
    "index": 4,
    "code": "from src.interfaces.hil.data_logging import MultiLogger\n\n# Log to multiple formats simultaneously\nlogger = MultiLogger(\n    outputs=[\n        (\"hil_data.csv\", \"csv\"),\n        (\"hil_data.h5\", \"hdf5\"),\n        (\"hil_data.parquet\", \"parquet\")\n    ]\n)\n\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n\n    # Log to all formats\n    logger.log_all(time=t, state=state, control=control)\n\nlogger.close_all()",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8462e84c"
  },
  {
    "id": "hil_data_logging_5_373b7e1d",
    "file": "docs\\reference\\interfaces\\hil_data_logging.md",
    "index": 5,
    "code": "from src.interfaces.hil.data_logging import DataLogger, Replay\n\n# Log data\nlogger = DataLogger(\"original.csv\", format=\"csv\")\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n    logger.log(time=t, state=state, control=control)\nlogger.close()\n\n# Replay simulation\nreplay = Replay(\"original.csv\")\n\nfor entry in replay:\n    t = entry[\"time\"]\n    state = entry[\"state\"]\n    control = entry[\"control\"]\n\n    # Reconstruct dynamics\n    reconstructed_state = plant.step(control)\n\n    # Compare original vs reconstructed\n    error = np.linalg.norm(state - reconstructed_state)\n    if error > 0.01:\n        print(f\"Reconstruction error at t={t:.2f}: {error:.4f}\")\n\nprint(\"Replay complete\")",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "373b7e1d"
  },
  {
    "id": "hil_enhanced_hil_1_0ec3cde5",
    "file": "docs\\reference\\interfaces\\hil_enhanced_hil.md",
    "index": 1,
    "code": "from src.interfaces.hil.enhanced_hil import ParameterSweep\n\n# Parameter sweep\nsweep = ParameterSweep()\n\n# Define parameter ranges\nsweep.add_parameter(\"mass_cart\", values=np.linspace(0.8, 1.2, 5))\nsweep.add_parameter(\"length_1\", values=np.linspace(0.3, 0.5, 5))\n\n# Run sweep\nresults = sweep.run()\n\n# Analyze sensitivity\nfor param, result in results.items():\n    print(f\"{param}: sensitivity = {result.sensitivity:.4f}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0ec3cde5"
  },
  {
    "id": "hil_enhanced_hil_2_00d934e5",
    "file": "docs\\reference\\interfaces\\hil_enhanced_hil.md",
    "index": 2,
    "code": "from src.interfaces.hil.enhanced_hil import DisturbanceInjector\n\n# Create disturbance injector\ninjector = DisturbanceInjector()\n\n# Add sinusoidal disturbance\ninjector.add_disturbance(\n    type=\"sinusoidal\",\n    amplitude=5.0,\n    frequency=1.0,\n    start_time=2.0\n)\n\n# Simulate with disturbance\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n\n    # Add disturbance\n    disturbed_control = injector.apply(control, t)\n\n    plant.step(disturbed_control)",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "00d934e5"
  },
  {
    "id": "hil_enhanced_hil_3_984b21b9",
    "file": "docs\\reference\\interfaces\\hil_enhanced_hil.md",
    "index": 3,
    "code": "from src.interfaces.hil.enhanced_hil import MultiFidelitySimulator\n\n# Multi-fidelity simulator\nsimulator = MultiFidelitySimulator()\n\n# Define fidelity levels\nsimulator.add_model(\"low\", SimplifiedDynamics())\nsimulator.add_model(\"medium\", FullDynamics(accuracy=\"medium\"))\nsimulator.add_model(\"high\", FullDynamics(accuracy=\"high\"))\n\n# Run with adaptive fidelity\nresult = simulator.run_adaptive(\n    initial_fidelity=\"low\",\n    accuracy_target=1e-3,\n    max_cost=100.0\n)\n\nprint(f\"Final fidelity: {result.final_fidelity}\")\nprint(f\"Total cost: {result.total_cost:.1f}\")\nprint(f\"Accuracy achieved: {result.accuracy:.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "984b21b9"
  },
  {
    "id": "hil_enhanced_hil_4_75febf3b",
    "file": "docs\\reference\\interfaces\\hil_enhanced_hil.md",
    "index": 4,
    "code": "from src.interfaces.hil.enhanced_hil import HardwareEmulator\n\n# Hardware emulator\nemulator = HardwareEmulator()\n\n# Configure actuator model\nemulator.set_actuator_model(\n    bandwidth=50.0,  # 50 Hz bandwidth\n    saturation=100.0,\n    delay=0.01  # 10 ms delay\n)\n\n# Configure sensor model\nemulator.set_sensor_model(\n    noise_std=0.01,\n    bias=0.005,\n    dropout_rate=0.01\n)\n\n# Simulate with hardware emulation\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n\n    # Emulate sensor\n    measured_state = emulator.sensor(state)\n\n    # Compute control\n    control = controller.compute(measured_state)\n\n    # Emulate actuator\n    actual_control = emulator.actuator(control)\n\n    plant.step(actual_control)",
    "lines": 33,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75febf3b"
  },
  {
    "id": "hil_enhanced_hil_5_b5716ca4",
    "file": "docs\\reference\\interfaces\\hil_enhanced_hil.md",
    "index": 5,
    "code": "from src.interfaces.hil.enhanced_hil import PerformanceProfiler\n\n# Performance profiler\nprofiler = PerformanceProfiler()\n\n# Profile simulation\nprofiler.start()\n\nfor t in np.arange(0, 10, 0.01):\n    with profiler.section(\"dynamics\"):\n        state = plant.get_state()\n\n    with profiler.section(\"control\"):\n        control = controller.compute(state)\n\n    with profiler.section(\"communication\"):\n        client.send_control(control)\n\nprofiler.stop()\n\n# Report profiling results\nreport = profiler.generate_report()\nprint(report.to_string())\n\n# Identify bottlenecks\nfor section, time in report.sorted_sections():\n    print(f\"{section}: {time:.2f} ms ({report.percentage(section):.1f}%)\")",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5716ca4"
  },
  {
    "id": "hil_fault_injection_1_763deb8b",
    "file": "docs\\reference\\interfaces\\hil_fault_injection.md",
    "index": 1,
    "code": "from src.interfaces.hil.fault_injection import FaultInjector, FaultType\n\n# Create fault injector\ninjector = FaultInjector()\n\n# Add sensor bias fault\ninjector.add_fault(\n    fault_type=FaultType.SENSOR_BIAS,\n    target=\"theta1\",  # First pendulum angle\n    bias=0.1,  # 0.1 radian bias\n    start_time=2.0,  # Start at 2 seconds\n    duration=3.0  # Last for 3 seconds\n)\n\n# Apply fault during simulation\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    faulty_state = injector.apply(state, t)\n    control = controller.compute(faulty_state)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "763deb8b"
  },
  {
    "id": "hil_fault_injection_2_55e800ad",
    "file": "docs\\reference\\interfaces\\hil_fault_injection.md",
    "index": 2,
    "code": "from src.interfaces.hil.fault_injection import FaultInjector, FaultType\n\n# Actuator fault\ninjector = FaultInjector()\n\ninjector.add_fault(\n    fault_type=FaultType.ACTUATOR_SATURATION,\n    target=\"control\",\n    saturation_min=-50.0,  # Reduced from -100\n    saturation_max=50.0,   # Reduced from +100\n    start_time=5.0\n)\n\n# Simulation with fault\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    control = controller.compute(state)\n    faulty_control = injector.apply(control, t)\n    plant.step(faulty_control)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "55e800ad"
  },
  {
    "id": "hil_fault_injection_3_cf58cd67",
    "file": "docs\\reference\\interfaces\\hil_fault_injection.md",
    "index": 3,
    "code": "from src.interfaces.hil.fault_injection import FaultInjector, FaultType\n\n# Packet loss fault\ninjector = FaultInjector()\n\ninjector.add_fault(\n    fault_type=FaultType.PACKET_LOSS,\n    loss_probability=0.2,  # 20% packet loss\n    start_time=3.0,\n    duration=5.0\n)\n\n# HIL with communication faults\nfor t in np.arange(0, 10, 0.01):\n    # Request state from server\n    state_msg = client.request_state()\n\n    # Apply packet loss\n    if injector.check_packet_loss(t):\n        # Use last known state\n        state = last_state\n    else:\n        state = state_msg.state\n\n    control = controller.compute(state)\n    client.send_control(control)\n    last_state = state",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf58cd67"
  },
  {
    "id": "hil_fault_injection_4_f33fb4d5",
    "file": "docs\\reference\\interfaces\\hil_fault_injection.md",
    "index": 4,
    "code": "from src.interfaces.hil.fault_injection import FaultInjector\n\n# Multiple faults\ninjector = FaultInjector()\n\n# Sensor noise\ninjector.add_fault(\n    fault_type=FaultType.SENSOR_NOISE,\n    target=\"theta1\",\n    noise_std=0.05,\n    start_time=0.0\n)\n\n# Actuator delay\ninjector.add_fault(\n    fault_type=FaultType.ACTUATOR_DELAY,\n    delay_time=0.05,  # 50 ms delay\n    start_time=4.0\n)\n\n# Communication latency spike\ninjector.add_fault(\n    fault_type=FaultType.LATENCY_SPIKE,\n    spike_probability=0.1,\n    spike_duration=0.1,\n    start_time=2.0\n)\n\n# Run with all faults\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    faulty_state = injector.apply_all(state, t)\n    control = controller.compute(faulty_state)\n    faulty_control = injector.apply_all(control, t)\n    plant.step(faulty_control)",
    "lines": 35,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f33fb4d5"
  },
  {
    "id": "hil_fault_injection_5_6d8ac33a",
    "file": "docs\\reference\\interfaces\\hil_fault_injection.md",
    "index": 5,
    "code": "from src.interfaces.hil.fault_injection import FaultInjector\nfrom src.analysis.fault_detection import FDISystem\n\n# Create fault injector and detector\ninjector = FaultInjector()\nfdi = FDISystem(threshold=0.15)\n\n# Inject sensor bias\ninjector.add_fault(\n    fault_type=FaultType.SENSOR_BIAS,\n    target=\"theta2\",\n    bias=0.2,\n    start_time=5.0\n)\n\n# Track detection performance\ndetection_time = None\nfalse_positives = 0\n\nfor t in np.arange(0, 10, 0.01):\n    state = plant.get_state()\n    faulty_state = injector.apply(state, t)\n\n    # Check fault detection\n    fault_detected = fdi.check(faulty_state)\n\n    if fault_detected and detection_time is None and t >= 5.0:\n        detection_time = t\n        print(f\"Fault detected at t={t:.2f}s (actual fault at 5.0s)\")\n\n    if fault_detected and t < 5.0:\n        false_positives += 1\n\n# Report results\nprint(f\"Detection delay: {detection_time - 5.0:.3f}s\")\nprint(f\"False positives: {false_positives}\")",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6d8ac33a"
  },
  {
    "id": "hil_plant_server_1_1a341be2",
    "file": "docs\\reference\\interfaces\\hil_plant_server.md",
    "index": 1,
    "code": "from src.interfaces.hil import PlantServer\nfrom src.config import load_config\n\n# Load configuration\nconfig = load_config(\"config.yaml\")\n\n# Initialize server\nserver = PlantServer(\n    cfg=config,\n    bind_addr=(\"127.0.0.1\", 5555),\n    dt=0.01,  # 10 ms control period\n    extra_latency_ms=5,  # 5 ms network latency\n    sensor_noise_std=0.01,  # 1% sensor noise\n    max_steps=5000  # 50 seconds simulation\n)\n\n# Start server (blocks until client connects)\nserver.start()\n\n# Server runs until client disconnects or max_steps reached\nserver.close()",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1a341be2"
  },
  {
    "id": "hil_plant_server_2_aad1acd0",
    "file": "docs\\reference\\interfaces\\hil_plant_server.md",
    "index": 2,
    "code": "from src.interfaces.hil import PlantServer\nfrom src.plant.models.full import FullDIPDynamics\n\n# Create high-fidelity dynamics model\ndynamics = FullDIPDynamics(\n    config=config,\n    enable_monitoring=True,\n    enable_validation=True\n)\n\n# Server with custom dynamics\nserver = PlantServer(\n    cfg=config,\n    bind_addr=(\"0.0.0.0\", 5555),  # Listen on all interfaces\n    dt=0.01\n)\n\n# Override dynamics model\nserver._dynamics = dynamics\n\nserver.start()",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aad1acd0"
  },
  {
    "id": "hil_plant_server_3_932a1c2a",
    "file": "docs\\reference\\interfaces\\hil_plant_server.md",
    "index": 3,
    "code": "from threading import Thread\nfrom src.interfaces.hil import PlantServer\n\ndef run_server(port, max_steps):\n    server = PlantServer(\n        cfg=config,\n        bind_addr=(\"127.0.0.1\", port),\n        dt=0.01,\n        max_steps=max_steps\n    )\n    server.start()\n    server.close()\n\n# Run multiple servers for parallel testing\nthreads = []\nfor port in [5555, 5556, 5557]:\n    t = Thread(target=run_server, args=(port, 5000))\n    t.start()\n    threads.append(t)\n\n# Wait for all servers to complete\nfor t in threads:\n    t.join()\n\nprint(\"All parallel tests complete\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "932a1c2a"
  },
  {
    "id": "hil_plant_server_4_6cea7396",
    "file": "docs\\reference\\interfaces\\hil_plant_server.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.interfaces.hil import PlantServer\nimport logging\n\n# Configure detailed logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='hil_server.log'\n)\n\n# Server with logging\nserver = PlantServer(\n    cfg=config,\n    bind_addr=(\"127.0.0.1\", 5555),\n    dt=0.01,\n    extra_latency_ms=5,\n    sensor_noise_std=0.01\n)\n\n# Enable detailed monitoring\nlogger = logging.getLogger('HIL.PlantServer')\nlogger.info(\"Starting HIL plant server...\")\n\ntry:\n    server.start()\nexcept Exception as e:\n    logger.error(f\"Server error: {e}\")\nfinally:\n    server.close()\n    logger.info(\"Server shutdown complete\")",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6cea7396"
  },
  {
    "id": "hil_plant_server_5_21a635f0",
    "file": "docs\\reference\\interfaces\\hil_plant_server.md",
    "index": 5,
    "code": "from src.interfaces.hil import PlantServer\nimport time\nimport psutil\n\n# Metrics collection\nmetrics = {\n    'step_times': [],\n    'memory_usage': [],\n    'cpu_usage': []\n}\n\n# Custom server with profiling\nserver = PlantServer(cfg=config, bind_addr=(\"127.0.0.1\", 5555), dt=0.01)\n\n# Override step function for profiling\noriginal_step = server._step\ndef profiled_step(control):\n    start = time.time()\n    result = original_step(control)\n    metrics['step_times'].append(time.time() - start)\n    metrics['memory_usage'].append(psutil.Process().memory_info().rss / 1024**2)\n    metrics['cpu_usage'].append(psutil.cpu_percent())\n    return result\n\nserver._step = profiled_step\nserver.start()\nserver.close()\n\n# Analyze performance\nprint(f\"Mean step time: {np.mean(metrics['step_times']):.4f} s\")\nprint(f\"Max memory: {max(metrics['memory_usage']):.1f} MB\")\nprint(f\"Mean CPU: {np.mean(metrics['cpu_usage']):.1f}%\")",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "21a635f0"
  },
  {
    "id": "hil_real_time_sync_1_572fda5e",
    "file": "docs\\reference\\interfaces\\hil_real_time_sync.md",
    "index": 1,
    "code": "from src.interfaces.hil.real_time_sync import RealTimeSync\n\n# Initialize synchronizer\nsync = RealTimeSync(\n    processes=[\"plant\", \"controller\"],\n    target_dt=0.01,  # 10 ms control period\n    tolerance=0.001  # 1 ms tolerance\n)\n\n# Synchronize processes\nsync.synchronize()\n\n# Plant and controller now running at same rate",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "572fda5e"
  },
  {
    "id": "hil_real_time_sync_2_07b887fe",
    "file": "docs\\reference\\interfaces\\hil_real_time_sync.md",
    "index": 2,
    "code": "from src.interfaces.hil.real_time_sync import ClockSync\n\n# Create clock synchronizer\nclock_sync = ClockSync()\n\n# Client-server clock sync\ndef client_sync():\n    t1 = time.time()\n    # Send to server\n    t2, t3 = server.get_timestamps()\n    t4 = time.time()\n\n    # Compute offset\n    offset = clock_sync.compute_offset(t1, t2, t3, t4)\n    print(f\"Clock offset: {offset * 1000:.2f} ms\")\n\nclient_sync()",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07b887fe"
  },
  {
    "id": "hil_real_time_sync_3_33f9c6f7",
    "file": "docs\\reference\\interfaces\\hil_real_time_sync.md",
    "index": 3,
    "code": "from src.interfaces.hil.real_time_sync import BarrierSync\nfrom threading import Thread\n\n# Create barrier\nbarrier = BarrierSync(n_processes=2)\n\ndef plant_process():\n    for step in range(1000):\n        # Compute dynamics\n        plant.step()\n        # Wait for controller\n        barrier.wait()\n\ndef controller_process():\n    for step in range(1000):\n        # Compute control\n        controller.compute()\n        # Wait for plant\n        barrier.wait()\n\n# Run synchronized\nt1 = Thread(target=plant_process)\nt2 = Thread(target=controller_process)\nt1.start()\nt2.start()\nt1.join()\nt2.join()",
    "lines": 27,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33f9c6f7"
  },
  {
    "id": "hil_real_time_sync_4_8bf785dd",
    "file": "docs\\reference\\interfaces\\hil_real_time_sync.md",
    "index": 4,
    "code": "from src.interfaces.hil.real_time_sync import AdaptiveSync\n\n# Adaptive synchronizer\nsync = AdaptiveSync(\n    kp=0.1,  # Proportional gain\n    target_rate=100.0  # 100 Hz\n)\n\n# Plant loop with adaptive timing\nplant_time = 0.0\nfor step in range(10000):\n    start = time.time()\n\n    # Step dynamics\n    plant.step(dt_adjusted)\n\n    # Measure actual time\n    actual_dt = time.time() - start\n\n    # Adjust for next iteration\n    dt_adjusted = sync.adjust_rate(actual_dt, step)\n\n    plant_time += dt_adjusted",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8bf785dd"
  },
  {
    "id": "hil_real_time_sync_5_5955b02e",
    "file": "docs\\reference\\interfaces\\hil_real_time_sync.md",
    "index": 5,
    "code": "from src.interfaces.hil.real_time_sync import DeadlineMonitor\n\n# Deadline monitor\nmonitor = DeadlineMonitor(\n    deadline=0.01,  # 10 ms deadline\n    tolerance=0.001  # 1 ms tolerance\n)\n\n# Control loop with deadline checking\nfor step in range(5000):\n    start = time.time()\n\n    # Compute control\n    control = controller.compute(state)\n\n    # Check deadline\n    elapsed = time.time() - start\n    if not monitor.check_deadline(elapsed):\n        print(f\"Deadline violation at step {step}: {elapsed*1000:.2f} ms\")\n\n# Report violations\nprint(f\"Total violations: {monitor.violation_count}\")\nprint(f\"Violation rate: {monitor.violation_rate * 100:.2f}%\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5955b02e"
  },
  {
    "id": "hil_simulation_bridge_1_2af8abfe",
    "file": "docs\\reference\\interfaces\\hil_simulation_bridge.md",
    "index": 1,
    "code": "from src.interfaces.hil.simulation_bridge import SimulationBridge\n\n# Initialize bridge\nbridge = SimulationBridge(\n    server_addr=(\"127.0.0.1\", 5555),\n    client_addr=(\"127.0.0.1\", 6666),\n    protocol=\"tcp\"\n)\n\n# Start bridge\nbridge.start()\n\n# Bridge runs until shutdown\nbridge.stop()",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2af8abfe"
  },
  {
    "id": "hil_simulation_bridge_2_b1e3835a",
    "file": "docs\\reference\\interfaces\\hil_simulation_bridge.md",
    "index": 2,
    "code": "from src.interfaces.hil.simulation_bridge import SimulationBridge\n\n# TCP server, UDP client\nbridge = SimulationBridge(\n    server_addr=(\"127.0.0.1\", 5555),\n    client_addr=(\"127.0.0.1\", 6666),\n    server_protocol=\"tcp\",\n    client_protocol=\"udp\"\n)\n\nbridge.start()",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b1e3835a"
  },
  {
    "id": "hil_simulation_bridge_3_ece8a6c5",
    "file": "docs\\reference\\interfaces\\hil_simulation_bridge.md",
    "index": 3,
    "code": "from src.interfaces.hil.simulation_bridge import SimulationBridge\nimport numpy as np\n\n# Bridge with interpolation\nbridge = SimulationBridge(\n    server_addr=(\"127.0.0.1\", 5555),\n    client_addr=(\"127.0.0.1\", 6666)\n)\n\n# Enable state interpolation\nbridge.enable_interpolation(method=\"linear\")\n\n# Custom interpolation\ndef custom_interpolator(state_buffer, t_req):\n    # Find surrounding states\n    t_prev, x_prev = state_buffer.get_before(t_req)\n    t_next, x_next = state_buffer.get_after(t_req)\n\n    # Linear interpolation\n    alpha = (t_req - t_prev) / (t_next - t_prev)\n    x_interp = x_prev + alpha * (x_next - x_prev)\n\n    return x_interp\n\nbridge.set_interpolator(custom_interpolator)\nbridge.start()",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ece8a6c5"
  },
  {
    "id": "hil_simulation_bridge_4_b52ed7eb",
    "file": "docs\\reference\\interfaces\\hil_simulation_bridge.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.interfaces.hil.simulation_bridge import SimulationBridge\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger('SimulationBridge')\n\n# Bridge with fault tolerance\nbridge = SimulationBridge(\n    server_addr=(\"127.0.0.1\", 5555),\n    client_addr=(\"127.0.0.1\", 6666),\n    heartbeat_interval=1.0,  # 1 second heartbeat\n    reconnect_attempts=5\n)\n\n# Monitor health\ndef health_callback(status):\n    if status == \"TIMEOUT\":\n        logger.warning(\"Connection timeout detected\")\n    elif status == \"RECONNECTING\":\n        logger.info(\"Attempting reconnection...\")\n    elif status == \"OK\":\n        logger.info(\"Connection healthy\")\n\nbridge.set_health_callback(health_callback)\nbridge.start()",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b52ed7eb"
  },
  {
    "id": "hil_simulation_bridge_5_8f6e8063",
    "file": "docs\\reference\\interfaces\\hil_simulation_bridge.md",
    "index": 5,
    "code": "from src.interfaces.hil.simulation_bridge import SimulationBridge\nimport time\n\n# Bridge with metrics\nbridge = SimulationBridge(\n    server_addr=(\"127.0.0.1\", 5555),\n    client_addr=(\"127.0.0.1\", 6666)\n)\n\n# Metrics collection\nmetrics = {\n    'throughput': [],\n    'latency': [],\n    'packet_loss': 0\n}\n\n# Override message handler for monitoring\noriginal_forward = bridge._forward_message\n\ndef monitored_forward(msg, direction):\n    start = time.time()\n    try:\n        result = original_forward(msg, direction)\n        latency = (time.time() - start) * 1000\n        metrics['latency'].append(latency)\n        return result\n    except Exception as e:\n        metrics['packet_loss'] += 1\n        raise\n\nbridge._forward_message = monitored_forward\nbridge.start()\n\n# Report metrics\nprint(f\"Mean latency: {np.mean(metrics['latency']):.2f} ms\")\nprint(f\"Packet loss: {metrics['packet_loss']} packets\")",
    "lines": 36,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f6e8063"
  },
  {
    "id": "hil_test_automation_1_8dd6eb28",
    "file": "docs\\reference\\interfaces\\hil_test_automation.md",
    "index": 1,
    "code": "from src.interfaces.hil.test_automation import TestSuite\n\n# Create test suite\nsuite = TestSuite(name=\"HIL_Controller_Tests\")\n\n# Define test cases\nsuite.add_test(\n    name=\"stability_test\",\n    initial_state=[0.0, 0.1, -0.05, 0.0, 0.0, 0.0],\n    duration=5.0,\n    pass_criteria={\"max_angle\": 0.2, \"settling_time\": 3.0}\n)\n\nsuite.add_test(\n    name=\"disturbance_rejection\",\n    initial_state=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    disturbance={\"type\": \"step\", \"magnitude\": 10.0, \"time\": 2.0},\n    pass_criteria={\"recovery_time\": 2.0}\n)\n\n# Run all tests\nresults = suite.run_all()\n\n# Report\nsuite.print_report()",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dd6eb28"
  },
  {
    "id": "hil_test_automation_2_1bd6b2ac",
    "file": "docs\\reference\\interfaces\\hil_test_automation.md",
    "index": 2,
    "code": "from src.interfaces.hil.test_automation import GridTestGenerator\n\n# Generate test cases on grid\ngenerator = GridTestGenerator()\n\n# Define parameter ranges\ntheta1_values = np.linspace(-0.2, 0.2, 5)\ntheta2_values = np.linspace(-0.2, 0.2, 5)\n\ntest_cases = generator.generate(\n    theta1=theta1_values,\n    theta2=theta2_values,\n    x=[0.0],  # Fixed cart position\n    velocities=[0.0, 0.0, 0.0]  # Zero initial velocity\n)\n\nprint(f\"Generated {len(test_cases)} test cases\")\n\n# Run all generated tests\nfor i, test_case in enumerate(test_cases):\n    result = run_hil_simulation(initial_state=test_case)\n    print(f\"Test {i+1}: {'PASS' if result.stable else 'FAIL'}\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1bd6b2ac"
  },
  {
    "id": "hil_test_automation_3_25a4f962",
    "file": "docs\\reference\\interfaces\\hil_test_automation.md",
    "index": 3,
    "code": "from src.interfaces.hil.test_automation import MonteCarloTester\n\n# Monte Carlo test generator\ntester = MonteCarloTester(n_trials=100)\n\n# Define parameter distributions\ntester.set_distribution(\n    \"theta1\", distribution=\"normal\", mean=0.0, std=0.1\n)\ntester.set_distribution(\n    \"theta2\", distribution=\"normal\", mean=0.0, std=0.1\n)\ntester.set_distribution(\n    \"noise\", distribution=\"uniform\", low=0.0, high=0.05\n)\n\n# Run Monte Carlo tests\nresults = tester.run()\n\n# Analyze results\nsuccess_rate = sum(r.passed for r in results) / len(results)\nprint(f\"Success rate: {success_rate * 100:.1f}%\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25a4f962"
  },
  {
    "id": "hil_test_automation_4_faef4cec",
    "file": "docs\\reference\\interfaces\\hil_test_automation.md",
    "index": 4,
    "code": "from src.interfaces.hil.test_automation import CITestRunner\n\n# CI test runner\nci_runner = CITestRunner(\n    test_suite_path=\"tests/hil_tests.yaml\",\n    report_path=\"ci_report.json\"\n)\n\n# Run tests\nresults = ci_runner.run()\n\n# Check for regressions\nif results.has_regressions():\n    print(\"REGRESSION DETECTED!\")\n    for test in results.regressions:\n        print(f\"  {test.name}: {test.baseline_time:.2f}s -> {test.current_time:.2f}s\")\n    exit(1)\n\nprint(\"All tests passed, no regressions\")\nexit(0)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "faef4cec"
  },
  {
    "id": "hil_test_automation_5_c574f976",
    "file": "docs\\reference\\interfaces\\hil_test_automation.md",
    "index": 5,
    "code": "from src.interfaces.hil.test_automation import AdaptiveTester\n\n# Adaptive tester\ntester = AdaptiveTester(\n    initial_difficulty=0.5,\n    adjustment_rate=0.1\n)\n\n# Run adaptive tests\nfor i in range(20):\n    test_case = tester.generate_test()\n    result = run_hil_simulation(test_case)\n\n    # Adjust difficulty based on result\n    tester.update(result.passed)\n\n    print(f\"Test {i+1}: difficulty={tester.current_difficulty:.2f}, \"\n          f\"result={'PASS' if result.passed else 'FAIL'}\")\n\n# Report final difficulty\nprint(f\"Final difficulty: {tester.current_difficulty:.2f}\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c574f976"
  },
  {
    "id": "hil___init___1_efa2e6c0",
    "file": "docs\\reference\\interfaces\\hil___init__.md",
    "index": 1,
    "code": "from src.interfaces import hil\n\n# Complete HIL system setup\nconfig = hil.load_config(\"config.yaml\")\n\n# Start plant server\nserver = hil.PlantServer(\n    cfg=config,\n    bind_addr=(\"127.0.0.1\", 5555),\n    dt=0.01\n)\n\n# Start controller client\nclient = hil.HILControllerClient(\n    cfg=config,\n    plant_addr=(\"127.0.0.1\", 5555),\n    bind_addr=(\"127.0.0.1\", 0),\n    dt=0.01,\n    steps=5000\n)\n\n# Run HIL simulation\nserver.start()  # Blocks until client connects",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "efa2e6c0"
  },
  {
    "id": "hil___init___2_e93f3907",
    "file": "docs\\reference\\interfaces\\hil___init__.md",
    "index": 2,
    "code": "from src.interfaces import hil\nfrom threading import Thread\n\n# Server on one thread\ndef run_server():\n    server = hil.PlantServer(\n        cfg=config,\n        bind_addr=(\"0.0.0.0\", 5555),\n        dt=0.01\n    )\n    server.start()\n\n# Client on another thread\ndef run_client():\n    time.sleep(1.0)  # Wait for server to start\n    client = hil.HILControllerClient(\n        cfg=config,\n        plant_addr=(\"127.0.0.1\", 5555),\n        bind_addr=(\"127.0.0.1\", 0),\n        dt=0.01,\n        steps=5000\n    )\n    client.run()\n\n# Run distributed\nt1 = Thread(target=run_server)\nt2 = Thread(target=run_client)\nt1.start()\nt2.start()\nt1.join()\nt2.join()",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e93f3907"
  },
  {
    "id": "hil___init___3_3d8278d3",
    "file": "docs\\reference\\interfaces\\hil___init__.md",
    "index": 3,
    "code": "from src.interfaces import hil\n\n# Setup with fault injection\nserver = hil.PlantServer(cfg=config, bind_addr=(\"127.0.0.1\", 5555), dt=0.01)\n\n# Add fault injector\ninjector = hil.FaultInjector()\ninjector.add_fault(\n    fault_type=hil.FaultType.SENSOR_BIAS,\n    target=\"theta1\",\n    bias=0.1,\n    start_time=5.0\n)\n\n# Attach to server\nserver.set_fault_injector(injector)\n\nserver.start()",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3d8278d3"
  },
  {
    "id": "hil___init___4_2861363f",
    "file": "docs\\reference\\interfaces\\hil___init__.md",
    "index": 4,
    "code": "from src.interfaces import hil\n\n# Setup with logging\nserver = hil.PlantServer(cfg=config, bind_addr=(\"127.0.0.1\", 5555), dt=0.01)\nclient = hil.HILControllerClient(\n    cfg=config,\n    plant_addr=(\"127.0.0.1\", 5555),\n    bind_addr=(\"127.0.0.1\", 0),\n    dt=0.01,\n    steps=5000\n)\n\n# Add logger\nlogger = hil.DataLogger(\"hil_results.h5\", format=\"hdf5\")\n\n# Attach to client\nclient.set_logger(logger)\n\n# Run with logging\nserver.start()",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2861363f"
  },
  {
    "id": "hil___init___5_3c3b2b5a",
    "file": "docs\\reference\\interfaces\\hil___init__.md",
    "index": 5,
    "code": "from src.interfaces import hil\n\n# Create test suite\nsuite = hil.TestSuite(name=\"Controller_Validation\")\n\n# Add test cases\nsuite.add_test(\n    name=\"stability\",\n    initial_state=[0.0, 0.1, -0.05, 0.0, 0.0, 0.0],\n    pass_criteria={\"settling_time\": 3.0}\n)\n\nsuite.add_test(\n    name=\"robustness\",\n    initial_state=[0.0, 0.2, -0.1, 0.0, 0.0, 0.0],\n    disturbance={\"type\": \"step\", \"magnitude\": 10.0},\n    pass_criteria={\"recovery_time\": 2.0}\n)\n\n# Run all tests\nresults = suite.run_all()\n\n# Generate report\nsuite.save_report(\"test_report.json\")\nprint(f\"Tests passed: {results.pass_count}/{results.total_count}\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3c3b2b5a"
  },
  {
    "id": "algorithms_base_1_0bc86293",
    "file": "docs\\reference\\optimization\\algorithms_base.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "algorithms_base_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_base.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_base_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_base.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_base_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_base.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_base_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_base.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_evolutionary_differential_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_differential.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_evolutionary_differential_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_differential.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_evolutionary_differential_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_differential.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_evolutionary_differential_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_differential.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_evolutionary_differential_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_differential.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_evolutionary_genetic_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_genetic.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_evolutionary_genetic_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_genetic.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_evolutionary_genetic_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_genetic.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_evolutionary_genetic_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_genetic.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_evolutionary_genetic_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_evolutionary_genetic.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_gradient_based_bfgs_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_bfgs.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_gradient_based_bfgs_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_bfgs.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_gradient_based_bfgs_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_bfgs.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_gradient_based_bfgs_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_bfgs.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_gradient_based_bfgs_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_bfgs.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_gradient_based_nelder_mead_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_nelder_mead.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_gradient_based_nelder_mead_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_nelder_mead.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_gradient_based_nelder_mead_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_nelder_mead.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_gradient_based_nelder_mead_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_nelder_mead.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_gradient_based_nelder_mead_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_gradient_based_nelder_mead.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_memory_efficient_pso_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_memory_efficient_pso.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_memory_efficient_pso_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_memory_efficient_pso.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_memory_efficient_pso_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_memory_efficient_pso.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_memory_efficient_pso_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_memory_efficient_pso.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_memory_efficient_pso_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_memory_efficient_pso.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_multi_objective_pso_1_7ca4a201",
    "file": "docs\\reference\\optimization\\algorithms_multi_objective_pso.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "algorithms_multi_objective_pso_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_multi_objective_pso.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_multi_objective_pso_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_multi_objective_pso.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_multi_objective_pso_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_multi_objective_pso.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_multi_objective_pso_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_multi_objective_pso.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_pso_optimizer_1_0bc86293",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "algorithms_pso_optimizer_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_pso_optimizer_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_pso_optimizer_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_pso_optimizer_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "algorithms_pso_optimizer_6_8322fe5d",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 6,
    "code": "from src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.controllers.factory import create_smc_for_pso, SMCType\n\n# Define multi-objective cost function\ndef multi_objective_cost(gains):\n    controller = create_smc_for_pso(SMCType.HYBRID, gains)\n    result = simulate(controller, duration=10.0)\n\n    # Combine objectives with weights\n    tracking_error = np.mean(np.abs(result.states[:, :2]))  # Angles\n    control_effort = np.mean(np.abs(result.control))\n    chattering = np.std(np.diff(result.control))\n\n    return 0.6 * tracking_error + 0.3 * control_effort + 0.1 * chattering\n\n# Configure PSO with adaptive parameters\npso = PSOTuner(\n    controller_factory=lambda g: create_smc_for_pso(SMCType.HYBRID, g),\n    bounds=([1.0]*4, [50.0]*4),  # Hybrid has 4 gains\n    n_particles=40,\n    max_iter=100,\n    w=0.7,           # Inertia weight\n    c1=1.5,          # Cognitive coefficient\n    c2=1.5           # Social coefficient\n)\n\nbest_gains, best_cost = pso.optimize()\nprint(f\"Optimal gains: {best_gains}, Cost: {best_cost:.4f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8322fe5d"
  },
  {
    "id": "algorithms_pso_optimizer_7_c66e4768",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 7,
    "code": "import matplotlib.pyplot as plt\n\n# Track convergence history\nconvergence_history = []\n\ndef convergence_callback(iteration, global_best_cost):\n    convergence_history.append(global_best_cost)\n    print(f\"Iteration {iteration}: Best cost = {global_best_cost:.6f}\")\n\npso = PSOTuner(\n    controller_factory=lambda g: create_smc_for_pso(SMCType.CLASSICAL, g),\n    bounds=(bounds_lower, bounds_upper),\n    callback=convergence_callback\n)\n\nbest_gains, _ = pso.optimize()\n\n# Plot convergence\nplt.plot(convergence_history)\nplt.xlabel('Iteration')\nplt.ylabel('Best Cost')\nplt.title('PSO Convergence Analysis')\nplt.grid(True)\nplt.show()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c66e4768"
  },
  {
    "id": "algorithms_pso_optimizer_8_5ff4e370",
    "file": "docs\\reference\\optimization\\algorithms_pso_optimizer.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Optimize for robustness across parameter uncertainty\ndef robust_cost(gains):\n    controller_factory = lambda: create_smc_for_pso(SMCType.ADAPTIVE, gains)\n\n    # Test across multiple scenarios\n    costs = []\n    for mass_variation in [0.8, 1.0, 1.2]:  # \u00b120% mass uncertainty\n        dynamics = SimplifiedDynamics(cart_mass=mass_variation * 1.0)\n        result = simulate(controller_factory(), dynamics, duration=10.0)\n        costs.append(compute_ISE(result.states))\n\n    # Return worst-case cost (robust optimization)\n    return max(costs)\n\npso = PSOTuner(\n    controller_factory=lambda g: None,  # Not used, cost computes internally\n    bounds=([0.1]*5, [100.0]*5),  # Adaptive SMC: 5 gains\n    fitness_function=robust_cost,\n    n_particles=50,\n    max_iter=150\n)\n\nrobust_gains, worst_case_cost = pso.optimize()",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5ff4e370"
  },
  {
    "id": "algorithms_swarm_pso_1_0bc86293",
    "file": "docs\\reference\\optimization\\algorithms_swarm_pso.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "algorithms_swarm_pso_2_e757136e",
    "file": "docs\\reference\\optimization\\algorithms_swarm_pso.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "algorithms_swarm_pso_3_8a586c1d",
    "file": "docs\\reference\\optimization\\algorithms_swarm_pso.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "algorithms_swarm_pso_4_1f439055",
    "file": "docs\\reference\\optimization\\algorithms_swarm_pso.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "algorithms_swarm_pso_5_c37800b0",
    "file": "docs\\reference\\optimization\\algorithms_swarm_pso.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_interfaces_1_bfdec01d",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nclass OptimizationAlgorithm(Protocol):\n    def optimize(self, problem: OptimizationProblem) -> OptimizationResult:\n        ...",
    "lines": 6,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfdec01d"
  },
  {
    "id": "core_interfaces_2_0bc86293",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 2,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "core_interfaces_3_e757136e",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 3,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "core_interfaces_4_8a586c1d",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 4,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "core_interfaces_5_1f439055",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 5,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "core_interfaces_6_c37800b0",
    "file": "docs\\reference\\optimization\\core_interfaces.md",
    "index": 6,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_parameters_1_0bc86293",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "core_parameters_2_e757136e",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "core_parameters_3_8a586c1d",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "core_parameters_4_1f439055",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "core_parameters_5_c37800b0",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_parameters_6_0bc86293",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 6,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "core_parameters_7_e757136e",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 7,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "core_parameters_8_8a586c1d",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 8,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "core_parameters_9_1f439055",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 9,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "core_parameters_10_c37800b0",
    "file": "docs\\reference\\optimization\\core_parameters.md",
    "index": 10,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_problem_1_0bc86293",
    "file": "docs\\reference\\optimization\\core_problem.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "core_problem_2_e757136e",
    "file": "docs\\reference\\optimization\\core_problem.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "core_problem_3_8a586c1d",
    "file": "docs\\reference\\optimization\\core_problem.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "core_problem_4_1f439055",
    "file": "docs\\reference\\optimization\\core_problem.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "core_problem_5_c37800b0",
    "file": "docs\\reference\\optimization\\core_problem.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_results_manager_1_0bc86293",
    "file": "docs\\reference\\optimization\\core_results_manager.md",
    "index": 1,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "core_results_manager_2_e757136e",
    "file": "docs\\reference\\optimization\\core_results_manager.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "core_results_manager_3_8a586c1d",
    "file": "docs\\reference\\optimization\\core_results_manager.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "core_results_manager_4_1f439055",
    "file": "docs\\reference\\optimization\\core_results_manager.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "core_results_manager_5_c37800b0",
    "file": "docs\\reference\\optimization\\core_results_manager.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "integration_pso_factory_bridge_1_98ede236",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef particle_to_controller(particle: np.ndarray) -> Controller:\n    gains = {\n        'k1': particle[0],\n        'k2': particle[1],\n        # ...\n    }\n    return ControllerFactory.create(gains)",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "98ede236"
  },
  {
    "id": "integration_pso_factory_bridge_2_0bc86293",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 2,
    "code": "from src.optimization.core import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0bc86293"
  },
  {
    "id": "integration_pso_factory_bridge_3_e757136e",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 3,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "integration_pso_factory_bridge_4_8a586c1d",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 4,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "integration_pso_factory_bridge_5_1f439055",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 5,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "integration_pso_factory_bridge_6_c37800b0",
    "file": "docs\\reference\\optimization\\integration_pso_factory_bridge.md",
    "index": 6,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "objectives_base_1_7ca4a201",
    "file": "docs\\reference\\optimization\\objectives_base.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "objectives_base_2_e757136e",
    "file": "docs\\reference\\optimization\\objectives_base.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "objectives_base_3_8a586c1d",
    "file": "docs\\reference\\optimization\\objectives_base.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "objectives_base_4_1f439055",
    "file": "docs\\reference\\optimization\\objectives_base.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "objectives_base_5_c37800b0",
    "file": "docs\\reference\\optimization\\objectives_base.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "objectives_multi_pareto_1_7ca4a201",
    "file": "docs\\reference\\optimization\\objectives_multi_pareto.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "objectives_multi_pareto_2_e757136e",
    "file": "docs\\reference\\optimization\\objectives_multi_pareto.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "objectives_multi_pareto_3_8a586c1d",
    "file": "docs\\reference\\optimization\\objectives_multi_pareto.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "objectives_multi_pareto_4_1f439055",
    "file": "docs\\reference\\optimization\\objectives_multi_pareto.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "objectives_multi_pareto_5_c37800b0",
    "file": "docs\\reference\\optimization\\objectives_multi_pareto.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "validation_enhanced_convergence_analyzer_1_7ca4a201",
    "file": "docs\\reference\\optimization\\validation_enhanced_convergence_analyzer.md",
    "index": 1,
    "code": "from src.optimization.algorithms import *\n\n# Initialize with configuration\nconfig = {'parameter': 'value'}\ninstance = Component(config)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7ca4a201"
  },
  {
    "id": "validation_enhanced_convergence_analyzer_2_e757136e",
    "file": "docs\\reference\\optimization\\validation_enhanced_convergence_analyzer.md",
    "index": 2,
    "code": "# Adjust parameters for better performance\noptimized_params = tune_parameters(instance, target_performance)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e757136e"
  },
  {
    "id": "validation_enhanced_convergence_analyzer_3_8a586c1d",
    "file": "docs\\reference\\optimization\\validation_enhanced_convergence_analyzer.md",
    "index": 3,
    "code": "# Use in complete optimization loop\noptimizer = create_optimizer(opt_type, config)\nresult = optimize(optimizer, problem, max_iter=100)",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8a586c1d"
  },
  {
    "id": "validation_enhanced_convergence_analyzer_4_1f439055",
    "file": "docs\\reference\\optimization\\validation_enhanced_convergence_analyzer.md",
    "index": 4,
    "code": "try:\n    output = instance.compute(parameters)\nexcept ValueError as e:\n    handle_edge_case(e)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f439055"
  },
  {
    "id": "validation_enhanced_convergence_analyzer_5_c37800b0",
    "file": "docs\\reference\\optimization\\validation_enhanced_convergence_analyzer.md",
    "index": 5,
    "code": "# Analyze metrics\nmetrics = compute_metrics(result)\nprint(f\"Best fitness: {metrics.best_fitness:.3f}\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c37800b0"
  },
  {
    "id": "core_dynamics_1_ebb07c92",
    "file": "docs\\reference\\plant\\core_dynamics.md",
    "index": 1,
    "code": "from src.plant.core.dynamics import *\nimport numpy as np\n\n# Basic initialization\n# Create dynamics model with standard parameters\nfrom src.plant.models.simplified import SimplifiedDIPDynamics\nfrom src.plant.configurations import get_default_config\n\nconfig = get_default_config()\ndynamics = SimplifiedDIPDynamics(config)\n\n# Compute state derivative\nstate = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])  # [x, \u03b81, \u03b82, \u1e8b, \u03b8\u03071, \u03b8\u03072]\ncontrol = np.array([5.0])  # Force in Newtons\nstate_dot = dynamics.step(state, control, t=0.0)\nprint(f\"State derivative: {state_dot}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ebb07c92"
  },
  {
    "id": "core_dynamics_2_172b213c",
    "file": "docs\\reference\\plant\\core_dynamics.md",
    "index": 2,
    "code": "from src.plant.models.simplified import SimplifiedDIPDynamics\n\n# Enable numerical stability features\ndynamics = SimplifiedDIPDynamics(\n    config=config,\n    enable_energy_monitoring=True,\n    numerical_tolerance=1e-8,\n    use_numba=True  # JIT compilation for performance\n)\n\n# Configure integration parameters\ndynamics.set_integration_params(\n    method='rk45',\n    atol=1e-8,\n    rtol=1e-6\n)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "172b213c"
  },
  {
    "id": "core_dynamics_3_10339f3c",
    "file": "docs\\reference\\plant\\core_dynamics.md",
    "index": 3,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "core_dynamics_4_0de60fb3",
    "file": "docs\\reference\\plant\\core_dynamics.md",
    "index": 4,
    "code": "import time\nfrom numba import njit\n\n# Enable Numba JIT compilation for hot loops\n@njit\ndef batch_dynamics_step(states, controls, params):\n    \"\"\"Vectorized dynamics computation.\"\"\"\n    N = states.shape[0]\n    state_dots = np.zeros_like(states)\n    for i in range(N):\n        state_dots[i] = dynamics_core_numba(states[i], controls[i], params)\n    return state_dots\n\n# Benchmark\nN = 1000\nstates = np.random.randn(N, 6)\ncontrols = np.random.randn(N, 1)\n\nstart = time.perf_counter()\nresults = batch_dynamics_step(states, controls, params)\nelapsed = time.perf_counter() - start\n\nprint(f\"Processed {N} states in {elapsed*1000:.2f}ms\")\nprint(f\"Throughput: {N/elapsed:.0f} states/sec\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0de60fb3"
  },
  {
    "id": "core_dynamics_5_6e95bdb3",
    "file": "docs\\reference\\plant\\core_dynamics.md",
    "index": 5,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "core_numerical_stability_1_3b94684b",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 1,
    "code": "class NumericalInstabilityError(RuntimeError):\n    \"\"\"Matrix too ill-conditioned for reliable computation.\"\"\"",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b94684b"
  },
  {
    "id": "core_numerical_stability_2_c9dca880",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 2,
    "code": "try:\n    q_ddot = solver.solve_linear_system(M, forcing)\nexcept NumericalInstabilityError as e:\n    logger.error(f\"Dynamics computation failed: {e}\")\n    # Fallback: use previous state or safe default",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9dca880"
  },
  {
    "id": "core_numerical_stability_3_a030c78f",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 3,
    "code": "from src.plant.core import NumericalInstabilityError, MatrixInverter\n\ninverter = MatrixInverter()\ntry:\n    M_inv = inverter.invert_matrix(M)\nexcept NumericalInstabilityError as e:\n    print(f\"Matrix inversion failed: {e}\")\n    # Handle error (use approximation, skip timestep, etc.)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a030c78f"
  },
  {
    "id": "core_numerical_stability_4_b4aa5f23",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 4,
    "code": "from src.plant.core import AdaptiveRegularizer\n\n# Research-grade precision (default)\nresearch_regularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-6,\n    max_condition_number=1e14\n)\n\n# Real-time systems (more aggressive)\nrealtime_regularizer = AdaptiveRegularizer(\n    regularization_alpha=1e-4,\n    max_condition_number=1e12\n)\n\n# Fixed regularization (fastest)\nfixed_regularizer = AdaptiveRegularizer(\n    use_fixed_regularization=True,\n    min_regularization=1e-8\n)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b4aa5f23"
  },
  {
    "id": "core_numerical_stability_5_0d20a981",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 5,
    "code": "import numpy as np\n\n# Ill-conditioned matrix (\u03ba \u2248 1e13)\nM = np.array([\n    [1.0, 0.99999999, 0.5],\n    [0.99999999, 1.0, 0.5],\n    [0.5, 0.5, 0.3]\n])\n\nprint(f\"Original condition number: {np.linalg.cond(M):.2e}\")\n\n# Apply adaptive regularization\nregularizer = AdaptiveRegularizer()\nM_reg = regularizer.regularize_matrix(M)\n\nprint(f\"Regularized condition number: {np.linalg.cond(M_reg):.2e}\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0d20a981"
  },
  {
    "id": "core_numerical_stability_6_82f9cf40",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 6,
    "code": "if regularizer.check_conditioning(M):\n    # Direct inversion safe\n    M_inv = np.linalg.inv(M)\nelse:\n    # Regularization needed\n    M_reg = regularizer.regularize_matrix(M)\n    M_inv = np.linalg.inv(M_reg)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "82f9cf40"
  },
  {
    "id": "core_numerical_stability_7_d3153084",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 7,
    "code": "from src.plant.core import MatrixInverter, AdaptiveRegularizer\n\n# Default regularizer\ninverter = MatrixInverter()\n\n# Custom regularizer\ncustom_reg = AdaptiveRegularizer(regularization_alpha=1e-5)\ncustom_inverter = MatrixInverter(regularizer=custom_reg)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3153084"
  },
  {
    "id": "core_numerical_stability_8_c36309d8",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 8,
    "code": "try:\n    M_inv = inverter.invert_matrix(M)\n    q_ddot = M_inv @ forcing\nexcept NumericalInstabilityError:\n    print(\"Matrix inversion failed - using approximate dynamics\")\n    q_ddot = np.zeros(3)  # Safe fallback",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c36309d8"
  },
  {
    "id": "core_numerical_stability_9_3afd72bc",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 9,
    "code": "# Dynamics computation: M(q)q\u0308 = \u03c4 - C\u00b7q\u0307 - G\nM = physics.compute_inertia_matrix(state)\nforcing = tau - C @ q_dot - G\n\n# Solve for accelerations (preferred method)\nq_ddot = inverter.solve_linear_system(M, forcing)\n\n# Equivalent but slower:\n# M_inv = inverter.invert_matrix(M)\n# q_ddot = M_inv @ forcing",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3afd72bc"
  },
  {
    "id": "core_numerical_stability_10_dbb7f185",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 10,
    "code": "from src.plant.core import NumericalStabilityMonitor\n\nmonitor = NumericalStabilityMonitor()\n\n# During simulation loop\nfor t in time_steps:\n    M = physics.compute_inertia_matrix(state)\n    cond_num = np.linalg.cond(M)\n    regularized = cond_num > 1e12\n\n    try:\n        M_inv = inverter.invert_matrix(M)\n        monitor.record_inversion(cond_num, regularized, failed=False)\n    except NumericalInstabilityError:\n        monitor.record_inversion(cond_num, regularized, failed=True)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dbb7f185"
  },
  {
    "id": "core_numerical_stability_11_877033ef",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 11,
    "code": "stats = monitor.get_statistics()\nprint(f\"Regularization rate: {stats['regularization_rate'] * 100:.1f}%\")\nprint(f\"Average condition number: {stats['avg_condition_number']:.2e}\")\nprint(f\"Max condition number: {stats['max_condition_number']:.2e}\")\nprint(f\"Failure rate: {stats['failed_count'] / stats['total_inversions'] * 100:.2f}%\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "877033ef"
  },
  {
    "id": "core_numerical_stability_12_647369fc",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 12,
    "code": "from src.plant.core import fast_condition_estimate\n\n# Compare with exact computation\nM = np.random.randn(3, 3)\nM = M @ M.T  # Make symmetric positive definite\n\nexact_cond = np.linalg.cond(M)\napprox_cond = fast_condition_estimate(M)\n\nprint(f\"Exact: {exact_cond:.2e}\")\nprint(f\"Approximate: {approx_cond:.2e}\")\nprint(f\"Relative error: {abs(exact_cond - approx_cond) / exact_cond * 100:.1f}%\")",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "647369fc"
  },
  {
    "id": "core_numerical_stability_13_c6324b5d",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 13,
    "code": "import numpy as np\nfrom src.plant.core import AdaptiveRegularizer\n\n# Create ill-conditioned matrix\nM = np.array([\n    [1.0, 0.999999999, 0.5],\n    [0.999999999, 1.0, 0.5],\n    [0.5, 0.5, 0.3]\n])\n\nprint(f\"Original condition number: {np.linalg.cond(M):.2e}\")  # ~1e13\n\n# Regularize\nregularizer = AdaptiveRegularizer()\nM_reg = regularizer.regularize_matrix(M)\n\nprint(f\"Regularized condition number: {np.linalg.cond(M_reg):.2e}\")  # ~1e8",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6324b5d"
  },
  {
    "id": "core_numerical_stability_14_ef54cd9f",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 14,
    "code": "from src.plant.core import MatrixInverter, NumericalInstabilityError\n\ninverter = MatrixInverter()\n\ntry:\n    M_inv = inverter.invert_matrix(M)\n    print(\"Inversion successful\")\nexcept NumericalInstabilityError as e:\n    print(f\"Inversion failed: {e}\")",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ef54cd9f"
  },
  {
    "id": "core_numerical_stability_15_9c9b2198",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 15,
    "code": "from src.plant.core import MatrixInverter, DIPPhysicsMatrices\nfrom src.plant.configurations import UnifiedDIPConfig\n\nconfig = UnifiedDIPConfig()\nphysics = DIPPhysicsMatrices(config)\ninverter = MatrixInverter()\n\n# State and control\nstate = np.array([0.1, 0.05, -0.03, 0.2, 0.1, -0.05])\ntau = np.array([10.0, 0.0, 0.0])\n\n# Compute physics matrices\nM, C, G = physics.compute_all_matrices(state)\nq_dot = state[3:]\n\n# Solve M(q)q\u0308 = \u03c4 - C\u00b7q\u0307 - G for q\u0308\nforcing = tau - C @ q_dot - G\nq_ddot = inverter.solve_linear_system(M, forcing)\n\nprint(f\"Accelerations: {q_ddot}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9c9b2198"
  },
  {
    "id": "core_numerical_stability_16_6992f238",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 16,
    "code": "from src.plant.core import NumericalStabilityMonitor\n\nmonitor = NumericalStabilityMonitor()\n\n# Simulation loop\nfor i in range(1000):\n    M = physics.compute_inertia_matrix(states[i])\n    cond_num = np.linalg.cond(M)\n\n    regularized = not regularizer.check_conditioning(M)\n\n    try:\n        q_ddot = inverter.solve_linear_system(M, forcing[i])\n        monitor.record_inversion(cond_num, regularized, failed=False)\n    except NumericalInstabilityError:\n        monitor.record_inversion(cond_num, regularized, failed=True)\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Simulation used regularization {stats['regularization_rate'] * 100:.1f}% of the time\")\nprint(f\"Max condition number: {stats['max_condition_number']:.2e}\")\nprint(f\"Failure rate: {stats['failed_count'] / stats['total_inversions'] * 100:.2f}%\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6992f238"
  },
  {
    "id": "core_numerical_stability_17_07b1f7c8",
    "file": "docs\\reference\\plant\\core_numerical_stability.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\n# Conservative (research-grade precision)\nconservative_reg = AdaptiveRegularizer(\n    regularization_alpha=1e-6,  # Minimal regularization\n    max_condition_number=1e15   # High tolerance\n)\n\n# Aggressive (real-time systems)\naggressive_reg = AdaptiveRegularizer(\n    regularization_alpha=1e-3,  # Strong regularization\n    max_condition_number=1e10   # Low tolerance\n)\n\n# Fixed (maximum performance)\nfixed_reg = AdaptiveRegularizer(\n    use_fixed_regularization=True,\n    min_regularization=1e-7\n)\n\n# Compare\nM_conservative = conservative_reg.regularize_matrix(M)\nM_aggressive = aggressive_reg.regularize_matrix(M)\nM_fixed = fixed_reg.regularize_matrix(M)\n\nprint(f\"Conservative \u03ba: {np.linalg.cond(M_conservative):.2e}\")\nprint(f\"Aggressive \u03ba: {np.linalg.cond(M_aggressive):.2e}\")\nprint(f\"Fixed \u03ba: {np.linalg.cond(M_fixed):.2e}\")",
    "lines": 29,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "07b1f7c8"
  },
  {
    "id": "core_physics_matrices_1_8112413f",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n@staticmethod\n@njit\ndef _compute_inertia_matrix_numba(theta1, theta2, m0, m1, m2, ...):\n    \"\"\"JIT-compiled inertia matrix computation.\"\"\"",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8112413f"
  },
  {
    "id": "core_physics_matrices_2_e89472f4",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 2,
    "code": "from src.plant.core import DIPPhysicsMatrices\nfrom src.plant.configurations import UnifiedDIPConfig\n\nconfig = UnifiedDIPConfig()\nphysics = DIPPhysicsMatrices(config)\n\nstate = np.array([0.1, 0.05, -0.03, 0.0, 0.0, 0.0])\nM = physics.compute_inertia_matrix(state)\n\n# Verify symmetry\nassert np.allclose(M, M.T)\n\n# Verify positive definiteness\neigenvalues = np.linalg.eigvals(M)\nassert np.all(eigenvalues > 0)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e89472f4"
  },
  {
    "id": "core_physics_matrices_3_567a3d8a",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 3,
    "code": "state = np.array([0.1, 0.05, -0.03, 0.2, 0.1, -0.05])\nC = physics.compute_coriolis_matrix(state)\n\n# Extract velocity-dependent terms\ntheta1, theta2 = state[1], state[2]\ntheta1_dot, theta2_dot = state[4], state[5]\n\n# Verify friction is on diagonal\nassert C[0, 0] == config.cart_friction\nassert C[1, 1] >= config.joint1_friction  # May include velocity terms",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "567a3d8a"
  },
  {
    "id": "core_physics_matrices_4_f6ae5ddf",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 4,
    "code": "# Upright equilibrium\nstate_upright = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\nG_upright = physics.compute_gravity_vector(state_upright)\nassert np.allclose(G_upright, 0.0)\n\n# Small perturbation\nstate_perturbed = np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\nG_perturbed = physics.compute_gravity_vector(state_perturbed)\nassert G_perturbed[1] < 0  # Restoring torque on link 1\nassert G_perturbed[2] < 0  # Restoring torque on link 2",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f6ae5ddf"
  },
  {
    "id": "core_physics_matrices_5_beb5ab01",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 5,
    "code": "state = np.array([0.1, 0.05, -0.03, 0.2, 0.1, -0.05])\nM, C, G = physics.compute_all_matrices(state)\n\n# Verify dynamics equation: M\u207b\u00b9(\u03c4 - C\u00b7q\u0307 - G) = q\u0308\ntau = np.array([10.0, 0.0, 0.0])  # Control force\nq_dot = state[3:]\nq_ddot = np.linalg.solve(M, tau - C @ q_dot - G)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "beb5ab01"
  },
  {
    "id": "core_physics_matrices_6_d8b08e2b",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 6,
    "code": "from src.plant.core import SimplifiedDIPPhysicsMatrices\n\nsimplified_physics = SimplifiedDIPPhysicsMatrices(config)\nM_simp = simplified_physics.compute_inertia_matrix(state)\n\n# Compare with full physics\nM_full = physics.compute_inertia_matrix(state)\nrelative_error = np.linalg.norm(M_simp - M_full) / np.linalg.norm(M_full)\nprint(f\"Inertia matrix error: {relative_error * 100:.2f}%\")  # Typically 2-5%",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d8b08e2b"
  },
  {
    "id": "core_physics_matrices_7_c6668fc4",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 7,
    "code": "import numpy as np\nfrom src.plant.core import DIPPhysicsMatrices\nfrom src.plant.configurations import UnifiedDIPConfig\n\n# Setup\nconfig = UnifiedDIPConfig()\nphysics = DIPPhysicsMatrices(config)\n\n# Define state: [x, \u03b8\u2081, \u03b8\u2082, \u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\nstate = np.array([0.0, 0.1, -0.05, 0.0, 0.2, -0.1])\n\n# Compute physics matrices\nM = physics.compute_inertia_matrix(state)\nC = physics.compute_coriolis_matrix(state)\nG = physics.compute_gravity_vector(state)\n\nprint(f\"Inertia Matrix M:\\n{M}\")\nprint(f\"\\nCoriolis Matrix C:\\n{C}\")\nprint(f\"\\nGravity Vector G:\\n{G}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c6668fc4"
  },
  {
    "id": "core_physics_matrices_8_e69dce0d",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 8,
    "code": "from src.plant.models.full import FullDIPDynamics\n\n# Create full dynamics model (uses DIPPhysicsMatrices internally)\ndynamics = FullDIPDynamics(config)\n\n# Simulate one timestep\ncontrol_input = np.array([5.0])  # 5N force on cart\nresult = dynamics.compute_dynamics(state, control_input, time=0.0)\n\nif result.success:\n    state_derivative = result.state_derivative\n    print(f\"State derivative: {state_derivative}\")\n\n    # Access physics matrices from dynamics model\n    M, C, G = dynamics.get_physics_matrices(state)",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e69dce0d"
  },
  {
    "id": "core_physics_matrices_9_a30a76d5",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 9,
    "code": "import time\n\n# Benchmark full physics\nstate_batch = np.random.randn(1000, 6)\nstart = time.perf_counter()\nfor state in state_batch:\n    M = physics.compute_inertia_matrix(state)\nfull_time = time.perf_counter() - start\n\n# Benchmark simplified physics\nsimplified_physics = SimplifiedDIPPhysicsMatrices(config)\nstart = time.perf_counter()\nfor state in state_batch:\n    M_simp = simplified_physics.compute_inertia_matrix(state)\nsimplified_time = time.perf_counter() - start\n\nprint(f\"Full physics: {full_time:.4f}s\")\nprint(f\"Simplified physics: {simplified_time:.4f}s\")\nprint(f\"Speedup: {full_time / simplified_time:.2f}\u00d7\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a30a76d5"
  },
  {
    "id": "core_physics_matrices_10_8dfd362f",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_inertia_matrix_properties(physics, state):\n    \"\"\"Verify mathematical properties of M(q).\"\"\"\n    M = physics.compute_inertia_matrix(state)\n\n    # 1. Symmetry\n    symmetry_error = np.linalg.norm(M - M.T)\n    print(f\"Symmetry error: {symmetry_error:.2e}\")\n\n    # 2. Positive definiteness\n    eigenvalues = np.linalg.eigvals(M)\n    min_eigenvalue = np.min(eigenvalues)\n    print(f\"Minimum eigenvalue: {min_eigenvalue:.6f}\")\n    assert min_eigenvalue > 0, \"M(q) must be positive definite\"\n\n    # 3. Condition number\n    cond = np.linalg.cond(M)\n    print(f\"Condition number: {cond:.2e}\")\n    if cond > 1e10:\n        print(\"Warning: Ill-conditioned matrix, consider regularization\")\n\nverify_inertia_matrix_properties(physics, state)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8dfd362f"
  },
  {
    "id": "core_physics_matrices_11_00a0e65c",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\ndef compute_kinetic_energy(state, physics):\n    \"\"\"Compute kinetic energy using M(q).\"\"\"\n    M = physics.compute_inertia_matrix(state)\n    q_dot = state[3:]  # Velocities\n    T = 0.5 * q_dot.T @ M @ q_dot\n    return T\n\ndef compute_potential_energy(state, config):\n    \"\"\"Compute potential energy.\"\"\"\n    _, theta1, theta2, _, _, _ = state\n    m1, m2 = config.pendulum1_mass, config.pendulum2_mass\n    L1, Lc1, Lc2 = config.pendulum1_length, config.pendulum1_com, config.pendulum2_com\n    g = config.gravity\n\n    V = m1 * g * Lc1 * np.cos(theta1) + m2 * g * (L1 * np.cos(theta1) + Lc2 * np.cos(theta2))\n    return V\n\n# Total mechanical energy\nT = compute_kinetic_energy(state, physics)\nV = compute_potential_energy(state, config)\nE_total = T + V\nprint(f\"Total energy: {E_total:.4f} J\")",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "00a0e65c"
  },
  {
    "id": "core_physics_matrices_12_8f665af8",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 12,
    "code": "import time\n\n# First call (includes compilation)\nstart = time.perf_counter()\nM1 = physics.compute_inertia_matrix(state)\nfirst_call = time.perf_counter() - start\nprint(f\"First call: {first_call:.4f}s\")\n\n# Subsequent calls (compiled code)\nstart = time.perf_counter()\nM2 = physics.compute_inertia_matrix(state)\nsubsequent_call = time.perf_counter() - start\nprint(f\"Subsequent call: {subsequent_call:.6f}s\")\nprint(f\"Speedup: {first_call / subsequent_call:.0f}\u00d7\")",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8f665af8"
  },
  {
    "id": "core_physics_matrices_13_5a4de9b7",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 13,
    "code": "def warmup_physics_computer(physics):\n    \"\"\"Pre-compile Numba functions.\"\"\"\n    dummy_state = np.zeros(6)\n    physics.compute_inertia_matrix(dummy_state)\n    physics.compute_coriolis_matrix(dummy_state)\n    physics.compute_gravity_vector(dummy_state)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5a4de9b7"
  },
  {
    "id": "core_physics_matrices_14_e1bea9dc",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 14,
    "code": "# Efficient: Vectorize over states\ndef compute_inertia_batch(physics, states):\n    \"\"\"Compute M(q) for batch of states.\"\"\"\n    batch_size = states.shape[0]\n    M_batch = np.zeros((batch_size, 3, 3))\n    for i in range(batch_size):\n        M_batch[i] = physics.compute_inertia_matrix(states[i])\n    return M_batch\n\n# More efficient: Use Numba parallel loops (future enhancement)",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e1bea9dc"
  },
  {
    "id": "core_physics_matrices_15_f82ee37e",
    "file": "docs\\reference\\plant\\core_physics_matrices.md",
    "index": 15,
    "code": "# Inefficient: Creates new arrays each call\nfor i in range(10000):\n    M = physics.compute_inertia_matrix(state)\n\n# Efficient: Reuse pre-allocated arrays\nM = np.zeros((3, 3))\nfor i in range(10000):\n    M[:] = physics.compute_inertia_matrix(state)  # In-place update",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f82ee37e"
  },
  {
    "id": "core_state_validation_1_fb278707",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 1,
    "code": "def runtime_monitor(x, t):\n    if not is_valid(x):\n        raise StateValidationError(f\"State violation at t={t}\")\n    if energy_drift(x) > threshold:\n        warn(f\"Energy drift detected: {energy_drift(x):.2%}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fb278707"
  },
  {
    "id": "core_state_validation_2_e9954efa",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 2,
    "code": "from src.plant.core.state_validation import *\nimport numpy as np\n\n# Basic initialization\n# Validate state and detect violations\nfrom src.plant.core.state_validation import StateValidator, ValidationResult\n\nvalidator = StateValidator()\nstate = np.array([0.0, 0.1, 0.05, 0.0, 0.5, 0.3])\n\nresult: ValidationResult = validator.validate(state)\nif result.is_valid:\n    print(\"State is physically valid\")\nelse:\n    print(f\"Violations: {result.violations}\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e9954efa"
  },
  {
    "id": "core_state_validation_3_dac304c2",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 3,
    "code": "from src.plant.core.state_validation import ValidationConfig\n\n# Custom validation constraints\nvalidation_config = ValidationConfig(\n    max_position=2.0,        # \u00b12m cart position\n    max_angle=np.pi/2,       # \u00b190\u00b0 joint angles\n    max_velocity=5.0,        # 5 m/s cart velocity\n    max_angular_velocity=10.0,  # 10 rad/s joint velocities\n    energy_conservation_tol=0.05  # 5% energy drift tolerance\n)\n\nvalidator = StateValidator(validation_config)",
    "lines": 12,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dac304c2"
  },
  {
    "id": "core_state_validation_4_10339f3c",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 4,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "core_state_validation_5_a8d903ec",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "core_state_validation_6_6e95bdb3",
    "file": "docs\\reference\\plant\\core_state_validation.md",
    "index": 6,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "core___init___1_3a4f78ec",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 1,
    "code": "# Clean separation\nM = compute_mass_matrix(q, params)        # Physics\nM_inv = robust_inverse(M)                 # Numerical\nis_valid = validate_state(x)              # Validation",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3a4f78ec"
  },
  {
    "id": "core___init___2_2bbabcfb",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef dynamics_step(x, u, params):\n    q, q_dot = extract_coordinates(x)\n    M = compute_mass_matrix(q, params)\n    C = compute_coriolis_matrix(q, q_dot, params)\n    G = compute_gravity_vector(q, params)\n    M_inv = robust_inverse(M)\n    q_ddot = M_inv @ (B @ u - C @ q_dot - G)\n    x_dot = assemble_state_derivative(q_dot, q_ddot)\n    validate_state(x_dot)\n    return x_dot",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bbabcfb"
  },
  {
    "id": "core___init___3_da7a3cda",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n@njit(cache=True, fastmath=True)\ndef compute_physics_matrices_numba(q, q_dot, params):\n    # Hot loop - compiled to machine code\n    ...",
    "lines": 7,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da7a3cda"
  },
  {
    "id": "core___init___4_5171ba71",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.core.__init__ import *\nimport numpy as np\n\n# Basic initialization\n# Initialize module\n# ... basic usage code ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5171ba71"
  },
  {
    "id": "core___init___5_c342876e",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced configuration\n# ... custom parameters ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c342876e"
  },
  {
    "id": "core___init___6_10339f3c",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 6,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "core___init___7_a8d903ec",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "core___init___8_6e95bdb3",
    "file": "docs\\reference\\plant\\core___init__.md",
    "index": 8,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "models_base_dynamics_interface_1_bb0c14de",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 1,
    "code": "class DynamicsInterface(ABC):\n    @abstractmethod\n    def step(self, x: np.ndarray, u: np.ndarray, t: float) -> np.ndarray:\n        \"\"\"Compute state derivative dx/dt = f(x, u, t).\"\"\"\n        pass\n\n    @abstractmethod\n    def get_linearization(self, x_eq: np.ndarray, u_eq: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Compute Jacobian matrices A, B at equilibrium.\"\"\"\n        pass",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb0c14de"
  },
  {
    "id": "models_base_dynamics_interface_2_1e0e1b3a",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 2,
    "code": "class SMCController:\n    def __init__(self, dynamics: DynamicsInterface):\n        self.dynamics = dynamics  # Works with any implementation",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1e0e1b3a"
  },
  {
    "id": "models_base_dynamics_interface_3_263c649a",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 3,
    "code": "# Simplified for development\ndynamics = SimplifiedDIPDynamics(config)\n\n# Full for validation\ndynamics = FullNonlinearDIPDynamics(config)\n\n# Controller code unchanged!\ncontroller.set_dynamics(dynamics)",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "263c649a"
  },
  {
    "id": "models_base_dynamics_interface_4_14e09947",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 4,
    "code": "class MockDynamics(DynamicsInterface):\n    def step(self, x, u, t):\n        return np.zeros_like(x)  # Trivial for testing",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "14e09947"
  },
  {
    "id": "models_base_dynamics_interface_5_757ead9f",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.models.base.dynamics_interface import *\nimport numpy as np\n\n# Basic initialization\n# Initialize module\n# ... basic usage code ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "757ead9f"
  },
  {
    "id": "models_base_dynamics_interface_6_172b213c",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 6,
    "code": "from src.plant.models.simplified import SimplifiedDIPDynamics\n\n# Enable numerical stability features\ndynamics = SimplifiedDIPDynamics(\n    config=config,\n    enable_energy_monitoring=True,\n    numerical_tolerance=1e-8,\n    use_numba=True  # JIT compilation for performance\n)\n\n# Configure integration parameters\ndynamics.set_integration_params(\n    method='rk45',\n    atol=1e-8,\n    rtol=1e-6\n)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "172b213c"
  },
  {
    "id": "models_base_dynamics_interface_7_10339f3c",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 7,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "models_base_dynamics_interface_8_0de60fb3",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 8,
    "code": "import time\nfrom numba import njit\n\n# Enable Numba JIT compilation for hot loops\n@njit\ndef batch_dynamics_step(states, controls, params):\n    \"\"\"Vectorized dynamics computation.\"\"\"\n    N = states.shape[0]\n    state_dots = np.zeros_like(states)\n    for i in range(N):\n        state_dots[i] = dynamics_core_numba(states[i], controls[i], params)\n    return state_dots\n\n# Benchmark\nN = 1000\nstates = np.random.randn(N, 6)\ncontrols = np.random.randn(N, 1)\n\nstart = time.perf_counter()\nresults = batch_dynamics_step(states, controls, params)\nelapsed = time.perf_counter() - start\n\nprint(f\"Processed {N} states in {elapsed*1000:.2f}ms\")\nprint(f\"Throughput: {N/elapsed:.0f} states/sec\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0de60fb3"
  },
  {
    "id": "models_base_dynamics_interface_9_6e95bdb3",
    "file": "docs\\reference\\plant\\models_base_dynamics_interface.md",
    "index": 9,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "models_base___init___1_b3f2168e",
    "file": "docs\\reference\\plant\\models_base___init__.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.models.base.__init__ import *\nimport numpy as np\n\n# Basic initialization\n# Initialize module\n# ... basic usage code ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3f2168e"
  },
  {
    "id": "models_base___init___2_c342876e",
    "file": "docs\\reference\\plant\\models_base___init__.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced configuration\n# ... custom parameters ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c342876e"
  },
  {
    "id": "models_base___init___3_10339f3c",
    "file": "docs\\reference\\plant\\models_base___init__.md",
    "index": 3,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "models_base___init___4_a8d903ec",
    "file": "docs\\reference\\plant\\models_base___init__.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "models_base___init___5_6e95bdb3",
    "file": "docs\\reference\\plant\\models_base___init__.md",
    "index": 5,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "models_simplified_config_1_6e8fda71",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndefault_config = SimplifiedDIPConfig(\n    m0=1.0,   # 1 kg cart\n    m1=0.2,   # 200g link 1\n    m2=0.1,   # 100g link 2\n    l1=0.3,   # 30cm link 1\n    l2=0.2,   # 20cm link 2\n    g=9.81,   # Earth gravity\n    d0=0.1,   # Light cart damping\n    d1=0.01,  # Light joint damping\n    d2=0.01\n)",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e8fda71"
  },
  {
    "id": "models_simplified_config_2_d8bced2c",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 2,
    "code": "from src.plant.models.simplified.config import *\nimport numpy as np\n\n# Basic initialization\n# Load and validate configuration\nfrom src.plant.models.simplified.config import SimplifiedDIPConfig\n\nconfig = SimplifiedDIPConfig(\n    m0=1.5,  # Cart mass (kg)\n    m1=0.3,  # Link 1 mass (kg)\n    m2=0.2,  # Link 2 mass (kg)\n    l1=0.35,  # Link 1 length (m)\n    l2=0.25,  # Link 2 length (m)\n    g=9.81   # Gravity (m/s\u00b2)\n)\n\n# Validate physics constraints\nif config.is_valid():\n    print(\"Configuration is physically valid\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d8bced2c"
  },
  {
    "id": "models_simplified_config_3_c342876e",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced configuration\n# ... custom parameters ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c342876e"
  },
  {
    "id": "models_simplified_config_4_10339f3c",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 4,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "models_simplified_config_5_a8d903ec",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "models_simplified_config_6_6e95bdb3",
    "file": "docs\\reference\\plant\\models_simplified_config.md",
    "index": 6,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "models_simplified_dynamics_1_09c52823",
    "file": "docs\\reference\\plant\\models_simplified_dynamics.md",
    "index": 1,
    "code": "from src.plant.models.simplified import SimplifiedDynamics\nfrom src.plant.models.full import FullDynamics\nfrom src.plant.configurations import DIPPhysicsConfig\n\n# Simplified dynamics (fast, linearized friction)\nsimplified = SimplifiedDynamics(\n    cart_mass=1.0,\n    pole1_mass=0.1,\n    pole2_mass=0.05,\n    pole1_length=0.5,\n    pole2_length=0.25,\n    friction_cart=0.1\n)\n\n# Full nonlinear dynamics (high fidelity)\nfull = FullDynamics(\n    config=DIPPhysicsConfig(\n        cart_mass=1.0,\n        pole1_mass=0.1,\n        pole2_mass=0.05,\n        pole1_length=0.5,\n        pole2_length=0.25,\n        friction_cart=0.1,\n        friction_pole1=0.01,\n        friction_pole2=0.01\n    )\n)\n\n# Compute dynamics at a state\nstate = [0.1, 0.2, 0.1, 0, 0, 0]  # [x, \u03b8\u2081, \u03b8\u2082, \u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\ncontrol = 10.0\n\nstate_derivative = simplified.compute_dynamics(state, control, t=0)\nprint(f\"Accelerations: {state_derivative[3:]}\")  # [\u1e8d, \u03b8\u0308\u2081, \u03b8\u0308\u2082]",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "09c52823"
  },
  {
    "id": "models_simplified_dynamics_2_4cc6e497",
    "file": "docs\\reference\\plant\\models_simplified_dynamics.md",
    "index": 2,
    "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulate and track energy\ndynamics = SimplifiedDynamics()\nstates = [initial_state]\nenergies = []\n\nfor t in np.arange(0, 10, 0.01):\n    state = states[-1]\n    u = controller.compute_control(state, t)\n\n    # Compute energy before step\n    E = dynamics.compute_total_energy(state)\n    energies.append(E)\n\n    # Integrate\n    x_dot = dynamics.compute_dynamics(state, u, t)\n    next_state = state + 0.01 * x_dot\n    states.append(next_state)\n\n# Plot energy conservation\nplt.plot(energies)\nplt.xlabel('Time step')\nplt.ylabel('Total Energy (J)')\nplt.title('Energy Conservation Analysis')\nplt.grid(True)\nplt.show()\n\nenergy_drift = abs(energies[-1] - energies[0]) / energies[0] * 100\nprint(f\"Energy drift: {energy_drift:.2f}%\")",
    "lines": 31,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4cc6e497"
  },
  {
    "id": "models_simplified_dynamics_3_8802ecee",
    "file": "docs\\reference\\plant\\models_simplified_dynamics.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Linearize around upright equilibrium\nequilibrium_state = [0, 0, 0, 0, 0, 0]  # Upright, stationary\nequilibrium_control = 0.0\n\nA, B = dynamics.compute_linearization(equilibrium_state, equilibrium_control)\n\nprint(\"A matrix (state dynamics):\")\nprint(A)\nprint(\"\nB matrix (control influence):\")\nprint(B)\n\n# Analyze stability of linearized system\neigenvalues = np.linalg.eigvals(A)\nprint(f\"\nEigenvalues: {eigenvalues}\")\nprint(f\"Unstable modes: {sum(np.real(eigenvalues) > 0)}\")",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8802ecee"
  },
  {
    "id": "models_simplified_dynamics_4_ce6e70d5",
    "file": "docs\\reference\\plant\\models_simplified_dynamics.md",
    "index": 4,
    "code": "from src.plant.models import SimplifiedDynamics, FullDynamics, LowRankDynamics\n\nmodels = {\n    'Simplified': SimplifiedDynamics(),\n    'Full': FullDynamics(),\n    'LowRank': LowRankDynamics()\n}\n\n# Compare computational cost\nimport time\nstate = [0.1, 0.2, 0.1, 0, 0, 0]\ncontrol = 10.0\n\nfor name, model in models.items():\n    start = time.perf_counter()\n    for _ in range(10000):\n        model.compute_dynamics(state, control, 0)\n    elapsed = time.perf_counter() - start\n\n    print(f\"{name}: {elapsed*1000:.2f}ms for 10k evaluations\")\n    print(f\"  \u2192 {elapsed/10000*1e6:.2f}\u00b5s per call\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ce6e70d5"
  },
  {
    "id": "models_simplified_physics_1_33cf7433",
    "file": "docs\\reference\\plant\\models_simplified_physics.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.models.simplified.physics import *\nimport numpy as np\n\n# Basic initialization\n# Initialize module\n# ... basic usage code ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "33cf7433"
  },
  {
    "id": "models_simplified_physics_2_c342876e",
    "file": "docs\\reference\\plant\\models_simplified_physics.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced configuration\n# ... custom parameters ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c342876e"
  },
  {
    "id": "models_simplified_physics_3_10339f3c",
    "file": "docs\\reference\\plant\\models_simplified_physics.md",
    "index": 3,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "models_simplified_physics_4_a8d903ec",
    "file": "docs\\reference\\plant\\models_simplified_physics.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "models_simplified_physics_5_6e95bdb3",
    "file": "docs\\reference\\plant\\models_simplified_physics.md",
    "index": 5,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "models_simplified___init___1_d370b1e4",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 1,
    "code": "from plant.models.simplified import (\n    SimplifiedDIPDynamics,    # Main dynamics class\n    SimplifiedDIPConfig,      # Configuration schema\n    compute_simplified_physics  # Physics functions\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d370b1e4"
  },
  {
    "id": "models_simplified___init___2_6889ffcb",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.plant.models.simplified.__init__ import *\nimport numpy as np\n\n# Basic initialization\n# Initialize module\n# ... basic usage code ...",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6889ffcb"
  },
  {
    "id": "models_simplified___init___3_c342876e",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Advanced configuration\n# ... custom parameters ...",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c342876e"
  },
  {
    "id": "models_simplified___init___4_10339f3c",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 4,
    "code": "from src.plant.exceptions import (\n    NumericalInstabilityError,\n    StateValidationError,\n    ConfigurationError\n)\n\ntry:\n    # Risky operation\n    state_dot = dynamics.step(state, control, t)\n\nexcept NumericalInstabilityError as e:\n    print(f\"Numerical instability detected: {e}\")\n    # Fallback: reduce timestep, increase regularization\n    dynamics.reset_numerical_params(stronger_regularization=True)\n\nexcept StateValidationError as e:\n    print(f\"Invalid state: {e}\")\n    # Fallback: clip state to valid bounds\n    state = validator.clip_to_valid(state)\n\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    # Fallback: use default configuration\n    config = get_default_config()",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "10339f3c"
  },
  {
    "id": "models_simplified___init___5_a8d903ec",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# Performance optimization\nimport cProfile\nimport pstats\n\n# Profile critical code path\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# ... run intensive operations ...\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(10)  # Top 10 time consumers",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a8d903ec"
  },
  {
    "id": "models_simplified___init___6_6e95bdb3",
    "file": "docs\\reference\\plant\\models_simplified___init__.md",
    "index": 6,
    "code": "from src.controllers import ClassicalSMC\nfrom src.core.simulation_runner import SimulationRunner\n\n# Create dynamics model\ndynamics = SimplifiedDIPDynamics(config)\n\n# Create controller\ncontroller = ClassicalSMC(\n    gains=[10.0, 8.0, 15.0, 12.0, 50.0, 5.0],\n    max_force=100.0,\n    boundary_layer=0.01\n)\n\n# Run closed-loop simulation\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    duration=5.0,\n    dt=0.01\n)\n\nresult = runner.run(\n    initial_state=np.array([0.0, 0.1, 0.05, 0.0, 0.0, 0.0])\n)\n\nprint(f\"Final state: {result.states[-1]}\")\nprint(f\"Settling time: {result.settling_time:.2f}s\")\nprint(f\"Control effort: {result.control_effort:.2f}\")",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6e95bdb3"
  },
  {
    "id": "context_safety_guards_1_85ab5836",
    "file": "docs\\reference\\simulation\\context_safety_guards.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "context_safety_guards_2_23946eea",
    "file": "docs\\reference\\simulation\\context_safety_guards.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "context_safety_guards_3_cc9e95a6",
    "file": "docs\\reference\\simulation\\context_safety_guards.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "context_safety_guards_4_6769f592",
    "file": "docs\\reference\\simulation\\context_safety_guards.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "context_safety_guards_5_eb487547",
    "file": "docs\\reference\\simulation\\context_safety_guards.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "context_simulation_context_1_663762a0",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 1,
    "code": "class SimulationContext:\n    def __enter__(self):\n        # Thread-local context initialization\n        return isolated_context\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # Cleanup and resource release\n        pass",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "663762a0"
  },
  {
    "id": "context_simulation_context_2_85ab5836",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 2,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "context_simulation_context_3_23946eea",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 3,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "context_simulation_context_4_cc9e95a6",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 4,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "context_simulation_context_5_6769f592",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 5,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "context_simulation_context_6_eb487547",
    "file": "docs\\reference\\simulation\\context_simulation_context.md",
    "index": 6,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "context___init___1_85ab5836",
    "file": "docs\\reference\\simulation\\context___init__.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "context___init___2_23946eea",
    "file": "docs\\reference\\simulation\\context___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "context___init___3_cc9e95a6",
    "file": "docs\\reference\\simulation\\context___init__.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "context___init___4_6769f592",
    "file": "docs\\reference\\simulation\\context___init__.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "context___init___5_eb487547",
    "file": "docs\\reference\\simulation\\context___init__.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "core_interfaces_1_85ab5836",
    "file": "docs\\reference\\simulation\\core_interfaces.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "core_interfaces_2_23946eea",
    "file": "docs\\reference\\simulation\\core_interfaces.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "core_interfaces_3_cc9e95a6",
    "file": "docs\\reference\\simulation\\core_interfaces.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "core_interfaces_4_6769f592",
    "file": "docs\\reference\\simulation\\core_interfaces.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "core_interfaces_5_eb487547",
    "file": "docs\\reference\\simulation\\core_interfaces.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "core_simulation_context_1_663762a0",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 1,
    "code": "class SimulationContext:\n    def __enter__(self):\n        # Thread-local context initialization\n        return isolated_context\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # Cleanup and resource release\n        pass",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "663762a0"
  },
  {
    "id": "core_simulation_context_2_85ab5836",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 2,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "core_simulation_context_3_23946eea",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 3,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "core_simulation_context_4_cc9e95a6",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 4,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "core_simulation_context_5_6769f592",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 5,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "core_simulation_context_6_eb487547",
    "file": "docs\\reference\\simulation\\core_simulation_context.md",
    "index": 6,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "core_state_space_1_85ab5836",
    "file": "docs\\reference\\simulation\\core_state_space.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "core_state_space_2_23946eea",
    "file": "docs\\reference\\simulation\\core_state_space.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "core_state_space_3_cc9e95a6",
    "file": "docs\\reference\\simulation\\core_state_space.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "core_state_space_4_6769f592",
    "file": "docs\\reference\\simulation\\core_state_space.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "core_state_space_5_eb487547",
    "file": "docs\\reference\\simulation\\core_state_space.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "core_time_domain_1_85ab5836",
    "file": "docs\\reference\\simulation\\core_time_domain.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "core_time_domain_2_23946eea",
    "file": "docs\\reference\\simulation\\core_time_domain.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "core_time_domain_3_cc9e95a6",
    "file": "docs\\reference\\simulation\\core_time_domain.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "core_time_domain_4_6769f592",
    "file": "docs\\reference\\simulation\\core_time_domain.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "core_time_domain_5_eb487547",
    "file": "docs\\reference\\simulation\\core_time_domain.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "core___init___1_85ab5836",
    "file": "docs\\reference\\simulation\\core___init__.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "core___init___2_23946eea",
    "file": "docs\\reference\\simulation\\core___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "core___init___3_cc9e95a6",
    "file": "docs\\reference\\simulation\\core___init__.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "core___init___4_6769f592",
    "file": "docs\\reference\\simulation\\core___init__.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "core___init___5_eb487547",
    "file": "docs\\reference\\simulation\\core___init__.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "engines_adaptive_integrator_1_85ab5836",
    "file": "docs\\reference\\simulation\\engines_adaptive_integrator.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "engines_adaptive_integrator_2_23946eea",
    "file": "docs\\reference\\simulation\\engines_adaptive_integrator.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "engines_adaptive_integrator_3_cc9e95a6",
    "file": "docs\\reference\\simulation\\engines_adaptive_integrator.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "engines_adaptive_integrator_4_6769f592",
    "file": "docs\\reference\\simulation\\engines_adaptive_integrator.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "engines_adaptive_integrator_5_eb487547",
    "file": "docs\\reference\\simulation\\engines_adaptive_integrator.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "engines_simulation_runner_1_7c14d729",
    "file": "docs\\reference\\simulation\\engines_simulation_runner.md",
    "index": 1,
    "code": "from src.simulation.engines.simulation_runner import run_simulation, SimulationRunner\nfrom src.controllers.smc.algorithms.classical import ClassicalSMC\nfrom src.plant.models.simplified import SimplifiedDynamics\n\n# Create controller and dynamics\nconfig = ClassicalSMCConfig(\n    surface_gains=[10.0, 8.0, 15.0, 12.0],\n    switching_gain=50.0,\n    max_force=100.0\n)\ncontroller = ClassicalSMC(config)\ndynamics = SimplifiedDynamics()\n\n# Run simulation (functional API)\nresult = run_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    initial_state=[0.1, 0.05, 0, 0, 0, 0],  # [x, \u03b8\u2081, \u03b8\u2082, \u1e8b, \u03b8\u0307\u2081, \u03b8\u0307\u2082]\n    duration=10.0,\n    dt=0.01\n)\n\nprint(f\"Final tracking error: {np.linalg.norm(result.states[-1, :2]):.4f}\")",
    "lines": 23,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c14d729"
  },
  {
    "id": "engines_simulation_runner_2_ee0946ec",
    "file": "docs\\reference\\simulation\\engines_simulation_runner.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nfrom src.simulation.engines.vector_sim import simulate_system_batch\nimport numpy as np\n\n# Test multiple initial conditions in parallel\ninitial_conditions = np.array([\n    [0.1, 0.05, 0, 0, 0, 0],\n    [0.2, 0.1, 0, 0, 0, 0],\n    [0.15, -0.05, 0, 0, 0, 0],\n    # ... 100 conditions\n])\n\n# Batch simulation (Numba accelerated)\nresults = simulate_system_batch(\n    controller=controller,\n    dynamics=dynamics,\n    initial_states=initial_conditions,\n    duration=5.0,\n    dt=0.01\n)\n\n# Analyze batch results\nsettling_times = [compute_settling_time(r.states) for r in results]\nprint(f\"Mean settling time: {np.mean(settling_times):.2f}s\")",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ee0946ec"
  },
  {
    "id": "engines_simulation_runner_3_0cd3381f",
    "file": "docs\\reference\\simulation\\engines_simulation_runner.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nfrom numba import jit\nfrom src.simulation.engines.simulation_runner import SimulationRunner\n\n# Define JIT-compiled dynamics function\n@jit(nopython=True)\ndef fast_dynamics_step(state, control, dt):\n    # Simplified dynamics for speed\n    # ... vectorized numpy operations ...\n    return next_state\n\n# Use in high-performance simulation\nrunner = SimulationRunner(\n    dynamics_model=fast_dynamics_step,\n    dt=0.001,  # High-frequency control (1kHz)\n    max_time=100.0  # Long-duration test\n)\n\nresult = runner.run_simulation(\n    initial_state=x0,\n    controller=controller,\n    reference=None\n)\n\nprint(f\"Simulation completed in {result.computation_time:.2f}s\")\nprint(f\"Average step time: {result.computation_time / len(result.time):.6f}s\")",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0cd3381f"
  },
  {
    "id": "engines_simulation_runner_4_2b1936c4",
    "file": "docs\\reference\\simulation\\engines_simulation_runner.md",
    "index": 4,
    "code": "from src.simulation.engines.simulation_runner import run_simulation\n\n# Compare Euler vs RK4 accuracy\nmethods = ['euler', 'rk4', 'rk45']\nresults = {}\n\nfor method in methods:\n    result = run_simulation(\n        controller=controller,\n        dynamics=dynamics,\n        initial_state=[0.1, 0.05, 0, 0, 0, 0],\n        duration=10.0,\n        dt=0.01,\n        integration_method=method\n    )\n    results[method] = result\n\n    # Analyze energy conservation\n    energy_drift = np.abs(result.energy[-1] - result.energy[0])\n    print(f\"{method.upper()}: Energy drift = {energy_drift:.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2b1936c4"
  },
  {
    "id": "engines_vector_sim_1_a7a3c2aa",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 1,
    "code": "@numba.jit(nopython=True, parallel=True)\ndef batch_integrate(X, U, dt, N):\n    for i in numba.prange(B):  # Parallel loop\n        X[i] = integrate_single(X[i], U[i], dt, N)\n    return X",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7a3c2aa"
  },
  {
    "id": "engines_vector_sim_2_3403b312",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 2,
    "code": "# Good: C-contiguous\nX = np.ascontiguousarray(X)  # Row-major\n\n# Bad: Non-contiguous views\nX_bad = X[:, ::2]  # Strided access",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3403b312"
  },
  {
    "id": "engines_vector_sim_3_85ab5836",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 3,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "engines_vector_sim_4_23946eea",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 4,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "engines_vector_sim_5_cc9e95a6",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 5,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "engines_vector_sim_6_6769f592",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 6,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "engines_vector_sim_7_eb487547",
    "file": "docs\\reference\\simulation\\engines_vector_sim.md",
    "index": 7,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "engines___init___1_85ab5836",
    "file": "docs\\reference\\simulation\\engines___init__.md",
    "index": 1,
    "code": "from src.simulation.core import SimulationEngine\nfrom src.simulation.engines import SimulationRunner\n\n# Initialize simulation engine\nrunner = SimulationRunner(\n    controller=controller,\n    dynamics=dynamics,\n    integrator='rk4',\n    dt=0.01\n)\n\n# Run simulation\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0\n)\n\n# Extract trajectories\nt = results.time\nx = results.states\nu = results.controls",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85ab5836"
  },
  {
    "id": "engines___init___2_23946eea",
    "file": "docs\\reference\\simulation\\engines___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.adaptive import AdaptiveRK45Integrator\n\n# Create adaptive integrator\nintegrator = AdaptiveRK45Integrator(\n    rtol=1e-6,\n    atol=1e-8,\n    max_step=0.1,\n    min_step=1e-6\n)\n\n# Simulate with automatic step size control\nresults = runner.simulate(\n    x0=initial_state,\n    duration=5.0,\n    integrator=integrator\n)\n\n# Check step size history\nprint(f\"Steps taken: {len(results.time)}\")\nprint(f\"Average dt: {np.mean(np.diff(results.time)):.6f}\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "23946eea"
  },
  {
    "id": "engines___init___3_cc9e95a6",
    "file": "docs\\reference\\simulation\\engines___init__.md",
    "index": 3,
    "code": "from src.simulation.engines import run_batch_simulation\n\n# Define batch of initial conditions\nx0_batch = np.random.randn(100, 6)  # 100 initial states\n\n# Vectorized batch simulation\nresults_batch = run_batch_simulation(\n    controller=controller,\n    dynamics=dynamics,\n    x0_batch=x0_batch,\n    duration=5.0,\n    dt=0.01\n)\n\n# Compute batch statistics\nmean_trajectory = np.mean(results_batch.states, axis=0)\nstd_trajectory = np.std(results_batch.states, axis=0)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc9e95a6"
  },
  {
    "id": "engines___init___4_6769f592",
    "file": "docs\\reference\\simulation\\engines___init__.md",
    "index": 4,
    "code": "from src.simulation.context import SimulationContext\nfrom src.simulation.safety import SafetyGuards\n\n# Configure safety constraints\nsafety = SafetyGuards(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    deadline_ms=10.0,\n    max_condition_number=1e6\n)\n\n# Simulation with safety monitoring\nwith SimulationContext(controller, dynamics, safety) as ctx:\n    results = ctx.simulate(x0, duration=5.0)\n\n    # Check safety violations\n    violations = ctx.get_safety_violations()\n    if violations:\n        print(f\"Warning: {len(violations)} safety events detected\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6769f592"
  },
  {
    "id": "engines___init___5_eb487547",
    "file": "docs\\reference\\simulation\\engines___init__.md",
    "index": 5,
    "code": "import time\nfrom src.simulation.engines import SimulationRunner\n\n# Profile different integrators\nintegrators = ['euler', 'rk4', 'rk45']\ntimes = {}\n\nfor method in integrators:\n    runner = SimulationRunner(\n        controller=controller,\n        dynamics=dynamics,\n        integrator=method,\n        dt=0.01\n    )\n\n    start = time.perf_counter()\n    results = runner.simulate(x0, duration=10.0)\n    elapsed = time.perf_counter() - start\n\n    times[method] = elapsed\n    print(f\"{method}: {elapsed:.4f}s ({len(results.time)} steps)\")\n\n# Compare speedup\nprint(f\"\\nRK4 vs Euler speedup: {times['euler']/times['rk4']:.2f}x\")",
    "lines": 24,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "eb487547"
  },
  {
    "id": "integrators_adaptive_error_control_1_6ca41722",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\nwhile t < t_final:\n    # Attempt integration step\n    y_new, y_hat = integrate_step(t, y, dt)\n\n    # Estimate error\n    error = norm((y_new - y_hat) / (atol + abs(y_new) * rtol))\n\n    # Acceptance decision\n    if error <= 1.0:\n        # Accept step\n        t += dt\n        y = y_new\n\n        # Increase step size for next step\n        dt_new = 0.9 * dt * error**(-1/5)\n    else:\n        # Reject step\n        # Decrease step size and retry\n        dt_new = 0.9 * dt * error**(-1/4)\n\n    # Apply safety bounds\n    dt = clip(dt_new, dt_min, dt_max)",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ca41722"
  },
  {
    "id": "integrators_adaptive_error_control_2_ff2fb8a9",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 2,
    "code": "from src.simulation.integrators import IntegratorsAdaptiveErrorControl\n\n# Initialize\ninstance = IntegratorsAdaptiveErrorControl()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ff2fb8a9"
  },
  {
    "id": "integrators_adaptive_error_control_3_6ad0116d",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 3,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsAdaptiveErrorControl(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6ad0116d"
  },
  {
    "id": "integrators_adaptive_error_control_4_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 4,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_adaptive_error_control_5_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 5,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_adaptive_error_control_6_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_adaptive_error_control.md",
    "index": 6,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_adaptive_runge_kutta_1_36bd9819",
    "file": "docs\\reference\\simulation\\integrators_adaptive_runge_kutta.md",
    "index": 1,
    "code": "from src.simulation.integrators import IntegratorsAdaptiveRungeKutta\n\n# Initialize\ninstance = IntegratorsAdaptiveRungeKutta()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "36bd9819"
  },
  {
    "id": "integrators_adaptive_runge_kutta_2_b9c9bcae",
    "file": "docs\\reference\\simulation\\integrators_adaptive_runge_kutta.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsAdaptiveRungeKutta(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b9c9bcae"
  },
  {
    "id": "integrators_adaptive_runge_kutta_3_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_adaptive_runge_kutta.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_adaptive_runge_kutta_4_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_adaptive_runge_kutta.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_adaptive_runge_kutta_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_adaptive_runge_kutta.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_adaptive___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\integrators_adaptive___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators_adaptive___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators_adaptive___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators_adaptive___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators_adaptive___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators_adaptive___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators_adaptive___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators_adaptive___init___5_735832df",
    "file": "docs\\reference\\simulation\\integrators_adaptive___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "integrators_base_1_bfc98258",
    "file": "docs\\reference\\simulation\\integrators_base.md",
    "index": 1,
    "code": "from src.simulation.integrators import IntegratorsBase\n\n# Initialize\ninstance = IntegratorsBase()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bfc98258"
  },
  {
    "id": "integrators_base_2_f2f4ae40",
    "file": "docs\\reference\\simulation\\integrators_base.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsBase(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2f4ae40"
  },
  {
    "id": "integrators_base_3_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_base.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_base_4_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_base.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_base_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_base.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_compatibility_1_b773e758",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 1,
    "code": "class CompatibilityIntegrator:\n    def integrate(self, dynamics, state, control, dt):\n        # Dispatch to appropriate method\n        pass",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b773e758"
  },
  {
    "id": "integrators_compatibility_2_4496d56a",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 2,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators_compatibility_3_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 3,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators_compatibility_4_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 4,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators_compatibility_5_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 5,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators_compatibility_6_735832df",
    "file": "docs\\reference\\simulation\\integrators_compatibility.md",
    "index": 6,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "integrators_discrete_zero_order_hold_1_4496d56a",
    "file": "docs\\reference\\simulation\\integrators_discrete_zero_order_hold.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators_discrete_zero_order_hold_2_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators_discrete_zero_order_hold.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators_discrete_zero_order_hold_3_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators_discrete_zero_order_hold.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators_discrete_zero_order_hold_4_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators_discrete_zero_order_hold.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators_discrete_zero_order_hold_5_735832df",
    "file": "docs\\reference\\simulation\\integrators_discrete_zero_order_hold.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "integrators_discrete___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\integrators_discrete___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators_discrete___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators_discrete___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators_discrete___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators_discrete___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators_discrete___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators_discrete___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators_discrete___init___5_735832df",
    "file": "docs\\reference\\simulation\\integrators_discrete___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "integrators_factory_1_856a5596",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 1,
    "code": "IntegratorConfig = {\n    'method': str,           # 'euler', 'rk2', 'rk4', 'rk45'\n    'dt': float,             # Fixed step size (for fixed-step methods)\n    'rtol': float,           # Relative tolerance (adaptive only)\n    'atol': float,           # Absolute tolerance (adaptive only)\n    'min_step': float,       # Minimum step size (adaptive only)\n    'max_step': float,       # Maximum step size (adaptive only)\n    'safety_factor': float,  # Step size safety factor (adaptive only)\n}",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "856a5596"
  },
  {
    "id": "integrators_factory_2_0f0cee16",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nclass IntegratorFactory:\n    _registry = {}\n\n    @classmethod\n    def register(cls, name, integrator_class):\n        cls._registry[name] = integrator_class\n\n    @classmethod\n    def create(cls, method_name, config):\n        if method_name not in cls._registry:\n            raise ValueError(f\"Unknown integrator: {method_name}\")\n        return cls._registry[method_name](config)",
    "lines": 15,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0f0cee16"
  },
  {
    "id": "integrators_factory_3_0313061e",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 3,
    "code": "factory.register('my_method', MyCustomIntegrator)\nintegrator = factory.create('my_method', config)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0313061e"
  },
  {
    "id": "integrators_factory_4_93d0f26d",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 4,
    "code": "from src.simulation.integrators import IntegratorsFactory\n\n# Initialize\ninstance = IntegratorsFactory()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "93d0f26d"
  },
  {
    "id": "integrators_factory_5_1d9c8574",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 5,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsFactory(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1d9c8574"
  },
  {
    "id": "integrators_factory_6_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 6,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_factory_7_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 7,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_factory_8_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_factory.md",
    "index": 8,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_fixed_step_euler_1_f0102785",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_euler.md",
    "index": 1,
    "code": "from src.simulation.integrators import IntegratorsFixedStepEuler\n\n# Initialize\ninstance = IntegratorsFixedStepEuler()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f0102785"
  },
  {
    "id": "integrators_fixed_step_euler_2_ad6b8f78",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_euler.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsFixedStepEuler(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad6b8f78"
  },
  {
    "id": "integrators_fixed_step_euler_3_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_euler.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_fixed_step_euler_4_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_euler.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_fixed_step_euler_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_euler.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_fixed_step_runge_kutta_1_cfd65544",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_runge_kutta.md",
    "index": 1,
    "code": "from src.simulation.integrators import IntegratorsFixedStepRungeKutta\n\n# Initialize\ninstance = IntegratorsFixedStepRungeKutta()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cfd65544"
  },
  {
    "id": "integrators_fixed_step_runge_kutta_2_ad911292",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_runge_kutta.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = IntegratorsFixedStepRungeKutta(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad911292"
  },
  {
    "id": "integrators_fixed_step_runge_kutta_3_c42c2702",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_runge_kutta.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "integrators_fixed_step_runge_kutta_4_76e79aac",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_runge_kutta.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "integrators_fixed_step_runge_kutta_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\integrators_fixed_step_runge_kutta.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "integrators_fixed_step___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\integrators_fixed_step___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators_fixed_step___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators_fixed_step___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators_fixed_step___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators_fixed_step___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators_fixed_step___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators_fixed_step___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators_fixed_step___init___5_735832df",
    "file": "docs\\reference\\simulation\\integrators_fixed_step___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "integrators___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\integrators___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "integrators___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\integrators___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "integrators___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\integrators___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "integrators___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\integrators___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "integrators___init___5_735832df",
    "file": "docs\\reference\\simulation\\integrators___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "orchestrators_base_1_969bbbbd",
    "file": "docs\\reference\\simulation\\orchestrators_base.md",
    "index": 1,
    "code": "from src.simulation.orchestrators import OrchestratorsBase\n\n# Initialize\ninstance = OrchestratorsBase()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "969bbbbd"
  },
  {
    "id": "orchestrators_base_2_ae341ff1",
    "file": "docs\\reference\\simulation\\orchestrators_base.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = OrchestratorsBase(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae341ff1"
  },
  {
    "id": "orchestrators_base_3_c42c2702",
    "file": "docs\\reference\\simulation\\orchestrators_base.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "orchestrators_base_4_76e79aac",
    "file": "docs\\reference\\simulation\\orchestrators_base.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "orchestrators_base_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\orchestrators_base.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "orchestrators_batch_1_bb9f8a17",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 1,
    "code": "# Batch state update (B \u00d7 n)\nx_new = x_batch + dt * f(x_batch, u_batch)  # Element-wise operations",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb9f8a17"
  },
  {
    "id": "orchestrators_batch_2_3accf06d",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 2,
    "code": "@njit(parallel=True, fastmath=True)\ndef batch_simulate(x0_batch, u_batch, dt, steps):\n    # Compiled to optimized machine code",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3accf06d"
  },
  {
    "id": "orchestrators_batch_3_6b9af19e",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\nstates = [(x1, theta1, theta2, ...), ...]  # Poor cache locality",
    "lines": 4,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b9af19e"
  },
  {
    "id": "orchestrators_batch_4_02c4c671",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\nx = [x1, x2, ..., xB]           # Excellent cache locality\ntheta1 = [\u03b81_1, \u03b81_2, ..., \u03b81_B]  # Contiguous memory",
    "lines": 5,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "02c4c671"
  },
  {
    "id": "orchestrators_batch_5_6fd46798",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 5,
    "code": "from src.simulation.orchestrators import OrchestratorsBatch\n\n# Initialize\ninstance = OrchestratorsBatch()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6fd46798"
  },
  {
    "id": "orchestrators_batch_6_8aa34eb5",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 6,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = OrchestratorsBatch(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8aa34eb5"
  },
  {
    "id": "orchestrators_batch_7_c42c2702",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 7,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "orchestrators_batch_8_76e79aac",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 8,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "orchestrators_batch_9_e0ee2eec",
    "file": "docs\\reference\\simulation\\orchestrators_batch.md",
    "index": 9,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "orchestrators_parallel_1_4c16d872",
    "file": "docs\\reference\\simulation\\orchestrators_parallel.md",
    "index": 1,
    "code": "from src.simulation.orchestrators import OrchestratorsParallel\n\n# Initialize\ninstance = OrchestratorsParallel()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4c16d872"
  },
  {
    "id": "orchestrators_parallel_2_8b3c39a0",
    "file": "docs\\reference\\simulation\\orchestrators_parallel.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = OrchestratorsParallel(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8b3c39a0"
  },
  {
    "id": "orchestrators_parallel_3_c42c2702",
    "file": "docs\\reference\\simulation\\orchestrators_parallel.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "orchestrators_parallel_4_76e79aac",
    "file": "docs\\reference\\simulation\\orchestrators_parallel.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "orchestrators_parallel_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\orchestrators_parallel.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "orchestrators_sequential_1_c76cb51c",
    "file": "docs\\reference\\simulation\\orchestrators_sequential.md",
    "index": 1,
    "code": "from src.simulation.orchestrators import OrchestratorsSequential\n\n# Initialize\ninstance = OrchestratorsSequential()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c76cb51c"
  },
  {
    "id": "orchestrators_sequential_2_3b52941b",
    "file": "docs\\reference\\simulation\\orchestrators_sequential.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = OrchestratorsSequential(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3b52941b"
  },
  {
    "id": "orchestrators_sequential_3_c42c2702",
    "file": "docs\\reference\\simulation\\orchestrators_sequential.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "orchestrators_sequential_4_76e79aac",
    "file": "docs\\reference\\simulation\\orchestrators_sequential.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "orchestrators_sequential_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\orchestrators_sequential.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "safety_constraints_1_65df0e4c",
    "file": "docs\\reference\\simulation\\safety_constraints.md",
    "index": 1,
    "code": "from src.simulation.safety import SafetyConstraints\n\n# Initialize\ninstance = SafetyConstraints()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "65df0e4c"
  },
  {
    "id": "safety_constraints_2_cc64c311",
    "file": "docs\\reference\\simulation\\safety_constraints.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = SafetyConstraints(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cc64c311"
  },
  {
    "id": "safety_constraints_3_c42c2702",
    "file": "docs\\reference\\simulation\\safety_constraints.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "safety_constraints_4_76e79aac",
    "file": "docs\\reference\\simulation\\safety_constraints.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "safety_constraints_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\safety_constraints.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "safety_guards_1_c5c41d5a",
    "file": "docs\\reference\\simulation\\safety_guards.md",
    "index": 1,
    "code": "from src.simulation.safety import SafetyGuards\n\n# Initialize\ninstance = SafetyGuards()\n\n# Execute\nresult = instance.process(data)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c5c41d5a"
  },
  {
    "id": "safety_guards_2_0aca7c90",
    "file": "docs\\reference\\simulation\\safety_guards.md",
    "index": 2,
    "code": "# Custom configuration\nconfig = {'parameter': 'value'}\ninstance = SafetyGuards(config)\nresult = instance.process(data)",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0aca7c90"
  },
  {
    "id": "safety_guards_3_c42c2702",
    "file": "docs\\reference\\simulation\\safety_guards.md",
    "index": 3,
    "code": "try:\n    result = instance.process(data)\nexcept Exception as e:\n    print(f\"Error: {e}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c42c2702"
  },
  {
    "id": "safety_guards_4_76e79aac",
    "file": "docs\\reference\\simulation\\safety_guards.md",
    "index": 4,
    "code": "import time\nstart = time.time()\nresult = instance.process(data)\nelapsed = time.time() - start\nprint(f\"Execution time: {elapsed:.4f} s\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76e79aac"
  },
  {
    "id": "safety_guards_5_e0ee2eec",
    "file": "docs\\reference\\simulation\\safety_guards.md",
    "index": 5,
    "code": "# Combine with other simulation components\nresult = orchestrator.execute(instance.process(data))",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e0ee2eec"
  },
  {
    "id": "safety_monitors_1_4496d56a",
    "file": "docs\\reference\\simulation\\safety_monitors.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "safety_monitors_2_3367d4b6",
    "file": "docs\\reference\\simulation\\safety_monitors.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "safety_monitors_3_c862a3fa",
    "file": "docs\\reference\\simulation\\safety_monitors.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "safety_monitors_4_224bd4ab",
    "file": "docs\\reference\\simulation\\safety_monitors.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "safety_monitors_5_735832df",
    "file": "docs\\reference\\simulation\\safety_monitors.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "safety_recovery_1_4496d56a",
    "file": "docs\\reference\\simulation\\safety_recovery.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "safety_recovery_2_3367d4b6",
    "file": "docs\\reference\\simulation\\safety_recovery.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "safety_recovery_3_c862a3fa",
    "file": "docs\\reference\\simulation\\safety_recovery.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "safety_recovery_4_224bd4ab",
    "file": "docs\\reference\\simulation\\safety_recovery.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "safety_recovery_5_735832df",
    "file": "docs\\reference\\simulation\\safety_recovery.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "safety___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\safety___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "safety___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\safety___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "safety___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\safety___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "safety___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\safety___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "safety___init___5_735832df",
    "file": "docs\\reference\\simulation\\safety___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "strategies_monte_carlo_1_4496d56a",
    "file": "docs\\reference\\simulation\\strategies_monte_carlo.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "strategies_monte_carlo_2_3367d4b6",
    "file": "docs\\reference\\simulation\\strategies_monte_carlo.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "strategies_monte_carlo_3_c862a3fa",
    "file": "docs\\reference\\simulation\\strategies_monte_carlo.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "strategies_monte_carlo_4_224bd4ab",
    "file": "docs\\reference\\simulation\\strategies_monte_carlo.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "strategies_monte_carlo_5_735832df",
    "file": "docs\\reference\\simulation\\strategies_monte_carlo.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "strategies___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\strategies___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "strategies___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\strategies___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "strategies___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\strategies___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "strategies___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\strategies___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "strategies___init___5_735832df",
    "file": "docs\\reference\\simulation\\strategies___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "validation___init___1_4496d56a",
    "file": "docs\\reference\\simulation\\validation___init__.md",
    "index": 1,
    "code": "from src.simulation.integrators import create_integrator\n\n# Create integrator\nintegrator = create_integrator('rk4', dt=0.01)\n\n# Integrate one step\nx_next = integrator.integrate(dynamics_fn, x, u, dt)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4496d56a"
  },
  {
    "id": "validation___init___2_3367d4b6",
    "file": "docs\\reference\\simulation\\validation___init__.md",
    "index": 2,
    "code": "from src.simulation.integrators.discrete import ZeroOrderHold\n\n# Linear system matrices\nA = np.array([[0, 1], [-2, -3]])\nB = np.array([[0], [1]])\n\n# Create ZOH integrator\nzoh = ZeroOrderHold(A, B, dt=0.01)\n\n# Discrete-time evolution\nx_next = zoh.integrate(None, x, u, dt)\n\n# Access discrete matrices\nA_d = zoh.A_d\nB_d = zoh.B_d",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3367d4b6"
  },
  {
    "id": "validation___init___3_c862a3fa",
    "file": "docs\\reference\\simulation\\validation___init__.md",
    "index": 3,
    "code": "from src.simulation.safety import SimulationPerformanceMonitor\n\n# Create monitor\nmonitor = SimulationPerformanceMonitor()\n\n# Simulation loop with monitoring\nfor i in range(N_steps):\n    monitor.start_timing('step')\n\n    u = controller.compute(x)\n    x = integrator.integrate(dynamics, x, u, dt)\n\n    elapsed = monitor.end_timing('step')\n\n    if elapsed > deadline:\n        print(f\"Deadline violation at step {i}: {elapsed:.4f}s\")\n\n# Get statistics\nstats = monitor.get_statistics()\nprint(f\"Mean: {stats['mean']:.4f}s\")\nprint(f\"95th percentile: {stats['p95']:.4f}s\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c862a3fa"
  },
  {
    "id": "validation___init___4_224bd4ab",
    "file": "docs\\reference\\simulation\\validation___init__.md",
    "index": 4,
    "code": "from src.simulation.strategies import MonteCarloStrategy\n\n# Define parameter distributions\ndistributions = {\n    'mass': ('normal', {'mean': 1.0, 'std': 0.1}),\n    'length': ('uniform', {'low': 0.9, 'high': 1.1})\n}\n\n# Create Monte Carlo strategy\nmc = MonteCarloStrategy(n_samples=1000, parallel=True)\n\n# Run Monte Carlo analysis\nresults = mc.analyze(\n    simulation_fn=run_simulation,\n    parameters=distributions\n)\n\n# Extract statistics\nprint(f\"Mean ISE: {results['metrics']['ise']['mean']:.4f}\")\nprint(f\"95% CI: [{results['metrics']['ise']['ci_lower']:.4f}, \"\n      f\"{results['metrics']['ise']['ci_upper']:.4f}]\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "224bd4ab"
  },
  {
    "id": "validation___init___5_735832df",
    "file": "docs\\reference\\simulation\\validation___init__.md",
    "index": 5,
    "code": "from src.simulation.safety import SafetyRecovery\n\n# Configure recovery\nrecovery = SafetyRecovery(\n    state_bounds=(-10, 10),\n    control_bounds=(-100, 100),\n    recovery_mode='qp'  # or 'projection', 'fallback'\n)\n\n# Simulation with safety recovery\nfor i in range(N_steps):\n    u = controller.compute(x)\n\n    # Check for violations\n    if recovery.check_violation(x, u):\n        x_safe, u_safe = recovery.recover(x, u)\n        x = integrator.integrate(dynamics, x_safe, u_safe, dt)\n    else:\n        x = integrator.integrate(dynamics, x, u, dt)",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "735832df"
  },
  {
    "id": "development_jupyter_tools_1_9d2a9f78",
    "file": "docs\\reference\\utils\\development_jupyter_tools.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "development_jupyter_tools_2_e64596c8",
    "file": "docs\\reference\\utils\\development_jupyter_tools.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "development_jupyter_tools_3_2bb1a341",
    "file": "docs\\reference\\utils\\development_jupyter_tools.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "development_jupyter_tools_4_5c33c7d4",
    "file": "docs\\reference\\utils\\development_jupyter_tools.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "development_jupyter_tools_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\development_jupyter_tools.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "development___init___1_c8eb368a",
    "file": "docs\\reference\\utils\\development___init__.md",
    "index": 1,
    "code": "from src.utils.development import load_simulation_environment\n\n# Load environment in Jupyter\n%load_ext autoreload\n%autoreload 2\n\n# Load simulation tools\nfrom src.utils.development import JupyterTools\ntools = JupyterTools()\n\n# Interactive plotting\n%matplotlib inline\ntools.plot_controller_performance(results)\n\n# Timing analysis\n%timeit controller.compute_control(x, state_vars, history)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c8eb368a"
  },
  {
    "id": "development___init___2_2e8e19a6",
    "file": "docs\\reference\\utils\\development___init__.md",
    "index": 2,
    "code": "from src.utils.development import DebugTools\nimport numpy as np\n\n# Enable interactive debugging\ndebug = DebugTools()\n\ndef problematic_function(x):\n    # Set breakpoint\n    debug.set_breakpoint()\n\n    # Inspect variables\n    debug.inspect_state(x)\n\n    # Step through computation\n    result = compute_control(x)\n\n    return result\n\n# Debug in Jupyter\nx = np.random.randn(6)\nresult = problematic_function(x)  # Stops at breakpoint",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2e8e19a6"
  },
  {
    "id": "development___init___3_ecdffa52",
    "file": "docs\\reference\\utils\\development___init__.md",
    "index": 3,
    "code": "from src.utils.development import RichDisplay\nfrom IPython.display import display, Markdown\n\n# Create rich display helper\nrich = RichDisplay()\n\n# Display simulation results\ndef show_results(results):\n    # Text summary\n    display(Markdown(\"## Simulation Results\"))\n\n    # Data table\n    rich.display_table(results.metrics)\n\n    # Interactive plot\n    rich.display_plot(results.t, results.x)\n\n    # Animation preview\n    rich.display_animation(results, frames=100)\n\nshow_results(simulation_results)",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ecdffa52"
  },
  {
    "id": "development___init___4_5fed625d",
    "file": "docs\\reference\\utils\\development___init__.md",
    "index": 4,
    "code": "from src.utils.development import NotebookStateManager\n\n# Create state manager\nstate_mgr = NotebookStateManager()\n\n# Save current workspace\nstate_mgr.save_state('experiment_checkpoint.pkl')\n\n# Run risky computation\ntry:\n    risky_computation()\nexcept Exception as e:\n    # Restore previous state\n    state_mgr.restore_state('experiment_checkpoint.pkl')\n    print(f\"Restored state after error: {e}\")\n\n# Check state consistency\nif not state_mgr.check_consistency():\n    print(\"Warning: Notebook cells executed out of order\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5fed625d"
  },
  {
    "id": "development___init___5_37758865",
    "file": "docs\\reference\\utils\\development___init__.md",
    "index": 5,
    "code": "from src.utils.development import InteractiveTuner\nfrom ipywidgets import interact, FloatSlider\n\n# Create interactive tuner\ntuner = InteractiveTuner()\n\n# Define interactive controller tuning\n@interact(\n    k1=FloatSlider(min=1, max=50, step=1, value=10),\n    k2=FloatSlider(min=1, max=50, step=1, value=8),\n    k3=FloatSlider(min=1, max=50, step=1, value=15)\n)\ndef tune_controller(k1, k2, k3):\n    # Update controller gains\n    controller.set_gains([k1, k2, k3, 12.0, 50.0, 5.0])\n\n    # Run simulation\n    result = run_simulation(controller)\n\n    # Display performance\n    tuner.display_performance(result)\n\n    return result\n\n# Interactive tuning in Jupyter\n# Sliders appear, live updates as you adjust",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37758865"
  },
  {
    "id": "reproducibility_seed_1_9d2a9f78",
    "file": "docs\\reference\\utils\\reproducibility_seed.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "reproducibility_seed_2_e64596c8",
    "file": "docs\\reference\\utils\\reproducibility_seed.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "reproducibility_seed_3_2bb1a341",
    "file": "docs\\reference\\utils\\reproducibility_seed.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "reproducibility_seed_4_5c33c7d4",
    "file": "docs\\reference\\utils\\reproducibility_seed.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "reproducibility_seed_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\reproducibility_seed.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "reproducibility___init___1_d0b194e2",
    "file": "docs\\reference\\utils\\reproducibility___init__.md",
    "index": 1,
    "code": "from src.utils.reproducibility import set_seed\nimport numpy as np\n\n# Set global seed for reproducibility\nset_seed(42)\n\n# Generate random numbers\nrandom_values_1 = np.random.randn(10)\n\n# Reset seed - get same sequence\nset_seed(42)\nrandom_values_2 = np.random.randn(10)\n\n# Verify reproducibility\nassert np.allclose(random_values_1, random_values_2)\nprint(\"\u2713 Reproducibility verified\")",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d0b194e2"
  },
  {
    "id": "reproducibility___init___2_4d71ce0a",
    "file": "docs\\reference\\utils\\reproducibility___init__.md",
    "index": 2,
    "code": "from src.utils.reproducibility import set_seed\nimport numpy as np\n\ndef monte_carlo_simulation(n_trials: int, seed: int):\n    # Set seed for reproducible Monte Carlo\n    set_seed(seed)\n\n    results = []\n    for i in range(n_trials):\n        # Simulate with random initial conditions\n        x0 = np.random.randn(6) * 0.1\n        result = run_simulation(x0)\n        results.append(result)\n\n    return np.mean(results), np.std(results)\n\n# Run twice with same seed - get identical results\nmean1, std1 = monte_carlo_simulation(1000, seed=42)\nmean2, std2 = monte_carlo_simulation(1000, seed=42)\n\nassert mean1 == mean2 and std1 == std2\nprint(\"\u2713 Monte Carlo reproducibility confirmed\")",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4d71ce0a"
  },
  {
    "id": "reproducibility___init___3_c303be88",
    "file": "docs\\reference\\utils\\reproducibility___init__.md",
    "index": 3,
    "code": "from src.utils.reproducibility import set_seed\nfrom src.optimizer import PSOTuner\n\ndef reproducible_pso_tuning(seed: int):\n    # Set seed before PSO initialization\n    set_seed(seed)\n\n    # Create PSO tuner\n    tuner = PSOTuner(\n        n_particles=30,\n        iters=100,\n        bounds=[(0.1, 50.0)] * 6\n    )\n\n    # Optimize (deterministic with fixed seed)\n    best_gains, best_fitness = tuner.optimize(fitness_function)\n\n    return best_gains\n\n# Verify PSO reproducibility\ngains_run1 = reproducible_pso_tuning(seed=123)\ngains_run2 = reproducible_pso_tuning(seed=123)\n\nassert np.allclose(gains_run1, gains_run2)\nprint(\"\u2713 PSO optimization is reproducible\")",
    "lines": 25,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c303be88"
  },
  {
    "id": "reproducibility___init___4_ad2e184d",
    "file": "docs\\reference\\utils\\reproducibility___init__.md",
    "index": 4,
    "code": "from src.utils.reproducibility import capture_random_state, restore_random_state\nimport numpy as np\n\n# Generate some random numbers\nset_seed(42)\nvalues_before = np.random.randn(5)\n\n# Capture current RNG state\nstate = capture_random_state()\n\n# Generate more numbers (changes state)\nnp.random.randn(100)\n\n# Restore previous state\nrestore_random_state(state)\n\n# Continue from captured state\nvalues_after = np.random.randn(5)\n\n# Should match continuation from before\nprint(\"State restoration allows sequence continuation\")",
    "lines": 21,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad2e184d"
  },
  {
    "id": "reproducibility___init___5_3622c6a3",
    "file": "docs\\reference\\utils\\reproducibility___init__.md",
    "index": 5,
    "code": "from src.utils.reproducibility import set_seed, capture_random_state\nimport json\nfrom pathlib import Path\n\nclass ReproducibleExperiment:\n    def __init__(self, name: str, seed: int):\n        self.name = name\n        self.seed = seed\n        set_seed(seed)\n        self.initial_state = capture_random_state()\n\n    def run(self):\n        # Restore initial state for clean run\n        restore_random_state(self.initial_state)\n\n        # Run experiment\n        results = self.execute_experiment()\n\n        # Save results with metadata\n        self.save_results(results)\n\n        return results\n\n    def save_results(self, results):\n        metadata = {\n            'experiment': self.name,\n            'seed': self.seed,\n            'results': results\n        }\n\n        Path('results').mkdir(exist_ok=True)\n        with open(f'results/{self.name}_seed{self.seed}.json', 'w') as f:\n            json.dump(metadata, f, indent=2)\n\n# Run reproducible experiment\nexp = ReproducibleExperiment(\"controller_comparison\", seed=42)\nresults = exp.run()\n\n# Re-run with same seed - identical results guaranteed\nexp2 = ReproducibleExperiment(\"controller_comparison\", seed=42)\nresults2 = exp2.run()\n\nassert results == results2\nprint(\"\u2713 Full experiment reproducibility achieved\")",
    "lines": 44,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "3622c6a3"
  },
  {
    "id": "types_control_outputs_1_9d2a9f78",
    "file": "docs\\reference\\utils\\types_control_outputs.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "types_control_outputs_2_e64596c8",
    "file": "docs\\reference\\utils\\types_control_outputs.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "types_control_outputs_3_2bb1a341",
    "file": "docs\\reference\\utils\\types_control_outputs.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "types_control_outputs_4_5c33c7d4",
    "file": "docs\\reference\\utils\\types_control_outputs.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "types_control_outputs_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\types_control_outputs.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "types___init___1_c691e7df",
    "file": "docs\\reference\\utils\\types___init__.md",
    "index": 1,
    "code": "from src.utils.types import ClassicalSMCOutput\nimport numpy as np\n\n# Controller computation returns structured output\ndef compute_control(x):\n    u = np.array([10.0])\n    state_vars = {'sliding_surface': 0.5}\n    history = np.array([[0.0]])\n\n    # Type-safe return with named fields\n    return ClassicalSMCOutput(u, state_vars, history)\n\n# Client code uses descriptive names\noutput = compute_control(x)\ncontrol = output.u\nsurface = output.state_vars['sliding_surface']\npast_controls = output.history",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c691e7df"
  },
  {
    "id": "types___init___2_682b7493",
    "file": "docs\\reference\\utils\\types___init__.md",
    "index": 2,
    "code": "from src.utils.types import ClassicalSMCOutput, AdaptiveSMCOutput\nimport numpy as np\n\ndef validate_output(output):\n    # Runtime type checking\n    if isinstance(output, ClassicalSMCOutput):\n        print(\"Classical SMC output detected\")\n        assert hasattr(output, 'u')\n        assert hasattr(output, 'state_vars')\n        assert hasattr(output, 'history')\n    elif isinstance(output, AdaptiveSMCOutput):\n        print(\"Adaptive SMC output detected\")\n        assert hasattr(output, 'adaptive_gains')\n    else:\n        raise TypeError(f\"Unknown output type: {type(output)}\")\n\n# Validate outputs\nclassical_output = ClassicalSMCOutput(u, state_vars, history)\nvalidate_output(classical_output)  # \u2713 Pass",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "682b7493"
  },
  {
    "id": "types___init___3_f7e5bdfb",
    "file": "docs\\reference\\utils\\types___init__.md",
    "index": 3,
    "code": "from src.utils.types import STAOutput\n\n# Create immutable output\nsta_output = STAOutput(u, state_vars, history)\n\n# Attempt modification (will fail - NamedTuple is frozen)\ntry:\n    sta_output.u = np.array([20.0])  # AttributeError\nexcept AttributeError:\n    print(\"Immutability enforced - cannot modify output\")\n\n# Correct approach: Create new output\nmodified_output = STAOutput(\n    u=np.array([20.0]),\n    state_vars=sta_output.state_vars,\n    history=sta_output.history\n)",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f7e5bdfb"
  },
  {
    "id": "types___init___4_7c5e272f",
    "file": "docs\\reference\\utils\\types___init__.md",
    "index": 4,
    "code": "from src.utils.types import HybridSTAOutput\nfrom typing import Tuple\nimport numpy as np\n\ndef hybrid_controller(\n    x: np.ndarray,\n    state_vars: dict,\n    history: np.ndarray\n) -> HybridSTAOutput:\n    \\\"\\\"\\\"Type-annotated controller with structured output.\\\"\\\"\\\"\n    u = compute_hybrid_control(x)\n    updated_vars = update_state_vars(state_vars, x)\n    updated_history = np.vstack([history, u])\n\n    return HybridSTAOutput(u, updated_vars, updated_history)\n\n# Static type checker (mypy) validates this\noutput: HybridSTAOutput = hybrid_controller(x, state_vars, history)",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7c5e272f"
  },
  {
    "id": "types___init___5_7670c877",
    "file": "docs\\reference\\utils\\types___init__.md",
    "index": 5,
    "code": "from src.utils.types import ClassicalSMCOutput\nimport numpy as np\nfrom typing import List\n\ndef batch_control(states: List[np.ndarray]) -> List[ClassicalSMCOutput]:\n    \\\"\\\"\\\"Process multiple states with type-safe outputs.\\\"\\\"\\\"\n    outputs = []\n\n    for x in states:\n        u = controller.compute_control(x, state_vars, history)\n        # u is already ClassicalSMCOutput\n        outputs.append(u)\n\n    return outputs\n\n# Type-safe batch processing\nstates = [x1, x2, x3]\noutputs = batch_control(states)\n\n# Extract all controls (type-safe field access)\ncontrols = np.array([out.u for out in outputs])\nsurfaces = [out.state_vars['sliding_surface'] for out in outputs]",
    "lines": 22,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7670c877"
  },
  {
    "id": "validation_parameter_validators_1_9d2a9f78",
    "file": "docs\\reference\\utils\\validation_parameter_validators.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "validation_parameter_validators_2_e64596c8",
    "file": "docs\\reference\\utils\\validation_parameter_validators.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "validation_parameter_validators_3_2bb1a341",
    "file": "docs\\reference\\utils\\validation_parameter_validators.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "validation_parameter_validators_4_5c33c7d4",
    "file": "docs\\reference\\utils\\validation_parameter_validators.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "validation_parameter_validators_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\validation_parameter_validators.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "validation_range_validators_1_9d2a9f78",
    "file": "docs\\reference\\utils\\validation_range_validators.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "validation_range_validators_2_e64596c8",
    "file": "docs\\reference\\utils\\validation_range_validators.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "validation_range_validators_3_2bb1a341",
    "file": "docs\\reference\\utils\\validation_range_validators.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "validation_range_validators_4_5c33c7d4",
    "file": "docs\\reference\\utils\\validation_range_validators.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "validation_range_validators_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\validation_range_validators.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "validation___init___1_50e5ade4",
    "file": "docs\\reference\\utils\\validation___init__.md",
    "index": 1,
    "code": "from src.utils.validation import require_in_range\n\ndef set_control_gain(gain: float):\n    # Validate gain is in acceptable range\n    validated_gain = require_in_range(\n        gain, min_val=0.1, max_val=100.0,\n        name=\"control_gain\"\n    )\n    return validated_gain\n\n# Valid gain\nk = set_control_gain(10.0)  # \u2713 Returns 10.0\n\n# Invalid gain\ntry:\n    k = set_control_gain(150.0)  # ValueError: out of range\nexcept ValueError as e:\n    print(f\"Validation failed: {e}\")",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "50e5ade4"
  },
  {
    "id": "validation___init___2_fe3a99b9",
    "file": "docs\\reference\\utils\\validation___init__.md",
    "index": 2,
    "code": "from src.utils.validation import require_positive\n\ndef configure_pendulum(mass: float, length: float):\n    # Physical parameters must be positive\n    m = require_positive(mass, name=\"mass\")\n    L = require_positive(length, name=\"length\")\n\n    # Compute inertia\n    I = m * L**2\n    return I\n\n# Valid parameters\nI = configure_pendulum(1.0, 0.5)  # \u2713 Returns 0.25\n\n# Invalid parameters\ntry:\n    I = configure_pendulum(-1.0, 0.5)  # ValueError: must be positive\nexcept ValueError as e:\n    print(f\"Invalid mass: {e}\")",
    "lines": 19,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fe3a99b9"
  },
  {
    "id": "validation___init___3_64c52362",
    "file": "docs\\reference\\utils\\validation___init__.md",
    "index": 3,
    "code": "from src.utils.validation import require_probability\n\ndef set_confidence_level(alpha: float):\n    # Validate probability constraint\n    validated_alpha = require_probability(\n        alpha, name=\"confidence_level\"\n    )\n    return validated_alpha\n\n# Valid probability\nalpha = set_confidence_level(0.95)  # \u2713 Returns 0.95\n\n# Invalid probability\ntry:\n    alpha = set_confidence_level(1.5)  # ValueError: not in [0,1]\nexcept ValueError as e:\n    print(f\"Invalid confidence: {e}\")",
    "lines": 17,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "64c52362"
  },
  {
    "id": "validation___init___4_109d1390",
    "file": "docs\\reference\\utils\\validation___init__.md",
    "index": 4,
    "code": "from src.utils.validation import require_in_range, require_positive\nimport numpy as np\n\ndef validate_controller_parameters(params: dict):\n    # Multiple constraint validation\n    validated = {}\n\n    # Gains must be positive\n    for gain_name in ['k1', 'k2', 'k3']:\n        validated[gain_name] = require_positive(\n            params[gain_name], name=gain_name\n        )\n\n    # Max force in specific range\n    validated['max_force'] = require_in_range(\n        params['max_force'], min_val=10.0, max_val=200.0,\n        name=\"max_force\"\n    )\n\n    # Boundary layer must be small positive\n    validated['boundary_layer'] = require_in_range(\n        params['boundary_layer'], min_val=0.0, max_val=1.0,\n        name=\"boundary_layer\"\n    )\n\n    return validated\n\n# Validate complete parameter set\nparams = {\n    'k1': 10.0, 'k2': 8.0, 'k3': 15.0,\n    'max_force': 100.0,\n    'boundary_layer': 0.01\n}\nvalid_params = validate_controller_parameters(params)  # \u2713 All pass",
    "lines": 34,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "109d1390"
  },
  {
    "id": "validation___init___5_d7c700e8",
    "file": "docs\\reference\\utils\\validation___init__.md",
    "index": 5,
    "code": "from src.utils.validation import require_positive, require_in_range\nimport numpy as np\n\ndef validate_gains_array(gains: np.ndarray):\n    \\\"\\\"\\\"Validate array of controller gains.\\\"\\\"\\\"\n    # Check array dimensions\n    if gains.shape[0] != 6:\n        raise ValueError(f\"Expected 6 gains, got {gains.shape[0]}\")\n\n    # Validate each gain individually\n    for i, gain in enumerate(gains):\n        if i < 5:  # First 5 gains must be positive\n            require_positive(gain, name=f\"gain[{i}]\")\n        else:  # Last gain can be zero or positive\n            require_in_range(gain, min_val=0.0, max_val=100.0,\n                           name=f\"gain[{i}]\")\n\n    return gains\n\n# Valid gains\ngains = np.array([10.0, 8.0, 15.0, 12.0, 50.0, 5.0])\nvalidated_gains = validate_gains_array(gains)  # \u2713 Pass\n\n# Invalid gains\ntry:\n    bad_gains = np.array([10.0, -8.0, 15.0, 12.0, 50.0, 5.0])\n    validate_gains_array(bad_gains)  # ValueError: negative gain\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")",
    "lines": 29,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d7c700e8"
  },
  {
    "id": "visualization_animation_1_9d2a9f78",
    "file": "docs\\reference\\utils\\visualization_animation.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "visualization_animation_2_e64596c8",
    "file": "docs\\reference\\utils\\visualization_animation.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "visualization_animation_3_2bb1a341",
    "file": "docs\\reference\\utils\\visualization_animation.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "visualization_animation_4_5c33c7d4",
    "file": "docs\\reference\\utils\\visualization_animation.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "visualization_animation_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\visualization_animation.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "visualization_legacy_visualizer_1_9d2a9f78",
    "file": "docs\\reference\\utils\\visualization_legacy_visualizer.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "visualization_legacy_visualizer_2_e64596c8",
    "file": "docs\\reference\\utils\\visualization_legacy_visualizer.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "visualization_legacy_visualizer_3_2bb1a341",
    "file": "docs\\reference\\utils\\visualization_legacy_visualizer.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "visualization_legacy_visualizer_4_5c33c7d4",
    "file": "docs\\reference\\utils\\visualization_legacy_visualizer.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "visualization_legacy_visualizer_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\visualization_legacy_visualizer.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "visualization_movie_generator_1_9d2a9f78",
    "file": "docs\\reference\\utils\\visualization_movie_generator.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "visualization_movie_generator_2_e64596c8",
    "file": "docs\\reference\\utils\\visualization_movie_generator.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "visualization_movie_generator_3_2bb1a341",
    "file": "docs\\reference\\utils\\visualization_movie_generator.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "visualization_movie_generator_4_5c33c7d4",
    "file": "docs\\reference\\utils\\visualization_movie_generator.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "visualization_movie_generator_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\visualization_movie_generator.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "visualization_static_plots_1_9d2a9f78",
    "file": "docs\\reference\\utils\\visualization_static_plots.md",
    "index": 1,
    "code": "# Basic usage example\nfrom src.utils import Component\n\ncomponent = Component()\nresult = component.process(data)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9d2a9f78"
  },
  {
    "id": "visualization_static_plots_2_e64596c8",
    "file": "docs\\reference\\utils\\visualization_static_plots.md",
    "index": 2,
    "code": "# Advanced configuration\ncomponent = Component(\n    option1=value1,\n    option2=value2\n)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e64596c8"
  },
  {
    "id": "visualization_static_plots_3_2bb1a341",
    "file": "docs\\reference\\utils\\visualization_static_plots.md",
    "index": 3,
    "code": "# Integration example\nfrom src.simulation import SimulationRunner\n\nrunner = SimulationRunner()\nrunner.use_component(component)",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2bb1a341"
  },
  {
    "id": "visualization_static_plots_4_5c33c7d4",
    "file": "docs\\reference\\utils\\visualization_static_plots.md",
    "index": 4,
    "code": "# Performance-optimized usage\ncomponent = Component(enable_caching=True)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5c33c7d4"
  },
  {
    "id": "visualization_static_plots_5_5cd8aaa9",
    "file": "docs\\reference\\utils\\visualization_static_plots.md",
    "index": 5,
    "code": "# Error handling\ntry:\n    result = component.process(data)\nexcept ComponentError as e:\n    print(f\"Error: {e}\")",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5cd8aaa9"
  },
  {
    "id": "visualization___init___1_b59c46b9",
    "file": "docs\\reference\\utils\\visualization___init__.md",
    "index": 1,
    "code": "from src.utils.visualization import DIPAnimator\nimport numpy as np\n\n# Create animator\nanimator = DIPAnimator(\n    L1=0.3, L2=0.25,  # Pendulum lengths\n    fps=30,  # 30 frames per second\n    trail_length=50  # Show last 50 positions\n)\n\n# Animate simulation results\nanimator.animate(\n    t=t,  # Time vector\n    x=x,  # State trajectories\n    save_path=\"simulation.mp4\",\n    dpi=120\n)\n\nprint(f\"Animation created at 30 FPS\")\nprint(f\"Frame interval: {1000/30:.2f} ms\")",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b59c46b9"
  },
  {
    "id": "visualization___init___2_95eee3ae",
    "file": "docs\\reference\\utils\\visualization___init__.md",
    "index": 2,
    "code": "from src.utils.visualization import ControlPlotter\nimport matplotlib.pyplot as plt\n\n# Create plotter\nplotter = ControlPlotter()\n\n# Create comprehensive plot layout\nfig, axes = plotter.plot_comprehensive(\n    t=t, x=x, u=u,\n    reference=np.zeros_like(x),\n    title=\"Classical SMC Performance\"\n)\n\n# Customize appearance\nplotter.set_style('seaborn-v0_8-paper')\nplotter.add_grid(axes, alpha=0.3)\n\nplt.savefig('performance.png', dpi=300, bbox_inches='tight')",
    "lines": 18,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "95eee3ae"
  },
  {
    "id": "visualization___init___3_f008e0cf",
    "file": "docs\\reference\\utils\\visualization___init__.md",
    "index": 3,
    "code": "from src.utils.visualization import MultiSystemAnimator\n\n# Create comparison animator\nanimator = MultiSystemAnimator(\n    systems=['Classical SMC', 'Adaptive SMC', 'STA SMC'],\n    L1=0.3, L2=0.25,\n    layout='horizontal'  # Side-by-side comparison\n)\n\n# Animate multiple controllers\nanimator.animate_comparison(\n    t=t,\n    states=[x_classical, x_adaptive, x_sta],\n    save_path=\"comparison.mp4\",\n    fps=30\n)",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f008e0cf"
  },
  {
    "id": "visualization___init___4_19e193e3",
    "file": "docs\\reference\\utils\\visualization___init__.md",
    "index": 4,
    "code": "from src.utils.visualization import ProjectMovieGenerator, MovieScene\n\n# Create movie generator\ngenerator = ProjectMovieGenerator(\n    title=\"DIP SMC PSO Project\",\n    output_path=\"project_overview.mp4\",\n    fps=30,\n    resolution=(1920, 1080)\n)\n\n# Define scenes\nscenes = [\n    MovieScene('intro', duration=5.0, content=\"Title and overview\"),\n    MovieScene('simulation', duration=10.0, content=simulation_results),\n    MovieScene('comparison', duration=8.0, content=comparison_data),\n    MovieScene('conclusion', duration=3.0, content=\"Summary\")\n]\n\n# Generate complete movie\ngenerator.create_movie(scenes)",
    "lines": 20,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "19e193e3"
  },
  {
    "id": "visualization___init___5_1bfcabb1",
    "file": "docs\\reference\\utils\\visualization___init__.md",
    "index": 5,
    "code": "from src.utils.visualization import ControlPlotter\nimport numpy as np\n\n# Define perceptually uniform color scheme\ncolors = {\n    'state': '#1f77b4',  # Blue\n    'control': '#ff7f0e',  # Orange\n    'reference': '#2ca02c',  # Green\n    'error': '#d62728'  # Red\n}\n\nplotter = ControlPlotter(color_scheme=colors)\n\n# Plot with consistent colors\nfig, axes = plt.subplots(2, 1, figsize=(10, 8))\n\naxes[0].plot(t, x[:, 1], color=colors['state'], label='\u03b8\u2081')\naxes[0].plot(t, ref, color=colors['reference'],\n            linestyle='--', label='Reference')\n\naxes[1].plot(t, u, color=colors['control'], label='Control')\naxes[1].axhline(0, color='gray', linestyle=':', alpha=0.5)\n\nfor ax in axes:\n    ax.legend()\n    ax.grid(alpha=0.3)\n\nplt.tight_layout()",
    "lines": 28,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1bfcabb1"
  },
  {
    "id": "control_systems_unit_testing_1_63fc0c4b",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_classical_smc_initialization():\n    \"\"\"Test Classical SMC initialization with valid parameters.\"\"\"\n    # Optimal gains from PSO optimization (report.log line 2)\n    gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]\n    boundary_layer = 9.76  # Matched to kd for chattering reduction\n    max_force = 20.0\n\n    controller = ClassicalSMC(\n        gains=gains,\n        max_force=max_force,\n        boundary_layer=boundary_layer,\n        switch_method='tanh'\n    )\n\n    # Verify gains unpacked correctly\n    assert controller.k1 == pytest.approx(77.62, rel=1e-6)\n    assert controller.k2 == pytest.approx(44.45, rel=1e-6)\n    assert controller.lam1 == pytest.approx(17.31, rel=1e-6)\n    assert controller.lam2 == pytest.approx(14.25, rel=1e-6)\n    assert controller.K == pytest.approx(18.66, rel=1e-6)\n    assert controller.kd == pytest.approx(9.76, rel=1e-6)\n\n    # Verify boundary layer for chattering reduction\n    assert controller.epsilon0 == pytest.approx(9.76)\n\n    # Verify control authority limits\n    assert controller.max_force == 20.0",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "63fc0c4b"
  },
  {
    "id": "control_systems_unit_testing_2_04f313cb",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_gain_positivity_enforcement():\n    \"\"\"Test strict positivity requirements for SMC gains.\"\"\"\n    boundary_layer = 0.1\n    max_force = 20.0\n\n    # Test k1 must be strictly positive\n    with pytest.raises(ValueError, match=\"k1.*must be > 0\"):\n        ClassicalSMC(\n            gains=[0.0, 44.45, 17.31, 14.25, 18.66, 9.76],\n            max_force=max_force,\n            boundary_layer=boundary_layer\n        )\n\n    # Test k2 must be strictly positive\n    with pytest.raises(ValueError, match=\"k2.*must be > 0\"):\n        ClassicalSMC(\n            gains=[77.62, -5.0, 17.31, 14.25, 18.66, 9.76],\n            max_force=max_force,\n            boundary_layer=boundary_layer\n        )\n\n    # Test lam1, lam2 must be strictly positive\n    with pytest.raises(ValueError, match=\"lam1.*must be > 0\"):\n        ClassicalSMC(\n            gains=[77.62, 44.45, 0.0, 14.25, 18.66, 9.76],\n            max_force=max_force,\n            boundary_layer=boundary_layer\n        )\n\n    # Test K (switching gain) must be strictly positive\n    with pytest.raises(ValueError, match=\"K.*must be > 0\"):\n        ClassicalSMC(\n            gains=[77.62, 44.45, 17.31, 14.25, -1.0, 9.76],\n            max_force=max_force,\n            boundary_layer=boundary_layer\n        )\n\n    # Test kd (derivative gain) can be zero but not negative\n    # This should NOT raise an error\n    controller = ClassicalSMC(\n        gains=[77.62, 44.45, 17.31, 14.25, 18.66, 0.0],\n        max_force=max_force,\n        boundary_layer=boundary_layer\n    )\n    assert controller.kd == 0.0\n\n    # But negative kd should fail\n    with pytest.raises(ValueError, match=\"kd.*must be\"):\n        ClassicalSMC(\n            gains=[77.62, 44.45, 17.31, 14.25, 18.66, -1.0],\n            max_force=max_force,\n            boundary_layer=boundary_layer\n        )",
    "lines": 56,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04f313cb"
  },
  {
    "id": "control_systems_unit_testing_3_71136983",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_state_vector_validation():\n    \"\"\"Test proper handling of state vectors with correct dimensions.\"\"\"\n    controller = create_test_controller()\n\n    # Valid 6D state: [x, theta1, theta2, xdot, dtheta1, dtheta2]\n    valid_state = np.array([0.1, 0.05, -0.03, 0.0, 0.1, -0.05])\n\n    result = controller.compute_control(\n        state=valid_state,\n        state_vars=(),\n        history={}\n    )\n\n    assert isinstance(result.u, (float, np.floating))\n    assert np.isfinite(result.u)\n\n    # Invalid state dimensions should be caught early\n    invalid_states = [\n        np.array([0.1, 0.05, 0.0]),  # Too short\n        np.array([0.1, 0.05, -0.03, 0.0, 0.1, -0.05, 0.0]),  # Too long\n    ]\n\n    for invalid_state in invalid_states:\n        with pytest.raises((ValueError, IndexError)):\n            controller.compute_control(\n                state=invalid_state,\n                state_vars=(),\n                history={}\n            )",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "71136983"
  },
  {
    "id": "control_systems_unit_testing_4_acd6a945",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_physical_state_bounds():\n    \"\"\"Test controller behavior within and beyond physical limits.\"\"\"\n    controller = create_test_controller()\n\n    # Test states within normal operating range\n    normal_states = [\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),  # Equilibrium\n        np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0]),  # Small displacement\n        np.array([0.5, 0.3, 0.2, 0.0, 0.0, 0.0]),  # Moderate displacement\n    ]\n\n    for state in normal_states:\n        result = controller.compute_control(state, (), {})\n\n        # Control must be finite and bounded\n        assert np.isfinite(result.u)\n        assert abs(result.u) <= controller.max_force\n\n    # Test extreme but valid states\n    extreme_states = [\n        np.array([0.0, np.pi/6, np.pi/6, 0.0, 2.0, 2.0]),  # Large angles/velocities\n        np.array([1.0, -np.pi/4, np.pi/4, 0.5, -1.5, 1.0]),  # Mixed extremes\n    ]\n\n    for state in extreme_states:\n        result = controller.compute_control(state, (), {})\n\n        # Must still produce finite, bounded control\n        assert np.isfinite(result.u)\n        assert abs(result.u) <= controller.max_force",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "acd6a945"
  },
  {
    "id": "control_systems_unit_testing_5_745e9041",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_lyapunov_decrease_property():\n    \"\"\"Test Lyapunov decrease property: V\u0307 < 0 when |\u03c3| > 0.\"\"\"\n    controller = create_test_controller()\n\n    # Test states with non-zero sliding surface values\n    test_states = [\n        np.array([0.0, 0.1, 0.0, 0.0, 0.0, 0.0]),   # Pendulum 1 displaced\n        np.array([0.0, 0.0, 0.1, 0.0, 0.0, 0.0]),   # Pendulum 2 displaced\n        np.array([0.0, 0.05, 0.05, 0.0, 0.1, 0.1]), # Both displaced with velocity\n    ]\n\n    history = {}\n\n    for state in test_states:\n        result = controller.compute_control(state, (), history)\n\n        # Extract sliding surface from history\n        assert 'sigma' in history\n        sigma = history['sigma'][-1]\n\n        # Lyapunov function V = 0.5 * sigma^2\n        V = 0.5 * sigma**2\n\n        # For non-zero sigma, ensure control acts to reduce V\n        if abs(sigma) > 1e-6:\n            # Control should oppose sigma to drive V\u0307 < 0\n            # For classical SMC: u = u_eq - K*sat(\u03c3/\u03b5) - kd*\u03c3\n            # The robust term -K*sat(\u03c3/\u03b5) should have opposite sign to \u03c3\n            u_robust = history['u_robust'][-1]\n\n            # Robust control should oppose sliding surface\n            assert np.sign(u_robust) == -np.sign(sigma) or abs(sigma) < controller.epsilon0",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "745e9041"
  },
  {
    "id": "control_systems_unit_testing_6_e3e55c87",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 6,
    "code": "def test_lyapunov_decrease_ratio_monitoring():\n    \"\"\"Test LDR monitoring for stability assessment.\"\"\"\n    from src.utils.monitoring.stability import LyapunovDecreaseMonitor\n\n    dt = 0.01\n    monitor = LyapunovDecreaseMonitor(\n        window_size_ms=300.0,\n        dt=dt,\n        ldr_threshold=0.95,\n        transient_time=1.0\n    )\n\n    controller = create_test_controller()\n\n    # Simulate trajectory\n    state = np.array([0.1, 0.2, -0.1, 0.0, 0.3, -0.2])\n    history = {}\n\n    ldr_values = []\n\n    for step in range(200):  # 2 seconds simulation\n        result = controller.compute_control(state, (), history)\n\n        # Extract sliding surface and update monitor\n        sigma = np.array([history['sigma'][-1]])\n        monitor_result = monitor.update(sigma)\n\n        # After transient period, check LDR\n        if monitor_result['status'] != 'transient':\n            ldr = monitor_result['ldr']\n            ldr_values.append(ldr)\n\n            # LDR should be high (>95%) for stable control\n            if len(ldr_values) > 50:  # After enough samples\n                recent_ldr = np.mean(ldr_values[-50:])\n                assert recent_ldr >= 0.90, \\\n                    f\"LDR too low: {recent_ldr:.2%} (should be \u226590%)\"\n\n        # Simple state update (mock dynamics)\n        state[3:] += -0.1 * state[:3] * dt  # Simplified dynamics\n        state[:3] += state[3:] * dt",
    "lines": 41,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3e55c87"
  },
  {
    "id": "control_systems_unit_testing_7_a4480742",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_optimal_gains_performance():\n    \"\"\"Test performance characteristics of PSO-optimized gains.\"\"\"\n    # PSO optimal gains\n    optimal_gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]\n    boundary_layer = 9.76  # Matched to kd for maximum chattering reduction\n\n    controller = ClassicalSMC(\n        gains=optimal_gains,\n        max_force=20.0,\n        boundary_layer=boundary_layer,\n        switch_method='tanh'\n    )\n\n    # Analyze gain ratios for insights\n    k1, k2, lam1, lam2, K, kd = optimal_gains\n\n    # Ratio k1/k2 indicates relative importance of pendulum rates\n    k_ratio = k1 / k2\n    assert 1.5 < k_ratio < 2.0, \\\n        f\"k1/k2 ratio {k_ratio:.2f} indicates strong first pendulum damping\"\n\n    # Ratio lam1/lam2 indicates relative position error weighting\n    lam_ratio = lam1 / lam2\n    assert 1.0 < lam_ratio < 1.5, \\\n        f\"lam1/lam2 ratio {lam_ratio:.2f} indicates balanced position control\"\n\n    # Large K relative to lam ensures reaching condition\n    K_to_lam_ratio = K / max(lam1, lam2)\n    assert K_to_lam_ratio > 1.0, \\\n        f\"K/lam ratio {K_to_lam_ratio:.2f} ensures reaching condition satisfied\"\n\n    # Boundary layer matching kd for chattering-free operation\n    assert boundary_layer == kd, \\\n        \"Boundary layer matched to kd for optimal chattering suppression\"",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a4480742"
  },
  {
    "id": "control_systems_unit_testing_8_76a96874",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_chattering_reduction_with_large_boundary_layer():\n    \"\"\"Test that large boundary layer (9.76) effectively reduces chattering.\"\"\"\n    optimal_gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]\n\n    # Test with optimal boundary layer\n    controller_optimal = ClassicalSMC(\n        gains=optimal_gains,\n        max_force=20.0,\n        boundary_layer=9.76,  # Large boundary layer\n        switch_method='tanh'\n    )\n\n    # Test with small boundary layer for comparison\n    controller_small_bl = ClassicalSMC(\n        gains=optimal_gains,\n        max_force=20.0,\n        boundary_layer=0.1,  # Small boundary layer\n        switch_method='tanh'\n    )\n\n    # Simulate near sliding surface\n    state = np.array([0.0, 0.01, 0.01, 0.0, 0.05, 0.05])\n\n    controls_optimal = []\n    controls_small_bl = []\n\n    for _ in range(100):\n        result_optimal = controller_optimal.compute_control(state, (), {})\n        result_small_bl = controller_small_bl.compute_control(state, (), {})\n\n        controls_optimal.append(result_optimal.u)\n        controls_small_bl.append(result_small_bl.u)\n\n    # Measure control signal variation (chattering indicator)\n    control_variation_optimal = np.std(np.diff(controls_optimal))\n    control_variation_small = np.std(np.diff(controls_small_bl))\n\n    # Large boundary layer should reduce variation significantly\n    assert control_variation_optimal < 0.5 * control_variation_small, \\\n        f\"Large boundary layer should reduce chattering: \" \\\n        f\"optimal={control_variation_optimal:.4f}, \" \\\n        f\"small={control_variation_small:.4f}\"",
    "lines": 45,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76a96874"
  },
  {
    "id": "control_systems_unit_testing_9_5e442b0e",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_controller_interface_compliance():\n    \"\"\"Test compliance with BaseController interface.\"\"\"\n    controller = create_test_controller()\n\n    # Test required properties\n    assert hasattr(controller, 'gains'), \"Must expose gains property\"\n    assert hasattr(controller, 'n_gains'), \"Must declare n_gains for PSO\"\n    assert controller.n_gains == 6, \"Classical SMC requires 6 gains\"\n\n    # Test required methods\n    assert hasattr(controller, 'compute_control'), \"Must implement compute_control\"\n    assert hasattr(controller, 'reset'), \"Must implement reset\"\n    assert hasattr(controller, 'initialize_state'), \"Must implement initialize_state\"\n    assert hasattr(controller, 'initialize_history'), \"Must implement initialize_history\"\n\n    # Test gains property returns copy\n    gains1 = controller.gains\n    gains2 = controller.gains\n    assert gains1 == gains2, \"Gains should be consistent\"\n\n    gains1[0] = 999.0  # Try to mutate\n    assert controller.gains[0] != 999.0, \"Gains property should return copy\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5e442b0e"
  },
  {
    "id": "control_systems_unit_testing_10_62dec13b",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_history_telemetry():\n    \"\"\"Test that controller properly tracks telemetry in history.\"\"\"\n    controller = create_test_controller()\n\n    state = np.array([0.1, 0.2, -0.1, 0.0, 0.3, -0.2])\n    history = {}\n\n    result = controller.compute_control(state, (), history)\n\n    # Verify all required telemetry is tracked\n    required_keys = ['sigma', 'epsilon_eff', 'u_eq', 'u_robust', 'u_total', 'u']\n    for key in required_keys:\n        assert key in history, f\"Missing required history key: {key}\"\n        assert len(history[key]) == 1, f\"History key {key} should have 1 entry\"\n\n    # Run multiple steps and verify accumulation\n    for _ in range(5):\n        controller.compute_control(state, (), history)\n\n    for key in required_keys:\n        assert len(history[key]) == 6, \\\n            f\"History key {key} should accumulate (expected 6, got {len(history[key])})\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "62dec13b"
  },
  {
    "id": "control_systems_unit_testing_11_d3794cd7",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.benchmark\ndef test_compute_control_performance(benchmark):\n    \"\"\"Benchmark control computation for real-time requirements.\"\"\"\n    controller = create_test_controller()\n    state = np.array([0.1, 0.2, -0.1, 0.0, 0.3, -0.2])\n\n    def run_control():\n        return controller.compute_control(state, (), {})\n\n    result = benchmark(run_control)\n\n    # Real-time requirement: <1ms computation time\n    # For 100Hz control loop (dt=0.01s), we need ~10ms budget\n    # Leave margin for other operations, target <1ms for controller\n    mean_time = benchmark.stats['mean']\n    assert mean_time < 0.001, \\\n        f\"Control computation too slow: {mean_time*1000:.2f}ms (target <1ms)\"",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d3794cd7"
  },
  {
    "id": "control_systems_unit_testing_12_d9581ade",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_numerical_stability():\n    \"\"\"Test controller numerical stability under edge cases.\"\"\"\n    controller = create_test_controller()\n\n    # Test with very small values (underflow risk)\n    tiny_state = np.array([1e-15, 1e-15, 1e-15, 1e-15, 1e-15, 1e-15])\n    result = controller.compute_control(tiny_state, (), {})\n    assert np.isfinite(result.u), \"Should handle tiny values\"\n\n    # Test with zeros\n    zero_state = np.zeros(6)\n    result = controller.compute_control(zero_state, (), {})\n    assert np.isfinite(result.u), \"Should handle zero state\"\n\n    # Test with mixed magnitudes (conditioning risk)\n    mixed_state = np.array([1e-6, 1e3, 1e-6, 1e3, 1e-6, 1e3])\n    result = controller.compute_control(mixed_state, (), {})\n    assert np.isfinite(result.u), \"Should handle mixed magnitudes\"",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d9581ade"
  },
  {
    "id": "control_systems_unit_testing_13_4fa72d2e",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_monte_carlo_robustness():\n    \"\"\"Test controller robustness with random state sampling.\"\"\"\n    controller = create_test_controller()\n\n    np.random.seed(42)\n    n_samples = 1000\n\n    failures = 0\n\n    for _ in range(n_samples):\n        # Random state within physical bounds\n        state = np.random.uniform(\n            low=[-1.0, -np.pi/6, -np.pi/6, -1.0, -2.0, -2.0],\n            high=[1.0, np.pi/6, np.pi/6, 1.0, 2.0, 2.0]\n        )\n\n        try:\n            result = controller.compute_control(state, (), {})\n\n            # Check for numerical issues\n            if not np.isfinite(result.u):\n                failures += 1\n            elif abs(result.u) > controller.max_force:\n                failures += 1\n        except Exception:\n            failures += 1\n\n    success_rate = 1.0 - (failures / n_samples)\n\n    # Require 99.9% success rate for production deployment\n    assert success_rate >= 0.999, \\\n        f\"Monte Carlo success rate too low: {success_rate:.2%} (target \u226599.9%)\"",
    "lines": 35,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4fa72d2e"
  },
  {
    "id": "control_systems_unit_testing_14_37c95a06",
    "file": "docs\\testing\\guides\\control_systems_unit_testing.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef create_test_controller():\n    \"\"\"Create controller with optimal gains for testing.\"\"\"\n    optimal_gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]\n\n    return ClassicalSMC(\n        gains=optimal_gains,\n        max_force=20.0,\n        boundary_layer=9.76,\n        switch_method='tanh',\n        regularization=1e-10\n    )",
    "lines": 14,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37c95a06"
  },
  {
    "id": "coverage_quality_gates_runbook_1_80163d53",
    "file": "docs\\testing\\guides\\coverage_quality_gates_runbook.md",
    "index": 1,
    "code": "SAFETY_CRITICAL_PATTERNS = [\n    'safety_guards',\n    'parameter_bounds',\n    'gain_validation',\n    'bounds_checking'\n]",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80163d53"
  },
  {
    "id": "coverage_quality_gates_runbook_2_0c1df1d1",
    "file": "docs\\testing\\guides\\coverage_quality_gates_runbook.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\nCRITICAL_COMPONENT_PATTERNS = [\n    'controllers/smc',\n    'controllers/adaptive_smc',\n    'controllers/classic_smc',\n    'controllers/sta_smc',\n    'core/dynamics',\n    'core/dynamics_full',\n    'optimizer/pso_optimizer',\n    'core/simulation_runner'\n]",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "0c1df1d1"
  },
  {
    "id": "coverage_quality_gates_runbook_3_bb23a936",
    "file": "docs\\testing\\guides\\coverage_quality_gates_runbook.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Coverage improvement workflow:\n# 1. Identify lowest coverage modules\n# 2. Focus on critical components first\n# 3. Add property-based tests for edge cases\n# 4. Implement error injection testing\n# 5. Validate theoretical properties",
    "lines": 9,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bb23a936"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_1_4858dc56",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 1,
    "code": "# Uncovered: Exception branches\n   try:\n       validate_gains(gains)\n   except ValueError as e:  # \u2190 Often uncovered\n       logger.error(f\"Invalid gains: {e}\")\n       raise ControllerConfigurationError(e)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4858dc56"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_2_8bcbb88f",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 2,
    "code": "def test_invalid_gains_exception_handling():\n       with pytest.raises(ControllerConfigurationError):\n           controller = ClassicalSMC(gains=[-1, 0, 5])  # Invalid gains",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8bcbb88f"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_3_9fe44e82",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 3,
    "code": "# Uncovered: Edge case validation\n   if abs(sliding_surface) < 1e-12:  # \u2190 Edge case not tested\n       return 0.0",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9fe44e82"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_4_41479554",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 4,
    "code": "def test_sliding_surface_near_zero():\n       state = np.array([1e-13, 1e-13, 0, 0, 0, 0])  # Near-zero state\n       surface = controller.compute_sliding_surface(state, target)\n       assert abs(surface) < 1e-10",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "41479554"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_5_f653a8fd",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 5,
    "code": "# Uncovered: Safety saturation limits\n   if abs(control_signal) > self.max_control:  # \u2190 Safety limit not tested\n       control_signal = np.sign(control_signal) * self.max_control",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f653a8fd"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_6_5d4c92c5",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 6,
    "code": "def test_control_saturation_safety():\n       # Force extreme control conditions\n       extreme_state = np.array([\u03c0/2, \u03c0/2, 1.0, 10.0, 10.0, 5.0])\n       control = controller.compute_control(extreme_state)\n       assert abs(control) <= controller.max_control",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "5d4c92c5"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_7_d1889ee7",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 7,
    "code": "# Uncovered: Invalid controller type handling\n   def create_controller(controller_type: str, **kwargs):\n       if controller_type not in VALID_CONTROLLERS:  # \u2190 Not tested\n           raise ValueError(f\"Unknown controller: {controller_type}\")",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d1889ee7"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_8_6b42ba6f",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 8,
    "code": "def test_factory_invalid_controller_type():\n       with pytest.raises(ValueError, match=\"Unknown controller\"):\n           create_controller(\"invalid_controller_type\")",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b42ba6f"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_9_c7af2424",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 9,
    "code": "# Uncovered: Convergence failure scenarios\n   if iteration > max_iterations:  # \u2190 Max iteration limit not tested\n       logger.warning(\"PSO failed to converge\")\n       return best_solution, False",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c7af2424"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_10_b28fb892",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 10,
    "code": "def test_pso_convergence_failure():\n       # Force non-convergence with difficult fitness landscape\n       pso = PSOTuner(max_iterations=5, convergence_threshold=1e-10)\n       result, converged = pso.optimize(difficult_fitness_function)\n       assert not converged",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b28fb892"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_11_d662a48c",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 11,
    "code": "# Problematic: Exact floating-point comparison\n   assert stability_margin == 0.5  # \u2190 Can fail due to floating-point errors\n\n   # Solution: Use tolerance-based comparison\n   assert abs(stability_margin - 0.5) < 1e-6",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d662a48c"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_12_703a0f70",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n   # Enhanced stability test\n   def test_lyapunov_stability_mathematical_proof():\n       \"\"\"Validate Lyapunov stability conditions with mathematical rigor.\"\"\"\n       controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n\n       # Test multiple initial conditions\n       initial_conditions = generate_stability_test_conditions(n=100)\n\n       for ic in initial_conditions:\n           # Lyapunov function: V = 0.5 * s\u00b2\n           trajectory = simulate_trajectory(controller, ic, duration=5.0)\n           lyapunov_values = [0.5 * compute_sliding_surface(state)**2\n                            for state in trajectory]\n\n           # V\u0307 \u2264 0 (non-increasing Lyapunov function)\n           for i in range(1, len(lyapunov_values)):\n               assert lyapunov_values[i] <= lyapunov_values[i-1] + 1e-6, \\\n                   f\"Lyapunov function not decreasing at step {i}\"",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "703a0f70"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_13_37735cba",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Calculate realistic thresholds based on component complexity\ndef calculate_optimal_thresholds(codebase_analysis):\n    \"\"\"\n    Calculate component-specific coverage thresholds based on:\n    - Cyclomatic complexity\n    - Code churn rate\n    - Critical path analysis\n    - Historical coverage trends\n    \"\"\"\n\n    thresholds = {}\n\n    for component, metrics in codebase_analysis.items():\n        # Base threshold\n        base_threshold = 85.0\n\n        # Adjustments\n        if metrics['safety_critical']:\n            thresholds[component] = 100.0\n        elif metrics['cyclomatic_complexity'] > 10:\n            thresholds[component] = min(95.0, base_threshold + 10)\n        elif metrics['code_churn'] > 0.3:  # High change frequency\n            thresholds[component] = base_threshold + 5\n        else:\n            thresholds[component] = base_threshold\n\n    return thresholds",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "37735cba"
  },
  {
    "id": "coverage_quality_gates_troubleshooting_14_8e9deade",
    "file": "docs\\testing\\guides\\coverage_quality_gates_troubleshooting.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\ndef calculate_coverage_production_score(gate_results):\n    \"\"\"\n    Calculate coverage contribution to overall production readiness score.\n\n    Current Production Readiness: 6.1/10\n    Target Production Readiness: 8.5/10\n    Coverage Weight: 25% of total score\n    \"\"\"\n\n    weights = {\n        'infrastructure_health': 0.15,\n        'safety_critical_coverage': 0.40,  # Highest weight\n        'critical_components_coverage': 0.25,\n        'overall_coverage': 0.20\n    }\n\n    coverage_score = 0.0\n\n    for gate_id, weight in weights.items():\n        if gate_results.get(gate_id, {}).get('status') == 'passed':\n            coverage_score += weight\n\n    # Scale to 0-10\n    production_contribution = coverage_score * 10\n\n    return {\n        'coverage_production_score': production_contribution,\n        'production_ready': production_contribution >= 8.0,\n        'improvement_needed': max(0, 8.0 - production_contribution)\n    }",
    "lines": 33,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8e9deade"
  },
  {
    "id": "integration_workflows_1_80866d76",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_closed_loop_integration():\n    \"\"\"Test full closed-loop system\"\"\"\n    controller = ClassicalSMC(gains=[77.62, 44.45, 17.31, 14.25, 18.66, 9.76])\n    dynamics = FullDynamics()\n    initial_state = [0.2, -0.1, 0.0, 0.0]\n\n    # Simulate closed loop\n    trajectory = simulate(\n        controller=controller,\n        dynamics=dynamics,\n        initial_state=initial_state,\n        duration=5.0,\n        dt=0.01\n    )\n\n    # Integration assertions\n    final_state = trajectory[-1]\n    assert np.linalg.norm(final_state) < 0.05, \"Did not stabilize\"\n\n    # Check no integration errors\n    assert len(trajectory) == 500, \"Unexpected trajectory length\"\n    assert all(is_valid_state(s) for s in trajectory), \"Invalid states generated\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "80866d76"
  },
  {
    "id": "integration_workflows_2_7d3040db",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_pso_tuning_workflow():\n    \"\"\"Test complete PSO tuning pipeline\"\"\"\n    # Define optimization problem\n    bounds = [(1, 100), (1, 100), (1, 100), (1, 100), (1, 100), (0.1, 10)]\n\n    def fitness(gains):\n        controller = ClassicalSMC(gains=gains)\n        cost = evaluate_controller(controller, test_scenarios)\n        return cost\n\n    # Run PSO\n    tuner = PSOTuner(n_particles=30, iterations=50, bounds=bounds)\n    result = tuner.optimize(fitness)\n\n    # Validate result\n    assert result['cost'] < 1.0, \"PSO did not find good solution\"\n    assert len(result['best_gains']) == 6, \"Incorrect number of gains\"\n\n    # Test optimized controller\n    optimized_controller = ClassicalSMC(gains=result['best_gains'])\n    performance = evaluate_controller(optimized_controller, validation_scenarios)\n    assert performance < 0.5, \"Optimized controller underperforms\"",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7d3040db"
  },
  {
    "id": "integration_workflows_3_2df00416",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_config_to_simulation_workflow():\n    \"\"\"Test configuration \u2192 controller \u2192 simulation pipeline\"\"\"\n    # Load config\n    config = load_config(\"config.yaml\")\n\n    # Create controller from config\n    controller = create_controller(\n        config['control']['type'],\n        config=config['control']['classical_smc']\n    )\n\n    # Create dynamics from config\n    dynamics = DoublePendulum(\n        m1=config['plant']['m1'],\n        l1=config['plant']['l1'],\n        # ... other params\n    )\n\n    # Run simulation\n    results = run_simulation(controller, dynamics, config['simulation'])\n\n    # Integration checks\n    assert results['success'], \"Simulation failed\"\n    assert 'trajectory' in results, \"Missing trajectory data\"\n    assert results['settling_time'] < 3.0, \"Took too long to settle\"",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2df00416"
  },
  {
    "id": "integration_workflows_4_67d0d537",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.fixture\ndef integrated_system():\n    \"\"\"Fixture providing fully integrated system\"\"\"\n    config = load_test_config()\n\n    return {\n        'controller': create_controller_from_config(config),\n        'dynamics': create_dynamics_from_config(config),\n        'observer': create_observer_from_config(config),\n        'reference': create_reference_from_config(config)\n    }\n\ndef test_with_integrated_system(integrated_system):\n    results = run_closed_loop(integrated_system)\n    assert results['tracking_error'] < 0.01",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "67d0d537"
  },
  {
    "id": "integration_workflows_5_352772ea",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_multi_stage_integration():\n    \"\"\"Progressive integration testing\"\"\"\n    # Stage 1: Unit level\n    controller = ClassicalSMC(gains=[10, 5, 8])\n    assert controller.compute_control([0.1, 0, 0, 0]) is not None\n\n    # Stage 2: Subsystem integration\n    dynamics = SimplifiedDynamics()\n    state = [0.1, 0, 0, 0]\n    u = controller.compute_control(state)\n    next_state = dynamics.step(state, u, 0.01)\n    assert dynamics.is_valid_state(next_state)\n\n    # Stage 3: Full system integration\n    trajectory = simulate(controller, dynamics, state, duration=1.0)\n    assert len(trajectory) > 0\n\n    # Stage 4: Performance validation\n    metrics = analyze_performance(trajectory)\n    assert metrics['settling_time'] < 2.0",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "352772ea"
  },
  {
    "id": "integration_workflows_6_f3a24422",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.integration\ndef test_nominal_stabilization():\n    \"\"\"Baseline integration test\"\"\"\n    initial_states = [\n        [0.1, 0, 0, 0],\n        [0, 0.1, 0, 0],\n        [-0.1, -0.1, 0, 0]\n    ]\n\n    for state in initial_states:\n        trajectory = simulate(controller, dynamics, state, duration=5.0)\n        final_error = np.linalg.norm(trajectory[-1])\n        assert final_error < 0.05, f\"Failed for initial state {state}\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3a24422"
  },
  {
    "id": "integration_workflows_7_40cdf6cf",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_disturbance_rejection_integration():\n    \"\"\"Integration test with external disturbances\"\"\"\n    state = [0, 0, 0, 0]\n\n    for t in np.arange(0, 5.0, 0.01):\n        # Apply disturbance at t=2.5s\n        disturbance = 0.5 if 2.5 <= t < 2.6 else 0\n\n        u = controller.compute_control(state)\n        u_total = u + disturbance\n\n        state = dynamics.step(state, u_total, dt=0.01)\n\n    # Should recover despite disturbance\n    assert np.linalg.norm(state) < 0.1, \"Failed to reject disturbance\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40cdf6cf"
  },
  {
    "id": "integration_workflows_8_a603c970",
    "file": "docs\\testing\\guides\\integration_workflows.md",
    "index": 8,
    "code": "@pytest.mark.parametrize(\"mass_error\", [0.8, 0.9, 1.1, 1.2])\ndef test_robust_integration(mass_error):\n    \"\"\"Integration test with plant uncertainties\"\"\"\n    perturbed_dynamics = DoublePendulum(\n        m1=M1_NOMINAL * mass_error,\n        m2=M2_NOMINAL * mass_error\n    )\n\n    trajectory = simulate(controller, perturbed_dynamics, [0.2, 0, 0, 0], 5.0)\n    assert np.linalg.norm(trajectory[-1]) < 0.1",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a603c970"
  },
  {
    "id": "performance_benchmarking_1_f9358aa2",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 1,
    "code": "import pytest\nfrom pytest_benchmark.fixture import BenchmarkFixture\n\ndef test_classical_smc_benchmark(benchmark: BenchmarkFixture):\n    \"\"\"Benchmark classical SMC control computation\"\"\"\n    controller = ClassicalSMC(gains=[10, 5, 8, 3, 15, 2])\n    state = np.array([0.1, -0.2, 0.5, -0.3])\n\n    result = benchmark(controller.compute_control, state)\n\n    # Performance requirements\n    assert benchmark.stats['mean'] < 50e-6  # <50\u00b5s mean\n    assert benchmark.stats['stddev'] < 5e-6  # <5\u00b5s std dev",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f9358aa2"
  },
  {
    "id": "performance_benchmarking_2_aff08b8f",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 2,
    "code": "@pytest.mark.benchmark(group=\"dynamics\")\ndef test_full_dynamics_performance(benchmark):\n    \"\"\"Benchmark full nonlinear dynamics\"\"\"\n    dynamics = FullDynamics()\n    state = np.array([0.1, 0.1, 0.0, 0.0])\n    u = 1.0\n\n    result = benchmark(dynamics.compute_derivatives, state, u)\n\n    # Requirement: 1000 steps in <1ms\n    assert benchmark.stats['mean'] < 1e-6  # <1\u00b5s per step",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "aff08b8f"
  },
  {
    "id": "performance_benchmarking_3_2990e853",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_pso_optimization_benchmark(benchmark):\n    \"\"\"Benchmark PSO convergence speed\"\"\"\n    tuner = PSOTuner(\n        n_particles=30,\n        iterations=50,\n        bounds=[(1, 100)] * 6\n    )\n\n    def run_pso():\n        return tuner.optimize(fitness_function)\n\n    result = benchmark.pedantic(run_pso, iterations=5, rounds=3)\n\n    # Requirements\n    assert benchmark.stats['mean'] < 60.0  # <60s for 50 iterations\n    assert result['cost'] < 0.1  # Converges to good solution",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2990e853"
  },
  {
    "id": "performance_benchmarking_4_cf21eade",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 4,
    "code": "from pytest_benchmark.stats import welch_ttest\n\ndef test_optimization_comparison(benchmark):\n    \"\"\"Compare two implementations with statistical significance\"\"\"\n    # Run baseline\n    baseline_times = benchmark_baseline()\n\n    # Run optimized version\n    optimized_times = benchmark_optimized()\n\n    # Welch's t-test for significance\n    t_stat, p_value = welch_ttest(baseline_times, optimized_times)\n\n    assert p_value < 0.05, \"No statistically significant improvement\"\n    assert np.mean(optimized_times) < np.mean(baseline_times), \\\n        \"Optimized version is slower\"",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "cf21eade"
  },
  {
    "id": "performance_benchmarking_5_9ce7ef48",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 5,
    "code": "import cProfile\nimport pstats\n\ndef profile_controller_step():\n    \"\"\"Profile control loop with cProfile\"\"\"\n    profiler = cProfile.Profile()\n\n    profiler.enable()\n    for _ in range(1000):\n        u = controller.compute_control(state)\n        state = dynamics.step(state, u, dt=0.01)\n    profiler.disable()\n\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(10)  # Top 10 functions",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ce7ef48"
  },
  {
    "id": "performance_benchmarking_6_b5c2ecc9",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 6,
    "code": "import line_profiler\n\n@profile  # Use kernprof -lv script.py\ndef slow_function():\n    # Line-by-line profiling\n    for i in range(1000):\n        expensive_operation(i)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b5c2ecc9"
  },
  {
    "id": "performance_benchmarking_7_b6cd0377",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 7,
    "code": "def compute_cost(states):\n    costs = []\n    for state in states:\n        cost = sum(state**2)  # Slow Python loop\n        costs.append(cost)\n    return np.array(costs)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b6cd0377"
  },
  {
    "id": "performance_benchmarking_8_76aa50ca",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 8,
    "code": "def compute_cost(states):\n    return np.sum(states**2, axis=1)  # Vectorized NumPy",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76aa50ca"
  },
  {
    "id": "performance_benchmarking_9_f211f513",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 9,
    "code": "from numba import jit\n\n@jit(nopython=True, cache=True)\ndef compute_control_numba(state, gains):\n    \"\"\"Compiled controller - 10-50x faster\"\"\"\n    k1, k2, k3, k4, k5, k6 = gains\n    # Control law implementation\n    u = -k1 * state[0] - k2 * state[1] - k3 * state[2]\n    return np.clip(u, -MAX_TORQUE, MAX_TORQUE)",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f211f513"
  },
  {
    "id": "performance_benchmarking_10_c9119280",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 10,
    "code": "from pytest_benchmark.utils import format_time\n\ndef test_with_custom_metrics(benchmark):\n    \"\"\"Track custom metrics beyond time\"\"\"\n    def func_with_metrics():\n        result = expensive_function()\n        # Custom metrics\n        return {\n            'result': result,\n            'memory_mb': get_memory_usage(),\n            'cache_misses': get_cache_misses()\n        }\n\n    output = benchmark(func_with_metrics)\n    print(f\"Memory: {output['memory_mb']:.2f} MB\")",
    "lines": 15,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c9119280"
  },
  {
    "id": "performance_benchmarking_11_dafd5537",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 11,
    "code": "@pytest.fixture(scope=\"function\")\ndef fresh_controller():\n    \"\"\"New controller instance per benchmark\"\"\"\n    return ClassicalSMC(gains=[10, 5, 8, 3, 15, 2])",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "dafd5537"
  },
  {
    "id": "performance_benchmarking_12_75355e32",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 12,
    "code": "def test_with_warmup(benchmark):\n    \"\"\"Include warm-up for JIT-compiled code\"\"\"\n    benchmark.pedantic(\n        function,\n        rounds=10,\n        iterations=100,\n        warmup_rounds=2  # Warm up JIT compiler\n    )",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "75355e32"
  },
  {
    "id": "performance_benchmarking_13_ad4f4784",
    "file": "docs\\testing\\guides\\performance_benchmarking.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@pytest.mark.benchmark(\n    disable_gc=True,  # Disable garbage collector\n    min_rounds=10,    # Ensure statistical significance\n    timer=time.perf_counter  # High-resolution timer\n)\ndef test_precise_benchmark():\n    ...",
    "lines": 10,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ad4f4784"
  },
  {
    "id": "property_based_testing_1_f5a49a68",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 1,
    "code": "def test_smc_zero_error():\n    \"\"\"Test SMC with zero error\"\"\"\n    state = [0, 0, 0, 0]  # Specific case\n    control = smc.compute_control(state)\n    assert control == 0",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5a49a68"
  },
  {
    "id": "property_based_testing_2_ec6ec8eb",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 2,
    "code": "@given(state=states())\ndef test_smc_bounded_output(state):\n    \"\"\"Test SMC output always bounded\"\"\"\n    control = smc.compute_control(state)\n    assert -MAX_TORQUE <= control <= MAX_TORQUE  # For ALL states",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec6ec8eb"
  },
  {
    "id": "property_based_testing_3_6655c2f7",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 3,
    "code": "from hypothesis import given, strategies as st\n\n@given(\n    theta1=st.floats(min_value=-\u03c0, max_value=\u03c0),\n    theta2=st.floats(min_value=-\u03c0, max_value=\u03c0),\n    velocity=st.floats(min_value=-10, max_value=10)\n)\ndef test_control_never_exceeds_limits(theta1, theta2, velocity):\n    \"\"\"Control output must NEVER exceed actuator limits\"\"\"\n    state = construct_state(theta1, theta2, velocity)\n    u = controller.compute_control(state)\n\n    assert -MAX_TORQUE <= u <= MAX_TORQUE, \\\n        f\"Control {u} exceeded limits for state {state}\"",
    "lines": 14,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6655c2f7"
  },
  {
    "id": "property_based_testing_4_a224bffe",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n@given(state=valid_states())\ndef test_lyapunov_decrease(state):\n    \"\"\"Lyapunov function decreases along trajectories\"\"\"\n    # Compute V(x) at current state\n    V_current = lyapunov_function(state)\n\n    # Simulate one timestep\n    u = controller.compute_control(state)\n    next_state = dynamics.step(state, u, dt=0.01)\n    V_next = lyapunov_function(next_state)\n\n    # V must decrease (or stay same if at equilibrium)\n    assert V_next <= V_current + 1e-6, \\\n        f\"Lyapunov increased: {V_current} -> {V_next}\"",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a224bffe"
  },
  {
    "id": "property_based_testing_5_403328c9",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n@given(\n    state=valid_states(),\n    perturbation=st.floats(min_value=-0.01, max_value=0.01)\n)\ndef test_control_continuity(state, perturbation):\n    \"\"\"Control law is Lipschitz continuous\"\"\"\n    u1 = controller.compute_control(state)\n\n    perturbed_state = state + perturbation\n    u2 = controller.compute_control(perturbed_state)\n\n    # Control change bounded by Lipschitz constant\n    L = 100  # Known Lipschitz constant\n    assert abs(u2 - u1) <= L * abs(perturbation), \\\n        f\"Discontinuity detected: \u0394u={u2-u1}, \u0394x={perturbation}\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "403328c9"
  },
  {
    "id": "property_based_testing_6_7741da75",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n@given(\n    mass_error=st.floats(min_value=0.8, max_value=1.2),  # \u00b120%\n    friction_error=st.floats(min_value=0.5, max_value=1.5),  # \u00b150%\n    initial_state=valid_states()\n)\ndef test_robust_stabilization(mass_error, friction_error, initial_state):\n    \"\"\"Controller stabilizes despite parameter uncertainties\"\"\"\n    # Create perturbed dynamics\n    perturbed_dynamics = DoublePendulum(\n        m1=M1 * mass_error,\n        m2=M2 * mass_error,\n        b=FRICTION * friction_error\n    )\n\n    # Simulate closed-loop\n    trajectory = simulate(\n        controller, perturbed_dynamics,\n        initial_state, duration=5.0\n    )\n\n    # Check final state near equilibrium\n    final_state = trajectory[-1]\n    assert np.linalg.norm(final_state) < 0.1, \\\n        \"Failed to stabilize with parameter errors\"",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "7741da75"
  },
  {
    "id": "property_based_testing_7_ecd5e385",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 7,
    "code": "from hypothesis import strategies as st\n\ndef valid_states(\n    theta_max=\u03c0,\n    velocity_max=10,\n    constrain_to_basin=False\n):\n    \"\"\"Generate valid state vectors\"\"\"\n    if constrain_to_basin:\n        # Only generate states in region of attraction\n        theta_strategy = st.floats(min_value=-0.5, max_value=0.5)\n    else:\n        # Full state space\n        theta_strategy = st.floats(\n            min_value=-theta_max,\n            max_value=theta_max,\n            allow_nan=False,\n            allow_infinity=False\n        )\n\n    velocity_strategy = st.floats(\n        min_value=-velocity_max,\n        max_value=velocity_max,\n        allow_nan=False\n    )\n\n    return st.tuples(\n        theta_strategy,  # theta1\n        theta_strategy,  # theta2\n        velocity_strategy,  # dtheta1\n        velocity_strategy   # dtheta2\n    )",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ecd5e385"
  },
  {
    "id": "property_based_testing_8_a7ac7895",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef positive_gains(min_value=0.1, max_value=100):\n    \"\"\"Generate valid controller gains\"\"\"\n    return st.floats(\n        min_value=min_value,\n        max_value=max_value,\n        allow_nan=False,\n        allow_infinity=False,\n        exclude_min=True  # Must be strictly positive\n    )\n\n@given(\n    k1=positive_gains(),\n    k2=positive_gains(),\n    k3=positive_gains()\n)\ndef test_smc_with_random_gains(k1, k2, k3):\n    \"\"\"SMC must remain stable for any positive gains\"\"\"\n    controller = ClassicalSMC(gains=[k1, k2, k3])\n    # Test stability property\n    ...",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a7ac7895"
  },
  {
    "id": "property_based_testing_9_ec0fa4e7",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 9,
    "code": "def trajectories(duration=5.0, dt=0.01):\n    \"\"\"Generate state trajectories\"\"\"\n    return st.lists(\n        valid_states(),\n        min_size=int(duration / dt),\n        max_size=int(duration / dt)\n    )",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ec0fa4e7"
  },
  {
    "id": "property_based_testing_10_8397483e",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 10,
    "code": "from hypothesis import given, assume, settings\nimport hypothesis.strategies as st\n\n@given(state=valid_states())\n@settings(max_examples=1000)  # Run 1000 random tests\ndef test_invariant_holds(state):\n    \"\"\"Template for testing control invariants\"\"\"\n    # Optionally filter invalid cases\n    assume(is_physically_realizable(state))\n\n    # Compute control\n    u = controller.compute_control(state)\n\n    # Check invariant\n    assert invariant_check(u, state), \\\n        f\"Invariant violated for state={state}, control={u}\"",
    "lines": 16,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8397483e"
  },
  {
    "id": "property_based_testing_11_86d53f93",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 11,
    "code": "@given(state=valid_states(), scale=st.floats(min_value=0.1, max_value=10))\ndef test_control_scaling_property(state, scale):\n    \"\"\"If error scales, control should scale proportionally\"\"\"\n    u1 = controller.compute_control(state)\n    scaled_state = state * scale\n    u2 = controller.compute_control(scaled_state)\n\n    # Check proportionality (for linear controllers)\n    assert abs(u2 / u1 - scale) < 0.01, \\\n        \"Control does not scale with state\"",
    "lines": 10,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "86d53f93"
  },
  {
    "id": "property_based_testing_12_25e64560",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n@given(state=valid_states())\ndef test_no_regression_from_baseline(state):\n    \"\"\"Current controller performs at least as well as baseline\"\"\"\n    # Baseline controller (e.g., from v1.0)\n    u_baseline = baseline_controller.compute_control(state)\n    cost_baseline = evaluate_performance(state, u_baseline)\n\n    # Current controller\n    u_current = current_controller.compute_control(state)\n    cost_current = evaluate_performance(state, u_current)\n\n    assert cost_current <= cost_baseline * 1.05, \\  # Allow 5% tolerance\n        f\"Performance regression detected: {cost_current} > {cost_baseline}\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "25e64560"
  },
  {
    "id": "property_based_testing_13_ae2016e0",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n@given(state=valid_states())\ndef test_sliding_surface_attractivity(state):\n    \"\"\"Sliding surface must be attractive from any state\"\"\"\n    sigma_values = []\n\n    for t in range(100):  # 1 second simulation\n        sigma = sliding_surface(state)\n        sigma_values.append(abs(sigma))\n\n        u = controller.compute_control(state)\n        state = dynamics.step(state, u, dt=0.01)\n\n    # \u03a3 must decrease on average\n    initial_sigma = sigma_values[0]\n    final_sigma = sigma_values[-1]\n\n    assert final_sigma < initial_sigma or initial_sigma < 0.01, \\\n        f\"Sliding surface not attractive: {initial_sigma} -> {final_sigma}\"",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae2016e0"
  },
  {
    "id": "property_based_testing_14_1c985038",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n@given(\n    state=valid_states(),\n    boundary_layer=st.floats(min_value=0.01, max_value=1.0)\n)\ndef test_chattering_bounded_by_boundary_layer(state, boundary_layer):\n    \"\"\"Chattering frequency inversely related to boundary layer\"\"\"\n    controller.set_boundary_layer(boundary_layer)\n\n    control_sequence = []\n    for _ in range(100):\n        u = controller.compute_control(state)\n        control_sequence.append(u)\n        state = dynamics.step(state, u, dt=0.01)\n\n    # Count sign changes (chattering indicator)\n    sign_changes = count_sign_changes(control_sequence)\n\n    # Larger boundary layer \u2192 fewer sign changes\n    assert sign_changes < 50 / boundary_layer, \\\n        f\"Excessive chattering: {sign_changes} switches with \u03d5={boundary_layer}\"",
    "lines": 23,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1c985038"
  },
  {
    "id": "property_based_testing_15_546d05ff",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 15,
    "code": "# example-metadata:\n# runnable: false\n\n@given(state=valid_states())\ndef test_property(state):\n    # Filter out uninteresting cases\n    assume(np.linalg.norm(state) > 0.01)  # Skip near-equilibrium\n    ...",
    "lines": 8,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "546d05ff"
  },
  {
    "id": "property_based_testing_16_85137f74",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 16,
    "code": "@st.composite\ndef controller_with_valid_gains(draw):\n    \"\"\"Generate controller with constraint: k1 > k2 > k3\"\"\"\n    k3 = draw(st.floats(min_value=1, max_value=10))\n    k2 = draw(st.floats(min_value=k3 + 1, max_value=50))\n    k1 = draw(st.floats(min_value=k2 + 1, max_value=100))\n    return ClassicalSMC(gains=[k1, k2, k3])",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "85137f74"
  },
  {
    "id": "property_based_testing_17_17d11b61",
    "file": "docs\\testing\\guides\\property_based_testing.md",
    "index": 17,
    "code": "# example-metadata:\n# runnable: false\n\nfrom hypothesis import settings, HealthCheck\n\n@given(state=valid_states())\n@settings(\n    max_examples=10000,  # Exhaustive testing\n    deadline=None,       # No timeout\n    suppress_health_check=[HealthCheck.too_slow]\n)\ndef test_critical_property(state):\n    ...",
    "lines": 13,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "17d11b61"
  },
  {
    "id": "testing_standards_1_84fb756d",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_classical_smc_control_computation_valid_input():\n    \"\"\"Test classical SMC control computation with valid state input.\"\"\"\n    # Setup\n    controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5], max_force=100.0)\n    state = np.array([0.1, 0.05, 0.02, 0.0, 0.0, 0.0])\n\n    # Execute\n    control = controller.compute_control(state, 0.0, {})\n\n    # Verify\n    assert isinstance(control, float)\n    assert -100.0 <= control <= 100.0  # Within actuator limits\n    assert not np.isnan(control) and not np.isinf(control)\n\ndef test_classical_smc_invalid_state_dimension():\n    \"\"\"Test classical SMC raises appropriate error for invalid state dimension.\"\"\"\n    controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n    invalid_state = np.array([0.1, 0.05])  # Only 2 elements instead of 6\n\n    with pytest.raises(ValueError, match=\"State vector must have 6 elements\"):\n        controller.compute_control(invalid_state, 0.0, {})",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "84fb756d"
  },
  {
    "id": "testing_standards_2_817308a9",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 2,
    "code": "from hypothesis import given, strategies as st\n\n@given(\n    gains=st.lists(st.floats(min_value=0.1, max_value=100.0), min_size=6, max_size=6),\n    state=st.lists(st.floats(min_value=-10.0, max_value=10.0), min_size=6, max_size=6)\n)\ndef test_control_output_bounded_property(gains, state):\n    \"\"\"Property: Control output must always be within actuator limits.\"\"\"\n    controller = ClassicalSMC(gains=gains, max_force=100.0)\n    state_array = np.array(state)\n\n    control = controller.compute_control(state_array, 0.0, {})\n\n    assert -100.0 <= control <= 100.0\n    assert not np.isnan(control) and not np.isinf(control)\n\n@given(\n    initial_state=st.lists(st.floats(min_value=-1.0, max_value=1.0), min_size=6, max_size=6)\n)\ndef test_lyapunov_stability_property(initial_state):\n    \"\"\"Property: Lyapunov function decreases for stable controllers.\"\"\"\n    controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n\n    # Simulate short trajectory\n    trajectory = simulate_short_trajectory(controller, np.array(initial_state))\n\n    # Compute Lyapunov function\n    V_values = [compute_lyapunov_function(state) for state in trajectory]\n\n    # Property: V should generally decrease (allowing for small numerical errors)\n    decreasing_trend = np.polyfit(range(len(V_values)), V_values, 1)[0]\n    assert decreasing_trend <= 0.01  # Allow small positive slope for numerical stability",
    "lines": 32,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "817308a9"
  },
  {
    "id": "testing_standards_3_da110b40",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_complete_pso_optimization_workflow():\n    \"\"\"Test complete PSO optimization workflow from CLI to results.\"\"\"\n    # Setup configuration\n    config = create_test_config(\n        controller_type=\"classical_smc\",\n        pso_iterations=10,  # Reduced for testing\n        pso_particles=5\n    )\n\n    # Execute workflow\n    results = run_pso_optimization_workflow(config)\n\n    # Verify results\n    assert results.optimization_successful\n    assert len(results.optimized_gains) == 6\n    assert results.final_cost < results.initial_cost\n    assert all(0.1 <= gain <= 100.0 for gain in results.optimized_gains)\n\n    # Verify simulation with optimized gains\n    controller = create_controller_from_gains(results.optimized_gains)\n    simulation_result = run_simulation(controller, config.simulation)\n    assert simulation_result.successful\n    assert simulation_result.final_state_error < 0.1",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "da110b40"
  },
  {
    "id": "testing_standards_4_615160d1",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 4,
    "code": "import pytest\n\n@pytest.mark.benchmark(group=\"control_computation\")\ndef test_classical_smc_performance(benchmark):\n    \"\"\"Benchmark classical SMC control computation performance.\"\"\"\n    controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n    state = np.array([0.1, 0.05, 0.02, 0.0, 0.0, 0.0])\n\n    result = benchmark(controller.compute_control, state, 0.0, {})\n\n    # Performance requirements\n    assert benchmark.stats.mean < 0.001  # Mean execution time < 1ms\n    assert benchmark.stats.stddev < 0.0005  # Low variance\n\n@pytest.mark.benchmark(group=\"batch_simulation\")\ndef test_batch_simulation_scaling(benchmark):\n    \"\"\"Benchmark batch simulation scaling with number of trials.\"\"\"\n    controller_factory = lambda: ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n\n    def run_batch(n_trials=100):\n        return run_multiple_trials(controller_factory, create_test_config(), n_trials)\n\n    result = benchmark(run_batch)\n\n    # Scaling requirements\n    assert benchmark.stats.mean < 10.0  # 100 trials in < 10 seconds",
    "lines": 26,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "615160d1"
  },
  {
    "id": "testing_standards_5_04e91c93",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_sliding_surface_design_theory():\n    \"\"\"Validate sliding surface design follows control theory principles.\"\"\"\n    gains = [10, 8, 15, 12, 50, 5]  # k1, k2, \u03bb1, \u03bb2, K, \u03b7\n\n    # Extract gains according to theory\n    k1, k2, \u03bb1, \u03bb2, K, \u03b7 = gains\n\n    # Theoretical requirements for stability\n    assert k1 > 0 and k2 > 0, \"Position gains must be positive\"\n    assert \u03bb1 > 0 and \u03bb2 > 0, \"Surface parameters must be positive\"\n    assert K > 0, \"Switching gain must be positive\"\n    assert \u03b7 >= 0, \"Boundary layer must be non-negative\"\n\n    # Pole placement verification\n    characteristic_poly = [1, \u03bb1 + \u03bb2, \u03bb1*\u03bb2 + k1, k2*\u03bb1]\n    roots = np.roots(characteristic_poly)\n\n    # All poles should have negative real parts for stability\n    assert all(np.real(root) < 0 for root in roots), \"System must be stable\"\n\ndef test_energy_conservation_in_simulation():\n    \"\"\"Verify energy conservation in frictionless simulation.\"\"\"\n    # Setup frictionless configuration\n    config = create_test_config(\n        friction_coefficients=[0.0, 0.0, 0.0],  # No friction\n        simulation_duration=5.0\n    )\n\n    controller = ClassicalSMC(gains=[10, 8, 15, 12, 50, 5])\n    result = run_simulation(controller, config)\n\n    # Compute total energy throughout simulation\n    potential_energy = compute_potential_energy(result.states, config.physics)\n    kinetic_energy = compute_kinetic_energy(result.states, config.physics)\n    total_energy = potential_energy + kinetic_energy\n\n    # Energy should be approximately conserved (allowing for numerical errors)\n    energy_variation = np.std(total_energy) / np.mean(total_energy)\n    assert energy_variation < 0.01, \"Energy should be conserved in frictionless system\"",
    "lines": 42,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "04e91c93"
  },
  {
    "id": "testing_standards_6_ed80e251",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# Example: Generate valid SMC parameters\n@pytest.fixture\ndef valid_smc_gains():\n    \"\"\"Generate valid SMC gain sets for testing.\"\"\"\n    return [\n        [10.0, 8.0, 15.0, 12.0, 50.0, 5.0],    # Typical values\n        [5.0, 3.0, 8.0, 6.0, 25.0, 2.0],       # Conservative gains\n        [20.0, 15.0, 30.0, 25.0, 100.0, 10.0], # Aggressive gains\n    ]\n\n@pytest.fixture\ndef test_trajectories():\n    \"\"\"Generate test state trajectories for validation.\"\"\"\n    # Analytical solutions for linear cases\n    # Numerical solutions for nonlinear cases\n    # Edge cases and boundary conditions\n    pass",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ed80e251"
  },
  {
    "id": "testing_standards_7_e3a6ebb8",
    "file": "docs\\testing\\standards\\testing_standards.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_sliding_surface_convergence():\n    \"\"\"Test that states converge to sliding surface under classical SMC.\n\n    Theory:\n    -------\n    Classical SMC guarantees finite-time convergence to sliding surface\n    s(x) = 0 when switching gain K > uncertainty bound.\n\n    Reference: Utkin, V. \"Sliding Modes in Control and Optimization\"\n\n    Test Setup:\n    ----------\n    - Initial state away from equilibrium\n    - Classical SMC with sufficient switching gain\n    - Simulation until convergence or timeout\n\n    Verification:\n    ------------\n    - |s(x(t))| \u2192 0 as t increases\n    - Convergence time < theoretical bound\n    - No chattering beyond boundary layer\n    \"\"\"\n    # Test implementation here\n    pass",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e3a6ebb8"
  },
  {
    "id": "lyapunov_stability_testing_1_8acf4874",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 1,
    "code": "import pytest\nimport numpy as np\nfrom hypothesis import given, strategies as st\n\n@given(state=valid_states())\ndef test_lyapunov_positive_definite(state):\n    \"\"\"V(x) \u2265 0 for all x, V(0) = 0\"\"\"\n    V = lyapunov_function(state)\n\n    if np.allclose(state, 0, atol=1e-6):\n        assert V < 1e-6, f\"V(0) = {V} \u2260 0\"\n    else:\n        assert V > 0, f\"V not positive: V({state}) = {V}\"",
    "lines": 13,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8acf4874"
  },
  {
    "id": "lyapunov_stability_testing_2_e9f28b04",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n@given(state=valid_states())\ndef test_lyapunov_decrease(state):\n    \"\"\"dV/dt \u2264 0 along trajectories\"\"\"\n    # Compute V at current state\n    V_t = lyapunov_function(state)\n\n    # Simulate one time step\n    u = controller.compute_control(state)\n    state_next = dynamics.step(state, u, dt=0.01)\n\n    V_next = lyapunov_function(state_next)\n\n    # Allow small numerical tolerance\n    assert V_next <= V_t + 1e-6, \\\n        f\"V increased: {V_t} \u2192 {V_next} (\u0394={V_next - V_t})\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e9f28b04"
  },
  {
    "id": "lyapunov_stability_testing_3_d6916153",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_finite_time_reaching():\n    \"\"\"Sliding surface reached in finite time\"\"\"\n    initial_state = np.array([0.5, -0.3, 1.0, -0.8])\n    sigma_0 = sliding_surface(initial_state)\n\n    trajectory = simulate(controller, dynamics, initial_state, duration=5.0)\n\n    # Find first time \u03c3 crosses zero\n    t_reach = None\n    for i, state in enumerate(trajectory):\n        sigma = sliding_surface(state)\n        if abs(sigma) < 0.01:  # Threshold for \"reached\"\n            t_reach = i * 0.01\n            break\n\n    assert t_reach is not None, \"Did not reach sliding surface\"\n\n    # Verify theoretical bound: t_reach \u2264 |\u03c3(0)| / \u03b7\n    eta = 0.1  # Known reaching constant\n    t_theoretical = abs(sigma_0) / eta\n\n    assert t_reach <= t_theoretical * 1.2, \\  # Allow 20% tolerance\n        f\"Took too long: {t_reach}s > {t_theoretical}s\"",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d6916153"
  },
  {
    "id": "lyapunov_stability_testing_4_9ce91369",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_region_of_attraction():\n    \"\"\"Verify estimated region of attraction\"\"\"\n    # Sample initial states from estimated ROA\n    R = 0.5  # Estimated ROA radius\n    test_states = sample_sphere(center=[0,0,0,0], radius=R, n_samples=100)\n\n    for initial_state in test_states:\n        trajectory = simulate(controller, dynamics, initial_state, duration=10.0)\n        final_state = trajectory[-1]\n\n        # Must converge to equilibrium\n        assert np.linalg.norm(final_state) < 0.05, \\\n            f\"Failed to converge from {initial_state}\"",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9ce91369"
  },
  {
    "id": "lyapunov_stability_testing_5_56988ea4",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n@given(\n    state=valid_states(),\n    disturbance=st.floats(min_value=-0.5, max_value=0.5)\n)\ndef test_ISS_property(state, disturbance):\n    \"\"\"Input-to-State Stability (ISS)\"\"\"\n    # Simulate with disturbance\n    u = controller.compute_control(state)\n    u_disturbed = u + disturbance\n\n    state_next = dynamics.step(state, u_disturbed, dt=0.01)\n\n    # ISS condition: ||x(t)|| \u2264 \u03b2(||x(0)||, t) + \u03b3(||d||)\n    x_norm = np.linalg.norm(state_next)\n    d_norm = abs(disturbance)\n\n    # Simplified check: state bounded by disturbance magnitude\n    assert x_norm <= 10 * d_norm + 1.0, \\\n        f\"Not ISS: ||x||={x_norm} vs ||d||={d_norm}\"",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "56988ea4"
  },
  {
    "id": "lyapunov_stability_testing_6_f3fd28ac",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 6,
    "code": "TOLERANCE = 1e-6\n\ndef test_lyapunov_with_tolerance(state):\n    V_next = lyapunov_function(next_state)\n    V_current = lyapunov_function(state)\n\n    # Use relative tolerance for small V values\n    if V_current < 1e-3:\n        assert V_next <= V_current + TOLERANCE\n    else:\n        assert V_next <= V_current * (1 + TOLERANCE)",
    "lines": 11,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f3fd28ac"
  },
  {
    "id": "lyapunov_stability_testing_7_fa540dc3",
    "file": "docs\\testing\\theory\\lyapunov_stability_testing.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_lyapunov_averaged_decrease(state):\n    \"\"\"Check V decreases on average over window\"\"\"\n    window_size = 10  # Average over 10 steps\n\n    V_values = []\n    for _ in range(window_size):\n        V = lyapunov_function(state)\n        V_values.append(V)\n\n        u = controller.compute_control(state)\n        state = dynamics.step(state, u, dt=0.01)\n\n    # Moving average should decrease\n    avg_first_half = np.mean(V_values[:5])\n    avg_second_half = np.mean(V_values[5:])\n\n    assert avg_second_half < avg_first_half",
    "lines": 20,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fa540dc3"
  },
  {
    "id": "pso_convergence_analysis_1_94e2b5c9",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_convergence_analysis.md",
    "index": 1,
    "code": "optimal_gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94e2b5c9"
  },
  {
    "id": "pso_convergence_analysis_2_ba43397c",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_convergence_analysis.md",
    "index": 2,
    "code": "# Standard deviation across 22 runs\nstd_dev(k1) \u2248 0.0001  # Excellent consistency\nstd_dev(k6) \u2248 0.0001",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ba43397c"
  },
  {
    "id": "pso_convergence_analysis_3_d8038c89",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_convergence_analysis.md",
    "index": 3,
    "code": "# Potential issue in cost function\n   cost = performance_metric + 1e6 * constraint_violation\n   # If constraint is always zero, cost = performance only\n   # If performance is normalized poorly, could yield 0",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d8038c89"
  },
  {
    "id": "pso_convergence_analysis_4_6b4d4e9d",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_convergence_analysis.md",
    "index": 4,
    "code": "if abs(cost) < 1e-10:\n       return 0.0  # Inappropriate threshold?",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "6b4d4e9d"
  },
  {
    "id": "pso_convergence_analysis_5_2c4edcbd",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_convergence_analysis.md",
    "index": 5,
    "code": "# Instead of fixed iterations\n   converged = (fitness_stdev < 1e-4) and (iterations >= min_iters)",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2c4edcbd"
  },
  {
    "id": "pso_fitness_investigation_1_bd0923fc",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 1,
    "code": "# example-metadata:\n# runnable: false\n\n# Automatic baseline normalization\nbaseline_particles = np.asarray(gains_list, dtype=float).reshape(1, -1)\nres = simulate_system_batch(\n    controller_factory=controller_factory,\n    particles=baseline_particles,\n    sim_time=self.sim_cfg.duration,\n    dt=self.sim_cfg.dt,\n    u_max=u_max_val,\n)\n\n# Extract baseline costs\nise_base = float(np.sum((x_b[:, :-1, :3] ** 2 * dt_arr) * time_mask, axis=(1, 2))[0])\nu_sq_base = float(np.sum((u_b ** 2 * dt_arr) * time_mask, axis=1)[0])\ndu_sq_base = float(np.sum((du ** 2 * dt_arr) * time_mask, axis=1)[0])\nsigma_sq_base = float(np.sum((sigma_b ** 2 * dt_arr) * time_mask, axis=1)[0])\n\n# Set normalization denominators\nself.norm_ise = max(ise_base, 1e-12)\nself.norm_u = max(u_sq_base, 1e-12)\nself.norm_du = max(du_sq_base, 1e-12)\nself.norm_sigma = max(sigma_sq_base, 1e-12)",
    "lines": 24,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "bd0923fc"
  },
  {
    "id": "pso_fitness_investigation_2_72b953f9",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# State error integration\nise = np.sum((x_b[:, :-1, :] ** 2 * dt_b) * time_mask, axis=(1, 2))\nise_n = self._normalise(ise, self.norm_ise)  # \u26a0\ufe0f  Division by large baseline\n\n# Control effort\nu_sq = np.sum((u_b_trunc ** 2 * dt_b) * time_mask, axis=1)\nu_n = self._normalise(u_sq, self.norm_u)\n\n# Control slew\ndu_sq = np.sum((du_trunc ** 2 * dt_b) * time_mask, axis=1)\ndu_n = self._normalise(du_sq, self.norm_du)\n\n# Sliding variable energy\nsigma_sq = np.sum((sigma_b_trunc ** 2 * dt_b) * time_mask, axis=1)\nsigma_n = self._normalise(sigma_sq, self.norm_sigma)\n\n# Weighted cost\nJ = (\n    self.weights.state_error * ise_n      # 50.0 * (tiny value)\n    + self.weights.control_effort * u_n   # 0.2 * (tiny value)\n    + self.weights.control_rate * du_n    # 0.1 * (tiny value)\n    + self.weights.stability * sigma_n    # 0.1 * (tiny value)\n) + penalty",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "72b953f9"
  },
  {
    "id": "pso_fitness_investigation_3_9dd0e201",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 3,
    "code": "def _normalise(self, val: np.ndarray, denom: float) -> np.ndarray:\n    \"\"\"Safely normalise with threshold check\"\"\"\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        ratio = val / denom\n    thr = float(self.normalisation_threshold)  # Default: 1e-12\n    return np.where(denom > thr, ratio, val)",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9dd0e201"
  },
  {
    "id": "pso_fitness_investigation_4_94e2b5c9",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 4,
    "code": "optimal_gains = [77.62, 44.45, 17.31, 14.25, 18.66, 9.76]",
    "lines": 1,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "94e2b5c9"
  },
  {
    "id": "pso_fitness_investigation_5_906796c8",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 5,
    "code": "#==========================================================================================\\\\\\\n#========================= scripts/debug_pso_fitness.py =================================\\\\\\\n#==========================================================================================\\\\\\\n\n\"\"\"PSO Fitness Function Diagnostic Tool\"\"\"\n\nimport numpy as np\nfrom src.optimization.algorithms.pso_optimizer import PSOTuner\nfrom src.config import load_config\n\ndef diagnose_normalization():\n    \"\"\"Diagnose normalization effects\"\"\"\n    config = load_config(\"config.yaml\")\n\n    # Create PSOTuner (triggers baseline normalization)\n    def dummy_factory(gains):\n        from src.controllers.smc.classic_smc import ClassicalSMC\n        return ClassicalSMC(gains=gains, max_force=100.0)\n\n    tuner = PSOTuner(dummy_factory, config)\n\n    # Print normalization constants\n    print(\"=\" * 90)\n    print(\"PSO NORMALIZATION DIAGNOSTIC\")\n    print(\"=\" * 90)\n    print(f\"\\nNormalization Constants:\")\n    print(f\"  norm_ise:    {tuner.norm_ise:.6e}\")\n    print(f\"  norm_u:      {tuner.norm_u:.6e}\")\n    print(f\"  norm_du:     {tuner.norm_du:.6e}\")\n    print(f\"  norm_sigma:  {tuner.norm_sigma:.6e}\")\n\n    print(f\"\\nCost Weights:\")\n    print(f\"  state_error:     {tuner.weights.state_error}\")\n    print(f\"  control_effort:  {tuner.weights.control_effort}\")\n    print(f\"  control_rate:    {tuner.weights.control_rate}\")\n    print(f\"  stability:       {tuner.weights.stability}\")\n\n    print(f\"\\nInstability Penalty: {tuner.instability_penalty:.6e}\")\n    print(f\"Combine Weights: mean={tuner.combine_weights[0]}, max={tuner.combine_weights[1]}\")\n\n    # Simulate example cost computation\n    print(f\"\\n{'=' * 90}\")\n    print(\"EXAMPLE COST COMPUTATION\")\n    print(\"=\" * 90)\n\n    # Example raw costs\n    ise_raw = 1.0      # Good tracking\n    u_sq_raw = 50.0    # Moderate control effort\n    du_sq_raw = 100.0  # Moderate slew rate\n    sigma_sq_raw = 0.5 # Good sliding surface convergence\n\n    # Normalize\n    ise_n = ise_raw / tuner.norm_ise if tuner.norm_ise > 1e-12 else ise_raw\n    u_n = u_sq_raw / tuner.norm_u if tuner.norm_u > 1e-12 else u_sq_raw\n    du_n = du_sq_raw / tuner.norm_du if tuner.norm_du > 1e-12 else du_sq_raw\n    sigma_n = sigma_sq_raw / tuner.norm_sigma if tuner.norm_sigma > 1e-12 else sigma_sq_raw\n\n    print(f\"\\nRaw Costs:\")\n    print(f\"  ISE:     {ise_raw:.4f}  \u2192  Normalized: {ise_n:.6e}\")\n    print(f\"  U\u00b2:      {u_sq_raw:.4f}  \u2192  Normalized: {u_n:.6e}\")\n    print(f\"  (\u0394U)\u00b2:   {du_sq_raw:.4f}  \u2192  Normalized: {du_n:.6e}\")\n    print(f\"  \u03c3\u00b2:      {sigma_sq_raw:.4f}  \u2192  Normalized: {sigma_n:.6e}\")\n\n    # Compute weighted cost\n    J_components = {\n        'state_error': tuner.weights.state_error * ise_n,\n        'control_effort': tuner.weights.control_effort * u_n,\n        'control_rate': tuner.weights.control_rate * du_n,\n        'stability': tuner.weights.stability * sigma_n\n    }\n\n    J_total = sum(J_components.values())\n\n    print(f\"\\nWeighted Cost Components:\")\n    for name, value in J_components.items():\n        pct = (value / J_total * 100) if J_total > 0 else 0\n        print(f\"  {name:20s}: {value:.6e}  ({pct:.1f}%)\")\n\n    print(f\"\\nTotal Cost: {J_total:.6e}\")\n\n    print(f\"\\n{'=' * 90}\")\n    print(\"ASSESSMENT\")\n    print(\"=\" * 90)\n\n    # Assess normalization health\n    if tuner.norm_ise > 100.0:\n        print(\"\u26a0\ufe0f  WARNING: norm_ise is very large - may cause excessive normalization\")\n    if tuner.weights.state_error > 10.0:\n        print(\"\u26a0\ufe0f  WARNING: state_error weight is very high - may dominate cost\")\n    if J_total < 1e-3:\n        print(\"\ud83d\udd34 CRITICAL: Total cost is near zero - PSO cannot distinguish particles\")\n    else:\n        print(\"\u2705 Cost function sensitivity appears reasonable\")\n\nif __name__ == \"__main__\":\n    diagnose_normalization()",
    "lines": 96,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "906796c8"
  },
  {
    "id": "pso_fitness_investigation_6_1db3a9b1",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\ndef validate_cost_function_config(cost_cfg):\n    \"\"\"Validate cost function configuration\"\"\"\n    # Check weight balance\n    if cost_cfg.weights.state_error > 10.0:\n        warnings.warn(f\"state_error weight ({cost_cfg.weights.state_error}) is very high\")\n\n    # Check baseline gains\n    if hasattr(cost_cfg, 'baseline') and cost_cfg.baseline.gains:\n        warnings.warn(\"Baseline normalization enabled - may cause cost=0 issues\")\n\n    # Check explicit norms\n    if not hasattr(cost_cfg, 'norms'):\n        warnings.warn(\"No explicit normalization constants - using baseline or defaults\")",
    "lines": 16,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1db3a9b1"
  },
  {
    "id": "pso_fitness_investigation_7_34a8fc46",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 7,
    "code": "# Diagnostic logging\nif logger.isEnabledFor(logging.DEBUG):\n    logger.debug(f\"Cost components (normalized):\")\n    logger.debug(f\"  ISE: {ise_n.mean():.6e}\")\n    logger.debug(f\"  U\u00b2:  {u_n.mean():.6e}\")\n    logger.debug(f\"  \u0394U\u00b2: {du_n.mean():.6e}\")\n    logger.debug(f\"  \u03c3\u00b2:  {sigma_n.mean():.6e}\")\n    logger.debug(f\"Total cost: {J.mean():.6e}\")",
    "lines": 8,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "34a8fc46"
  },
  {
    "id": "pso_fitness_investigation_8_d874bb7e",
    "file": "docs\\testing\\reports\\2025-09-30\\pso_fitness_investigation.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef test_cost_sensitivity():\n    \"\"\"Verify PSO cost function distinguishes good/bad controllers\"\"\"\n    # Test that different gains produce different costs\n    gains_good = [10, 5, 8, 3, 15, 2]\n    gains_bad = [100, 100, 100, 100, 100, 100]\n\n    cost_good = evaluate_gains(gains_good)\n    cost_bad = evaluate_gains(gains_bad)\n\n    # Good gains should have lower cost\n    assert cost_good < cost_bad, \"Cost function cannot distinguish controller quality\"\n\n    # Costs should not be zero\n    assert cost_good > 1e-6, \"Good controller cost is suspiciously small\"\n    assert cost_bad > 1e-3, \"Bad controller cost is suspiciously small\"",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d874bb7e"
  },
  {
    "id": "technical_analysis_1_d24d3e20",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 1,
    "code": "# Failed assertion details\nFAILED tests/test_fault_detection/test_fdi_infrastructure.py::TestThresholdAdaptation::test_fixed_threshold_operation\n\nExpected: \"OK\"\nActual: \"FAULT\"\nFault Detection Time: t=0.05s\nResidual Norm: 0.1332 (exceeds threshold: 0.1000)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "d24d3e20"
  },
  {
    "id": "technical_analysis_2_1f2f6bd5",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_fdi_failure():\n    \"\"\"Technical analysis of FDI threshold sensitivity.\"\"\"\n\n    # Problem: Threshold too aggressive for operational conditions\n    current_threshold = 0.1000\n    observed_residual = 0.1332\n    exceedance_ratio = observed_residual / current_threshold  # 1.332\n\n    # Statistical analysis of residual norms\n    residual_statistics = {\n        'mean': 0.0845,\n        'std': 0.0287,\n        'p95': 0.1265,  # 95th percentile exceeds current threshold\n        'p99': 0.1421   # 99th percentile well above threshold\n    }\n\n    # Recommended threshold adjustment\n    recommended_threshold = residual_statistics['p95'] * 1.15  # ~0.145\n    safety_margin = (recommended_threshold - current_threshold) / current_threshold * 100  # 45%\n\n    return {\n        'issue': 'Threshold too restrictive for operational variability',\n        'recommendation': f'Increase threshold to {recommended_threshold:.3f}',\n        'safety_margin': f'{safety_margin:.1f}% additional tolerance'\n    }",
    "lines": 28,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1f2f6bd5"
  },
  {
    "id": "technical_analysis_3_c3b44f8c",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Adaptive Threshold with Hysteresis\nclass AdaptiveThreshold:\n    def __init__(self, base_threshold=0.135, hysteresis=0.02):\n        self.base_threshold = base_threshold\n        self.hysteresis = hysteresis\n        self.current_state = \"OK\"\n\n    def evaluate(self, residual_norm):\n        if self.current_state == \"OK\":\n            threshold = self.base_threshold\n        else:\n            threshold = self.base_threshold - self.hysteresis  # Lower for recovery\n\n        if residual_norm > threshold:\n            self.current_state = \"FAULT\"\n        elif residual_norm < threshold - self.hysteresis:\n            self.current_state = \"OK\"\n\n        return self.current_state\n\n# 2. Statistical Threshold Calibration\ndef calibrate_threshold_from_data(residuals, false_positive_rate=0.05):\n    \"\"\"Set threshold based on statistical analysis.\"\"\"\n    return np.percentile(residuals, (1 - false_positive_rate) * 100)\n\n# 3. Enhanced Residual Calculation\ndef compute_robust_residual(y_actual, y_predicted, outlier_threshold=3.0):\n    \"\"\"Compute residual with outlier rejection.\"\"\"\n    raw_residual = np.linalg.norm(y_actual - y_predicted)\n\n    # Z-score based outlier detection\n    if abs(raw_residual - residual_mean) / residual_std > outlier_threshold:\n        return previous_valid_residual  # Use previous value for outliers\n\n    return raw_residual",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3b44f8c"
  },
  {
    "id": "technical_analysis_4_8c91b8b9",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 4,
    "code": "# example-metadata:\n# runnable: false\n\n# Three critical memory management failures identified:\n\n# Failure 1: Memory Leak Detection\ndef test_memory_leak_detection():\n    \"\"\"Tests controller instantiation memory cleanup.\"\"\"\n    # Issue: Controllers not properly deallocating internal arrays\n    # Memory growth: ~15MB per controller instantiation\n    # Accumulates over batch PSO optimization runs\n\n# Failure 2: NumPy Memory Optimization\ndef test_numpy_memory_optimization():\n    \"\"\"Tests efficient numpy array handling.\"\"\"\n    # Issue: Unnecessary array copies in state calculations\n    # Memory overhead: 2.3x baseline for large state histories\n    # Impact: Batch simulations with 1000+ trials\n\n# Failure 3: Memory Pool Usage\ndef test_memory_pool_usage():\n    \"\"\"Tests memory pool allocation efficiency.\"\"\"\n    # Issue: Memory pool not releasing allocations properly\n    # Fragmentation: 35% internal fragmentation observed\n    # Impact: Long-running optimization sessions",
    "lines": 25,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8c91b8b9"
  },
  {
    "id": "technical_analysis_5_453c6252",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\nclass MemoryAnalysis:\n    \"\"\"Detailed memory usage breakdown.\"\"\"\n\n    def __init__(self):\n        self.baseline_usage = 45.2  # MB\n        self.peak_usage = 2100.3    # MB during batch operations\n        self.growth_rate = 15.7     # MB per controller instantiation\n\n    def analyze_controller_memory(self):\n        \"\"\"Memory usage by controller type.\"\"\"\n        return {\n            'classical_smc': {\n                'instantiation': 12.3,  # MB\n                'per_step': 0.08,       # MB\n                'cleanup_efficiency': 0.73  # 73% properly deallocated\n            },\n            'adaptive_smc': {\n                'instantiation': 15.7,  # MB (higher due to adaptation arrays)\n                'per_step': 0.12,       # MB\n                'cleanup_efficiency': 0.68  # Lower cleanup efficiency\n            },\n            'sta_smc': {\n                'instantiation': 14.1,  # MB\n                'per_step': 0.10,       # MB\n                'cleanup_efficiency': 0.71\n            },\n            'hybrid_smc': {\n                'instantiation': 18.9,  # MB (highest due to dual controllers)\n                'per_step': 0.15,       # MB\n                'cleanup_efficiency': 0.65  # Lowest cleanup efficiency\n            }\n        }\n\n    def numpy_memory_patterns(self):\n        \"\"\"NumPy array allocation patterns.\"\"\"\n        return {\n            'state_arrays': {\n                'allocation_count': 1247,\n                'avg_size': 0.15,  # MB\n                'copy_operations': 423,  # Unnecessary copies\n                'view_efficiency': 0.34  # Only 34% use views vs copies\n            },\n            'control_arrays': {\n                'allocation_count': 890,\n                'avg_size': 0.08,  # MB\n                'copy_operations': 312,\n                'view_efficiency': 0.42\n            }\n        }",
    "lines": 52,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "453c6252"
  },
  {
    "id": "technical_analysis_6_052c6d0f",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 6,
    "code": "# 1. Enhanced Controller Cleanup\nclass MemoryOptimizedController:\n    def __init__(self, gains, max_force, dt):\n        self.gains = np.asarray(gains)\n        self.state_history = deque(maxlen=100)  # Bounded history\n        self.control_history = deque(maxlen=100)\n        self._temp_arrays = []  # Track temporary allocations\n\n    def __del__(self):\n        \"\"\"Explicit cleanup on destruction.\"\"\"\n        self.state_history.clear()\n        self.control_history.clear()\n        for arr in self._temp_arrays:\n            if hasattr(arr, 'base') and arr.base is not None:\n                del arr.base\n        self._temp_arrays.clear()\n\n    def compute_control_efficient(self, state, reference):\n        \"\"\"Memory-efficient control computation.\"\"\"\n        # Use pre-allocated workspace arrays\n        if not hasattr(self, '_workspace'):\n            self._workspace = np.zeros_like(state)\n\n        # In-place operations to avoid copying\n        np.subtract(state, reference, out=self._workspace)\n        error_norm = np.linalg.norm(self._workspace)\n\n        # Use views instead of copies where possible\n        position_error = self._workspace[:4]  # View, not copy\n        velocity_error = self._workspace[4:]  # View, not copy\n\n        return self._compute_control_law(position_error, velocity_error)\n\n# 2. Memory Pool Implementation\nclass ControllerMemoryPool:\n    \"\"\"Custom memory pool for controller operations.\"\"\"\n\n    def __init__(self, pool_size_mb=100):\n        self.pool_size = pool_size_mb * 1024 * 1024  # Convert to bytes\n        self.pool = np.empty(self.pool_size // 8, dtype=np.float64)  # 8 bytes per float64\n        self.allocations = {}\n        self.free_blocks = [{'start': 0, 'size': len(self.pool)}]\n\n    def allocate(self, size, dtype=np.float64):\n        \"\"\"Allocate array from pool.\"\"\"\n        elements_needed = size\n        for i, block in enumerate(self.free_blocks):\n            if block['size'] >= elements_needed:\n                # Allocate from this block\n                start_idx = block['start']\n                allocated_view = self.pool[start_idx:start_idx + elements_needed].view()\n                allocated_view = allocated_view.astype(dtype)\n\n                # Update free blocks\n                remaining_size = block['size'] - elements_needed\n                if remaining_size > 0:\n                    self.free_blocks[i] = {\n                        'start': start_idx + elements_needed,\n                        'size': remaining_size\n                    }\n                else:\n                    del self.free_blocks[i]\n\n                allocation_id = id(allocated_view)\n                self.allocations[allocation_id] = {\n                    'start': start_idx,\n                    'size': elements_needed\n                }\n\n                return allocated_view\n\n        raise MemoryError(\"Insufficient pool memory\")\n\n    def deallocate(self, array):\n        \"\"\"Return array memory to pool.\"\"\"\n        allocation_id = id(array)\n        if allocation_id in self.allocations:\n            alloc_info = self.allocations[allocation_id]\n            # Add back to free blocks (with coalescing logic)\n            self._add_free_block(alloc_info['start'], alloc_info['size'])\n            del self.allocations[allocation_id]\n\n# 3. Batch Operation Memory Optimization\ndef run_batch_simulation_memory_optimized(controller_factory, n_trials=1000):\n    \"\"\"Memory-optimized batch simulation.\"\"\"\n\n    # Pre-allocate result arrays\n    results = np.empty((n_trials, 7))  # 7 performance metrics\n\n    # Reuse single controller instance\n    controller = controller_factory()\n\n    # Memory monitoring\n    memory_monitor = MemoryMonitor()\n\n    for trial in range(n_trials):\n        # Monitor memory before trial\n        memory_monitor.checkpoint(f\"trial_{trial}_start\")\n\n        # Run simulation (controller reused, not re-instantiated)\n        result = run_single_simulation_efficient(controller, trial)\n        results[trial] = result\n\n        # Explicit garbage collection every 100 trials\n        if trial % 100 == 0:\n            import gc\n            gc.collect()\n\n        # Memory monitoring\n        memory_monitor.checkpoint(f\"trial_{trial}_end\")\n\n        # Alert if memory growth detected\n        if memory_monitor.growth_rate > 0.5:  # MB per trial\n            warnings.warn(f\"Memory leak detected at trial {trial}\")\n\n    return results",
    "lines": 116,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "052c6d0f"
  },
  {
    "id": "technical_analysis_7_8901d762",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# 8 critical numerical stability failures identified:\n\nnumerical_failures = {\n    'matrix_conditioning': {\n        'test': 'test_matrix_inversion_robustness',\n        'issue': 'Ill-conditioned matrices causing inversion failures',\n        'condition_numbers': [1e14, 2e13, 8e12],  # Near singular\n        'frequency': '15% of test cases'\n    },\n    'lyapunov_stability': {\n        'test': 'test_lyapunov_stability_verification',\n        'issue': 'Stability analysis diverging for edge cases',\n        'lyapunov_derivatives': [-0.001, 0.002],  # Should be negative definite\n        'impact': 'Stability guarantees violated'\n    },\n    'smc_chattering': {\n        'test': 'test_chattering_reduction_effectiveness',\n        'issue': 'Chattering reduction not working in boundary layer',\n        'chattering_index': 4.7,  # Should be < 2.0\n        'boundary_layer_effectiveness': 0.23  # Should be > 0.8\n    },\n    'division_by_zero': {\n        'test': 'test_zero_division_robustness',\n        'issue': 'Insufficient safeguards for small denominators',\n        'min_denominators': [1e-16, 3e-15],  # Below safe threshold\n        'safe_threshold': 1e-12\n    },\n    'matrix_regularization': {\n        'test': 'test_matrix_regularization',\n        'issue': 'Regularization not applied consistently',\n        'singular_value_ratios': [1e-8, 2e-9],  # Below stability threshold\n        'regularization_parameter': 1e-6  # Too small\n    }\n}",
    "lines": 37,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8901d762"
  },
  {
    "id": "technical_analysis_8_35204c0a",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\ndef analyze_matrix_conditioning():\n    \"\"\"Analysis of matrix conditioning problems.\"\"\"\n\n    # Problem matrices encountered in testing\n    problematic_matrices = [\n        np.array([[1.0, 1.0], [1.0, 1.0000001]]),  # Nearly singular\n        np.array([[1e-8, 0], [0, 1.0]]),           # Poorly scaled\n        np.array([[1.0, 1e8], [1e-8, 1.0]])       # Wide dynamic range\n    ]\n\n    for i, matrix in enumerate(problematic_matrices):\n        cond_num = np.linalg.cond(matrix)\n        if cond_num > 1e12:\n            print(f\"Matrix {i}: Condition number {cond_num:.2e} (CRITICAL)\")\n\n            # Propose regularization\n            regularized = matrix + np.eye(matrix.shape[0]) * 1e-6\n            new_cond = np.linalg.cond(regularized)\n            print(f\"  Regularized: {new_cond:.2e}\")",
    "lines": 22,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "35204c0a"
  },
  {
    "id": "technical_analysis_9_76b09bb0",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 9,
    "code": "# example-metadata:\n# runnable: false\n\ndef verify_lyapunov_stability(A, Q):\n    \"\"\"Verify Lyapunov stability with robust numerical methods.\"\"\"\n\n    # Standard Lyapunov equation: A^T P + P A + Q = 0\n    try:\n        P = scipy.linalg.solve_lyapunov(A.T, -Q)\n    except LinAlgError:\n        # Fallback to regularized solution\n        A_reg = A + np.eye(A.shape[0]) * 1e-8\n        P = scipy.linalg.solve_lyapunov(A_reg.T, -Q)\n\n    # Verify positive definiteness\n    eigenvals = np.linalg.eigvals(P)\n    if np.any(eigenvals <= 0):\n        return False, f\"Non-positive eigenvalues: {eigenvals[eigenvals <= 0]}\"\n\n    # Verify stability condition\n    stability_matrix = A.T @ P + P @ A + Q\n    max_eigenval = np.max(np.real(np.linalg.eigvals(stability_matrix)))\n\n    if max_eigenval > 1e-10:  # Numerical tolerance\n        return False, f\"Stability violated: max eigenvalue {max_eigenval}\"\n\n    return True, \"Stable\"",
    "lines": 27,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76b09bb0"
  },
  {
    "id": "technical_analysis_10_542c164e",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# 1. Enhanced Matrix Operations\nclass RobustMatrixOps:\n    \"\"\"Numerically stable matrix operations.\"\"\"\n\n    @staticmethod\n    def safe_inverse(matrix, regularization=1e-12):\n        \"\"\"Compute matrix inverse with automatic regularization.\"\"\"\n        cond_num = np.linalg.cond(matrix)\n\n        if cond_num > 1e12:\n            # Apply Tikhonov regularization\n            regularized = matrix + np.eye(matrix.shape[0]) * regularization\n            return np.linalg.inv(regularized)\n        else:\n            return np.linalg.inv(matrix)\n\n    @staticmethod\n    def robust_solve(A, b, regularization=1e-12):\n        \"\"\"Solve linear system with enhanced stability.\"\"\"\n        try:\n            # Try standard solution first\n            return np.linalg.solve(A, b)\n        except LinAlgError:\n            # Fallback to regularized solution\n            A_reg = A + np.eye(A.shape[0]) * regularization\n            return np.linalg.solve(A_reg, b)\n\n    @staticmethod\n    def safe_division(numerator, denominator, epsilon=1e-12):\n        \"\"\"Division with zero-protection.\"\"\"\n        safe_denom = np.where(np.abs(denominator) < epsilon,\n                             np.sign(denominator) * epsilon,\n                             denominator)\n        return numerator / safe_denom\n\n# 2. Numerically Stable SMC Implementation\nclass NumericallyStableSMC:\n    \"\"\"SMC controller with enhanced numerical stability.\"\"\"\n\n    def __init__(self, gains, max_force, boundary_layer=0.01):\n        self.gains = np.asarray(gains)\n        self.max_force = max_force\n        self.boundary_layer = max(boundary_layer, 1e-6)  # Prevent zero boundary\n        self.matrix_ops = RobustMatrixOps()\n\n    def compute_sliding_surface(self, state):\n        \"\"\"Numerically stable sliding surface computation.\"\"\"\n        # Enhanced precision for critical calculations\n        state_hp = np.array(state, dtype=np.float64)  # High precision\n\n        # Compute sliding surface with overflow protection\n        surface_terms = []\n        for i, gain in enumerate(self.gains):\n            if i < len(state_hp):\n                term = gain * state_hp[i]\n                # Prevent overflow\n                if np.abs(term) > 1e6:\n                    term = np.sign(term) * 1e6\n                surface_terms.append(term)\n\n        surface = np.sum(surface_terms)\n\n        # Prevent numerical underflow\n        if np.abs(surface) < 1e-15:\n            surface = 0.0\n\n        return surface\n\n    def robust_switching_function(self, surface):\n        \"\"\"Switching function with enhanced stability.\"\"\"\n        # Use tanh for smooth switching with numerical stability\n        normalized_surface = surface / self.boundary_layer\n\n        # Prevent overflow in exponential\n        if np.abs(normalized_surface) > 50:\n            return np.sign(normalized_surface)\n\n        return np.tanh(normalized_surface)\n\n# 3. Adaptive Numerical Precision\nclass AdaptivePrecisionController:\n    \"\"\"Controller that adjusts numerical precision based on conditioning.\"\"\"\n\n    def __init__(self, base_precision=np.float64):\n        self.base_precision = base_precision\n        self.high_precision = np.longdouble  # Higher precision for critical ops\n        self.precision_threshold = 1e10  # Condition number threshold\n\n    def compute_control_adaptive_precision(self, state, gains):\n        \"\"\"Adaptively adjust precision based on numerical conditioning.\"\"\"\n\n        # Compute condition number estimate\n        state_matrix = np.outer(state, gains)\n        cond_estimate = np.linalg.cond(state_matrix)\n\n        if cond_estimate > self.precision_threshold:\n            # Use high precision for ill-conditioned problems\n            state_hp = np.array(state, dtype=self.high_precision)\n            gains_hp = np.array(gains, dtype=self.high_precision)\n            control_hp = self._compute_control(state_hp, gains_hp)\n            return np.array(control_hp, dtype=self.base_precision)\n        else:\n            # Standard precision sufficient\n            return self._compute_control(state, gains)",
    "lines": 107,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "542c164e"
  },
  {
    "id": "technical_analysis_11_ae32cfde",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\nperformance_metrics = {\n    'test_execution_time': {\n        'total_duration': '45 minutes 23 seconds',\n        'average_per_test': '5.04 seconds',\n        'slowest_tests': [\n            ('test_batch_pso_optimization', '8m 34s'),\n            ('test_memory_stress_test', '6m 12s'),\n            ('test_numerical_stability_monte_carlo', '4m 56s')\n        ],\n        'fastest_tests': [\n            ('test_controller_instantiation', '0.12s'),\n            ('test_basic_configuration', '0.08s'),\n            ('test_simple_math_operations', '0.05s')\n        ]\n    },\n    'memory_consumption': {\n        'peak_usage': '2.1 GB',\n        'baseline_usage': '45.2 MB',\n        'memory_efficiency': 0.67,  # 67% efficient usage\n        'gc_collections': 847,\n        'large_object_allocations': 23\n    },\n    'cpu_utilization': {\n        'average_cpu': '78%',\n        'peak_cpu': '95%',\n        'cpu_efficiency': 0.82,\n        'parallel_test_efficiency': 0.71  # 71% parallel efficiency\n    }\n}",
    "lines": 32,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ae32cfde"
  },
  {
    "id": "technical_analysis_12_557d1f1c",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Current vs. Target Performance\nperformance_comparison = {\n    'test_suite_execution': {\n        'current': '45m 23s',\n        'target': '30m 00s',\n        'gap': '+51% slower than target'\n    },\n    'memory_efficiency': {\n        'current': '67%',\n        'target': '85%',\n        'gap': '18 percentage points below target'\n    },\n    'numerical_stability': {\n        'current': '74% tests passing',\n        'target': '98% tests passing',\n        'gap': '24 percentage points below target'\n    }\n}",
    "lines": 21,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "557d1f1c"
  },
  {
    "id": "technical_analysis_13_68c97753",
    "file": "docs\\testing\\reports\\2025-09-30\\technical_analysis.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\nvalidation_checklist = {\n    'numerical_stability': {\n        'matrix_conditioning': '\u2705 All matrices well-conditioned (cond < 1e10)',\n        'lyapunov_stability': '\u2705 Stability verified for all controllers',\n        'chattering_reduction': '\u2705 Chattering index < 2.0 in all scenarios',\n        'division_safety': '\u2705 Zero-division protection in all operations'\n    },\n    'memory_management': {\n        'leak_detection': '\u2705 No memory leaks in 8-hour stress test',\n        'allocation_efficiency': '\u2705 >85% memory pool utilization',\n        'garbage_collection': '\u2705 Automatic cleanup verified'\n    },\n    'fault_detection': {\n        'threshold_calibration': '\u2705 <1% false positive rate',\n        'detection_accuracy': '\u2705 >99% true positive rate',\n        'response_time': '\u2705 Fault detection within 100ms'\n    },\n    'performance': {\n        'test_execution': '\u2705 Full test suite completes in <30 minutes',\n        'simulation_speed': '\u2705 Real-time factor >10x',\n        'optimization_convergence': '\u2705 PSO converges within 200 iterations'\n    }\n}",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "68c97753"
  },
  {
    "id": "control_theory_analysis_1_e645d1e6",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 1,
    "code": "# FDI Residual Computation\nr(t) = ||x(t) - x\u0302(t)||\u2082  [Observer-based residual]\nFault Detection: r(t) > \u03c4  [Threshold-based detection]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "e645d1e6"
  },
  {
    "id": "control_theory_analysis_2_113c4d37",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 2,
    "code": "# Adaptive Threshold Strategy\n\u03c4_adaptive(t) = \u03c4_base + k\u2081\u00b7e^(-k\u2082\u00b7t)  [Time-varying threshold]\nwhere: \u03c4_base = 0.1350, k\u2081 = 0.0500, k\u2082 = 20.0",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "113c4d37"
  },
  {
    "id": "control_theory_analysis_3_1083678d",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 3,
    "code": "# Jacobian Matrix Condition Number\nJ = \u2202f/\u2202x  [System Jacobian]\n\u03ba(J) = ||J||\u00b7||J\u207b\u00b9||  [Condition number]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1083678d"
  },
  {
    "id": "control_theory_analysis_4_fc5a8f33",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 4,
    "code": "# Tikhonov Regularization\nJ_reg = J + \u03bb\u00b7I  where \u03bb = \u03b5\u00b7trace(J)/n\nJ_inv = (J_reg)\u207b\u00b9  [Stable inversion]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "fc5a8f33"
  },
  {
    "id": "control_theory_analysis_5_1aa003ac",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 5,
    "code": "if \u03ba(J) > condition_threshold:\n    # Use pseudoinverse with SVD\n    U, \u03a3, V\u1d40 = SVD(J)\n    \u03a3_reg = diag(max(\u03c3\u1d62, \u03b5) for \u03c3\u1d62 in \u03a3)\n    J_pinv = V\u00b7\u03a3_reg\u207b\u00b9\u00b7U\u1d40",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "1aa003ac"
  },
  {
    "id": "control_theory_analysis_6_76c454bb",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 6,
    "code": "# Gain Saturation\nK_safe = clip(K, K_min, K_max)\nwhere K_min = 0.1, K_max = 1000.0\n\n# Division-by-Zero Protection\ndenominator = max(|denominator|, \u03b5_safe)\nwhere \u03b5_safe = 1e-10",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "76c454bb"
  },
  {
    "id": "control_theory_analysis_7_c4d057de",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 7,
    "code": "# Control Loop Memory Requirements\nT_sample = 0.01s  [10ms sampling period]\nT_computation < 0.8\u00b7T_sample  [Real-time constraint]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4d057de"
  },
  {
    "id": "control_theory_analysis_8_ac421cf8",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 8,
    "code": "# Pre-allocated Memory Pools\ncontrol_buffer = numpy.zeros((N_steps, n_controls))  [Pre-allocation]\nstate_history = collections.deque(maxlen=history_length)  [Bounded storage]\n\n# Deterministic Memory Management\nwith memory_pool_context():\n    control_signal = controller.compute_control(state)",
    "lines": 7,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ac421cf8"
  },
  {
    "id": "control_theory_analysis_9_c4484e34",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 9,
    "code": "# Integral Performance Measures\nISE = \u222b\u2080\u1d40 ||e(t)||\u00b2 dt  [Integral Squared Error]\nITAE = \u222b\u2080\u1d40 t\u00b7||e(t)|| dt  [Integral Time-weighted Absolute Error]\nIAE = \u222b\u2080\u1d40 ||e(t)|| dt     [Integral Absolute Error]",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c4484e34"
  },
  {
    "id": "control_theory_analysis_10_b3172294",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 10,
    "code": "# Phase and Gain Margins (Linearized Analysis)\nPM = arg(G(j\u03c9c)) + 180\u00b0  [Phase Margin at gain crossover]\nGM = -20log\u2081\u2080|G(j\u03c9p)|   [Gain Margin at phase crossover]",
    "lines": 3,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b3172294"
  },
  {
    "id": "control_theory_analysis_11_f2cf2dc1",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 11,
    "code": "# Quantitative Chattering Measure\nCI = (1/T)\u222b\u2080\u1d40 |du/dt| dt / |u_nominal|  [Normalized chattering index]",
    "lines": 2,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f2cf2dc1"
  },
  {
    "id": "control_theory_analysis_12_4133527b",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# Implementation Priority: HIGH\nclass NumericallyRobustController:\n    def __init__(self, condition_threshold=1e6):\n        self.condition_threshold = condition_threshold\n        self.epsilon_safe = 1e-10\n\n    def safe_matrix_inverse(self, matrix):\n        condition_number = np.linalg.cond(matrix)\n        if condition_number > self.condition_threshold:\n            return self.regularized_inverse(matrix)\n        return np.linalg.inv(matrix)\n\n    def regularized_inverse(self, matrix):\n        regularization = self.epsilon_safe * np.trace(matrix) / matrix.shape[0]\n        regularized_matrix = matrix + regularization * np.eye(matrix.shape[0])\n        return np.linalg.inv(regularized_matrix)",
    "lines": 19,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "4133527b"
  },
  {
    "id": "control_theory_analysis_13_49b1fc2e",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Implementation Priority: HIGH\nclass AdaptiveFaultDetection:\n    def __init__(self, base_threshold=0.135, decay_rate=20.0):\n        self.base_threshold = base_threshold\n        self.decay_rate = decay_rate\n        self.initial_threshold_offset = 0.05\n\n    def compute_adaptive_threshold(self, time):\n        transient_compensation = self.initial_threshold_offset * np.exp(-self.decay_rate * time)\n        return self.base_threshold + transient_compensation\n\n    def detect_fault(self, residual, time):\n        threshold = self.compute_adaptive_threshold(time)\n        return residual > threshold",
    "lines": 17,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "49b1fc2e"
  },
  {
    "id": "control_theory_analysis_14_ebc1e206",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\control_theory_analysis.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# Implementation Priority: MEDIUM\nclass MemoryEfficientController:\n    def __init__(self, max_history=100):\n        self.state_history = collections.deque(maxlen=max_history)\n        self.control_history = collections.deque(maxlen=max_history)\n\n    def compute_control(self, state):\n        # Use in-place operations to minimize allocations\n        control_signal = self._compute_control_inplace(state)\n\n        # Bounded history storage\n        self.state_history.append(state.copy())\n        self.control_history.append(control_signal.copy())\n\n        return control_signal",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "ebc1e206"
  },
  {
    "id": "resolution_roadmap_1_c634ea5b",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 1,
    "code": "# Current Issue:\nFAULT_THRESHOLD = 0.1000  # Too conservative\nresidual_norm = 0.1332    # Normal transient behavior\nresult = \"FAULT\"          # False positive",
    "lines": 4,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c634ea5b"
  },
  {
    "id": "resolution_roadmap_2_8ba7c428",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 2,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/utils/monitoring/fault_detection.py\nclass AdaptiveFaultDetection:\n    \"\"\"Enhanced FDI with time-varying thresholds and statistical validation.\"\"\"\n\n    def __init__(self, config: FDIConfig):\n        self.base_threshold = 0.135          # Calibrated base threshold\n        self.transient_offset = 0.05         # Initial transient allowance\n        self.decay_rate = 20.0               # Exponential decay rate\n        self.statistical_window = 10         # Rolling window for statistics\n        self.confidence_level = 0.95         # Statistical confidence\n\n    def compute_adaptive_threshold(self, time: float) -> float:\n        \"\"\"Time-varying threshold to handle initial transients.\"\"\"\n        transient_compensation = self.transient_offset * np.exp(-self.decay_rate * time)\n        return self.base_threshold + transient_compensation\n\n    def detect_fault_with_statistics(self, residual: float, time: float) -> FaultStatus:\n        \"\"\"Statistical fault detection with false positive reduction.\"\"\"\n        threshold = self.compute_adaptive_threshold(time)\n\n        # Basic threshold check\n        exceeds_threshold = residual > threshold\n\n        # Statistical validation\n        if exceeds_threshold:\n            return self._validate_fault_statistically(residual, threshold)\n\n        return FaultStatus(detected=False, confidence=0.0, type=None)",
    "lines": 31,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "8ba7c428"
  },
  {
    "id": "resolution_roadmap_3_2a5c3724",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 3,
    "code": "# example-metadata:\n# runnable: false\n\n# Test file: tests/test_monitoring/test_adaptive_fault_detection.py\ndef test_transient_handling():\n    \"\"\"Verify FDI handles initial transients correctly.\"\"\"\n    fdi = AdaptiveFaultDetection(FDIConfig())\n\n    # Test early time period (t < 0.1s)\n    early_threshold = fdi.compute_adaptive_threshold(0.05)\n    assert early_threshold > 0.15  # Allow for transients\n\n    # Test steady-state period (t > 1.0s)\n    steady_threshold = fdi.compute_adaptive_threshold(1.0)\n    assert abs(steady_threshold - 0.135) < 1e-3\n\ndef test_false_positive_reduction():\n    \"\"\"Verify statistical validation reduces false positives.\"\"\"\n    fdi = AdaptiveFaultDetection(FDIConfig())\n\n    # Simulate normal operation with noise\n    residuals = [0.132, 0.128, 0.135, 0.130, 0.133]  # Normal variation\n    faults = [fdi.detect_fault_with_statistics(r, 0.1) for r in residuals]\n\n    false_positive_rate = sum(f.detected for f in faults) / len(faults)\n    assert false_positive_rate < 0.05  # < 5% false positive rate",
    "lines": 26,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "2a5c3724"
  },
  {
    "id": "resolution_roadmap_4_a50f252e",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 4,
    "code": "# Current Issues:\n1. Controller instantiation memory leaks\n2. Numpy array allocation inefficiencies\n3. Missing cleanup in controller destructors\n4. Memory pool allocation failures",
    "lines": 5,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a50f252e"
  },
  {
    "id": "resolution_roadmap_5_c3ad9097",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 5,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/base/memory_efficient_controller.py\nclass MemoryEfficientController(ABC):\n    \"\"\"Base class with automatic memory management.\"\"\"\n\n    def __init__(self, max_history: int = 100):\n        # Pre-allocated memory pools\n        self._state_buffer = np.zeros((max_history, 8))     # State history\n        self._control_buffer = np.zeros((max_history, 1))   # Control history\n        self._computation_buffer = np.zeros(64)             # Temporary computations\n\n        # Bounded history with automatic cleanup\n        self._history_index = 0\n        self._max_history = max_history\n\n        # Memory monitoring\n        self._memory_tracker = MemoryTracker()\n\n    def compute_control(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Memory-safe control computation.\"\"\"\n        with self._memory_tracker.track_allocation():\n            # Use pre-allocated buffers for computations\n            control = self._compute_control_efficient(state)\n\n            # Store in circular buffer (no memory growth)\n            self._store_in_circular_buffer(state, control)\n\n            return control\n\n    def __del__(self):\n        \"\"\"Explicit cleanup on controller destruction.\"\"\"\n        self._cleanup_resources()\n\n    def _cleanup_resources(self):\n        \"\"\"Clean up all allocated resources.\"\"\"\n        self._state_buffer = None\n        self._control_buffer = None\n        self._computation_buffer = None\n        if hasattr(self, '_memory_tracker'):\n            self._memory_tracker.cleanup()",
    "lines": 42,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "c3ad9097"
  },
  {
    "id": "resolution_roadmap_6_74daa21f",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 6,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/utils/memory/numpy_optimizer.py\nclass NumpyMemoryOptimizer:\n    \"\"\"Optimized numpy operations to minimize allocations.\"\"\"\n\n    @staticmethod\n    def in_place_matrix_operations(matrix: np.ndarray, operation: str) -> np.ndarray:\n        \"\"\"Perform matrix operations in-place to avoid allocations.\"\"\"\n        if operation == \"normalize\":\n            norm = np.linalg.norm(matrix)\n            if norm > 1e-10:\n                matrix /= norm  # In-place division\n            return matrix\n\n        elif operation == \"clip\":\n            np.clip(matrix, -1000.0, 1000.0, out=matrix)  # In-place clipping\n            return matrix\n\n    @staticmethod\n    def memory_pool_context():\n        \"\"\"Context manager for temporary memory pool usage.\"\"\"\n        return MemoryPoolContext()\n\nclass MemoryPoolContext:\n    \"\"\"Context manager for bounded memory operations.\"\"\"\n\n    def __enter__(self):\n        self.initial_memory = psutil.Process().memory_info().rss\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        final_memory = psutil.Process().memory_info().rss\n        memory_growth = final_memory - self.initial_memory\n\n        if memory_growth > MEMORY_GROWTH_THRESHOLD:\n            warnings.warn(f\"Memory growth detected: {memory_growth/1024/1024:.2f} MB\")",
    "lines": 38,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "74daa21f"
  },
  {
    "id": "resolution_roadmap_7_9501a82d",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 7,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/factory/memory_managed_factory.py\nclass MemoryManagedFactory:\n    \"\"\"Controller factory with automatic memory management.\"\"\"\n\n    def __init__(self):\n        self._controller_pool = {}           # Reusable controller instances\n        self._memory_monitor = MemoryMonitor()\n\n    def create_controller(self, controller_type: str, config: dict) -> Controller:\n        \"\"\"Create controller with memory tracking.\"\"\"\n        with self._memory_monitor.track_creation():\n            # Check for reusable instance\n            controller_key = self._compute_controller_key(controller_type, config)\n\n            if controller_key in self._controller_pool:\n                controller = self._controller_pool[controller_key]\n                controller.reset_state()  # Reset instead of recreate\n                return controller\n\n            # Create new instance with monitoring\n            controller = self._create_new_controller(controller_type, config)\n            self._controller_pool[controller_key] = controller\n\n            return controller\n\n    def cleanup_unused_controllers(self):\n        \"\"\"Cleanup controllers not used recently.\"\"\"\n        current_time = time.time()\n        to_remove = []\n\n        for key, controller in self._controller_pool.items():\n            if current_time - controller.last_used > CONTROLLER_TIMEOUT:\n                controller._cleanup_resources()\n                to_remove.append(key)\n\n        for key in to_remove:\n            del self._controller_pool[key]",
    "lines": 40,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "9501a82d"
  },
  {
    "id": "resolution_roadmap_8_f981c0d2",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 8,
    "code": "# example-metadata:\n# runnable: false\n\n# Test file: tests/test_memory/test_memory_management.py\ndef test_memory_leak_prevention():\n    \"\"\"Verify no memory leaks in controller lifecycle.\"\"\"\n    initial_memory = get_memory_usage()\n\n    # Create and destroy multiple controllers\n    for i in range(100):\n        controller = create_controller(\"classical_smc\", test_config)\n        _ = controller.compute_control(test_state)\n        del controller\n\n    final_memory = get_memory_usage()\n    memory_growth = final_memory - initial_memory\n\n    assert memory_growth < ACCEPTABLE_MEMORY_GROWTH  # < 10MB growth\n\ndef test_numpy_memory_optimization():\n    \"\"\"Verify numpy operations don't cause memory growth.\"\"\"\n    optimizer = NumpyMemoryOptimizer()\n\n    with memory_monitoring():\n        for i in range(1000):\n            matrix = np.random.random((100, 100))\n            optimizer.in_place_matrix_operations(matrix, \"normalize\")\n            optimizer.in_place_matrix_operations(matrix, \"clip\")\n\n    assert memory_growth < NUMPY_MEMORY_THRESHOLD",
    "lines": 30,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f981c0d2"
  },
  {
    "id": "resolution_roadmap_9_a9c4cd9c",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 9,
    "code": "# Current Issues:\n1. Matrix condition numbers > 10^12 (ill-conditioned)\n2. Division by zero in matrix operations\n3. Numerical overflow with large gains\n4. Lack of robust matrix inversion methods\n5. Missing numerical safeguards in control laws",
    "lines": 6,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "a9c4cd9c"
  },
  {
    "id": "resolution_roadmap_10_60f8ffcb",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 10,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/utils/numerical/robust_matrix_ops.py\nclass RobustMatrixOperations:\n    \"\"\"Numerically stable matrix operations for control systems.\"\"\"\n\n    def __init__(self, condition_threshold: float = 1e6, regularization_eps: float = 1e-10):\n        self.condition_threshold = condition_threshold\n        self.regularization_eps = regularization_eps\n\n    def safe_matrix_inverse(self, matrix: np.ndarray) -> np.ndarray:\n        \"\"\"Numerically stable matrix inversion with fallback methods.\"\"\"\n        try:\n            # Check condition number\n            condition_number = np.linalg.cond(matrix)\n\n            if condition_number > self.condition_threshold:\n                return self._regularized_inverse(matrix)\n\n            # Standard inversion for well-conditioned matrices\n            return np.linalg.inv(matrix)\n\n        except np.linalg.LinAlgError:\n            # Fallback to pseudoinverse\n            return self._robust_pseudoinverse(matrix)\n\n    def _regularized_inverse(self, matrix: np.ndarray) -> np.ndarray:\n        \"\"\"Tikhonov regularization for ill-conditioned matrices.\"\"\"\n        regularization = self.regularization_eps * np.trace(matrix) / matrix.shape[0]\n        regularized_matrix = matrix + regularization * np.eye(matrix.shape[0])\n        return np.linalg.inv(regularized_matrix)\n\n    def _robust_pseudoinverse(self, matrix: np.ndarray) -> np.ndarray:\n        \"\"\"SVD-based pseudoinverse with numerical thresholding.\"\"\"\n        U, sigma, Vt = np.linalg.svd(matrix, full_matrices=False)\n\n        # Threshold small singular values\n        sigma_threshold = self.regularization_eps * np.max(sigma)\n        sigma_inv = np.where(sigma > sigma_threshold, 1.0 / sigma, 0.0)\n\n        return Vt.T @ np.diag(sigma_inv) @ U.T\n\n    def safe_division(self, numerator: float, denominator: float) -> float:\n        \"\"\"Division with zero-protection.\"\"\"\n        if abs(denominator) < self.regularization_eps:\n            return np.sign(denominator) * numerator / self.regularization_eps\n        return numerator / denominator",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "60f8ffcb"
  },
  {
    "id": "resolution_roadmap_11_b459cbc8",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 11,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/controllers/base/numerically_stable_controller.py\nclass NumericallyStableController(ABC):\n    \"\"\"Base class for numerically robust control implementations.\"\"\"\n\n    def __init__(self, numerical_config: NumericalConfig):\n        self.matrix_ops = RobustMatrixOperations(\n            condition_threshold=numerical_config.condition_threshold,\n            regularization_eps=numerical_config.regularization_eps\n        )\n        self.gain_limits = numerical_config.gain_limits\n        self.output_limits = numerical_config.output_limits\n\n    def compute_control_safe(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Numerically safe control computation.\"\"\"\n        try:\n            # Validate inputs\n            self._validate_state_vector(state)\n\n            # Compute control with numerical safeguards\n            control = self._compute_control_with_safeguards(state)\n\n            # Apply output limiting\n            control = self._apply_output_limits(control)\n\n            # Validate outputs\n            self._validate_control_output(control)\n\n            return control\n\n        except NumericalInstabilityError as e:\n            # Log the issue and return safe fallback\n            logger.warning(f\"Numerical instability detected: {e}\")\n            return self._safe_fallback_control(state)\n\n    def _compute_control_with_safeguards(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Control computation with numerical protection.\"\"\"\n        # Safeguarded sliding surface computation\n        sliding_surface = self._compute_sliding_surface_safe(state)\n\n        # Robust equivalent control\n        equivalent_control = self._compute_equivalent_control_safe(state)\n\n        # Bounded switching control\n        switching_control = self._compute_switching_control_safe(sliding_surface)\n\n        return equivalent_control + switching_control\n\n    def _compute_equivalent_control_safe(self, state: np.ndarray) -> np.ndarray:\n        \"\"\"Equivalent control with matrix operation safeguards.\"\"\"\n        # Compute Jacobian with numerical stability checks\n        jacobian = self._compute_jacobian_safe(state)\n\n        # Robust matrix inversion\n        jacobian_inv = self.matrix_ops.safe_matrix_inverse(jacobian)\n\n        # Safe matrix-vector multiplication\n        return -jacobian_inv @ self._compute_drift_term(state)\n\n    def _apply_output_limits(self, control: np.ndarray) -> np.ndarray:\n        \"\"\"Apply control output limits with smooth saturation.\"\"\"\n        return np.tanh(control / self.output_limits.max_force) * self.output_limits.max_force",
    "lines": 64,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "b459cbc8"
  },
  {
    "id": "resolution_roadmap_12_412f67e3",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 12,
    "code": "# example-metadata:\n# runnable: false\n\n# File: src/utils/validation/gain_validator.py\nclass GainValidator:\n    \"\"\"Comprehensive gain validation for numerical stability.\"\"\"\n\n    def __init__(self, stability_margins: dict):\n        self.min_gains = stability_margins[\"min_gains\"]\n        self.max_gains = stability_margins[\"max_gains\"]\n        self.stability_constraints = stability_margins[\"stability_constraints\"]\n\n    def validate_gain_stability(self, gains: List[float], controller_type: str) -> ValidationResult:\n        \"\"\"Validate gains for numerical and control stability.\"\"\"\n        results = ValidationResult()\n\n        # Basic bounds checking\n        if not self._check_gain_bounds(gains):\n            results.add_error(\"Gains outside allowable bounds\")\n\n        # Stability-specific validation\n        if controller_type == \"classical_smc\":\n            results.merge(self._validate_classical_smc_gains(gains))\n        elif controller_type == \"adaptive_smc\":\n            results.merge(self._validate_adaptive_smc_gains(gains))\n\n        # Numerical conditioning checks\n        results.merge(self._validate_numerical_conditioning(gains))\n\n        return results\n\n    def _validate_numerical_conditioning(self, gains: List[float]) -> ValidationResult:\n        \"\"\"Check for potential numerical conditioning issues.\"\"\"\n        results = ValidationResult()\n\n        # Check for extreme gain ratios\n        gain_ratios = [g1/g2 for g1 in gains for g2 in gains if g2 != 0]\n        max_ratio = max(gain_ratios)\n\n        if max_ratio > NUMERICAL_CONDITIONING_THRESHOLD:\n            results.add_warning(f\"Large gain ratio detected: {max_ratio:.2e}\")\n\n        # Check for very small or large gains\n        if any(g < MINIMUM_STABLE_GAIN for g in gains):\n            results.add_error(\"Gains too small for numerical stability\")\n\n        if any(g > MAXIMUM_STABLE_GAIN for g in gains):\n            results.add_error(\"Gains too large for numerical stability\")\n\n        return results",
    "lines": 50,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "412f67e3"
  },
  {
    "id": "resolution_roadmap_13_f45e4dbe",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 13,
    "code": "# example-metadata:\n# runnable: false\n\n# Test file: tests/test_numerical/test_numerical_stability.py\ndef test_matrix_conditioning_robustness():\n    \"\"\"Test matrix operations with ill-conditioned matrices.\"\"\"\n    matrix_ops = RobustMatrixOperations()\n\n    # Create ill-conditioned matrix\n    ill_conditioned = create_ill_conditioned_matrix(condition_number=1e12)\n\n    # Should not raise exception\n    result = matrix_ops.safe_matrix_inverse(ill_conditioned)\n\n    # Verify result is reasonable\n    assert np.allclose(ill_conditioned @ result, np.eye(ill_conditioned.shape[0]), atol=1e-3)\n\ndef test_division_by_zero_protection():\n    \"\"\"Test division operations with zero denominators.\"\"\"\n    matrix_ops = RobustMatrixOperations()\n\n    # Test various zero and near-zero denominators\n    test_cases = [0.0, 1e-15, -1e-15, 1e-12, -1e-12]\n\n    for denominator in test_cases:\n        result = matrix_ops.safe_division(1.0, denominator)\n        assert np.isfinite(result)\n        assert abs(result) < SAFE_DIVISION_THRESHOLD\n\ndef test_controller_numerical_stability():\n    \"\"\"Test controller stability with extreme conditions.\"\"\"\n    controller = create_numerically_stable_controller(\"classical_smc\")\n\n    # Test with various challenging states\n    extreme_states = [\n        np.array([1e6, 1e6, 1e6, 1e6, 0, 0, 0, 0]),     # Large positions\n        np.array([1e-12, 1e-12, 1e-12, 1e-12, 0, 0, 0, 0]), # Very small values\n        np.array([np.inf, 0, 0, 0, 0, 0, 0, 0]),         # Infinite values\n    ]\n\n    for state in extreme_states:\n        try:\n            control = controller.compute_control_safe(state)\n            assert np.all(np.isfinite(control))\n            assert np.all(np.abs(control) <= MAX_CONTROL_OUTPUT)\n        except NumericalInstabilityError:\n            # Acceptable if properly handled\n            pass",
    "lines": 48,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f45e4dbe"
  },
  {
    "id": "resolution_roadmap_14_f5f69677",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 14,
    "code": "# example-metadata:\n# runnable: false\n\n# File: pytest.ini\n[tool:pytest]\nmarkers =\n    integration: Integration tests requiring full system\n    slow: Slow tests (>10 seconds)\n    memory: Memory-intensive tests\n    numerical: Numerical stability tests\n    hardware: Hardware-in-loop tests\n    benchmark: Performance benchmark tests\n    smoke: Quick smoke tests for CI\n    regression: Regression prevention tests\n\n# Test timeout and memory limits\ntimeout = 300\nmaxfail = 5",
    "lines": 18,
    "is_runnable": false,
    "metadata": {
      "runnable": false,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "f5f69677"
  },
  {
    "id": "resolution_roadmap_15_40c70ae2",
    "file": "docs\\testing\\reports\\2025-09-30\\technical\\resolution_roadmap.md",
    "index": 15,
    "code": "# Before (problematic):\ndef test_controller_performance():\n    performance = evaluate_controller(controller)\n    return performance > threshold  # WRONG: pytest ignores returns\n\n# After (correct):\ndef test_controller_performance():\n    performance = evaluate_controller(controller)\n    assert performance > threshold, f\"Performance {performance} below threshold {threshold}\"",
    "lines": 9,
    "is_runnable": true,
    "metadata": {
      "runnable": null,
      "requires": [],
      "timeout": 30,
      "expected_output": null
    },
    "hash": "40c70ae2"
  }
]