\)
Advanced
PIDControl
KarlJ. Astrom ToreHdgglund
Department of Automatic Control Lund Institute of Technology Lund Uniuersity
z\
J, ?l s n r ISA-ThInestrumentaSlioysnt,ems,
andAutomaStionciety

Copyright@2006by

ISA - Instrumentation, Systems,and Automation Society 67 AlexanderDrive P.O.Box 12277 ResearchTriangle Park, NC 27709

All rights reserved.

Printed in the United States of America. 1098765432

ISBN r-55617-942-r

No part of this work may be reproduced,storedin a retrieval system,or transmitted in any form or by any means,electronic,mechanical,photocopying,recording or otherwise,without the prior written permission of the publisher.

Notice The information presentedin this publication is for the general educationof the
reader.Becauseneither the author nor the publisher has any control over the useof the information by the reader,both the author and the publisher disclaim any and all liability of any kind arising out of suchuse.The readeris expectedto exercisesound professionaljudgment in using any of the information presentedin a particular application.
Additionally, neither the author nor the publisher have investigated or considered the effect of any patents on the ability of the reader to use any of the information in a particular application.The readeris responsiblefor reviewing any possiblepatents that may affectany particular useof the information presented.
Any referencesto commercialproducts in the work are cited as examplesonly. Neither the author nor the publisher endorsesany referencedcommercialproduct. Any trademarks or tradenamesreferencedbelongto the respectiveowner of the mark or name.Neither the author nor the publisher makesany representationregardingthe availability of any referencedcommercialproduct at any time. The manufacturer's instructions on use of any commercialproduct must be followedat all times, evenif in conflict with the information in this publication.

Library of Congress Cataloging-in-Publication Data

Astrtjm, Karl J. (Karl Johan), lg34-

AdvancedPID control / Karl Johan Astrom and Tore Hagglund.

p. cm.

Includesbibliographicalreferencesand index.

ISBN 1-55617-942-(1pbk.)

1. PID controllers. I. Hrigglund,Tore.II. Title.

TJ223.P55A852006

629.8'3--dc22

20050r4664

Preface
The PID controller is the most common solution to practical control problems. Although controllers with proportional and integral action have been used from the time when windmills and steam engines were the dominant technologies, the current form of the PID controller emerged with the pneumatic controllers in the 1930s. The controllers have been implemented in many different ways using mechanical, pneumatic, electronic, and computer technolory. The development accelerated when the microprocessor implementations appeared in the 1980s. One reason was that the computer implementations made it possible to add features like auto-tuning and diagnostics, which are very beneficial for users. From an engineering perspective, it is particularly interesting to analyze what happened at the technology shifts, when some important features were rediscovered and others were added.
This book has grown out of more than 25 years of development of autotuners for PID controllers in close collaboration with industry. Through this work, we have been exposedto a large number of real industrial control problems. We have benefited much from participating in development, commissioning, and troubleshooting of industrial controllers. The practical work has also inspired research.
This book is the last part of a trilogy. The first book, Automatic Tfu.ningof PID Controllers, 1988, which had 6 chapters, gave a short description of our early experienceswith development of relay auto-tuners. The secondbook, PID Controllers: Theory, Design,, and Tfu.ning,1995, which has 7 chapters, grew out of the need for a broader coverageof many aspectsof PID control. In particular, it reviews many design methods for PID controllers that we investigated in connection with our work on auto-tuners.
The knowledge about PID control in 1995 still was not satisfactory for design of auto-tuners. One drawback was that the user had to provide the controller with design choices. It is particularly difficult for a user to assess if dynamics is dead-time or lag dominated. This question stimulated further research. Becauseof the drastic increase in computing power, it was also possible to use design algorithms that require more computations.
Thning and design of PID controllers have traditionally been based on special techniques. Robust control was a major development of control theory that matured in the late 1990s, resulting in powerful design methods based on robust loop shaping. This stimulated us to initiate a research program to adapt

Preface
these methods to PID control. At the same time, it seemed natural to bring PID control closer to the mainstream ideas in control. When working with industrial auto-tuners, we also saw a great need to include diagnostics in the controller, because it is no use to tune a controller if the process has severe malfunctions. The present book, Aduanced PID Control, is the result of this effort.
With a total of 13 chapters, this new book substantially expands on some of the topics covered in the previous versions and provides several new chapters that deal with controller design, feedforward design, replacement of the ZieglerNichols tuning rules, predictive control, loop and performanee asqeqqrnnnr?-i interaction. At this point in our book trilogy, we assume that the reader rb highly familiar with control theory.
Our research has given a deeper understanding of the trade-offs between load disturbance attenuation, injection of measurement noise, and set-point response.We have also been able to answer questions like: Should a controller be tuned for response to load disturbances or set points? What information is required to design a PID controller? When can derivative action give significant improvements? When are more complicated controllers justified? When is it justified to develop more accurate process models? With the knowledge developed,it is now possible to design auto-tuners that can make these assessments autonomously. In addition, we have developed new simple methods for designing PID controllers.
As an example of the insight gained we can mention that control theory tells that it is not necessary to make a compromise between tuning for load disturbance response and set-point response. Both requirements can be satisfied by using a controller with two degrees of freedom, which combines feedback and feedforward. The feedback gains should be chosen to satisfy requirements on disturbance attenuation and robustness. The desired response to set-point changes can then be obtained by proper use of feedforward. Set-point weighting is a simple form of feedforward for PID control. In some cases,it is justified to use more elaborate feedforward. For this reason, we have included a chapter on controller design and another chapter on feedforward in the new book.
The robustness analysis also shows the advantage of having low controller gain at high frequency, high frequency roll-off. This can be accomplished by flltering the process output by a second order filter. Based on the insight obtained, we recommend extended use of set-point weighting or more advanced feedforward. We also recommend that the process output is fiItered using a second order filter.
We would like to thank many people who have given knowledge, insight, and inspiration. Our interest in PID control was inspired by Axel Westrenius and Mike Somerville of Eurotherm in the early 1980s. We have learned much from working with students; particular thanks are due to Lars Gdran Elfgren (Eurotherm), Giiran Grtinhammar (LTH), Ari Ingimundarson (UPC), Oskar Nordin (Volvo), Helene Panagopoulos (Volvo), Per Persson (Volvo), Mikael Petersson (ABB), Ola Slattke (ABB), and Anders Wall6n (Ericsson Mobile Platforms), who continue to give us valuable insight even if they are now pursuing careers in industry.
We are very grateful to Sune Larsson and Lars Beath, formerly of NAF
vi

Controls, with whom we developed the first industrial relay auto-tuner. The company NAF Controls was merged several times and is now part of ABB, where we have enjoyed interactions with Gdran Arinder, Alf Isaksson, Per Erik Mod6n, Lars Pernebo, and Thomas Vonheim. We have shared the joy and challenges in moving techniques for auto-tuning and diagnostics into a wide range of industrial products. Many stimulating discussionswith our colleaguesAnton Cervin (LTH), Sebastian Dormido (UNED), Gty Dumont (UBC), Chang Chieh Hang (NUS), Karl Henrik Johansson (KTH), Birgitta Kristiansson (CTH), Bengt Lennartsson (CTH), Manfred Morari (ETH), Dale Seborg (UCSB), Sigurd Skogestad (NTNU), Bjiirn Wittenmark (LTH), and Karl-Erik Arz6n (LTH) from academia are also highly appreciated.
Our friends in industry Bill Bialkowski, Terry Blevins, Greg McMillan, and Willy Wojsznis from Emerson, Edgar Bristol, Sigifredo Niflo, and Greg Shinskey from Foxboro, Bdrje Eriksson (M-real), Krister Forsman (Perstorp), Ken Goff (Leeds and Northrup), Niklas Karlsson (Evolution Robotics), Joseph Lu (Honeywell), Tor Steinar Schei (Cybernetica), Stefan Rtrnnbiick (Optimation), have generously shared their knowledge and insight with us. We are particularly grateful to Peter Hansen, formerly of Foxboro, who read the complete manuscript and gave us very good feedback.
We are very grateful to Leif Andersson who made the layout of the text and gave much assistance with TbX, Agneta T\rszyriski who translated much of the text to I4rIbX, and Eva Dagnegfird who drew several of the figures.
Finally, we would like to thank the Swedish Research Council (VR), the Swedish Agency for Innovation Systems (VINNOVA), and the Swedish Foundation for Strategic Research (SSF) who have supported our research for many years.
Kanr, JoHaNAsrnOnt Tonn HAccluNn
Department of Automatic Control Lund Institute of Technology Box 118, SE-22I00 Lund, Sweden
k ar l- j ohan.a s tro m @ c o n tro l. Ith . s e t or e .hagglun d @ c o n tro l. l th . s e
vu

Contents

1. Introduction

1

1.1 Introductio" . : . : . : .

1

1.2 Feedback

2

1.3 Simple Forms of Feedback

3

1.4 How the PID Controller Developed

5

1.5 Technology Changes and Knowledge Thansfer

7

1.6 Outline of the Contents of the Book .

8

I.7 Summary

10

1.8 Notes and References

10

2. Process Models .

t2

2.1 Introduction .

t2

2.2 Static Models

13

2.3 Dynamic Models

T4

2.4 Feature-BasedModels

23

2.5 Tlpical Process Models

28

2.6 Models for Disturbances .

44

2.7 How to Obtain the Models

47

2.8 Model Reduction

56

2.9 Summary

61

2.t0 Notes and References

62

3. PID Control .

64

3.1 Introduction .

64

3.2 The PID Controller .

64

3.3 Filtering the Derivative

73

3.4 Set-Point Weighting

74

3.5 Integrator Windup

76

3.6 When Can PID Control Be Used?

87

3.7 Summary

92

3.8 Notes and References

93

4. Controller Design

95

4.1 Introduction .

95

4.2 A Rich Variety of Control Problems

96

4.3 Feedback Fundamentals .

96

4.4 Stability

r02

ix

Contents

4.5 4.6 4.7 4.8 4.9 4.10 A.LI

Closed-Loop Poles and Zeros The Sensitivity Functions . Robustness to ProcessVariations Quantifying the Requirements Classical Specifications Summary Notes and References

Feedforward Design 5.1 Introduction . 5.2 Improved Set-Point Response . 5.3 Set-Point Weighting 5.4 Neutral Feedforward . 5.5 Fast Set-Point Response . 5.6 DisturbanceAttenuation 5.7 Summary 5.8 Notes and References

6. PID Design 6.1 Introduction . 6.2 Ziegler-Nichols and Related Methods 6.3 Rule-Based Empirical T\rning. 6.4 Pole Placement 6.5 Lambda T\rning . 6.6 Algebraic Design 6.7 Optimization Methods 6.8 Robust Loop Shaping 6.9 Summary 6.10 Notes and References

7. A Ziegler-Nichols Replacement 7.1 Introduction . 7.2 The Test Batch 7.3 PI Control . 7.4 PID Control 7.5 Frequency ResponseMethods 7.6 PID Control Based on Second-Order Model 7.7 Comparison of the Methods . 7.8 Measurement Noise and Filtering 7.9 Detuning . 7.10 Summary 7.1I Notesand References

Predictive Control 8.1 Introduction . 8.2 The Smith Predictor 8.3 Analysisof Smith PredictorControl . 8.4 The PPI Controller . 8.5 Predictorsfor Integrating Processes 8.6 Model PredictiveControl 8.7 Summarv

109 111 118 122 128 136 137
139 139 139 I45 I46 150 154 156 157
158 158 159 169 t74 186 189 196 206 221 222
225 225 226 228 230 238 242 247 251 253 262 265
266 266 267 271 279 283 285 291

8.8 Notes and References

Automatic Thning and Adaptation 9.1 Introduction . 9.2 Process Knowledge . 9.3 Adaptive Techniques . 9.4 Model-BasedMethods 9.5 Rule-Based Methods 9.6 Supervision of Adaptive Controllers 9.7 Iterative Feedback Ttrning 9.8 Commercial Products 9.9 Summary 9.10 Notes and References

10. Loop 10.1 I0.2 10.3 10.4 10.5 10.6 10.7

and Performance Assessment Introduction . Valves Loop Assessment Performance Assessment Integrated Ttrning and Diagnosis Summary Notes and References

ll. Interaction 11.1 Introduction . LI.2 Interaction of Simple Loops . 11.3 Decoupling 1I.4 Parallel Systems 11.5 Summary 11.6 Notes and References

12. Control Paradigms 12.1 Introduction . I2.2 Bottom-Up and Top-Down Approaches 12.3 Repetitive Control 12.4 Cascade Control I2.5 Mid-Range and Split-Range Control . 12.6 Nonlinear Elements I2.7 Neural Network Control . I2.8 Fuzzy Control .

I2.9 System Structuring 12.10 Summary t2.II Notes and References

13. Implementation 13.1 Introduction . I3.2 Analog Implementations 13.3 Computer Implementations . 13.4 Velocity Algorithms 13.5 OperationalAspects 13.6 Controller Outputs . L3.7 Summarv

Contents
292
293 293 294 295 298 302 304 313 316 327 327
329 329 329 334 336 344 345 346
347 347 347 354 360 364 365
366 366 367 368 373 378 381 389 392 398 404 406
407 407 408 4r2 420 423 427 43r
xi

C'ontents
13.8 Notes and References Bibliography . Index .

. 432 . 433 . 456

xll

Introduction
1.1 Introduction
The idea of feedback is deceptively simple and, yet, extremely powerful. Feedback can reduce the effects of disturbances, it can make a system insensitive to process variations and it can make a system follow commands faithfully. Feedback has also had a profound influence on technology. Application of the feedback principle has resulted in major breakthroughs in control, communication, and instrumentation. Many patents have been granted on the idea.
The PID controller is a simple implementation of feedback. It has the ability to eliminate steady-state offsets through integral action, and it can anticipate the future through derivative action. PID controllers, or even PI controllers, are sufficient for many control problems, particularly when process dynamics are benign and the performance requirements are modest. PID controllers are found in large numbers in all industries. The controllers come in many different forms. There are stand-alone systems in boxes for one or a few loops. The PID controller is a key part of systems for motor control. The PID controller is an important ingredient of distributed systems for processcontrol. The controllers are also embedded in many special-purposecontrol systems. They are found in systems as diverse as CD and DVD players, cruise control for cars, and atomic force microscopes.In processcontrol, more than 95 percent of the control loops are of PID type; most loops are actually PI control. Many useful features of PID control have not been widely disseminated because they have been considered trade secrets. Tlzpical examples are techniques for mode switches and antiwindup.
PID control is often combined with logic, sequential functions, selectors, and simple function blocks to build the complicated automation systems used for energy production, transportation, and manufacturing. Many sophisticated control strategies, such as model predictive control, are also organized hierarchically. PID control is used at the lowest level; the multivariable controller gives the set points to the controllers at the lower level. The PID controller can thus be said to be the "bread and butter" of control engineering. It is an important component in every control engineer's toolbox.
PID controllers have survived many changes in technology, ranging from

Chapter 1. Introduction
pneumatics to microprocessorsvia electronic tubes, transistors, and integrated circuits. The microprocessorhas had a dramatic influence on the PID controller. Practically all PID controllers made today are based on microprocessors.This has created opportunities to provide additional features like automatic tuning. gain scheduling, continuous adaptation, and diagnostics. Most new PID controllers that are produced today have some capability for automatic tuning. T\rning and adaptation can be done in many different ways. The simple controller has in fact becomea test bench for many new ideas in control. There has also been a renaissance of analog implementation in micro-mechanical systems becauseanalog implementation requires less silicon surface than digital implementations. The PID controller is also implemented using field programmable gate arrays for applications where very fast control is required.
A large number of instrument and processengineers are familiar with PID control. There is a well-established practice of installing, tuning, and using the controllers. In spite of this there are substantial potentials for improving PID control. Evidence for this can be found in the control rooms of any industry. Many controllers are put in manual mode, and among those controllers that are in automatic mode, derivative action is frequently switched off for the simple reason that it is difficult to tune properly. The key reasons for poor performance are equipment problems in valves and sensors,processconstraints and bad tuning practice. The valve problems include wrong sizing, hysteresis, and stiction. The measurement problems include poor or no anti-aliasing filters; excessive filtering in "smart" sensors, excessive noise, and improper calibration. Substantial improvements can be made. The incentive for improvement is emphasized by demands for improved quality, which is manifested by standards such as ISO 9000. Knowledge and understanding are the key elements for improving performance of the control loop. Specific process knowledge is required as well as knowledge about PID control.
Based on our experience, we believe that a new era of PID control is emerging. This book will take stock of the development, assessits potential, and try to speed up the development by sharing our experiences in this exciting and useful field of automatic control. The goal of the book is to provide the technical background for understanding PID control.
1.2 Feedback
A simple feedback system is illustrated by the block diagram in Figure 1.1. The system has two major components, the process and the controller, represented as boxes with arrows denoting the causal relation between inputs and outputs. The process has one input, the manipulated variable (MV), also called the control variable. It is denoted by u. The control variable influences the process via an actuator, which typically is a valve or a motor. The process output is called processvariable (PV) and is denoted by y. This variable is measured by a sensor. In Figure 1.1 the actuator and the sensor are considered part of the block labeled "Process".The desired value of the processvariable is called the set point (SP) or the reference value. It is denoted by /rp. The control error e is the difference between the set point and the processvariable, i.e., e : lsp - !.
2

Controlle

1.3 Simple Forms of Feedback

Figure 1.1 Block diagram of a process with a feedback controller.
Assume for simplicity that the process is such that the process variable increaseswhen the manipulated variable is increased.The principle of feedback can then be expressed as follows:
Increase the manipulated variable when the error is positive, and decrease it when the error is negative.
This type of feedback is called negatiue feedback because the manipulated variable moves in opposite direction to the process variable since : lrp - !.
The PID controller is by far the most common form of feedback. This type of controller has been developedover a long period of time, and it has survived many changes in technology, from mechanical and pneumatic to electronic and computer based. Some insight into this is useful in order to understand its basic properties as is discussed in Section 1.4.
Some properties of feedback can be understood intuitively from Figure 1.1. If the feedback works well the error will be small, and ideally it will be zero. When the error is small the process variable is also close to the set point irrespective ofthe properties ofthe process.To realize feedback it is necessary to have appropriate sensors and actuators and a mechanism that performs the control actions.
Feedback has some interesting and useful properties.
r Feedback can reduce effects of disturbances
. Feedback can make a system insensitive to process variations
o Feedback can create well-defined relations between variables in a svstem

1.3 SimpleFormsof Feedback

Many of the nice properties of feedback can be accomplished with simple controllers. In this section we will discuss some simple forms of feedback, namely, on-off control, proportional control, integral control, and PID control.

On-Off Control
The feedback can be arranged in many different ways. A simple feedback mechanism can be described as

,: {:::',

ife>0 ife<0,

(1.1)

3

Chapter 1. Introduction

Figure 1.2 Controller characteristics for ideal on-off control (A), and modifications with dead zone (B) and hysteresis (C).

where e - ysp- y is the control error. This control law implies that maximum corrective action is always used. This type of feedback is called on-off control.It is simple and there are no parameters to choose.On-off control often succeeds in keeping the process variable close to the set point, but it will typically result in a system where the variables oscillate. Notice that in Equation 1.1 the control variable is not defined when the error is zero. It is common to have some modifications either by introducing hysteresis or a dead zone (see Figure 1.2).

Proportional Control

The reason why on-off control often gives rise to oscillations is that the system

overreacts since a small change in the error will make the manipulated variable

change over the full range. This effect is avoided in proportional control where

the characteristic of the controller is proportional to the control error for small

errors. This can be achieved by making the control signal proportional to the

error

u-K(Y,p-Y):Ke,

(1.2)

where K is the controller gain.

Integral Control
Proportional control has the drawback that the processvariable often deviates from the set point. This can be avoided by making the control action proportional to the integral of the error

t

u(t)-ki

I
I e(r)dr,

0

(1.3)

where ft; is the integral gain. This strategy is called integral control. Integral control has an amazing property. Assume that there is a steady state with constant error e6 and constant control signal us. It follows from the above equation that
us -- kieot.
Since u6 is a constant it follows that eerrrust be zero. We thus find that if there is a steady state and a controller has integral action the steady-state error is

4

1.4 How the PID Controller Deueloped

Present

Past

I

<--|----.--->

Future

t*7,1
Figure 1.3 A PID controller takes control action based on past, present, and future control errors.

alwavs zero.It follows that this is also true for the PI controller

t

u(t) :

I
Ke(t)*lei I

e(r)dr.

,J

0

This is one of the reasons why PI controllers are so common.

(1.4)

PID Control
An additional refinement is to provide the controller with an anticipative ability by using a prediction of the output based on linear extrapolation. See Figure 1.3. This can be expressed mathematically as

u ( t )-

x(,Al

+

1i
T, .l

e(r)dc-trary)

(1.5)

0

The control action is thus a sum of three terms representing the past by the integral of the error (the I-term), the present (the P-term) and the future by a linear extrapolation of the error (the D-term). The term e I Taff is a linear prediction of the error Ta time units in the future. The parameters of the controller are called: proportional gain K, integral time Ti, and derivative time Ta.
It has been found empirically that the PID controller is capable of solving a wide range of control problems. There are more complicated controllers that differ from the PID controller by using more sophisticated methods for prediction.

1.4 Howthe PIDControlleDr eveloped
The PID controller has developed over a period of time that stretches over at least 250 years. It is useful to have some perspective of this development in order to understand many of the issues. The technology used to implement

Chapter 1. Introduction
the controllers has naturally changed significantly over the years. The first controllers were mechanical devices (centrifugal governors) used to control windmills and steam engines. Sensing of angular velocity was combined with actuation of valves. A great deal of clevernesswas involved in devising integral action.
A significant change occurred in connection with the development of industrial processcontrol. The functions of sensing, control, and actuation were then separated and special devices that performed the control actions represented by Equation 1.5 were built. An interesting feature was that signal transmission and computing were done pneumatically. A major advance occurred when the tubes used to transmit the pressure and the pressure levels were standardized to 3-15 PSI. This made it possible to combine sensors, controllers, and actuators from different suppliers. It also made it possible to concentrate controllers in separate control rooms that were located far away from sensors and actuators. Much cleverness was again used to obtain the controllers. The use of feedback in the controllers themselves was a major improvement. In this way it was possible to obtain linear action out of components that had strongly nonlinear characteristics.
Starting in 1950s,electronic versions of the PID controller becameavailable. The control actions represented by Equation 1.5 were then obtained by a simple analog computer based on operational amplifiers. The signal transmission was also standardized as current signals in the range 4-20 mA. To represent zero by a nonzero current was useful for diagnostics.
Yet another advance occurred when digital computers were used to implement controllers. Strongly centralized systems were first used when computer control emerged, because digital computing was only cost effective in large systems. With the advent of microprocessors in the 1970s even simple controllers were implemented using computers. When a digital computer is used it is also possible to add many functions such as automatic tuning, adaptation, and diagnostics. This is an area of very active development.
Today we are experiencing other shifts in technology. Analog implementations are reappearing in micro-mechanical electrical systems (MEMS), and digital controllers are also implemented using field programmable gate arrays (FPGA), which admit very short sampling periods. The FPGAs differ significantly from digital computers because they are highly parallel.
Today we find PID controllers in many forms. There are dedicated controllers that can control one or a few loops. PID functions are found in Programmable Logic Controllers that were originally designed to replace relays. There are systems that contain many PID controllers implemented in computers ranging from small systems for a few dozen loops to large distributed systems for process control. PID controllers are commonly used in dedicated systems for motion control. There are also a whole range of special controllers such as autopilots and control systems for CD and DVD players and optical memories that are based on PID control.

1.5 Technology Changes arud Knowledge Tlansfer
1.5 TechnologyGhangesand KnowledgeTransfer
The PID controller is an interesting case study for management of technology, becauseit has a long history and it has experienced many technology changes. Since we have had personal experiences of several technology shifts, we will present some personal reflections where we discuss creation and destruction of knowledge and the role of key people and documentation.
Technology transfers are often abrupt and unplanned. The reason why a company decides to change technology may be drastic drops in hardware costs or pressure from competitors and customers. A switch in technolory often means that R&D staff has to be replaced by new people that are familiar with the new technology, but often not with the old one. This means that there is a high risk that information is lost during the transition. Since the technology transfers often have to be done fast, there is also a high risk that the potential of the new technology is not utilized.
Early temperature controllers were of the on-off type. The on-off controllers are simple and cheap, but there are unavoidable oscillations. The amplitude of the oscillations can be kept at reasonable levels, since the dynamics of many thermal systems is lag dominated. When electronics became cost effective, there was a transition from on-off to continuous PID control. The development of the analog PID controller is well documented in publically available material from Eurotherm, which was started by faculty from the University of Manchester.The controllers were developedbased on solid knowledge of modeling and control. Theory helps, because many applications of temperature admit high gains and derivative action can be very beneficial. T\rning rules were also provided and protection for windup was developed under the name of integrator desaturation and crossed time-constants. The result of the development was a drastic improvement of the performance of temperature controllers. It is interesting to observe that it took a long time before the interesting and important phenomena of integrator windup received any attention in academia.
When computer based processcontrol emerged in the early 1960s,the focus was initially on higher-level control functions. Analog PID controllers were used at the base level and the computer supplied set point to the controllers. As the systems developed,the attention focusedagain on PID control where many PID loops were implemented in one computer, so called Direct Digital Control. The technical development focused on discretization of the PID algorithm, one reason being that computing resources was a bottleneck. Little attention was given to integrator windup, and some attention was given to filtering of sensor signals.
The emergence of the microprocessor made digital computing cheaply available in small quanta, a development which had a major impact on the PID controller. It resulted in small single loop controllers, controllers for a few loops, and large distributed systems. The development was slow for two reasons. Many new persons without previous experience of analog control entered the arena, and many old-timers were unwilling to learn the new technology. Important aspects such as integrator windup and filtering were not documented in a way that was easily accessible.Therefore, it took some time before the appropriate knowledge and experience was recaptured. There was also a tendency to

Chapter 1. Introduction
simply implement old ideas in new technology without considering the opportunities offered by the new technology. Gradually the potentials of the digrtal computer were exploited by incorporating features like, auto-tuning, adaptation, and diagnostics into the systems.
When distributed control system (DCS) systems replaced the analog systems, the distributed architecture was retained. Analog controllers and function modules were represented as blocks in the DCS programs. This was probably a good idea, but the opportunities given by the fact that all signals were available in one computer was not utilized. It took over a decade before DCS systems that handle anti-windup above the loop level were presented.
A couple of conclusions that can be drawn are that documentation, and open-minded persons who can bridge the gap between different technologies, are important. When new technologies are available it is also useful to stop and think to find out how the new technolory can be exploited rather than to quickly implement old ideas in the new technology. It is also important to filter out the essenceof the old systems so that good features are not lost. Finally, it is important to document ideas, write books, and ensure that information is not only transferred from human to human, but widespread.
1.6 Outlineof the Contentsof the Book
The reader is advised to look at the table of contents to see the overall structure of the book. Process dynamics is a key for understanding any control problem. Chapter 2 presents concepts that are useful for describing the behavior of processes.Static models are mentioned briefly, but the main focus of the chapter is on process dynamics. Representations in terms of time- and frequency responsesare given. These dual views are very useful to gain a good understanding of dynamics. The notions of step responses and transfer functions are used throughout the book. A number of typical models that are used for PID control are discussedin detail. Models for disturbances are also treated as well as techniques for experimental determination of the models.
An in-depth presentation of the PID controller is given in Chapter 3. This includes principles as well as many implementation details, such filtering to provide high-frequency roll-off, anti-windup, improvement of set-point response, etc. The PID controller can be structured in different ways. Commonly used forms are the series and the parallel forms. The differences between these and the controller parameters used in the different structures are treated in detail. The limitations of PID control are also described. Tlpical cases where more complex controllers are worthwhile are systems that have long dead time and oscillatory systems. Extensions of PID control to deal with such systems are discussed briefly.
Chapter 4 treats controller design in general. There is a rich variety of control problems with very diverse goals. The chapter gives an overview of ideas and concepts that are relevant for PID control. It is attempted to bring design of PID controllers into the mainstream of control design. Topics such as fundamental limitations, stability, robustness, and specifications are treated.
Feedforward control, a simple and powerful technique that complements
8

1.6 Outline of the Corutentsof the Book
feedback, is treated in Chapter 5. A systematic design of feedforward control to improve set-point responses is given as well as a discussion of design of model-following systems. The special case of set-point weighting is discussed in detail, and methods for determining the set-point weights are provided. The chapter also shows how feedforward can be used to to reduce the effect of disturbances that can be measured.
Chapter 6 describes methods for the design of PID controllers. Many different methods for tuning PID controllers that have been developed over the years are presented. Their properties are discussed thoroughly. It has been attempted to strike a balance by providing both an historical perspective and to present powerful methods.
A reasonable design method should consider load disturbances, model uncertainty, measurement noise, and set-point response.A drawback of many of the traditional tuning rules for PID control is that such rules do not consider all these aspects in a balanced way. New tuning techniques that do consider all these criteria are presented in Chapter 7.
Chapter 8 treats model predictive controllers. The Smith predictor, which is a special case,is first presented and analysed, and modifications to treat integrating processesare provided. Then other types of model predictive controllers are presented, such as the MPC controller, the Dahlin-Higham controller, dynamic matrix control, and minimum variance control.
In Chapter 9 we discuss some techniques for adaptation and automatic tuning of PID controllers. This includes methods based on parametric models and non-parametric techniques. Supervision of adaptive controllers and iterative feedback tuning are also discussed. A number of commercial controllers are described to illustrate the different techniques.
Chapter 10 treats methods for commissioning, supervision and diagnosis of control loops. Loop assessmentprocedures are used to investigate properties of the control loop, e.g. signal levels, noise levels, nonlinearities, and equipment conditions. Performance assessment procedures are used to supervise the control loops during operation, and ensure that they meet the specifications.
The PID controller is typically used as a single-loop controller. In practice, there are often interactions between the loops. Some key issues about interacting loops that are of particular relevance for PID control are discussed in Chapter 11. In particular it is shown that controller parameters in one loop may have significant input on dynamics of other loops. Bristol's relative gain array, which is a simple way to charactertze the interactions, is also introduced. The problem of pairing inputs and outputs is discussed, and a design method based on decoupling, which is a natural extension of the tuning methods for single input single output systems, is presented.
In Chapter 12 it is shown how complex control problems can be solved by combining simple controllers in different ways. The control paradigms of repetitive control, cascadecontrol, mid-range and split-range control, ratio control, and control with selectors are discussed. Use of currently popular techniques such as neural networks and fiizzy control are also covered briefly.
Chapter 13 presents implementation issues related to PID control. A short overview of the early analog pneumatic and electronic implementations are first given. A detailed presentation of computer implementation aspects such

Chapter 1. Introduction
as sampling, pre-filtering, and discretization of the PID algorithm is then given. Operational aspects such as bumpless transfers are presented, and the chapter ends with a discussion about the different controller outputs that have to be used depending on which actuating device is used.
1.7 Summary
In this section we have given a brief description of the concept of feedback. The application of feedback has had very useful and sometimes revolutionary impact. Some of the useful properties of feedback, its ability to reduce disturbances, insensitivity to process variations, linearity between set point and process variable, have been discussed. We have also briefly described some simple forms of feedback such as on-off control and PID. The development of PID controllers has been discussed brieflv. and the contents of the book have finally been outlined.
1.8 Notesand References
PID controllers were used extensively in the early development of control from the 1870s through 1920. The modern form of the PID controller emerged in the development of process control in the 1930s and 1940s, as discussed in [Bennett, 1979] and [Bennett, 1993]. The PID controller is still the standard tool for solving industrial control problems. In a detailed study of the state of the art in industrial process control by the Electric Measuring Instrument Manufacturer in Japan from 1989 it is found that more than than 90 percent of the control loops were of the PID type; see [Yamamoto and Hashimoto, 1991]. The paper [Desbourough and Miller, 20021 surveyed the U.S. industry. It is found that there are more than 8 million facilities in the petrochemical, pulp and paper, power, and metals industries. Each facility has between 500 and 5000 regulatory control loops, 97 percent of them are of the PID type. The PID controllers are manufactured in large quantities in other industries too. Optical memories for CD and DVD contain three PID loops for control of rotation speed, focus, and track following. About 140 million units were manufactured in 2002; see [Akkermans and Stan, 2002\. In addition, there is a large number of PID controllers for motor drives and positioning systems. It is therefore safe to say that the PID controller is one of the most common tools for control.
PID control is discussedin most textbooks on processcontrol such as [Luyben, 1990; Shinskey, 1994; Marlin, 2000; Bequette, 2003; Seborg et al., 20041, and there are also books that focus on PID control [McMillan, 1983; Corripio, 1990; Suda et al., 1992; Wang and Cluett, 2000; Quevedo and Escobet, 2000; Wang et a1.,2000;O'Dwyer, 2003; Michael and Moradi, 2005].
The theory of PID controllers was for a long time based on special techniques. Lately there have been efforts to bring PID control into the the mainstream of control theory. A notable effort was made in the year 2000 when the International Federation of Automatic Control (IFAC) arranged a workshop on
10

1.8 Notes and References the past, present, and future of PID control; see [Quevedo and Escobet, 2000]. A collection of papers from this workshop was also published as a special issue of Control Engineering Practice. The papers [Bennett, 2000] and [Astrtim and Htigglund, 2001] give a perspective on the development of PID control.
Because of the large number of PID controllers and their widespread use there are still significant benefits in improving the practice of PID control. Such an improvement requires attention to the complete control loop and not just the controller itself as is demonstrated in the paper [Bialkowski, 19941 which describes audits of paper mills in Canada. A typical mill has more than 2000 control loops, 97 percent of the loops are based on PI control. It was found that only 20 percent of the control loops worked well and decreased process variability. The reasons why performance is poor are bad tuning (30 percent) and valve problems (30 percent). The remaining 20 percent of the controllers functioned poorly for a variety of reasons such as: sensor problems, bad choice of sampling rates, and poor or non-existing anti-aliasing filters. Similar observations are given in [Ender, 1993], where it is claimed that 30 percent of installed processcontrollers operate in manual mode, that 20 percent of the loops use default parameters set by the controller manufacturer (socalled "factory tuning"), and that 30 percent of the loops function poorly because of equipment problems in valves and sensors.
11

ProcessModels
2.1 Introduction
Mathematical models are commonly used to describe the behavior of processes. Models give a unified way to treat systems of widely different types, and they make it possible to introduce a number of useful concepts. The models are also essential for simulation and control design. In this chapter we will review some of the models that are commonly used for PID control. The models try to capture some aspects of the process that are relevant for control. Many different types of models are used.
The steady-state behavior of a process can be captured by a function that tells the steady-state value of the process variable for given values of the manipulated variable. such models are discussed in Section 2.2.
To control a system it is necessary to describe process dynamics. For the purpose of control it is often sufficient to describe small deviations from an equilibrium. In this case the behavior can be modeled as a linear dynamical system. This is a very rich field with many useful concepts and tools, which form the core of control theory. Different ways to describe process dynamics are discussed in Section 2.3. The ideas of transient response and frequency response are introduced as well as the important concepts of step response, impulse responses,and transfer functions.
Special techniques for modeling process dynamics have traditionally been used in PID control. The idea is to characterize process dynamics by a few features. This is discussed in Section 2.4, where features such as average residence time, apparent time delay, apparent time constant, normalized delay, ultimate gain, ultimate frequency, and gain ratio are introduced.
In Section2.S we introduce some particular models that are widely used for PID control' These models are introduced in terms of their transfer functions. The important concepts of normalization are also introduced in that section, as well as nonlinearities. The examples introduced in Section2.S will be used extensively in the book.
Disturbances are an important aspect of a control problem. In Section2.6 we describe some models that are used to describe disturbances. Section 2.2 describes simple methods for obtaining the models, and Section 2.8 describes
12

2.2 Static Models
Input u
Figure 2.1 Static process characteristic, which shows process output y as a function of process input u under steady-state conditions.
some techniques used to simplify a complicated model. The chapter is summarized in Section 2.9, and references are given in Section 2.10.
2.2 StaticModels
It is natural to start by describing the stationary behavior of the process. This can be done by a curve that shows the steady-state value of the processvariable y (the output) for different values of the manipulated variable u (the input); seeFigure 2.1. This curve is called a static model or a static processcharacteristic. All processinvestigations should start with a determination of the static processmodel. It can be used to determine the range of control signals required to change the process output over the desired range, to size actuators, and to select sensor resolution. The slope of the curve in Figure 2.1 tells how much the process variable changes for small changes in the manipulated variable. This slope is called the static gain of the process.Large variations in the gain indicate that the control problem may be difficult.
The static model can be obtained experimentally in several ways. A natural way is to keep the input aL a constant value and measure the steady-state output. This gives one point on the process characteristics. The experiment is repeated to cover the full range of inputs.
An alternative procedure is to make a closed-loop experiment where the output of the system is kept constant by feedback and the steady-state value of the input is measured.
The experiments required to determine the static process model often give a good intuitive feel for how easy it is to control the process, and if there are many disturbances. Data for steady-state models can also be obtained from on-line measurements.
Sometimes process operations do not permit the experiments to be done as described above. Small perturbations are normally permitted, but it may not be possibleto move the processover the full operating range. In such a casethe experiment must be done over a long period of time. It is possible to provide a control system with facilities to automatically determine the static process model during operation; see Chapter 10.

Chapter 2. Process Models a)
0.8 0.4
0 e) 0.8 0.4
0
Figure 2.2 Open-loop step responses.
2.3 DynamicModels
A static process model like the one discussed in the previous section tells the steady-state relation between the input and the output signal. A dynamic model should give the relation between the input and the output signal during transients. It is naturally much more difficult to capture dynamic behavior. This is, however, essential when dealing with control problems.
Qualitative Characterization of Process Dynamics Before attempting to model a system it is often useful to give a crude characterization of its dynamical behavior. To describe the dynamical behavior we will simply show the response of the system to a step change in the manipulated variable. This is called the step response of the system or the process reaction curve.
One distinction is between stable and unstable systems. The step response of a stable system goes to a constant value. An unstable system will not reach a steady state after a step change. Systems with integrating action are a typical example of an unstable system. In early process control literature, stable systems were called self-regulating systems.
Many properties of a system can be obtained directly from the step response. Figure 2.2 shows step responsesthat are typically encountered in processcontrol.
In Figure 2.2a, the process output is monotonically changed to a new stationary value. This is the most common type of step response encountered in
t4

2.3 Dynamic Models
process control. In Figure 2.2b, the process output oscillates around its final stationary value. This type of processis uncommon in processcontrol. One case where it occurs is in concentration control of recirculation fluids. In mechanical designs, however, oscillating processesare common where elastic materials are used, e.9., weak axles in servos, spring constructions, etc. The systems in Figures 2.2a and 2.2b are stable, whereas the system shown in Figures 2.2c and 2.2d are unstable. The system in Figure 2.2c is an integrating process.Examples of integrating processesare level control, pressure control in a closed vessel, concentration control in batches, and temperature control in well isolated chambers. The common factor in all these processesis that some kind of storage occurs in them. In level, pressure, and concentration control, storage of mass occurs, while in the case of temperature control there is a storage of energy. The system in Figure 2.2e has a long time delay. The time delay occurs when there are transportation delays in the process.The system in Figure 2.2f is a non-minimum phase system. Notice that the output initially moves in the wrong direction. The water level in boilers often reacts like this after a step change in feed water flow.
Linear Time-lnvariant Systems
There is a restricted class of models, called linear time-invariant systems, that can often be used. Such models describe the behavior of systems for small deviations from an equilibrium. Time-invariant means that the behavior of the system does not change with time. Linearity means that the superposition principle holds. This means that if the input u1 gives the output y1 and the input u2 gives the output y2 it then follows that the input cr.u1I bu2 gives the output ay1* by2.
A nice property of linear time-invariant systems is that their response to an arbitrary input can be completely characterized in terms of the response to a simple signal. Many different signals can be used to characterize a system. Broadly speaking, we can differentiate between transient and frequency responses.
In a control system we typically focus on only two signals, the control signal and the measured variable. Process dynamics deals with the relation between those signals. This means that it includes dynamics in actuators, process,and sensors.The dynamics are often dominated by processdynamics. In some cases it is, however, the sensors and actuators that give the major contribution to the dynamics. For example, it is very common that there are long filter-time constants in temperature sensors. There may also be measurement noise and other imperfections. There may also be significant dynamics in the actuators. To do a good job of control, it is necessary to be aware of the physical origin of the process dynamics to judge if a good response in the measured variable actually corresponds to a good response in the physical process variable. Even if the attention is focused on the measured variable it is useful to always keep in mind that the processvariable is the signal that really matters.
Physical Modeling-Differential Equations
A traditional way to obtain a process model is to use basic physical laws such as mass, momentum and energ'y balances. Such descriptions typically lead to
15

Cltapter 2. Process Models

Figure 2.3 Schematic diagram of a system consisting of two tanks.

a mathematical model in terms of a differential equation. We illustrate this with two examples.
Exavpln 2.l-SrmRED TANK Consider an ideal stirred tank reactor. Let the reactor volume be V and the volume flow rate through the reactor be q. The manipulated variable is the concentration u of the inflow, and the process variable y is the concentration in the reactor. A mass balance for the reactor gives

,dy,\ q\u- y).

The parameter T - V lq, which has dimension time, is the average residence time of particles that enter the reactor. It is also called the time constant of

the system.

tr

The system in Example 2.1 is of flrst order becauseonly one variable is required to account for the storage in the tank. This is possible because the tank is well stirred so the concentration is constant throughout the tank. In more complicated cases many variables are required to account for the storage of mass, energ'y,and momentum. This is illustrated in the next example.

Exavplp 2.2-CoUPLED TeNxs
Consider the system shown in Figure 2.3, which is composedof two well-stirred
tanks. Assume that each tank has volume V, that the inflow and the outflow are q, and that the reflux flow is q". Furthermore, let the input be the concentration of the inflow u : cin, and let the output be the concentration of the outflow, ! : cout.When the tanks are well stirred the mass balance can be characterized by the concentrations in the tanks. The mass balances for the tanks become

v, , d c l : -(q * q , )cr * q,cz-l qu dt
.v, d c z dt:(q+e")c1-@+q,)cz y:c2.

The model in the example consists of two differential equations of first order. There are two differential equations becausethe system is completely described by mass balances and the storage of mass can be captured by two variables. Similar descriptions are obtained for more complicated systems, but the number of equations increases with the complexity of the system. The differential equation may also be nonlinear if there are nonlinear transport phenomena.
16

2.3 Dynamic Models

The model in Example 2.2 consists of a system of first-order differential equations. If we are only interested in the relations between the input u and the output y a linear model can also be described by a differential equation of higher order, i.e.,

dy
jv

+

"

t

dn-l
it"i

y

+ " ' * a n J:

b- 'dAuu- tiu

+ "' * b'u'

(2.1)

The number n is equal to the number of variables required to account for the storage. This is one of the standard models used in automatic control.
The differential equation (2.I) is characterized by two polynomials

o(s) - s' +d1s'-1 +' .. * dn b(s) :brsn-l +"'lbn,

(2.2)

where the polynomial o(s) is called the characteristic polynomial. The zeros of the polynomial o(s) are called the poles of the system, and the zeros of the polynomial b(s) are called the zeros of the system.
The differential equation (2.I) has a solution of the form

y ( t ) : L n C u ( t ) r o+uf', o Q- r)u(r)dr,

(2.3)

where dp vte the poles of the system and Cp(r) are polynomials (constants if the poles are distinct). The first term of the above equation depends on the initial conditions and the second on the input. The function g has the same form as the first term of the right-hand side of (2.3). The poles thus give useful qualitative insight into the properties of the system.
In more complicated situations it may be more difficult to account for the storage of mass momentum and enerry. We illustrate with a simple example.

Exenapln 2.3-Trun Dnlav Consider a system where mass is transported on a conveyor belt. Let the input u(t) be the mass flow rate onto the belt, and let the output y(t) be the mass flow out of the belt. The input-output relation for the system is then

v(t):u(t-L),

(2.4)

where Z is the time it takes for a particle to pass the belt. To account for the storage of mass on the belt it is necessary to specify the mass distribution on the belt. The output is thus simply the delayed input. This system is therefore called a time delay or a transport delay. A time delay is also called a dead time. The model (2.a) also describes the concentration in a pipe with no mixing. I

Other physical systems such as heat conduction and diffusion give rise to models in terms of partial differential equations; examples of such models are given in Section 2.5.
An attractive feature of physical models is that the parameters of the equation can be related to physical quantities such as volumes, flows, and material constants. Complicated models can also be constructed by dividing a system into subsystems, deriving simple models for each subsystem and combining the simple models.

77

Chapter 2. Process Models
1
s 0.5
0
Figure 2.4 The lower curve shows an input signal in the form of a step, and the upper curve shows the response of the system to the step.
State Models The notion of state is an important concept in system dynamics. The state is a collection of variables that summarize the past behavior of the system and admits a prediction of the future under the assumption that future inputs are known. For the system in Example 2.2, which consists of two tanks, the state is simply the concentrations c1 and c2in the tanks. In general, the state is the variables required to describe storage of mass, momentum, and energy of a system. Sometimes it is necessary to use infinitely many variables to describe storage in a system. For the system in Example 2.3 the state at time f is the past inputs over an interval of length L, i.e., {u(t),t - L < t < t} .
TransienRt esponses
An alternative to describing models by differential equations is to focus directly on the input-output behavior. Dynamics can in principle be described by a large table of input signals and corresponding output signals. This approach, which is called transient response, is perhaps the most intuitive way to charactenze processdynamics. A very nice property of linear time-invariant systems is that the table can be described by one pair of signals. The particular input signal is often chosen so that it is easy to generate experimentally. Tlpical examples are steps, pulses, and impulses. Recall that typical step responseswere shown in Figure 2.2.
Because of the superposition principle the amplitude of the signals can be normalized. For simplicity it is common practice to normalize by dividing the output with the magnitude of the input step. It is also common practice to translate the curve so that the step starts at time f - 0. It is then sufficient to show the output only. This practice will be followed in this book. For example, in Figure 2.4 the output should be divided by 0.8 and translated one unit to the left. In early process control literature the step response was also called the reaction curve.
18

2.3 Dynamic Models

The output generated by an arbitrary input can be computed from the step response.Let h(t)be the responseto a unit step. The output y(t) to an arbitrary input signal z(t) is then given by

y(t-) l, *@ry dt- Iou@n-Qr)d,r, (2.5)
where we have introduced g(r) as the derivative of the step response h(r). The function g(t) is called the impulse response of the system because it can be interpreted as the response of the system to a very short impulse with unit area.

TheTransfeFr unction
The formula (2.5) can be simplified significantly by introducing Laplace transforms. The Laplace transform F(s) of a time function f (t) is defined as

F(s-) Io*,-"r(t)dt.

(2.6)

Assuming that the system is initially at rest, t.e., y(t) - 0 and u(t) - 0 for t < A, and using Laplace transforms, Equation 2.5 can be written as

Y ( s )- c ( r ) U ( r ) ,

(2.7)

where U(r), Y(r), and G(s) are the Laplace transforms of u(t), y(t), and g(t), respectively.The function G(r) is called the transfer function of the system. The transfer function G(r) is also the Laplace transform of the impulse response
s(t).
The formula given by (2.7) has a strong intuitive interpretation. The Laplace transform of the output is simply the Laplace transform of the input multiplied by the transfer function of the system. This is one of the main reasons for using Laplace transforms when analyzing linear systems. Analysis of linear systems is reduced to pure algebra. A nice feature is that processes,controllers, and signals are described in the same way.
Equation 2.7 can also be used to define the transfer function as the ratio of the Laplace transforms of the input and the output of a system. As illustrations we will give the transfer function for some systems.

ExaMpLs 2.4-SrmRED TANK The stirred tank in Example 2.1 has the transfer function

G ( s )- s V l q + r s ? + 1 '

(2.8)

where the quantity T : V f q, which has dimension time, is called the time

constant of the svstem.

T

19

Chapter 2. Process Models

Exaupln 2.5-TruE DELAY
Consider the system describing a transport delay in Example 2.3. Assuming thatu(t) -0for -L< t<0wefind

Y(s) -

rx | n-" y(t)d,t:

f I

n-"u(t - L)dt:

s - s LU ( r ) .

JO

JO

The transfer function of a transport delay is thus

G(t) : s-sL.

(2.9)

,

Equation 2.7 implies that it is easy to obtain the transfer function of interconnected system. This is illustrated by the following example.

Exeupm 2.6-Fnsr-ORDER SvsrpnnwrrH Twn Dnlev (FOTD)

Consider a system that is a stirred tank that is fed by a pipe with no mixing.

Multiplying the transfer function of the tank in Example 2.4 with the transfer

function of a time delay in Example 2.5 we find that the system has the transfer

function

c(t) :

1
#r"

e-'1.

(2.10)

This model is very common in process control. It is called a first-order system

with a time delay or a FOTD system for short.

I

Another nice property of Laplace transforms is that the transform of a derivative is given by the formula

r.x
I

,-nf'(t)dt:tl

roc
e - ' t S Q ) d t - f ( 0:)s F ( s ) - / ( 0 )

Jo

Jo

If the initial value of the time function is zero it follows that differentiation of a time function corresponds to multiplication of the Laplace transform with s. Similarly, it can be shown that integration of a signal corresponds to dividing the Laplace transform with s. This gives a very simple rule for manipulating differential equations where initial values are zero. Simply replace functions with their corresponding Laplace transforms and derivatives by s. The relation between signals is then obtained by simple algebra.

Exeupln 2.7-GnNERAL DmrnRpNTrAL EeuATroN Consider the system described by the differential equation (2.1).Assuming that the system is initially at rest and taking Laplace transforms of (2.1) we get
( r " + d r s n - r + . . . * a , ) Y ( s ) - ( b 1 s " - r* b 2 s " - 2+ . . . + b , ) I / ( r ) ,

where Y(s) is the Laplace transform of the output, and t/(r) the Laplace transform of the input. The transfer function of the system is the ratio of the Laplace transforms of output and input, i.e.,

^, \
(ltSl :

Y(t) -i
;u- ( s )

btsn I 1-b2s"-2+...+b, s n+ Q , 1 5 n - r 1 . . . * A n

(2.11)
r

20

0.2 0.1
\,

2.3 Dynamic Models

0n

5

10

15

Figure 2.5 Illustration of frequency response. The input signal u is a sinusoid, and the output signal y becomes sinusoidal after a transient. The dashed line shows the steadystate response to the sinusoidal input.

Exaupln 2.8-PID CoNrRollnR

The PID controller given by Equation 1.5 is a dynamical system with the trans-

fer function

c(s:f)fi:r< ('*# . ,r,)

Q.r2)

f,

The last two examples illustrate that transfer functions can be obtained from differential equations by inspection. The rule is simply to replace derivatives by t, integrals by If s, and time functions by their transforms. The transfer functions are then obtained as the ratio between signals.

FrequencyResponse
Another way to characterize the dynamics of a linear time-invariant system is to investigate the response to sinusoidal input signals, an idea that goes back to the French mathematician Fourier. Frequency response is less intuitive than transient response, but it gives other insights.
Consider a stable linear system. If the input signal to the system is a sinusoid, then the output signal will also be a sinusoid after a transient (see Figure 2.5). The output will have the same frequency as the input signal. Only the phase and the amplitude are different. If the input signal is u(t) : u0 sinrot the steady-state output is

y(t) : a(at)ugsin (art+ rp(ro)).

The steady-state relations between the output and a sinusoidal input with frequency a car' be described by two numbers: the amplitude ratio and the phase. The amplitude ratio is the output amplitude divided by the input amplitude,

21

Chapter 2. Process Models

G(iro)

Re G(lar)

Figure 2.6 The Nyquist curve of a system is the locus of the complex number G(iro) as al goes from 0 to oo.

and the phase is the phase shift of the output in relation to the input. The func-

tions a(a) and g(a) gr,r" amplitude ratio and phase for all frequencies. The

functions a(a) and g(rtt) are related to the transfer function in the following

way.

G(iat):s(o)sia@)'

(2'13)

The values of the transfer function for imaginary arguments thus describe the steady-state transmission of sinusoidal signals, and G(iat) is called the frequency response function of the system.

The Nyquist Plot
There are very useful graphical illustrations of the frequency response. The complex number G(ia) can be represented by a vector with length a(at) that forms angle q(aD with the real axis (see Figure 2.6). When the frequency goes from 0 to oo, the vector describes a curve in the plane, which is called the frequency curve or the Nyquist curve.
The Nyquist curve gives a complete description of the system. It can be determined experimentally by sending sinusoids of different frequencies through the system. This may, however, be time consuming. It can also be determined from other signals.

The Bode Plot
The Bode plot is another graphical representation of the transfer function. The Bode plot of a transfer function consists of two curves, the gain curve and the phase curve; see Figure 2.7. The amplitude or gain curve shows the amplitude ratio a(o) - lG(irlo)l as a function of the frequency a. The phase curve shows the phase g@) - arg G(ia) as a function of the frequency ar. The frequency is given in logarithmic scales on both curves, either in rad/s or Hz. The gain is also given in logarithmic scales.The angle is given in linear scales.The Bode

22

2.4 Feature-BasedModels

102
' Ai o
r\

1oo 1o-'
90

1oo

101

q)
a 66n

f I I

-90

1o-'

1oo

10t

Frequency

Figure 2.7 Bode plot of an ideal PID controller (solid lines) and a controller with a filter
(dashed). The upper curve shows the gain curve lc(ia)1, and the lower diagram shows the phase curve argG(ia). The controller has high gain for low frequencies, and the phase is -90'. The ideal controller also has high gain at high frequencies and the phase is 90".
The controller with a filter has constant gain for high frequencies.

plot gives a good overview of the properties of a system over a wide frequency range. Because of the scales the gain curve also has linear asymptotes.

2.4 Feature-BaseMdodels

Sometimes it is desirable to have a crude characterization of a process based on only a few features. The features should be chosen so that they are meaningful with good physical interpretation. They should also be easy to determine experimentally. This way of describing dynamics has a long tradition in process control. It is useful to start with a crude classification of step responses as illustrated in Figure 2.2.

ProcessGain
For stable processesthe steady-state behavior can be described by one parameter, the processgain Ko. For processeswith integration a constant input gives in steady state an output that changes with a constant rate. This behavior can be captured by the rate constant Kr.

Average Residence Time
It is also useful to find a few parameters to characterize processdynamics. The time behavior of stable system with positive impulse response can be characterized with the parameter

mr a r :

.[{ ts7)at jf s@dt

(2.r4)

23

Chapter 2. Process Models

Figure 2.8 Illustrates the area method for determining the average residence time.

which is called the average residence time. The average residence time is a

rough measure of how long it takes for the input to have a significant influence

on the output. Notice that the probability density if s(r) > 0.

function

g(t) I

I

g(t)dt

can be interpreted

as a

The average residence time can be calculated from the step response in the

following way

To,

Kp

Kp

(2.r5)

where h(t) is the step response and Ko: G(0) is the static processgain. Notice that Kr: h(oo) and that 46 is the shaded area in Figure 2.8.

Average Residence Time and Transfer Functions The average residence time can be computed very conveniently from the transfer function. Since the transfer function is the Laplace transform of the impulse response we have
G(s ) - J[o e-.' ts(t)dt. Differentiation of this expression with respect to s gives

G'(r) -- [" e-,tts(t)dt.
JO
Setting s : 0 in these expressions it then follows from the definition of the average residence time (2.Ia) that

rrne r : - CG( 0' ()0 )

(2.16)

This formula will now be illustrated by a few examples.

24

2.4 Feature-Based Models

Exaupln 2.9-AvpRAGE Rpsnpucp Tnan FoR STTRREDTANK The transfer function for the stirred tank in Example 2.4 is

G (\s/) 1 + s Z

We have

G ' (\ s/) :

-

T

(1 +sf;z'

and it follows from (2.rG) that the average residence time is

Tor:f:Y' q

The average residence time is thus the ratio of the volume and the flow through

the tank.

-

Exeupln 2.1O-AvnRAGE Rpsmpucn Trup poR Tnap Dnlay The transfer function for the time delay in Example 2.b is

G(") : e-'L.

We have G'(") - -Le-'L,
and it follows from (2.rG) that the average residence time is

To, : L.

The average residence time is thus equal to the time delay.

!

Exalrpln 2.11-AvnRAGE RnsnnNcn TrnappoR cascADED sysrpnrs A system that is the cascade combination of two stable linear systems with transfer functions Gr(r) and G2(s) has the transfer function
c(') - Gr(s)G2(s).

Differentiation gives

G'(r) - G'l(r)Gr(r) + Gr(r)Gr(r).

It follows from (2.1G) that the average residence time is

r-u^ -'

__

ci

(

0 ) c 2 ( 0+)c 1 ( 0 ) c cr(o)c2(o)

i(

0_-)

-CciiO( 0 )-

GLQ) c'r@

The averageresidencetime is the sum of the residencetimes of eachsvstem.

T
It follows from this example that the averageresidencetime for the FOTD modelin Example2.6 is To,- L + T.
A systemwith the transfer function

G ( s )_

. Kp(r+sT1)(r+sTz) ( 1 + s 7 3 ) ( 1+ s ? a ) ( 1+ s ? 5 )" _ s L

has the averageresidencetime To, : Te+ T+-l Ts f- L _ T _ 72.

25

Chapter 2. ProcessModels

Models with Two Parameters A very simple way to characterizethe dynamicsof a stableprocessis to use the gain Ko and the averageresidencetime 4". This gives the following models
c(":#) h (2.r7)
G(") - Kne-'ro'

where dynamics is either represented by a lag or a time delay.

Apparent Time Delay and Apparent Time Constant
Systems with essentially monotone step responsesare very common in process control. Such systems can be modeled as first-order systems with time delay with the transfer function

G(s) -

K --!i-!--
r + s 7 '"-'L

(2.18)

To emphasize that the parameters L and T are approximate they are referred
to as the apparent time delay and the apparent time constant, or the apparent log, respectively. The average residence time is ?o. : L * 7. The parameter

L
ne-
1L 1a r

L+T'

(2.le)

which has the property 0 ( c ( 1, is called the normalized ttme delay or the normalized dead time. This parameter can be used to characterize the difficulty of controlling a process.It is sometimes also called the controllability ratio. Roughly speaking, processeswith small t are easy to control, and the difficulty in controlling the system increases as r increases. Systems with t - I correspond to processeswith pure time delay, which are difficult to control well.

U l t i m a t eG a i na n d U l t i m a t eP e r i o d
So far we have used features that are based on the transient response. It is also possible to use features of the frequency response. Models can be characterized in terms of their phase lags and the frequency, where the systems have a given phase lag. For this purpose, we introduce ot, to denote the frequency where the phase lag is g degrees, and we introduce K, - lG (ir,t,p)lto denote the process gain at otr. The frequencies-rdeeand rdlse and the corresponding processgains Kee and Klss are of particular interest for PID control. These frequencies correspond to the intersections of the Nyquist curve with the negative imaginary and real axes; see Figure 2.9. They also have nice physical interpretations. Consider a processwith pure proportional control. If the controller gain is increased the processwill start to oscillate, and it will reach the stability limit when the controller gain is Ku : llK:rlo. The oscillation will have the frequency raa16T,oh.is frequency is called the ultimate frequency. The parameter Ku is called the ultimate gain or the critical gain. The parameters Kes and ale6 have similar interpretations for a process with pure integral control.

26

2.4 Feature-Based Models

Figure 2.9 Nyquist curve with the points @0,asy and @1s6.The gain ratio r is the ratio of the distances o and b.

The Gain Ratio
The gain ratio is an additional parameter that gives useful information about the system. This parameter is defined as

K;p1o lG(larlss)l

A:-

Kp

G(0)

(2.20)

It is an indicator -bo* difficult it is to control the process. Processes with a small K are easy to control. The difficulty increases with increasing r. The

parameter is also the ratio between the distances o and b in the Nyquist plot;

seeFigure 2.9.

Parameter K is also related to the normalized time delay r. For the FOTD

model given by Equation 2.18 the parameters c and K are related in the fol-

lowing way:

n - arctan 1/Tl F=1
n - arctanlT/i, - t + fT@- t

Q.2r)

This relation is close to linear as is shown in Figure 2.I0. This relation holds approximately for many other systems. As a crude approximation we can thus equate r and r. For small values a better approximation is given by r - t.6t. For the FOTD model it is also possible to find the parameters L and ? from r and arlseusing the following equations

T : '1{ T r-- l
@no

f

:

f

1
0-ir-s o(' tr

-

arctanrc-2-

11

A : -I.G( l a t l s e|)
K

(2.22)

27

Chapter 2. Process Models

0.4

0.5

0.6

0.7

0.8

0.9

1

K

Figure 2.10 The normalized time delay r as a function of gain ratio r for the system (2.18). The dashed line shows the straight line approximation K: r.

2.5 TypicalProcessModels
Much of the dynamic behavior encountered in control is relatively simple. Processesare designed in such a way that they should be easy to control. If PID control is used it is thus natural that simple process models are used. In this section we will discuss some of the models that are commonly used in connection with PID control. Most of these models are characterized bv a few parameters only.
The FOTD Model A process model that is commonly used in process control has the transfer function (2.18). It is simple and it describes the dynamics of many industrial processesapproximately. A comparison with Examples 2.3 and 2.4 shows that it can represent the dynamics of a stirred tank with a pipe without mixing. The model is characterized by three parameters: the (static) gain Ko, the time constant 7, and the time delay Z. The time constant 7 is also called the lag. The step responseof the model (2.18) is
h(t1: X, (I - e-u-L)tr) .
Since the average residence time is ?o" - L * 7, the value of the step response at this time becomes
h(7",) : Kp (t - n-') ru 0.63Ko.
The average residence time can thus be determined as the time when the step response has reached 63 percent of its steady-state value.
T\woparameters of the model (2.18) correspond to scaling of the axes and can be reduced by normalization. They can be chosen as the gain and the average residencetime. This means that if the output is scaledby the gain Kp : G(0) and time by the average residence time To, the response is completely characterized by one parameter, the normalized dead time r. The system is a pure time delay for t: 1 and a first-order system or a pure lag for r :0.

28

2.5 fupical ProcessModels

0.8
\i^ u . o
' '0.4

0.2

0

u

u.3

I

1.5

Z

2.5

3

3.5

t lTo,

Figure 2.11 Normalized step responses of the FOTD model (2.18) for different values of the normalized time delay.The normalized time delay is e:0 (dotted),0.25,0.b,0.25 and 0.99 (dashed).

Figure 2.11 shows the normalized step responses for different values of r. Notice that all curves intersect at one point t -- To, because of the normalization.

Noninteracting Tanks or Multiple Lags The transfer function (2.8) represents the dynamics of a simple tank. The upper part of Figure 2.12 shows a system that is a cascade combination of n tanks. This system has the transfer function

G"-\(s/) -

Ko (1+sT),

(2.23)

where n is the number of tanks. Since a first-order system is also called a lag the system is also called a multiple lag system. Notice that this formula holds only if the outflow of each tank only depends on its level. This means that there is no interaction between the tanks.
The average residence time is

To, : - GG('o(oi) - n Tn '

The model (2.23) has the impulse response

s(t)-#"'I1,-,r,

which has its maximum

max g (t) :

Ko@ - 7)n-z T(n-2)l n-n+1

for t : (n - I)f . The unit step response is

h(t1: u , ( ' - ( r * *

* m*

+"'*

1

"

*
-

_
t

7
1

|

7

..*\

\'

)

-)_',

1

"

(2.24) (2.25)

29

Chapter 2. Process Models
Qin

Qin

Qout

*

*

Figure 2.12 Cascaded tanks and corresponding block diagram representations. The upper tanks are noninteracting, and the lower are interacting'

The step response is characterized by three parametets, Kp, n, and ?. The number of parameters can be reduced by normalization. Parameters Kp and ? only influence the scaling of the axes. The shape of the step response is thus uniquely given by the parameter n. Normalized step responses for different values of n are shown in Figure 2.L3. The step responses are close but not equal at t : ?o'. As /, goes to infinity we have
JH G"(t) - Koe-tlr"'

0.8

N^i0 . 6 E o.o

0,2

0" 0

0.5

1

1.5

2

2.5

3

3.5

4

t lT"'

Figure 2.13 Normalizedstepresponsesfor the processeGs "(s) = 710 *s?)" for n: I ( d o t t e d )2, , 4 , 8 , 1 6 , a n d 3 2 ( d a s h e d ) .

30

2.5 \pical Process Models
Table 2.1 Apparent time constant 7", apparent time delay L", average residence time Tor, and normalized time delay r for the process (2.23).
16 32 Tn 1.86 2.44 2.91 3.32 3.68 4.01 4.31 6.23 8.90 L, 0.28 0.81 r.43 2.r0 2.8I 3.55 4.3L 10.78 24.67 To, 2.L4 3.25 4.34 5.42 6.49 7.56 8.62 L7.02 33.57 r 0.13 0.25 0.33 0.39 0.43 0.47 0.50 0.63 0.73

For large n the system thus approaches a pure time delay. Figure 2.13 shows, however, that very large values of n are required to get a good approximation of the step response of a time delay.
The transfer function G,,(s) can be approximated by an FOTD system. The apparent time constants and time delays for the approximation are given in Table 2.1.

MultipleInteractingTanks-DistributedLags
The dynamics of cascaded tanks are very different if the tanks are interacting. In the system shown in the lower part of Figure 2.L2 the outflow of a tank depends on the levels of the neighboring tanks. Let xp be the level of tank fr. The control variable u is the inflow to the first tank, and let the output be the outflow of tank ru.Assume that the tanks have unit cross-section,and assume that the flow from tank ft to tank k + t is rp - xp-t The mass balances for the tanks are
dxt
d't:-xr*)cz*u

:

dxe

(2.26)

dt

:

dxn xo-1-2xn.
i:

This is a state model with n states. The state variables represent the levels in
the different tanks. The system is also called a distributed lag. With a unit step input the equilibrium values of the states a;ro)cp- n-k+t. The characteristic
polynomials of systems having different order are

dt:s+1 dz:s2+3s+1 d,:(s+2)d"-t-d,-2.

31

Chapter 2. Process Models
1
0.8
^ 0.6
\i - o.+
0.2
0
z .t I/'lL' A r
Figure 2.14 Normalized step responsesfor interacting tanks, (2.26), for n :1 (dotted), 2, 4, and 8 (dashed).

The transfer functions for a few values of n are given by

Gr(r) : - 1 s*1

G z( s ) s2+3s+1

Gn(') G s( s )

sa+7s3*15s2*10s*1 1
s8+ 15s7* 91s6* 286s5* 495s4* 462s3* 210s2+ 36s+ 1

The average residence time is the ratio of the total steadv-state volume to the flow, hence
,r, n(n + l)
Lar ,
This is also the coefficient of the s-term in the denominator of the transfer function. As the number of tanks increases we have asymptotically for large n

G"

.\

(/s

)

----L.
coshJ2

T

o

r

s

These transfer functions are very different from the transfer function (2.23) of noninteracting tanks.
Figure 2.14 shows normalized step responses for interacting tanks. Notice that the responses are very similar for larger values of n. A comparison with Figure 2.13 shows that there is a significant difference between interacting and noninteracting tanks.

AnotherVersionof InteractingTanks
The model (2.26) is not the only way to interconnect tanks. Another configuration is shown in Figure 2.15. For simplicity we have shown a system with

32

2.5 I)pical Process Models

Figure 2.15 Schematic diagr:am of three cascaded tanks with recirculation.

three tanks. The system consists of identical stirred tanks with a forward flow q and a recirculation flow q". Let V be the tank volume, u the concentration of the inflow, cp the concentration in t]ne kth tank, and y : cn the concentration in the outflow. The mass balances for a system with n tanks are
,v,id: -c(Lq * q " ), c r t q , c z * q u

:

,v, d c k : dt

(,q + e,)cp-r -

(q + 2q,)rn * e,cn+r

:

-v- d c n ;

:

(q+ e")c,-,-

(q+ e")c,

!:cn.

This is also a state model where the states are the concentrations in the different tanks. The transfer functions for a few values of n are

Gr(t) : G2(s): G 3( s ) :

-v3s-+- q
q(q+ q,) V s 2+ 2 V ( q * g " ) s+ q ( q- r A , )
2q,(q+ q,)2 ( V s + q + q , ) ( V z t z+ ( 2 q * S q " ) s* 2 q , ( q+ q , ) )

V3s3+ (3q+ q,)Yziz

")'

'

The static gain is Ko - 1 and the averageresidencetime is
nV
-Qr q
The recirculation flow has a major impact on the dynamics. For ec :0 there is no interaction, and the system is equivalent to the model given by (2.28). As q,lq -) oo the model is equivalent to the model given by (2.26). The model with recirculation thus makes it possible to interpolate between the models with noninteracting and distributed lags.
Figure 2.16 shows the step response of a system of n:th order for different values of the recirculation flow.
33

Chapter 2. Process Models

1

0.8

^ u.b
V
- o.+

0.2

0 0.5

22.533.54 t lTo"

Figure 2.16 Normalized step responses for eight tanks with recirculation. The recirculation ratio is q"lq:0 (dotted), 1,2,5 and 10 (dashed).

OscillatorySystems
The model (2.18) cannot describe systems with oscillatory responses.A simple model for such systems is given by the transfer function

G(s):

Kp l+2(sT+(s?)z'

(2.27)

This model has three parameters: static gain Ko, time constant 7, and relative damping (. The parameter llT is also called undamped natural frequency. The step responses can be normalized by the gain and the time constant. Its shape is then determined by one parameter only. The step responses are shown in Figure 2.I7. For ( ( 1 the step response has its maximum

M-Kpe

n(
11 r9.
VL-9-

which occurs at

v+m-a x -

2rT

th-?

The position of the maximum increases with increasing (, and it becomes infinite for ( : 1 when the overshoot disappears. The transfer function is then

G (\ "s,),:

Ko=,=.

,-. (1 +

s7;z

'

and the step response is

h ( t 1-

Ke^\(tt -

"e - t t r-

L"-'t'\.

T"

)'

The Bode plots of the systems are shown in Figure 2.18.

34

2.5 fiPicat ProcessModels

Figure 2.17 Normalizedstepresponsesof oscillatorysystems(2'2?) with ( : 0 (dotted)' o.i o z, 0.5,o.?,and 1'o (dashed)'
= 10'
3 16u
;_1 .i i n
1 0.-1:0 - '

a\
H -qn
d 0) a
d

100 coT

Figure2.l'sBodeplotsofoscillatorysystems(2.zl)with(=0.05(dotted),0.1,0.2,0.5, 0.?,and 1'0 (dashed)'

Processeswith Integration
Integrating processes will not In practice, the same is true

reach steady state during for processes with very

open-loop conditions' long time constants'

AissstnhatsyeeistydahtAmetdetrmoyapccntsobsoostmena,ft"etibtwrnceroiuinaltrafhaluuslfotytlnii"e'og,uctrntnvttti.a,oas.lo".oedfrIl,uifnsa,o-rttrnfopuetaharugibnueutputrwlee,ru"ofg.aito;lcirr'loralecyttshlso"sMutparacw'n;ou"hiagtystihntees'dyamsstaetc"cetlootfttmh-'innomresetdsregstopaaulirdonleflaoeictttrleroeiaoasbrPynasttIeatDiuvsiabnrayefetartuideasnct'rbihosantemeigsmstmepdeaolipydslnsyconsbhmtotyaerotenmddargieestvelai'wdscTieuhnrchgeahe

transfer function is

c(t) :

K".
T

e

--r"

'

'

(2.28)

This model is characterized by two parameters' a gain and a time delay' The

Chapter 2. Process Models

V, a
-

0
tlr",

Figure 2.19 Normalized step responses for the FOTDI model (2.30) for t:0 0.25,0.5,0.75,and 0.99 (dashed).

(dotted).

integrating gain is denoted by a special symbol K,, which tells how fast the output increases in steady state after a unit input step change. The parameter K, has dimension frequency.
A combination of a lag and an integrator is a model that is commonly used to describe simple drive systems. This model has the transfer function

c(r:)m+:D

(2.2e)

The transfer function K,f(1 + s") represents the transfer function from the

voltage of the drive system to the rate of rotation, and the integrator represents

the relation between angular rate and angle.

A slightly more complicated model is obtained by adding integration to the

c(,:)fi4,-'" standard model (2.18).

(2.30)

We call this the FOTD model with integration or FOTDI for short. This process can be normalized in the same way as the model (2.18) by introducing the normalized time delay given by (2.19). The normalized step responses of the FOTDI model are shown in Figure 2.I9.

Systemswith InverseResponses

The systems discussed so far do not have any zeros. Systems that are repre-

sented as a parallel connection of several systems can have transfer functions

of the type

u^ ,( ,s ] :

l*s?

s 2+ 1 . 4 s+ 1 '

(2.31)

This system has a zero at s : -tlT, which may have a significant influence

on the response of the system. Figure 2.20 shows the step response of this system for T - -2, -1, 0, 1, and 2. Notice that the overshoot of the step

response increases with increasing positive values of T. Also notice that the

output signal initially moves in the wrong direction when 7 is negative. Such

36

2.5 Ilpical Process Models

Figure 2.20 step responses for the model (2.31) for T : -2 (dotted), -1, 0, 1 and 2 (dashed).

systems are said to have inverse responses. Systems with inverse responses are difficult to contr6i.'Examples of such systems are level dynamics in steam generators, dynamics of hydroelectric power stations, dynamics of backing cars, etc.

Heat Conduction
Temperature control is a very common application of PID control. Some models that are directly based on physics will now be discussed.Consider an infinitely long rod with thermal diffusivity 2. Assume that there is no radial heat transfer and that the input is the temperature at the left end of the rod. The transfer function to a point at the distance o from the left end point is

G(t) : s-{sr, where T : a217. The impulse response of the system is given by

(2.32)

h (\t l/ :

t/T 2/tlslz

I -4

(2.33)

This impulse response has the property that all its derivatives are zero for f : 0, which means that the initial response of the system is very slow. The
impulse response has a maximum at t - f 16.For large values of r the impulse response decays very slowly as t-1'5. The step response of the system is

y(t:)r- *rl!*- 1- # ly e-d*,'x

(2.34)

The step and impulse responsesare shown in Figure 2.2L Notice that the temperature starts to rise very slowly initially. After a rapid rise it also approaches the steady state very slowly.
We will now instead consider the situation when the right-hand side is isolated. The transfer function then becomes

G ( s ): coshv67'

(2.35)

37

Chapter 2. Process Models

1

I

I
a 0.5 I
, ,

\\\

I

0

0.2

0.4

u.b

0.8

1

t.z

1.4

- 0.5

0

0

10

20

30

40

50

60

70

80

90

100

tlr

Figure 2.21 Step response (solid) and impulse response (dashed) for a system with the transfer function s-\/sT . The upper curves show the step responses and the impulse response. The lower curve shows the step response in a different time scale.

1.5

0

0.5

1

1.5

2

2.5

3

3.5

4

tlr

Figure 2.22 Step responses for the transfer function 1/ cosh v67 (solid) , e-tGT (dashed) and 2e-@ (dotted).

This is a system with infinitely many lags with time constants 4T f n2, T f gnz, 4T 125n2,4T l49x',. . . .This transfer function is also called a distributed lag.
The step response of this transfer function is shown in Figure 2.22. Notice

that the response approaches the steady-state value faster than the system

(2.32). The step response of the systems are thus quite different. The isolation

of the right end of the rod makes it much easier to transfer heat into the

system. A simple calculation shows that the average residence time for the

SYSTCM iS

Tor:

- - G ' 1 0- T1 2

(2.36)

The system (2.32) with the transfer function e-@ has infinite residence time which reflects the fact that the impulse response decays very slowly; compare with Figure 2.2I.

38

100
=
-.tn

1

01

0_ t-

_t
10

2.5 TJtpical Process Models

1oo

io'

102

x -90

tr

-1 80

2
10-

-1
10

1oo

101

otT

102

Figure 2.23 Bode plots for the transfer functions 1/ cosh r4? (solid lines), e-',Gr (dashed). For comparison we also show the gain curve for the transfer function 2e-6 (dotted).

We will now investigate the frequency responsesof the systems (2.32) and (2.35).It can be shown that both transfer functions have a phase lag of 180'
at the same frequency.

2n2 a)tgo:
T

(2.37)

The magnitudes of the transfer functions at @Bs are given by

p-fiatnTl-e-o

1

:

lcosht/ianoTl #

x0.04821
x0.08627.

At the frequency where the phase lag is 180' the gain of the system (2.35) is thus very close to twice as high as the gain for the system (2.32). The Bode plots of the system are shown in Figure 2.23. Notice that for frequencies above 2 radf s there are very small differences between the transfer functions 2e-6 and LI cosh \/;T even if the step responses differ significantly. This observation is very important for the design of control systems. Figure 2.22 also shows that the step responses for the transfer functions 2e-G and 1/ cosh /r" are verv close.

A Heat Exchanger

The transfer function from input temperature to output temperature of an ideal heat exchanger is

c(r)- +s l(' r - u-"t).

(2.88)

The step and impulse responsesof this system are shown in Figure 2.24. Notice that the step response settles to the final value at time t - T and that the

39

Chapter 2. Process Models

E-
I
^;
0.5

u.o

0.8

1

1.2

tlr

Figare 2.24 Normalized step (solid) and impulse (dashed) responses for the transfer function (2.38) of an ideal heat exchanger.

impulse response is zero after that time. This reflects the fact that once liquid has passed through the heat exchanger its temperature is no longer influenced. The average residence time of the system is
rt oy t, -- T t
The frequency response of the system is
G ( i a' t )+L:a'(l r -' r - ' " ) .
The transfer function is zero for aT - 2nn. This is clearly seen in the Nyquist curve of the transfer function in Figure 2.25. An interesting property of this transfer function is that
arsG(ia): -+. foratT12n.

A ContinuousStirredTankReactor

Consider a continuous-time stirred tank reactor where the reaction A --+R

takes place. The reaction is exothermic, and reaction heat is removed by a

coolant. The system is modeled by mass and energy balances.The mass balance

is

#: #c,- c)- k(r)c,

(2.3e)

where c lkmollm3] is the concentration of speciesA, cf the concentration of A in the feed, q l*3/s] the volume flow rate,V l*tl the reactor volume, and k(f) [s-1] the reaction rate which is a function of temperature

hQ) - k(rs-Elnr

(2.40)

40

2.5 Tltpical Process Models P(ia)

Figure 2.25 Nyquist plot of the transfer function G(s) (2.38) of an ideal heat exchanger.

Table 2.2 Parameters of the exothermic continuous-time stirred tank reactor.

q 0.002*3 It
v 0.Lm3
p 1000ksl*t C- a kJ lkgK h6 3 x 1 0 8s - 1

Tf,7, EIR
cS
uA
LH

300K 8 7 5 0K
2 kmolf m3
50w/K
-5 x t05 kJ/kmol

The first term on the right-hand side represents the mass flow rate and the second term represents the rate of removal of A through the reaction.
The energy balance can be written as

dT :+er-T+ke)#,*ffie,r-),
dt

(2.4r)

where LH ll?J lkmol] is the reaction heat, p lkg l*3] the density of the species A, Cp lkJ lkgK] specific heat, U lJ lmin I K I rn2l the heat transfer coefficient, A l*'l the area, T" lKl the cooleant temperature, and,Ts [,K] the feed temperature. The first term on the right-hand side represents the energy flow rate of
the system, the second term represents the power generated by the reaction,
and the last term represents the energ-yremoval rate through cooling. Tlpical parameters are given in Table 2.2.
We will first analyse the steady-state solutions. In steady state it follows
from (2.a0) that

c:

__]
1+

V

k

Q_

)

l

q

"c'"'

The power generated by the reaction is

lr(T)

D
Lq-

I+vk(r)lq (-A,H)c,

(2.42)

41

Chapter 2. Process Models
x 10

ts1
"sa

380

400

420

440

460

480

500

T

Figure 2.26 Steady-state heat generation rate (solid) and heat removal rate (dashed) as function of temperature. The equilibria are marked with o.

and the rate of removal of enerry is

p,: +g - ri +uAe- r,).

(2.43)

Equating Pn and P. gives an equation in one variable to determine the reaction temperature ?. A graphical solution gives insight as illustrated in Figure 2.26, which shows Pn and P" as functions of temperature. There are three equilibria where the curves intersect at 7 - 300.5,375.1, and 438.6. The equilibrium at T - 375.1 is unstable because the rate of heat generation is larger than the rate heat removal if temperature is increased. The other equilibria are stable. Approximating the dynamics in the neighborhood of the unstable equilibrium gives the following linear model of the system

#:_-o.o422xr*o.oo13r2 # : 2 . 7 7 4 6 x r -0 . 0 0 6x4zt 0 . ! 5 u ,

(2.44)

where xr: C-CO,X2:T-TO,andU-

T, - Tro and cg, Tg, and Tr, are the

equilibrium values. The transfer function is

P(s) -

0 .1 5 s+ 0 .0 0 6 3 s2+ 0.048631-s 0.003359

- 0 .'1^5" ( s +

s + 0.44224 0 . 0 8 7 1 7 ) (-r 0 . 0 3 8 5 4 )

The system has the pole s - 0.03854 in the right half plane.

NonlineaBr lackModels
The static model discussed in Section 2.2 could be nonlinear. The dynamic models discussed so far have, however, been linear. Since nonlinearities are common in practice it is highly desirable to have nonlinear models. Valves, actuators, and sensorsmay be nonlinear; the processdynamics itself can also be

42

a) '-ffiffi

2.5 Tlpical Process Models

Figrre 2.27 A Hammerstein model a), and a Wiener model b).
nonlinear. General models for nonlinear dynamics are complicated, and there are no good methods for designing PID controllers for such systems.
Fortunately, there are special classes of models that are well suited for PID control. A system may be represented as a combination of a static nonlinearity and a linear dynamical system. Such models are quite simple, and they are nicely adapted to PID control, but there are nonlinear systems that cannot be modeled well using this approach.
The nonlinearity can be before the linear part as shown in Figure 2.27a. This model is called a Hammerstein model. It is a good model for a system with a nonlinear actuator, for example, a nonlinear valve.
The nonlinearity can also be placed after the linear dynamical system. This gives a Wiener model, which is illustrated in the block diagram in Figure 2.27b. The Wiener model is a good representation for a system with a nonlinear sensor, for example, a pH electrode.
If the process is nonlinear the dynamics are varying with the operating conditions. Ideally, the controller should be tuned with respect to these variations. A conservative approach is to tune the controller for the worst case and accept degraded performance at other operating conditions. Another approach is to find a measurable variable that is well correlated with the process nonlinearity. Such a variable is called a scheduling variable. The controller is then tuned for a few values of the scheduling variable. Controller parameters for intermediate values may be obtained by interpolation. This approach to generating a nonlinear controller is called gain scheduling. It will be discussed in more detail in Section 9.3.
It is easy to compensate for the nonlinearity for a system that is described by a Wiener or a Hammerstein model by using a nonlinear controller composed of a PID controller and a static nonlinearity. The linear PID controller is designed as if the system was linear. When the process has a nonlinearity at the input we simply pass the control signal through the inverse of the nonlinearity. If the nonlinearity is at the output, as for the Wiener model, we simply pass the sensor signal through an inverse of the nonlinearity before feeding the measured signal to the controller. Many PID controllers have a facility to introduce a nonlinearity characterized as a piecewise linear function.

Chapter 2. Process Models
2.6 Modelsfor Disturbances
So far, we have only discussed models of process dynamics. Disturbances are another important aspect of the control problem. In fact, without disturbances and processuncertainty there would be no need for feedback.There is a special branch of control, stochastic control theory, that deals explicitly with disturbances.This has had little impact on the tuning and design of PID controllers. For PID control, disturbances have mostly been considered indirectly, e.g., by introducing integral action. As our ambitions increase and we strive for control systems with improved performances it will be useful to consider disturbances explicitly. In this section, therefore, we will present some models that can be used for this purpose. Models for disturbances are useful for simulation, diagnostics, and performance evaluation.
TheNatureof Disturbances
We distinguish between three types of disturbances, namely, set-point changes, load disturbances, and measurement noise. In process control, most control loops have set points that are constant over long periods of time with occasional changes.An appropriate model is therefore a piecewise constant signal. Set-point changes are typically known beforehand. Good response to set-point changes is the major issue in drive systems.
Load disturbances are disturbances that enter the control loop somewhere in the process and drive the system away from its desired operating point. Load disturbances typically have low frequency. Efficient reduction of load disturbances is a key issue in process control systems.
Measurement noise represents disturbances that distort the information about the process variables obtained from the sensors. Measurement noise is often a high-frequency disturbance. It is often attempted to filter the measured signals to reduce the measurement noise. Filtering does, however, add dynamics to the system.
The Character of Disturbances One way to get a first estimate of the disturbances is to log the measured variable. The measured signal has contributions both from load disturbances and measurement noise. If there are large variations it is often useful to investigate the sensor to reduce some of the measurement noise. Filtering may also be useful. Filtering should be done in such a way that it does not impair control.
The process variations may have very different character. Some examples are given in Figure 2.28. The disturbances can be classified as pulses (a), steps (b), ramps (c), and periodic (d). It is useful to compute statistics such as mean values, variances, and maximum deviation. It is also useful to plot a histogram of the amplitude distribution of the disturbances.
Simple Models
It is useful to have simple models for disturbances for simulation and evaluation of control strategies. Models that are typically used are shown in Figure 2.28. The impulse is a mathematical idealization of a pulse whose duration
44

2.6 Models for Disturbances

Figure 2.28 Different types of disturbances: a) impulses, b) steps, c) ramps, and d) sinusoids.

a)

b)

c)

d)

0

1

Figure 2.29 Examples of stochastic disturbances.
is short in comparison with the time scale. The signals are essentially deterministic. The only uncertain elements in the impulse, step, and ramp are the times when they start and the signal amplitude. The uncertain elements of the sinusoid are frequency, amplitude, and phase.
Random Fluctuations Disturbances may also be more irregular as is shown in Figure 2.29. There are weII developed concepts and techniques for dealing with random fluctuations that are described as stochastic processes.There are both time domain and frequency domain characterizations. In the frequency domain the random disturbances are characterized by the spectral density function 0@t). The variance
45

Chapter 2. Process Models

0 T
Figure 2.30 Prediction error opeas a function of predictiontime ?o.

of the signal is given by

oo
I
o2- I Q@)da. I -oo

The spectral density tells how the variation of the signal is distributed on different frequencies. The value

2Q(ro)Lat

is the average energy in a narrow band of width Aar centered around at. A signal where Q@) is constant is called white noise. Such a signal has its enerry equally distributed on all frequencies.
There are efficient techniques to compute the spectral density of a given function. If the spectral density is known it is possible to evaluate how the variations in the process variable are influenced by different control strategies.

Predictionof Disturbances
When controlling important quality variables in a process it is often of interest
to assess the improvements that can be achieved and to determine if a particular control strategy gives a performance that is close to the achievable limits.
This can be done as follows. The processvariable y(f) is logged during normal
operation with or without control. By analyzing the fluctuations it is possible to determine how accurately the process variable can be predicted !o time units into the future based on present and past values of y.Let iU +?olt) be the best prediction of y(t + T) based on y(r) for all r < t. By plotting the variance of the prediction error y(t + T) - i(t + foV) as a function of the prediction time we obtain the curve shown in Figure 2.30. For large prediction times the prediction error is equal to the variance of the processvariable, approximately
op": 12in the figure. The best control error that can be achieved is the prediction error at a prediction time !o corresponding to the time delay of the process and the sampling time of the controller. This can be achieved with a
so called minimum variance controller. See Section 8.6. The figure indicates
that variances less that 5 can be obtained if 4 ir less than 3.4. Further reductions are possible for smaller To,but variances less than l cannot be achieved

46

2.7 How to Obtain the Models
even if Tp is very short. By comparing this with the actual variance we get an assessment of the achievable performance. This is discussed in more detail in Chapter 10. There is efficient software for computing the prediction error and its variance from process data.
2.7 Howto Obtainthe Models
In previous sections we have briefly mentioned how the models can be obtained. In this section we will give a more detailed discussion of methods for determining the models. There are two broad types of methods that can be used. One isj-hysical modeling, and the other is modeling from data.
Physical modeling uses first principles to derive the equations that describe the system. The physical laws express conservation of mass, momentum, and energ"y.They are combined with constitutive equations that describe material properties. When deriving physical models a system is typically split into subsystems. Equations are derived for each subsystem, and the results are combined to obtain a model for the complete system. Simple examples were grven in Section 2.3. Physical modeling is gften very time consuming. There are often difficult decisions on suitable approximations. The models obtained can, however, be vgry useful since they have a sound physical basis. They also give considerable i4Sigh! into the dependence of the model on the physical parameters. A simple way to start is to model dynamics as first-order systems tihere the time constants are the ratio of storage and flow.
Modeling from data is an experimental procedure. Data is generated by perturbing the input signal (the manipulated variable) and recording the system output. The experiment can also be per-formedunder closed-loopconditions, for example, by perturbing the set point of a controller or the controller output. It is then attempted to find a model that fits the data well. There are several important issues to consider; selection of input signals, selection of a suitable model structure, parameter adjustments, and model validation. Ideally, the erperimental conditions should be chosen to be as similar as possible to the intended use of the model. The parameter adjustment can be made manually for crude models or by _usingoptimization techniques.
Static Models
Static models are easy to obtain by observing the releition between the input and the output in steady state. For stable, well-damped processesthe relation can be obtained by setting the input to a constant value and observing the steady-state output. The procedure is then repeated for different values of the input until the full range is covered. For systems with integration it is convenient to use a controller to keep the output at a constant value. The set point of the controller is then changed so that the full signal range is covered. Effects of disturbances can be reduced by taking averages.
TheBumpTest Thebumptestis a simpleprocedurtehat is commonluysedin procescsontrol.
It is based on an experimental determinatio4 qf the step response. To perform
47

Chapter 2. Process Models

1 0.8 u.o 0.4 0.2
0

'r'5

2'5

3

,11",

3'5

4

Figure 2'31 Step responses for a large batch of stable systems. The responses have been normalized to give the same average residence time.

the experiment the system is first brought to steady state. The manipulated variable is changed rapidly to a new constant value and the output is record.ed. The measured data is scaled to correspond to a unit step. The change in the manipulated variable should be large in order to get a good signal-to-noise ratio but it should not be so large that the process behavior is not linear. The allowable magnitude is also limited by process operation. It is also useful to record the fluctuations in the measurement signal when the control signal is constant. This gives data about the process noise. It is good practice to repeat the experiment for.different amplitudes of the input rignui and at different operating conditions. This gives an indication of the signal ranges when the model is linear. It also indicates if the process changes with th" op"rating conditions.
By inspection of the step response it is possible to make a crude classification of the dynamics of the system into the categories shown in Figure 2.2. A model with a few parameters is then fitted to the data.

The Average Residence Time

The average residence time is a simple way to charac terizethe response time of

systems with essentially monotone step responses.Figure 2.81 step responses

for a large batch of systems that are normalized to give the same average res-

iclencetime. (The transfer functions for the systems are given in Sectioi 2.1.)

The figure shows that all step responsesare close for t - Tor. For all processes

in the test batch we have 0.99 < TaelTo, < 1.08. The average residence time

can thus be estimated as the percent of its final value.

time

?63 where

the

step response has reached 68

The FOTD model

The parameters of the FOTD model given by Equation 2.18 can be determined

from a bump test as illustrated in Figure 2.3i. The static gain Ko is simply

determined from the steady-state values of the signals before and afier the siep

change' The apparent time delay Z is given by the point where the steepest

tangent intersects the residence time To, -

steady-state level before the T * Z is determined as the

step change. The average time ?0, luhe.e the stJp

48

Kp o.63Kp

2.7 How to Obtain the Models

-a
Figure 2.32 Unit step response of a process and a procedure used to determine the process parameters Kp, L, 7, and K, of an FOTD model. The point of largest slope is denoted by o.

response has reached 63 percent of its final steady-state value. This gives the correct results for the FOTD-model (see Figure 2.II) and approximate results for many other models (seeFigures 2.13,2.I4,2.16, and 2.31). The velocity gannKu is the slope of the steepest tangent.
Similar methods can be used when the input signal is a pulse instead of a step. Pulses may be used when it is not permitted to use a step. This is common in medical and biological applications and is less common in process control. Ramp response analysis is common when analyzing servo drives and hydraulic systems.

The lntegral and Time Delay Approximation The model parameters of the model (2.28), which has the transfer function

c ( r :)+ e - ' L - # , n - "

(2.45)

can also be determined from a bump test as indicated in Figure 2.32. The velocity constant Ku is the steepest slope of the step response,and the intersections of this tangent with the vertical and horizontal axes give o and I, respectively. The model given by Equation 2.45 is the basis for the Ziegler-Nichols tuning procedure discussed in Chapter 6.

The Doublet-Pulse Method A variation of the bump test is to excite the process by a doubled pulse as is illustrated in Figure 2.33. The pulse amplitude a is chosen so that the response is well above the noise level, and the pulse width 4 ir chosen a little longer than the time delay of the process. The maximum y,''u,.and the minimuffi .lmin and the times /-u* and /-i,, when they occur are determined. Simple calculations show that for an FOTD system with the transfer function (2.10) we
49

Chapter 2. Process Models

Figure 2.33 Determination of the parameters of an FOTD model by exciting the process by a doublet pulse.

have

J m a x: q Kp (\- e-rol r) J mi n: -d K p (t - n-r' tr 7' t^ur: L + To /min: L+2Tp.

It follows from these equations that

Jmin __1 *e-TolT .}max
^rL- --aKP' ffi

and we get the following simple equations for the parameters of the model

,
^t-
K__rmax aJmin
T^ T_
log(1 * y*u*/y*i,,)
L _ t^ut - Tp
L - t^rn - 2Tr.

(2.46)

The fact that the time delay L can be estimated in two ways can be used to assesif a processcan be modeled by an FOTD model.
The selection of the pulse time To can be determined automatically, for example, as the time when the output has changed a specified amount. The method can be applied to SOTD models, but the formulas are more complicated.
The main advantages of using a doublet pulse is that the process output relurns to its original value after the perturbation, and the time required to

50

2.7 How to Obtain the Models

u.b 0.4 0.2
22.53 t lQt + Tz)
Figure 2.34 Normalizesdtepresponsefosrthesystem(2.48f)orT2lT1: 0.1,...,1.

determine the dynamics is short because it is not necessary to wait for steady state as for the bump test. The disadvantages of the method are that it is difficult to determine times when the extrema occurs accurately, and the estimate of the gain is poor because the excitation of the pulse is mainly in the highfrequency regime. Another disadvantage is that the method cannot be applied to oscillatory systems.

The SOTD Model The model

G ( s ):

(

1+

s

"

Kp
il(

1+

s

r

y

e-strr

(2.47)

which is a natural generalization of the FOTD model (2.18), is called the second-order model with time delay or SOTD model. Without loss of generality it can be assumed that Tz a ft. The step response of the system (2.47) is

v('[):{;[:

+nr-(t-1,)rcr #^r*v-"urc")

e-(t-LrIr), -

tr,)

Lnr,-",1

ffrt r rz
if TL - Tz.

(2.48)

The normalized step responses for different ratios T2lT1 are shown in Fig-

ure 2.34. The responses have been normalized so that all systems have the

same average residence time. All step responses are quite close, and they are

almost identical for t l(71 1 Tz) r 1.3. Since the separation of the curves is so small it is difficult to determine the parameters ft and T2 robustly from the
step response, particularly if there is a small amount of noise. Other inputs

that excite the system better are necessary to determine the parameters re-

liably. The figure shows that it would be easier to determine the parameters

based on an impulse response, which could be obtained by differentiating the

step response.

51

Chapter 2. Process Models .''.

Kp

Figure 2'35 Graphical determination cillatory step response.

of mathematical

models for systems with an os-

An OscillatorySystem ttrpmThoeahoeltraeidasmtemimtveelfeoepopdtdrreeeeasrrlsmusi(op:c2tpdhoh.i1enTsn8syogse)s(taacat.dsnatTimidncnhdn-sdegieosisacctgemaianiptvyKoearedpdarnie,atnbitlmohsyFeeydtihstgueaetunerstrsdmrefcaaoas2mnlwln.so3pibfwt5eehe.sdrPdf.nouaeasnrttcaecuimrtlrlimaaoeltnitnofe(rer2eryds.qr?a2euplsiea,ppwnnrocodhnyxi(csLimhelaTsarhA,.etaearsselnyitldfmhartrotpheemleede

d.- e-2(olvtr-<,

,11

2nT

rp -

/T:P

(2.4e)

r

r-Bro

(2.50)

The accuracy of the model is limited step or a pulse. Measurement errors other factors that limit the accuracy.

by the limited excitation obtained with a and difficulty in obtaining steady state are Some improvements can be made by using

optimization for fitting the parameters. T)'pically, it is difficult to determine

more than three parameters from a step response unless the experimental

conditions are exceptional.

FrequencyResponse

In f the

requency response analysis, a sinusoidal signal is steady-state response is analyzed. An advantage

inst with

ead introduced, and frequency response

analysis is that very accurate measurements can be made Uy.rsi.rg correlation

techniques. The long experimental times is a drawback.

It is also possible to introduce an arbitr
frequency response can be obtained as the the output and the input signals. It is also model with given structure to the data.

ary signal as a perturbation. The
raiio of the Fourier transforms of possible to fit the parameters of a

A nice feature of using signals other than steps is that it is possible to make a trade-off between signal amplitude and duration.

52

2.7 How to Obtain the Models

Figure 2.36 Block diagram of a process with relay feedback.

l---l gl

I

tl

1l

fl

1l

ll

1l

ll

I I I I

ll

It tl lr tl

t----

I I I I I
tl tl tl tt ----l
IJ
t

r---.1 l1 lt 1l l1
l1 l1 l; l1 l---J

t- - - rl tl rl rl
I I I I

Figure 2.37 Relay output u (dashed) and process output y (solid) for a system under relay feedback.

Relay Feedback

lhere is a very special technique that is particularly suited to determine arlse ,rd K1ss. This has been used very effectively for tuning PID controllers. The
iea is the observation that it is possible to create an oscillation with the :ltimate frequency automatically by using relay feedback.

To make the experiment the system is connected in a feedback loop with a :'-'lavfunction as shown in Figure 2.36. For many systems there will then be an -cillation (as shown in Figure 2.37) where the control signal is a square wave ,rd the processoutput is closeto a sinusoid. Notice that the processinput and
-:tput have oppositephase.

To explain how the system works, assume that the relay output is expanded

:: a Fourier series and that the processattenuates higher harmonics effectively.

-: rs then sufficient to consider the first harmonic component of the input only.

''-:r'sr-et'QiuhnapDrumCt ojoanfnictdheothfoetshceoiullsatpqtiuuotanrtehisewneaqvhueaavlientopoupat p,lorhesa.oistIefapdmhpaislsitetuh,dewehrei4cldhalyxm. aemLapenltsitauthdbaeet,

the the the

,::rplitude of the process output. The process gain at aas is then given by

x r a of f: i .

(2.51)

\ ,tice that the relay experiment is easily automated. Since the amplitude of :.'-'oscillation is proportional to the relay output, it is easy to control it by , itusting the relay output. Also notice in Figure 2.37 that a stable oscillation - established very quickly. The amplitude and the period can be determined

53

Chapter 2. Process Models

after about 20 s only, in spite of the fact that the system is started so far from the equilibrium that it takes about 8 s to reach the correct level. The average residence time of the system is 12 s, which means that it would take about 40 s for a step response to reach steady state.

The SOTD Model-Combined Step and Frequency Response
It was mentioned previously that the-_parametersof the SOTD model cannot be determined reliably from step response data. Good estimates can, however, be obtained by combining step and frequency response data. The idea is that the step response gives Ko and ?63 and the frequency response method grves the ultimate frequency*rtt"--: (l:u,oand the ultimate gain Ku : IlK.u'o.This gives the equations

K\KS: (1+ a?rl)Q+ of,r])
7T: atctanauTy * arctan auTz * auL1.

(2.52)

Combined with the data Ko and 763 the parameters are then given by Equations 2.48 and 2.52 which gives four equations for the four unknown.

0:

( o^ '^3-7I

T:,+-- r _T.r\-T a r - L r t i T r -

T= 'z,-

=Ttn-- t T 6 - L 1 ) 1 7 2 i f T 1 +

72,

{ f

t

-

u _ . ( r a ' t - L-t \ l r r

- 0.68

ffn-e,,-1,)lr'

if Tr - Tz (2.b8)

0: (1+ r,f"rl1Q+ r,f"rfl- K3K3

0 : arctanouTl * arctan @uTz* (DuLt - ft.

These equations can be solved iteratively, but this is complicated sinc! we have to take care of the special caseswhen the parameters ?r and T2 are equal or zeto.
An alternative method is to iterate the ratio a:TzlTt until the equations match. Parameter Ko is determined as the static gain of the step response. The equation (2.52) for the ultimate gain then becomes
(t + r,f"r!)(t+ a2r,f,rfl: K3K3.

This equation has the solution

rryll -

The parameters T2 and Ly are then given by

T2 -- aTy

lt - atctanauTt - atctanauTz

Lt :

.

a)u

The step response given by Q.a8) can then be computed as a function of o, and the parameter d car' be iterated to match the value of 763.

54

2.7 How to Obtain the Models

. .1.318

e- 19'53s5

3 9 3 0 1s - 1 | ' ?

Error= 1.02e-01

1J

TJ

74
/J.f,
73 72.5

71,5

s00 s50 1000 1050 1100

D r a gt h eh a n d l et or is h a pteh es t E p r e s p o n soeft h em o d E l .

,, iil,J ;,'9. f,.,J

CoF$rights 1gS7* I 9gg,Alsers $Allen,Dtprtmtnt of Altfmatic Ccntrsl, L|Jld lffitit{te of TchnoloEiL, rrrrdS, vedm

Figure 2.38 Computer screen from a tool for process modeling. From [Wall6n, 2000]

Modeling Tools
There are several modeling tools that are very useful. They make it possible to enter process data in the form of sequencesof input-output data from bump tests or other process experiments. Models of different structure can be selected, and their parameters can be fitted to the data using some optimization procedure. The tools also permit selection of parts of data sequencesqsed in the analysis.
Figure 2.38 shows the computer screen for a particular system. A model structure can be chosen from a menu. When data has been entered a preliminary model can be fitted by manually dragging the handles shown in the figure. The handles represent the start of the step, the initial level, the final level, and the time when the responsehas reached 63 percent of its final value. The model parameters are displayed. Optimization can then be used to improve the fit.
The particular tool illustrated in the figure also allows use of a nonlinear model as illustrated in Figure 2.39. In this case a static model is first fitted to input-output data obtained from a static experirnent. A dynamic model is then fitted as indicated in Figure 2.39. Both Wiener and Hammerstein models are tried to see which gives the best fit. The particular example is from a tank system where the outflow is a nonlinear function of level. In this casethe Wiener model gives the best fit becausethe nonlinearity appears at the system output. Notice in Figure 2.39 that the input steps are of equal size, but the magnitude of the output response changes significantly. This data cannot be well matched by u linear model.
The interactive tools give a very good feel for the relations between the parameters and the response and the sensitivity of the parameters. It is also very effective to combine simple manual fits with numeric optimization. Most tools
OD

Chapter 2. Process Models

Processmodel:
80 60
20 o

1.670' 2.701s + t

e- 0.190s

Enor- 1.08e+00

Drag the handles to shape the step ^f th. m^.lal

Figure 2.39 Illustrates computer-based nonlinear modeling. From [Wall6n, 2000]
permit fitting a simple bump test, but there are also tools that permit general input signals. They also make it possible to determine noise characteristics and the prediction curve shown in Figure 2.30.

2.8 ModelReduction

Many methods for tuning PID controllers are bpqedon simple models of process dynamics. To use such methods it is necessary to have methods for simplifying a complicated model. A typical case is when a model is obtained by combining models for subsystems. To find suitable approximations it is necessary to specify the purpose of the model. For tuning PID controllers this can be done by specifying the-frequency range of interest. This can be done simply by specifying the highest frequency ar* where the model is valid. For PI control the frequency _qrllq"about 0)t4s,the frequency where the phase lag of the process is 145'. The reason for this is that a PI controller always has a phase lag. For a PID controller, which can provide phase lead, the frequency a* can be chosen
aQ!2rso. Model reduction starts with a model represented by the transfer function
G(r). The transfer function is first factored as

c(") - Gr(")1

G i ,( r ) .

* ,",

(2.54)

The low frequency factor Gz(r) has all its poles and zeros and time delays at frequencies around al* or at lower frequencies. The high-frequency factor Ga(s)

DO

2.8 Model Reduction

het 4yq+qiqs at frequencieshigher than ar*.The time constant 7, represents an intermediate pole.The factorization can always be donein such a way that the high frequencyfactor Gn(r) has the propertypa(9) - f .
For designof PID controllersthe model (2.54)will be simplifiedto

c(:,r)fu{"

G ( s ):

Kp

(

1

+

s

"

1

)

(

1+

s

7

2

e
)

-

t

L

(2.55)

The reason for these choices is that there are methods for designing PID controllers for models of this type. These models are particularly suitable for typical process control problems where the dynamics have essentially monotone step responses.

T h e L o w - F r e q u e n cFy a c t o r
The low-frequency factor will normally only contain one or two modes. If the system has multiple poles they can be approximated by the transfer function

G r ( r:)i h e = 1 " .

where T" and L" are obtained from Table 2.I. In this way we obtain a lowfrequency factor of first or second order, which is required for PID control. If the model is more complex it is necessary to reduce (D*or to use a more complex controller.

Approximation of Fast Modes
There are several ways to approximate the fast modes. A simple way is to characterize the high-frequency part by its average residence time Torh.This is illustrated by the following example.

Exeupln 2.72-AppRoxrMATroN oF FASTMoDES Consider a system where the high-frequency factor is

G7,(s) -

( 1 + s 7 1 ) ( 1 +s ? 2 ) -----------:---:-

.g _ , r

( 1 + s ? 3 ) ( 1+ s ? a ) ( 1+ s ? r )

This system has the average residence time

Torh : Ts + Tq,* Ts * L - Tr - 72.

l
Compare this with Section 2.4, which shows how average residence times are computed. When using digital control half the sampling period should also be added to To,1.

Chapter 2. Process Models

Skogestad's Half Rule
Having simplified the low- and high-frequency factors we have obtained a lowfrequency factor of the form given by (2.55) or (2.58) and a characterization of the high-frequency factor by its average residence time Torh.Skogestad has suggested that the intermediate time constant 7, in (2.54) is approximated by adding T,12 to the time delay of the model andT,12 to its time constant. The reduced model then becomes

G ( s ): G ( s ):

1+

Kp
s ( 7+

T , 1 2U)-s(L+7,,,1,+7l2" )

Kp

(1 +

s?r)(1 +

s ( T z+

n-s(L+7"412).
T " , nl 2 ) )

(2.56)

The model error is characterized by Torn+ Trf 2, which means that it must be required that co*(To,n+ T,l2) is sufficiently small. A reasonable value is that it is less than 0.1 or 0.2, which means that the neglected dynamics has a phase lag of 6 Lo 12 degrees.

ApproximatinSg lowModesby Integrators
Modes that are much slower than (D* can be approximated by integrators. For example, if ot*T or @*Tt are larger than 5 to 10, the model (2.56) can be approximated by

G ( s ): G ( s ):

Kp
I+sQ+T",hl4e

s ( L + 7 " , 6 1 2 )*

K,
s ( 7 + T " , n l 2n)- s ( L + 7 " , 7 1 2 )

K

-s(L+7.412)

( 1+ s " r ) ( 1+ s ( T z+

K' - p.

-s(L+7.,6 l2

" " r ( 1 * s ( 7 2 * T o , hl 2 ) ) -

Another Model Representation

For somedesigntechniquesit is desirableto have modelsof the form

(2.57)

G(') G ( s ):

h
s+o - b . "r b z
s"1_a1s*az

(2.58)

which do not have any time delays. These forms can also be used for oscillatory

systems. The models given by (2.55) can be converted to the form (2.58) bV

using the approximation

q|
e-o'N

-

sT 12

l+srlz

(2.5e)

Time delays and zeros in the right half plane are the features of a system that ultimately limits the achievable performance. These properties are preserved by the above approximation.

58

2.8 Model Reduction

Examples Modelreductionwill now be illustrated with a few examples.

Exalrplp 2.13-Moopl RpnucrroN Consider a system described by the transfer function

G ( s ):

Kp ( 1+ s ) ( 1+ 0 . 1 s ) ( 1+ 0 . 0 1 s ) ( +1 0 . 0 0 l s ) '

(2.60)

We have asy : 3 and (Dr8o: 31.6, which gives the ranges of a*. Let us first consider model reduction for a design with (t)*:3. The low-frequency factor is

G'i \(s/) -

Ko 1*s

the mid-frequency factor is ?, - 0.1, and the average residence time of the high-frequency part is To,h :0.011. Skogestad's half rule gives the model

c(r) :

K-o^=

-1 +

n-o.o61s 1.05s

Requiring that a*(To,n+7,12) <0.2 we find that the model can be used for designswith al* < 3.3.
For a;* - 31.6 the low-frequency factor becomes

Gz(s): (,,1+ s,)f(,1o+ ^0 . 1 s ) '
rhe mid-frequency time constant is 7, : 0.01, and the average residence time ,rf the high-frequency part is then To,6 -=!-Q01. The half rule gives the model

c(r) :

,1-. ,*-

, ,Ko s)(1+

,"-o.oo6s. 0.105s)

l..-quiring that ot*(To,r,+ Trl2) < 0.2 we find that the model can be used for

: . - s ignswit h a l * < 3 3 .

The approximations are illustrated in Figure 2.40.

n

A Warning
. :.' fact that the step responses of two systems are similar does not imply ,rt the systems are similar under feedback control. This is illustrated by the .iorvingexample.

: ,.r\rplE 2.14-SnrnaR OpnN Loop - Dm'rpRpNr ClosED Loop - ..tems with the transfer functions

G ' ( r ): # ,

G 2 (:r )

100

( s + 1 ) ( 1+ 0 . 0 2 5 s ) 2

59

Chapter 2. Process Models

100
6'.,,^-1
a\
1o-'
_1
10 0

100

101

' 1 02 -

a\ -100
h0
li lAn
-200 10 - '

100

101

1 02 -

Figure 2.40 Bode plots of the original system (solid line) and the approximations for frequencies ar* < 3.3 (dashed) and @* < 33 (dash-dotted).

have very similar open-loop responses as illustrated in Figure 2.4I. The differences between the step responses are barely noticeable in the figure. The closed-loop systems obtained with unit feedback have the transfer functions

100

100

GuI: s + 101'

Gz"t ( 1 + 0 . 0 1 1 9 2 s ) (-10 . 0 0 1 5 1 9+s 0 . 0 0 0 5 r 9 3 s 2 ) '

The closed-loopsystems are very different since the system Pza is unstable._

It is also possible to have the opposite situation, namely, systems whose closedloop behavior are very similar even if their open-loop behavior are very different.

Exeuple 2.II-DTFFERENT OpnN Loop - Srnru,aRCLoSEDLoop The systems with the transfer functions

P r ( s- #) ,

P z ( r )- *

have very different open-loop properties because one system is unstable and

the other is stable. The closed-loopsystems obtained with unit feedback are,

however,

Pr"r(s) : 100 s*101

Pza(s): 100 s* 99'

which are very close.

f

The paradoxes in the examples can be resolved by considering the frequency ranges that are relevant for closed-loopcontrol. In Example 2.I4 the closed-loop system bandwidth of relevance is about 100 rad/s. This corresponds to time

60

2.9 Summary

Figure 2.41 Step responsesfor systems with the transfer functions G1(s) : 100i (s+ 1) ( d a s h e d )a n d G 2 ( s ) : 1 0 0 / ( ( s + 1 ) ( 1 - 0 . 0 2 5 s ) 2 )( s o l i d ) .
constants of about 0.01 s. A closer examination shows that the step responses in Figure 2.4I ar.eindeed quite different at that time scale even if the general appearance of the step responsesare very similar. In Example 2.15 the closedloop bandwidth is also about 100 rad/s, which corresponds to a time scale of 0.01 s. At that time scale the open-loop systems are very similar even if one model is stable and the other unstable. It is a good rule to be aware of the relevant frequency ranges and to analyze the Bode plots. This is one of the main reasons for using frequency response.

2.9 Summary

Modeling is an important aspect of controller tuning. The models we need

should describe how the process reacts to control signals. They should also

describe the properties of the disturbances that enter the system. Most work

on tuning of PID controllers has focusedon the processdynamics, which is also

reflected in the presentation in this chapter.

A number of methods for determining the dynamics of a processhave been

presented in this chapter. Some are very simple: they are based on a direct

measurement of the step response and simple graphical constructions. Others

are based on the frequency response. It has been shown that very useful infor-

mation can be generated from relay feedback experiments. Such experiments

are particularly useful becausethe processis brought into self-oscillation at the

ultimate frequency, which is of considerable interest for design of controllers.

The simple methods are useful in field work when a controller has to be

tuned and few tools are available. The methods are also useful to provide

understanding as well as being references when more complicated methods

are assessed.We have also presented more complicated methods that require

significant computations.

Models of different complexity have been presented. Many models were

characterized by a few parameters. Such models are useful for many purposes

)

and are discussed in Chapter 6. When using such models it should be kept in

mind that they are approximations.

61

Chapter 2. Process Models
When deriving the models we also introduced two dimension-free quantities, the normalized time delay r and the gain ratio r. These parameters make it possible to make a crude assessment of the difficulty of controlling the process. Processeswith small values of r and t are easy to control. The difficulty increases as the values approach 1. T\rning rules based on r and K are provided in Chapter 7.
To summarize; When deriving a simple model to be used for PID controller tuning, it is important to ensure that the model describes the process well for the typical input signals obtained during the processoperations. The amplitude and frequency distribution of the signal is of importance. Model accuracy may be poor if the process is nonlinear or time varying. Control quality can be improved by gain scheduling or adaptive control. It is also important to know what kind of disturbances are acting on the system and which limitation they impose.
2.10 Notesand References
Early efforts in modeling using differential equations were made independently by [Maxwell, 1868] and [Vyshnegradskii, 1876] in connection with analysis of engines with centrifugal governors. The idea of modeling a processby its reaction curve (step response) emerged in the 1930s. The reaction curve was approximated by an FOTD model (2.18) in [Callender et al., 1936]. The reaction curve was also used in [Ziegler and Nichols, 1942]. Frequency response arguments were used in [Ivanoff, 1934] who investigated a temperature-control loop using the model given by (2.32). Frequency response was also used by [Ziegler and Nichols, l942l.An early reference to the notion of block diagram is found in [Mason and Philbrick, 19401.
Process modeling is a key element in understanding and solving a control problem. Good presentations of modeling are found in standard textbooks on control, such as [Eckman,,7945; Buckley, 1964; Cannon, 7967; Smith, L972; Luyben, 1990;Shearer and Kulakowski, 1990].The books [Oquinnaike and Ray, 1994; Marlin,2000; Bequette,2003; Rawlings and Ekerdt,,2OO2;Seborg et al., 20041are of particular interest for processcontrol. These books have much material on many different modeling techniques. Similar presentations are given in [Gille et a1.,1959;Harriott, 1964;Oppelt, 1964;Takahashi et al.,1972; Deshpande and Ash, 1981; Shinskey, 1996; Stephanopoulos, 1984; Htigglund, 1991]. The books [T\rcker and Wills, 1960] and [Lloyd and Anderson, 79771are written by practitioners in control companies. There are also books that specialize in modeling for control system design; see [Wellstead, 1979; Nicholson, 1980; Nicholson, 1981; Close and Frederick, 19931.
By the mid-1950s frequency response was very well established as manifested by a symposium organized as part of the annual meeting of the American Society of Mechanical Engineering in 1953. The proceedings of the symposium were published in the book [Oldenburg, 1956]. A nice overview of step and frequency response methods is given in the paper [Rake, 19801.Additional details are given in [Strejc, 1959; Anderssen and White, LgTl; Anderssen and White, 19701.The doublet method is discussed in [Shinskey, 1994], and the method of
62

2.10 Notes and References
moments is described in [Gibilaro and Lees, 1969]. The relay method is introduced in [Astrdm and Hiigglund, 1984b], and it
is elaborated in [Hagglund and Astrcim, 1991; Schei, 7992; Hang and Astrdm, 2002]. The describing function method is well documented in [Atherton, 1975] and [Gelb and Velde, 1968]-A method to estimate what is today called an ARX model was developed in [Astr6m an_dBohlin, 1965] and applied to modeling and control of paper machines in [Astrdm, 1967]. There are many books on parameter estimation: [Ljung and S0derstrtim, 1983; Ljung, 1998; Sdderstriim and Stoica, 1989;Bohlin, 1991;Johansson,1993].Many useful practical aspects on system identification are given in [Isermann, 1980].
Modeling has been greatly enhanced by simulation. The first simulation of a control system with PID control was made at the University of Manchester using a copy of the differential analyzer developed by Vannevar Bush; see [Callender et a1.,1936].The differential analyser was also used in [Ziegler and Nichols, 19421to develop tuning rules. Pneumatic simulators built from components of pneumatic controllers were used early by equipment manufacturers. The first electronic analog computer developedby Philbrick had a major impact, and the use of simulation increased drastically. The rapid development of digital computing hqs made it possible for every engineer to have simulation tools on his lap; see [Astrcim et al., 1998]. Many of the simulation programs used today mimic the diagrams used to program early analog computers in the 1950s.There are major efforts underway to combine experiencesof process modeling with advances in computing science to develop a new generation of languages and tools for processmodeling; see [Elmqvist et a1.,1998]and [fillea
20011.
There are many methods for model reduction. Early work was reported in [Ziegler and Nichols, 1943]. A nice survey is found in [Glovea 1990]. One method that is geared to PID control is presented in [Frrihr and Orttenburger, 19821.The half-rule was developed in [Skogestad, 2003] as a simple method that works well for the purpose of tuning PID controllers.
63

PID Control

3.1 Introduction
The PID controller is by far the most common control algorithm. Most feedback loops are controlled by this algorithm or minor variations of it. It is implemented in many different forms, as a stand-alone controller or as a part of a DDC (Direct Digital Control) package or a hierarchical distributed process control system. Many thousands of instrument and control engineers worldwide are using such controllers in their daily work. The PID algorithm can be approached from many different directions. It can be viewed as a device that can be operated with a few rules of thumb, but it can also be approached analytically.
This chapter gives an introduction to PID control. The basic algorithm and various representations are presented in detail. A description of the properties of the controller in a closed loop based on intuitive arguments is given. The phenomenon of reset windup, which occurs when a controller with integral action is connectedto a processwith a saturating actuator, is discussed,including several methods to avoid it. Filters to reduce noise influence and means to improve set-point responses are also provided.
Implementation aspects of the PID controller are presented in Chapter 13.

3.2 ThePIDController

The "textbook" version of the PID algorithm can be described as:

u ( t ): r

1i
( r 1 r +l Ti .l

e(r)dr-rrary)

(3.1)

0

where u is the control signal and e is the control error (u : yro- y).The control signal is thus a sum of three terms: the P-term (which is proportional to the error), the I-term (which is proportional to the integral of the error), and the D-term (which is proportional to the derivative of the error). The controller

64

Controller

3.2 The PID Controller

Figure 3.1 Block diagram of a simple feedback loop.
parameters are proportional gain K, integral time ?,, and derivative time ?a.

Proportional Action

In the caseof pure proportional control, the control law of Equation 3.l reduces

to

u(t):Ke(t)*ua.

(3.2)

The control action is simply proportional to the control error. The variable rz6 is a bias or a reset. When the^control error e is zero,the control variable takes the value u(t) - u6. Bias u6 is often fixed to (u-ur*u-i.) f 2,but can sometimes be adjusted manually so that the stationary control error is zero at a given set
point.

Statie Analysis Several properties of proportional control can be understood by the following argument, which is based on pure static considerations. Consider the simple feedback loop, shown in Figure 3.1, and composed of a process and a controller. Assume that the controller has proportional action and that the process is modeled by the static model

x:Kp(u+d).

(3.3)

where r is the processvariable, u is the control variable, d is a load disturbance, and Ko is the static process gain. The following equations are obtained from the block diagram.

J:x*n

x - Kp(u * d)

(3.4)

u-K(y,p-y)*ut.

where n is measurement noise. Elimination of intermediate variables gives the following relation between process variable r, set point yrp, Ioad disturbance d, and measurement noise n:

*:

KKol\K,
ffi(t,,

- "l + f* ftt+@+ u6).

(3.5)

65

Chapter 3. PID Control
Figure 3.2 Simulation of a closed-loop system with proportional control. The process transfer function is G(s) : (s * 1)-3. The upper diagram shows set point !,p:1 and process output y for different values of controller gain K. The lower diagram shows control signal u for different controller gains.
Product K Ko is a dimensionless number called the loop gain. Several interesting properties of the closed-loopsystem can be read from Equation 3.5. First assume that n and u6 are zero. Then the loop gain should be high in order to ensure that processoutput r is closeto set point !rp. A high value of controller gain K also makes the system insensitive to load disturbance d. However, if n is nonzero, it follows from Equation 3.5 that measurement noise n influences the process output in the same way as set point !rp. To avoid making the system sensitive to measurement noise, the loop gain should not be made too large. Further, the controller bias u6 influences the system in the same way as a load disturbance. It is, therefore, obvious that the design of the loop gain is a trade-off between different control objectives and that there is no simple answer to what loop gain is the best. This will depend on which control objective is the most important.
It also follows from Equation 3.5 that there will normally be a steadystate error with proportional control. This can be deduced intuitively from the observation following from Equation 3.4 that the control error is zero only when u. - rl.bin stationarity. The error, therefore, can be made zero at a given operating condition by a proper choice of the controller bias u6.
The static analysis given above is based on the assumption that the process can be describedby a static model. This leaves out someimportant properties of the closed-loopsystem dynamics. The most important one is that the closed-loop system will normally be unstable for high-loop gains if the process dynamics are considered. In practice, the maximum loop gain is thus determined by the process dynamics. One way to describe process dynamics leads to descriptions like Equation 3.3 where the process gain is frequency-dependent. This was discussedin Chapter 2.
A typical example of proportional control is illustrated in Figure 3.2. The figure shows the behavior of the process output and the control signal after
66

3.2 The PID Controller

Figure 3.3 Implementation of integr:al action as positive feedback around a lag.

a step change in the set point. The steady-state error can be computed from Equation 3.5. The bias term u6, t}'e load d, and the noise n are all zero in the simulation. With a controller gain K - 1 and a static process gain Kp : l, the error is therefore 50 percent. The figure shows that the steady-state error decreaseswith increasing controller gain as predicted by Equation 3.5. Notice also that the response becomesmore oscillatory with increasing controller gain. This is due to the process dynamics.

Integral Action
The main function of the integral action is to make sure that the process output agrees with the set point in steady state. With proportional control, there is normally a control error in steady state. With integral action, a small positive error will always lead to an increasing control signal, and a negative error will give a decreasing control signal no matter how small the error is.
The following simple argument shows that the steady-state error will always be zero with integral action. Assume that the system is in steady state with a constant control signal (us) and a constant error (ee). It follows from Equation 3.1 that the control signal is then given by

,o:" (t,. Ar)

As long &s s # 0, this clearly contradicts the assumption that the control signal uq is constant. A controller with integral action will always give zero steady-state error.
Integral action can also be visualized as a device that automatically resets the bias term u6 of a proportional controller. This is illustrated in the block dihgram in Figure 3.3, which shows a proportional controller with a reset that is adjusted automatically. The adjustment is made by feeding back a signal, rvhich is a filtered value of the output, to the summing point of the controller. This was actually one of the early inventions of integral action, or "automatic reset," as it was also called. The implementation shown in Figure 3.3 is still used by many manufacturers.
Simple calculations show that the controller in Figure 3.3 gives the desired results. The following equation is obtained from the block diagram:

Hence,

u-

Ke * I :

Ti

dI dt

+

I.

-' 'd I : Ke, dt

67

Chapter 3. PID Control

11.
LI

_
-

T,

Ti: -

Figure 3.4 Simulation of a closed-loop system with proportional and integral control. The process transfer function is G(s) : (s * 1)-3, and the controller gain is K : 1. The upper diagram shows set point !sp : t and process output y for different values ofintegral time 7; . The lower diagram shows control signal a for different integral times.

and we find that

u-K/

( n*

L
i

f
.l

, ( r ) a\)r

which is a PI controller. The properties of integral action are illustrated in Figure 3.4, which shows
a simulation of a system with PI control. The proportional gain is constant, K : l, and the integral time is changed. The caseTi: oo correspondsto pure proportional control. This case is identical to the case K : 1 in Figure 3.2, where the steady-state error is 50 percent. The steady-state error is removed when ?, has finite values. For large values of the integration time, the response creeps slowly towards the set point. The approach is approximately exponential with time constant Ti I K Kp. The approach is faster for smaller values of fl but is also more oscillatorv.

Derivative Action
The purpose of the derivative action is to improve the closed-loop stability. The instability mechanism can be described intuitively as follows. Because of the process dynamics, it will take some time before a change in the control variable is noticeable in the process output. Thus, the control system will be late in correcting for an error. The action of a controller with proportional and derivative action may be interpreted as if the control is made proportional to the predicted process output, where the prediction is made by extrapolating the error by the tangent to the error curve (see Figure 3.5). The basic structure of a PD controller is
u ( t ) :x ( r l l * r a # )

6B

3.2 The PID Controller
e(t + T4)
e(t)+ ro#
Figure 3.5 Interpretation of derivative action as predictive control, where the prediction is obtained by linear extrapolation.
T6 -- 0.7
Figure 3.6 Simulation of a closed-loop system with proportional, integral, and derivative control. The processtransfer function is G(s) : (s* 1)-3, the controller gain is K : 3, and the integral time is 4 :2. The upper diagram shows set point lsp: l and processoutput y for different values of derivative time 7a. The lower diagram shows control signal u for different derivative times.
A Taylor series expansion of e(t a Ta) gives
e(t+Ta)oe(t)+rrry
The control signai is thus proportional to an estimate of the control error at time Ta ahead, where the estimate is obtained by linear extrapolation. The properties of derivative action are illustrated in Figure 3.6, which shows a simulation of a system with PID control.
Controller gain and integration time are kept constant, K : 3 and Ti : 2, and derivative time Ta is changed. For T6 - 0 we have pure PI control. The closed-loopsystem is oscillatory with the chosen parameters. Initially damping increases with increasing derivative time but decreasesagain when derivative time becomestoo large.
69

Chapter 3. PID Control

Figure 3.7 Classical implementation of derivative action.

Classicallmplementationof DerivativeAction
In Figure 3.3 it was shown that integral action originally was implemented by positive feedbackaround a first-order lag. Derivative action was also origrnally implementedusing a first-orderlag as is shownby the block diagram in Figure 3.7. The Laplace transform of the output is given by

r/(,:)(r-#-)"t,1 :#E(s)

(8.6)

The systemthus has the transfer function G(r) : sTl(1 + sT). Notice that filtering is obtained automatically with this implementation.

AlternativeRepresentations

The PID algorithm given by Equation 3.1 can be representedby the transfer

function

c ( s ) - " ( t */

1

\

- +sra).

(B.z)

A slightly different version is most commonin commercialcontrollers.This controlleris describedbv

c'(,:)K'(t*#) e+sro)

(3.8)

The two controller structures are presented in block diagram form in Figure 3.8. The controller given by Equation 3.7 is called non-interacting, and the one given by Equation 3.8 interacting. The reason for this nomenclature is that in the controller (3.7) the integral time ?, doesnot influence the derivative part, and the derivative time 74 does not influence the integral part. The parts are thus non-interacting. In the interacting controller, the derivative time Q does influence the integral part. Therefore, the parts are interacting.
The interacting controller (3.8) can always be represented as a non-interacting controller whose coefficients are given by

K : K''i :r'l
t;

Ti:Ti+rd

mr d :

riri r! +q

(3.e)

70

3.2 The PID Controller

Non-interacting form

Interacting form Figure 3.8 Interacting and non-interactingform of the PID algorithm.

An interacting controller of the form (3.8) that corresponds to a non-interacting controller can be found onlv if

Ti ) 4Ta.

Then,

K,

K 2

(t+

6:n;ft)

r! _ T i 2

(t*

,/tr- 4F;n)

(3.10)

r:

_Ti 2

(-Jr-4Fil4)

The non-interacting controller given by Equation 3.7 is more general, and we will use that in the future. It is, however, sometimes claimed that the interacting controller iq easier to tune manually.
There is also a historical reason for preferring the interacting controller. Early pneumatic controllers were easier to build using the interacting form. See Chapter 13. When the controller manufacturers changed technology from pneumatic to analog electric and, finally, to digital technique, they kept the interactive form. Therefore, the interacting form is most common among singleloop controllers.
It is important to keep in mind that different controllers may have different structures. It means that if a controller in a certain control loop is replaced by another type of controller, the controller parameters may have to be changed. Note, however, that the interacting and the non-interacting forms are different only when both the I and the D parts of the controller are used. If we only use the controller as a P, PI, or PD controller, the two forms are equivalent. Yet

7T

Chapter 3. PID Control

another representation of the PID algorithm is given by

C"(r):k*li+rto

(3.11)

The parameters are related to the parameters of standard form through

Iz: K

,^"i -- K
Ti

ka : KTa.

(3.12)

The representation (3.11) is equivalent to the standard form, but the parameter values are quite different. This may cause great difficulties for anyone who is not aware of the differences, particularly if parameter lf ki is called integral time and k6 derivative time. The form given by Equation 3.11 is often useful in analytical calculations because the parameters appear linearly. The representation also has the advantage that it is possible to obtain pure proportional, integral, or derivative action by finite values of the parameters.
Summarizing, we have thus found that there are three different forms of the PID controller.
o The standard or non-interacting form given by Equation 3.7.
. The series or interacting form given by Equation 3.8.
. The parallel form given by Equation 3.11.

The standard form is sometimes called the ISA algorithm, or the ideal algorithm. The proportional, integral, and derivative actions are non-interacting in the time domain. This algorithm admits complex zeros, which is useful when controlling systems with oscillatory modes.
The series form is also called the classical form. This representation is obtained naturally when a controller is implemented as an analog device based on a pneumatic force balance system. The name classical reflects this. The series form has an attractive interpretation in the frequency domain because the zeros correspond to the inverse values of the derivative and integral times. All zeros of the controller are real. Pure integral or proportional action cannot be obtained with finite values of the controller parameters.
The parallel form is the most general form because pure proportional or integral action can be obtained with finite parameters. The controller can also have complex zeros. In this way it is the most flexible form. However, it is also the form where the parameters have little physical interpretation.

Summary
The PID controller has three terms. The proportional term P corresponds to proportional control. The integral term I gives a control action that is proportional to the time integral of the error. This ensures that the steady-state error becomes zero. The derivative term D is proportional to the time derivative of the control error. This term allows prediction of the future error. There are many variations of the basic PID algorithm that will substantially improve its performance and operability. They are discussed in the following sections.

72

3.3 Filtering the Deriuatiue

3.3 Filteringthe Derivative

A drawback with derivative action is that an ideal derivative has very high gain for high-frequency signals. This means that high-frequency measurement noise will generate large variations of the control signal. To seethis we consider a measured output

J:sint*asintDt,

where the first term is the useful signal and the secondterm represents noise. The ratio of noise to signal is thus o. The derivative term of the controller is then

D - KTa# : KTa(corst aa coas t) '

(3.13)

The amplitude of the signal is KT6, and the amplitude of the noise is KTaao. The ratio of noise and signal ts aat. This can be arbitrarily large even if a is small if the frequency is sufficiently high. The effect of measurement noise can to some extent be eliminated by implementing the derivative term as

.nI -) -' : - l + ssTKi lTNar ' u

(3.14)

This can be interpreted as an ideal derivative that is filtered using a firstorder system with the time constant TaI N .For small s the transfer function is approximately sKT6, and for large s it is equal to KN. The approximation acts as a derivative for low-frequency signal components, and the high-frequency gain is limited to KN. High-frequency measurement noise is amplified at most by a factor KN . Tlpical values of N are 2 to 20. Notice that the implementation of the derivative given in Figure 3.7 automatically gives a limitation of the high-frequency gain; see Equation 3.6.
The transfer function of a PID controller with a filtered derivative is

c(s:)" ('. # .;#;A

(B1b)

The high-frequency gain of the controller is K(1 + N). High frequency measurement noise can thus generate significant variations in the control signal. It is therefore advantageous to use heavier filtering.
Instead of filtering only the derivative it is possible to filter the measured signal and apply the filtered signal to an ideal PID controller. The equivalent controller transfer function is

c , q:

c ( s ) G y ( r:) "

(t .

#

+ rrd) r+sT1+@7^1)'12'

(3.16)

when a second-orderfilter with relative damping ( : Ilt/2 is used. The filtertime constant TS is typically chosen asT;lN for PI control or as TalN for PID control, where N ranges from 2 to 20.
It follows from (3.16) that the controller gain goes to zero for high frequencies. This property, which is called high frequency roll-off, guarantees that high-frequency measurement noise wiII not generate large control signals. High-frequency roll-off also increases the robustness of the closed loop
ffiem.

73

Chapter 3. PID Control

3.4 Set-PoinWt eighting

The control system in Figure 3.1is called a system with error feedback because the controller acts on the error, which is the difference between the set point and the output. A more flexible structure is obtained by treating the set point and the process output separately. A PID controller of this form is given by

'f

u(t) :

K- -l/n r + ; V

r
t'

i

Jl

n

z
(t

*
)d

s

*

T

a-

de
idl .' t

a
/

\

0

(3.17)

where the error in the proportional part is

p -- b!rp - !'

(3.18)

and the error in the derivative part is

d:cJtp-J.

(3.le)

The error in the integral part must be the true control error

:ltp-!'

in order to avoid steady-state control errors. The controllers obtained for different values.-of b and c will respond to load disturbances and measurement noise in the same way. The response to set-point changes will depend on the
values of b and c, which are called set'point weights. The properties of a system where the controller has set-point weighting is
illustrated in Figure 3.4, which shows the response of a PID controller to setpoint changes, Ioad disturbances, and measurement errors for different values of b. The figure shows clearly the effect of chan$ng b. The overshoot for setpoint changes is smallest for b : 0, which is the case where the reference is only introduced in the integral term, and increases with increasing b. Notice that a simulation like the one in Figure 3.4 is useful in order to give a quick assessment of the responsesof a closed-loopsystem to set-point changes, load
disturbances, and measurement errors. The parameter c is normally chosen equal to zero to avoid large transients
in the control signal due to sudden changes in the set point. An exception is when the controller is the secondary controller in a cascade coupling (see Section t2.4). In this case,the set-point changes smoothly becauseit is given by the primary controller output. Notice that if the integral action is implemented with positive feedback around a lag as in Figure 3.3, the parameter b is equal
to one. The controller with b : 0 and c : 0 is sometimes called an I-PD controller,
and the controller with b: I and c : 0 is sometimes called a PI-D controller. We prefer to stick to the generic use of PID and give the parameters b and c, thereby making a small contribution towards reduction of three-letter abbre-
viations.

74

Set point J.spand process output y
O: I
b :0.5 b:0
Control signal b:7

3.4 Set-Point Weighting

Load disturbance d and measurement noise n

Figure rors for

3'9 The response to set-point changes, load disturbances, different values of set-point weighting 6.

and

measurement

er-

Figure 3'10 Block diagram degree-of-freedom structure.

of a The

simple feedback transfer function

loop with Pis) is

a pID controller having a twothe process transfer function.

FacthorigeenuItunerresorretloh3dlrea.'1wAb0lgow:biclhvokJeecsrdnkepiab*dtgyhiaryeEag.mqrtaNruamoainnttsiicofFfoeenirgr tu3ahfr.uaeLsnt7yc3stta.hti1oeni,snmdthtdchwe(ieasitcLg)horrraniosPmtrrIgoDilivdlseecernonfiononbtuirytltooipoln(u8ngits.se7irs()in8aigs.an1teleidgnda)edarawngthdeivede(ngnfr.to1hbm9ey)

b+h+scTa
F(s) -

cTiT6s2*bsTi+I

1+;h *sTa TiT6s2*s4+1

(3.20)

to

Chapter 3. PID Control
System with Two Degrees of Freedom
In general, a control system has many different requirements. It should have good transient response to set-point changes, and it should reject load disturbances and measurement noise. For a system with error feedback only, an attempt is made to satisfy all demands with the same mechanism. Such systems are called one-degree-of-freedomsystems.
The system shown in Figure 3.10 is said to have two degrees of free{qm because the signal path from the set point to the control signal is different from the signal path from measured value to control signal.
There are many possible configurations of systems with two degreesof freedom. The system shown in Figure 3.10 is only one alternative. An extended use of structures with two degreesof freedom is a very natural extension of the PID controller. The key idea is to let the controller C be a PI or a PID controller but to use more flexible feedforward than the standard PID controller permits. This will be discussed more fully in Chapter 5.

3.5 IntegratoWr indup

Although many aspects of a control system can be understood based on linear theory, some nonlinear effects must be accounted for. All actuators have limitations: a motor has limited speed, a valve cannot be more than fully opened or fully closed, etc. For a control system with a wide range of operating conditions, it may happen that the control variable reaches the actuator limits. When this happens the feedback loop is broken and the system runs as--qn op-enloop because the actuator will remain at its limit independently of the process output. If a controller with integrating action is used, the error may continue to be integrated if the algorithm is not properly designed. This means that the integral term may become very large or, colloquially, it "winds up." It is then required that the error has opposite sign for a long period before things return to normal. The consequenceis that any controller with integral action may give large transients when the actuator saturates.

Exeuplp 3.l-Ilr,usrRATroN oF INTEGRAToRWrNoup

Figure 3.11 shows the control signal, the measurement signal, and the set point

in a case where the control signal becomes saturated. After the first set-point

change, the control signal increases to its upper limit Ltrmax.Thiscontrol signal

is not large enough to eliminate the control error. Therefore, the integral of

the control error, and the integral part of the control signal, increases. Since

the desired control signal a increases, there is a difference between the desired

control signal and the true control signal uo,rt.

Figure 3.11 shows what happens when after a certain time the set point is

Iowered to a level where the controller is able to eliminate the control error.

Since the sign of the control error becomesnegative, the control signal starts to

decrease,but since the desired control signal u is above the limit ttrmaxth, e true

control signal uo,r1is stuck at the limit for a while and the response becomes

delayed.

T

76

Measurement signal and set point

3.5 Integrator Windup

Control signal
umax

Figure 3.11 Illustration of integrator windup.

The following example shows some other effects that may occur due to integrator windup when the process is unstable.

Exavpln 3.2-h,lusrRATroN oF INTEGRAToRWrunup

The windup phenomenon is illustrated in Figure 3.L2, which shows control

of an integrating process with a PI controller. The initial set-point change

is so large that the actuator saturates at the high limit. The integral term

increases initially because the error is positive; it reaches its largest value at time / : 10 when the error goesthrough zero.The output remains saturated at

this point because of the large value of the integral term. It does not leave the

saturation limit until the error has been negative for a sufficiently long time to

Iet the integral part come down to a small level. Notice that the control signal

bounces between its limits several times. The net effect is a large overshoot

and a damped oscillation where the control signal flips from one extreme to

the other. The output finally comes so close to the set point that the actuator

does not saturate. The system then behaves linearly and settles.

n

Integrator windup may occur in connection with large set-point changes, or it may be caused by large disturbances or equipment malfunctions. Windup can also occur when selectors are used so that several controllers are driving one actuator. In cascadecontrol, windup may occur in the primary controller when the secondary controller is switched to manual mode, uses its local set point, or if its control signal saturates. See Section I2.4.
The phenomenon of windup was well known to manufacturers of analog controllers, who invented several tricks to avoid it. They were described under labels like preloading, batch unit, etc. Although the problem was well understood,there were often limits imposed becauseof the analog implementations. The ideas were often kept as trade secrets and not much spoken about. The croblem of windup was rediscovered when controllers were implemented digItally and several methods to avoid windup were presented in the literature. In the following section we describe several of the ideas.

77

Chapter 3. PID Control
0.1
-0.1
Figure 3.12 Illustration of integrator windup. The diagrams show process output y, set point yro, control signal z, and integr:al part I.
Set-Point Limitation One way to try to avoid integrator windup is to introduce limiters on the setpoint variations so that the controller output will never reach the actuator bounds. This often leads to conservative bounds and limitations on controller performance. Further, it does not avoid windup caused by disturbances.
Incremental Algorithms In the early phases of feedback control, integral action was integrated with the actuator by having a motor drive the valve directly. In this case, windup is handled automatically because integration stops when the valve stops. When controllers were implemented by analog techniques, and later with computers, many manufacturers used a configuration that was an analog of the old mechanical design. This led to the so-called vg]ocily algorithms, discussed in Chapter 13. In this algorithm the rate of change of the control signal is first computed and then fed to an integrator. In some cases this integrator is a motor directly connected to the actuator. In other cases the integrator is implemented internally in the controller. With this approach it is easy to handle mode changes and windup. Windup is avoided by inhibiting the integration whenever the output saturates. This method is equivalent to back-calculation, which is described below. If the actuator output is not measured, a model that computes the saturated output can be used. It is also easy to limit the rate of change of the control signal.
7B

3.5 Integrator Windup Actuator

Figure 3.lS PID controller with anti-windup.

Back-Calculation and Tracking

Back-calculation works as follows. When the output saturates, the integral

term in the controller is recomputed so that its new value gives an output at the

saturation limit. It is advantageous not to reset the integrator instantaneously

but dynamically with a time constant fi.

Figure 3.13 shows a block diagram of a PID controller with anti-windup

based on back-calculation. The system has an extra feedback path that is gen-

erated by measuring the actual actuator output, or the outp_utof a mathemat-

ical model of the saturating actuator, and forming an error signal (er) as the

difference between the output of the controller (u) ai-d the actuator output (u).

The signal e, is fed to the input of the integrator through gain 11T;. The signal

is zero when there is no saturation. Thus, it will not have any effect on the

normal operation when the actuator does not saturate. When the actuator sat-

urates, the signal a rg different from zero. The normal feedback path around the process is broken because the process input remains constant. There is,

however, a feedback path around the integrator. Because of this, the integra-

tor output is driven towards a value such that the integrator input becomes

zero. The integrator input is

IK

-o

'- L - o

Ti"'

rvhere e is the control error. Hence.

KT,

s:-

n

f,

in steady state. Since s: u - u, it follows that

"l

n:ttrrim*+n,

l.

ri'here uhm is the saturating value of the control variable. Since the signals
rl
.' and u1;- have the same sign, it follows that u is always larger than u1i- in

79

Chapter 3. PID Control
0.15
0.05
-0.05
0
-0.4
-0.8
Figure 3.14 Controller with anti-windup applied to the system of Figure 3.12. The diagrams show process output y, set point y"o, control signal z, and integral paft L
magnitude. This prevents the integrator from winding up. The rate at which the controller output is reset is governed by the feedback gain,IIT,, where T7 can be interpreted as the time constant, which determines how quickly the integral is reset. We call this the tracking time constant.
Figure 3.14 shows what happens when a controller with anti-windup is applied to the system simulated in Figure 3.12. Notice that the output of the integrator is quickly reset to a value such that the controller output is at the saturation limit and the integral has a negative value during the initial phase when the actuator is saturated. This behavior is drastically different from that in Figure 3.L2, where the integral has a positive value during the initial transient. Also notice the drastic improvement in performance compared to the ordinary PI controller used in Figure 8.I2.
The effect of chan$ng the values of the tracking time constant is illustrated in Figure 3.15. tr'rom this figure, it may thus seem advantageous to always choose a very small value of the time constant because the integrator is then reset quickly. However, some care must be exercised when introducing antiwindup in systems with derivative action. If the time constant chosen is too small, spurious errors can cause saturation of the output, which accidentally resets the integrator. The tracking time constant fi should be larger than T6 and smaller than Ti. A rule of thumb that has been suggested is to choose T7:1fTfi.
80

3.5 Integrator Windup

Figure 3.15 The step response of the system in Figure 3.12 for different values of the trackingtime constantTl. The upper curve shows processoutput y and set point ysp,and the lower curve shows control siqnal u.
Isp
v
w

Figure 3.16 Block diagram and simplifled representation of PID module with tracking signal.

l

I

Controllers with a Tracking Mode

e

-\ controller with back-calculation can be interpreted as having two modes:

,d

:he normal control mode, when it operates like an ordinary controller, and a

,'S

:racking mode,,when the controller is tracking so that it matches given inputs

rY1

.ind outputs. Since a controller with tracking can operate in two modes, we

ri-

nay expect that it is necessary to have a logical signal for mode switching.

oo

However, this is not necessary, because tracking is automatically inhibited

Ilr.
T,i

;r hen the tracking signal ru is equal to the controller output. This can be used ii'ith great advantage when building up complex systems with selectors and

)se

:ascade control.

Figure 3.16 shows a PID module with a tracking signal. The module has

81

Chapter 3. PID Control

SP MV PID TR

Actuator model

Actuator

Figure 3.17 Representation of the controller with anti-windup in Figure 3.13 using the basic control module with tracking shown in Figure 3.16.

three inputs: the set point, the measured output, and a tracking signal. The new input TR is called a tracking signal because the controller output will follow this signal. Notice that tracking is inhibited when rD: tr. Using the module the system shown in Figure 3.13 can be presented as shown in Figure 3.17.

The Proportional Band
The notion of proportional band is useful in order to understand the windup effect and to explain schemes for anti-windup. The proportional band is an interval such that the actuator does not saturate if the instantaneous value of the process output or its predicted value is in the interval. For PID control without derivative gain limitation, the control signal is given by

u-K(by,p-t)+I-KTa

dy

dt

Solving for the predicted processoutput

(3.21)

Jp:y+roH,

gives the proportional band (yt,yn) as

Jl:

o, j s p *. I - L r ^ o * X

lt

: o, ! " p ' l

I -u^in K

(3.22)

and u-i,r, Ltrmaaxre the values of the control signal for which the actuator saturates. The controller operates in the linear mode, if the predicted output is in the proportional band. The control signal saturates when the predicted output is outside the proportional band. Notice that the proportional band can be shifted by changing the integral term.
To illustrate that the proportional band is useful in understanding windup, we show the proportional band in Figure 3.18 for the system discussed in Example 3.2. (Compare with Figure 3.t2.) The figure shows that the proportional band starts to move upwards becausethe integral term increases.This implies that the output does not reach the proportional band until it is much larger than the set point. When the proportional band is reached the control signal

82

3.5 Integrator Windup

0.1 0
-0.1

Figure 3.18 The proportional band for the system in Example 3.2. The upper diagram shows process output y and the proportional band. The lower diagram shows control signal

&.

Tt :0.1

Tt:0.3

Figure 3.19 The proportional band and the process output y for a system with conditional integration and tracking with different tracking time constants 4.
decreasesrapidly. The proportional band changes so rapidly, however, that the output very quickly moves through the band, and this process repeats several times.
The notion of proportional band helps us to understand several schemes for anti-windup. Figure 3.19 shows the proportional band for the system with tracking for different values of the tracking time constant ?,. The figure shows that the tracking time constant has a significant influence on the proportional band. Because of the tracking, the proportional band is moved closer to the processoutput. How rapidly it does this is governed by the tracking time constant ?r. Notice that there may be a disadvantage in moving it too rapidly, since the predicted output may then move into the proportional band because of noise and cause the control signal to decreaseunnecessarily.
83

Chapter 3. PID Control
0.02
-0.02
Figure 3.20 Simulation of the system in Example 3.2 with conditional integr:ation. The diagrams show the proportional band, process output y, control signal z, and integral part .L
Conditional Integration Conditional integration is an alternative to back-calculation or tracking. In this method integration is switched off when the control is far from steady s,!qte. Integral action is thus only used when certain conditions are fulfilled; otherwise the integral term is kept constant. The method is also called integrator clamping.
The conditions when integration is inhibited can be expressed in many different ways. Figure 3.20 shows a simulation of the system in Example 3.2 with conditional integration such that the integral term is kept constant during saturation. A comparison with Figure 3.19 shows that, in this particular case, there is very little difference in performance between conditional integration and tracking. The different wind-op schemes do, however, move the proportional bands differently.
A few different switching conditions are now considered. Orre simple approach is to switch off integration when the control error is large. Another approach is to switch off integration during saturation. Both these methods have the disadvantage that the controller may get stuck at a non-zero control error if the integral term has a large value at the time of switch-off.
A method without this disadvantage is the following. Integration is switched off when the controller is saturated and the integrator update is such that it causesthe control signal to becomemore saturated. Suppose,for example, that the controller becomes saturated at the upper saturation. Integration is then
84

3.5 Integrator WinduP

Figfrre 3.21 Adjustment of the proportional band using cut-back parameters. The diaglams show the proportional band, set point 1lsp,plocess output y, control signal u, and
integral part 1.

switched off if the control error is positive, but not if it is negative. Some conditional integration methods are intended mainly for startup of
batch processes,when there may be large changes in the set point' One particular version, used in temperature control, sets the proportional band outside the set point when there are large control deviations. The offset can be used to adjust the transient response obtained during startup of the process. The parameters used are called cutback or preload (see Figure 3.21). In this syslem the proportional band is positioned with one end at the set point and the other end towards the measured value when there are large variations. These
methods may give windup during disturbances'

Series lmplementation

In Figure 3.3, we showed a special implementation of a controller in interact-

ing form. To avoid windup in this controller we can incorporate a model of the

saturation in the system as shown in Figure 3.22a. Notice that in this imple-

mentation the tracking time constant T, is the same as the integration time

l
I

2,. This value of the tracking time constant is often too large. In Figur e 3.22a, the model of the saturation will timit the control signal

j

directly. It is important, therefore, to have a good model of the physical saturation. Too hard a limitation will cause an unnecessary limitation of the control

I

action. Too weak a limitation will cause windup.

It

More flexibility is provided if the saturation is positioned as in Figure 3.22b.

n

85

Chapter 3. PID Control a)
b)
Figure 3.22 TWo ways to provide anti-windup in the controller in Figure 3.3 where integral action is generated as automatic reset.
Figure 3.23 A "batch unit" used to provide anti-windup in the controller in Figure 3.3.
In this case, the saturation will not influence the proportional part of the controller. With this structure it is also possible to force the integral part to assume other preload values during saturation. This is achieved by replacing the saturation function by the nonlinearity shown in Figure 3.23. This antiwindup procedure is sometimes called a "batch unit" and may be regarded as a type of conditional integration. It is mainly used for adjusting the ouershoot during startup when there is a large set point change. In early single-loop controllers the batch unit was supplied as a special add-on hardware. Combined Schemes Tlacking and conditional integration can also be combined. In [Howes, 1986] it is suggested to manipulate the proportional band explicitly for batch control. This is done by introducing so-called cutbaclzpoints. The high cutback is above the set point, and the low cutback is below. The integrator is clamped when the predicted process output is outside the cutback interval. Integration 86

3.6 When Can PID Control Be Used?
is performed with a specified tracking time constant when the process output is between the cutback points. The cutback points are considered as controller parameters that are adjusted to influence the response to large set-point changes. A similar method is proposed in [Dreinhofer, 1988], where conditional integration is combined with back-calculation. In [Shinskey, 1988], the integrator is given a prescribed value i - ls during saturation. The value of ls is tuned to give satisfactory overshoot at startup. This approach is also called preloading.

3.6 WhenCanPIDControlBe Used?

There are many requirements on a controlled system. It sho-muledarseusrpeomnednwt ell to

set-point changes, it should attenuate load disturbancds,

noise

should not give excessivecontrol actions, and the system should be insensitive

to processvariations. Design of a control system also involves aspectsof process

dynamics, actuator saturation, and disturbance characteristics. It may seem

surprising that a controller as simple as the PID controller can work so well.

The general empirical observation is that most industrial processes can be

controlled reasonably well with PID control provided that the demands on

the performance of the control are not too high. In the following paragraphs

we delve further into this issue by first considering cases where PID control is

sufficient and then discussing some generic problems where more sophisticated

control is advisable.

When ls Pl Control Sufficient?
All stable processes can be controlled by an I controller if the performance requirements are modest. Proportional action gives additional performance enhancements. It is therefore not surprising that the PI controller is the most common controller. Disregarding saturations a process with first-order dynamics can be given any desired performance using a PI controller. PI control can also be used for processeswith integral action.
Derivative action is frequently not used. It is an interesting observation that many industrial controllers only have PI action and that in others the derivative action can be (and frequently is) switched off. It can be shown that PI control is adequate for all processeswhere the dynamics are essentially of the first order (level controls in single tanks, stirred tank reactors with perfect mixing, etc). It is fairly easy to find out if this is the caseby measuring the step response or the frequency response of the process. If the step response looks like that of a first-order system or, more precisely, if the Nyquist curve lies in the first and the fourth quadrants only, then PI control is sufficient. Another reason is that the process has been designed so that its operation does not require tight control. Then, even if the process has higher-order dynamics, what it needs is an integral action to provide zero steady-state offset and an adequate transient response by proportional action.

S

When ls Derivative Action Useful?

c

A double integrator cannot be controlled by a PI controller. The reason is that

n

the process has a phase lag of 180' and that a PI controller also has a phase

87

Chapter 3. PID Control

lag. Derivative action is needed for such a process. Disregarding saturations a process with second-order dynamics can be given any desired performance using a PID controller.
Similarly, PID control is sufficienJ for processeswhere the dominant dyaa_mics are of the second order. For such processesthere are no benefits gained by using a more complex controller. A typical case of derivative action improving the response is when the dynamics are characterized by time constants that differ in magnitude. Derivative action can then profitably be used to speed up the response. Temperature control is a typical case. Derivative control is also beneficial when tight control of a higher-order system is required. The higherorder dynamics would limit the amount of proportional gain for good control. With a derivative action, improved damping is provided, hence, a higher proportional gain can be used to speed up the transient response.
Many processesencountered in process control have dynamics with essentially monotone step responses, often with time delay. If the dynamics is delay dominated derivative action gives modest performance improvements compared with PI control, but derivative action gives significant improvements for processesthat are lag dominated. This is discussed further in Chapter 7.

When ls More Sophisticated Control Needed?
The benefits of using a more sophisticated controller than the PID is demonstrated by some examples below.

Higher-Order Processes When the system is of an order higher than two, the control can be improved by using a more complex controller than the PID controller. This is illustrated by the following example.

Exauplp S.3-SvsrEMS oF HrcH Onopn Consider a third-order process described by the following transfer function

P (\s/) :

-- 1 (s*1)r

Figure 3.24 shows the control obtained using a PID controller and a more
complex controller of higher order. The PID controller has the parameters K - 3.4, Ti - 2.0, and T6 - 0.6.
The PID controller is compared with a controller of the form

E(s)u(r) - -S(s)y(l) + T(s)y,o(t),

with the following controller polynomials

R ( t ) : s ( s 2* 1 1 ' 5 s+ 5 7 . 5 ) S ( s ) - I 4 4 s 3* 5 7 5 s 2 * 8 7 0 s + 5 1 2 ? ( s ) - 8 s 3+ 7 7 s 2+ 3 0 9 s + 5 1 2 .

The benefits of using a more complex controller in the case of higher-order

dynamics is clearly demonstrated in the figure.

I

88

3.6 When Can PID Control Be Used?

Figure 3.24 Control of the third-order system in Example 3.3 using a PID controller (PID) and a more complex controller (CC). The figure shows responses to a set-point change, a load disturbance, and finally a measurement disturbance. The upper diagram shows set point y", and measurement signal y, and the lower diagram shows control signaliu.

Systems with Long Time Delay Control of systems with a dominant time delay are notoriously difficult. It is also a toprc on which there are many different opinions concerning the merit of PID control. There seems to be general agreement that_d_erivatiyeaction does not help much for processeswith dominant time delays. For open-loop stable processes,the response to command signals can be improved substantially by introducing dead-time compensation. The load disturbance rejection can also be improved to some degree because a dead-time compensator allows a higher loop gain than a PID controller. Systems with dominant time delays are thus candidates for more sophisticated control.

Exeupln 3.4-CoupENSATroN FoR Trnp Dnlavs Consider a process with the transfer function

P(s): 1|1;n_-n',

which has a significant time delay. Figure 3.25 shows a simulation of the closed-

loop system obtained with a PI controller with a gain K : 0.2 and an integral

time Ti :2.5. For comparison the figure also shows the performance with a

Smith predictor, which is a special controller for a system with time delays.

This controller will be discussed in detail in Chapter 8. The response to set-

point changes is much better with the Smith predictor, but the improvement

in responseto load disturbances is less.

n

Systems with Oscillatory Modes Systems with oscillatory modes occur in applicationssuch as flexible robot arms, disk drives and optical memories,

89

Chapter 3. PID Control

Figure 3.25 Control of the system in Example 3.4 with PI control (PI) and with a Smith predictor (SP). The upper diagram shows set point Jsp and measurement signal y, and the lower diagr:am shows control signal u.

atomic force microscopes (AFMs), micro-mechanical systems (MEMS), flexible space structures, and combustion systems. There are particular difficulties when the damping is very low so that the system is highly resonant. Tlpical applications are in micro-mechanical systems and in atomic force microscopes. Systems with resonant modes are not so common in process control applications. Derivative action can give drastic improvements for oscillatory systems as is illustrated by the following example.

Exeupln 3.5-AN Oscu-leroRy SysrEM wrrH Low Deupwc Consider a system with the normalized transfer function

P(s) -

a -2.

s2+2(as*a2'

We will consider systems with very low relative dampins ( : 0.005. The performance obtained with a PI controller is severely limited by the low relative damping of the process. Since a PI controller cannot provide any phase lead the damping of the oscillatory modes of the closed-loopsystem will be smaller than those of the open-Ioop system. A key requirement is that the PI controller does not excite the high-frequency modes.
A pure integrating controller is a reasonable choice. The stability condition for such a controller is ki <2(a3, which implies thatki: (a3 is a good value of the controller gain. With this choice the closed-loop system has the same settling time as the open-loop system. The response time can only be improved a little by adding proportional action. Figure 3.26 shows the input and the output for a step change in the set point for a controller with these parameters. The step response has a settling time of about 1500 s. The reason why the system has to be so slow is that the oscillatory motion cannot be damped by the PI controller. and it is therefore necessarv to have a slow controller so that

90

z 1.5 h1

3.6 When Can PID Control Be Used?

0 1

u.c

0 t
Figure 3.26 Output and control signals for PI control of the oscillatory system. The oscillating signal is the open-loop response.

the oscillatory modes are not excited by the controller. In the figure we have also shown the step response of the process.
The performance can be improved drastically by using a PID controller. One possibility is to use a PID controller with parameters

k

:

(

L

+

2

a

s

(

o'

l4-
o,2

r

,
Ri:

do@?
--i

a'

, (uo + 2(o)an- 2( o

,.u-

o

(3.23)

Here a)0, do, and (s are design parameters that give the properties of the closed-loop system. A reasonable choice is als - 3a, &0 : I, (o : 0.5. The

rationale for the formulas and the parameter choices will be given later in

Section 6.4. Figure 3.27 shows the responses of the output and the controller

to a step change in the set point. In this casethe system has a settling time of

about 2 s. This is about three orders of magnitude better than with PI control!

The reason for this is that by using derivative action it is possible to damp the

oscillations. This is indicated in the figure by showing the open-loop response

of the process in dashed line. Also notice the drastic differences in the control

signals for PI and PID control. It is also important to use set-point weighting

with b : 0 to avoid a rapid change of the control variable. Such a change will

excite the poorly damped oscillatory modes.

n

Summary
When the dynamics of the process to be controlled are simple, a PID controller is sufficient. When the dynamics become more complicated, the performance

91

Chapter 3. PID Control

1.5 -1
0.5 0

z
il
0
.l

2.5 t

Figure 3.27 Output and control signals for PID control of the oscillatory system. The dashed curve is the open-loop response.

can be improved by using a more sophisticated controller structure than the PID. Examples of such processeshave been given above.
For some systems with large parameter variations it is possible to design linear controllers that allow operation over a wide parameter range. Such controllers are, however, often of high order.
The control of processvariables that are closely related to important quality variables may be of a significant economic value. In such control loops it is frequently necessary to select the controller with respect to the disturbance characteristics. This often leads to strategies that are not of the PID type. These problems are often associated with time delays.
A general controller attempts to model the disturbances acting on the system. Since a PID controller has limited complexity, it cannot model complex disturbance behavior in general nor periodic disturbances in particular.

l

3.7 Summary

I

I

A detailed presentation of the PID algorithm has been given. Several modi-

I

fications of the "textbook" version must be made to obtain a practical, useful

(

controller. Problems that must be handled are, for example, integral windup

I

and introduction of set-point values. A discussion of the limitations of the PID

algorithm and a characterization of processesin which the PID controller man-

tl

ages to perform the control have also been given.

c(

92

,di,ir.rl
irrr-t
JLrf
I)ID
111,I1-

3.8 Notes and References
3.8 Notesand References
An interesting summary of the development of the PID controller is given in [Bennett, 20001.Proportional feedback in the form of a centrifugal governor was used to regulate the speed of windmills around 1750. James Watt used a similar system for speed control of steam engines in 1788. Integral action was discovered later by several authors. It is explained analytically by [Maxwell, 1868] and [Vyshnegradskii, 1876]. Feedback control with proportional and integral action was rediscovered many times after that. In the early stages, the development of controllers was closely related to development of sensors and actuators. Sensing, actuation, and control were often combined in the same device. There was also confusion about integral and derivative action because some controllers acted through motors that had integral action.
The PID controller in the form we know it today emerged in the period from 1915 to 1940. The major development was made in legendary instrument companies such as Bristol, Fisher, Foxboro, Honeywell, Leeds & Northrup, Mason-Neilan, and Taylor Instrument. Integral action was called automatic reset because it replaced a manual reset that was used in proportional controllers to obtain the correct steady-state value. The potential of a controller that could anticipate future control errors was discussed in the 1920s. However, it took some time before the idea could be implemented. A controller with derivative action was introduced by Ralph Clarridge of the Taylor Instrument Company in 1935. At that time the function was called "pre-act." An interesting overview of the early history of PID controllers is given by [Stock, 1988]. There is also much interesting material in publications from the instrument companies.The interview with Ziegler,who is one of the pioneers in our field, in [Blickley, 1990], gives a perspective on the early development; other interesting material is found in [Bennett, 1993].
It is interesting to observe that feedback was crucial for the construction of the controller itself. The early pneumatic systems used the idea that an essentially linear controller can be obtained by a feedback loop composed of linear passive components and a nonlinear amplifier, the flapper valve. Similar ideas were used in electronic controllers with electric motors and relays.
Many of the practically useful modifications of the controller first appeared as special hardware functions. They were not expressedin mathematical form. An early mathematical analysis of a steam engine with a governor was made independently by [Maxwell, 1868] and [Vyshnegradskii, 1876]. This analysis clearly showed the difference between proportional and integral control. The papers [Minorsky, 1922; Kiipfmiiller, 1928; Nyquist, L932; Hazert, 1934] were available at the time when the PID controller was developed.However, there is little evidencethat the engineers in the processcontrol field knew about them. Process control therefore developed independently. TWo of the early papers fGrebe et al., 1933] and [Ivanoff, Ig34l were written by engineers at the Dow Chemical Company. There were also contributions from university researchers Callender et al., 1936] and [Hartree et al., 1937).
The PID controller has gone through an interesting development becauseof the drastic technolory changes that have happened since 1930. The pneumatic controller improved drastically by making systematic use of the force balance
93

Chapter 3. PID Control
principle. Pneumatics was replaced by electronics when the operational amplifier appeared in the 1950s. The emergence of computer control in the 1960s was an important development. In the early computer control systems the computer commanded the set points of analog controllers. The next stage of the development was direct digital control (DDC), where the computer was controlling the actuator directly; see [Webb, 1967]. A digital computer was then used to implement many PID controllers. This development led to a reconsideration of much of the fundamentals of PID control; see [Goff, 1966b], [L&N, 19681,[Moore et a1.,1970],and [Palmor and Shinnar, 1979].The appearanceof microprocessorsin the 1970s made it possible to use digital control for singleloop controllers. It also led to the development of distributed control systems for process control, where the PID controller was a key element; see [Lukas, 1986].As the computing power of the microprocessorsincreased it was possible to introduce tuning, adaptation, and diagnostics in the single-loop controllers. T"his development started in the 1980s and has accelerated in the 1990s; see [Astrdm et a1.,1993].
It is interesting to observe that many facts about PID control were rediscovered in connection with the shifts in technology. One reason being that many practical aspects of PID control were considered as proprietary information that was not easily accessible in public literature. Much useful information was also scattered in the literature.
TWo different approaches were used to deal with set-point changes in early controllers. Some controllers used error feedback but others introduced the set point only in the integral part. The effect of this is that the overshoot that occurs with set-point changes can be reduced. The idea that a separation of the responses to set points and load disturbances can be accomplished by using a controller with two degrees of freedom was introduced in [Horowitz, 1963]. The application to PID control was introduced in [Araki, L984].An early industrial application is described in [Shigemasa et al., 1987], see also [Araki and Taguchi, 1998; Taguchi and Araki, 2000]. Set-point weighting where an adjustable fraction of the set point is introduced in proportional and derivative parts is now a common feature of PID controllers.
The phenomenon of integral windup was well known in the early analog implementations. The controller structures used were often such that windup was avoided. The anti-windup schemes were rediscovered in connection with the development of direct digital control. This is discussedin [Fertik and Ross, 19671.Much work on avoiding windup has been done since then, and windup has now made its way into some textbooks of control; see [Astrdm and Wittenmark, 1997]. There are many papers written on the windup phenomenon; see [Kramer and Jenkins, 1977; Glattfelder and Schaufelberger, 1983; KrikeIis, 1984; Gallun et al., 1985; Kapasouris and Athans, 1985; Glattfelder and Schaufelberger, 1986; Howes, 1986; Astrdm, 1987b; Hanus et al., L987; Chen and Wang, 1988; Glattfelder et al., 1988; Hanus, 1988; Zhang and Evans, 1988; Astrom and Rundqwist, 1989; Rundqwist, 1990; Walgama and Sternby, 19901.A detailed treatment of the windup problem is given in the book [Glattfelder and Schaufelbergea 2003]. Mode switching is treated in the paper [Astrdm, 1987b].
94

Controller Design
4.1 Introduction
Control system design is a very rich field. There have been substantial advances over the past 50 years that have resulted in much insight and understanding as well as specific design methods. This development has been augmented by the advances in computing and the development of computer-based design tools. Broadly speaking, PID controllers have been designed using two different approaches; mpdel-based control and direct tuning. The model based approaches start with a simple mathematical model of the process. Very simple models have been used, typically a first-order system with a time delay. In direct tuning a controller is -applied to the process, and some simple experiments are performed to arrive at the controller parameters. Because of the simplicity of models and the controller special methods have been developedfor PID control. From 1990 there has been a significant increase in the interest in design of PID controllers, partially motivated by the needs of automatic tuning devices for such controllers.
To develop design methods it is necessaryto realize that there is a very wide range of different types of control problems even if the controller is restricted to PID. Some typical examples are:
. Design of a simple controller for a non-critical application.
o Design of a controller for a special process that minimizes fluctuations in important control variables.
r Development of a design technique that can be used in a universal autotuner for PID control.
There are also a number of important non-technical issues that should be considered: What is the time and effort required to apply the method? What is the knowledge level required of the user? A solution to the design problem should also give an understanding of when it is beneficial to add derivative action to a PI controller and when even more complex controllers should be considered.
This chapter gives an overview of ideas and concepts that are relevant for
95

Chapter 4. Controller Design
PID control. It is attempted to bring design of PID controllers more into the mainstream of control design.
4.2 A RichVarietyof ControlProblems
Before discussing specific tuning methods it is useful to reali ze that there is a wide range of control problems with very diverse goals. Some examples are: steady-state regulation, set-point tracking and path following, and control of b-uffers and surge tanks.
The goal of stea"dy-stateregulation is to keep process variables close to desired values. The key problems are caused by load disturbances, measurement noise, and processvariations. Steady-state regulation is very common in process control.
In set-point tracking it is attempted to make process variables follow a given time function or a given curve. These problems typically occur in motion control and robotics. In some cases,for example, machine tool control or robotics, the demand on tracking precision is very severe. In other cases, for example, moving robots, the requirements are less demanding. There is a significant difference between tracking a given time curve and path following, which typically involves control of several variables.
Buffers are common in the industrial production. They are used to smooth variations between different production processes,both in process control and in discrete manufacturing. In processcontrol they are often called surge tanks. Buffers are also common in computing systems. They are used in servers to smooth variations in demand of clients, and they are used in computer networks to smooth variations in the load. Buffers are also key elements in supply chains where effective buffer control has a major impact on profitability. The buffer levels should fluctuate; otherwise the buffer does not function. Ideally, no control should be applied unless there is a risk of over- or underflow. An integrating controller with low gain and a scheduling that gives higher gains at the buffer limits are commonly used.
The key issues in many of the control problems are attenuation of load disturbances, injection of measurement noise, robustness to process variations, and set-point following. The relative importance of these factors and the requirements vary from application to application, but all factors must be considered.
4.3 FeedbackFundamentafs
A block diagram of a basic feedback loop with a controller having two degrees of freedom is shown in Figure 4.1. The process is represented by the block P. The controller is represented by the feedback block C and the feedforward
96

4.3 FeedbackFundamentals

I I I
0
!'
IC
]"
ln NS
rs-
0St
reon-
Jrees olock rvard

r

9gl_tl"llq.

Figure 4.1 Block diagram of a basic feedback loop having two degrees of freedom.

part F. For an ideal PID controller with set-point weighting we have

c ( s ): r ( r + 1 + s"a)
t?|t

n, \ b+#*csTa

I

lo,

-

1+#*sTa

(4.1)

Compare with (3.7) and (3.20). The signal u is the control signal, and the signal r is the real processvariable. Information about r is obtained from the sensor s-ignaly, which is corrupted by measurement noise n. The signal d represents load disturbances that drive the system away from its desired state. This signal can enter the processin different ways; in Figure 4.1it is assumed that it acts on the process input.
The goal of control design is to dejermine the transfer functions C and -F so that the process variable r is close to the set point Jrp in spite of load disturbances, measurement noise, and processuncertainties. The feedbagkcan reduce the effect of load disturbances. Because of the feedback measurement
noise is fed back into the system. It is essential to make sure that this does not cause large variations in the process variable. Since the process model is never accurate it is essential that the behavior of the closed-loop system is insensitive to variations in the process.The feedforward transfer function F is designed to give the desired response to set-point changes.

Fundamental Relations
The feedback loop is influenced by three external signals, the set p,oint y"r, the load disturbance d, and the measurement noise n. There are at least three signals x, !, and,u that are of great interest for control. This means that there are nine relations between the input and the output signals. Since the system is linear these relations can be expressed in terms of the transfer functions. Let x,Y, u, D, N, and Y"o be the Laplace transforms of r, !, u, d,, n, and .|sp, respectively. The following relations are obtained from the block diagram

Chapter 4. Controller Design

inFigu4re'1:

x _##y,p* i*n _ffiu

" - ffiY,p*#*o* ,*}uar

(4.2)

,r_ cF u _ PC n

C Ar

": r+PCtsP r+PCu- r+pct\'

There are several interesting conclusions we can draw from these equations.

First, we can observe that several transfer functions are the same and that all

relations are given by the following six transfer functions, called the Gang of

Six.

PCF

PC

P

T+PC CF

I+PC C1

I+PC

(4.3)

1+ PC

I+PC

7+PC.

The transfer functions in the first column give the response of process variable and control signal to the set point. The second column gives the same signals in the case of pure error feedback when F - 1. The transfer function P/(1 + PC) in the third column tells how the process variable reacts to load disturbances, and the transfer function C lQ + PC) gives the response of the control signal to measurement noise.

Notice that only four transfer functions,

PC L+PC
C
L+ PC

L+PC
I l+PC'

(4.4)

are required to describe how the system reacts to load disturbance and the measurement noise. These transfer functions are called tineGang of Four. They also capture robustness, as will be discussed in Section 4.6. Tlvo additional transfer functions are required to describe how the system responds to setpoint changes.
The special case when F - I is called a system with (pure) error feedback. In this case, all control actions are based on feedback from the error only. In this case,the system is completely characterized by the Gang of Four e.1).
We are often interested in the magnitude of the transfer functions given by Equation 4.4. It is important to be aware that the transfer functions eC 1g + PC) and tlQ+ PC) arc dimension free, but the transfer functions PIQ+fC; and Cl(1 + PC) are not. For practical purposes it is therefore important to normalize the signals, for example, by scaling process inputs and outputs to the interval 0 to 1 or -1 to 1.

A PracticaCl onsequence
The fact that six relations are required to capture properties of the basic feedback loop is often neglected in literature, particularly in the papers on pID control. To describe the system properly it is thus necessary to show the response of all six transfer functions. The transfer functions can be represented

98

4.3 Feed'backFundarnentals

t
l

-0.50-10

F;li;n"episgarineuftohrrese,elTt-,Pr,ot,ri:wfeli:g#htaf"=fiio',fu'f."ai'iriJ"J'"-.tT"aTlinielisFfojris:e*t-pioli{nwtl'e3ighxtbt: irlf' itJriil'lil:::fr

ipcnahdapiefngfreessro.ersn, u'towc"ha'#y"s",b;*;vr;'thegsilhiu"sortweodr"Jrers;r;p";;oi"lni's1eo1srob1il'rTt'"hl"?e;;i;,r;"f;r'iel"q"u|uej'un*}'c:liulyrebs"l"plt:oo?nsJseerts-"Mp'Joo"sin$t t
:fr*#fi*:l,t"ril:iliii:"':'$nT:x'?tl:d';;:ilr::*resh rcmscehhhseaaponnrotwganntecrsotrieeni"s,r.eii"s'z.retaprprtroi-#.o.r*"nr.*oo*;uf;aanru"l;lliiu;inos.erwi"u*se"itr,adr\"a:**onu#rs"'.]iatt"ih. ;.e;"r;n"r;"e^tir";.soiopl"norssl""rariig:" niynrra;"o;rtE't*aoql udai-ain:s4titeou2xnrt'pbar4Tean'r3ndi'gmgtehei,evnaetndwdsaaismthcheoeaadmslsiunptereleeps-te

manvvari.

:
I
o .o

H::#::"'il:n inFigur1e^1'ii1l::i:1yflil:1il;Il;,*e ationsof this nr"ur"*. r-r,ngrrr"'i.l-;;i"";

airtotu.ttcesact on the process

inpruntprac;t;i;;;-.b;:m;n*f: ru*16:4F:: i""lf.f{:: tbvFeFct,aertmioig.agrd"n.iunutatyfrTsrr"teneoitfhoelae+4lnrem..sfmf1gruuw.ci,enn.tAai,accttosnnsrtt,utoi#Io'osri';r.ne,ne,ium;"sliGi-*;liuep;;'o1t;tno:*o;()trrisrna,t)ntt"i*io"dso"uriw,ns"ai*ieg*1',thrra";ia;ir;;i';mrr;Fig;,ii.o,f'ai*sina;u;dr"s;cnoauhvdsrueieefs"i;dcct''ii;oa"g;'Li;niJ;;ilo;dl^";n-io*rsrrtndro"e"tfmr;vnttp"lheib"ineattvassla(unaoner]e'fatx1emara)vrmaessenenipdsndtlfAb'eistlaithloselsertarefh'ifdlPiTteIeotIhsDerne'er

(4.5)

Gr(t) = TT4Tszrl12

d-
.D
'e-

The relations between the input signals and output signals in Figure 4'3 are

ed

99

Chapter 4. Controller Design

Figure 4.3 Block diagram of a basic feedback loop having two degrees of freedom and filtering of the measurement.

given by

. *hqD-i#l PCF

X-

Ysp
| + PCGI

v' -_

PCF v r+PCG."P

. #tqD

+ r+#GrN

(4.6)

- # q n - f f i r t ur r -:

u

CF \./ pggrr'n

Equation (4.6) is identical to (4.2) if the transfer function C(s) and F(s) are

i

replaced by

I

C 1 r-; c ( s ) G i ( s )F, 1 r:; iGqr,( t ) '

C

(4.7)

E

The modifications required to deal with fiItering are thus minor, and it suffices to develop the theory for the configuration in Figure 4.1.

I\

Separation of Responses to Disturbances and Set Points

a

In early work on PID control it was a tradition to have two tuning rules, one

b

for good set-point response and another for efficient attenuation of load distur-

bances. This practice still continues. A strong advantage of a controller with

p

iwo degreesof freedom is that the responsesto disturbances and set point can

S

be designed separately. This follows from (4.2), which shows that the response

b

to load disturbances and measurement noise is given by the C(t), or from (4.6)

o

by C(s) - C(s)Gr(r) when the measurement is filtered. A good design proce-

Cl

dure is thus to determine C(s) to account for robustness and disturbances. The

feedforward transfer function F(s) can then be chosen to give the desired set-

point response.In general, this requires that the feedforward transfer function

tt

can be chosen freely. Simply choosing the set-point weights often give satisfac-

a

tory results. Notice that there are some situations where only the error signal

tl

is available. The decoupling of the design problem then is not possible, and the

design of the feedback then has to consider a trade-off between disturbances,

n

robustness, and set-point response.

is

100

)e .rth an
ISE
6) ce.he .et.ion lacInal the lces,

4.3 Feedbach,Fundamentals

Fundamental Limitations
In any design problem it is important to be aware of the fundamental limitations. Tlpical sources of limitations are

o Process dynamics

o Nonlinearities

o Disturbances

o Process uncertainty

Process dynamics is often the limiting factor. Time delays and poles and zeros

in the right half plane are relevant factors. It is important to be aware of these

limitations. Time delays are the most common factor for PID control. It seems

intuitively reasonable that it is impossible to have tight control of a system

with a time delay. It can be shown that for a process with a time delay Z

the aghievable gain crossover frequency o)sctwhich is defined in Section 4.4, is

limited by

asrL < l.

(4.8)

Since

c

-

^r
""

<-

l-sL12
1+ sLf2'

it also seems reasonable that right-half plane zeros also limit the achievable

performance. It can be shown that a right-half plane zero at s - b limits the

gain crossover frequency to

0s" < 0.5b.

(4.e)

A right-half plane pole s : a in the processlimits the achievable gain crossover

frequency asc to

anc) 2a.

(4.10)

Notice that time delays and right-half plane zeros give an upper bound to the achievable gain crossover frequency while right-half plane poles give a lower bound.
Nonlin-earities, saturation, and rate saturation are verv common; they impose limitations on how much and how fast the process variables can .hu.rg". Saturations combined with unstable processdynamics are particularly serious because they may lead to situations where it is not possible to recover stable operating conditions. Such situations are fortunately not common in process control.
Load disturbances and measurement noise limit how accurately a process variable can be controlled. The limitations often interact. The allowable controller gain is, for example, limited by a combination of measurement noise and actuator saturation. The effect of load disturbances depends critically on the achievable bandwidth.
Process models used for control are always approximations. Process dynamics may also change during operation. Insensitivity to model uncertainty is one of the essential properties of feedback. There is, however, a limit to the

101

Chapter 4. Controller Design
Stable

Unstable

Stable

Unstable

Figure 4.4 Illustration of different system behaviors used to define stability.
uncertainty that can be dealt with. Feedback cannot be active in frequency ranges where the uncertainty in the phase of the process is larger than +90". To have reasonable control performance the uncertainty should be less thqn about +15". If the processvariations correlate well with some measured quantity it is possible to compensate for the uncertainties by changing the controller parameters. This technique, which is called gain scheduling, will be discussed in Section 9.3.
4.4 Stability
Feedback has many useful properties. The main drawback is that feedback may cause instability. It is therefore essential to have a good understanding of stability and the mechanisms that cause instability.
Stability Concepts The notion of stability is intuitively very simple. It tells how a system behaves after a perturbation. Already in 1868 Maxwell classified the behavior as follows: U1: The variable increases continuously
51: The variable decreasescontinuously U2: The variable increases in an oscillatory manner 52: The variable decreasesin an oscillatory manner These behaviors are illustrated in Figure 4.4. Maxwell called the behaviors Iabeled S stable and the ones labeled U unstable. He also found that for linear time-invariant systems stability was related to properties of the roots of an algebraic equation.
r02

G r( s )

4.4 Stability

Figure 4.5 Block diagram of a simple feedback system.

Consider a system with the transfer function

c ( s-) 9 1 . a(s I

(4.11)

where a(s) and b(s) are polynomials. Recall that the roots of the polynomial
o(s) are called the poles of the system. Since a pole s; corresponds to a time function e'" the following relations are obtained between the behaviors and the roots of an algebraic equation:

Ul: Corresponds to real poles with positive real part

51: Corresponds to real poles with negative real part

U2: Corresponds to complex poles with positive real part

52: Corresponds to complex poles with negative real part

The system (4.11) is stable if it has no poles in the right half plane. The

equation

o(s) : g

(4.12)

is called the characteristic equation. A system is stable if the characteristic equation does not have any roots with positive real parts. It is common practice to label poles on the imaginary axis as unstable.

Nyquist'sStabilityCriterion
The algebraic definition of stability based on the roots of the characteristic equation is useful, but it also has some drawbacks. Consider, for example, the feedback system in Figure 4.5 where the transfer functions of the process and the controller have been combined into one block with the transfer function Gt : PC. The characteristic equation for this system is

l+Gt(s) :0.

(4.13)

The transfer function, which is the product of the transfer functions of the pro-

cess and the controller, describes how signals propagate around the feedback

5

loop and is called the loop_trqnsferfunction.It is not easy to seehow the roots

IT

of (4.13) are influenced by the transfer functions of the process and the con-

rn

troller. This can, however, be done by using a totally different view of stability,

which was developed by Nyquist. He started by investigating the conditions

103

Chapter 4. Controller Design

for maintaining an oscillation in the system shown in Figure 4.5. Assume that the feedback loop is broken as is indicated in the figure and that the signal ue(t): sin@sf is injected at point A. After a transient the output at point B is then given by
u n ( t ) : - l G 1 ( i a h ) ls i n ( a r s f* a r g G 1 ( i a ) ) .

The signals ua(r) and u"(t) are identical if G1 (i z ts )- -1,

(4.r4)

and an oscillation will be maintained if the loop is closed by joining points A and B. Equation 4.14 thus gives the condition for oscillations in the system.
It follows from (4.13) and (4.14) that the condition for oscillation implies that the characteristic equation of the system has a root s - iao.The frequencies where the system can maintain an oscillation can be determined by solving (4.I4) for a,'s.
Nyquist developed a stability criterion based on the idea of how sinusoids propagate around the feedback loop. Nyquist argues as follows. He first investigated frequencies where the signals ua ar,.dup are in phase, i.e., when argGl\an) - Tt.Intuitively it seems reasonable that the system is stable if
lG1(iah)l < 1 because the amplitude is then decreased when the signal traverses the loop. The situation is actually a little more complicated becausethe system may be stable even if lct(irrto)l > 1. The precise result can be expressed in terms of the Nyquist curve introduced in Section 2.3. Recall that the Nyquist curve is a plot of (ReG;(iro),ImG7(ia)) for 0 l ro 1oo. When the loop transfer function does not have poles in the right half plane the condition for stability is that the critical point -1 is to the left of the Nyquist curve when it is traversed for increasing a.l.
A nice property of the Nyquist's criterion is that it indicates how a system should be changed in order to move the Nyquist curve away from the critical point. Figure 6.4 shows that derivative action, which introduces phase lead, bends the curve away from the critical point. Integral action, which introduces phase lag, bends the curve towards the critical point. The idea is to modify the controller so that the curve is bent away from the critical point. This has led to a whole class of design methods called loop shaping.

Stability Margins
In practice it is not enough to require that the system is stable. There must also be some margins of stability. This means that the Nyquist curve should not be too close to the critical point. This is illustrated in Figure 4.6, which shows several stability margins. The gain margin g- tells how much controller gain can be increased before reaching the stability limit. Let phase crossouerfrequency rdlsebe the smallest frequency where the phase lag of the loop transfer function Gl (r) is 180' and the gain margin be defined as

em:rc

(

1
rdi

ll

(4.15)

L04

.I tr
ci
rl
tl w is
Br Bc frc dir sta
ma
Ny For nec mol nar dek dec syst pea Thir Cha

i t- GlQat)
I- - l - - - r -

t

-r

tr

\

4.4 Stability

,' Re GlQot)

:
I t
r
S
d
m al d.
ES
he ed
ust not )ws :ain frn' sfer
t.r5)

Figure 4.6 Nyquist plot of the loop transfer function G7 with gain margiD em, phase margin cp^ and stability margin s-.

The point where the Nyquist curve intersects the unit circle is another interesting point. This point can be characterized by the angle p,,,. This angle
called the phase mqrgin is also a measure of ho* close the Nyquist curve is to the critical point. The angle g^ is the amount of phase lag required to reach
the stabitlty iimit. The gain crossouerfrequency atn, is the lowest frequency where the loop transfer function Gz(r) has unit magnitude. The phase margin is formally defined as

gm:7t+argG1(iatnr).

(4.16)

Both gain and phase margin are classical measures of degrees of stability. Both values must be specified in order to ensure that the Nyquist curve is far from the critical point. They can be replaced by a single number, the shortest distance from the Nyquist curve to the critical point -1, which is called the stability margin sm.
Reasonablevalues of the margins are phase margin gm :90" - 60., gain margin gm : 2 - 5,,stability margin sm :0.5 - 0.8.
The gain and phase margins were originally conceivedfor the casewhen the Nyquist curve only intersects the unit circle and the negative real axis once. For more complicated systems there may be many intersections, and it is then necessaryto consider the intersections that are closestto the critical point. For more complicated systems there is also another number that is highly relevant, namely, the delay margin. The delay margin is defined as the smallest time delay required to make the system unstable. For loop transfer functions that decay quickly the delay margin is closely related to the phase margin, but for systems where the amplitude ratio of the loop transfer function has several peaks at high frequencies the delay margin is a much more relevant measure. This is particularly relevant for the Smith predictor that will be discussed in Chapter 8.

105

Chapter 4. Controller Design

Internal Stability
So far we have only discussed the simple feedback system in Figure 4.5. For the more general system in Figure 4.1 which is characterized by six transfer functions, it is necessary to require that all four transfer functions,

PCP I+PC
C
I+PC

I+PC 1
I+PC

(4.r7)

are stable; compare with (4.3). This is called internal stability. Notice that there may be cancellations of poles and zeros in the product PC.

Stability Regions

A primary requirement for a PID controller is that the parameters of the controller are chosen in such a way that the closed-loopsystem is stable. A PID

controller of the form

c ( s-) u * ? * h a s

(4.18)

has three parameters only, and the stability region can be represented by a volume in three dimensions. To describe this volume the processtransfer function is represented as

P(i o t): r(o t)e i a t(,-) r(ar)(cos(o) + l si n(a.r)),

and the condition for oscillation (4.14) then becomes

P(ia)C(iot) :

r(a)(cos(ar) *

i si n(ar))(fr -

b.
r; *

ikaat) -

-1.

Separating the real and imaginary parts we find that the boundary of the stability region can be represented parametrically as

, c o sQ @ )

I( -

- ----------;---.
rla)

t ki:

(.D. 2-1k

a) sin /(a.t)
r(tt)

(4.1e)

It is thus straightforward to determine the stability region for a constant value of ka. Repeating the calculations for a set of ka-values gives the stability region for the PID controller.

Exaupln 4.1-SraeILITy RncIoN non P(s) - 1/(s + 1)n

Figure 4.7 shows the stability region for a process with the transfer function

P(s) - 1i (s + t)4. The value ka : 0 corresponds to PI control. Integral gain

ki ma;;obe increased by adding derivative action. The integral gain has its maximum kr : 36 at the boundary of the stability region for le: 8 and ka : 20.

The system is unstable for all values of k and hi if ka > 20.

I

106

4.4 Stability
Figure 4.7 Stability region for the system P(s) : (1 + s)-4.
Some interesting conclusions can be drawn from Example 4.1. To have good disturbance rejection it is desirable to have a large value of ki. This is shown in Section 4.9. With PI control, the largest value of ki for a stable system is ki : t. Figure 4.7 shows that the value of fu can be increased substantially by introducing derivative action. The highest value of ki that can be obtained with a stable system is ft; : 36. This will, however, be a very fragile controller becausethe system can be made unstable by arbitrarily small changes in controller gains. For large values of k6 the curves have sharp corners at the point qf maximum integral gain. This property of derivative action is one reason why tuning of controllers with derivative action is difficult. It will be discussed further in Chapters 6 and 7.
ConstanPt roportionaGl ain
The region of parameters where the system is stable is a subset of .83. The calculations performed give the two-dimensional intersections with constant derivative gain. Additional insight can be obtained from another representation of the stability regions. To investigate the stability we will use the Nyquist criterion and plot the locus of the loop transfer function G7(s). With proportional control we have Gr : kP.For a fixed value of the proportional gain k > 0 rve determine the frequency on where the Nyquist curve of kP(iat) intersects the circle with the line segment (-1,0) as a diameter; see Figure 4.8. We will first consider the casewhen the intersection of the Nyquist curve and the circle
107

Chapter 4. Controller Design

ImGlQro)

hP(ico,,)

Figure 4.8 Nyquist curve of the loop transfer function G7(s) : hP(s).

occurs in the lower half plane as shown in Figure4.8.The controllertransfer

function is

C(ittt:) k t,(-2

+

k

a

a

t:)

n

-

i

(

!t
\n

-

tr*u/ a\.

hence,

G1(iot,) -

P(iot*)C(ia4) :

kP(irtt)

-

i( lL
\0)n

-

k a* r , t",/\ k P ( i a 4 ) .

If proportional gain fr is fixed the point kP(iot") moves to G1(iro,) when proportional and integral gains are different from zero. To avoid reaching the critical point it must be required that

rk; |*

-

k.

a

0

n)\ ,l

-.. P(i

a

,

)

l<

lr + P(iat")1.

The same analysis can be made when the intersection of the Nyquist curve and the circle occurs in the upper half plane. Combining the inequalities we find that the stability regions are given by the conditions

ki>0

k

,

i

<o

t'

2r

kd

l

@

nl1+

kP(iro,,)l
for

Im

P(iat")

<

0

lP(ia")l

k;>a2rtzd.-o)nlI +

kP(ian)l
for

Im

P(iot")

>

0

lP(ia4)l

which should hold for for all rtt, such that

(4.20)

lnelir,). * |

1 2'

(4.2r)

108

er
rpOf-
rical
curve es we
d.20)
t4.21)

4.5 Closed-LoopPoles and Zeros

We can thus conclude that for constant proportional gain the stability region is represented by several convex polygons in the ki-ka plane. In general, there may be several polygons, and each may have many surfaces. The number of surfaces of the polygons is determined by the number of roots of the Equation 4.2L In many cases,the polygons are also very simple, as is illustrated with the following example.

Exanapln 4.2-FovR EqUAL Polns To illustrate the results we consider a process with the transfer function
11 P ( ' ) ( s + 1 ) a s a + 6 s 2+ 1 + 4 s ( s+2 1 )

In this case,Equation 4.21 becomes

a4-60t2+1+k:0.

This equation has only two positive solutions,

o)2:3+\E-k,

and it follows from (4.20) that the stability region is given by the inequalities

ki>o Li < (3- !E=E)ka + 4k -56 + 2s\/8- k ki > (3+ J8-)ka + 4t?-56 - 2svE1.

(4.22)

The stability region is shown in Figure 4.7. The integral gain has its maximum

hi : 36 at the boundary of the stability region for k: 8 and lza: 20.

tr

4.5 Closed-LoopPolesandZeros

Many properties of a feedback system can be obtained from the closed-loop

poles and zeros. For PID control the behavior is often characterized by a few

dominant poles, typically those closest to the origin. Many properties of the

closed-loopsystem can be deduced from the poles and the zeros of complemen-

tary sensitivity function

T

tl

^' s\

/-

:

1

PC(s)
+PCo

With error feedback, F : 1 in Figure 4.1, the closed-loopzeros are the same as the zeros of loop transfer function Gt(s), and the closed-looppoles are the roots of the equation
L+Gt(s) :0.
The pole-zero configurations of closed-loop systems may vary considerably. Many simple feedback loops, however, will have a configuration of the type

109

Chapter 4. Controller Design

Figure 4.9 Pole-zero configuration of the transfer function from set point to output for a simple feedback system.

shown in Figure 4.9, where the principal characteristics of the response are given by u complex pair of poles, p1 and p2, called the dominant poles. The responseis also influenced by real poles and zerosp3 and z1 closeto the origin. The position of p3 and 21 mal be reversed. There may also be more poles and zeros far from the origin, which typically are of less influence. Poles and zeros to the left of the dominant poles have little influence on the transient response if they are sufficiently far away from the dominant poles. The influence of a pole diminishes if there is a zero close to it.
Complex poles can be characterized in terms of their frequency ao, which is the distance from the origin, and their relative damping (. A first approximation of the response is obtained from the equivalent second-order system. The response is modified if there are poles and zeros close to the dominating poles. Classical control was very much concerned with closed-loopsystems having the pole-zero configuration shown in Figure 4.9.
Even if many closed-loop systems have a pole-zero configuration similar to the one shown in Figure 4.9, there are, however, exceptions. For instance, systems with mechanical resonances,which may have poles and zeros closeto the imaginary axis, are generic examples of systems that do not fit the pole-zero pattern of the figure. Another example is processeswith a long dead time.
Design of PID controllers are typically based on low-order models, which gives closed-loopsystems with a small number of poles and zeros.

DominanPt olesfromthe LoopTransfeFr unction

A simple method for approximate determination of the dominant poles from

knowledge of the Nyquist curve of the loop transfer function will now be given.

Consider the loop transfer function Gt (r) as a mapping from the s-plane to the

G7-plane. The map of the imaginary axis in the s-plane is the Nyquist curve

G1(ia), which is indicated in Figure 4.t0. The closed-looppoles are the roots

of the characteristic equation

T

l+Gt(s) :0.

G

re

The map of a straight vertical line through the dominant closed-looppoles in

br

110

4.6 The Sensitiuitv Functions

r )
.o 'o
:h
)m en. the n/e rots
's rn

A=Gr (iaz) B = Gr (ia\)
G,(ia)

Figure 4.10 Representation of the loop transfer function GlQrtt) as a map of complex planes.

the s-plane is thus a curve through the critical point Gt : -1 in the G7-plane. This curve is shown by a dashed line in Figure 4.L0. Since the map is conform, the straight line A'C' is mapped on the curve AC, which intersects the Nyquist curve orthogonally. The triangle ABC is also mapped conformally to A'B'C'. If ABC can be approximated by a triangle, we have

Gt(ian)- Gr\r'tt) o | + Gt(iaz)

102 - L(D1

o

When /d1is close to ot2this becomes

o:(7tGt(ian))

iah - iatt

| * Gt\roz)

G1(ia2) -

Al
Gt(irot)

__-:-
G',(ia4)

(4.23)

where Gj(r) : dGt(s)/ds. To determine the dominant poles we first determine the point A on the Nyquist curve that is closest to the critical point -1. This
point is characterized by the frequency az. Then determine the derivative of the Iooptransfer function at a4.The dominant poles are then given by s : -o*.iro2,
where o is given by Equation 4.23.

4.6 TheSensitivityFunctions

TWo of the transfer functions (4.3) are of particular interest, the sensitivity function S and the complementary sensitivity function ?. These functions are defined by

s- t+PC t+Gt

T-

PC :- Gt I+PC t+Gt

(4.24)

The sensiti"ily functions are uniquely given by the loop transfer function

Gr(r) - P(s)C(s) and have the property S * T : 1. The transfer functions

reflect 'rustne

smsatnoyp

interesting prope rocess variations.

r

ties

of

the

closed-loop system,

particularly

ro-

111

Chapter 4. Controller Design

SmallProcessVariations-TheSensitivityFunction
We will start by investigating how sensitive the response to set-point changes is to small process variations. It follows from (4.2) that the transfer function from set point to process variable is

PCF Gry"r: Gyyrr: 7+PC'

Consider Gry,oas a function of the processtransfer function P. Differentiating with respect to P gives

d,G*y", CF

PC2F

CF

CF

dP I + P C 6TFCP (r + PC)2 t + P C t + P C '

Hence,

dGry"o _

1 dP - ,"\^-d P

Grr,o l+PC P

P

(4.25)

Notice that the quantity dG lG can be interpreted as the relative variation in the transfer function G. Equation 4.25 thus implies that the relative error in the closed-loop transfer function Grr,o is equal to the product of the sensitivity function and the relative error in the process. For frequencies where the sensitivity function is small it thus follows that the closed-loopsystem is very insensitive to variations in the process.This is actually one of the key reasons for using feedback. The formula (4.25) is one of the reasons why S is called the sensitivity function. The sensitivity function also has other interesting proper-
ties.

DisturbancAe ttenuation
A very fundamental question is how much the fluctuations in the process variable are influenced by feedback. Consider the situation shown in Figure 4.11 where the same load disturbance acts on a process P in open loop and on the process P in a closed loop with the controller C. Let lot be the output of the open-loop system and y4 the output of the closed-loop system. We have the following relation between the Laplace transforms of the signals,

39:
%r(s)

1- + P=( s,')1=C (,s,): s-(\ -s/ ) .

(4.26)

Disturbances with frequencies ar such that lS(lal)l < 1 are thus attenuated by feedback,but disturbances such that lS(lat)l > 1 are amplified by the feedback. A plot of the amplitude ratio of S thus immediately tells the effect of feedback.
Since the sensitivity only depends on the loop transfer function it can be
visualized graphically in the Nyquist plot of the loop transfer function. This is
illustrated in Figurc 4.12. The complex number I + Gt(iot) can be represented as the vector from the point -1 to the point Q(io) on the Nyquist curve. The sensitivity is thus less than one for all points outside a circle with radius 1 and center at -1. Disturbances of these frequencies are attenuated by the feedback.

r72

4.6 The Sensitiuitv Functions

Figure 4.11 Block diagr:ams of open- and closed-loop systems subject to the same disturbances.
ImGl(ia)

Re GlQa)

t
e e
Figure 4.12 Nyquist curve of loop transfer function showing graphical interpretation of maximum sensitivity. The sensitivity crossover frequency a)r., and the frequency a*, where the sensitivity has its largest value are indicated in the figure. All points inside the circle with center at the -1 have sensitivities greater than 1.

)]'-

The lowest frequency where the sensitivity function has magnitude 1 is called

k.

the sensitiuity crossouerfrequency atrr. The value

'k.

be is

M , : m aax)l's| v( \l a&.)wrt :)--l' -u;*^ll t .

+

p

f

t @

c

t

@

l

|

-

*

,

3

"|1t

+

1 c1

1

t

.r1, t,1

t

A.27\

'ehde

which is called the maximum sensitivitv. tells the worst-case amplification of

.nd

the disturbances.

ck.

The sensitivity cannot be made arbitrarily small. The following relation

113

Chapter 4. Controller Design

holds under reasonably general conditions for stable systems
I,*loglS(1o)lda- 0.

(4.28)

This very important relation is called Bode's integral. It says that if the sensitivity is reduced for one frequency it increases at another frequency. Feedback can thus redistribute the attenuation of disturbances for different frequencies, but it cannot reduce the effect of disturbances for all frequencies.
In Section 2.6 it was mentioned that random fluctuations can be modeled by a power spectral density. If the spectral density is Q(al for a system without control it becomes lS(iar)l'Q@) for a system with control. The rations of the variances under open and closed loop are thus

o

?
CL

,

_

Ii*lS(iat)l2Q@)aat

;k

[i*Q@)a,

(4.2e)

Stability Margins and Maximum Sensitivity
Notice that |1* Gt(iat)l is the distance from a point on the Nyquist curve of the loop transfer function to the point -1. See Figure 4.I2. The shortest distance from the Nyquist curve of the loop transfer function to the critical point -1 is thus IlM,, which is equal to the stability margin s-. Compare Figures 4.12 and 4.6. The maximum sensitivity can thus also serve as a stability margin. A requirement on M, gives the following bounds for gain and phase margins

e ^- )#M r=- l
e * ) 2 a r c s i n( h )

The requirement M, : 2 implies that g^ ) 2 and g^ ) 29" and M, : 1.4 implies Lhat g* > 3.5 and cp^ > 4t .

Nonlinearities in the Loop
The condition that the Nyquist curve of the loop transfer function is outside a circle at the critical point with radius I I M, has strong implications. It follows from Nyquist's stability criterion that the system remains stable even if the gain is increased by the factov M,l(M,- 1) or if it is decreased by the factor M,l(M, + 1).More surprising is that the closedloop is stable even if a static nonlineartly f is inserted in the loop, provided that

M, Mr+l-

-f(x), r

- r r rMr - ,t '

(4.30)

A small value of M" thus ensures that the system will remain stable in spite of nonlinear actuator characteristics. With M, : 2 the function lies in a sector limited by straight lines through the origin with slopes 213 and 2. With M,: 1.4 the slopesare between 0.28 and 3.5.

rt4

4.6 The SensitiuitvFunctions
ImGlQot)
ReGl(ia)

Figure 4.13 Nyquist curve of a nominal loop transfer function and its uncertainty caused by process variations AP.

LargeVariations
We wiII now investigate conditions for the system to remain stable under large variations in the process transfer function. Assume that the process transfer function changes from P to P + LP, where AP is a stable transfer function. Consider a point A on the the Nyquist curve of the loop transfer function; see Figure 4.I3. This point then changes from A to B in the figure. The distance from the critical point -1 to the point A is lI + G1l. This means that the perturbed Nyquist curve will not reach the critical point -1 provided that

l C ^ P l< 1 1 + G 7 1 ,

which implies

l

^

P

<l

lt

1

*G
c

r

t

I

(4.31)

Notice that the condition is conservative because it follows from Figure 4.13 that much larger changes can be made in directions from the critical point. The condition (4.31) must be valid for all points on the Nyquist curve, i.e, pointwise for all frequencies. The condition (4.31) for stability can then be written

AS

t LP(iat) |

I

|

\

/t

/

_

lP(irtt)l-lT(irtt)l'

(4.32)

where ? is the complementary transfer function. The inequality (a.32) tells that large relative perturbations are permitted as long as 7 is small. A simple conservative estimate of the permissible relative error in the process transfer function is llMt where

:-r*#l ffi,1, {+es) Mt:

-f*

lf Qat):l -f*l

P(iat)C(iat) 1 | + P(ia.a)C\a((iia.a) \|

115

r'hapter 4. Controller Design

is the largest magnitude of l?1. Notice that Mr is also the largest gain of the transfer function from set point to output for a system with error feedback.
Equation 4.32 can also be written as

Itp(irt.tf)fIi|

(4.34)

It follows from this equation that the magnitude of the permissible error ItP(ia)l is small when lP(iat)l is less than lf Qrtt)1.High model precision is thus required for frequencies where the gain of the closed-loopsystem is larger than the gain of the open-loop system.

Graphical Interpretation of Constraint on Sensitivities
The requirements that the sensitivities are less than given values have nice geometric interpretations in the Nyquist plot. Since the sensitivity is defined by
s(la:r)r ++,u-)'
it follows that the sensitivity has constant magnitude on circles with center at the critical point -1. The condition that the largest sensitivity is less than M, rs equivalent to the condition that the Nyquist curve of the loop transfer function is outside a circle with center at -1 and radius llM'.
There is a similar interpretation of the complementary sensitivity
r :- G'\9,.). 1 * Gt\rt)'

Introducing

GlQut) : ReGrQat) + iImGt(iot) : x * iY,

we find that the magnitude of T is given by

lrl:

JaTF \/F+;V +V

The magnitude of the complementary sensitivity function is constant if

x2+ v2: M?((t + *)2+ v2): M?(r i2x + x2+ v2),

or

*,'M--?f-f | *2x-r'W*1:o

This condition can be written as

w= x 2' +-2M' Y7-; '1."+-Y ' + M?

:

r ('+

M M=

? 1

)

\

2

+

" M Jr t " I I

?
M

?

-

'
T

-

:

(r Mr +?

\2
M

"M?
?_r

)

+Y

'

-

@I_

+

\/ Mu ?7\-2t |
-0.

116

4.6 The Sensitiuity Functions
ImGl(ia)

Re G1(ios)

Figure 4.14 Loci where the complementary sensitivity function has constant magnitude. The solid lines show points where the magnitude of the sensitivity function is M1 : l.l, 1.2, I.4, 1.5, 2, and 5 and the inverses of these values. The dashed line corresponds to Mt:I'

This is a circle with center at x: -M7lW? - 1) and !:0, and with radius r : M r lW ? - 1 ). F o r Mt:1 th e c i rcl e degeneratesto the strai ght l i ne w i th x : -0.5. The requirement that the complementary sensitivity function is
less than M; thus implies that the Nyquist curve is outside the corresponding
circle. The loci of constant gain of the complementary sensitivity function Gt are shown in Figure 4.14. Notice that the circles enclose the critical point -1.
Notice also that the closed-looptransfer function is insensitive to variations at
frequencies where the loop transfer function is far from the origin, particularly if the Nyquist curve is closeto the straight line ReGt(ia) : -0.5. This implies that controllers with the property

Ti xT'#E

(4.35)

are very robust. Compare with Section 6.3.
Combined Sensitivities The requirements that the maximum sensitivity is less than M, and the complementary sensitivity is less than M7 imply that the Nyquist curve should be outside the corresponding circles. It is possible to find a slightly more conservative condition by determining a circle that enclosesboth circles as is illustrated in Figure 4.I5. The radii and the centers of the circles are given in Table 4.1. In that table we have also given the circles that guarantee that both My and M, are smaller than specified vaiues. A particular simple criteria is obtained if it is required that M, - Mt.

Chapter 4. Controller Design
Mr:M1-)

M r : f u [ ,: 1 . 4

Figure 4.15 Curves for constant sensitivity, constant complementary sensitivity, and constant combined sensitivity.

Table 4.1 Center and radius of circles defining locus for constant sensitivity Mr, constant complementary sensitivity M7, constant mixed sensitivity, and equal sensitivities M : M, : Mt'

Contour M, Mt
M,,M,
M-Mr:Mt

Center
-1
_M? M?-r
M,(zMt - 1) - Mt -r I 2M,(Mt - t)
2M2-2M +t 2M(M -r)

Radius
TIM'
wMt=
Mr*Mr-I
2M,(M - 1) 2M -I
2M@1

4.7 Robustnessto ProcessVariations
Robustness to processvariations is a key issue in control systems design. Process parameters can change for many reasons; they typically depend on operating conditions. Time delays and time constants often change with production levels. Parameters can also change because of agrng of equipment. One of the key reasons for using feedback is that it is possible to obtain closed-loopsystems that are insensitive to variations in the process.
The analysis of the sensitivity functions in Section 4.6 gives insight into the effects of process variations. Equation 4.25 shows the effect of small process variations on the closed-loop system. In particular it tells that a closed-loop system is insensitive to small process variations for frequencies where the sensitivity function is small.
The robustness inequality given by (a.32) tells that a closed-loop system will remain stable when the process is perturbed from P(s) to P(s) + AP(s),
118

4.7 Robustness fo ProcessVariations
Im P(iar)

Figure 4.16 Shaded circle shows permissible values of P(iot) + LP(iot) given by the inequality (4.32). The circle is drawn for M1 : ).

where AP(ia) is a stabletransfer function,if the perturbationsare bounded by
lnP(iat)l .- I lP(ia)l lrQa)l'
This equation is one of the reasons why feedback systems work so well in practice. The mathematical models used to design control system are often strongly simplified. There may be model errors and the properties of a process may change during operation.
Equation (4.32) implies that the closed-loopsystem will be stable for substantial variations in the process dynamics. The closed-loop system is stable if, for all a, the perturbed process transfer function P(iat) + LP(iat) lies in a circle with center at P(iat) and radius Illf (iat)1,seeFigure 4.16. For a system designed with Mt : 2 it is possible to change the process gain by factors in the range 0.5 to 1.5 and the phase can be changed by 60". For a system with Mt : 1.4L4 the gain can be changed by factors in the range 0.3 to 1.7, and the phase can be changed by 45".

The Cancellation Problem

The sensitivities depend on the loop transfer function G7 : PC. Robustness criteria based on sensitivities can give misleading results when there are factors in the process and controller transfer functions that cancel each other. We will illustrate what happens with an example. e

S

p

Exauplp 4.3-CaNcELLArroNS

.e

Consider a process with the transfer function

TI

P(s) :

),

s2+2(asla2'

119

Chapter 4. Controller Design

and a controller with the transfer function
c ( s ): 50(s2* 2( as + o')
s(s2+10s+50)

This controller is a combination of a PID controller with a filter to provide high-frequency roll-off and a notch filter to reduce the excitation of the lowfrequency oscillatory mode. The loop transfer function is

G 7(s ) :

50

s(s2+10s+50)'

Notice that the oscillatory modes vanish becausethe same factor appears both in the controller and the process.The sensitivity functions are

s ( s ):
7(s) :

s /( s + c: r )9 s3+10s2*50s+50
1
s3+10s2*50s+50'

With the numericalvaluesa:0.5 and ( :0.02 we get Mr:1.2 and Mt: L

A casual application of the robustness inequality @.32) may lead us to believe that the closed-loopsystem is robust. However, if a controller is designed based

on the nominal value a : 0.5 and if the process parameter is changed by 5 percent to a : 0.4775 the system becomes unstable. The reason is that if we

interpret the parameter variation as an additive disturbance in the process

model the small perturbation in the process parameter o translates as a much

larger additive disturbance becauseit is associatedwith a resonant mode with

a very small relative damping.

I

The controller in the example is not a good design becauseit is bad practice to cancel slow process poles.

OtherRobustnessMeasures
There are other robustness results that permit more realistic processvariations than the stable additive perturbation used in the robustness inequality (4.32). One result represents the process transfer function as
Ar/-\
P ( s ): : \ " 1
l/(s)

where N(r) and D(s) are stable transfer functions. The results state that the

'I system is stable for variations Al/ and AD such that

max(lN (iat)l,lD(iat)l)-

t I + P(irtt)C(iat)
c(ia)

P(ia) | + P(iat)C (ia)
P(ia)c(ia)

I + P(iat)C(ia) | + P(ia)C(ia) (4.36)

l7+ P(iat)C(iat)l

: L(o),

L20

4.7 Robustness to Process Variations

1o'

x10
---:
vtu
F:
__-a
s 1 n_ 1
--
I U 1 0-t

100 0)

Figure 4.17 The magnitudes of the sensitivity function ls(;ar)l (dotted), the complementary sensitivity function lS(;ar)l (dashed) and the largest singular value X(la;) (solid) for the system in Example 4.3.

where o is the largest singular value. The parameter Mo : maxaL(a)

is a robustness measure. The robustness condition (4.32) requires that the processperturbation AP(s) is a stable transfer function. Criteria based on Mo do not have this limitation because it permits more general perturbations of the process, for example, changing a small stable pole, an integrator, or an unstable pole. It also covers the situation when there are cancellations of poles and zeros. To have good robustness the parameter Mo should be less than 3 to 5. Notice that Mo is larger than both M, and M1.
To illustrate the effectivenessof Mo we apply it to Example 4.3. Figure 4.17 shows ls(lar)l, lT(irtt)1,and L(rtt) for the nominal system in Example 4.3. We have Mo :46; since this is much larger than 5 it follows that the closed-loop system has very poor robustness.
Another way of investigating robustness is to explore variations in processparameters required to make the closed-loopsystem unstable. Changes in gain and time constants can be captured by replacing P(s) by rcP(us). Process variations that make the system unstable are given by

r c P ( i a a t ) C ( i o t*) 1 : 0 .

Solving for a and r for all ar gives the functions r(ar) and a(a). Peter Hansen has suggested the following robustness index

Rph: min(logl"(all + logla(at)l).

(4.37)

This measure is a generalization of gain margin and delay margin.

ot

The largest singular value Mo and the robustness measure Rpn are more

complicated than M, and M7, ar-d we will therefore mostly use M, and My.

It should, however, be kept in mind that evaluating robustness requires some

care, particularly when there are cancellations and when the loop transfer

127

Chapter 4. Controller Design
function has high peaks above the gain crossover frequency. This is typically the cases for motion control with systems having mechanical resonances and for predictive controllers investigated in Chapter B.
4.8 Quantifyingthe Requirements
Having understood the fundamental properties of the basic feedback loop we will now quantify the requirements on a typical control system. To do this it is necessaryto have a clear understanding of the primary goal of control. Control problems are very rich as was discussed in Section 4.2.ln general, we have to consider
r Load disturbance attenuation
o Measurement noise response
r Robustness to process uncertainties
o Set-point response
The emphasis on the different factors depends on the particular problem. Robustness is important for all applications. Set-point following is the major issue in motion control, where it is desired that the system follows commanded trajectories. In processcontrol, the set point is normally kept constant most of the time; changes are typically made only when production is altered. Rejection of load disturbances is instead the key issue in process control. There are also situations where the purpose of control is not to keep the process variables at specified values. Level control in buffer tanks is a typical example. The reason for using a buffer tank is to smooth flow variations. In such a case the tank level should fluctuate within some limits. A good stratery is to take no control actions as long as the tank level is within certain limits and only apply control when the level is close to the limits. This is called averaging control or surge tank control. There are special strategies developed for dealing with such problems, techniques such as gain scheduling have also been applied. This is discussedin Section 9.3.
The linear behavior of the system is completely determined by the Gang of Sfu (a.3). Neglecting set-point response it is sufficient to consider the Gang of Four (4.4). Specifications can be expressedin terms of these transfer functions.
A significant advantage with a structure having two degrees of freedom, or set-point weighting, is that the problem of set-point response can be decoupled from the response to load disturbances and measurement noise. The design procedure can then be divided into two independent steps.
o First design the feedback controller C that reduces the effects of load disturbances and the sensitivity to process variations without introducing too much measurement noise into the system.
o Then design the feedforward F to give the desired response to set points.
We will now discuss how specifications can be expressed in terms properties of the transfer functions (4.4).
r22

4.8 QuantifyingtheRequirements

Responseto LoadDisturbances
An estimate of the effectiveness of a control system to reject disturbances is given by @.26), which compares the outputs of a closed- and an open-loop system when the disturbances are the same. The analysis shows that disturbances with frequencies less than the sensitivity crossover frequency a)scare attenuated by feedback and that the largest amplification of disturbances is the maximum sensitivity Mr.
We will now turn specifically to load disturbances which are disturbances that drive the process variables away from their desired values. Attenuation of load disturbances is a primary concern for process control. This is particularly the case for regulation problems where the processes are running in steady state with constant set point. Load disturbances are often dominated by low frequencies. Step signals are therefore used as prototype disturbances. The disturbances may enter the system in many different ways. If nothing else is known, it is often assumed that the disturbances enter at the process input. The response of the process variable is then given by the transfer function

, t - t Grd, : I + P C

(4.38)

Since load disturbances typically have low frequencies it is natural that the criterion emphasizes the behavior of the transfer function at low frequencies. Filtering of the measurement signal has only marginal effect on the attenuation of load disturbances because the filter only attenuates high frequencies. For a system with P(0) I 0 and a controller with integral action control the controller gain goes to infinity for small frequencies, and we have the following approximation for small s;

G"d. :

T
e

1ose

o k

(4.3e)

Since load disturbances typically have low frequencies this equation implies that integral gain ki is a good measure of load disturbance rejection.

Exaupln 4.4-Lon DrsruRsANCEATTENUATToN Consider a processwith the transfer function P - (s * 1)-a and a PI controller with k - 0.5 and k; : 0.25. The system has M, : 1.56 and ams :0.494. Figure 4.18 shows the magnitude curve of the transfer function (4.38). The figure shows clearly that feedback reduces the low-frequency gain significantly compared with the open-loop system. The dashed-dotted line in the figure shows the gain curve for the transfer function sller.The figure shows clearly that this is a very good approximation of G"a for low frequencies, approximately up to cl^r. Integral gain ki is a good measure of load frequency disturbance attenuation. For high frequencies the load disturbance rejection is given by the process dynamics; feedback has no influence. The sensitivity crossover frequency is d)r. - 0.25, which is close to k;.
Attenuation of load disturbances can also be characterized in the time domain by showing the time response due to a representative disturbance. This

I23

Chapter 4. Controller Design

100
=
tln'

1 0-2-2 IU

10 - 1 a

100

101

Figure 4.18 The gain of the transfer function Gr4 from load disturbance to process variable for PI control (k : 0.5, Ti : 2.0) of the processp : (s * t)-4. The dashed dotted curve shows the gain of sf h,;, and the dashed curve shows gain of the process transfer
function P.

is illustrated in Figure 4.19, which shows the response of the process output

to a unit step disturbance at the process input. The output has its maximum

lmax : 0.66 for t-o, : 5.62. Furthermote) tmaxl)ms: 2.76, integrated error

IE :4.00 and integrated absolute error IAE : 4.26.

I

The steady-state error caused by a unit step load disturbance for proportional

control is

L s s- P ( 0 ) 1+frP(o)'

(4.40)

where fr is the proportional gain of the controller. As indicated in Figure 4.19, the steady-state error for proportional control can be used as an approximation of the largest error for PID control. For the system in Example 4.4 we have P ( 0 ) : 1 a n d k : 0 . 5 a n d ( 4 . 4 0 )g i v e s t h e e s t i m a t e e * o , &  s s: 1 1 7 . 5 : 0 . 6 7 which is close to the correct value 0.66.

Response to Measurement Noise
An inevitable consequenceof using feedback is that measurement noise is fed back into the system. Measurement noise, which typically has high frequencies, generates undesirable control actions and variations in the process variable. Rapid variations in the control variable are detrimental because they cause wear in valves and motors and they even saturate the actuator. It is important to keep these variations at a reasonable level. A typical requirement is that the variations are only a fraction of the span of the control signal. The variations can be influenced by filtering and by proper design of the high-frequency properties of the controller.
The effects of measurement noise are thus captured by the transfer function from measurement noise to the control signal

,t -T C
Gun:
I+PC

(4.4r)

For low frequencies (small s) the transfer function approaches 1/P(0) and for

t24

4.8 Quantifying the Requirements
0.8 u.b o4 0.2
0

U
s -o'5
1
tc
t
Figure 4.19 Response to a load disturbance in the form of a unit step with a PI controller having parameters k,:0.5 and ki = 0.25 and the processP : (s + 1)-n. The dashed curve shows the response to a proportional controller with gain k :0.5.

high frequencies (large s) we have approximately

Gu, x C.

For an ideal PID controller the transfer function Gun becomes infinite for large s which clearly indicates the necessity to filter the derivative, as discussed in Section 3.3. We illustrate with an example.

ExeMpLo 4.5-ErpECT oF FtLrpRINc Figure 4.20 shows the gain curve of the transfer function (4.4f) for PID control of the processP - (s+ 1)-+. The dashed line is for a controller with a first-order filter of the derivative and the full line for a controller with a second-order filter of the measured signal. The significant differences in the transfer functions for high frequencies is a good motivation for preferring the controller with filtering of the measurement signal. For low frequencies (small s) the transfer function approaches 1/P(0).

A simple measure of the effect of measurement noise is the largest gain of the

t

transfer function Gu,,,

t

Mu,, - max IG""(irtt)l

(4.42)

For PI control the gain of the transfer function Gu, has a peak close to the peak of the sensitivity function and we have approximately

Mu, N MrK.

(4.43)

For PID control the gain of the transfer function G,n typically has two local

t)

maxima, one is close to the maximum of the sensitivity function. The other

peak is larger

Mrn N lralTa,

(4.44)

125

Chapter 4. Controller Design
10'

B a\

1

0 1

0 0

t-

10

100

10t

a

102

Figure 4.20 The magnitude of the transfer function Gu, : CS for PID control (k : I, Ti : 2, Td : I, Tf : 0.2) of the process P : (s + 1)-4. The solid line represents a controller with a second-order noise filter of the measured signal (3.16) and the dashed line a controller with a first-order filter of the derivative (3.15).

and it occurs close to the frequency LlTf .
If the standard deviation of the measurement noise is on, a crude estimate of the variations in the control signal is Munon More accurate assessment can be made if the power spectrum Q" of the measurement noise is known. The standard deviation of the control signal is then given by

o ?:,

I

p,(at)dat. _rG*,(iot)1z

(4.45)

However, it is rare that such detailed information is rarely available for typical applications.

Robustnessto ProcessVariations
The inverse of the maximum sensitivity is the shortest distance from the critical point -1 to the Nyquist curve of the loop transfer function.
The sensitivity to small variations in process dynamics is captured by the sensitivity function. We have

d T : D^ dPP. T
Variations in process dynamics thus have small influence on the closed-loop system for frequencies where the sensitivity function is small.
Variations in process dynamics may also lead to instability. The condition

ItP(iat)l .lP(iut)l

I
lr (ia),

guarantees that a variation A,P(ia) in the process transfer function does n : make the system unstable. Robustness to process variations is thus captur, : by the sensitivity and the complementary sensitivity functions. Simple m,. , sures are the maximum sensitivity Mr, the maximum of the complementi-.-

126

4.8 Quantifying the Requirements

sensitivity Mt, or the largest combined sensitivity M. T\zpical values of the sensitivities are in the range of L2 - 2.0.
Other measures are the gain margin g* (typically 2 to 8), the phase margin g^ (typically 30" to 60"), or the stability margin sm: llM, (typically 0.5 to
0.8). Compare with Section 4.4.

Trade-offs
Load disturbance attenuation is captured by integral gain l?i. It follows from (4.39) that attenuation of low-frequency disturbances is approximately inversely proportional to k;. Injection of measurement noise is captured by the noise gain Mun. It follows from (4.42) that Mun gives the gain from measurement noise to control variable. The trade-off between load disturbance attenuation and injection of measurement noise can thus be achieved by balancing h; and Mun.

Set-Point Response
By using a controller with two degrees of freedom it is possible to obtain any desired response to set-point changes. This will be discussed further in Chapter 5. The limitations are given by the permissible magnitude of the control signal. In some cases only the control error is measured. A controller with two degrees of freedom then cannot be used and the response to set points has to be handled by proper choosing of the controller transfer function. Large overshoots can be avoided by requiring low values of M7.

Summary

Summarizing we find that the behavior of the system can be characterized

in the following way. The transfer function from load disturbance to process

variable is

Gvd: I+PC :PS -;,

(4.46)

where the approximation holds for low frequencies. The effect of measurement noise can be captured by the noise gain

Mun-- -3*

lG""(ia)l*

( kM"
\noir,

for PI control

(4.47\

forthe PID controller (3.16)

ri'hich strongly depends on the filtering of measurement noise. Stability and robustness to process uncertainties can be expressed by the
sensitivity function and the complementary sensitivity function

s- T+PC'

T- PC I+PC,

,i'herethe largest values of the sensitivity functions M, and Ms are good quanti:ative measures. The parameter llM, is the shortest distance from the critical : ,rint to the Nyquist curve of the loop transfer function.
Essential features of load disturbance attenuation, measurement noise in'-,ction,and robustness can thus be captured by four parameters ki, Mur, Mr,

L27

Chapter 4. Controller Design
and M,. An attractive feature of this choice of parameters is that ki and Mun are directly related to the controller parameters and that there are good design methods that can guarantee given M, and Ms.

4.9 ClassicaSl pecifications

The specifications we have given have the advantage that they capture robustness as well as the responses to load disturbances, measurement noise, and set points with only four parameters. Unfortunately, it has been the tradition in PID to judge a system based on one response only, typically the response of the output to a step change in the set point. This can be highly misleading as we have discussed previously. A large number of different parameters have also been used to characteize the responses.For completenessand to connect with classical literature on PID control some of the classical specifications will be summarized in this section.

CriteriaBasedon TimeResponses
Many criteria are related to time responses,for example, the step response to set-point changes or the step response to load disturbances. It is common to use some feature of the error typically extrema, asymptotes, areas, etc.
The maximum error errru"is defined as

max: max In(r)l
0(/{:o'
7-"* : argmax le(r)1.

(4.48)

The time 7*u" where the maximum occurs is a measure of the response time of the system. The integrated absolute error (IAE) is defined as

IAE _ lo*vt)t0,.

(4.4e)

A related error is integrated error (IE), defined as

,": .loe(-t)dt.

(4.50)

The criteria IE and IAE are the same if the error does not change sign. Notice that IE can be very small even if the error is not. For IE to be relevant it is necessary to add conditions that ensure that the error is not too oscillatory. The criterion IE is a natural choicefor control of quality variables for a process where the product is sent to a mixing tank. The criterion may be strongly misleading, however, in other situations. It will be zero for an oscillatory system with no damping. lt wiil also be zero for a control \oop with two integratots.
There are many other criteria, for example, the time multiplied absolute error, defined by

IrNAE - t"le(t)ldt. .[,

(4.51)

t2B

4.9 Classical Specifications

The integrated squared error (ISE) is defined as

ISE- l'"n1r1'or. Jo

(4.52)

There are other criteria that take account of both input and output signals, for example, the quadratic criterion

eE: ,lo-rn'(r+)pu21t)1d,t,

(4.53)

where p is a weighting factor. The criteria IE and QE can easily be computed analytically, simulations are, however, required to determine IAE.
One reason for using IE is that its value is directly related to the parameter ki of the PID controller, as is illustrated by the following example.

Exeupln 4.6-InrncRAL Gen aNo Itr n'oRLoao DrsruneANcns Consider the control law
u ( t ) - ke(t*) u,Io eQ)d-t kr?;
Assume that this controller gives a stable closed-loop system. Furthermore, assume that the error is zero initially and that a unit step load disturbance is applied at the processinput. Since the closed-loopsystem is stable and has integral action the control error will go to zero. We thus find

u(oo-) u(o)- u, e(t)dt. lo-

:ince the disturbance is applied at the process input, the change in control

-rgnal is equal to the change of the disturbance. Hence,u(oo) - u(0) - 1 a n d

.i'eget

rE: I e@dt:l:

Jo

ki

Ti
K.

(4.54)

u

Integral gain fr; is thus inversely proportional to the integrated error caused rr- a unit step load disturbance applied to the process input.

Set-PoinRt esponse
{pecifications on set-point following are typically expressedin the time domain. - hey may include requirements on rise time, settling time, decay ratio, over-:root, and steady-state offset for step changes in set point. These quantities .r'edefined as follows, see Figure 4.21.
. The rise time ?. is defined either as the inverse of the largest slope of the step response or the time it takes for the step response to change from 10 percent to 90 percent of its steady-state value.

t29

Chapter 4. Controller Design
!tp
y0

Figure 4.21 Specifications on set-point following based on the time response to a unit step in the set point. The upper curve shows the response of the output, and the lower curve shows the corresponding control signal.

o The settling time T, is the time it takes before the step response remains within p percent of its steady-state value. The values p - I,2, and 5 percent of the steady-state value are commonly used.

o The decay ratio d is the ratio between two consecutive maxima of the

error for a step change in set point or load; see Figurc 2.35. The value d : Il4, which is called quarter amplitude damping, has been used tra-

v

ditionally. This value is, however, normally too high, as will be shown later.

E V

o The ouershoof o is the ratio between the difference between the first

P

peak and the steady-state value of the step response. It is often given

P- l -

in percent. In industrial control applications it is common to specify a

maximum overshoot of 8 to 10 percent. In many situations it is desirable,

however, to have an over-damped response with no overshoot.

Cr

. The steady-state error ss: jrp - 3o is the steady-state control error e.

.S1

This is always zero for a controller with integral action. i\'(

Actuators may have rate limitations, which means that step changes in the

control signal will not appear instantaneously. In motion control systems it

is often more relevant to consider responses to ramp signals instead of step

,n

signals.

130

4.9 Classical Specifications

Figure 4.22 The error due to a unit step load disturbance at the process input and some features used to characterize attenuation ofload disturbances. The dashed curve show the
open-loop error.

Responseto LoadDisturbances
The response to load disturbances is of primary importance in process control. Figure 4.22 shows the output for a step disturbance in a load applied at the processinput and somefeatures that are used to characterize the response.The figure shows the maximum error maxt,he time it takes to reach the maximum T^u, and the settling time ?r. In addition to these numbers the integrated error (IE) or the integrated absolute error (IAE) are also commonly used to characterize the load disturbance response.The maximum error for a unit step and the time where this is reached can be approximated by

em* ^a- -x--

1
1+ rrFO

T^ut N a)*t

We illustrate these estimates by an example.

(4.55)

Exaupr,n 4.7-EsUMATTNG THE MAxTMUMEnnon When a process with the transfer function P(s) - (s * 1)-4 is controlled by a P I c ont r ol l e r h a v i n g p a ra m e te rs fr:0 .28 and,k;:0.88, w e have a,ns:O.bbg, smax: 0.59, and 7-." : 5.15. The estimates above give maxN 0.56, ?-u* - b.6.

Criteria Based on Frequency Responses

Specifications can also be related to frequency responses. Since specifications

\vere originally focused on set-point response it was natural to consider the

r

transfer function from set point to output. A typical gain curve for this response

t

is shown in Figure 4.23.It is natural to require that the steady-state gain is

Lrne.Tlpical specifications are then as follows:

o The resonancepeak Mo is the largest value of the frequency response.

131

Chapter 4. Controller Design
Mp 1
rl J'

aP

@6

Figure 4.23 Gain curve for transfer function from set point to output.

The peak frequency ao is the frequency where the maximum occurs. Tkrebandwidth at6is the frequency where the gain has decreasedto IlyO,.

For a system with error feedback the transfer function from set point to output is equal to the complementary transfer function, and we have Mp: Mt.
Specifications can also be related to the loop transfer function. Useful features that have been discussed previously are
o Gain crossover frequency osr.
o Gain margin g-.
o Phase margln (pm.
o Maximum sensiLivity M,.
o Frequency where the sensitivity function has its maximlrm a)ms.
o Sensitivity crossover frequency arr.
r Maximum complementary sensitivity Mt.
o Frequency where the complementary sensitivity function has its maxi-
lJllJm (Drr1.

Relations between Time and Frequency Domain Specifications
There are approximate relations between specifications in the time and frequency domain. Let G(s) be the transfer function from set point to output. In the time domain the response speed can be characterized by the rise time 7,, the average residence time Tor, or the settling time 7r. In the frequency domain the response time can be characterized by the closed-loopbandwidth a6, the gain crossover frequency a)s, and the sensitivity frequency a;-r. The product of bandwidth and rise time is approximately constant, and we have

Tra6 x 2.

(4.56)

L32

I
I s
S
a
is r
pr
Be
of fici cox or mei gair this Sec feed phar impr
F impc eXprl
wher it car the p circler .syster
(Ds6La
FOTD Cor
rnd a iefiner

4.9 Classical Specifications

It has previouslybeenshownthat G',(0)
tar:-G(o) '

see(2.16). The overshoot of the step response o is related to the peak M, of the fre-
quency response in the sense that a larger peak normally implies a larger overshoot. Unfortunately, there are no simple relations because the overshoot also depends on how quickly the frequency response decays. For Mo 4I.2 the overshoot o in the step responseis often closeto Mo- 1. For larger values of Mo the overshoot is typically less than Mp - 1. These relations do not hold for all systems;there are systems with Mp:1 that have a positive overshoot.These systems have transfer functions that decay rapidly around the bandwidth.
To avoid overshoots in systems with error feedback it is therefore advisable to require that the maximum of the complementary sensitivity function is small, say,Ms: 1.1- I.2 in order to avoid too large overshootin the step response to command signals.

Performance Assessment

Before designing a controller it is useful to make a preliminary assessment

of achievable performance. It is interesting to know if a PID controller is suf-

ficient or if the performance can be increased substantially by using a more

complex controller. It is also interesting to know if a PI controller is sufficient

or if derivative action gives significant improvements. To make the assess-

ment we need some measure of performance. In this section we will use the

gain crossover frequency as" as a yardstick. When the phase margin is 60'

this frequency is equal to the sensitivity crossover frequertcy a)sc.Recall from

Section 4.6 that disturbances with frequencies lower than o)scare reduced by

t'eedback.For phase margins lower than 60' we have @r, 1a)sc, &nd for larger

phase margins we have o", ) os,. Attenuation of load disturbances is thus

improved with increasing gain crossover frequencies.

Process dynamics with non-minimum phase properties like a time delay

rnlposesfundamental limitations on the achievable performance which can be

.:xprssedby the inequality

alnrL < a,

(4.57)

'.rhere o is a number less than 1. Since the true time delay Z is rarely known

.t can be approximated by the apparent time delay 2". Figure 4.24 shows

:lre product oo"Lo for a large batch of systems under robust PID control. The

.rrcleswhich represents FOTD systems show that the product is 0.5 for FOTD

-r'stems. For high order systems with lag dominated dynamics the product

,, Los is larger than 0.5 becausethe apparent time delay of the approximating

:'OTD model is larger than the true time delay of the system.

Consider a closed-loopsystem with a processhaving transfer function P(s)

':rd & controller with transfer function C(t). The gain crossover frequency is

:..finedby

argP(iroo") + arg C(ian,) - -7T * g*.

(4.58)

133

Chapter 4. Controller Design

102
101 *l
100

a
^xE .^ ,xXA

xx^*

F*ifl.' 'I

xX %' . -J8 l t.X. *I * -

I

x xX

@6. O- 3'::88

lFJr-&85qna-

-8-

- -A- - -E-E- -6s-

-g. ee

10 - ' 0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

T

Figarc 4.24 The product of gain crossover frequency ao" and apparent time delay Io as a function of normalized dead time, for a large set of systems under PID control. The circles show results for FOTD systems and the squares for SOTD systems. The PID controllers are designed to give a combined sensitivity M :1..4. All systems are described in Section 7.2. The dashed line gives the relation aorLa: 0.5.

Notice that the units radians is used in this equation. A PD controller has a maximum phase lead of about 60" (x l3 rad), a proportional controller has zero phase lag, a PI controller has a phase lag of about 45" (x14 rad), and a PID controller can have a phase lead of about 45'.If a phase margin of 45' is desired it follows from Equation 4.58 that crossover frequencies for PI, PID, and PD control are the frequencies where the process has phase-lags of 90", 135', and 195", respectively. These frequencies are denoted 8s fde6,fd135,ard ans. An estimate of the controller gains required can be obtained by computing the processgains at the corresponding frequencies.Notice that this assessment only requires the process transfer function. We illustrate by two examples.

Exeupln 4.8-MuLrr-LAG Pnocpss Consider a process with the transfer function

P /\-Ds )/-:

1
GllF

We have aso :0.41 and Kgo: 0.73,where Kee denotesthe processgain at oss.

F ur t her m or e, w e h a v e a )r1 1: 0 .6 7 , K1 1 ;:,0s .48, and @ 1e5: L.14, K .* s :0.19.

We can thus expect that disturbances with frequencies lower than 0.4 rad/s

can be reduced by PI control. Since /0135is moderately larger than &)eewe c&D

expect that a PI controller can be improved somewhat by introducing derivative

action. The gain of a PID controller can be expected to be about twice as large

as for PI control. Also notice that the apparent time delay is Z : 2.14 and that

as" :0.47 which is in good agreement with (4.24).

I

Exaupln 4.9-A Lac-DonnrNArEDPnocpss Consider a process with the transfer function
P ( s ): ( s+ 1 ) ( 0 . l s+ 1 ) ( 0 . 0 l s+ 1 ) ( 0 . 0 0 l+s 1 ) '

134

4.9 ClassicalSpecifications

Table 4.2 Parameters of PI controllers for the process P(s) : (s + 1)-3 designed with different M".

M,

ki

Mun

b ams IAE T" Mt

r.2 0.355 0.171 0.426 1.00 0.671

1.00

t.4 0.633 0.325 0.866 1.00 0.74 3.07 10.3 1.00

1.6 0.862 0.461 1.379 0.93 0.79 2.28 7.87 1.05

1.8 1.056 0.580 1.901 0.70 0.83 2.00 6.77 r.24

2.0 L.222 0.685 2.444 0.50 0.86 1.89 6.27 I.45

W e hav e 0 )s 0:3 .0 , K g o - 0 .3 , o )7 8 5:9 .9, K 135: 0.07,ond @ 1e5- 47.5, K .* s : 0.004. We can thus expect that disturbances with frequencies lower than 3 radf s can be reduced by PI control. With a PID controller disturbances with frequencies up to 9.9 rad/s can be reduced. In this case, there are significant performance benefits from using derivative action. Since @1e5is much larger than frrss there may be substantial benefits by using more complex controllers. Since the processgain K135is so low the improved benefits require controllers with high gain, and the benefits may be not be realizable unless sensor noise if very low.
DesignParameters
In control system design and implementation it is convenient to have a parameter that can be changed to influence the key trade-offs in a design problem. Performance expressedby fast responsetime and good attenuation of load disturbances can be obtained, but large control signals may be required. Stricter requirements on robustness may lead to poorer performance.
The trade-off between performance and robustness varies between different control problems. Therefore, it is desirable to have a design parameter to change the properties of the closed-loopsystem. Ideally, the parameter should be directly related to the performance or the robustness of the system; it should not be process oriented. There should be good default values so a user is not forced to select some value. This is of special importance when the design procedure is used for automatic tuning. The design parameter should also have a good physical interpretation and natural limits to simplify its adjustment.
The behavior of a system can often be characterized by a few dominant poles that are closeto the origin. When there is one real dominant pole this pole can be used as a design parameter. This is used, for example, in the design method Lambda T\r.ning,which will be discussed in Section 6.5. When the dominant poles are complex the distance from the origin of the poles ale and their relative damping ( are good design parameters. This applies to controllers based on cole placement design, which will be discussed in Section 6.4. The maximum sensitivity M, or the combined sensitivity M are good design variables for :'egulation problems. This is illustrated in Figure 4.25, which shows the effect ,f M, on time and frequency responses for a PI controller, and in Table 4.2,
135

Chapter 4. Controller Design

-'

s0

n.Js Illustrate's the effects or,r.i'rrg M, as aa"rlgr i.ru-"t"'i. The lefi c..rrr"s "sihgo.rwt. the Nyquist plots of the loop transfer functions together with the circles of constant
Ms:1.2 (dotted), 1.4, 2.0 (dashed). The curves on the right show process outputs and
control signals for the different values of the design parameters.

which gives numerical values of controller parameters and various criteria. The step response for M, : t.2 has no overshoot and relatively long settling time. The settling time decreasesand the overshoot increases as the value of M, is increased. Notice that set-point weighting is used for larger values of Ms to reduce the overshoot. The performance also increases with increasing Mr. The values of IAE decreasewith about a factor of 2. Apart from use in design it is also possible to implement systems where the user can adjust the design parameters on line.
4 . 1 0S u m m a r y
In this section we have summarized some important issues for the design of control systems, with particular emphasis for PID control. A discussion of the basic feedback loop showed that it is necessary to consider six transfer functions (the Gang of Six) to determine the properties of a feedback loop. This is severely neglected in most elementary texts in control and in the literature of PID controllers. The notion of stability was then discussed.This is important because the risk for instability is the main disadvantage of feedback. Stability criteria and stability margins were also introduced. The stability criteria also made it possible to obtain the parameter regions which give a stable closedloop system under PID control. Characterization of a closed-loopsystem by its poles and zeros give very valuable insight, and it is also closely related to many design methods. The sensitivity function and the complementary sensitivity functions, which are useful to express the robustness to parameter variations, were also introduced. The problem of controller design was then discussed, and a number of criteria used to give specifications on a control system were also introduced. The key factors are load disturbances, measurement noise, robustness, and set-point response. A nice result is that for systems having
136

4.11 Notes and References
two degreesof freedom it is possible to design for disturbances and robustness. The desired set-point response can then be obtained by using feedforward. For PID control set-point weighting is a special form of controller with two degrees of freedom that often is sufficient. It is also shown that the key requirements can be parametefized in a simple way. Load disturbance response is captured by integral gain of the controller h,i.Effects of measurement noise are captured by the noise gain Mur, which has a simple relation to controller parameters. Robustness is captured by the maximum sensitivities M" and M1.

4.'11Notesand References

Control system design is complicated because many factors have to be con-

sidered and trade-offs have to be made. It is therefore natural that it took

time before a good understanding was developed. Early work on control de-

sign was based on the differential equations describing the closed-loopsystem.

A typical approach was to adjust the controller parameters so that the domi-

nant closed-looppoles had desired properties. Systematic methods for control

system design appeared in the 1940s when the field of control emerged. The

design methods were based on frequency response, computations were based

on graphics, and modeling was often done experimentally by perturbing the

system with sinusoidal signals;see [Bode,1945;James et al.,Ig47; Brown and Campbell, 1948; Chestnut and Mayer, 1959]. It is noteworthy that particular

emphasis was given to robustness to process variations. The insightful book

[Horowitz,1963] gives a mature account. This book also emphasizes the important concept of controllers that have two degrees of freedom. Such controllers

admit a decoupling of the responsesto set points and load disturbances.

There was a paradigm shift in the 1960s when differential equations reap-

peared in the name of state-space systems; see [Zadeh and Desoer, 1963]. This coincided with the appearance of digital computers, which permitted efficient

numerical computations. The important ideas of optimal control and Kalman

filtering are key contributions; see [Bellman, 1957; Kalman, 1960; Kalman and Bucy, 1961; Kalman, 1961; Pontryagin et aI., 1962; Athans and Falb,

1966; Bryson and Ho, 1969].

i

There was a very dynamic development of theory, many design methods and

l

efficient computational techniques were also developed;see [Boyd and Barratt,

I

1ee1l.

L

t.

The robustness issue was unfortunately neglected for a long period. This

l,)

was remedied with the emergence of the so called t{n theory, which led to a

t-

reconciliation with the classical frequency response methods. The books [Doyle

et al., 1992; Zhou et al., 1996; Skogestad and Postlethwaite, 1996] give a bal-

anced perspective. The robustness criteriia Mr, Ms, and Mo are results of robust

control theory. An interesting novel robustness criterion which focuses on vari-

ations in the process parameters has been suggested in [Hansen, 2000] and [Hansen, 2003]. The question of fundamental limitations is closely related to
robustness as is discussedby [Astriim, 2000j. For processcontrol the true time delay is a key limiting factor. Notice that the true time delay can be different

from the apparent time delay obtained when fltting FOTD models.

t37

Chapter 4. Controller Design Many practitioners of control have been fully aware of the importance of the
compromise between performance and robustness; see [Shinskey, 1990], and it is now pleasing to see that robust control theory has made it possible to merge theory and practice; see [Panagopoulosand Astrdm, 2000].
In the literature on PID control there has been a long discussion, whether tuning should be basecion response to set-point changes or load disturbances. It is surprising that so many papers just show the response of process output to a step change in the set point. Since steady-state regulation is the essential problem in processcontrol, load-disturbance responsesare more important than responsesto set points as has been emphasized many times by Shinskey; see for example [Shinskey, 1996]. One of the useful conclusions of robust control theory is that six responses are required to get a complete understanding of a closed loop system,
Another lesson from robust control theory is that high-frequency roll-off improves robustness. This is a good reason to use effective filtering in PID control.
138

Feedfonvard Design
5.1 Introduction
Feedforward is a simple and powerful technique that complements feedback. Feedforward can be used both to improve the set-point responsesand to reduce the effect of measurable disturbances. IJse of feedforward to improve set-point response has already been discussed in connection with set-point weighting in Section 3.4. We will now give a systematic treatment of design of feedforward control and also discuss design of model-following systems. The special case of set-point weighting will be discussed in detail, and we will present methods for determining the set-point weights. We will also show how feedforward can be used to reduce the effect of disturbances that can be measured.
5.2 lmprovedSet-PointResponse
Feedforward can be used very effectively to improve the set-point response of the system. By using feedforward it is also possible to separate the design problem into two parts. The feedback controller is first designed to give robustness and good disturbance rejection and the feedforward is then designed to give a good response to set-point changes.
Effective use of feedforward requires a system structure that has two degrees of freedom. An example of such a system is shown in Figure 3.10. It is first assumed that the system has the structure shown in Figure 5.1. Let the process have the transfer function P(s). We assume that a feedback controller C(r), which gives good rejection of disturbances and good robustness, has been designed, and we will consider the problem of designing a feedforward compensator that gives a good response to set-point changes.
The feedforward compensator is characterized by the transfer functions M"(s) and Mr(s), where My(s) gives the desired set-point response.The system works as follows. When the set point is changed the transfer function -U,(r) generates the signal uy,which gives the desired output when applied trs input to the process.The desired output y* is generated by Mr(t).Under ideal conditions this signal is equal to the processoutput y. The control error e
139

Chapter 5. Feedforward Design

Figure 5.1 Block diagram of a system with two degrees of freedom.

is zero, and the feedback signal u 16 tarr'e:insconstant. If there are disturbances or modeling errors the signal y^ and y will differ. The feedback then attempts

to bring the error to zero.The transfer function from set point to processoutput

is

G rr"o(t) -

P(CMya M") : I+PC

irv, rry -,r

PMu-My 1a pa

.

(5 1)

The first term represents the desired transfer function. The second term can be made small in two ways. Feedforward compensation can be used to make PMu-My small, or feedback compensation can be used to make the error small by making the loop gain PC larye. The condition for ideal feedforward is

My: PMu'

(5.2)

Notice the different character of feedback and feedforward. With feedforward it is attempted to match two transfer functions, and with feedback it is attempted to make the error small by dividing it by a large number. With a controller having integral action the loop gain is very large for small frequencies. It is thus sufficient to make sure that the condition for ideal feedforward holds at higher frequencies. This is easier than to satisfy the condition (5.2) for all frequencies.

SystemInverses
From (5.2) the feedforward compensator Mu rs

Mu : P-tMr,

(5.3)

which means that it contains an inverse of the process model P. A key issue in design of feedforward compensators is thus to find inverse dynamics. It is easy to compute the inverse formally. There are, however, severe fundamental problems in system inversion, which are illustrated by the following examples.

Exeuplp 5.1-INvoRSE oF FOTD Sysrnvr

The system

P ( s ):

1
Tj*

e-'r

r40

5.2 Improued Set-Point Response

has the formal inverse

p - t ( r ) : ( 1 + s T ) e ' 1.

This system is not a causal dynamical system becausethe term etl represents a prediction. The term (1 + sT) requires an ideal derivative. which also is problematic as was discussed in Section 3.3. Implementation of feedforward thus requires approximations.

Exanrpln 5.2-IwvnRSEoF Svsrnu wITHRHP Zsno The system

P(s) -

.s-1
s +:z

has the inverse

tp

-

1

1

-
\

t
D

/

-

-
s

-

D^
1

r-

OT

t

r

Notice that this inverse is an unstable system.

n

It follows from (5.2) that there will be pole-zero cancellations when designing feedforward. The canceled poles and zeros must be stable and sufficiently fast; otherwise, there will be signals in the system that will grow exponentially or decay very slowly.
The difficulties in computing inverses can be avoided by restricting the choice of Mr. Since Mu: P-'M, we can require that the transfer function M, has a time delay that is at least as long as the time delay of P. Further, M, and P must have the same zeros in the right half plane. To avoid differentiation, the pole excessin M, must be at least as large as the pole excessin P. One possibility is to approximate processdynamics by a simple model and to choose M, as a model having the same structure. To design feedforward we thus have to compute approximate system inverses with suitable properties.

ApproximateInverses
Different ways to find approximate process models were discussed in Section 2.8. Here we will give an additional method that is tailored for design of feedforward control.
Let PI denote the approximate inverse of the transfer function P. A common approximation in processcontrol is to neglect all dynamics and simply take the inverse of the static gain, i.e.;
pt(r) : P(o)-1.

A number of results on more accurate system inverses have been derived in system theory. Some of these will be shown here. Note that the inverse transfer function only has to be small for those frequencies where the sensitivity tunction is large.

t4l

Chapter 5. FeedforwardDesign

Exaupr,n5.3-AppRoxrMATEIwvoRspoF FOTD Svsrnm The system
P(s-) j*u-"

has the approximate inverse

P '\("s, /:-)

t *lT
I+sTf N'

where N givesthe frequencyrange where inversion is valid.

tr

Exevplp 5.4-AppRoxrMATEIurrBnsnon'SysrpM wrrH RHP Zpno
The system
P ( s: #)

has the inverse

pt(r:)H

Notice that the unstable zero in P gives rise to a pole in PT that is the mirror

image of the unstable zero.

I

A simple model for systems with monotone step responses has the transfer

function

P ( s' ) :-(J1+ s^?-)"' - "

(5'4)

We call this the NOTD model because it has one time delay and n equal lags.
The approximation can be made by fitting the transfer functions at a few relevant frequencies. Assuming that we want a perfect fit at a :0 and ctt- os
we find that

P(0)- K
l P ( l a r s-) l ( I + ( a s T ) 2 ) n t 2
aryP(ias) : -, arctan ooT - @oL.

Solving these equations we find

K _ P(0)
r_w a)s L _ argP(iah) + , arctan cosT
0g

(5.5)

A good fit is required at the frequency o^, of maximum sensitivity. Since this frequency is known when the feedback controller C has been designed it is natural to choose0)o: o)*r.
We will give an example to illustrate the accuracy of the approximation.

r42

5.2 Improued Set-Point Response

0.3

.So.z
I 3q 0 . 1

0 -2
10-

-1
10 a

100

101

Figure 5.2 Error when fitting NOTD models of different orders to the transfer function P(s) : 1/(s + 1)a for n : 1 (dotted), n : 2 (solid), and n : 3 (dashed).
Table 5.1 Parameters and maximum errors when fitting NOTD models of different orders to the transfer function P(s) : 1/(s + 1)4.

K

T

max

a^u"

10.5 1 1.9566 2.4012 0.1828 1.7400 2 0.5 1 r.1352 1.5000 0.0710 1.4500 30.5 1 0.5169 r.7773 0.0255 1.3300 11.0 1 1.8235 3.8730 0.2603 0.2800 21.0 1 r.0472 L.732r 0.1043 0.3400 31.0 1 0.4737 r.2328 0.0378 0.3600

Exauplp 5.5-FouR EQUALLacs Considera processwith the transfer function

P

\(

-s/ )

-

,

(

s

t +

, f

, ;

. a

'

In 'r.

Figure5.2we showthe error lP(iot)-e1tro1lfor NO and in Table5.1we givethe parametersand the ma

TD modelswith ximumerror for

different different

tits. Noticethat relatively large errors,20 to 30 percent,are obtainedfor first-

'rder models,and significantreductionsare obtainedby increasingthe model

,rder.

n

For a processgiven by (5.a) it is reasonableto choosethe responsemodelas

My:E;me-'I.

.: then follows from (5.2) that the feedforward compensator is given by

I:

M,: I (,.lt'3 )"

(5'6)

K\l tsT^)

I43

Chapter 5. Feedforward Design
z

\1 0.5 0

1.5

1

s

nE

0

10
Figure 5.3 Responsesto set points and load disturbances of the processP(s) : 1/(s+ l)a with a PI controller and a feedforward based on the FOTD model for desired response times T, : l0 (dashedline) and T, :2 (solid line).

In this particular case the feedforward compensator thus consists of a process model and a lead-lag or lag-lead network.
There are situations where it is desired that a feedback loop should have a set-point response with specified response time. A typical case is when several substances coming from different sources are mixed. When making production changes it is highly desirable that all systems react to production changes in the same manner. It is very easy to accomplish this when the required process dynamics are slow in comparison to the bandwidth of the feedback, because it follows from (5.1) that the set-point response is not very sensitive to the process model. We illustrate this with an example.
Exaupln 5.6-Sr-ow Snr-PorNT RESpoNSE Consider a processwith the transfer function
t,,. P (\ "s/)-- , ( s + 1 ; a .
controlled with a PI controller with K - 0.775 and Ti :2.05. This gives M, :2 antda*, : 0.559. Approximating the process model with a first-order FOTD model givesthe parametersKp: l, T - 2.57,and Z :1.94, see (5.5).Assume that the desired set-point response is given by
Mr(t) : l+sT,
Figure 5.3 shows set-point responsesfor different values of Tr. The figure shows that the load disturbance response is the same in both casesand that the setpoint response has the expected behavior. Notice the distortions of the curves for T, - 2; they are due to the fact that the model does not fit so well for high

144

5.3 Set-Point Weighting

frequencies. A rule of thumb is that the first-order model is reasonable for

(0^rT, > 2.In this case this gives T, ) 3.6. More accurate models are required

to get the desired behavior for T, :2.

tr

The advantage by using a controller with two degrees of freedom is that the good disturbance attenuation can be maintained while making the set-point response slower.

5.3 Set-PoinWt eighting

For simple PID controllers it may not be necessary to use a complete system with two degreesof freedom. The desired set-point responsecan often be maintained simply by adjusting the set-point weights; see Section 3.4. To determine the set-point weights we consider the transfer function from set point to processoutput, and we chooseset-point parameters so that the largest gain of this transfer function is one or closeto one. This gives a set-point response without overshoot for most systems.
It follows from Figure 3.10 and Equation 3.20 that the transfer function from set point to process output is

Grr,o(t) :

ki -l bks t ckas2 P(s)C(s) : kt+ ks+EF 1+ P6CG)

ki -l bks * ck6sz
7r* Pt* P*z "(')

(5.7)

One possibility to achieve the largest gain close to one is to specify that the
maximum sensitivity Mt is closeto one. In such a caseit may not be necessary
to use set-point weighting. For designs with larger values of Ml we can simply
compute maximum of lGrr,o(fro)l and adjust the values of b and c that give a value close to one. The weight c is often set to zero.In that case,there is only
one parameter to choose.If lGly",(iro)l is larger than one for b:0, a low-pass filtering of the set point may be used to reduce the magnitude of lGrr.,(iro)l further. The set-point filter {,o(r) can be determined in the following way. Let rn, be the maximum of the transfer function (5.7) with b - c: 0, and let a,o
be the frequency where the maximum occurs. A first-order filter

'Fs p
1 + s?ro
has the magnitude \f m, at the frequency orp if the time constant is
1 T r. o : A)sp
Feeding the set point through a low-pass filter designed in this way will reduce the magnitude at the frequency orp to one.
A drawback with set-point weighting and filtering is that the set-point responsemay be unnecessarily slow.

t45

Chapter 5. Feedforward Design

5.4 NeutralFeedforward

A very simple choice of feedforward control for systems with monotone step responsesthat satisfies (5.2) is given by

My:

PP
FO

-

,q

1 M"_
Kn

(5.8)

This means that the desired set-point response is the normalized open-loop response of the system. Since Mu: llK, the control signal is proportional to the set point. At a step change in the set point the control signal thus changes stepwise to the constant value that gives the desired steady-state, and remains at that value. The design of a neutral feedforward is thus very simple.
A complicated processmodel can be replaced by an approximate model. For PID control it is natural to base design of feedforward on the NOTD model. One way to determine appropriate parameters is to match the model at the frequency o*r where the sensitivity function has its largest value. We illustrate the design procedure with an example.

Exanpr,n 5.?-FouR EeUAL Lacs Consider a process with the transfer function

t

P (\ -s')l - ,

(s +

,,. 1;+'

A PI controller with a specification on M, - 2 for this system gives the parameters K - 0.775, Ti : 2.05, and Q)*, : 0.56 of an approximate model.

Equation 5.5 gives the parameters K - l, L : I.94, and T :2.50. Figure 5.4

shows the response of the system to step and load disturbances. Notice that

there is a dip in the control signal around time t - 2. The reason is the mis-

match between the processand the model used to design the feedforward. This

is illustrated in Figure 5.5, which shows the initial responses of the process

and the model. Notice that the processresponds faster than the model initially.

There is then an error, which is compensated for by the feedback.

The set-point response can be improved by using a better approximation

of the process model. One possibility is to fit a second-order NOTD model. Such a model has the parameters K : l, T - I.52, and L - 1.13.Figure 5.6

shows the responses of the system to step and load disturbances. Compared

with Figure 5.4 the control signal is closer to the ideal value u - I and the

set-point response is a little better. Figure 5.7 shows the comparison of the

model output y* and the process output. A comparison with Figure 5.5 shows

that the second-ordermodel gives a better fit. A comparison of Figure 5.4 with

Figure 5.6 also illustrates that feedforward requires good modeling.

D

In temperature control it is often desirable to have a controller without overshoot to step responses. The next example illustrates how neutral feedforward can be used to accomplish this.

I46

5.4 Neutral Feedforward

1q
-1
n6

1q
/\
1
! ntr

-0.5

10

40

70

Figure 5.4 Responsesto set point and load disturbances of the processP(s) : 1/(s + 1)a with a PI controller (dashed line) and feedforward based on the FOTD model (solid line).

0.8
\ u.o
0.4 0.2
0

10

12

14

16

18

Figure 5.5 Step responsesof the processP (solid line) and the model used to design the feedforward (dashed line).

Exeupln 5.8-DrsrRrBUTEDLecs Considera processwith the transfer function

P(s) : cosh\6'

.{n aggressivePI controller with Mr:2 has K - 2,66, Ti:0.197, artd o)^, -

9.68. Even with b : 0 this controller gives an overshoot as is shown by the

dashed curve in Figure 5.8. Fitting a FOTD model at the frequencies 0 ar'd a)ms

ives K : I, T - 0.408, and ,L - 0.0917. The error in the transfer function is

less than 5 percent. Figure 5.8 shows a simulation of the system with neutral

feedforward based on that model. The figure shows that neutral feedforward

achievesthe desired response.

n

Oscillatory System
PID controlis not the best strategyfor oscillatorysystemsbecausemuch better performancecanbe obtainedwith more complexcontrollers.PID controlis,

147

Chapter 5. Feedforward Design

Z
1.5 -1
0.5 0

1.5 1
- u.3 0
-0.5

10

20

30

40

50

60

70

80

t

Figure 5.6 Responsesto set points and load disturbances of the processP(s) : 1/(s+ 1)a with a PI controller (dashed line) and feedforward based on a SOTD model (solid line).

u.b

0.2

10

12

14

to

18

Figure 5.7 Step responsesof the processP (solid line) and the model used to design the feedforward (dashed line).

however, sometimes used for such systems, and the performance of a conventional PID controller can often be improved by feedforward. Neutral feedforward, which gives a response similar to the uncontrolled system, can, however, not be used becauseit will give a response that is too oscillatory. We will illustrate how feedforward can be used by an example.
Exaupln 5.9-OscrLLAToRY Svsrpvt Consider a system with the transfer function
P(s): (s+1)(r'+0.ls+9)'
The oscillatory mode has a relative damping ( : 0.03, which is quite low. Reasonable PI controller parameters for the system are K - -0.167 and
Tr : -0.210. Since the controller has negative gain, set-point weighting with b : 0 must be used to get a reasonable response. The overshoot is, however,

148

5.4 Neutral Feedforward

0

a /\ /r
*1
I
0

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

Figure 5.8 Responses to set points and load disturbances of the process P(s) : 1/ cosh y6 with a PI controller (dashed lines) and a neutral feedforward based on a first order FOTD model (solid lines).

2.5
a
1.5 1
0.5

t.3
1I

0 -0.5

10

15

25

Figure 5.9 Responsesto set points and load disturbances of the process P(s) : 9/(s + t)(s2 +0.2s*9) with a PI controller (dashedlines) and a feedforward (solid lines).

-:ill substantial as is seen by the dashed curve in Figure 5.9. To design the :..edforward we choosea desired response given by the transfer function

My
(s+1)(rt+6s+9)

.t' dynamics of this system is essentially the same as for the process,but the ::rplex poles now have critical damping. It follows from (5.2) that

t^v,

rt

u_ -

s ;t

2 +

+ 6

0.1s s+g

*

9

t49

Chapter 5. Feedforward Design

This transfer is close to one for all frequencies except those conesponding to

the oscillatory modes where it has low gain. The transfer function thus blocks

signals that can excite the oscillatory modes. Figure 5.9 shows the response

of the system to set points and load disturbances. It is clear that the set-

point response is improved substantially by the use of feedforward. The load

disturbance response is still quite poor, which reflects the fact that PI control

is not appropriate for a highly oscillatory system.

I

5.5 FastSet-PointResponse

With neutral feedforward there is no overshoot in the control signal. It is possible to obtain more aggressive responses if we allow the control signal to overshoot. This is accomplished simply by requiring a faster response. To do this the model must also be accurate over a wider frequency range. The overshoot in the control signal may, however, increase very rapidly with increases in response time as is illustrated by the following example.

Exauplp 5.10-Fasr SET-PoINTRnspot'IsB

Consider the system

1 P ( s ) - (,s +^ .r,l =

Assume that it is desired to have a set-point response given by

M

v

:G

1
er

r

It follows from (5.3) that

t^v,rru- (s + l)a (r",,llF

For neutral feedforward we have T^ - 1, which gives Mu:1. have
M"(0) - T;0.

In general, we

The controller gain thus increases very rapidly with decreasing values of T*. This is illustrated in the simulation shown in Figure 5.10, which shows the responsefor T*: 1 (neutral feedforward), T^ :0.5, and T* :0.2. The initial values of the control signal are 1, 16, and 625, respectively. Notice that the power 4 in the expressions is due to the fact that the processhas a pole excess of 4. In practice, saturation of the actuator determines what can be achieved.
tr

TimeOptimalControl
The example clearly illustrates that feedforward can be used to obtain fast setpoint responses but that it requires models that are valid over a wide frequency range and that very large control signals may be required. The size of the

150

Process variable
0.8 0.6 0.4 0.2

5.5 Fast Set-Point Response

Process variable
u.o 0.4

Process variable
1 0.8 u.o 0.4 o.2

Control signal

Control signal

Control signal

Figure 5.10 Set-point responses of the process P(s) : (s + 1)-a with feedforward compensatorsdesignedto give Mr(s): (sT^ + 1)-4 for T^:1 (left),0.5 and 0.2 (right).
control signal depends critically on the pole excessof the process.In practice, it is also necessary to take account of the fact that the control signals have limited range. It is therefore very natural to look for strategies that bring the process output from one set point to another in minimum time. This problem is solved by optimal control theory. It is known that for linear systems the solution is bang-bang control which means the control signal switches between its extreme values. An example is given in Figure 5.11, which shows the minimum time solution for the processp : (s*1)-2 when the control signal is limited to values between 0 and 2. The control is very simple in this case. There can, however, be a large number of switches for high-order systems or for oscillatory systems. Becauseof its complexity it is not feasible to use optimal control except in very special situations. Approximate methods will therefore be developed.
PulseStepControl
For stable systems with monotone step responsesfast set-point responsescan often be achieved with control signals that have the shape shown in Figure 5.11. This means that the maximum control signal is used initially. The control signal is then switched to its lowest value, and the control signal is finally given the value that gives the desired steady state. If the initial pulse is approximated with an impulse we obtain the situation shown in Figurc 5.I2.
151

Chapter 5. Feedforward Design

1 l

h 0.5

I

I

n

1

-0.5

Figure 5.11 Time optimal set-point change for the process P: (s + 1)-2

SU1
u
u0
Figure 5.12 Response to an impulse (dotted line) and a delayed step (dashed-dotted line) for a system with monotone step response. The dashed line is the set point, and the solid line is the process output, composed of the sum of the impulse and step responses.
Assumingthat the systemis initially at restits outputis thengivenby
v(t):as(t)+bh(t-L),
where h is the step response and g the impulse response of the system. The parameters d, b, and Z should be chosen so that the response matches the desired response as closely as possible. To do this the parameter o should be chosen as Jrplg^u", where g-.* is the maximum of the impulse response g(t). Parameter b should be chosen so that the desired steady state is obtained. Hence, b: yrplKp where Ko ir the steady-state process gain. The parameter L should be adjusted to keep the output as close to the set point as possible. These choices imply that the settling time of the system is equal to the time
t52

5.5 Fast Set-Point Response

0.5

z
s0 -z
^

10

tz

14

tb

18

Figure 5.13 Comparison between the fast set-point response strategy (solid) and PI control with M" : 1.4 (dashed) and Ms :2.0 (dotted) for P(s) : 1/(s + 1)4.

where the impulse responsehas its maximum. The closed-loopsettling time is thus matched to the natural response time of the system. It is of course not possible to have an impulse as an input. The impulse is therefore approximated by a pulse with an amplitude that corresponds to the maximum value of the control signal. The duration is chosen so that the area under the pulse equals a. The parameters given above can be fine-tuned by optimization. We illustrate the procedure by an example.

Exaupln 5.1l-Fasr SET-PorNrRnspoNsn Consider a system with the transfer function

-p(\."s/) -_

1 (s+ 1)a.

Figure 5.13 compares the fast set-point response method with regular PI

control with two parameter settings. The fast set-point response has been computed with umax: 4 and umin : -4, and the resulting rise time and settling

time are approximately 4 time units. The controllers have been designed with

loop shaping for maximum sensitivities M, : L.4 and M, : 2.0. The cor-

responding controller parameters are K - 0.43, T; : 2.25, and b - 1 for

Mr:1.4, andK:0.78,Ti:2.05, andb :0.23for M,:2.0. BothPI designs

are clearly outperformed by the pulse-step method. The rise times are a factor

2-3 longer, and the settling times approximately 3 times longer. The reason is,

of course, that much less of the available control authority is used. If set-point

weight b andf or M, is increased, the size of the control signal will increase.

This leads to a faster rise time, but at the expense of larger overshoot, so the

settling time may actually be even higher.

n

153

Chapter 5. Feedforward Design
n6

0
Figure 5.14 Process output and control signal for fast set-point changes with rate limit a t i o n s l d u l d t l 1 2 f o r t h e p r o c e s sP ( s ) : 1 / ( s + 1 ) 4 .
Rate Limitations The idea of fast set-point response can also be applied to the case when there are rate limitations. This is illustrated in Figure 5.I4, which shows a simulation of the process with the transfer function P - ll! + 1)n when there are rate limitations lduldtl <2. It is also possible to combine rate and level limitations.

5.6 DisturbanceAttenuation

Disturbances can be eliminated by feedback. With a feedback system it is, however, necessary that there be an error before the controller can take actions to eliminate disturbances. In some situations, it is possible to measure disturbances before they have influenced the processes. It is then natural to try to eliminate the effects of the disturbances before they have created control errors. This control paradigm is called feedforward. The principle is illustrated in Figure 5.15.
In Figure 5.15 processtransfer function P is composedof two factors, P: PtPz. A measured disturbance d enters at the input of process section P2. The measured disturbance is fed to the process input via the feedforward transfer function Gy.The transfer function from load disturbance to process output is

Gra(s: )o#P

: Pz(-r PvGris,

(5.e)

where S : 1/(l+PC) is the sensitivity function. This equation shows that there are two ways of reducing the disturbance. We can try to make I - PlGSS small

by a proper choice of the feedforward transfer function G y, or we can make

l

the loop transfer function PC large by feedback. Feedforward and feedback can

I

also be combined.

t

L54

5.6 Disturbance Attenuation

Figure 5.15 Block diagram of a system where a measured disturbance d is reduced by a combination of feedback and feedforward.

Notice that with feedforward we are trying to make the difference between two terms small, but with feedback we simply multiply with a small number. An immediate consequenceis that feedforward is more sensitive than feedback. With feedback there is risk of instability; there is no such risk with feedforward. Feedback and feedforward are therefore complementary, and it is useful to combine them.
An ideal feedforward compensator is given by

Gff :

Pr' :

Pva P,,,,

(5.10)

where Pra is the transfer function from d to y and Py, : P is the transfer function from u to y. The ideal feedforward compensator is formed by taking the inverse of the processdynamics Pr. This inverse is ofbennot realizable, but approximations have to be used.
Feedforward is most effective when the disturbance d enters early in the process.This occurs when most of the dynamics are in processsection P2. When Pt : 1, and therefore Pz : P, the ideal feedforward compensator is realizable, and the effects of the disturbance can be eliminated from the process output y. On the other hand, when the dynamics enter late in the process, so that Pt x P, the effects of the disturbance are seen in the process output y at the same time as they are seen in the feedforward signal. In this case, there is no advantage of using feedforward compared to feedback.

Applications

In many process control applications there are several processesin series. In

such cases,it is often easy to measure disturbances and use feedforward. T)rpi-

cal applications of feedforward control are drum-level control in steam boilers,

control of distillation columns, and rolling mills. An application of combined

feedback and feedforward control follows.
r

Ii

.e

Exauplp 5.12-DnuM LEVEL CoNTRoL

n

A simplified diagram of a steam boiler is shown in Figure 5.16. The water in the raiser is heated by the burners. The steam generated in the raiser, which

IDD

Chapter 5. Feedforward Design

Feed water

Steam valve

oil

Turbine

4-E

Air

/

\

Down comer

Figure 5.16 Schematic diagram of a drum boiler with level control.

is lighter than the water, rises toward the drum. This causes a circulation

around the loop consisting of the raisers, the drum, and the down comers. The

steam is separated from the water in the drum. The steam flow to the turbine

is controlled by the steam valve.

It is important to keep the water level in the drum constant. Toolow a water

level gives insufficient cooling of the raisers, and there is a risk of burning. With

too high a water level, water may move into the turbines, which may cause

damage. There is a control system for keeping the level constant. The control

problem is difficult because of the so-called shrink and swell effect.It can be

explained as follows. Assume that the system is in equilibrium with a constant

drum level. If the steam flow is increased by opening the turbine valve, the

pressure in the drum will drop. The decreased pressure causes generation of

extra bubbles in the drum and in the raisers. As a result, the drum level

will initially increase. Since more steam is taken out of the drum, the drum

level will of course finally decrease. This phenomenon, which is called the

shrink and swell effect, causes severe difficulties in the control of the drum

level. Mathematically, it also gives rise to right-half plane zero in the transfer

function.

The problem can be solved by introducing the control stratery shown in

Figure 5.16. It consists of a combination of feedback and feedforward. There is

a feedback from the drum level to the controller, but there is also a feedforward

from the difference between steam flow and feed-water flow so that the feed-

water flow is quickly matched to the steam flow.

I

5.7 Summary
Design of feedforward has been discussed in this chapter. Feedforward can be used to reduce the effect of measurable disturbances. Design of feedforward is essentially a matter of finding inverse process models. Different techniques to do this have been discussed. The major part of the chapter has been devoted to set-point response.A structure with two degrees of freedom has been used. This gives a clean separation of regulation and set-point response and of feed-
156

5.8 Notes and References
back and feedforward. It has been assumed that the feedback controller has been designed.A simple way to modify the set-point responseis to use set-point weighting. If the desired results cannot be obtained by zero set-point weighting a full-fledged two-degree-of-freedom can be used. This makes is possibie to make a complete separation between load disturbance response and setpoint response. The crucial design issue is to decide the achievable response speed. For systems with monotone set-point responses the notion of neutral feedforward has been proposed.Many other variants have also been discussed. Finally, it has been demonstrated that very fast set-point responses can be obtained by using nonlinear methods.
Special care must be taken when implementing feedforward control, otherwise integrator windup may occur. Implementation of feedforward control is discussedin Section 13.4.
5.8 Notesand References
Feedforward is a useful complement to feedback. It was used in electronic amplifiers even before the feedback amplifier emerged as discussed in [Black, 19771.Use of feedforward in processcontrol was pioneered in [Shinskey, 1963]. The effectivenessof feedforward to improve set-point response using a system structure with two degrees of freedom (2DOF) was introduced in [Horowitz, 19631.Set-point weighting, which is a simple form of 2DOB has been used to a limited extent in early PID controllers where the weights have been 0 or 1. The use of continuously adjustable weights appeared in the 1980s.Use of feedforward to reduce the effect of measured disturbances is cumbersome to apply in the process control systems built on separate components but very easy in modern distributed control system; see [Bialkowski, 1995] and [ABB, 2002]. Applications of feedforward are gaining in popularity. Methods for assessment of potential improvements by using feedforward are also emergrng; see [Peterss on ef a1. , 2 0 0 1 ;Pe te rs s o ne t a 1 .,2 0 0 2 ;P eterssonet a1.,20031.
r57

PID Design
6.1 Introduction
This chapter describes methods for finding parameters of a PID controller, which is a special case of the problem of control system design that was discussed in Chapter 4. Design of PID controllers differs from the general design problem because the controller complexity is restricted. The general design methods give a controller with a complexity that matches the process model. To obtain a controller with restricted complexity we can either simplify the process models so that the design gives a PID controller, or we can design a controller for a complex model and approximate it with a PID controller. Another reason why special design methods for PID controllers emerged is the desire to have simple design methods that can be used by persons with poor knowledge of control. The situation has changed substantially with the advent of tuning tools and automatic tuners, which have made it possible to improve the process knowleCge and permitted the use of more extensive calculations. This has brought design of PID controllers closer to the mainstream of control systems design.
In this chapter it has been attempted to strike a balance by providing both a historical perspective and to present powerful methods. Section 6.2 describes the methods developed by Ziegler and Nichols, which have had a major impact on the practice of PID control even if they do not result in good tuning. Some extensions of the Ziegler-Nichols methods are also discussed.
It is often necessary to complement the design methods with manual finetuning to obtain the desired goals of the closed-loopdynamics. These manual tuning rules are discussed in Section 6.3.
Section 6.4 presents the pole placement method, which is one of the main stream methods in control system design. To apply this method it is necessary to approximate process dynamics by a first order model for PI control and a secondorder model for PID control. Instead of attempting to position all closedloop poles, it can be attempted to assign only a few dominating poles. Such methods are discussed in Section 6.4. The most common dominant pole placement design method is the lambda tuning method, presented in Section 6.5.
In Section 6.6, algebraic tuning methods are presented. In these methods,
158

6.2 Ziegler-Nichols and Related Methods
"l
Figure 6.1 Characterization of a step response in the Ziegler-Nichols step response method.
the controller parameters are obtained from the specifications by a direct algebraic calculation. In these techniques it is also necessary to approximate process dynamics by low order models.
Many techniques for control system design are based on optimization. This gives a very flexible way of balancing conflicting design criteria. It is also possible to apply directly to controllers having restricted complexity.A number of uses of optimization for PID control are discussed in Section 6.7.
Loop shaping is another well-known technique for control system design. In Section 6.8 it is shown how this can be used for PID control. This gives a very flexible design method, which allows a nice trade-offbetween performance and robustness. An analysis of the method also gives useful insight into the difficulties with derivative action.
Conclusions and references are given in Sections 6.9 and 6.10.
6.2 Ziegler-Nicholasnd RelatedMethods
T\vo classical methods for determining the parameters of PID controllers were presented by Ziegler and Nichols in 1942. These methods are still widely used, either in their original form or in some modification. They often form the basis for tuning procedures used by controller manufacturers and the process industry. The methods are based on determination of some features of process dynamics. The controller parameters are then expressed in terms of the features by simple formulas. It is surprising that the methods are so widely referenced because they give moderately good tuning only in restricted situations. Plausible explanations may be the simplicity of the methods and the fact that they can be used for simple student exercisesin basic control courses.
The Step Response Method The first design method presented by Ziegler and Nichols is based on process information in the form of the open-loop step response. This method can be viewed as a traditional method based on modeling and control where a very simple process model is used. The step response is characterized by only two parameters o and L, as shown in Figure 6.1. Compare also with Figure 2.32.
159

Chapter 6. PID Design

Table 6.1 Controller parameters for the Ziegler-Nichols step response method.

Controller aK TiIL

P

1

PI

0.9 3

PID

t.2 2

TaIL Ll2

TrlL
4
o.l
3.4

Figure 6.2 Set-point and load disturbance response of a process with transfer function Il$ + 1)3 controlled by a PID controller tuned with the Ziegler-Nichols step response method. The diagrams show set point Jsp, process output y, and control signal a.

The point where the slope of the step response has its maximum is first determined, and the tangent at this point is drawn. The intersections between the tangent and the coordinate axes give the parameters o and L.ln Chapter 2, a model of the process to be controlled was derived from these parameters. This corresponds to modeling a process by an integrator and a time delay. Ziegler and Nichols have given PID parameters directly as functions of o and Z. These are given in Table 6.1. An estimate of the period T, of the closed-loop system is also given in the table.

Exeuplp 6.I-ZrncLER-NrcHoLS SrEp RpspoNsn MorHoo Ziegler-Nichols'method will be applied to a processwith the transfer function

P(s:#) ry

(6.1)

Measurements on the step response give the parameters o : 0.218 and L : 0.806. The controller parameters can now be determined from Table 6.1. The parameters of a PID controller are K - 5.50, Ti : I.6I, and Ta :0.403. The response of the closed-loopsystems to a step change in set point followed by a
step change in the load is shown in Figure 6.2. The behavior of the controller is as can be expected.The decayratio for the step responseis closeto one quarter.

160

6.2 Ziegler-Nichols and Related Methods

Table 6.2 Controller parameters for the Ziegler-Nichols frequency response method.

Controller K I K"

P

0.5

PI

0.4

PID

0.6

Ti lT"
0.8 0.5

TalT" TolT"
1.0 r.4 0.125 0.85

It is smaller for the load disturbance. The overshoot in the set-point response

is too large. This can be improved by the set-point weighting b. Compare with

Section 3.4.

I

The Frequency Response Method
This method is also based on a simple characterization of the processdynamics. The design is based on knowledge of the point on the Nyquist curve of the processtransfer function P(s) where the Nyquist curve intersects the negative real axis. In Section 2.4 this point was characterized by K1s6 and fo1ss.For historical reasons the point has been referred to as the ultimate point and char ac t er iz edby th e p a ra me te rs K u : Il Ktao and Tu:2nl atns, w hi ch are called the ultimate gain and the ultimate period. These parameters can be determined in the following way. Connect a controller to the process, and set the parameters so that control action is proportional, i.e., Ti: oo and ?a - Q. Increase the gain slowly until the process starts to oscillate. The gain when this occursis K,, and the period of the oscillation is 7". We have Ku:llKrco and Tu - 2t latu. The parameters can also be determined approximately by relay feedback as is discussed in Section 2.7.
Ziegler-Nichols have given simple formulas for the parameters of the controller in terms of the ultimate gain and the ultimate period shown in Table 6.2. An estimate of the period To of the dominant dynamics of the closed-loop system is also given in the table.
The frequency response methods can also be viewed as an empirical tuning procedure where the controller parameters are obtained by direct experiments on the process combined with some simple rules. For a proportional controller the rule is simply to increase the gain until the process oscillates and then to reduce the gain by 50 percent.
We illustrate the design procedure with an example.

Exenpr,p 6.2-Tun Zmclnn-Nrcuor.s FnoqunNcy RESeoNSEMETHoD

Consider the same processas in Example 6.1. The processgiven by (6.1) has

the ultimate gain Ku : 8 and the ultimate period Tu - 2r lt/S : 3.63. Table 6.2 gives the parameters K - 4.8, Ti : 7.81, and Ta : 0.44 for a PID controller.

The closed-loopset-point and load disturbance responses when the controller

is applied to the process given by (6.1) are shown in Figure 6.3.

The parameters and the performance of the controllers obtained with the

frequency response method are close to those obtained by the step response

method. The responses are slightly better damped.

I

161

Chapter 6. PID Design
Figure 6.3 Set-point and load disturbance response of a process with the transfer function 1/(s + 1)3 controlled by a PID controller that is tuned with the Ziegler-Nichols frequency response method. The diagrams show set point .lsp, process output y, and control signal u.
The Ziegler-Nichols tuning rules were originally designed to give systems with good responsesto load disturbances. They were obtained by extensive simulations of many different systems with manual assessment of the results. The design criterion was quarter amplitude decay ratio, which is often too large, as is seen in the examples. For this reason the Ziegler-Nichols method often requires modification or re-tuning. Since the primary design objective was to reduce load disturbances, it is often necessary to choose set-point weighting carefully in order to obtain a satisfactory set-point response.
An Interpretation of the Frequency Response Method The frequency response method can be interpreted as a method where one point of the Nyquist curve is positioned. With PI or PID control, it is possible to move a given point on the Nyquist curve of the process transfer function to an arbitrary position in the complex plane, as indicated in Figure 6.4. By changing the gain, a point on the Nyquist curve is moved radially from the origin. The point can be moved in the orthogonal direction by changing integral or derivative gain. Notice that with positive controller parameters the point can be moved to a quarter plane with PI or PD control and to a half plane with PID control. From this point of view the Ziegler-Nichols method can be interpreted as a primitive loop-shaping method where one point of the loop transfer function is moved to a desired point.
The frequency response method starts with determination of the point (-I I K", 0) where the Nyquist curve of the open-loop transfer function intersects the negative real axis.
Let us now investigate how the ultimate point is changed by the controller. For a PI controller with Ziegler-Nichols tuning we have K :0.4Ku and tDuT;(2nlT")0.8"" : 5.02. Therefore, the transfer function of the PI controller at
162

6.2 Ziegler-Nichols and Related Methods

Figure 6.4 Illustrates that a point on the Nyquist curve of the process transfer function
may be moved to another position by PID control. The point marked with a circle may be moved in the directions P(iro), -iP(ia), and iP(ial by changing the proportional, integral,
and derivative gain, respectively.

the ultimate frequency is

c(ia4): K (t*
\

-ia+"T) ; /

- 0 . n " ,G - it1 5 . 0 2 )K: u ( 0 . 4 - 0 . 0 8 r ) .

The ultimate point is thus moved to -0.4 + 0.08i. This means that a lag of 17.2' is introduced at the ultimate frequency.
F or a PID c o n tro l l e r w e h a v e K - 0.6K u, a)rTi :7T, ei fi do. uTa: r14.The frequency response of the controller at frequency @zis

c

(

i

o

t

,

)

:K

(
\

r

*

i

(

r
\

,

r

a- -

+

))
au

'

r

'

i

/

/

-

o . o ne + 0 . 4 6 7 i )

This controller gives a phase advance of 25" at the ultimate frequency. The loop transfer function is

G1(iat"): P(iat")C(ia4) : -0.6(I+0.4G7j) : -0.0 -0.28i.

The Ziegler-Nichols frequency response method for a PID controller thus moves the ultimate point (-11K",0) to the point -0.6 _ 0.28i. The distance from this point to the critical point is 0.5. This means that the method gives a sensitivity that is always greater than 2.
It has been suggestedby Pessen to move the ultimate point to -0.2- 0.86t or -0.2 - 0.2Li. Suda used approximations to obtain Mt :1.8 by moving the critical point to -0.628 - 0.483i.

Design of Pl Controller with a Given phase Margin t

Using the idea that the PI controller can be interpreted as moving a point on

the loop transfer function it is easy to develop a design method thal gives a

r.

closed-loop system with a given phase margin. Let the process transfer function

=

be

It

PQat): a(a) + iB@t)- p(a)siv@).

163

Chapter 6. PID Design

ImGlQro) R eG ; ( l a r )

Figure 6.5_ Nyquist plot for the loop transfer function G7 for PI control of the process P(s): e-l". The controller was designed to give the phase margin of 60'.

With PI control the loop transfer function becomes

G 1 ( i a: \( n- t L : )@ t r l+i B @ t:) )o ( a ) k. r y + i ( p @ )-u" ( Z ) u ' )
Let asc be the gain crossoverfrequency; requiring that the system has a phase margin e* it follows that
G 1 (i an " ) - - c o s ( g^) - i si n(rp^),
which implies that

u(ran)k * f(qn')ki - - cos(e^)
0g"
F@tn,)k- u(c!s')ki - - sin(p- ). @g"

Solving this equation for k and ft; gives

k,^- - d1as,)cos(pm+ F@n,)srnem: - 1 - , -

kt^i :

(.-osa, (otn")srngm- F@nr) cosgm -

P(o)*)cos(9*-v/(as"))

0)

(p- - W@)s,)).

(6.2)

ffr)sin

It is thus straightforward to compute the controller gains when the gain crossover
frequency is given. Reasonable values of the gain crossover frequency are in the ranga ago I a)sc{ ago-q",. The method can be improved by sweeping over
{Dn,to maximize integral gain. Applying the method to design a PI controller for the process P(s) - e-rE with a phase margin of 60' gives os" : s.s27 K : 4.79 and ?, : 0.392 and M,: 1.53.The Nyquist plot of the loop transfer
function is shown in Figure 6.5.

164

6.2)
JSsover lre in g over troller
'D.527 '.rnsfer

6.2 Ziegler-Nichols and Related Methods

Relations Between the Ziegler-Nichols Tuning Methods The step response method and the frequency response method do not give the same lrul,r", of the controller parameters. comparing Examples 6.1 and 6.2 we find that the controller gains are 5.5 and 4.8 and that the integral times are 1.61 and 1.81. The step response method will in general give larger gains and smaller integral times. This is further illustrated in the following example.

Exauplp 6.3-PnocESS wITH INrBcReuoN AND Dnlav Consider a process with the transfer function

P ( s )-

K,,
i

u -^"f " ,

which is the model originally used by Ziegler and Nichols to derive their tuning

rules for ultimate

the freq

step response uency rs ou -

method. For rl2L, which

this giv

process we hav es the ultimate

ea : period

KuL' T" -

The 4L,

and the ultimate gain is Ku : r l2KrL.

For pI control the step response method gives the following parameters:

K

:

0'9
fr"

T i: 3 L '

This can be compared with the parameters

6 : 9 .K , L ' T ; : 8 2 L
obtained for the frequency response method. Notice that the integral times are within 10 percent, but that the step response method gives a gain that is about 40 percent higher.
The PID parameters obtained from the step response method are

K1 7 : I ' 2 ;;.

,TTit : 2 Lo r

a^ -nl d -T a -: L 2.

and those given by the frequency response methods are

K_Y, r;_2L and ,o: *

Both methods give the same values of integral and derivative times, but the

srep response method gives a gain that is about 25 percent higher than the

frequency response method.

T

Exeuple 6.4-PnocESS wITH Punn Dst,ev Consider a process with the transfer
P(s) : Kor-"

165

Chapter 6. PID Design
{tr
1 - 0.5
0 -0.5
0 0.5

10

12

14

to

18

r

nR

{

1

10

12

l4

to

18

Figure 6.6 Responses to a load disturbance for a process with pure delay (,L : 1) with PI controllers tuned by Ziegler-Nichols frequency response method (dashed) and a proper method (solid).

In this case we find that o - oo! The step response method thus gives zero

controller gain for PI and PID control. The ultimate period is ?" - 2L, and the ultimate gain is K" _ tlKo.
Using the frequency responsemethod it follows from Table 6.2 that K Ko : 0.4

and Ti : I.6L for PI control. The PI controller gives a very poor result as is

illustrated in Figure 6.6. The integral action is too small, which implies that it

takes a very long time for the error to approach zero. For comparison we also show the response with a PI controller having K Ko : 0.25 and T; - 0.35. This

controller has a much better response to load disturbances.

For PID control the frequency response method gives KKo - 0.6, Tr : L

and Ta - 0.25, which results in an unstable closed-loopsystem.

I

These examples show that there can be considerable differences between the controller parameters obtained by the step response and the frequency response methods.

The Chien, Hrones, and Reswick Method
There have been many suggestions for modifications of the Ziegler-Nichols methods. There are methods that use the same information about the process as the Ziegler-Nichols methods, but the coefficients in Tables 6.1 and 6.2 are modified. Many methods of this type are used by controller manufacturers. There are also other methods that use more process data. Many methods are based on the idea that the process is approximated with the FOTD model

P(s:) #*e_*1 .
As an illustration we will describe a method developed by Chien, Hrones, and Reswick (CHR). Their method gives closed-loop systems with slightly better

166

6.2 Ziegler-Nichols and Related Methods

Table 6.3 Controller parameters obtained from the Chien, Hrones and Reswick disturbance response method.

No overshoot

20Vo overshoot

Controller aK TiI L TaI L aK T,l L TaI L

P

0.3

0.7

PI

0.6 4.0

0.7 2.3

PID

0.95 2.4 0.42 L.2 2.0 0.42

Table 6.4 Controller parameters obtained from the Chien, Hrones and Reswick set-point response method.

No overshoot

207o overshoot

Controller aK TilL TalL aK TilL TalL

P

0.3

0.7

PI

0.35 r.2

0.6 1.0

PID

0.6 1.0 0.5 0.95 L.4 0.47

robustness than the Ziegler-Nichols method. The design criteria used were "quickest response without overshoot" or "quickest response with 20 percent overshoot." They proposed different tuning rules for load disturbances and setpoint response.
To tune the controller according to the CHR method, the parameters o and L of the process model are first determined in the same way as for the Ziegler-Nichols step responsemethod. The controller parameters are then given as functions of these two parameters. The tuning rule for load disturbance response are given in Table 6.3. The tuning rules in Table 6.3 have in general Iower gains than the corresponding Ziegler-Nichols rule in Table 6.1.
Chien, Hrones, and Reswick found that tuning for set-point response was different than tuning for load disturbances. At that time the advantages of set-point weighting and systems with two degrees of freedom were not known. An additional parameter, time constant ?, was required, and the controller gains were in general lower; see Table 6.4.
The Cohen-Coon Method The Cohen-Coon method is also based on the FOTD process model
P ( s:) # e _ - ' 1 .
The main design criterion is rejection of load disturbances. It attempts to position dominant poles that give a quarter amplitude decay ratio. For P and PD
r67

Chapter 6. PID Design

Table 6.5 Controller parameters from the Cohen-Coon method.

Controller
PI PD PID

aK

TilL

1+

0.35r 1-r

o . g( r * \

o'oe2r) r-r /

3 . 3- 3 . 0 r L + l.2r

n+(r.H)

r a s ( r . H ) 2.5- 2.0r 1-0.39c

TalL
0 . 2 7- 0 . 3 6 2 I - 0.87c
0 . 3 7- 0 . 3 7 t 1-0.81r

controllers the poles are adjusted to give maximum controller gain, subject to the constraint on the decay ratio. This minimizes the steady-state error due to load disturbances. For PI and PID control the integral gain ki : K lTi is maximized. This corresponds to minimization of IE, the integral error due to a unit step load disturbance. For PID controllers three closed-looppoles are assigned; two poles are complex, and the third real pole is positioned at the same distance from the origin as the other poles. The pole pattern is adjusted to give quarter amplitude decay ratio, and the distance of the poles to the origin are adjusted to minimize IE.
Since the process is characterized by three parameters (Kp, L, and T), it is possible to give tuning formulas where controller parameters are expressed in terms of these parameters. Such formulas were derived by Cohen and Coon based on analytical and numerical computations. The formulas are given in Table 6.5. The parameters @: K.LIT and r - Ll@ + 7) are used in the table to facilitate comparisons with Ziegler-Nichols tuning. A comparison with Table 6.1 shows that the controller parameters are close to those obtained by the Ziegler-Nichols step response method for small r. Also notice that the integral time decreases for increasing e, which is desirable as was found in Section 6.2. A peculiarity is that the gains go to infinity when t goes to 1, which is not correct. The method does also suffer from the decay ratio being too large, which means that the closed-loopsystems obtained have poor damping and high sensitivity.
Commentary
The Ziegler-Nichols tuning rules are simple and intuitive. They require little process knowledge, and they can be applied with modest effort. The process is characterized by two parameters that can be determined by simple experiments. The frequency response method has the advantage that parameters Ku and Tu are easier to determine accurately than the parameters o and Z, which are used by the step response method.
The methods are still widely used even if they give closed-loop systems that are not robust. The rules are often combined with manual tuning, which will
168

6.3 Rule-Based Empirical Tttning
be discussedin Section 6.3. The main drawbacks with the methods are that too Iittle process information is used and the design criterion quarter amplitude damping gives closed-loop systems with poor robustness. It is not clear why this design criterion was used. The load disturbance responseslook quite reasonable, but without analysis or sensitivity studies it is not obvious that the closed-loopsystems are not robust. The simulations shown in Figure 6.2 and Figure 6.3 indicate that the methods give reasonable control. Repeated simulations with perturbations in controller parameters reveal very clearly that the closed-loopsystem is not robust. Systems like the ones shown in Examples 6.3 and 6.4 also illustrate that it is not sufficient to characterize the process by two parameters only.
A very large number of variations of the Ziegler-Nichols methods have been proposed.Here we have chosento discusstwo methods. The modifications of the Chien-Hrones-Reswick method give systems with somewhat better robustness, but it still uses too little process information. The Cohen-Coon method uses three parameters to characterizet}re process,but it still uses quarter amplitude damping as a design criterion.
In Chapter 7 we will develop new methods that address the major shortcomings of the Ziegler-Nichols methods while retaining their simplicity.
6.3 Rule-BaseEd mpiricaTl uning
Since the Ziegler-Nichols methods only give "ball-park" values, it is necessary to complement the methods by manual tuning to obtain reasonable closed-loop properties. Manual tuning is typically performed by experiments on the process in closed loop. A perturbation is introduced either as a set-point change or as a change in the control variable. The closed-loopresponse is observed, and the controller parameters are adjusted. The adjustments are based on simple rules, which give guidelines for changing the parameters. The rules were developed by extensive experimentation. The following is a simple set of rules:
o Increasing proportional gain decreasesstability
o Error decays more rapidly if integration time is decreased o Decreasing integration time decreasesstability o Increasing derivative time improves stability
Lately, the tuning rules have also been formalized in various types of formal rule-based systems such as expert systems or fuzzy logic.
T\rning maps are one way to express the tuning rules. The purpose of these maps is to provide intuition about how changes in controller parameters influencethe behavior of the closed-loopsystem. The tuning maps are simply arrays of transient or frequency responses corresponding to systematic variations in controller parameters. An example of a tuning map is given in Figure 6.7.
The figure illustrates how the load disturbance response is influenced by changes in gain and integral time. The process model
P(s- )#rtr
169

Chapter 6. PID Design K :7.5 Ti:70

K:L5Ti:5

K :1.5 T;:3

20

40

K:1.04:10

20

40

K : 1 . 0T r : 3

02040 K : O . 5T i : I 0

20

40

K :0.5 Tt:3

-0.5 0
Figure 6.7 T\rning map for PID control of a process with the transfer function P(s) : (s + 1)-8. The figure shows the responses to a unit step disturbance at the process input. Parameter ?6 has the value 1.9.
has been used in the example. The Ziegler-Nichols frequency response method gives the controller parameters K - 1.13, Ti : 7.58, and Ta : 1.9. The figure shows clearly the benefits of having a smaller value of Ti. Judging from the figure, the values K : 1 and Ti : 5.0 appear reasonable. The figure also shows that the choice of Ti is fairly critical. Also notice that controllers with Ti < 7.6 cannot be implemented on series form (compare with Section 3.4).
A different type of tuning map is shown in Figure 6.8, which shows the Nyquist curves of the loop transfer function. The figure shows that several of the Nyquist curves bend over too much to the right at low frequencies; see the figures in the left positions with Ti : 10. This means that the controller introduces too much phase lead. This is reduced by reducing parameter fl.
A comparative study of curves like Figure 6.7 and Figure 6.8 is a good way to develop intuition for the relations between the time and frequency responses. An even better way is to use the interactive software that is now emerglng.
Counter-lntuitivBeehavior
Common rules for manual tuning says that the system becomesless oscillatory if the gain is reduced, if the integral time is increased, and if the derivative time is increased. Compare with Figure 6.4. These rules hold for the system
170

K :1.5 Ti: l0

6.3 Rule-Based Empirical Tbning

K :1.5 Ti:5

K : 1 . 5T i : 3

0
-1
\ \
_Z
-2-101 K : I.0Ti:10

0
-l I
-2 -2-101 K : 1 . 0T t : 5

0
1
-2 /
-2-101 K : 1 . . T0 i : 3

0
\
1
-2 -2-101 K :0.5 Ti : L0
1

0

-l t

-2

-2 - 1

0

K :0.5 Tr:5

0

-l 1
(

-2

-2 - 1

01

K :0.5 Ti:3

U
-lI
-2 --22 - 1

\
0 ''11

0

I -l

-2

--22--11 0 1

01

0

I
-2 -2-1

(
0

Figure 6.8 Thning map for PID control of a process with the transfer function P(s) : (s + 1)-8. The figure shows the Nyquist plots of the Ioop transfer functions. Parameter T4 has the value 1.9.

shownin Figure 6.7 and Figure 6.8.Thereare,however,situationswherethese rules do not hold. The followingis a simple commonexample.
Exalrpr-n6.5-PI CoNrnol oF ANlNrpcnaron Considera processwith the transfer function
P\(/ss)- 1 .
and a PI controller with the transfer function
c(s:1) ((+1rtl
The loop transfer function is
G , ( s-)P ( s ) c ( s-) x \ f t

L7t

Chapter 6. PID Design

Figure 6.9 Nyquist curves for the loop transfer functions for an integrator with PI control. Integration time 7, is constant, and the gain has the values K : 0.2 (dotted), 1 (dashed), and 5 (solid). Notice the counterintuitive behavior that phase margin increases with increasing controller gain.

l

and the characteristic equation is

I (

(

s2+Ks+ L:N

I

Ti

Identifying this with a standard second-order system s2 + 2( ato+ ofi we find that

F

It follows from this equation that the damping increases when the controller

Z

gain is increased contrary to the intuition developed for the simple systems.

,)

This is also illustrated by the Nyquist curves in Figure 6.9. Notice that the

Nyquist curve moves away from the critical point -1 as the gain increases.

The reason for this is that the Nyquist curve is very close to the negative

imaginary axis for large a;. Notice that a small time delay or a small lag will

destroy this property.

tr

Situations like this make it difficult to form efficient rules that cover a wide range of conditions.

An lnequality for the Integration Time
It is useful to have a simple way to judge if the integral action of a controller is too weak, as in the three left and the lower middle examples in Figure 6.7 and Figure 6.8. Such a criterion can be based on a calculation of the asymptotic behavior of the loop transfer function for low frequencies. For a process with

772

6.3 Rule-BasedEmpirical Tl^tning

transfer function P and a PI controller with transfer function C we have

G , ( s ):

P ( s ) C ( s )a r( P ( o )+

sP'(o))K

(/ ,t*

1\
;tr,)

_

K

P s

(T0; ) +

KP

(

o

)*

rP'Q r'

+ KP'(0)s.

Thus, for low frequencies the asymptote of the Nyquist curve is parallel to the imaginary axis with the real part equal to

K+P-:KKp(t-+)

I(P(0) +-T

,\

tt/

where Kp : G(0) is the static process gain, and To, is the average residence time. It is reasonable to require that the real part of the asymptote be less
than -0.5. This gives

ri1rq,#n1To,.

(6.3)

For the system in Figure 6.7 and Figure 6.8, we get the requirement Ti < 6.0 for the systems in the upper row, fi < 5.3 for the systems in the middle row, and,Ti < 4.0 for the systems in the lower row. This means that condition (G.B)excludes the three left and the lower middle examples in Figure 6.7 and
Figure 6.8. The inequality for the integration time given by (6.3) can be used to give
insight into the limitations of tine Ziegler-Nichols rules for systems with large
time delays. Consider a process with the transfer function

P(s) :

go e-tL 1+s?'

For this system we have To, : L + T. Consider a PI controller tuned by the Ziegler-Nichols step response method. It follows from Table 6.1 that KKp:
a.9T lL and T; : 3L. Equation 6'3 then gives

g L < ( L +'T' '\L=+t 81 -. 8T7 '

which implies that L < 0.38?. This means that the Ziegler-Nichols step response method for PI control will not give good control unless the time delay is sufficiently small. Compare with Example 6.4.
Commentary
Manual tuning was used.before any systematic tuning methods were available. lt became a necessary complement to the Ziegler-Nichols method. It is essential for all practitioners of control to gain experience in judging the properties ,rf closed-loopsystems and to change controller parameters to modify the behavior. The assessment can be based on simple bump tests where set points or

L73

Chapter 6. PID Design
controller output is perturbed or by more elaborate frequency response measurements of the transfer function. It is necessary to be aware of the counterintuitive behavior of processeswith integral action illustrated in Example 6.5. The rule-based systems have been formalized when automatic tuners based on expert systems and fuzzy logic were developed. In Section 6.7 we will present systematic methods for improving the tuning based on optimization.

6.4 PolePlacement

Many properties of a closed-loopsystem are expressed by its poles. The idea with pole placement is to design a controller that gives a closed-loop system with desired closed-looppoles. The method requires a complete model of the process. Subject to some technical conditions it is possible to find a controller that gives the desired closed-loop poles, provided that the controller is sufficiently complex. To use the method for PID control it is necessary to restrict the complexity of the model by various approximation methods. The selected poles must then be chosen with care in order to ensure that the approximated model is valid for frequencies that correspond to the chosen poles.
A refinement of the procedure is to consider also the zeros of the transfer functions. This is particularly relevant for the set-point response. The zeros of the transfer function originating from the controller can be influenced by
set-point weighting.

Exaupln 6.6-PI CoNrnoi, oF A FIRST-ORDERSvsmna Suppose that the process can be described by the following first-order model
P ( s ): Kp 1+s?'
which has only two parameters, process gain Ko and time constant ?. Let the process be controlled by a standard PI controller with set-point weighting,

c ( s ): r 1 r + ] ) sli
c r r G ) :K ( a+ $ )

The closed-loopsystem is of secondorder. The loop transfer function is

Gr(s)-

p(s)c(s)-

KeIrlr + s:r) s 4 ( 1+ s ? )

:

*':(' *-:[) 7 ( s+ l l r )

and the characteristic polynomial

, l+KoK

KoK

.q- --r-

.q =L

T

TT,

(6.4)

The closed-loopsystem has two poles that can be given arbitrary values by a suitable choice of gain K and integral time Ti of the controller. Now suppose

174

6.4 Pole Placement

that the desired closed-Ioop poles are characterized by their relative damping ( and their frequency @0.The desired characteristic polynomial then becomes

s2+ 2( atss* @fr.

(6.5)

Identifying coefficients of equal powers of s in (6.4) and (6.5) we get

2(asT -7 K_
Kp

2( ztgT - I

Ti-

o3r

,n", __ K _ a \ r
Ti Kp

(6.6)

It is convenient to use the parameters @s and ( as design parametersi @s determines the response speed and ( determines the shape of the response.
With controller parameters given by (6.6) the closed-loopsystem is characterized by the Gang of six, see Equation (4.2).

PC

(2( c'to- 7lT)s + 03

: w C

K(s + llTi)(s + 1/")

I + P C sz+ 2( ross* af; T + P C

P

KoslT

I+PC:W

1 - - s ( s* r l r )
I+PC s2+2(ass*(D(

PCrr _ bQeao- llT)s +_aZ Crr _ K(bs+ rlTi)(s + LfT) 1+PC- s2+2(ass*of; L+PC- s2+2(atss*of;

(6.7)

The largest value of the transfer function from a load disturbance at the process input to the process output is

max lG,6(iat)lOJ

- " ? * l rP+Pd(iao)tr66

|
|

:

Kp
a,ro-"i" (LO'

To have good rejection of load disturbances it is thus desirable to choose ale as large as possible. The largest value of as is limited by the magnitude of the control signals and the validity of the process model. The transfer function from measurement noise to the control signal has the magnitude K for high frequencies. If K-"* is the largest permissible value of the controller gain it
follows from (6.6) that o t-n2T61 l I \e-K ^u" .

Let T" be the sum of neglected time constants or time delays and using the rule of thumb that the phase error should be less than t15" we find that ctts must be chosen so that ooTn < 0.25. Compare with Section 2.8.
The frequency 6tr6chosen should not be too small. An indication of this is given by Equation 6.6, which shows that the proportional gain is negative if 2(cosT < 1. Further evidence is given in Figure 6.10, which shows Bode plots

775

Chapter 6. PID Design l s ( ia t 6 ) l
101

lT(izts)l 10'

100

100

10

-1 1

0- 2-

100 at lao

)
10-

_1

1

0 1

0- 2-

\\.

100

102

a lao

Figure 6.10 Gain curves of the sensitivity functions for ( :0.7 and osT - 0.1, 0.2, 0.5, and 1. The dotted curve corresponds to rosL: 0.1 and the dash-dotted curve to ahL : L

of the gain curves of the sensitivity functions for different values of ar67. The figure shows that the sensitivities are large when ahT is small. The maximum of the sensitivity function is approximately M, - IIQ(ahT). A reasonable choice of the parameter ars is thus

2( < ttsr l

min1(E0 .

2

5-| -+--Kt-o

K

^

o

,y
)

(6.8)

The lower limit corresponds to pure integral control; see (6.6).
It follows from (6.7) that the transfer function from set point to process output has a zero at s - -tl(bTi).To avoid excessiveovershoot in the set-
point response, parameter b should be chosen so that the zero is to the left of the dominant closed-looppoles. A reasonable value is b - 7l@tsT;), which places the zero at s - -as. This gives

6:

2- (

-

L-
rlGttsT)'

It is particularly important to use a small value of b wher' osT is small and for unstable systems where 7 is negative. A response to set-point changes that does not have an overshoot is obtained by choosing b - 0 and ( > 1.
The reason why the sensitivities are large for small values of ahT is that the characteristic polynomial (6.5) is a poor choicefor designswhere the closedloop system is slower than the open-loop system. In such cases it is better to make a design that cancels the process pole and gives a closed-Ioop system with a time constant 76. Such a controller has the parameters

K- T KrTo
Ti:7,

(6.e)

and it gives a closed-loop system with M, : Mt : 1. The controller is not suitable when @oTo> 1 becauseit follows from (6.7) that the transfer function from load disturbances to process output is

P

sKoTs

I + P C ( 1 + s Z ) ( 1+ s ? 6 ) '

176

6.4 Pole Placement The attenuation of load disturbances is thus poor for large values of TslT. tr

Exeupln 6.7-PI CoNrRol oF PRocESSwrrH Two Rnel Polns Assume that the processis characterized by the second-ordermodel

P(s)-

K ( 1+ s ? r ) ( 1+ s 7 2 ) '

and that a PI controller is used. The loop transfer function becomes

Gr(r) -

P ( s ) C ( s )-

KpK(7 * sT;) r7,(1* s?r)(1+ srr)

KoK(s+ IlTi) TrTz(s+ llTl)(r + llTr)'

and the characteristic polynomial becomes

rr' '-

(L
\ .T -

1\
h)

^2
t-

,

1r

+-KTrfKr

-^s,

+

KrK
Vryr7,

(6.10)

The zeros of this third-order polynomial cannot be assigned arbitrary values since the controller only has two parameters. In particular, we find that the coefficient of s2 is given by the time constants of the process.However, if we also consider the frequency d)s&sa parameter it is possibleto match the polynomial ( 6 . 1 0 )t o
( s+ a a h ) ( r ' +2 ( a s s+ t 3 ) .
Matching coefficients of equal powers of s we get

Tt l- Tz a)o: (u + 2OTyT2
(r+zeoafirrr2-t
K_
Kp

KoK

T
LI

.
,

-

_

aatflT1T2

o, r : ao\rrTz Ko

It is thus possible to obtain a design that gives a prescribed configuration of

the poles with PI control, i.e., specified a and (. The parameter 6dsis a scale

factor that is determined by the process dynamics.

I

Exenpln 6.8-PID CoNrRol op Pnocoss wrrH Two Rnal Por,os Supposethat the processis characterized by the second-ordermodel

P(s)-

K (1+s"r)(l +s?2)

177

Chapter 6. PID Design

Ttlohhoriespesmpyoasdtreaemml .ehtTaeshrest,htrriteaenissfppeaorrsasfmuibnelectettiroosn.arBobfiyttrhauersiliynPgIDpalacPcoeInDttrhoeclloetnhrtrrecoeallneprbo, elewswhoriicfthttehnealcsaloossheads-

c ( s )-

K(l

+

s T i+ sTi

s z T i T a.)

The characteristic polynomial of the cJosed-loopsystem is
s3+sz+(;..ffi).'(h.ffi).ffi

(611)

A suitable closed-loop characteristic polynomial for a third-order system is

(s+ aah)(t' + 2( ross+ aZ),

(6.12)

which and a

contains two dominant poles with relative real pole located Ln -aoo.Identifying the

damping ( and frequencY (Do' coefficients of equal powers of

s in Equations 6.11 and 6'12 gives

1 - 1 * -xTui TEza --a* u,.\("d+zo

T- h-
1 - * 9 ! -- *ou\-l + z ( c a o )
fiTr- TrT,

KoK : TtTzTi

a o v, L .

solving theseequationsgivesthe following controller parameters:

TIzatZQ+zaO-t

K_

Ko

, - W ri - -

T{2aotf,

T1T20ts(u+20-Tt-Tz Ta-

,
rrt

_

aatTtTz

Kp

provided that c - 0, the transfer function from set point to process output has

onezero?t parameter

S b

:_rl@Ti).Toavoi can be'chosen so

dex that

cess this

iveovershootin zero cancels the

tphoeles

eatt -

ps

o:

i

n-tdroeos' p

oTnhsise

'

glves

b:

1
aroT,:

atf;TtT,
ffi'r,p+zao

-t'

Also, notice that pure PI control is obtained for

(t)s--(oficS:Lrr,

178

6.4 Pole Placement

The choice of os may be critical. The derivative time is negative for as I ag.

Thus, frequency oc gwes a lower bound to the bandwidth. The gain increases

rapidly with aro.The upper bound to the bandwidth is given by the validity of

the model.

n

The General Case
Since there is a relation between the complexity of the model and the complexity of the controller it is natural to ask what is the most general model that will give PI and PID controllers. A PI controller has two parameters which are sufficient to characterize a second-order equation; this permits a process model of first order. The system in Example 6.6 is thus the most general system where pole placement will give a PI controller.
Since a PID controller has three parameters, it is possible to determine all parameters of a third-order equation. With PID control it is thus possible to use pole placement for a second-order system. The most general second-order system is not the one in Example 6.8, but the one in the next example.
If only a pattern of the pole is specified a PI controller suffices for a secondorder system and a PID controller for a third-order system.

Exanrplp 6.9-GnxERAL SncoNo-ORDERSvsrnna Suppose that the processis charactefized by the second-ordermodel

h, \
r_\D/:

bp-lbz sLo * a G l a z

(6.13)

This model has four parameters. It has two poles that may be real or complex, and it has one zero. This model captures many processes,oscillatory systems, and systems with right half-plane zeros. The right half-plane zero can also be used as an approximation of a time delay. We assume that the process is controlled by a PID controller parameterized as

C ( s ): k + b * k a s
s
c r ( 4,:sb k * ) * c k a s '

The closed-loopsystem is of third order, and the characteristic polynomial is

s(sz + a1s * or) * (b1s* b2)(kas2+ h,s+ k).

A suitable closed-loopcharacteristic equation of a third-order system is (s -r aos)(rt + 2( :a.s+s ar|).

Equating coefficients of equal power in s in these equations gives the following

equations:

q * bzha* bft - (artto+ 2( los)(l + bftr)

dz* bzk+ b1k;- (L+ 2aOr30 + brkd)

b2k;:ao\(I+btka)'

179

Chapter 6. PID Design

This is a set of linear equations in the controller parameters. The solution is straightforward but tedious and is given by

b-

o r b \ - a 2 b 1 b 2 (+a 2 O o , - ( b , - a t b ) ( b z ( I + z a O @ ! + u b p t s o )
bt- brbT@+ zOan+ b1b2+(r2dOr3 - ublau

(-a1b1b2+a2bl+bl)aafr k i : bt- brbT@+ zoax+ b?bz+(rza( )r3- ublaf,

(6.14)

ka:

-otbT* a2b1b+2bl(u + 2Oah- b1b2atf+,(2r a( ) + blao! b?-, brbS@+ 2Oan+ blbz(r+ 2aOtB - ablatf,

These formulas are quite useful because many processescan be approximately described by the transfer function given by (6.13).
The transfer function from set point to process output is

G . , . ,( s ) : JJSP w

(b1s+ b2)(ckasz* bks * kr)
(s* aah)(r' + 2( ahs+ ,3)

The parameters b and c have a strong influence on the responseof this transfer

function.

I

The formulas given in Example 6.9 are particularly useful in cases when we are "stretching" the PID controller to extreme situations. The standard tuning rules will typically not work in these cases.Tlrpical examples are systems with zerosin the right half-plane and systems with poorly damped oscillatory modes. To illustrate this we will consider an example.

Exauplo 6.l0-OscrLr,AToRv SvsrpnrwrrH RHP Znno Considera systemwith the transfer function
P(') 1-s s2+1
This system has one right half-plane zero and two undamped complex poles. The processis difficult to control. To provide damping for the undamped poles at s : tl it is necessaryto have a reasonablecontrol gain at (t)- 1. This is difficult because the right-half plane zero at s : 1 implies that the gain crossover frequencies should be less than 0.5 in order to have a reasonably robust closedloop system. None of the standard methods for tuning PID controllers work well for this system. To apply the pole placement method we specify that the closed-loopsystem has the characteristic polynomial

s3+2s2*2s*1.

The formulas in Example 6.9 give a controller with the parameters k :0, kr :

1/3, and ka :2/3. This can also be verified with a simple calculation. Notice

that the proportional gain is zero and that the controller has two complex zeros

at +it/Z. Such a controller can only be implemented with a PID controller

having the non-interacting form. Compare with Section 3.2.

I

180

6.4 Pole Placement

Using Approximate Models
Since pole placement will only give PID controllers if the process model is of second order or less it is necessary to develop approximate models in order to use pole placement. Different approximation methods were discussedin Section 2.8. In this section we will illustrate the method with a few examples.
Consider a process described by the transfer function

P ( s ) : ( 1+ s ) ( 1+ o . z s ) (+1 0 . 0 5 s ) (+10 . 0 1 s ) '

(6.15)

This process has four lags with time constants l, 0.2, 0.05, and 0.01. The approximations can be done in several different wavs.

Exaupln 6.11-AppRoxrMATroN wrrH A Frnsr-OnDERSYSTEM

If the control requirements are not too severe,we can attempt to approximate

the transfer function by

P ( s ):

1

1+ 1.26s'

where the time constant is the average residence time of the system. As discussedin Section 2.8, this approximation is good at low frequencies.The sum of the neglected time constants is Tn : 0.26. The phase error is less than 15' for frequencies below 1 rad/s. Designing a PI controller with the pole placement method with ( : 0.5, the following controller parameters are obtained,

K:\.26(Do-l

L 2 6 0 t o- I

Ti

1.26a1

I.26as b - I . 2 6 a n- l '

rvhere b is chosen so that the zero becomes s - -@s. If the process model

rvould be correct, the phase margin with ( : 0.5 would be 50". Because of the

approximations made, the phase margin will be less. It will decreasewith al6.

For a;6 - 1 the phase margin it g* - 42. The closed-looppoles for the system are -100, -20, -4.99, -0.46 + 1.02i. The closed-looppoles obtained when the

controller is applied to the simplifled model are -0.5 + 0.87i. Because of the

approximation the dominant poles differ from the design values. The difference

increaseswith increasinE ao.The system becomesunstable for a)o:3.8255.

Figure 6.11 shows the sensitivity functions for the approximate and the

exact system. The maximum sensitivities are Mt : 1.35 and M, : 1.66, re-

spectively.This indicates that the closed-looppoles must be chosen with care

ri'hen using pole placement.

n

The next example shows what happens when the system is approximated with r second-ordermodel.

181

Chapter 6. PID Design

100 ca

10 - 1 1o-1

100 a

101

Figure 6.11 Sensitivity functions for the approximate system (dashed) and the true system in Example 6.11.

Exaupln 6.12-AppRoxrMATroNwrrH A SECoND-OnnuMn oonl Considerthe systemgiven bV (6.15).Approximatethe transfer function by

P(s)- ( 1 + s ) ( 1+ O . Z G s ) '

It is obtained by keeping the longest time constant and approximating the three shorter time constants with their sum. The sum of the neglected time constants is T" - 0.06. The phase error is less than 15' for frequencies below 4.4 radls. By making an approximation of the process model that is valid for higher frequencies than in the previous example, we can thus design a faster controllen If ( - 0.5 and a - 1 are chosen in (6.16), the design calculations in Example 6.12 give the following PID parameters:

K -0.52a3-r

,rt 'I;:

0.52afi- L
----------------
0.260tfl

0.52a0- 1.26 T a : 0.\2atf-; |

(6.16)

0.26a1 b - 0.52at!- I

In this case, pure PI control is obtained for ots : 2.4. The derivative gain becomes negative for lower bandwidths. The approximation neglects the time constant 0.05. If the neglected dynamics are required to give a phase error of, at most, 0.3 rad (17 deg) at the bandwidth, ots < 6 radls can be obtained. In Figure 6.12, the behavior of the control is demonstrated for ag:4,5, and 6.
The specification of the desired closed-loop bandwidth is crucial, since the controller gain increases rapidly with the specified bandwidth. It is also crucial to know the frequency range where the model is valid. Alternatively, an upper bound to the controller gain can be used to limit the bandwidth. Notice the effect of changing the design frequency ao.The system with (D0:6 responds

r82

6.4 Pole Placement

Figure 6.12 Set-point and load disturbance responses of the process with two poles controlled by a PID controller tuned according to Example 6.12. The responses for as : 4,5, and 6 are shown. The upper diagram shows set point lrp : I and process output y, and the lower diagram shows control signal u.

faster and has a smaller error when subjected to load disturbances. The design

will not work well wherr @ois increased above 8.

X

Dominant Pole Design In pole placement design it is attempted to assign all closed-loop poles. One drawback with the method is that it is difficult to specify many closed-loop poles. In Section 4.5 it was mentioned that the behavior of a system can often be characterized with a few dominant poles. It can therefore be attempted to place a few dominant poles. We will illustrate this with a few examples.
Exaupln 6.13-AN IxrncnarrNc CoNTRoLLER Consider a process with the transfer function P(s) and an integrating controller
c(s1- ki.
s
The closed-looppoles are given by

r+kiP(t) -o' s

Since the controller has one adjustable parameter, it is possible to assign one pole. To obtain a pole at s : -a the controller parameter should be chosen as

n, ai : P c a ) '

(6.17)

To obtain a good attenuation of load disturbances we will choosethe closed-loop pole so that the integral gain ft; is as large as possible. For example, if

P(s-)#1P,

183

Chapter 6. PID Design

we get

k i - a ( - a + 1 ) ' : e . 3- 2 a 2 + a ,

which has its maximum 4127 for a : LlB.

T

Exaupln G.14--pI CoNrRol

pApaoPrleaIsmc' eoCtnoetnrrioszlieldederrahasasprtowcoespsawraitmhettrearns.sfCeor nfsuenqcutieonntlPy,(irt),isannedcleeststahrey

to assign t controller

wo be

c ( s )- k + b .
s The closed-loopcharacteristic equation is

t+

(
\

k

+

&)
s/

p

(

s'

)_

o

.

Require that this equation has roors at

whereT : thus

atccos(6. The conditionthat the closed-loopsystemhas a polep1 is

r

+

/

(- u

*

;

A, )P

\ (

n

,

)

:0.

(6.18)

This is a linear equation in complex variables with solve it we introduce a(@0) and Q(ri,s),defined as

two unknown

variables. To

p (aorito-rt) - a(as)sia@il.

Notice that P (ahei(o-r)) represents the values r ay ei( n- v ) .Wh e n y : i T l 2 , th e n p (a 4 e i (o-i l ): frequency response.

of the transfer p(iah),which

function on the is the normal

Equation 6.18 can be written as

L+(k+\

k' \ a);"'@-))

"@ildo(ao:)

g'

This equation, which is rinear in ft and ft;, has the sorution

k__sin(Q@o)+y) a (ro o)si n 7
tt'"L-_ -;1aals,,s;in QGto) r* /

(6.1e)

Notice implies

that Q@ts)is zero for a6 that the proportional

_- 0 gain

and typically is negative

negative as a)sincreases.This and the integral gain positive

184

6.4 Pole Placement

but small for small alo. When als increases both k and ft; will increase initially. For larger values of ah both parameters will decrease. Requiring that both parameters are positive, we find that al6 must be selected so that

Y < -Q(,to) < r.

The integral time of the controller is

,-r' , - k sin(Q\ts)+y) k, al6sinQGto)

Notice t}l,atTi is independentof a(ah).

T

Exeupln 6.15-4 Punn Doao-TnanPRocnss Considera processwith the transfer function
P(s) - e-'1.
Using pure integral control, it follows from Equation 6.17 that ki: ae-o'. The gain has its largest value lzi - e-7lL for a:11L. The loop transfer function for the system is then

G z ( s )- P ( s ) C ( s.) - ] , u - " .
CSL

The sensitivity of the system rs Mr: 1.39, which is a reasonable value. With PI control it follows from Equation 6.19 that

l?-

sin(arsZsiny siny

y) n-aoL cosy

lei:

a

o

s i n ( a r e Ls i n 7 ) sin y

"-ahL

cosy

To minimize IE, we determine the value of as that maximizes h;.The results are given in Table 6.6. This table also gives the M" values and the IAE. The IAE has minimum at ( x 0.6. Notice that there are significant variations in the gain but that the values of integration time are fairly constant for all values of the design parameter (. The value of IAE should be small to give good rejection of load disturbances, and M, should be small to give good robustness. The table illustrates the trade-offs between these goals. To obtain a reasonable robustness of M, 12, the relative damping should be greater than 0.5.
Notice that for ( : l we get k : e-2 and lzi : 4e-2lL This can be compared ri'ith ki : e-r L for pure I control. With PI control the integral gain can thus be increased by a factor of 1.5 compared with an I controller. For a well-damped s-vstem(( : 0.707) the gain is about 0.2 and the integral time is fl - 0.28L. This can be compared with the values 0.45 and 2L obtained with the Ziegler\ichols frequency response method. The dominant pole design thus gives a controller with much stronger integral action than ttre Zregler-Nichols method. in Example 6.4 we found that this was highly desirable.

185

Ch.apter 6. PID Design.

Table 6.6 Controller parameters for dominant pole design of a PI controller for a pure time delay process.

k

kiL TilL ooL M, IAEIL

0.1 0.388 1.50 0.258 t.97 6.34 0.2 0.343 1.27 0.270 1.93 3.60 0.5 0.244 0.847 0.288 1.86 1.99 0.707 0.195 0.688 0.284 1.88 1.69 1.0 0.135 0.541 0.250 2.00 1.49

4.03 2.42 1.56 L.54 1.85

In summary, we find that a process with a pure delay dynamics can be

controlled quite well with a PI controller.

n

Dominant pole design is a special case of pole placement where it is only attempted to place a few dominant poles. For pure P, I, or D controllers one pole can be placed. For PI and PD controllers there are two dominant poles, which can conveniently be parameterized with the relative dampins (.The method becomes more complicated for PID control. After the design it is necessary to check that the closed-loop poles obtained are actually dominating. It is also necessary to evaluate the robustness of the closed-loopsystem.

Commentary
Pole placement is a standard method for control system design. The specifications are given in terms of all poles of the closed-loop system or possibly only the pole pattern. Goodjudgment is required to choosethe poles properly. When using pole placement the complexity of the controller is determined by the complexity of the process model. To obtain a PID controller it is required that the model is of low order or that the model is approximated by a low-order model. Time delay are often approximated when using pole placement. There is no natural way to introduce a robustness constraint in pole placement. The resulting closed-loopsystem must be analyzed to ensure that it is sufficiently robust.

6.5 LambdaTuning
Lambda tuning is a special case of pole placement that is commonly used in the process industry. The process is modeled by the FOTD model
P(s-) #e-1 .
Different approximationsof time delay,L result in both PI and PID controllers.
186

6.5 Lambda Tfuning

Pl Control If a PI controller with the transfer function

C;"( s J-

^- - I

+ sTi ,?i

is usedwith integral time fi chosenequal to the time constant T of the process, the loop transfer function becomes

G r ( r-)P ( s ) c ( s- )\ f e - ' L * & Y ,
where the exponential function has been approximated using a Taylor series expansion. The characteristic equation of the closed-loop system is
s(? - K,KL) * KoK :0.
Requiring that the closed-loop pole is s : -llT4, where Ta is the desired closed-looptime constant, we find

KoK L+7"1
which gives the following simple tuning rule
K_ IT KoL*Ta

(6.20)

The closedloop responsetime f:

a".r*n parameter. In the original work

by Dahlin [Dahlin, 1968] it was d"erln"oted as T4 : 1, which explains the name lambda tuning.

The choice of 7"1 is critical. A common rule of thumb is to choose 7"1 - 3T

for a robust controller and Tr7 - ? for aggressive tuning when the process

parameters are well determined. Both choices lead to controllers with zero

gain and zero integral time for pure time delay systems. For delay-dominated

processesit is therefore sometimes recommended to chooseT; as the largest of

the values ? and 32.

A drawback with lambda tuning is that the process pole is canceled. This

is not serious if for delay dominated processes.The integral gain is

',-.L- K -

1

T; Ko(L + Ta)'

When 7"1 is proportional to 7 integral gain is thus small for large ?. The response to load disturbances is thus very poor for lag-dominated processes.
For lag-dominated processes it is therefore useful to make a design that does not cancel the process pole. When the FOTD process is controlled with a PI controller the loop transfer function is

G r ( " ): P ( s ) C ( s ): KoK(l + sT)e-'L sTi(I + s?)

K K(1 + r",)(1- sL) sTi(l + sT) ..

-

,-.r.

''li, ri\tl

L87

\i
;

,' (

ii

r,

.

l

:

! -.,'i '

'i't'l"r /f "

Chapter 6. PID Design

where the exponential function has been approximated by a Taylor series expansion. The characteristic equation is of second order:

,
"

/lT;iiT"

*

-

r- .'\L)+ ' (t Tr,,

+;k-L)

*1:o

Comparing this with the desired characteristic equation,

t'T:, * 2 ( T 4 s * 1 : 0 ,

gives the controller parameters

K

L+2(7,1 r:, + r:tl6pK) + 2(T,tL + L2

T; _ K.K(L + 2(Ta) I+KoK

(6.21)

These tuning rules can also be applied to integrating process provided that 7"1 is chosen properly. For lag-dominated processesit is reasonable to choose ?"7 proportional to L.

PID Control

For the derivation of the PID design, the interacting form of the PID controller

(3.8) is used:

c ' ( r )-

K

'

9+

s

r

i) ( 1+ 'Ti

s

4

)

The time delay is approximated using (2.59),which givesthe processtransfer

function

p(\ s/): 21r+,s1Z

x

Ko\ - sL 12)
(1+ s7)Q+ sr lz)',

The integral time is chosento T! - ? and the derivative time to T!: Ll2. The zerosof the controller will then cancelthe polesof the process,and the loop transfer function becomes

G z( r ) : P ( s ) C ' ( r )= K o K ' ( I - s L l 2 ) sT
The characteristicequationis

s(7 - KpK'Ll2) + KpK' -- 0.

Requiringthat the closed-loopoleis s - -llTa we find

KpK' :

T L12+7,1

188

6.6 Algebraic Design

which gives the following simple tuning rules:
IT K,
KpLl2-rTa T! :T
ri: +

Using (3.9), the correspondingouJurn"r.rs for the noninteracting PID controller becomes
K:L!I?*T K,L12*Ta

Ti: T + L12

(6.22)

TL Td: L +27'

Notice that there is no derivative action for pure delay processes(? : 0).

Commentary
Lambda tuning is a special case of pole placement. It is a simple method that can give good results in certain circumstances provided that the design parameter is chosenproperly. The basic method cancelsa processpole which will lead to poor response to load disturbances for lag-dominated processes.Various ad hoc fixes can be made, but this requires insight.

6.6 AlgebraicDesign

There are several algebraic tuning methods where the controller transfer function is obtained from the specifications by a direct algebraic calculation. The methods are closely related to pole placement.

StandardForms
A fundamental question is to determine transfer functions that give suitable responses to set-point changes. This can be done by starting with a transfer function of a given form and determining the parameters so that some error criterion such as IAE. ISE. or ITAE is minimized.
Tlpical examples are

rofi
Gr: s2+ 2( oto+ at!

a (DB
G z : (r' + 2(ahs+ ,ilG -raah)

Gs:

an(s+ Fao) FG' + 2( ahs+ ,3)

Gq:

aafi(s+ Fao) FG' + 2( ahs+ ,3)G + azts)

(6.23)

189

Chapter 6. PID Design

The parameter a.rsis a scale factor that determines the response speed. Pa-
rameters d, F, and ( determine the shape of the transfer functions. Relative damping ( is typically in the range of 0.5 to 1. The parameters a and B have a significant influence if they are less than one. Decreasing a makes the response slower and reduces the overshoot. Decreasing B makes the responsefaster and increases the overshoot. There have been many efforts to find parameters that optimize various criteria. Consider a system where the process has transfer
function P(s) and the controller transfer functions are

c

(

s

)

:x

(
\

t

+

+
s

+
Ti

s

"

a")/

crr(q- *(u. # +sc"a).

The closed-Iooptransfer function from set point to process output is then

G.,^,: PCrr

JJsp

I+PC.

The controller parameters K, Ti, arrd T6 are first chosen to match the denominator of the specified transfer function, and the set-point weights b and c are then chosen to match the numerator of the specified transfer function. Since the simple controllers only have a few parameters it is necessary that the chosen transfer functions be sufficiently simple.
For systems with error feedback where C(s) : CrrG) it is possible to give an explicit expression for the controller transfer function:

G rr,o | - Grr"o

(6.24)

To make sure that the controller obtained is a PID controller it is necessary to make approximations or cancellations as was discussed in Section 2.8.
It follows from (6.24) that all process poles and zeros are canceled by the controller unless Grr"o has corresponding poles and zeros. This means that error feedback cannot be applied when the process has poorly damped poles and zeros. The method will also give a poor load disturbance response when slow process poles are canceled.
There are many different versions of algebraic design methods. Let it suffice to present a few cases.

Haalman's Method

For systems with a time delay Z, Haalman has suggested choosing the loop

transfer function

,. Gr(t) :P(s)C(t) :gZ, e-tL .

The valu e 213was found by minimizing the mean square error for a step change in the set point. This choice gives a sensitivity M, - 1.9, which is a reasonable value. Notice that it is only the dead time of the process that influences the

190

6.6 Algebraic Design

Ioop transfer function. All other process poles and zeros are canceled, which may lead to difficulties.
Applying Haalman's method to a process with the transfer function
P(-sr)fun-'"

gives the controller

u^ ,(\s;:

2 ( 1+ s
wl;

?

)

:

2T
sxur

/
(t

*

1\
sT/

.

which is a PI controller with K - 2TlBKpL and ri - T. These parameters can be compared with the values K : 0ST lL and ?, : BL obtained by the Ziegler-Nichols step response method.
Comparing Haalman's method with lambda tuning we find that the integral times are the same and that the gains are the same if we choose Trt : L 12. Since lambda tuning is based on approximations of the time delay it appears more reasonable to use Haalman's method when the time delay L is large.
Applying Haalman's method to a process with the transfer function

P(s)-

Kp
( 1+ s f i ) ( 1 + s 7 2 )e-tL

gives a PID controller with parameters K : 2(Tt+?:2) lBKoL, Ti - T1tTz, and Ta : TrT2l(Tr+Tz). For more complex processesit is necessary to approximate the processesto obtain a transfer function of the desired form as was discussed in Section 2.8.
Figure 6.13 shows a simulation of Haalman's method for a system with normalized dead time t:0.5. The figure shows that the responsesare good.

Dangers of Cancellation of Slow Process potes
A key feature of Haalman's method is that processpoles and zeros are canceled by poles and zeros in the controller. When poles and zeros are canceled, there will be uncontrollable modes in the closed-loopsystem. This may lead to poor performance if the modes are excited. The problem is particularly severe if the canceled modes are slow or unstable. We use an example to illustrate what may happen.

Exavplp 6.16-Loss oF coNrnoll,ABrt,rry Dun ro ceNcsr,LArroN Consider a closed-loopsystem where a processwith the transfer function

P(s- /) : -J-^ n-sr 1+s?"
is controlled with a PI controller whose parameters are chosen so that the processpole is canceled.The transfer function of the controller is then
c(s:)"(t.#) -KL:f

191

Chapter 6. PID Design

01020

30

40

50

Figure 6.13 Simulation of a closed-loop system obtained by Haalman's method. The
plant transfer function is P(s) : e-" l(s + 1). The diagrams show set point yrr, process output y, and control signal u.

The process can be represented by the equation

U9
dt

_

*

@
1'

Q
\

\_

L

)

_/

y

(

t

)

)

,

and the controller can be described bv
ry--Kw.+)

(6.25) (6.26)

Consider the behavior of the closed-loopsystem when the initial conditions are chosen as y(0) - 1 and u(t) - 0 for -L < t < 0. Without feedback the output is given by
Y"I(t) - e-tlr .
To compute the output for the closed-loop system we first eliminate y(f) between (6.25) and (6.26). This gives

4dt )tK- :/ '_: i "(t _ L).
It thus follows that u(t): 0, and (6.25) then implies that y,t(t)-e-tlr -y"t(t).

The trajectories of the closed-loop system and the open-loop system thus are

the same. The control signal is zero, which means that the controller does not

attempt to reduce the control error.

I

The example clearly indicates that there are drawbacks with cancellation of process poles. Another illustration of the phenomenon is given in Figure 6.14,

192

6.6 Algebraic Design
Figure 6.14 Simulation of a closed-loop system obtained by Haalman's method. The process transfer function is P(s) : e-'/(10s * 1), and the controller parameters are K : 6.67 and Ti : I0. The upper diagram shows set point !"p : 1 and process output y, and the lower diagram shows control signal u. The figure also shows the responses to a re-tuned controller with K : 6.67, Ti : 3, and b : 0.5.
which is a simulation of a closed-loopsystem where the controller is designed by Haalman's method. This simulation is identical to the simulation in Figure 6.13, but the processtime constant is now 10 instead of 1 for the simulation in Figure 6.L4.
In this case we find that the set-point response is excellent but that the response to load disturbances is very poor. The reason for this is that the controller cancels the pole s : -0.1 by having a controller zero at s - -0.1. Notice that the process output after a load disturbance decays with the time constant T : 10 but that the control signal is practically constant due to the cancellation. The attenuation of load disturbances is improved considerably by reducing the integral time of the controller as shown in Figure 6.14.
We have thus shown that cancellation of process poles may give systems with poor rejection of load disturbances. Notice that this does not show up in simulations unless the processis excited. For example, it will not be noticed in a simulation of a step change in the set point. We may also ask why there is such a big difference in the simulations in Figures 6.13 and 6.14. The reason is that the canceledpole in Figure 6.14 is slow in comparison with the closed-loop poles, but it is of the same magnitude as the closed-looppoles in Figure 6.13.
We can thus conclude that pole cancellation can be done for systems that are dead-time dominated but not for systems that are lag dominated.
Internal Model Control (lMC) The internal model principle is a general method for design of control systems that can be applied to PID control. A block diagram of such a system is shown in Figure 6.15. In the diagram it is assumed that all disturbances acting on the process are reduced to an equivalent disturb*nce d at the process output. In the figure P denotes a model of the process, PT is an approximate inverse
193

Chapter 6. PID Design
Controller

Figure 6.L5 Block diagram of a closed-loop system with a controller based on the internal model principle.

of P, and G1 is a low-pass filter. The name internal mod.el controller derives from the fact that the controller contains a model of the process internally. This model is connected in parallel with the process.
If the model matches the process, i.e., P : P, the sigpal e is equal to the disturbance d for all control signals z. If Gf : 1 and PT is an exact inverse of the process, then the disturbance d will be canceled perfectly. The filter G1 is introduced to obtain a system that is less sensitive to modeling errors. A common choice is G1(t) : tl$ + tTt), where Ty is a design parameter.
The controller obtained by the internal model principle can be represented as an ordinary series controller with the transfer function

(/1/ : - . crPr
I-GfPlP

(6.27)

From this expression it follows that controllers of this type cancel process poles

and zeros.

The internal model principle will typically give controllers of high order.

By making special assumptions it is, however, possible to obtain PI or PID

controllers from the principle. To see this consider a process with the transfer

function

P(s-) ,!*n-'"

(6.28)

An approximate inverse is given by

rt 1r;-

1+s? Kp

Notice that it is not attempted to find an inverse of the time delay. Choosing

the filter

G 1 ( s ):

1
| + sTs'

194

6.6 Algebraic Design

and approximating the time delay by

e-tL ol_ sL,

Equation 6.27 now gives

c ( s' ')--

1 , 1t ? = Kot(L+Ts)'

which is a PI controller. Notice that this controller is identical to the one ob-

tained by lambda tuning if T1 : T"r; see Equation 6.20.

If the time delay is approximated instead by a first-order Pad6 approxima-

tion,

e-

'r u N

I-sL1
r.;rE

2

Equation 6.27 glves instead the PID controller

c ( s )- ( r + s Ll 2 ) ( 1+ s " )
Kos(L*Ty*sTyL12)

( r + s Ll 2 ) ( 1+ s " ) Kos(L + Tf)

For processesdescribed by Equation 6.28, we thus find that the internal model principle will give PI or PID controllers. Approximations like the ones discussed in Section 2.8 canbe used in the usual manner to obtain PI and PID controllers for more complex processes.
An interesting feature of the internal model controller is that robustness is considered explicitly in the design. Robustness can be adjusted by selecting the filter G1 properly. A trade-off between performance and robustness can be made by using the filter constant as a design parameter. The IMC can be designed to give excellent response to set-point changes. Since the design method inherently implies that poles and zeros of the plant are canceled,the response to load disturbances may be poor if the canceled poles are slow in comparison with the dominant poles. Compare with the responsesin Figure 6.14. The IMC controller can also be viewed as an extension of the Smith predictor; see
Chapter 8.

Skogestad's lnternal Model Controller (SIMC)
Skogestad has developed a version of internal model control tuning method for PID control that avoids some of the drawbacks mentioned above. The method starts with a FOTD model for PI control or a SOTD model for PID control. It is required that the closed-loop system should have the transfer function

Grrro: ,jrre-rL

For an FOTD system it then follows from Equation 6.24 that the controller transfer function is

c ( s )-

1+s? KoG -t sT4 -

* e-'L)

I+sT ttEqn

",

195

Chapter 6. PID Design

where the exponential function is approximated using a Taylor series expan-

sion. In contrast with the recommendation for IMC the closed-looptime con-

stant is proportional to the time delay Z. The choice Td : Z is recommended.

The integral term is also modified for lag-dominated processes.The tuning rule

for PI control is

K- T
2KpL

(6.2e)

4 : min(T,8L)

The same parameters are used for a PID controller in series form, and the derivative time is chosen as the shortest time constant.

Commentary
The analytical design methods are very closely related to pole placement. The main difference is that the complete transfer function is specified instead of just the closed-looppoles. A nice feature is that the calculations required are very simple. A drawback is that processpoles are canceled.This is particularly serious for lag-dominated systems.

6.7 OptimizationMethods

Optimization is a powerful tool for design of controllers. The method is conceptually simple. A controller structure with a few parameters is specified. Specifications are expressedas inequalities of functions of the parameters. The specification that is most important is chosen as the function to optimize. The method is well suited for PID controllers where the controller structure and the parameterization are given. There are several pitfalls when using optimization. Care must be exercised when formulating criteria and constraints; otherwise, a criterion will indeed be optimal, but the controller may still be unsuitable because of a neglected constraint. Another difficulty is that the loss function may have many local minima. A third is that the computations required may easily be excessive.Numerical problems may also arise. Nevertheless, optimization is a good tool that has successfully been used to design PID controllers. In this section we discuss some of these methods.
A Warning
Optimization algorithms are very powerful. They will solve whatever criterion is formulated. It is therefore very important to formulate the problems correctly and to introduce all relevant constraints. For PID control it is particularly important to introduce robustness constraints. This has frequently been disregarded in much work the on use of optimization for PID control. The following example illustrates what can happen.
Exauplo 6.17-A PI CoNTnoLLEROprrurzno n'on IAE Consider a process with the transfer function

P (\s/) :

-l s*1

n_-'r

196

6.7 Optimization Methods

Table 6.7 Controller parameters obtained from minimization of integrated absolute error, I AE. Ky is the high-frequency gain of the controller.

L IAE M, Knr aK TilL

0.0 0

oo

0.2 0.r4 3.3 4.7 0.94 2.9

0.5 0.60 3.0 2.0 1.0 2.2

1.0 1.5 2.4 1.0 1.0 1.4

2.0 3.2 2.7 0.60 L.2 1.0

5.0 7.7 2.0 0.42 2.r 0.6

10.0 15 1.9 0.37 3.7 0.53

Table 6.7 gives controller parameters that minimize IAE for load disturbances.

Some of the other criteria are also given in the table. The table shows that the

integrated absolute error increaseswith L, as can be expected.The table shows

that the maximum sensitivity is large for practically all systems, particularly

those with small L. The table also shows that the high-frequency gain of the

controller is high for small values of L. For example, if we require M, < 1.8,

which is a fairly modest robustness requirement, none of the systems is ac-

ceptable.

n

The example illustrates the necessity of considering all aspects of a problem when formulating the problem. Unfortunately, this was not observed in much of the early work on controller tuning.

TuningFormulasBasedon Optimization
Many studies have been devoted to development of tuning rules based on optimization. Very often a process described by

P--lo-n-'r 1+s?-
has been considered. The loss functions obtained for unit step changes in set point and process input have been computed and formulas of the type
(+)' P:A

where p is a controller parameter and a and b are constants, have been fitted to the numerical values obtained. In many cases,the criterion is IAE for load disturbances, which often gives systems with low damping and poor sensitivity. The formulas given often only hold for a small range of normalized dead times, e.g., 0.2 < r < 0.6. It should also be observed that criteria based on set-point changes can often be misleading because it is often not observed that the setpoint changes are drastically influenced by different set-point weightings.

197

Chapter 6. PID Design

ModulusandSymmetricaOl ptimum
Modulus Optimum (BO) and Symmetrical Optimum (SO) are two methods for selecting and tuning controllers that also can be viewed as analytical designs where the desired transfer functions given by Equations 6.23 are obtained by optimization. The acronyms BO and SO are derived from the German words Betrags Optimum and Symmetrische Optimum. The methods were developed for motor drives where the response to set-point changes is particularly important. The basic idea is to find a controller that makes the frequency response from set point to plant output as close to one as possible for low frequencies. If G(r) is the transfer function from the set point to the output, the controller is determined in such a way that G(0) : 1 and that dlc(iot)llda" : 0 at o - 0 for as many n as possible. An interesting property is that the design method takes account of unmodeled dynamics explicitly. We illustrate the idea with a few examples.

Exeuplp 6.18-SncoND-ORDERSysrEM Consider the transfer function

G ( s )-

cL2

s2+a1s+a2'

which has been chosen so that G(0) - 1. Let us first consider how the param-

eters should be chosenin order to get a maximally flat frequency response.We

have

l

G

(

i

c

o

)-1

2o

?

a

'

*

(

al
oz

-

r

o

'

)

'

al
aZ+ a2(o?- 2or)* a4'

By choosing a1 - \Ea2 we find

l G ( i o t ) 1:2

al
a2,+ a+ '

The first three derivativesof lc(iat)l will vanish at the origin. The transfer function then has the form

G(s)-

afi

s2+aosvE+aZ

The step response of a system with this transfer function has an overshoot

o : 4Vo.The settling time to 2Voof the steady-state value is ?, - 6l ao.

I

If the transfer function G in the example is obtained by error feedback of a system with the loop transfer function Geo, the loop transfer function is

u^

,e\ o

(

s

,

)

:

1

G(r) _66;

:

afi
s(s * t/1r,to)

(6.30)

which is the desired loop transfer function for the method called modulus optimum.
The calculation in Example 6.18 can be performed for higher-order systems with more effort. We illustrate by another example.

198

6.7 OptimizationMethods

Exeupln 6.19-THmr-ORopn SvsrnnawIrH No Zpnos Considerthe transfer function

G ( s ):

A3

s3+41s2 *a2slas

After somecalculationswe get

l G ( i a ) l-

cL3

,v1o \".?+ @7-2aps)atz+ ("?_ 2a2)ra*4at6

Five derivatives of lG(ia)l will vanish at co : 0, if the parameters are such that al - 2az and al : 2atas.The transfer function then becomes

G ( s ):

afi
s3+ 2atss+2 2af;s+ aB

afi
(s+ ars)(r'+ ahs+ af;)'

(6.31)

The step response of a system with this transfer function has an overshoot o : 8.IVo.The settling time to 2Voof the steady state value is 9.41ah. A system with this closed-loop transfer function can be obtained with a system having error feedback and the loop transfer function
rnfl
Gr(t) : P(s)C(s) : s ( s 2+ 2 a h s+ 2 a t ! ) '

The closed-loop transfer function (6.31) can also be obtained from other loop transfer functions if the controller has set-point weighting. For example, if a process with the transfer function

p(s_)

"#^ is controlled by a PI controller having parameters K - 2, Ti - 2loto, and b : 0,
the loop transfer function becomes

u,-s, o:

ro!(2s+ aro)
aC +roj

(6.32)

The symmetric optimum aims at obtaining the loop transfer function given by Equation 6.32. Notice that the Bode plot of this transfer function is symmetrical around the frequency o) : ao. This is the motivation for the name symmetrical
optimum. If a PI controller with b : I is used, the transfer function from set point to
processoutput becomes

^, \

Gso(t)

G\o-l:.r, t

-r

.nr s s ( s, )

(2s+ an)a| (s+aro)(r'+ ahs+raof;)'

199

Chapter 6. PID Design

This transfer function is not maximally flat because of the zero in the numer-

ator. This zero will also give a set'point response with a large overshoot, about

43 percent.

tr

The methods BO and SO can be called loop-shaping methods since both methods try to obtain a specific loop transfer function. The design methods can be described as follows. It is first established which of the transfer functions, Geo or Gs6, is most appropriate. The transfer function of the controller C(s) is then chosen so that the loop transfer Gl(r) - P(s)C(s) meet specifications. We illustrate the methods with the following examples.

Exeupln 6.20-80 CoNrnol Consider a process with the transfer function

P(\s"), :

--{t: s(l + s?)'

With a proportional controller the loop transfer function becomes

G ,(" s / : s ( 1K K+os n

(6.33)

To make this transfer function equal to Gss given by Equation 6.30 it must be required that
alo: t/z
/T' The controller gain should be chosen as
K- ahJ2 1
2Ko zKpT'
!

Exaupln 6.21-SO CoNrnol Consider a processwith the same transfer function as in the previous example (Equation 6.33). With a PI controller having the transfer function
c ( s:)4 # 9 ,

we obtain the loop transfer function

G r ( s )- P ( s ) C ( s ):

KrK (1+ sT,) s z T ; ( I+ s ? )

This is identical to Gss if we choose

K-

1'

2K"T

Ti : 47.

To obtain the transfer function given by Equation 6.31 the set-point weight should be zero.

200

6.7 Optimization Methods

A Design Procedure A systematic design procedure can be based on the methods BO and SO. The design method consists of two steps. In the first step the process transfer function is simplified to one of the following forms:
p , ( r:)#

&(s) :

Kp
(1+s?r)(t+sTz)' T1)72

P3(s) :

Kp (1 + s?r)(L + sT2)(1+ s73)'

TrlTztTe

Pa(s) :

Kp

s ( 1+ s ? )

P5(s) -

Kp s ( 1+ r " r ) ( 1 * s T 2 ) '

T1) T2.

Process poles may be canceled by controller zeros to obtain the desired loop transfer function. A slow pole may be approximated by an integrator; fast poles may be lumped together as discussed in Section 2.8. The rule of thumb given in the original papers on the method is that time constants ? such that asT .--0.25 can be regarded as integrators.
The controller is derived in the same way as in Examples 6.20 and 6.21 by choosing parameters so that the loop transfer function matches either Gss or Gso. By doing this we obtain the results summarrzed in Table 6.8. Notice, for example, that Examples 6.20 and 6.21 correspond to the entries Process Ga in the table. It is natural to view the smallest time constant as an approximation of neglected dynamics in the process.It is interesting to observe that it is this time constant that determines the bandwidth of the closed-loopsystem.
The set-point response for the BO method is excellent. Notice that it is necessary to use a controller with a two-degree-of-freedom structure or a prefilter to avoid a high overshoot for the SO method. Notice also that process poles are canceled in the cases marked C1 or C2 in Table 6.8. The response to load disturbances will be poor if the canceled pole is slow compared to the closed-loopdynamics, which is characterized by ao in Table 6.8.
These design principles can be extended to processesother than those listed in the table.

Exaupln 6.22-AppLrcATroN oF BO AND SO Consider a process with the transfer function

P(s) : ( 1 + s ) ( 1+ 0 . 2 s ) ( 1+ 0 . 0 5 s ) (+1 0 . 0 1 s ) '

(6.34)

Since this transfer function is of fourth order, the design procedure cannot be applied directly. We show how different controllers are obtained depending on the approximations made. The performance of the closed-loopsystem depends on the approximation. We use parameter @6as a crude measure of performance.
If a controller with low performance is acceptable, the process (6.34) can be approximated with

P(s)1+ 1.26s'

(6.35)

20r

t9

N3

P

C

M

Remark

KKo

Ti

Ta

@s

g *FE

$

H

\Y

]

FE

-

UFYA

-l

XX
E.

TIiI

'

F

F

9)

P1

BO

0.5

T

0.7
r

K<
x.

+)
x

Xc@,t

XF

'

-

*a H

ia

\l

q= Xvd5

9 !-

P2

BO

A1

T1
n,

Tr

P2 PI B O

C1

n,

P2

PI

SO

A1

T1
n,

P3 PD BO AI, C2

Tr nt

0.7

r,

0.7

T1

n

0.5

4Tz

r,

T2

0.7
n

^@l

3iH i'rn

d-

,

g 6

. -

q, O?t

r5 Hx

5P
3H

ct)
orq

^5:.FD

\r

-

v

H

H'rHH

^-Y

J

A

P-^-

a\96
P r SA

, b< g

9P oF

P

-uYt

P3 PID B O CL,C2

Tt*Tz
nt

Tt*Tz

TrTz T:t+h

0.7 h

1

95 6 &

o
g

6$ @+

i

-

P3 PID S O

Pa

P

BO

P4

PI

SO

P5 PD B O

P5 PD SO

P5 PID S O

AI, C2
C1 A1 C1

-T-r-(Tz+ 4n) 8r{-
1
n
1
n
1
n,
Tr
8',ry
-T-r8*174T- z

Tz * 4Ts

4TzTs Tz * 4Te

0.5
n

T2 Tz * 4Ts

4T Tt * 4Tz

TL
4Tz 4T1?2
T+4r,

0.7

T

1

0.5

T

0

0.7 1

h

0.5

r,

1

0.5

Ty

h

Tr+4h

H^A+

'Y-^+

o95rr 9rd I

o

4p

e
x

E'
=v

P

55oar

dqlFj{

sFea

a;18

to

e

-
,

i
t

i
r

-
B

gHHHsNFE-

!AgJ

5^-
^r \Y L-f *_ -GJ l
Tq q [ 3'o
-h-r i-oo q. ? .

aaa

6.7 Optimization Methods

Table 6.9 Results obtained with different controllers designed by the BO and SO methods in Example 6.22. The frequency at- defines the upper limit when the phase error is less than 107o.

Controller
1 2 310 4

K

T; Ta hi

0s 0)m IAE

0.4

t.92 1

0.52 1

r.2 0.17 8.3 1 1

15.3 0.44 0.11 35 0.45 0

0.55 r.r2 2.7 2.7 5.15 0.52 t1.7 26.6 0.12 8.3 26.6 0.029

The approximation has a phase error less than 10" for @ < 1.I2. It follows from Table 6.8 that the system (6.35) can be controlled with an integrating controller with
n , : IT:i t-.o26: u: 0^. 4 .
This gives a closed-loopsystem with a)o:0.55. A closed-loop system with better performance is obtained if the transfer
function (6.34) is approximated with

P(s)- ( 1 + s ) ( 1+ 0 . 2 6 s ) '

(6.36)

The slowest time constant is thus kept, and the remaining time constants are approximated by lumping them together. The approximation has a phase error less than 10" for o < 5.15. A PI controller can be designed using the BO method. The parameters K : 7.92 and Ti: 1 are obtained from Table 6.8. The closed-loopsystem has a-r6: 2.7.
If the transfer function is approximated as

P(s): ( 1+ s ) ( 1+ 0 . 2 s ) ( 10+. 0 6 s ) '

(6.37)

the approximation has a phase error less than 10" for a < 26.6.The BO method can be used also in this case.Table 6.8 gives the controller parameters K - 10, Ti: L.2, andTa - 0.17. The controller structure is defined by the parameters b - t and c - 1. This controller gives a closed-loopsystem with (Do: It.1.
The method SO can also be applied to the system (6.37). Table 6.8 gives the controller parameters K - 15.3,Ti : 0.44, Ta :0.11, and 6 : 0.45.For these parameters we get as: 8.3.
Controllers with different properties can be obtained by approximating the transfer function in different ways. A summary of the properties of the closedioop systems obtained is given in Table 6.9, where IA-E refers to the load disturbance response. Notice that Controller 2 cancels a process pole with time constant 1 s and that Controller 3 cancelsprocesspoles with time constants 1 s
and 0.25 s. This explains why the IAE drops drastically for Controller 4, which

203

Chapter 6. PID Design

Figure 6.16 Simulation of the closed-loop system obtained with different controllers designed by the BO and SO methods given in Table 6.9. The upper diagram shows set point y"o and process output y, and the lower diagram shows control signal u.

doesnot cancel any processpoles. Controller 4 actually has a lower bandwidth

a;6than Controller 3.

A simulation of the different controllers is shown in Figure 6.16. The simula-

tion and the data shown in Table 6.9 clearly illustrate the benefits of improved

modeling and more complicated controllers.

I

Designfor DisturbanceRejection
The design methods discussed so far have been based on a characterization of process dynamics. The properties of the disturbances have only influenced the design indirectly. A load disturbance in the form of a step was used, and in some cases a loss function based on the error due to a load disturbance was minimized. Measurement noise was also incorporated by limiting the highfrequency gain of the controller.
In this section, we briefly discuss design methods that directly attempt to make a trade-off between attenuation of load disturbances and amplification of measurement noise due to feedback.
Consider the system shown in Figure 6.17. Notice that the measurement signal is filtered before it is fed to the controller. Let D and N be the Laplace transforms of the load disturbance and the measurement noise, respectively. The process output and the control signal are then given by

x-i"D-#;1

u--#"o-!9r-tt,

(6.38)

where Gt : PCQ is the loop transfer function. Different assumptions about the disturbances and different design criteria can now be given. We illustrate by an example.

204

Controller

6.7 OptimizationMethods

Figure 6.17 Block diagram of a closed-loopsystem.

Exenapln 6.23-DnsrGN FoR DrsruneANCEREJECTToN Assume that the transfer functions in Figure 6.17 are given by

P- I s

Gf:L'

C:k+b

Furthermore, assume that n is stationary noise with spectral density Qn and

that d is obtained by sending stationary noise with the spectrum Q6 through

an integrator. This is one way to model the situation that the load disturbance

is drifting and the measurement noise has high frequency.

With the given assumptions, Equation 6.38 then becomes

X-

1p,_fiffi*

s2*ks*ki

u--;Hh1 o,- s2k+ kis Ar s4 7r,*4"'

where we have assumed

D ( s )- 1 a ' ( ' ) '
.s

If n and d4 are white noises, it follows that the variance of r is given by

T ) , " r : E x 2 : h u a + i ( u .

This equation clearly indicates the compromise in designing the controller.

The first term of the right-hand side is the contribution to the variance due

to the load disturbance. The second term represents the contribution due to

the measurement noise. Notice that the attenuation of the Ioad disturbances

increases with increasing k and ki, but that large values of fr and lzi also

increase the contribution of measurement noise.

We can attempt to find values of ft and lzi that minimize J. A straightforward

calculationgives

,, :14
k: vE(U\
\Q" /

R, i :

t

l l

Q ,

a.

uQ,

205

Chapter 6. PID Design

This means that the controller parameters are uniquely given by the ratio of the intensities of the process noise and the measurement noise. Also notice that with these parameters the closed-loopcharacteristic polynomial becomes

t'+ahtJi+a20,

with a0 : 1/AJA" The optimal system thus has a relative damping ( :0.707 and a bandwidth that is given by the ratio of the intensities of load disturbance

and measurement noise.

I

Commentary
Optimization techniques are very powerful. When using them it is essential to include all relevant aspects of the problem in the formulation; otherwise, the so-called optimal controller may have very bad properties. In this section we have covered a few optimization methods that have been used for PID control.
The methods BO and SO are widely used for drive systems. The optimization is to find a transfer function from set point to process output that is maximally flat. The methods are primarily intended for systems without dead time. Small dead times can be dealt with by approximation.
An interesting feature of the procedure is the use of approximations; fast poles and slow time constants are neglected, and slow dynamics are approximated by integrators. Model uncertainty also appears explicitly in the design because the achievable bandwidth is determined by slowest neglected time constants.
The methods can be interpreted as pole placement where the desired closedloop characteristic polynomial is
Aso(t) :s2*@os{2+o2o
for the modulus optimum and
Aso(s) : (s * aro)(r' * alss+ ar|)
for the symmetrical optimum. There are possibilities for combining the approaches. A drawback with all design methods of this type is that process poles may be canceled.This may lead to poor attenuation of load disturbances if the canceled poles are excited by disturbances and if they are slow compared to the dominant closed-looppoles.

6.8 RobustLoopShaping
The design methods discussed so far all have the property that the robustness to process variations has to be checked after a design. One of the major advances in control theory in the end of the last century was the emergence of design methods with guaranteed robustness (the so called l{n theory). In this section we will present a method for design of PID controllers in the same
206

6.8 Robust Loop Shaping

spirit. In Section 4.6 it was shown that robustness conditions can be expressed in terms of circular discs that are forbidden regions for the Nyquist curve of the loop transfer function. For PID control these conditions give a set of admissible values of the controller parameters, called the robustness region. Attenuation of low-frequency load disturbances is inversely proportional to integral gain ft;. Measurement noise injection is captured by controller gain k for P and PI control or derivative gain k6 for PD and PID control. The design method is to maximize integral gain ft; subject to constraints on robustness and noise injection. Good set-point response is then obtained by set-point weighting or feedforward as discussed in Section 5.3. This design method brings design of PID controllers into the mainstream of control system design.

TheRobustnessRegion
In Section 4.6 it was shown that robustness to process variations can be expressed by the maximum sensitivity Mr, the maximum complementary sensitivity M7, ot with the joint sensitivity M. All these conditions say that the Nyquist curve of the loop transfer function should avoid circles enclosing the critical point. For PID control of a process with given transfer function the robustness constraint translates into constraints on the controller parameters, called the robustness region. To determine the robustness region we consider a processwith the transfer function P(s) and an ideal PID controller with the transfer function C(r).The loop transfer function is G7(s),and the square of the distance from a point on the Nyquist curve of the loop transfer function to the point -c is

f (k,ki, ka,@): lc * G1(ia)l' - lt + (k + i(k6ot- k,l a)) P(iro)12;

and the robustness constraint becomes

f (k, ki, ha,a) > r2.

(6.3e)

Introduce where

P(iat) : a(at) + iB@t) - P(aleie(a)

(6.40)

u(a) - p(a)cosg(a), F@t): p(o) sing(at).
The following straightforward but tedious calculation showsthat the function f canbe written as

f ( k , k i , k a , a- ) )l , * ( n+ \ n 4 a- k , l a ) ) ( a ( o+t )t B @ \ 1 ' z : lc* utz-rF&aa- kilro)+ i(Bk-ra(lz6a- tk,lr))l'
- c2t p't' * 2cak + p2(kaa-t k,la)' - 2Bc(k6a- kila)
: p2(u#.)' * #(u,*# - no,',)','.

207

Chapter 6. PID Design

Figure 6.18 Robustness region for a process with the transfer function P(s) : 1/(s + l)a and the robustness criterion M. < 7.4.

where the argument o in the functions a and B have been dropped to simplify the writing. Inserting the arguments the robustness condition can be written

AS

1p @\t')(n+
\r/\'"'p(al2)

"

_

t

q

+

)* '

( plq\'(u,*
\ar /\'-"

r!:?y
p(o)'

_ a z k ) '. ,

(6.41)

To have a stable closed-loop system there is also an encirclement condition required by Nyquist's stability theorem. The robustness constraint thus implies that the controller parameters must belong to a region called the robustness region; see Figure 6.18. Design of PID controllers can thus be formulated as the following semi-infinite programming problem: maximize ft; subject to the robustness constraint (6.41) and constraints on k and ka.
Figure 6.18 gives good insight into the design problem. The PI controller, which maximizes integral gain, can be found from the intersection of the robustness region with the plane lza:0. The best PI controller has k - 0.4 and Izi : 0.2. Five times larger values of the integral gain can be obtained by using derivative action.
The optimization problem is not straightforward since the constraint (6.41) must be satisfied for all rtt, and the set of parameters that satisfy the constraint is not necessarily convex. Before solving the optimization problem we will therefore investigate the constraint set.

A Geometric Interpretation
The robustness constraint (6.41) has a nice interpretation. For fixed a and k6 it represents the exterior of an ellipse in the k-lzi plane; see Figure 6.19.

208

6.8 Robust Loop Shaping

n
ri r)
1e
er. tond Ing
+r)
onwe
and j.19.

Figure 6.19 Graphical illustration of the sensitivity constraint (6.41).

The ellipse has its center in k - acf p2 and &; : a7clp2, and its axes are parallel to the coordinate axes. The horizontal half axis has length rf p, and the vertical half axis has length (DrI p. The center of the ellipse lies on the stability boundary.
When al ranges from 0 to oo the ellipses have an envelope

f ( k , k i , k a , 0 ) ): 1 2,

af

U^

o

(k t'

,

l

z

i

,

k

d

,

a

):

0,

(6.42)

which defines one boundary of the sensitivity constraint. Assuming that the process has positive gain the other boundary is given by the k - ka plane. Since the function f is quadratic in ki the envelope has two branches; only one branch corresponds to stable closed-loopsystems.
Having understood the nature of the constraints it is conceptually easy to solve the optimization problem by finding the largest value of ki on the envelope. There may be local minima and the envelope may have edges. This is illustrated in Figure 6.20, which shows the envelopes and the locus of the lowest vertex of the ellipse in two cases.The figure on the left has a smooth envelope, and the locus of the lowest vertex coincides with the envelope at the maximum. The figure on the right has an envelope with an edge at the nraximum value of ki. Since it is quite time-consuming to generate the envelope, it is desirable to find algorithms that can give a more effective solution. It is rilsoof interest to charactertze the caseswhere there is onlv one local minimum.

Smooth Envelope
\\'e will first consider the casewhere the envelope is smooth and doesnot have eorners near the maximum. The largest value of ki fot fixed ka then occurs at a tangency with the lower vertex of the ellipse; see Figure 6.19. The locus of :]re lower vertical vertex is given by

k(a): -# : -;^coss(at),
k i ( a,t ) : - F( D 1 c - ; o r * a "ek. a : - @ * c s i n p ( a t )+) rtf k4. ^AQ

(6.43)

209

Chapter 6. PID Design
0
"{i

Figure 6.20 Geometrical illustration of the ellipses generated by the sensitivity con-
straint (6.39) and the envelope generated by it. The curves on the left are generated for a system with the transfer function P(s) : (s + 1)-a with the constraint M" : I.4. The curves on the right are generated for a system with the transfer function P(s) : 1/(s + 1)(s2 + 0.2s * 9) with the constrain| M, : 1,4.

It is shown as a dashed line in the Figure 6.20. The largest value of ki can thus be found by maximizing ki on the locus of the lowest vertex. Differentiating the expression for ki in (6.a8) gives

dki drtt

d
drtt

ro(r
I \

+9sinp)
p

* 2aka

- (r* csinp(#)

il

- *#"

i 2 o t k . :s .

To simplify the writing we have dropped the argument ot of the functions a,
B, and p. Dividing the above equation with ot and multiplying it with p, the condition for extremum becomes

hpro(a) :

(r

*

c

s

i

n'a' \\

(4
p

-

1'1
@/

-

c9' cos9 * 2pk4 :

g.

(6.44)

To find the optimum we thus have to find the solution ai,, of this equation; the controller parameters are then obtained from Equation 6.43.
Equation 6.44 is satisfied for a minimum, a maximum, or saddle point. To ensure that there is a maximum it must be required that

# r , . ) >o

(6.45)

To guarantee that the constraint (6.41) is satisfied globally we have to evaluate it for all at. This can be done by the Nyquist plot of the loop transfer function.
Equation 6.44 can be solved iteratively by bisection or with the NewtonRaphson method, both methods converge very fast, but they require appropriate initial conditions. Notice, however, that in general, there may be several solutions that can be found by starting the iteration from different initial conditions.

2I0

6.8 Robust Loop Shaping

For special classes of systems it is possible to give good initial conditions. Consider systems where the transfer function P(s) has positive low-frequency gain and

d aryP(io) <0, dat
d l o g l sl e Q a t ) l< 1 .
dlogto ttt

(6.46)

These conditions imply that the quantity p' I p-Ilat is negative. For PI control, rvhen ka : 0, it follows from (6.44) and (6.46) that hpr(ago) ) 0 and that
hprGttgo-arcsin,/"<) 0. Equation 6.44 then has a root in the interval

Aso l Abt < 0180-arcsin(rlc).

(6.47)

The monotonicity condition (6.46) thus only has to be valid in the interval 6.47). If condition (6.46) holds it follows from Equation 6.43 and 6.47 that both ft and lzi are positive. Many processessatisfy this condition.

P DC o n t r o l
For PD control it is natural to maximize proportional gain subject to the robustness constraint. Working out the details for the case of smooth envelopes ri-efind that the problem can be solved as follows: Find a value of ar such that

hpn(rrt):(r * ccosO'4p + ce'sinp : 6.

(6.48)

Then compute the controller gains from the equations

k ( a -t )- # ka(al#: :

L

r+ccos(p

p

CSLn9
0p

(6.4e)

If p'I p is negative(6.a8)alwayshas a solutionaio in the interval

@no 1 Abn

1

(;DzTo-arcsin(r : lc)

& ) l 8 q + a r c c o s( r / c ) .

(6.50)

The formula and the code for design of PD controllers can also be used simply by making the observation that designing a PD controller for the system P(s) is the same as designing a PI controller for the system sP(s).

A Design Algorithm
We obtained the following algorithm for solving the design problem in the case of smooth envelopes.

27r

Chapter 6. PID Design

AlconrrHu 6.1-CoNTRoLLEn DpsrcN pon SuoorH ErwsI,opn
1. Design a PD controller by solving (6.48) by bisection starting with the interval (atrro,d)180+u"..os(r/cT)h).e solution gives the frequency abn.
2. Design a PI controller by solving rc.aa) with ka :0 by bisection starting with the interval (ales,d)l86-arcsin(r/c)T)h. e solution gives the frequency
ofu.
3. Design a PID controller for fixed ka by solving (6.44) by bisection starting with the interval (rai,,@bo). Increase k6 to the largest value for which the robustness constraint is satisfied.
4. Verify that there is a smooth envelope by computing (6.45) or by the Nyquist plot of the loop transfer function. tr
If the envelope is not smooth the solution obtained by iteration corresponds to a local maximum of the distance from the critical point to the Nyquist curve. The Nyquist curve then enters the constraint region for points around the maximum.

Envelopewith Corners
The largest value of ki may also occur at a point where the envelopehas an edge.This is illustrated in Figure 6.2t. The verticesB and C of the ellipsein Figure 6.19 are given by

I e ( a t ) :p- +" p+ L : -

a

(

a

)

c
p

c o sQ
(al

(

a

t

)

-I J-

r
---l-Tr
p\(t))

k i f u'ip) -. - ' F o ' * o t 2 k 4

_

_acsi:tQ@t) p(at)

*

a2k4.

(6.51)

where the left vertex corresponds to a minus sign and the right vertex to a

plus sign. The loci of these vertices are shown in thin dotted lines, and the loci

of the center of the ellipses are shown in thin dashed lines. The envelope is

shown as a thick solid line, and the locus of the lowest vertex of the ellipse

by thick dashed lines. Notice that the maximum occurs at the intersection of

ellipses corresponding to two different frequencies, al1 and rtt2;see Figure 6.21.

The envelope condition (6.42) is then satisfied for both frequencies. This gives

the condition

f (lr,ki,kd,at): R2

af 0 r ( k . k i . k a .a r ) : 0 .
f (k,ki,ka,rloz):R2

(6.52)

af :0.
#(k.ki.ka,oz)

In the Nyquist plot this correspondsto the casewhen the loop transfer function is tangent to the M circle at two points.

It is thus possible to charactefize the point where lz; has its largest value by algebraic equations. This means that the design problem is reduced to solving

212

6.8 Robust Loop Shaping

I S
e )f
1
l.
j5
Iron eby ving

-02

-1 5

-1

-0.5

0

0.5

1

t?

Figure 6.21 Geometrical illustration of the sensitivity constraint (6.39) and the envelope generated by it. The envelope is shown by the thick solid line; the locus of the lower vertex by the thick dashed line. One half ellipse is shown as a thin solid line. The locus of the center of the ellipses is shown as a thin dashed line, and the loci of the vertical vertices by dotted lines. The curves are generated for a system with the transfer function P(s) : 1/(s + 1)(s2+ 0.2s* 9) with the constraint M, :2.0.

algebraic equations, (6.52), and that elaborate search procedures are avoided. The equation can be solved using the Newton-Raphson method.
Good initial values essential for the Newton-Raphson iteration can be obtained by approximating the envelope by the loci of the right horizontal locus and the locus of the lowest vertex of the ellipse; see Figure 6.21. We illustrate the case of envelopes with corners with an example.
Exaupln 6.24-AN Oscrr.leroRy SysrEM Consider the process with the transfer function
P(s): (s+1)(r'+osf9)'
This is an interesting process from two points of view. First, the system has two oscillatory poles with relative damping ( : al6. When parameter o is decreased it becomes more and more difficult to control the process. Second, depending on the value of parameter a the envelope may have a continuous derivative, a ) 1.0653,or a corner, a < 1.0653.
For the case when the envelope has a corner, a PI controller was designed for tr[.:2.0. In Figure 6.22the Nyquist curves and the time responsesare shown for the cases a - 0.2. 0.5, and 1.0. The controller behaves reasonably well in spite of the poorly damped poles. In Table 6.10 the controller parameters and

2r3

Cltapter 6. PID Design
Figure 6.22 Nyquist curves of the loop transfer function and time responses for Example 6.24 with o:0.2 (dotted),0.5, and 1.0 (dashed),when designing for Mr:2.0. Table 6.10 Interesting parameters when designing a controller for Ms :2.0 and different values of a in Example 6.24.
ki 01 0.0 -0.29 0.68 0.97 2.75 0.1 -0.25 0.82 1.08 2.7L 0.2 -0.20 0.93 1.16 2.67 0.5 -0.09 r.r7 r.37 2.55 1.0 0.09 1.38 1.65 2.30 2.0 0.48 r.54 2.79 2.79
the frequencies at which the loop transfer function is tangent to the Mr-circle are shown. Notice in Table 6.10 how the proportional gain is negative for small values of a. This is the only way to increase the damping of the oscillatory poles with a PI controller.
Finally, we illustrate how our design method will provide a reasonable PI controller for the extreme case a - 0. With the design parameter M, - 1.4 we obtain the controller parameters K - -0.183, ki : 0.25I, and b - 0. The time responses are shown in Figure 6.23. We observe that the set-point response is quite reasonable, even if there is a trace of poorly damped modes. The load disturbance will, however, excite the oscillatory modes. The fact that the PI controller is unable to provide damping of these modes is clearly noticeable in the figure.
The DerivativeCliff Smooth envelopesare frequently encounteredfor PI control of systems with essentiallymonotonefrequencyresponsesa, nd for PID control with moderate
274

6.8 Robust Loop Shaping

'cle rall oles
ePI I rve time , s ei s Ioad re PI ole in
r
s with ,derate

Figure 6.23 Time response of the closed-loopsystem of Example 6.24 obtained for a:0, when designing the PI controller for M, :1.4.

values of ka. However, optimization of ki over the robustness region often gives controllers with undesirable properties. This can be understood from the plot
of the robustness region in Figure 6.18, which shows that the largest value of lei occurs at an edge. Such a solution is undesirable because small changes in controller parameters give drastic changes in &;. This is also illustrated in Figure 6.24, which shows intersections of the robustness surface for fixed values of ka. The figure shows that for PI control (ka - 0) the envelope is smooth at the maximum hi : 0.2 which occurs for k : 0.4. Integral gain ki can be increased substantially by introducing derivative action. With higher values of ka the maximum of ft; does, however, occur at an edge. Integral gain has its maximum ft; - 0.9 fot k - 0.925 and ka - 2.86. The performance is very sensitive to variations in the controller parameters at the maximum. Figure 6.24 shows that a marginal increase of proportional gain makes the system unstable. The controller that maximizes ft; also has other drawbacks, which are illustrated by the following example.

Exavplo 6.25-TsE DERTvATTvECLrFF Consider a process with the transfer function

P r\'Dc )/_-

1
GllF

Maximizing integral gain &; subject to the robustness constraint M, < I.4, gives the controller parameters k - 0.925, ki : 0.9, and k,a- 2.86. The Nyquist plot of the loop transfer function is shown in Figure 6.25. Notice that the Nyquist curve has a loop. This will always occur when the maximum occurs where the envelope has an edge. The controller obtained has excessive phase lead, which is obtained by having a PID controller with complex zeros, Ti I 4Ta.In the particular case we have Tr : 0.3376. Time plots showing the response of

2t5

Chapter 6. PID Design

kd:o 1

0.8

0.6

0.4

0.2

-004.5 0 0 . 5

1

ha:7 1

0.8

0.6

u.+

0.2

-00 5 0 0 . 5

1

1 0.8 0.6 0.4 u.z
0=

ka:2 0.5 1

l?a:3
1

ka:3'I 1

0.8

0.8

0.6

u.b

0.4

0.4

0.2

0.2

t,nttnlt I tt,t ttt tt t.

atttt.tt

- 00 F. 5

0

0.5 1

1 . 5 -00w. 5

0

0.5

ka :3.3 1

0.8

u.b

0.4

0.2

J
1 . 5 - 00 * . 5

,ilttxt,t I t.t I
0 0.5

Figure 6.24 Cuts of the robustness region for constant derivative gain ka. The curves are computed for PID control of the process P(s) : 1/(s+ 1)4. Notice the sharp corners of the region for large k6 fthe derivative cliff).

A I- G1(irtt)

ReGlQa)

Figure 6.25 Nyquist curve of the loop transfer function for PID control of the process P(s) : 1/(s + 1)4,with a controller having parameters k :0.925, ki : 0.9, and ka :2.86.
216

6.8 Robust Loop Shaping

Step in set point

f
0.5 I
I
I

10

40

t.3
:1 I
0.5 I
0 10

Step in load disturbance

0.4

,\
I

- 0.2

\, lr \

0

-v,z
10

t.J

1
I I
0.5

0 10

Figure 6.26 Time responses for PID control of the process P(s) : 1/(s + 1)4, with controller having parameters k:0.925, ki :0.9, and &a : 2.86 (solid lines) and ft - 1.1,
Ai : 0.36, and h4: 0.9 (dashedlines).

the system to step changes in set point and load disturbances are shown in

Figure 6.26. The responses are oscillatory.

For comparison we have shown Nyquist plots and time plots for a PID controller where Ti : 4Ta. The controller parameters are lz : 1.1, ki - 0.36,

and ka : 0.9. The responses of this controller are better, even if the peak in

the response to load disturbances is larger.

n

Avoiding the Derivative Cliff There are several ways to modify the design problem to avoid the difficulties associatedwith the derivative cliff. One way is to introduce conditions that do not allow the Nyquist curve to have loops. Another alternative is to require Lhat Ti ) aTa. It has also been attempted to fix derivative gain to the value obtained by a PD controller. This does not eliminate the loops on the Nyquist curve in all cases.Maximization of ki can also be replaced by maximizing the absolute integral error due to load disturbances.
The MIGO Method \fter many attempts it has been found that a simple solution is to restrict derivative gain so that the maximum occurs at a point where Akil0k: 0. This rrvoids having a maximum at a ridge. The algorithm is straightforward.
-\lconrrHM 6.2-MIGO DnsrcN oF PID CoNTRoLLER
1. Fix derivative gain ft6. Find controller parameters by solving (6.44); then compute controller gains from (6.43).
2. Compute the value of M for a range of frequencies around al*, and test
.D.
the robustness constraint M > M*it.

2t7

Chapter 6. PID Design

3. Increase le6until the largest value that satisfies the robustness constraint is obtained. n
A good initial value of integral gain is the value obtained for a PD controller. This particular design method is called MIGO (M constrained Integral Gain Optimization).

An Algorithm for a Controller in Series Form
It frequently happens that the MIGO design method gives controller parameters such that T; < 4Ta. In Section 3.2 it was shown that such controllers cannot be implemented in series form. It is therefore of interest to have controllers where the parameters are constrained to Ti ) 4Ta. When the ratio n : TilTa 2 4, tt.e controller can be written as

c ( s:)a ( r +

#,.,r0):n

, ( T i s+

1 ) (Tis+
r:s

1

) ,

(6.53)

where

k : k ' T,T!+ TI

L
Ti: T!+ rl

rr'd -:

rirl
T!+1

Introducingn' - T!lTl, it alsofollowsthat

(6.54)

n:7 (r + n')2

(6.55)

Notice that n' : 1 corresponds to n -- 4. It follows from Equation 6.54 that Ti :
between the controller parameters

nTa gves the following relation

n,: kr'
nRa

A simple algorithm for maximizing the integral gain of a PID controller with Ti : nTa subject to a robustness constraint will now be developed. We first make the observation that PID control of the process P(s) gives the loop transfer function
Gr(r)- p(s)c(s-) u,G+ srDL+t sr} p(s)- k,G!:ry (tt * s"j)p(s)).

This is identical to the loop transfer function for PI control of the process
P'(') - (1 +s{)P(s).
Since there are efficient algorithms for PI control we obtain the following iterative algorithm.

2L8

6.8 Robust Loop Shaping

Table 6.ll Controller parameters obtained by loop-shaping design with M' : 1.4 for a processwith the transfer function P(s) : (s + 1)-4.

Controller

K

k;

ka b T; T6 IAE

PD PI PID MIGO PID 4 : 4Ta

1.333 0 1.333 1 01m 0.433 0.192 0 0.14 2.25 0 5.20 1.305 0.758 1.705 0x I.72 1.31 2.25 r.r32 0.356 0.900 0.9 3.18 0.80 2.5r

Ar,conrtnM 6.3-DESIGN oF PID CoNrnolLER wITH Ti : 4Ta

1. Start by designing a PI controller for the process P(s). This gives a controller with the integral time Ti : klki. Set Ti,: Til2 and j : l.

2. Design a PI controller for the process P'(s) : (1 + s?{)P(r). Let the

integral time of the controller be T!. Set {*, : (fj + f)p until ! converges to Tt . Let the controller gain be k' .

and repeat

3. The controller parameters are k - 2k', Tr :27' and Ta: T'12.

T

Examples The design method will be illustrated by two examples.

Exaupln 6.26-FouR EQUALLAGS Consider a system with the transfer function

P (\ s" /)--

-- 1(s+1;+'

Table 6.11 summarizes properties of PD, PI, and PID controllers designed for

M, : 1.4. The PD controller was designed by maximizing proportional gain;

the PI and PID controllers by maximizing integral gain. A PID controller with

the additional constraint T; - 4Ta was also designed. Responsesto set-point

changes and load disturbances for are shown in Figure 6.27.

The PID controllers have better performance than the PI controller. Inte-

gral gain is 2 to 3 times larger and IAE a factor of 2 smaller. The controller

PID MIGO has Ti : l.\Ta. The table shows that performance is decreased

when controller parameters are constrained to ?, : 4Ta.Notice that many

commercial PID controllers have the constraint T; ) 4Ta built in, because they

are based on the series form; see (3.10).

The parameter b is calculated as described in Section 5.3. The calculation

for the PID MIGO controller shows that the overshoot cannot be reduced suf-

ficiently by using zero set-point weight, which is indicated by the entry 0* in

the table. In this case it is recommended to use a proper feedforward design

for a system with two degrees of freedom. Such a design can improve set-point

response signifi cantly.

T

219

Chapter 6. PID Design
Step in set point

Step in load disturbance

0.5

0

10

20

30

0

10

20

30

l.t '
y'..f

0.5

I

0.5

I

I

01020300102030

Figure 6.27 Responsesfor the system P(s) : (s+ 1) a with the controllers in Table 6.11 to unit step changes in set point (left) and load disturbances (right). The dotted lines show responses with the PD controller, dashed with the PI controller, dash-dotted with the PID controller with parameters constrained to T; : 474, and solid lines with the PID controller designed using the MIGO method.

Exalrpr,n 6.27-FouR WTDELyDTSTRTBUTELDacs Consider a system with the transfer function
P ( s ): ( s+ 1 ) ( 0 . 1+s 1 ) ( 0 . 0 1+s 1 ) ( 0 . 0 0 1+s 1 ) '
Table 6.12 summarizes properties of PD, PI and PID controllers. All controllers were designed with the constraint that the maximum sensitivity is not larger than M, : 1.4. The PD controller was designed by maximizing proportional gain, and the PI and PID controllers by maximizing integral gain. A PID with the additional constraint T; : 4Ta was also designed. Responsesto set-point changes and load disturbances for the different controllers are shown in Figure 6.28.
Table 6.12 and Figure 6.28 show that derivative action improves performance drastically. The proportional gains of the controllers with derivative

Table 6.12 Controller parameters obtained by loop-shaping design with M, : 1.4 for a p r o c e s sw i t h t h e t r a n s f e r f u n c t i o n P ( s ) : 1 / ( s + 1 ) ( 0 . 1 s+ 1 ) ( 0 . 0 1 s+ 1 ) ( 0 . 0 0 1 s+ 1 ) .

Controller

K

ki

ka b

Ti

Ta

IAE

PD

9I.7 0 4.4 1 0 0.048 oo

PI

4.2t 8.53 0 | 0.494 0 0.1044

PID MIGO 85.5 1488 3.87 0 0.057 0.045 0.00143

PID 4 - 4Ta 86.7 518 3.63 0.6 0.168 0.042 0.00143

220

6.9 Sulli nt,:tt".

Step in set point

,''l-');'

:t I

0.5

:I'
:! l/

! l,'

I

0.2 0.4 u.o 0.8

i

* 16-sSteP in load disturbance

I

I

10

I tt

:

\

\ ':. -

0.2 4.4 0.6 1.5

10
0 -10
-20 0.2 0.4 u.o 0.8

nq
0.2 0.4 0.6 0.8

F i g u r e 6 . 2 8 R e s p o n s e sf o r t h e s y s t e m P ( s ) : 1 l @ + 1 ) ) ( 0 . 1 s+ 1 ) ( 0 . 0 1 s+ 1 ) ( 0 . 0 0 1 s+ 1 ) with the controllers in Table 6.12. The dotted lines show responses with the PD controller, dashed with the PI controller, dash-dotted with the PID controller with parameters constrained to Ti : 474, and solid lines with the PID controller designed using the MIGO method. The load-disturbance response for the PI controller is out of scale.

action are around 90, while the PI controller has the gain 4.2. It follows from

(4.40) that the largest peak of the load-disturbance responseis around 0.01 for

controllers with derivative action and about 20 times larger for PI control. The

peak is so large that the load disturbance response for PI control is way out-

side the graph. The response time is also drastically increased when derivative

action is used. The integral gains of controllers with derivative action are also

,r

much larger than for PI control.

I

-t
It is interesting to compare Examples 6.26 and 6.27. For the system with four

ir

equal lags in Example 6.26 the integral gain can be increased by a factor of 3 by

1t

introducing derivative action, while it can be increased by a factor of 200 for the

-

system with distributed lags in Example 6.27. The main differences between

the system is that the system in Example 6.27 is lag dominated; it has a

rI'-

normalized time delay r - 0.07. The system in Example 6.26 has r : 0.33. The

Ve

normalized time delay is a good indicator for the benefits of derivative action.

In Chapter 7 it will be shown that the large performance improvement with

derivative action is possible for processeswith small normalized time delays

(lag dominated processes).

6.9 Summary
A number of techniques for designing PID controllers have been presented in this chapter, starting with methods of the Ziegler-Nichols type, where process dynamics were characterized by a few features that could be obtained from simple experiments. These methods have been very influential and have been
221

Chapter 6. PID Design
used extensively by vendors. In spite of their popularity there are two drawbacks with the Ziegler-Nichols method, the fundamental assumption of quarter amplitude damping, which results in systems with very bad robustness, and the limited processknowledge used. Methods which avoids both difficulties will be developed in Chapter 7.
Standard methods for control system design can also be adapted to design of PID controllers. When using analytical techniques there is a correspondencebetween model and controller complexity, and it is necessary to approximate process dynamics by first- and second-order systems. Model reduction techniques are therefore necessary to apply pole placement to PID control. In particularly it is necessary to approximate the time delay. The unmodeled dynamics limit the performance that can be achieved, and the closed-looppoles that can be chosen.
Another way to use pole placement is to fix a pole configuration and to determine both the controller parameters and the magnitude of the poles. In this way it is possible to use second-ordermodels to design PI controllers and third-order models to design PID controllers. Another way to apply pole placement to PID control is to place the dominant poles only. The advantage of this approach is that it can be applied to models of arbitrary order. A particular pole placement technique called lambda tuning, which has been used extensively in the process industry, is given particular attention.
A number of so-called algebraic design methods have also been discussed. In these methods the closed-loop transfer function is given and the controller parameters are obtained by algebraic calculations. The controller parameters can also be determined by optimization methods, where it is attempted to optimize criteria that specify performance subject to various constraints. There are many methods reflecting the richness of the control problem. TWomethods, BO and SO, which are commonly used in motion control, have been given particular attention.
A novel design method developedby the authors and their coworkers is also presented. In this method it is attempted to optimize disturbance attenuation subject to constraints on robustness. The method gives a simple way to balance attenuation of load disturbances with the injection of measurement noise that is inevitable when feedback is used. Combining this method with set-point weighting, or more elaborate feedforward, gives a nice way to also achieve good response to set-point changes. The method can be viewed as an adaptation of robust design to PID control.
6.10 Notesand References
There is a very large literature on tuning of PID controllers. Good general sources are the books [Smith, 1972; Deshpande and Ash, 1981; Shinskey, 1988; McMillan, 1983; Corripio, 1990; Suda et al., 1992; Oquinnaike and Ray, 1994; Marlin, 2000; Wang and Cluett, 2000; Wang et a1.,2000; Quevedo and Escobet, 2000; Cominos and Munro,2002; Seborg et a1.,2004;O'Dwyer,2003; Choi and Chung, 2004; Michael and Moradi, 2005]. The books clearly show the need for a variety of techniques, simple tuning rules, as well as more elaborate procedures
222

6.10 Notes and References

that are based on process modeling, formulation of specifications, and control

design. Even if simple heuristic rules are used, it is important to realize that

they are not a substitute for insight and understanding. Successful controller

tuning cannot be done without knowledge about process modeling and control

theory. It is also necessary to be aware that there are many different types of

control problems and consequently many different design methods. To only use

one method is as dangerous as to only believe in empirical tuning rules. Control

problems can be specified in many different ways. A good review of different

ways to specify requirements on a control system is given in [Thuxal, 1955; Maciejowski, 1989; Boyd and Barratt, 1991].To formulate specifications it is

necessary to be aware of the factors that fundamentally limit the performance

of a control system.

The seminal papers [Ziegler and Nichols, 1942; Ziegler and Nichols, 1943] are the first attempts to develop systematic methods for tuning PID controllers.

An interesting perspective on these paper is given in an interview with Zieglery

see [Blickley, 1990]. The CHR-method, described in [Chien et aL, 1952], is a modification of the Ziegler-Nichols method. This is one of the first papers where

it is mentioned that different tuning methods are required for set-point re-

sponse and for load disturbance response. Good response to load disturbances

is often the relevant criterion in process control applications. Notice that the

responses can be tuned independently by having a controller that admits a

two-degree-of-freedom structure. The usefulness of a design parameter is also

mentioned in the CHR-paper. In spite of its shortcomings, the Ziegler-Nichols

method has been the foundation for many tuning methods; see [Tan and Weber, 1985;}'4.antz and Tacconi, 1989; Hang et al., 1991]. Ttrning charts were

presented in [Wills, 1962b; Wills, 1962a; Fox, 1979]. The loop-shaping methods were inspired by classical control design methods

basedon frequency response;see [Tbuxal, 1955j.Applications to PID control are
found in [Pessen, L954; Habel, 1980; Chen, 1989; Yuwana and Seborg, 1982]. The idea of algebraic design was presented in [T[uxal, 1955] and [Newton
et al., 1957]1as a systematic method of design to given specifications; a more

recent presentation is found in [Boyd and Barratt, 1991]. Algebraic design was

applied to processcontrol in [Smith,7957; Atherton, 1999; Hansen, 2000]. The

t

original papers on the 2-tuning method are [Dahlin, 1968] and [Higham, 1968].

I

The method is sometimes called the Dahlin method; see [Deshpande and Ash,

f

1981]. The method is very popular in the pulp and paper industry where it

has been used to develop standardized tuning procedures; see [SelI, 1995] and

[Anonymous, 1997]. Lambda tuning is closely related to the Smith predictor

and the internal model controller; see [Smith, 1957; Chien, 1988; Chien and

Fruehauf, 1990;Rivera et a1.,1986].The tuning techniques developedin [Smith

and Murrill, 1966; Pemberton, L972a; Pemberton, I972b; Smith et aI., 1975;

Hwang and Chang, 1987] are other examples of the analytical approach to

design. In [Rivera et a1.,1986]it was shown that internal model control reduces to PI and PID control when proper approximations of the time delay are done.

A novel algebraic design method, described in [Hansen, 2000; Hansen, 2003] is used in a PID controller developed by Foxboro. An interesting feature is that

the desired response is given as a high-order system.

The analytical tuning method gives controllers that cancel poles and zeros

Chapter 6. PID Design
in the transfer function of the process. This leads to lack of observability or controllability. There are severe drawbacks in this as has been pointed out many times, e.9., in [Chien and Fruehauf, 1990; Shinskey, 1991b; Morari and Lee, 19911.The response to load disturbances will be very sluggish for processes with lag dominated dynamics. A modification that does not cancel the process pole is given in [Chien and Fruehauf, 1990]. Skogestad's internal model controller is presented in [Skogestad,2003]. This controller avoids the cancellation by an ad hoc modification of integral time for lag dominated dynamics.
Many methods for control design are based on optimization techniques. This approach has the advantage that it captures many different aspects of the design problem. There is also powerful software that can be used. A general discussion of the use of optimization for control design is found in [Boyd and Barratt, 1991]. The papers [Rovira et al., 1969; Lopez et al., 1969] give controllers that are optimized with respect to the criteria ISE, IAE, and ITAE. Other applications to PID control are given in [Hazebroek and van der Waerden, 1950;Wolfe, 1951;Oldenburg and Sartorius,1954; van der Grinten, 1963; Lopez et al., L967; Marsili-Libelli, 1981; Yuwana and Sebory, 1982; Patwardhan et a1.,1987;Wong and Seborg, 1988;Polonoyi, 1989; Zhuang and Atherton, 19911.The methods BO and SO were introduced in [Kessler, 1958a; Kessler, 1958b1.A discussion of these methods with many examples is found in [Frdhr, 1967; Fr0hr and Orttenburger, 1982].
Pole placement is a straightforward algebraic design method much used in control engineering; see [Tluxal, 1955]. It has the advantage that the closedloop poles are specified directly. Many other design methods can also be interpreted as pole placement. The papers [Elgerd and Stephens, 1959; Graham and Lathrop, 19531show how many properties of the closed-loopsystem can be deduced from the closed-looppoles. This gives good guidance for choosing the suitable closed-looppoles. An early example of pole placement is [Cohen and Coon, 1953; Coon, 1956a; Coon, 1956b1.It may be difficult to choosedesired closed-loop poles for high-order systems. This is avoided by specifying only a few poles, as in the dominant pole design method described in [Persson, 1992; Persson and Astr<im, 1992; Persson and Astrdm, 1993].
The development of robust control was a major advance of control theory which made it possible to explicitly account for robustness in control design; see [Doyle et al., 1992; Horowitz, 1993; Green and Limebeer, 1995], [Skogestad and Postlethwaite, 1996; Zhou et al., 1996; Vinnicombe, 2000]. These ideas were applied to PID control in the papers [Panagopoulos et al., 1997 Astrcim et aL.,1998;Panagopoulosand Astr6m, 2000; Panagopoulos,2000; Kristensson, 20031.The method discussedin Section 6.8 are based on these papers.
There are comparatively few papers on PID controllers that consider the random nature of disturbances. The papers [van der Grinten, 1963; Goff, 1966a; Fertik, 19751are exceptions.
There are many papers on comparisons of control algorithms and tuning methods. The paper [McMillan, 1986] gives much sound advice; other useful papers are [Miller et al., 1967; Gerry, 1987; Gerry, 1999].
224

A Ziegler-Nichols Replacement
7,1 Introduction
Since PID controllers are so common it is useful to have simple tuning rules that can be applied to a wide range of processes.This is testified to by the longevity of the Ziegler-Nichols rules. They have been used for more than half a century even though they have severe drawbacks. In this chapter we present new tuning methods in the spirit of Ziegler and Nichols.
Control system design is a rich problem, as was discussed in Section 4.2. Any design problem should take account of load disturbances, measurement noise, robustness, and set-point following. When developing the simple rules we will follow the main ideas used by Ziegler and Nichols. We will thus focus on load disturbances by maximizing integral gain, but we will depart from Ziegler and Nichols by also adding a robustness constraint. In this chapter we have chosen to require that the joint sensitivity is larger than M : 1.4. Measurement noise is handled by detuning the controllers if the gains are too large, and set-point following is dealt with by set-point weighting.
The procedure we use is essentially the same as the one employed by Ziegler and Nichols. We will select a large batch of representative processes. This includes a wide variety of systems with essentially monotone step responses, which are typically encountered in processcontrol. Controllers for each process in the batch are then obtained by applying the MIGO design described in Section 6.8, which is based on the criteria given above. Having obtained the controller parameters we will then try to find correlations with normalized processparameters. The simple tuning rules obtained are called AMIGO, which stands for Approximate MIGO design.
The procedure shows that it is indeed possible to obtain simple tuning formulas. A major result is that it is necessaryto use more processinformation than used by Ziegler and Nichols. T\rning based on step responsescan be based on FOTD models. It is necessaryto use all three processparameters Kp, L, and 7 and not just two parameters a : KpL lT and L, as was suggested by Ziegler and Nichols. For PI control it is possible to obtain tuning rules that are closeto the optimal rules for the whole test batch. For PID control rules that are close to optimal can be obtained for balanced and delay-dominated processes.For
225

Chapter 7. A Ziegler-Nichols Replacement
lag-dominated processesit is necessary to have better process information. It is, however, possible to obtain efficient rules for balanced and delay dominant processes.
For the frequency response method where Ziegler and Nichols characterized the process by two parameters, Klse and ftss, we have shown that it is necessary to add a third parameter, e.9., the static gain Kr. Even with these parameters it is not possible to obtain rules that are close to optimal for all processesin the test batch. It is, however, possible to obtain conservative tuning rules both for PI and PID controllers.
The design method used can give high controller gains for processesthat are lag dominated. This may result in large variations in the control signal due to noise. In some cases,it may therefore be necessary to make a trade-off between attenuation of load disturbances and injection of measurement noise. This can be accomplished by detuning the controllers. Methods for doing this are also included in this chapter.
Analysis of all the controllers in the test batch has also given much insight into PI and PID control. It is shown that derivative action only gives moderate improvement for balanced and delay-dominated processes but that very large improvements can be obtained for lag-dominated processes.It is also shown that there is a wide range of processes where it is advantageous to have fr < 47a. Notice that controllers implemented on series form do not permit this. Nice formulas that give the ratio of the average residence time for open- and closedIoop systems are also given. This makes it possible to estimate the closed-loop response times that can be expected.
In the next section, the test batch is presented. Using this batch, AMIGO tuning rules based on step response experiments are derived for PI controllers in Section 7.3 and PID controllers in Section 7.4. AMIGO tuning rules based on frequency response experiments are presented in Section 7.5. More efficient tuning rules for PID control of lag-dominant processes can be obtained if a second order model is used. This is discussed in Section 7.6. In Section 7.7. the MIGO and AMIGO rules are compared for three different processes, one Iag-dominant, one balanced, and one delay dominant, respectively. Section 7.8 and Section 7.9 treat noise filtering and high-frequency gain reduction of the controllers by detuning.

7.2 TheTestBatch

PID control is not suitable for all processesI.n [Hagglund and Astr0m, 2002]it is suggestedthat the classof processews here PID is suitablecanbe characterized as having essentiallymonotonestep responsesO. ne way to characterize such processesis to introducethe monotonicityindex:

- - ff, g(t)dt ,tr ls(t)ldt

(7.1)

where g is the impulse response of the system. Systems with a - t have monotone step responses,and systems with a > 0.8 are considered essentially

226

7.2 The Test Batch

monotone. The tuning rules presented in this paper are derived using a test batch of essentially monotone processes.
The following 134 processeswere used to derive the tuning rules:

t

P- r (\ "s.)/:

'" -. 1+S?.

T - - 0 . 0 2 ,0 . 0 5 ,0 . 1 ,0 . 2 ,0 . 3 ,0 . 5 ,0 . 7 ,r ,

1 . 3 ,1 . 5 ,2 , 4 , 6 , 8 ,1 0 ,2 0 , 5 0 , 1 0 0 , 2 0 0 , 5 0 01,0 0 0 Pz(r): -- n " =-
1r+ sT)2' 7 : 0 . 0 1 , 0 . 0 2 , 0 . 0 05 ., 1 ,0 . 2 ,0 . 3 ,0 . 5 ,0 . 7 , 7 ,

1 . 3 ,1 . 5 ,2 , 4 , 6 , 8 ,1 0 ,2 0 , 5 0 , 1 0 0 , 2 0 0 , 5 0 0

P3(s): (s+1)(1+sr;z'

? : 0 . 0 0 50,. 0 10, . 0 20, . 0 50, . I , 0 . 2 , 0 . 5 , 2 ,150,

,1

&(t) :

, ls

+-

,r-]'"

n-3,4,5,6,7,8

P5(s) : ( 1 + s ) ( 1+ a s )( r + a 2 s ) ( 1+ a 3 s ) ' d : 0 . 7 - , 0 . 2 , 00. 3,4,, 0 . 5 , 0 . 60,. 7 0, . 8 0, . 9

P vo \( s/) -

t

s

(,

.l

*

s

"

r

=. )"

e-sLt.

L t : 0 . 0 1 , 0 . 0 2 , 0 . 0 5 , 0 . 1 , 0 . 3 , 0 . 5 , 0 1. 7. 0, 0, . T9 ,t * L r : I

(7.2)

P 'z\( r/): (, .1 + s ?= )3(-l + s ?=1 ,)e- - s L r , T yl L r - 1 ,

T : 1 , 2 , 5 , I 0 L t : 0 . 0 1 , 0 . 0 2 , 0 . 0 5 , 0 . 1 , 0 . 3 , 0 . 5 , 0 .17. ,00 . 9 ,

P- o"(\s, ). ,-,

1
!-

3!-.

(s+ f ;s,

d : 0 . I , 0 . 2 , 0 . 30, . 4 ,0 . 5 ,0 . 6 ,0 . 7 ,0 . 8 ,0 . 9 ,1 . 0 ,1 . 1

-Pus\(-s/) ( s + 1 ) ( ( t " ) ' * l ' A s T + 1 ) ' T - 0 . r , 0 . 2 , 0 . 3 , 0 . 40,. 5 ,0 . 6 ,0 . 7 ,0 . 8 ,0 . 9 ,1 . 0 .

The processesare representative for many of the processesencountered in process control. The test batch includes both delay-dominated, lag-dominated, and integrating processes.AII processeshave monotone step responses except Ps and Pe. The parameters range for processes Ps and Pe are chosen so that the systems are essentially monotone with a > 0.8. The normalized time delay ranges from 0 to 1 for the process P1 but only from 0.14 to 1 for P2. Process P6 is integrating, and therefore x - 0. The rest of the processes have values of c intherange0<c<0.5.

227

Chapter 7. A Ziegler-Nichols Replacement

7.3 PlControl

The processesin test batch (7.2) are first approximatedby the simple FOTD

model

P(:s,f)u{"

(7.3)

where Ko is the static gain, T the time constant (also called lag), and Z the time delay. Processeswith integration are approximated by the model

P(s:) ?n-'"

(7.4)

where K, is the velocity gain and L the time delay. The model Q.a) can be regarded as the limit of (7.3) as K, and ? go to infinity in such a way that Kolf - K, is constant. The parameters of (7.3) and (7.a) can be determined from a step response experiments using the methods presented in Section 2.7.
The tuning rules were obtained in the following way. The MIGO design method (see Section 6.8) with M - 1.4 was applied to all processesin the test batch (7.2). This gave the PI controller parameters K andT;. The AMIGO rules were then obtained by finding relations between the controller parameters and the process parameters.
Figure 7.1 illustrates the relations between the controller parameters and the process parameters for all processesin the test batch. The controller gain is normalized by multiplying it either with the static process gain Ko or with the parameter a: KpLIT : KuL. The integral time is normalized by dividing it by T or by L.The parameters for the integrating processes P6 are only normalized with o and L since Ko and T are infinite for these processes.The controller parameters in Figure 7.1 are plotted versus the normalized dead
time r:LlQ+f). The figure shows that there is a good correlation between the normalized
controller parameters and normalized time delay. This indicates that it is possible to develop good tuning rules based on the FOTD model. Notice, however, that there are significant variations in the parameters with the normalized
time delay r. Ziegler and Nichols tried to find rules that do not depend on r. Figure 7.1
shows that the normalized parameters K Kp, aK , Ti f T , and Ti I L vary as much as two orders of magnitude with e. It is thus not possible to find efficient rules
that do not depend on r. The solid lines in Figure 7.1 correspond to the AMIGO tuning formula,

"--V+(oss-#ry);e

(7.5)

Ti -

0.35L+

13LT2 T2+12LT+7L2'

and the dotted lines show the limits for 15 percent variations in the controller parameters. Almost all processesincluded in the test batch fall within these limits.

228

KKo vs t 102 10t 100 10-1
0.2 0.4 0.6 0.8 T;fTvsr
102
100

7.3 PI Control
aKvst
101
100
s-P
_1
10 0.2 0.4 0.6 0.8 T;fLvsr
101
100

100.2 0.4 0.6 0.8

_1
10 0.2 0.4 0.6 0.8

Figure 7.1 Normalized PI controller parameters plotted versus normalized time delay r. The solid lines correspond to the AMIGO design rule (7.5), and the dotted lines indicate 15 percent parameter variations. The circles mark parameters obtained from process P1, and squares parameters obtained from process P2.

For integrating processes,Ko and T go to infinity and KrlT - Ku. Therefore, the AMIGO tuning rules (7.5) can be simplified to

n: 0.35 KrL
Ti : I3-4L-

(7.6)

for integrating processes.
The tuning rule (7.5) can be seen as a replacement for the Ziegler-Nichols' step response method for PI control. Notice that the rule was designed for the sensitivity M : 1.4. Similar rules can be found for other values of the design parameter.

Set-Point Weighting
The MIGO design method also gives suitable values of b. It is determined so that the resonance peak of the transfer function between set point and process rrutput becomesclose to one, as discussedin Section 5.3. Figurc 7.2 shows the values of the b-parameter for the test batch (7.2).

229

Chapter 7. A Ziegler-Nichols Replacement

bvsr

0.8 0. 0 .4 0.2

x x rSF<*l A x&(E x) E

E8

xxX
a

aaxa

* "X

x- x x

XX

XX X

x x<x XEAA XXx x

0.1

0.2

0.3

0.4

NF

0.6

0.7

0.8

a8E6
0.9

Figure 7.2 Set-point weighting as a function of c for the test batch (7.2). The circles mark parameters obtained from the process P1, and the squares mark parameters obtained from the process P2.

Figure 7.2 shows that the correlation with parameter t is not as good as for the feedback parameters and that there is a larger difference between the pure FOTD model P1 and the other processes.The set-point weight should be b : L for processeswith t > 0.3.

7.4 PIDControl
Figure 7.3 illustrates the relations between the PID controller parameters obtained from the MIGO design and the process parameters for all processes in the test batch. The robustness criterion fu[ - 1.4 is used together with the additional constraint }kil0k:0; see Section 6.8. The normalized controller parameters in Figure 7.3 arc plotted versus the normalized dead time r.
The figure indicates that the variations of the normalized controller parameters are several orders of magnitude. We can thus conclude that it is not possible to find good universal tuning rules that do not depend on the normalized time delay c. Recall that Ziegler and Nichols suggested the rules aK - L.2, T; - 2L, and Ta : 0.5L. Figure 7.3 shows that these parameters are only suitable for very few processes in the test batch.
The controller parameters for processes P1 are marked with circles and those for P2 are marked with squares in Figure 7.3. For t < 0.5, the gains for P1 are typically smaller than for the other processes, and the integral time is larger. This is the opposite to what happened for PI control; see Figure 7.L. Process P2 has a gain that is larger and an integral time that is shorter than for the other processes.
For PI control, it was possible to obtain simple tuning rules, where the controller parameters obtained from the AMIGO rules differed less than 15 percent from those obtained from the MIGO rules for most processesin the test batch. Figure 7.3 indicates that universal tuning rules for PID control can be obtained only for t > 0.5.
For e < 0.5 there is a significant spread of the normalized parameters. This
230

7.4 PID Control

100

KK vst

102

100

a8 I @g

0.2 0.4 0.6 0.8 TilT vs c
102

a

102 101 100

xxE
x"E .X.ab
X1

aK V S ? xo E ffi@a

0.2 0.4 0.6 0.8 T;fLvsr
101

100

100

a8 e @6

0.2 0.4 0.6 0.8 T6lT vs t

100

E8 E M@

1 0-

10-o 0.2 0.4 0.6 0.8

1 0_ 1
0.2 0.4 0.6 0.8 TalL vs r

100
1g- X "a &3%*e B qsI

10-' E @

&

0.2 0.4 0.6 0.8

Figure 7.3 Normalized PID controller parameters as a function of the normalized time delay r. The controllers for the process P1 are marked with o and controllers for P2 with

implies that it is not possible to find universal tuning rules for lag-dominated processes.Notice that the gain and the integral time are well defined for 0.3 < r < 0.5 but that there is a considerable variation of the normalized derivative time in that interval.
Because of the large spread in parameter values for t < 0.5 it is worthwhile to model the process more accurately to obtain good tuning of PID controllers. The process models (7.3) and (7.a) model stable processeswith three parameters and integrating processeswith two parameters. In practice, it is very difficult to obtain more processparameters from the simple step response experiment. A step response experiment is thus not sufficient to tune PID controllers with r < 0.5 accurately.
However, it is possible to find conseruotiue tttntng rules for t < 0.5 by choosing controllers with parameters that correspond to the lowest gains and the largest integral times of Figure 7.3. Before developing such rules, we will discuss the reason why universal tuning rules for lag-dominant processescannot be found.
231

Chapter 7. A Ziegler-Nichols Replacement

Problemswith FODTStructure
The criterion used is to maximtze integral gain k;.Tt'e fundamental limitations are given by the true time delay of the process, which we denote 26. The integral gain is proportional to the gain crossover frequency os, of the closedloop system. The gain crossover frequency os, is typically limited to

{Dn"Lo< 0.5.

When a process is approximated by the FOTD model the apparent time

delay 1, is longer than the true time delay Zs because lags are approximated

by additional time delays. This implies that the integral gain obtained for the

FOTD model will be lower than for a design based on the true model. The

situation is particularly pronounced for systems with small r.

Consider PI control of first-order systems, i.e., processeswith the transfer

functions

P(s-)1;ft {o, K u or P(s-)-:

Since these systems do not have time delays there is no dynamics limitation, and arbitrarily high integral gain can be obtained. Since these processescan be matched perfectly by the models (7.3) and (7.4), the design rule reflects this property. The process parameters are L : 0, a : 0, and r : 0, and both the design method MIGO and the approximate AMIGO rule (7.5) give infinite integral gains.
Consider PID control of second-order svstems with the transfer functions

P(s): fr*'

and P(s):

K

( 1 + s ? r ) ( 1+ s " 2 ) '

Since the systems does not have time delays it is possible to have controllers with arbitrarily high integral gains. The first transfer function has c - 0. The secondprocesshas values of r in the range 0 { r < 0.13, where r:0.13 correspondsto Tt :72. When these transfer functions are approximated with a FOTD model one of the time constants will be approximated with a time delay. Since the approximating model has a time delay there will be limitations in the integral gain.
We can thus conclude that for t < 0.13 there are processesin the test batch that permit infinitely large integral gains. This explains the wide spread of controller parameters for small r. The spread is infinitely large for t < 0.13, and it decreases for larger e. Therefore, for small r improved modeling gives a significant benefit.
One way to avoid the difficulty is to use a more complicated model, such as

P(s) :

*'?t

u
S'

u- t

:

t
0.f

t

e-'1.
a2

It is, however, very difficult to estimate the parameters of this model accurately from a simple step response experiment. Design rules for models having five

232

rS r-).
l.l
aq
itv.
in
.tch lof ,13. esa 'h as
ratelY ,g five

7.4 PID Control

parameters may also be cumbersome. Since the problem occurs for small values of t it may be possible to approximate the process with
P(s:)*+r" -'1,
which only has three parameters. Instead of developing tuning rules for more complicated models it may be better to simply compute the controller parameters based on the estimated model.
ConservativTeuningRules(AMIGO)
Figure 7.3 shows that it is not possible to find optimal tuning rules for PID controllers that are based on the simple process models (7.3) or Q.a). It is, however, possible to find conservative robust tuning rules with lower performance. The rules are close to the MIGO design for the process P1, i.e., the processthat gives the lowest controller gain and the longest integral time; see Figure 7.3.
The suggestedAMIGO tuning rules for PID controllers are
K:+(or*r*T)

mt ' : - T0+.a4lLT+ 0 . 8 7u,

(7.7)

Ta: O.\LT 0.3L+ T
For integrating processes,Equation 7.7 can be written as
K - 0.451K,
Ti :8L Ta:0.5L.

(7.8)

Figure 7.4 comparesthe tuning rule (7.7) with the controller parameters given in Figure 7.3. The tuning rule (7.7) describes the controller gain K well for a processwith r > 0.3. For small r, the controller gain is well fitted to processes P1, but the AMIGO rule underestimates the gain for other processes.
The integral time 4 is well described by the tuning rule (7.7) for r > 0.2. For small c, the integral time is well fltted to processesP1, but the AMIGO rule overestimates it for other processes.
The tuning rule (7.7) describesthe derivative time Q well for processwith r > 0.5. In the range 0.3 < t < 0.5 the derivative time can be up to a factor of 2 larger than the value given by the AMIGO rule. If the values of the derivative time for the AMIGO rule are used in this range the robustness is decreased; the value of M may be reduced by about 15 percent. For r < 0.3, the AMIGO tuning rule gives a derivative time that sometimes is shorter and sometimes longer than the one obtained by MIGO. Despite this, it appears that AMIGO gives a conservative tuning for all processesin the test batch, mainly because of the decreasedcontroller gain and increased integral time.
The tuning rule (7.7) has the same structure as the Cohen-Coon method, but the parameters differ significantly.

233

Chapter 7. A Ziegler-Nichols Replacement

KKo vs t

aKvsr

1.5 0.5

X

xF x

r

XF

8k

Xy XX

>B

0.2 0.4 0.6 0.8 TifT vsr
0.2 0.4 0.6 0.8 TafT vsr
u.z 0.4 0.6 0.8

0.4 0.6 0.8 T;fLvsr

X\ X xX
3
X1
"E
X X
X
"E X

x" "

x

tE
E

E

0

1.4

0.4 0.6 T6lLvst

1.2

i##

i* :.%-* 0.8 it ".X.
0.6

0.

qgxa
' ' xX

- q . t c r . r g ._g 8 .

0 . 2 x x Ea

a

0 0.2 0.4 0.6 0.8

Figure 7.4 Normalized controller parameters as a function of normalized time delay r. The solid line corresponds to the tuning rule (7.7), and the dotted lines indicate 15 percent parameter variations. The circles mark parameters obtained from the process P1, and the squares mark parameters obtained from the process P2.

Robustness
Figure 7.5 shows the Nyquist curyes of the loop transfer functions obtained when the processesin the test batch (7.2) are controlled with the PID controllers tuned with the conservative AMIGO rule (7.7). When using MIGO all Nyquist curves are outside the M -circle. With AMIGO there are some processeswhere the Nyquist curves are inside the circle. An investigation shows that the derivative action is too small in these cases; compare with the curves of T6l L vs t in Figure 7.4. The increase of M is at most about 15 percent
234

7.4 PID Control

Figure 7.5 Nyquist curves of loop transfer functions obtained when PID controllers tuned according to (7.7) are applied to the test batch (7.2). The solid circle corresponds M : I.4, and the dashed to a circle where M is increased by 15 percent.
bvsr
a8
0.8

a

0.4

Fer,
t""ta

0.2

X
* r8

.^.^x

A A x Ex

a9

x xx< xG[Ka XDaxKxx8lcrt E x)S<x x

0.1 0.2 0.3

0.4

0.5

u.o

0.7

0.8

0.9

Figure 7.6 Set-point weighting as a function of z for the test batch (7.2). The circles mark parameters obtained from the process P1, and the squares mark parameters obtained from the process P2.

with the AMIGO rule. If this increase is not acceptable derivative action can be increased or the gain can be decreasedwith about 15 percent.

Set-Point Weighting
Figure 7.6 shows the values of the b-parameter for the test batch (7.2). The correlation between 6 and r is not so good, but a conservative and
simple rule is to chooseb as

fO.
b:1
| .1 .

forr<0.5 for r > 0.5.

(7.e)

235

Chapter 7. A Ziegler-Nichols Replacement kilPlDllki[P/] vs r
t
10-

;X

'"t

'q

101

x x

X

NX xx

X - '"li:os

-e-[J;* ;- a -5?"'b,.ux*-6 E-s a6

100

u.z

0.3

0.4

u.c

u.o

0.7 0.8

no

Figure 7.7 The ratio of integral gain with PID and PI control as a function of normalized

time delay r. The dashed line correspondsto the ratio kiIPID)lki[PI]:2.

The controllers

for the process P1 are marked with circles and controllers for P2 with squares.

The Benefits of Derivative Action
Since maximization of integral gain was chosen as design criterion we can judge the benefits of derivative action by the ratio of integral gain for PID and PI control. Figure 7.7 shows this ratio for the test batch, except for a few processeswith a high ratio at small values of r.
The figure shows that the benefits of derivative action are marginal for delay-dominated processesbut that the benefits increase with decreasing r. For c : 0.5 the integral gain can be doubled, and for values of r < 0.15 integral gain can be increased arbitrarily for some processes.

The Ratio TilTd

The ratio TilTa is of interest for several reasons. It is a measure of the relative importance of derivative and integral action. Many PID controllers are implemented in series form, which requires that the ratio be larger than 4. Many classical tuning rules therefore fix the ratio to 4. Figure 7.8 shows the ratio for the full test batch. The figure shows that there is a significant variation in the ratio TilTa, particularly for small r. The ratio is close to 2 for 0.b < r < 0.9, and it increases to infinity as t approaches 1 because the derivative action is zero for processeswith pure time delay.

Figure 7.8 also shows the ratio obtained by the AMIGO tuning rule (7.7).

T

The ratio is less than four for processes with 0.3 < r < 0.g, which means

T

that the tuning rule cannot be used for controllers in series form for these

p(

processes.However, it appears that the changes of performance and robustness

th

are marginal if the tuning rule (7.7) is modified so thatT6 - Til4for these

sir

processes.Figure 7.9 shows the Nyquist curves of the loop transfer functions

To

obtained when the processesin the test batch with 0.3 < t < 0.9 are tuned such

sy

that gain K and integral time Ti are obtained from (7.7), and the derivative

th,

time is obtained as Td: Til4. The figure shows that the robustness is about

the same as for (7.7); compare with Figure 7.5.

clo

236

Tif Ta vs r

7.4 PID Control

101

100

0.2 0.3 0.4

0.5

u.o

0.7

0.8

0.9

Figure 7.8 The ratio between ?; and T4 as a function of normalized time delay r. Process P1 is marked with circles and process P2 with squares. The dashed line corresponds to the ratio TilTa:4, and the solid line to the ratio given by the AMIGO tuning rule (7.7).

cl

-3

-2.5

1

Figure 7.9 Nyquist curves of the loop transfer functions obtained from the processes in the test batch with 0.3 < t < 0.9 when the controller is tuned with Ta: Til4.

The Average Residence Time The parameter ?63,which is the time when the step response has reached 63 percent, a factor of (1- t I ,), of its steady-state value, is a reasonable measure of the response time for stable systems. It is easy to determine the parameter by simulation, but not by analytical calculations. For the FOTD process we have Tor: ?os. The average residence time To, is in fact a good estimate of ?63 for systems with essentially monotone step response. For all stable processesin the test batch we have 0.99 < TsslT", < 1.08.
The average residence time is easy to compute analytically. Consider the closed-loopsystem obtained when a processwith transfer function P(s) is con-
237

Chapter 7. A Ziegler-Nichols Replacement

PI
J

2.5
z
;\L
tF-\1- . 5

- - ;hs' m6 o- @ @
sT+D
**#ff;p
#fl**

F-1

{+r A+-

*'' 6

0.5 p

2.5
2
^:L
-F:-1i- 6 r
1
0.5

u.z 0.4 0.6 0.8
f7

u.1.

0.4

tt h

0.8

Figure 7.10 The ratio of the average residence time of the closed loop system and the open loop system for PI control Ieft and PID control right.

trolled with a PID controller with set-point weighting. The closed-loop transfer function from set point to output is

u, .

!,

!

"

0,

(\s

/

:

1

P(s)C +pG)

ry(s) r C G )'

where

crr({ : bK* L s

Straightforward but tedious calculations give

ro,: *#:r,(r- b+trn)

(7.10)

Figure 7.10 shows the average residence times of the closed-loopsystem divided with the average residence time of the open-loop system. Figure 7.10 shows that for PID control the closed-loopsystem is faster than the open-loop system when t < 0.3 and slower for t > 0.3.

7,5 FrequencyResponseMethods

In this section we will investigate if it is possible to obtain simple tuning rules similar to the Ziegler-Nichols frequency response method.

Parameterization

,

Ziegler-Nichols characterized the processesby two parameters K1s6 and ftss when they developed their frequency response method for controller tuning. The Ziegler-Nichols tuning rules do not use sufficient information, and they give too aggressive tuning, which does not give robust closed-loop systems.

238

7.5 Frequency Response Methods

KK1s6 vs ,r 0.2

^x
0 . 15

'a

[."ryr*

Y "- 6a*{^^

n if^

0.05

T;f T13svs

o.4 0.6 0.8

0.4 0.6 0.8

Figure 7.11 Normalized controller parameters plotted versus gain ratio r for stable processesfor M :1.4. The solid lines correspond to the tuning rule (7.11), and the dotted lines indicate 15 percent variations from the rule. The circles mark data from process P1,
and squares data from P2.

When investigating the step response method it was found that significant improvement could be obtained by including an additional third process parameter, the static process gain. In this section it will be investigated if similar improvements can be obtained for the frequency domain method.
For the step response method we used the normalized time delay r as a parameter to characterize the process. The corresponding frequency domain parameter is the gain ratio K : K11;ljKoo.

Pl Tuning Rules for Balanced and Delay-Dominated Processes

The MIGO design method has been applied to aII processesin the test batch (7.2). Figure 7.11 shows the controller parameters obtained for M - 1.4. The

figure shows that there is a significant spread of controller parameters for

lag-dominant processes. The Ziegler-Nichols tuning rules have constant values KKno - 0.4 and

TilTu,o:0.8, for all values of tc.Figure 7.11 shows that it may be reasonable

to have a constant value K Kfio for rc> 0.5, but not for smaller values of r. The

gain K K180: 0.4 suggested by Ziegler and Nichols is clearly too high, which

explains the poor robustness of their method. The integral time suggested by Zregler and Nichols, fi - 0.8?ras, is too high except for processeswith very

small values of rc.

Figure 7.11 shows that it is not possible to capture all data by one tuning

rule. It may, however, be possible to obtain a rule for balanced and delay-

dominated processes.Figure 7.LI shows the graphs corresponding to the fol-

lowing tuning rule.

KK1p,o: 0.16

Ti1

(7.11)

?*: l+4,5K

The tuning rule (7.11) is not appropriate for lag-dominant processes,but it gives controller parameters that are fairly close to the optimal for processes with K > 0.2. Notice in particular that the ratio TilT1p1ois reduced by a factor

239

Chapter 7. A Ziegler-Nichols Replacement

I

I

__l

0

0.5

ifaF"u'ci*ngci luctottrr"ieodni ns7g'c1to2cororr(er7Nes'spy1pqo1oun) nidsaditnrsegctuotaor vpMeppsrl io:eocdfe1lso't4sooepapsntwrrdoai tncthhesefse0srd.e1asfsu<ihnnecr (dttih<oteno0sa.t 2eocsbiatrt carbclienasehtwcdohhwwenwrheeiwtnhMi tphrIi sdc>ooi nntctte0rreod. 1al ll.sei nerTsedbsatb.unynTseh1f ede5r

of three when r increases from 0.2 to 1.

ba all

Figure tch with loop tra

n7Ks'1f>2ers0hf'u1onwwcshtieothnnesthNaeyreqfuucnilsoitnsgecutroruvlteehse(o7bM.1ta-1ci)nftiecsdreuf.soerda.ltlilp" roncgers.seessihnotwhse

test that

PIDTuningRuresfor BarancedandDeray-Dominatepdrocesses

Parameters of PID computed using the

controllers for MIGo design

all t with

he processesin the constraints

section.The design parameter was chosento M :1.4.

the test batch describedin th

(7.z)were e previous

Figure 7'13 illustrates the tained from the MIGo design
the test batch.

relations between the controller and the process parameters for

parameters oball processesin

pgitfshoaroorilnacsTPreehlgtsheefisaosretc'rstoTyPi.nsph2tiirclsaoaarlrlliegelsyermor sppamaaprnkroaadeslmldietaeernwttteohiitrnahswtnehfsgofaqroraturlp_ahrtrathoeipmecspeeoiesntnshteehFeasdiifgtPriuoo1ircrseeapsrs2eIhs.eo1cmsrgot,ae.nrrFtkaroeonthrdld.arnptwhr<ieotfohcire0ns.ctm8esir,gocptrslh2aetelsho,tagtiahmsaneienard

TNgeohtiecoerThdsrhouuaelnlsreiefvsi geimusrugsoriagernleedisnittcuhtdaenai ctdinentahdgtaeenbsruyrotulhertldahseetetrKht hdoaKeaft1smvdghaao0erg-dinanolti0iittnou.de6ndess,eTp.feoiulTnfThJtnrheseoeroone"nf"-toohrree0m7,.g.a5riatl8,iizn.iasenTrdnadhotc,eitToi pn6zrotifcreTso.gsllzellieebioerrl:ge-0Nplte.aoi1rcrh2faaionmnbldd.s-

240

KK

VSK

0.2 0.4 u.o 0.8 TifT$svsr
roo

7.5 Frequency ResporuseMethods
KK VSK
X
x^ E
{,f6
mX ! X
ft
*.) X
X
0.2 0.4 0.6 0.8

't
,re rus
ob'in
rlnd Iain lme asa ther
ram' find r and t.I25. rchols

0.2 0.4 0.6 0.8
Figure 7.13 Normalized PID controller parameters as a function of the gain ratio r. Parameters obtained for process P1 are marked with circles, and parameters obtained for process P2 with squares. The dashed lines indicate Ziegler-Nichols' tuning rule and the solid lines corresponds to the rule (7.12).

rule is only suitable for very few processesin the test batch. The controller gain is too high except for some processeswith very small values of r.
Even if Figure 7.13 indicates that it is not possible capture all data by one tuning rule it is clear that a good tuning rule can be found for balanced and delay-dominated processes.Figure 7.13 shows the graphs corresponding to the following tuning rule as solid lines.

K : (0.3- o.bc4l)Krao
mt i : 0 ' 6 I*2*tteo
mr d : 0 . 1 5 ( I - K ) ,r-r s o . 1_6195"

(7.12)

The tuning rule (7.12) is not appropriate for lag-dominant processes,but it gives controller parameters that are fairly close to the optimal for processes with K > 0.2. Figure 7.14 shows the Nyquist curves obtained for all processes in the test batch with K > 0.1 when the tuning rule (7.12) is used. The figure shows that all loop transfer functions remain fairly close to the M -circ\e.

247

Chapter 7. A Ziegler-Nichols Replacement
Figure 7.14 Nyquist curves of loop transfer functions obtained when PID controllers tuned according to (7.I2) are applied to processes in the test batch with r > 0.1. Tbansfer functions corresponding to processes with 0.1 < /r < 0.2 are shown with dotted lines. The solid circle corresponds to M - 1.4, and the dashed to a circle where M is increased bv 15 percent.
7.6 PIDControlBasedon Second-OrdeMr odel
In this section, tuning rules based on the SOTD model (2.47) are presented. The SOTD model may be obtained using the combined step and frequency response method presented in Section 2.7.
Figure 7.15 shows controller parameters K, ki: KlTi, and k6 -- KTa for all processesin the test batch except the integrating process, plotted against the normalized time delay rt: LtlTus. Figures 7.16 shows the controller parameters 4 and ?a with different normalizations. Notice that the scales are also different. A comparison with Figure 7.3, where the simpler FOTD model is used, shows a significant improvement, particularly for small normalized time delays. This is not surprising because the achievable performance is primarily given by the time delay, and the improvement is mainly due to improved estimates of the true time delay.
The figures show that there is a considerable span of the parameter values. In Figure 7.15 the parameters KLllTuu, kiTas, and k;L1 ranse over two decades.The range of variation is larger for other normalizations; for example, the parameter KKo ranges over five decades.Also notice that there is a spread in the values, particularly in ka and ?a. This means that we cannot expect to find nice formulas where the normalized parameters are functions only of c1.
242

I
l.
).
)r
St are
:-
t5
ne 1r'ed
'ai.wo pl", ead tto
r1.

7.6 PID Control Based on Second-Order Model

KoK 1oo

K LrlT63 1ot

10"

1oo

@eoeeg @
0.2 0.4 0.6 NA hiTas

1oo 10

A- $^e E O a

-

0.2 0.4 0.6 0.8 kiLt

10' 100 102

oBoEoe @ 0.2 0.4 0.6 0.8
kalres

100

q7H$fr a .yH tU

0

0.2 0.4 0.6 0.8

1

1oo

_H

^

m

A

E

A

-U

-

'10-t
102 100 1 0_2-
0

0.2 0.4 0.6 0.8 h a lL t

O t s O E O a* e

0.2 0.4 0.6 0.8

1

Figure 7.15 Normalized controller parameters K, ki, and ka for the processes in the test batch plotted versus cl.Data for the processesP1 are marked with circles, and those for P2 with squares.

Structureof TuningFormulas
To get insight into suitable parameterizations we will consider some special systems.
For delay-dominated processeswhere Lt 2 Tr ) T2 the model (2.47) can be approximated by
P(s) - Koe-'L,.
Derivative action cannot be used for this process.Designing a PI controller for the processwe find

c ( s )- K + L - 0 ' 1 6 7 7 + o a 6 l 8 .

s

Kp

sLlKr'

where the numerical values are given for design with M - 1.4. Neglecting the
time delay and using the numerical values of the controller parameters we find that the closed-loopsystem is of first order with the pole sLr - -0.4.
If the process dynamics is a time delay with a small lag,

K P(s) : --llP -r-'L
l+sl

243

Chapter 7. A Ziegler-Nichols Replacement
TilTas
100

TalTas @EOBo@ e

0.4 0.6 TilLt
101

10-o

0.2 0.4 0.6 0.8 T a lL t

100

@EO- ^
vH^

10-1

0

0.2 0.4 0.6 0.8

1

100
1 00

sEom

V

V!!

^

A

A

VH

e H

0.2 0.4 0.6 0.8

1

Figure 7.16 Normalized controller parameters Z; and Ta for the processes in the test batch plotted versus r1. Data for the processesP1 is marked with circles, and those for P,) with squares.

we find that the loop transfer functions under PID control with derivative gain

k6 approaches

G'

1"

(

s

=/

-

k f

a

K

o

e

_" ".

'.r

The Nyquist curve of this transfer function is a circle around the origin with

radius k6KolT. The design criterion using the combined sensitivity requires

that the radius is less than (M - l) I M .The largest permissible derivative gain

is thus

k,:l M-'

KpM

For delay-dominated processesthe derivative time is thus proportional to the 1ag.

The PID controller for the process

t{
P(s)- Ze-'Lt

is

L^,( s\ l- ^ f*7; r kl4eis : 1

0.46037
Koh -

0

.0
,I

5941
+L?

?

*

U0

.

1

?

g

6

s

?

where the numerical values are given for design with M - 1.4. Neglecting the
time delay and using the numerical values of the controller parameters we find that the closedloop system is of secondorder with the polesstrt - _,0.2t0.11l;
the dominant pole is thus @a:0.2.

The PID controller for the process

p ( s ): &_*Lt

244

is
w ti tl sl Pi Br he
Th
por the ma int thi T1 oft Fin Its
The
ESS
isa for 1 the pari
lnte
To ir inve

7.6 PID Control Basedon Second-OrdeMr odel

is

c ( s ):

K +4
s

*

k

a-so

o

'

!rn?
KrLl

T

,

'

"+

0

'

001?
KoLls

!

?

r

rnr' 20

3!{z
KrL,

s

.

where the numerical values are given for design with M - 1.4. Neglecting the
time delay and using the numerical values of the controller parameters we find that the closed-loop system is of third order with the poles sLt - -0.23 and sLt - 0.035+0.064i; the dominant pole is thus o)d:0.07.

Parameterization
Based on the special casesgiven above it is reasonable to try tuning formulas having the form

K o K- & 1 ta z T . " r 7 t a a T

K

o

k

,

:F

r

1
^

+

P, 7r1i +,

0t ) '7q2 ,*

Pa T^t T-z; t

(7.13)

Krko: (rrL,* TzT*tysT+zy^T)#+;.,

This will match the controllers for the special cases. The coefficients of proportional and integral gain are simply obtained by adding the coefficients for the prototype processes.Because of the structure of the formula this will automatically give an interpolation between processeswith pure delay and double integrator with delay. This procedure will not work for the derivative gain. In this case we have simply taken the weighted average with weights Z1 and Tt -l Tz.
Making a least squares fit of the parameters in (7.13) using the parameters of the test batch gives the results in Table 7.1.

Final Parameters It seems reasonable to make the following approximations.

A 1 : 0 . 1 9 d z : 0 . 3 7 6 y e: 0 . 1 8 a + : 0 . 0 2

F,: 0.48 Fz : 0.03 F, : -0.0007 Fn:0.0012

Tt - 0.29 Tz:0.16 Ts:0.20

T+:0.28.

(7.r4)

The parameters Bs and Ba arc quite small. This means that integral gain is essentially determined by parameters Kp, ft, and 21. This explains why there is a good correlation in the data for integral gain in Figure 7.75. The correlation
for proportional gain in Figure 7.15 is good but not as good as for ft;, because the parameters d3 and d4 a;telarger. The correlation is poor for ka because
parameterc Te and ya are large.

Integrating Processes
To investigate that the formulas also work for integrating processes we will investigate the process Po. A model for integrating processescan be obtained

245

Chapter 7. A Ziegler-Nichols Replacement

Table 7.1 Parameters fitted to the tuning formula for different data sets; Pt denotes all processes except the integrating process P6.

Par

Pr

P2

Pr, Pz

Pr

e-s

e-'ls

n-sfs2

d1 0.1755 0.1815 d,2 0.4649 -0.0215

ds

0

0.6816

da

0

0.0210

0.1823 0.4607 0.0930 0.0211

0.1903 0.t677 0.3698 0.L777 0.0196

0.4603

0.02140

F, 0.5062 0.4613 F, 0.0587 -0.2028

fuo

0.2877

Fno

0.0013

0.4800 0.0596 -0.0367
0.0013

0.4767 0.4618

0.0310 -

0.05841

0.0017

0.0012

0.001218

Tr 0.3026 Tz 0.1805 Ts0 Tt0

0.2864 0.0590 0.2464 0.3090

0.297r 0.1814 0.0814 0.3096

0.2918 0.1654 0.2033 0.2772

0.1796 0.3

by taking the limit of

P(s):

Kp

(1+

s " r ) ( 1+

e-sLt'
s72)

as Kp and ft goes to infinity in such a way thab KolTr: becomes
P(s:) fi?*;*L.
The tuning formula (7.13) becomes

K,. The model then

KuK :

lTz

G2 L,

+ "^q

K

,

k

i

:

F

z^ 7

1 Z+

p

4^rTt

z

"1

ul

T Krka:Tzly^;

(7.15)

Validation
Figure 7.17 shows the Nyquist curves of the loop transfer functions obtained when the processesin the test batch (7.2) are controlled with the PID controllers tuned with the rules (7.13), (7.15), and (7.la). When using MIGO all Nyquist curves are outside the M-circle in the figure. With the approximative rule there are some processeswhere the Nyquist curves are inside the circle. The increase of M is, however, less than 15 percent for all processesin the test batch.

246

7.7 Comparison of the Methods
Figure 7.17 Nyquist curves of loop transfer functions obtained when PID controllers tuned according to (7.13), (7.15), and (7.1a) are applied to the test batch (7.2). The solid circle corresponds M : I.4, and the dashed to a circle where M is increased by 15 percent.
7.7 Comparisonof the Methods
This section presents a few examples that illustrate the AMIGO method and compares it with the MIGO designs for PI and PID controllers. Three examples are given, one with a lag-dominant process,one with a delay-dominant process, and one with a process with balanced lag and delay. Exaupln 7.l-Lac-DouwerED DyNAMrcs Consider a process with the transfer function
P ( s ) - ( 1 + s ) ( 1+ 0 . 1 s ) (+1 0 . 0 l s ) ( 1 +0 . 0 0 l s ) ' Fitting the model (7.3) to the process we find that the apparent time delay and time constants are L : 0.075 and T - I.04, which gives t : 0.067. The dynamics are thus lag dominated. The corresponding frequency response data needed for the AMIGO design are Klss - 0.0091 and ?rso - 0.199. Since the static gain is Ko : 1, the gain ratio becomes K : KBolKp :0.0091. Since the process is lag dominant with r < 0.1, the AMIGO rules based on frequency response data cannot be used for this process. Fitting the second-order model ( 2 . 4 7 )g i v e st h e p a r a m e t e r sT r : 0 . 9 8 0 , T z : 0 . 1 0 8 , a n d - L 1: 0 . 0 1 0 .
The controller parameters obtained from the MIGO and AMIGO tuning rules are presented in Table 7.2.
Figure 7.18 shows the responses of the system to changes in set point and Ioad disturbances when the controllers are tuned with the MIGO and AMIGO design. The figure shows that the AMIGO rule gives responses that are close
247

Chapter 7. A Ziegler-Nichols Replacement

Table 7.2 Controller parameters obtained from the MIGO and AMIGO tuning rules for the lag-dominant processin Example 7.1.

Controller PI
PID

Design

T;

T6

kt

MIGO AMIGO-step

3.56 0.660 4.L3 0.539

0 5.39 0 7.66

MIGO AMIGO-step AMIGO-step+frequency

56.9 6.44 59.6

0.115 0.0605 0 0.361 0.0367 0 0.127 0.0523 0

495 L7.8 468

Figure 7.18 Responses to a unit step change at time 0 in set point and a unit load step at time 3 for PI controllers designed by MIGO (solid line) and AMIGO (dash-dotted line), and PID controllers designed by MIGO (dashed line) and AMIGO-step (dotted line) for the lag-dominant processin Example 7.1.
to the MIGO rule for PI control. However, since this is a lag-dominant process, the AMIGO tuning rule for PID control is conservative compared to the MIGO rule. This is obvious in the figure.
The responses obtained using the SOTD model are not presented in the figure, but Table 7.2 shows that the controller parameters are close to the MIGO design.
Notice that the magnitudes of the control signals are about the same at load disturbances, but that there is a major difference in the response time. The differences in the responses clearly illustrate the importance of reacting quickly.
The example shows that derivative action can give drastic improvements in performance for lag-dominated processes.It also demonstrates that the control performance can be increased considerably by obtaining better processmodels than (7.3).
248

7.7 Comparison of the Methods

Table 7.3 Controller parameters obtained from the MIGO and AMIGO tuning rules for the process with balanced lag and delay in Example 7.2.

Controller PID

Design

Ti

7,1

k;

MIGO AMIGO-step AMIGO-frequency

0.432 2.43 0.414 2.66 0.640 2.96

1 0.178 0 0.156
0.216

MIGO AMIGO-step AMIGO-frequency AMIGO-step*frequency

1.19 t.12 r.20 1.15

2.22 2.40 2.5r 2.I7

r.27 0 0.619 0 0.927 7.32

0.536 0.467 0.478 0.506

Next we will consider a process where the lag and the delay are balanced.
Exalrplp 7.2-BuANCED Lec eNo Dplev Consider a process with the transfer function

P(s) - -(-s=+ r J *

Fitting the model (7.3) to the processwe find that the apparent time delay and time constantsare L:1.42 and ? - 2.90.Hence,Llf - 0.5 and t - 0.33.

The frequency response data needed for the AMIGO design are K1s6 - 0.250 and ?rso : 6.28. The gain ratio becomes rc - KBolKp - 0.25. Fitting the

second-ordermodel (2.47) gives the parameters ft - 1.73, T2 - 1.73, and Lt:1.05.

The controller parameters obtained from the MIGO and AMIGO tuning

rules are presented in Table 7.3.

Figure 7.19 shows the responses of the system to changes in set point and

Ioad disturbances when the MIGO and AMIGO-step designs are used. The fig-

ure shows that the load disturbance responsesobtained by MIGO and AMIGO

irre quite similar, which can be expected because of the similarity of the con-

troller parameters. The difference in set-point response between the MIGO

and AMIGO design is caused by the different set-point weightings b of the two

designs.

The integral gain ft; is about three times higher for PID control than for PI

control. This is in accordancewith Figure 7.7.

n

Finally, we will consider an example where the dynamics are dominated by the time delay.

Exaupln 7.3-DnIAy-DoMINATED DyNnurcs Consider a process with the transfer function

P(s:) (1#obsr e-'

249

Chapter 7. A Ziegler-Nichols Replacement

z
1.5 -1
0.5 0
1.5
1 a' f-/
s 0.5
!,''

i\
\'- \

t.\

\

10
Figure 7.19 Responses to a unit step change at time 0 in set point and a unit load step at time 30 for PI controllers designed by MIGO (solid line) and AMIGO-step (dash-dotted line), and PID controllers designed by MIGO (dashed line) and AMIGO-step (dotted line) for the process with balanced lag and delay in Example 7.2.
Table 7.4 Controller parameters obtained from the MIGO and AMIGO tuning rules for the delay-dominant processin Example 7.3.

Controller PI
PID

Design

Ti

Ta

MIGO AMIGO-step AMIGO-frequency

0.170 0.404 0.175 0.360 0.163 0.407

MIGO AMIGO-step AMIGO-frequency AMIGO-step*frequency

0.216 0.242 0.2t2 0.218

0.444 0.474 0.446 0.453

0.L29 0.119 0.0957 0.129

k;
0.42L 0.486 0.400
0.486 0.511 0.475 0.481

Approximating the process with the model (7.3) gives the process parameters

Z - 1.01, T :0.0932, and r : 0.92.The large value of r shows that the process

is delay dominated. The frequency response data needed for the AMIGO design

is K ls s - 0. 980 a n d ? rs s -2 .2 0 . T h e g a i n rati o becomesK - K B ol K p:0.98.

The process has the same structure as (2.47) so the parameters of this model

becomeTt : Tz :0.05, and Z1 : l.

The controller parameters obtained from the MIGO and AMIGO tuning

rules are presented in Table 7.4.

Figure 7.20 shows the responses of the system to changes in set point and

load disturbances. The responsesobtained from the MIGO and AMIGO designs

are similar. It also shows that there are small differences between PI and PID

control, which was expected since the process is delay dominant.

I

250

7.8 Measurement Noise and Filtering

z

-{
0.5 0
1

8

10

12

14

16

18

20

t L

i,
r nq

-
0

10

12

14

to

18

Figure 7.20 Responses to a unit step change at time 0 in set point and a unit load step at time 10 for PI controllers designed by MIGO (solid line) and AMIGO-step (dash-dotted line), and PID controllers designed by MIGO (dashed line) and AMIGO-step (dotted line) for the delay-dominant process in Example 7.3.

7.8 MeasuremenNt oiseand Filtering

So far we have focused on attenuation of load disturbances and robustness to processvariations. In many casesit is also necessaryto consider measurement noise. This is particularly the case for lag-dominated processeswhere maximization of integral gain gives controllers with high gain. Measurement noise can then create large control actions. In extreme cases the control signals can be so large that the actuator is saturated. The effect of measurement noise can be estimated from the transfer function from measurement noise to control signal:

Gun: I+PC,

(7.16)

Since measurement noise typically has high frequencies, the high-frequency properties of the transfer function are particularly important.
The effect of measurement noise can be alleviated by filter the measurement signal as is shown in Figure 4.3. The transfer function from measurement noise to controller output is then

cGr
Grn: l+ PCGf

(7.17)

A typical filter transfer function is given by

G1(s): r+sT1+@Ty)212'

(7.18)

see (3.16). Adding a filter will reduce the robustness of the controller. It is easy to recover robustness by redesigning a controller for a process with the

25L

Chapter 7. A Ziegler-Nichols Replacement

10

^
Q

1' d'- 2

a\ 1 n-"

A
10 1 10 1oo

t

100

10'

10-

10-

- 1nr\

1oo 1o-t

100

1o'

102

103

omega

Figure 7.21 Gain curves of the transfer functions from load disturbance to process output (upper) and from measurement noise to controller output (lower). Curves for ideal PID control are shown in dotted lines, and for PID control with filtering with time constants Tf :0.002, 0.005, and 0.010 in dashed lines, and for T1 : 0.02 in solid lines.

transfer function P(s)G1(s). The design procedure starts by designing an ideal PID controller for the process P(r). The design gives guidance for choosing the filter time constant Ty; typically a fraction of the integral time for PI control or the derivative time for PID control. An ideal PID controller is then designedfor the processP(s)Gs(s), and the controller for the processP(s) is then C(s)G1(s). If necessary,the procedure can be iterated a few times. Adding a filter improves attenuation of measurement noise at the cost of poorer load disturbance attenuation. The final design choice is thus a compromise. The procedure is illustrated by an example.

Exauplp 7.4-EppECT oF FIlrnRrNc.

Consider the lag-dominated system in Example 7.1. Table 7.2 shows that the

MIGO design gives a controller with high gain, k : 56.9,, which gives good

attenuation of load disturbances with integral gain k; : 495. The transfer

function from measurement noise to controller output has high gain at high

frequencies, as is shown by the Bode plot in Figure 7.2I. The derivative time

I

is Ty : 0.06 and reasonable filter time constants are in the range T1 :0.002-

I

0.020.

I

To design controllers for the system P(s)Gr(r) we approximate the transfer

(
L

function using Skogestad's half-rule. Starting with the SOTD model used in

C

Example 7.1 we account for filtering by adding Tf 12 to the time constant ?2

r,

and to the time delay 21. The combination or process P(s) and filter G1(s) is

then representedby the SOTD model (2.47) with Tt :0.980, Tz :0.108+ Tf 12,

0

and .L1 : 0.010 * Tr 12. Equation (7.13) then gives the controller parameters

t

shown in Table 7.5. Controller gain decreasesby a factor of 2 with increasing

c

values of the filter constant, integral time increases by a factor of 2 and the

o

derivative time increases by about 40 percent. Integral gain ki decreaseswith

k

252

7.9 Detuning

Table 7.5 Controller parameters obtained in Example 7.4. Compare with Example 7.1.

T1

Ta

ki kalTr

0 .0 0 0 5 9 .6 0.r27 0.0523 468 0.002 52.6 0.138 0.0546 382 0.005 44.7 0.153 0.0578 293 0.010 35.6 0.176 0.0624 203 0.020 25.L 0.220 0.0705 115

oo 7436 516 222 88.6

M,,
oo
1436. 520 234 tt2

a factor of 4 and the largest high-frequency gain of G,, decreaseswith several

orders of magnitude.

Table 7.5 also shows the largest gain, Mur, of the transfer function G""(s)

and its estimate kalTf given by @.aa). The simple estimate is remarkable accurate for small filter-time constants.

The properties of the different controllers are also illustrated inFigure 7.22

which shows the responses of the system to load disturbances and measure-

ment noise for different controllers designed with different values of the filter-

time constant 71.

Notice that there are large variations in the control signal for Ty : 0.002

even if the noise in the process output is not too large. The reason for this is

that the controller gain is quite large.

Figures 7.21 and 7.22 glve a good illustration of the trade-off between at-

tenuation of load disturbances and injection of measurement noise. The final

trade-off is always subjective, but a moderate amount of filtering is always

useful because the effect of measurement noise can be decreased significantly

with only moderate increase of integral gain. In the particular case a value of

7r eround 0.01 is a reasonable choice.

n

7.9 Detuning
The AMIGO tuning rule lends itself naturally to detuning. For PI control, load disturbance rejection can be characterized by integral gain ki : K lTi. Amplification of measurement noise can be characterized by controller gain K. Since measurement noise typically has high frequencies the variation of the control signal generated by measurement noise is approximately Kn(t) where ru(r)is the measurement noise.
Figure 7.23 shows the robustness domain of a PI controller for typical firstorder processes.All gains in the white area satisfy the robustness condition that the combined sensitivities are less than fu[ - 1.4. Any combination of controller parameter in that range is thus admissible from the point of view of robustness. Load disturbance attenuation is captured by the integral gain fr;. Assuming that load disturbances enter at the process input the transfer
253

Chapter 7. A Ziegler-Nichols Replacement Tf : o'oo2

?/ : o'oo5

-0.5
0 _10 = -20 -30 _40
I
0.5
-
0
-0.5
0 _10
I
-zv
-30 _40

1
L
?/ : o'o1o

-u.c
0 -10 -20 -.tu -40
'l
nq
0

0.5

1

1.5

2

Tf : o'o2o

Figure 7.22 Simulation of PID control of the system in Example 7.4.The measurements are filtered with the second order filter (7.18) where time constants are Tf :0.002, 0.005, 0.010, and 0.020. For each filter constant the controller parameters are chosen to maximize integral gain subject to the robustness constraint M : L4. A load disturbance of 25 is applied at time 0 and measurement noise is acting on the system.
function from load disturbances to process output is approximately given by
c(') s ki
Load disturbance attenuation is thus inversely proportional to ft;. Measurement noise typically has high frequencies.For high frequenciesthe transfer function from measurementnoise to the control signal is approximately given by
G(r) - K.
254

7.9 Detuning

T:L 0.4
0.3

T:I0

?: 100

"aio.2 0.1

0

0.2 0.4 0.6

0123402040

K

KK

Figure 7.23 The sensitivity constraint for a system with M : 7.4 and the transfer function P(s) : e-'lG * sZ), with ? : 1, 10 and 100.

Injection of measurement noise is thus proportional to controller gain K. Since all values of K and ki that satisfy the robustness requirement are given in Figure 7.23, it is straightforward to make a trade-offbetween load disturbance attenuation and injection of measurement noise.
Figure 7.23 indicates that variations of the control variable due to measurement noise can be reduced simply by reducing proportional gain. The penalty for this is poorer attenuation of load disturbances. A proper quantitative tradeoff is easily done based on Figure 7.23. Instead of choosing the largest value of integral gain we should simply choose a combination of proportional and integral gain on the left border of the robustness region in the figure. Since the figure is not available when the simple tuning formulas are used we will develop an approximate formula for the left boundary of the robustness region.

A FirstAttempt
One possibility is to reduce the gains as indicated by the straight line in Figwe 7.23. This line goes through the peak with parameters K0 and ft! obtained by the nominal design. When integral gain is zero the robustness boundary goes through the point

KKo: -1 + 1 M,
ki:0'

Mr-l M,

(7.1e)

A line through this point and the extremum is

' - , 7 T n K K r + a
h.-h-
K0Kp + u

(7.20)

Notice that it is not useful to reduce proportional gain below the value K :0, when the controller is reduced to a pure integral controller. Figure 7.23 shows that the formula (7.20) is conservative for T - 1 and T - 10 but not for 7 : 100 since the line will be partially outside the robustness boundary for this process.We will use the detuning formula (7.20) for processeswith r > 0.1. For

255

Chapter 7. A Ziegler-Nichols Replacement

lag-dominant processeswith t < 0.1, better approximations of the robustness boundary are required.
Figure 7.23 indicates that for 7 - 100 the lower left-hand side of the robustness boundary has the shape of a parabola. To obtain a better approximation of the left-hand boundary of the robustness region we will first consider a simple example where the robustness boundary can be computed explicitly. An integrator with delay is the extreme case of a lag-dominated process,but we will start by determining the robustness bound for an even simpler case.

A PureIntegrator
Consider a pure integrator
P(s)- 1
s The loop transfer function with PI control is

G r ( r ) --

Kt!h'-\
-

K
-r--'

t,

t,

Requiring that the loop transfer function is outside a circle with radius r and center at -c gives

t
l

tc2-

f

G

r

f

t

a

\

l

> r2.

I'"1

(7.2r)

But

- (,- #)'*(L,)' |lc+G" r(i'la)l'I:lr-t4oz-,

Kl, al

l??
:^T-orv:
a*

6z - 2cki
a)o

,

rk;
I'

+ 6z

\ a.r2

-
Z

2
n

c
,

k

;:,
)

2+

r

',

,-

\

r Kz - 2ck;:,2
,k )

The robustness condition can thus be written as

| ^,.,12 tki 6z-2ck;:,2 ,, tK2-2ck;:,rrrr.

lc+Gr\La)l:(rr+

zt, )tt"-\

n )_

The left-hand side has its smallest value for
.,)2:n#*,

where we require that 2clei ) K2. The robustness condition thus imposes the following constraint between integral and proportional gain:

r2ck, -
lT)

K 2 r , 2< " 2 - ' 2

Equality is achieved for

2- Eck; - K2 - t / c 2 - r 2 ,

or 6z
ki: 2(,-'/F -7')
which is a parabola in the K, ft; plane.

K'(, + lF -.J1
2r2

(7.22)

256

7.9 Detuning

Non-normalized Variables

So far we have used scaledvariables. If we consider a processwith the transfer

function

p ,(,s , ): ; : K , K o ,"'

the equation becomes KrK'1,+t/r'_ 12)
kr: 2Tr2
For a design based on a constraint on M." we have c:

I and r : IlMr; hence

c * Jc2 - r2 _ M,IM, + \/M7=)

2r2

2

For a design with equal constraints on both sensitivity and complementary sensitivity we have

':

2M -T 2M1M_ 11

2 M 2- 2 M + r

1)

This implies c2 - 12 -- 1, and we get

,+r@-12 2r2

c*1 M(M - 1). 212

Summarizing, we find that the robustness constraint for a pure integrator

becomes

R| i :

ltKrK'
P-V-

(7.23)

rvhere

(r

B

-

l

Mlu'l\uM-'

+ t1

12 for design based on M, for design based on M.

(7.24)

Equation 7.23 rmplies that integral gain is reduced by the factor n2 when gain is reduced by the factor n. Since 7, : K lki we find that the integral time increases with the factor n.
The detuning rule (7.23) is derived for an integrator without time delay. To
deal with the process(7.3) we first observefrom Figure 7.23 and Equation 7.19 that the parabola passes through the point KKp - -a for ki: 0. For the
process (7.3) the detuning rule (7.23) should therefore be replaced by

k i -: FRf@f i+,K K ) 2

(7'25)

where the time constant ? has been replaced by the effective time constant
T +L.

257

Chapter 7. A Ziegler-Nichols Replacement

Combining the Results
We have obtained two formulas for detuning. The formula (7.20) based on linear extrapolation gives good results for processeswith c > 0.1, and processes with r < 0.1 as long as the gain reduction is moderate. The formula (7.25) gives good results for strongly lag-dominated processes with large gain reduction. It is then natural to combine the formulas. This will give a good match to the left part of the robustness constraint in Figure 7.23.
The formulas (7.20) and (7.25) give the same result for
*t oi oa**6KoKgon - U_ o ( o + K K ) 2 KJL+T

K'LLKLp^- : $!-o(!i!) - ow. F@ + KoK)

(7.26)

Summarizing we obtain the following formula for detuning the PI controller. First choosea gain K I Ko.Then determine the integral gain in the following way. For process with r > 0.1, determrne k; from (7.20). For processeswith r < 0.1, compute integral gain from

n, oY& fIf iK K o

Bo (&a

+
ff

K
i

K

)

'

f o r K K o >h?. Kp(L+ r) - a
0@ + KoKo)

f

orKK

o<hyKp
F@ +

( L+ Ko

K" )o

)

a.

(7.27)

Notice that this equation is an approximation of the left-hand side of the robustnessconstraintin Figure 7.23.

Examples
The detuning rule (7.27)will be illustrated by someexamples.First, we treat one singleprocesswith the structure (7.3).

Exeuplp 7.5-DpruNrNG A PI controllerdesignedfor the process

1

P(\s)/ _

_:__e-s
1*1000s

(7.28)

using the AMIGO design (7.5) with the robustness constraint M - 1.4 has the controller parameters K - 349 and Ti - 13.2, which gives the integral gain ki : 26.4. The process is almost an integrator with delay, P(s) n: 0.001e-'/s, with a normalized time delay e er 0.001. This explains the high gain in the controller. Figure 7.24 shows Nyquist curves of the loop transfer function, as well as the curves obtained when the gain is reduced by the factors 0.5, 0.1, 0.05, 0.01, and 0.005, respectively, using the detuning rule (7.27). The figure shows that the loop transfer functions of the detuned systems remain close to the robustness region.

258

7.9 Detuning

1
F.igrre 7.24 Nyquist curves for loop transfer functions for PI control of the process (7.28). The thick line corresponds to the optimal controller, and the thin lines to controllers where the gain is reduced by the factors 0.5, 0.1, 0.05, 0.01, and 0.005, respectively. The circle shows the robustness constraint M : I.4.

k;vsK

T;vs K

10
100
Figure 7.25 Relations between the reduced gain K and the integral gain ft; (left) and the integral time fr (right). The dashed line corresponds to the detuning rule (7.20) and the dotted line to the rule (7.25\
Figure 7.25 shows how integral gain A; and integral time Ti are changed when the gain is reduced. Notice that the integral time remains almost constant as long as the gain reduction is made according to the linear part of (7.27). The linear reduction is replaced by the quadratic reduction when the gain is Iower than K x I35. The gain reduction at this point is K lK0 N I351349 nv0.4.
T In the next example, the detuning rule (7.27) is applied to a large test batch of processes.
259

Chapter 7. A Ziegler-Nichols Replacement

Figure 7.26 Nyquist curves of loop transfer functions where the controller is detuned using the rule (7.27). The circles show the robustness margin M :1.4.

Exeuplp 7.6-DoruNING Applmo ro rHE Tnsr BarcH

The detuning rule (7.27) has been applied to all processesin the test batch

(7.2). Figure 7.26 shows the Nyquist plots of the loop transfer functions ob-

tained when the PI controllers are detuned using (7.27). The figure shows four

cases;the original loop and loops where the controller gain is reduced by fac-

tors 0.5, 0.1, and 0.01. Only those systems where the controller gain is larger

than 0.5 are shown. This is the reason why only three casesare left when the

controller gain is reduced by a factor of 0.01.

The example shows that the loop transfer functions remain close to the

robustness region and that the detuning rule works well for the processesin

the test batch.

I

TI

in

A Pole Placement Interpretation

There are situations when the response time and the bandwidth are of great

Pt

importance. In this casethe detuning problem can be solvedusing a simple pole

Fo

placement approach. Neglecting the the time delay the loop transfer function

du

260

7.9 Detuning

Table 7.6 Controller parameters, frequency and damping.

T6ok?

a)e

('

5 1.21 0.296 0.343 0.910 0.222 0.830 10 2.82 0.513 0.226 0.845 0.216 0.804 20 6.24 0.99 0.222 0.815 0.2I7 0.794 100 34 4.94 0.222 0.788 0.2Lr 0.784

obtained when a PI controller is combined with the processmodel (7.3) becomes
G z (:r4) 4 : J #

The characteristic polynomial is

s2- + s^ 1 + K r K

kiKp +-f .

T

Comparing this with the standard polynomial s2 + 2( as * a2 we find

l+KoK -2(aT Krlr, - ot2T.

(7.2e)

Using the numerical values for the process (7.3) with Kp : 1 and Z - 1 we get the values in Table 7.6 for different values of time constant 7. The optimal controller parameters K0 and ft! are determined from the MIGO design with M - 1.4. The last two columns are the frequency and the damping when the time constant 7 is replaced by the effective time constant T, : T + L. Notice that the frequency and the damping are practically constant for the whole range of parameters.
Another way to detune the controller is to use Equation 7.29 and reduce the natural frequency. This gives
I+KKo 2( T"

and

k,_Ql=ry!!,)'.
4(2KpT,

(7.80)

This is similar but of somewhat different form than the parabolic expression in (7.27).

PIDControl
For PID control, it is natural to start a high-frequency gain reduction by reducing the derivative gain. One way to do this is the following. Let KPID , kl'' ,

267

Chapter 7. A Ziegler-Nichols Replacement
and klID denote the gains for PID controllers obtained by the AMIGO tuning formula, and let KPI and kll be the corresponding controller gains for the PI controller. Following the ideas used in PI control we will obtain detuned controller by linear interpolation. This gives

K : K P I * 4 1 6kPrroDtn-tK--' ' )

ki:

k!'

+'

L k

(k lo

l

I

Dr' -

t

- kft).

(7.31)

This gives a natural way to detune the PID controller until it becomes a PI controller. If further gain reductions are required we can proceed as for PI controllers.

Exaruplp 7.7-DstuNING Applmn ro rHE Tnsr Bercu

The detuning rule (7.31) has been applied to the test batch (7.2).Figarc 7.27

shows the Nyquist plots of the loop transfer functions obtained when the PID

controllers are detuned using (7.31). The figure shows four cases,the original

loop tuned with the AMIGO tuning rules (7.7) and loops where the deriva-

tive gain is reduced by factors 0.1, 0.01, and 0. The last case gives a pure PI

controller.

The example shows that the loop transfer functions remain close to the

robustness region and that the detuning rule works well for the processesin

the test batch.

I

7 . 1 0S u m m a r y
In this section it has been attempted to develop simple tuning rules in the spirit of the work done by Ziegler and Nichols in the 1940s. The goal has been to make rules that can be used both for manual tuning and in auto-tuners for a wide range of processes.The methods were developed by applying the techniques for robust loop shaping presented in Section 6.8 to a large test batch of representative processes.The controller parameters obtained were then correlated with simple features of process dynamics.
One interesting observations was that there are significant differences between processeswith delay-dominated and lag-dominated dynamics. To capture this difference, process dynamics must be characterized by at least three parameters. Notice that Ziegler and Nichols used only two parameters. One possible choice is: process gain Ko, apparent time constant T, and apparent time delay Z. These parameters can be obtained from a step response experiment. Section 2.7. The relative time delay r : Ll@ + ?), which ranges from 0 to 1, is used for a crude characterization of dynamics. Processeswith small r are called lag dominated, processeswith r close to one are called delay dominated and processeswith r around 0.5 are called balanced.
262

hdPID - 1

7.10 Summary

Figure 7.27 Nyquist curves of loop transfer functions where the controller is detuned using the rule (7.31). The circles show the robustness constraint M :1.4.

Very satisfactory results were obtained for PI control, where the parameters from MIGO tuning can be matched with

K:E+(oss-#d;J

T; -

0.35L*

L3LT2 T2+12LT +7L2'

(7.32)

for the full test batch. The tuning rule, which we called AMIGO (Approximate MIGO), gave good results for all processes in the test batch ranging from process with integration to processes with pure time delay.
The numerical values in (7.32) are based on a combined sensitivity M - 1.4. The form of the tuning rules are the same for other values of M but the numerical values of the coefficients are different.
For PID control of processeswith r > 0.3 it was also possible to find the
263

Chapter 7. A Ziegler-Nichols Replacement

simple tuning rule

K:+(or*,*i)

,' r' - _

0.4L+ 0.8f r L+a\T "

(7.33)

Ta:

O.5LT 0 . 3 L+ T '

This tuning rule also gave a conservative tuning rule for lag-dominant pro-

cesses. It can thus be used for the full range of processes provided that a

conservative tuning is acceptable. Derivative action can give substantial ben-

efits for lag-dominated processes.A quantitative estimate can be obtained by

comparing the integral gains ki of of (7.32) and (7.33).

For some lag-dominated processesit is possible to give tuning rules with

much better performance than (7.33). When processdynamics is characterized

by the parameters Kp, L, and ? both time delay and small time constants

are captured in L. For lag-dominated processesimproved performance can be

obtained if the time constant and the delay are separated by better modeling.

For a model characterized by an SOTD model with four parameters the AMIGO

tuning rule is

KoK -

G1*or-?L ,

t

o

t

T2 r,-*

-

&

sT-

tqT

z

K

o

t

,

: F'

t|
L1

*

Br++Fsft*

L.t

L)

Bnr'? L1

(7.34)

Krka: (rrL,* Tzr*r Tsr*zT^T) #+;.T,

where the parameters are given by

&1 - 0.19 az:0.37 as : 0.18 d+:0.02

f, - 0.48 f z : 0.03 Ft - -0.0007 0n:0.0012

Tt : 0 . 2 9 T z : 0 . 1 6 T e : 0 . 2 0

T+:0.28.

(7.35)

This tuning rule is similar to (7.33) for processeswith balanced and delay-

dominated dynamics, but it typically gives higher gain for lag-dominated pro-

cesses.This tuning rule requires improved process models. It is difficult to

obtain two time constants from a step response experiment. System identi-

fication or the combined frequency and step response methods described in

Section 2.7 can be used.

T\rning rules based on frequency response data have also been developed.

In this case the parameters were chosen as: process gain Ko, ultimate gain K.aro,and ultimate period ?rso. The parameter r<: K161oKfo was used to clas-

sify the processes.This choice matches what is used in auto-tuners based on

relay feedback. The AMIGO tuning rule for PI controllers based on frequency

response data is

KK;r,o: 0 . 1 6

T;

1

(7.36)

I + 4.5rc "*

264

Th, wit
ifie, out dyn AM add trac mer
r
gain
7.1
This tion, good autor whicl
Hage
stanc and I
2002
proce Astrd can b Much

7.11 Notes and References

and the tuning rules for PID controllers are 6 : (0.3- O.rK\ lKLso
r,-ffir,,'
ra:T!#?reo'

(7.37)

These tuning rules give good tuning for balanced and delay-dominant processes with rc> 0.2, but are not appropriate for lag-dominant processes.
The AMIGO tuning rules optimize load disturbance attenuation with a specified robustness. Measurement noise can be dealt with by filtering the process output. There are significant advantages of using a second-order filter. The dynamics of the filter can be accounted for in a simple way by applying the AMIGO rules with Tr12 added to T and L for the FOTD model and with Trl2 added to T2 and Z for the SOTD model. In this way it is possible to make the trade-off between attenuation of load disturbances and injection of measurement noise.
A systematic method of detuning the controllers to give a specific controller gain has also been developed.

7.11Notesand References
This chapter is based on work by the authors and their students. The motivation was to gain improved understanding in the information required to develop good tuning rules and to find tuning rules that can be used for manual and automatic tuning. The basis for the work is the robust design method (MIGO) rvhich is developed in [Astrdm et al., 1998] for PI control and in [Astr<im and Hdgglund , 2001; Panagopoulos et al., 20021for PID control. In certain circumstancesit is advantageous to have Ti I 4Ta as has been noted by [Kristiansson and Lennartsson, 20021.T\rning rules for that case are given by [Wall6n et al., 20021.The MIGO method requires knowledge of the transfer function of the process.The AMIGO tuning rules for PI and PID presented in JHagglund and Astriim, 2002; Hiigglund and Astrdm, 2004b; Hdgglund and Astrtim, 2004a1 can be applied when only features of step and frequency responsesare known. \luch of the material in the chapter have not been published before.

265

Predictive Control
8.1 Introduction
A PI controller only considers present and past data, and a PID controller also predicts the future process behavior by linear extrapolation. There have been many attempts to find other ways of predicting future process behavior and to take this into account when making the control actions. Good predictions can improve controller performance, particularly when the process has time delays, which are common in process control. Time delays can arise from a pure delay 4echanism caused by transport or time for computation and comriiunication. Delays may also be caused by measurements obtained by off-line analysis. They also appear when a high-order system or a partial differential equation is approximated with a low-order model as in heat conduction. fime delays appear in many of the models discussed in this book. A new controller that could deal with processes having long time delays was proposedJeseSmith in 1957. The controller is now commonly known as the Smith predictor. It can be viewed as a new type of controller but it can also be interpreted as an augmentation of a PID controller. There are also many other controllers that have predictive abilities. The model predictive controller is a large class of controller that is becoming increasingly popular.
In this chapter we start by presenting the Smith predictor in Section 8.2. This controller can give significant improvements in the response to set-point changes, but the Smith predictor can also be very sgnsitive to model uncertainties. This is shown in Section 8.3 where we analyze the closed-loopsystem when a Smith predictor is used. The analysis also shows that the concepts of gain and phase margin are not sufficient to characterize the robustness of the system. The reason for this is that the Nyquist curve of the loop transfer function can have large loops at frequencies larger than the gain crossover frequency. The robustness is well captured by the properties of the Gang of Four. and there is also another classical robustness measure, the delay margin, that gives good insight. A special type of the Smith predictor called the PPI controller is discussed in Section 8.4. This controller is simpler and more robust. Model predictive control, a more general form of prediction that is gaining in popularity, is discussed in Section 8.6.
266

8.2 The Smith Predictor

Figure 8.1 Block diagram of a system with a Smith predictor.

8.2 TheSmithPredictor

To describe the idea of a Smith predictor we consider a process with a time delay Z, and we factor the process transfer function as

P(s) - Ps(s)e-'L

(8.1)

where the transfer function Pe does not have any time delays. Figure 8.1 shows a block diagram of a closed-loopsystem with a Smith predictor. The controller
consists of ar1ordinary PI or PID controller C6 and a model of the pro."r, .F, factored in th'e same way as the process,connectedin parallel with the process. If the model is identical with the process the signal Jip represents the output without the delay or, equivalently, a prediction of what the output would be if there were no delays. By using the model it is t-hus possible to generate a pae{ic-tion of the output. The signal yp is fed back io tfr" controller, and there is also an additional feedback from the process output y to cope with load disturbances. If the modet 3 is identical to the process P and if there are no distqrbanCes acting on the-process the signal e is zero. This means that the outer feedback loop gives no contribution, and the input-output relation of the system is given by

G,,, -

PCo

PoCo -cr.

:-p"-

1 * PoCo 1 * P o C o -

(8.2)

The controller Co can thus be designed as if the process has no time delay, and the response of the closed-loopsystem will simply have an additional time delay.
The system shown in Figure 8.1 can also be represented by the block diagram in Figure 8.2, which is an ordinary feedback loop with a process P and a controller C, where the controller has the transfer function

r-t -

vr-ot

1+Co(Po-P)

Co 1 * C o P o ( 1- e - " r ;

(8.3)

267

Chapter B. Predictiue Control
Controller

Figure 8.2 Another representation of a system with a Smith predictor.

The transfer function P6e-"2 is the transfer function of the processmodel used to design the controller. The controller C is thus obtained by wrapping a feedback around the controller Co. The input-output relation of the controller C can be written as

u ( " )- c o ( s ) ( a (-s )4 ( ' ) ( 1- e - ' L ) u ( ' ) ) ,

(8.4)

where I/(r) and E(s) are the Laplace transforms of the control signal and the error. The term 4(r)(I - r-'r)U(r) can be interpreted physicaJl_y-as-the predictdd effect on the output of control signals in the interval (t - L,f). The Smith predictor can thus be interpreted as an ordinary PI controller whe?e the effects of past control actions are subtracted from the error. The controller can be compared with a PID controller, which predicts by extrapolating the current processoutput linearly, as is illustrated in Figure 3.5. This type of prediction is less effective for systems with time delays because future process outputs are strongly influenced by past control control actions rather than current inputs.
The properties of the Smith predictor will be illustrated by an example.

Exeupln 8.1-Fmsr-ORonn SvsrnnawITH Trup Dolav Consider a process with transfer function
P(:sr)fu{".
A PI controller that gives the characteristic polynomial

(8.5)

s2+2(ia,ss*ofi

for the process without delayis designedas describedin Section6.4.The controller is
c o ( s: K) ( t * # ) .

268

8.2 The Smith Predictor

L:B

1.5

LC

-1

1

0.5

u.c

0

U

z

z

1.5

1

1

0.5

0.5

0

0

-0.5

AE

n

Figure 8.3 Responses of a closed-loop system with Smith predictor. The process has the transfer function P(s) : e-"L lG + 1), and the figure showsresponsefor L:1and 8. The dashed line is the load disturbance.

where

K- 2(ayT -l
Kp ti:
a|r'

(8.6)

Figure 8.3 shows the responses of the system to a unit step change in the set

point and a load disturbance in the form of a unit step in the process input.

The load disturbance is applied at time t : I5 in all cases.The time constant is

equal to one in all cases,and the time delay L is changed. The PI controller is

designed to give a closed-loopsystem with o)o:2 and ( : 0.7 for the process

without delays. The figure shows that the responsesto set point have the same

shape but with a delay that changes with the process delay. The shape is the

same as for a system without the time delay. This property of the system is

quite remarkable.

The shapes of the responsesto load disturbances change with the time delay

L. With increasing time delay it will take a longer time for the system to react.

The initial part of the responsesare similar but with different delays. Because

of the varying delay the time to recover from the disturbance varies with the

time delay.

n

Analyzing the results it may appear remarkable that it is possible to obtain such good responses even when the time delay is as long as L : 8.In the following we will analyze the systems obtained when using the Smith's predictor to better understand its behavior.

The Predictor It follows from (8.3) that the Smith predictor can be viewed as the cascade

269

Chapter B. Predictiue Control

connection of an ordinary controller Cs and a block with the transfer function

(1 vpred

-
1 + Co(Po- P )

1+C6P6(1-e-"2';

(8.7)

To obtain the responses shown in Figure 8.3 the transfer function Cpredc. om-
pensates for the time delay of the process. Intuitively this can be understood in the following way. Assume CsPsnv-1; it then follows from (8.7) that

Cpred. x etL '

This means that the transfer function Cp,"d.(s)acts like an ideal predictor.
We can therefore expect that the transfer function Cor"dbehaves like an ideal predictor for frequencies where Cs(io)Pg(lar) is close to -1. Notice that it is not possible to have Cs(io)Ps(iat) : -1 for any frequency becausethe transfer function (8.2) is then unstable. The properties of the transfer function (8.7)
will be illustrated by an example.

Exevpr,p 8.2-PnpDrcroR FoR FrRST-ORDERSysrnu wrrH Trun Dnlay Consider the same system as in Example 8.1. Assuming that there are no modeling errors it follows that P : P : Pss-sL. Combined with a PI controller the predictor becomes

(\
vpred

-

1+co(Po-P)

1+

KpK(I srlt

-r sT + s4

1,t)r

-

e-'L)

(8.8)

It follows from (8.8) that Cp,"a(ia) : 1 for aL : 2tr, 4tt,6iT, . .. and that Co,ra(s) goes to 1 for large s. The transfer function Cprrd.has the series expansion

cp,edt .--(r=T) i-++K*o K L

(,
\tr

*

r=i

*+ox-p{-x"t=' - =e=+

*2

'

-
tt

r,),
-

-r ,

"

'

\
)'

The static gain of Cp,radecreaseswith increasing L and is always less than one. Figure 8.4 shows the Bode plot for the transfer function for L - 8. The figure shows that the transfer function gives a very large phase advance, more than 800'. A comparison with the phase curve of an ideal predictor shows that the system does approximate an ideal predictor well for certain frequencies. The solid and dashed curves are very close for those frequencies where the gain curve has peaks. Notice, however, that the gain curves are different. The ideal predictor has constant gain, but the gain of the transfer function Cp,ed. changes with several orders of magnitude.
We will now investigate how the large phase advance is created. Figure 8.5 shows Nyquist curves of the transfer function Cp,"df.or K, : l, T : l, K - 1.8, Tr : 0.45, and -L - 1, 2.5, 4, and B. For L : l the largest phase advance is closeto 90". The phase advance increases with increasing L, as is indicated in the curve for L : 2.5 where the circular part of the Nyquist curve increases. The Nyquist curve goes to infinity for L : 2.99, which indicates that the

270

'tot
810-
L
rP
-l
10

8.3 Analysis of Smith Predictor Control

720
1J
L
r$
9360

1o-1

10'

101

Figure 8.4 Bodeplot of the looptransfe.,,l.,.rro.rC. o,na(s)givebny (8.8)for L : 8 (solid)andfor theidealpredictoer 't (dashed).

transfer function has poles on the imaginary axis. For larger L the Nyquist

curve encircles the origin, which means that the phase advance is more than 360". The curve for L - 4 shows that the largest phase advance is more than

450'. As Z is increased further the Nyquist curve again goes to infinity for

L - 6.40, and for larger ,L there are two encirclements of the origin, indicating that the phase advance is more than 720". The curve for L - 8 shows that the

largest phase advance is more than 800'.

To deform the curve for L - 2.5 continuously to the curve for L : 4 in

Figure 8.5 the curve must go to infinity for some intermediate value of Z. In the particular case the Nyquist curve of Cp,ra goes to infinity for L - 2.99,

6.40, 9.80, 13.40, 17,00, 20.6,.... This means that the transfer function Cp,"d.

is unstable for some values of L. It has two poles in the right-half plane for

2.99 < L < 6.40, four poles in the right half plane for 6.40 < Z < 9.80, etc. For the simulation with L : 70 in Figure 8.3 the predictor transfer function has

six poles in the right half plane. The predictor (8.3) thus achieves very large

phase advances through poles in the right half plane.

I

There are severe drawbacks with unstable controllers. It follows from Bode's integral (4.28) that poles in the right half plane increase the sensitivity. The remarkable response to set-point changes shown in Figure 8.3 thus comes at a price. Some of these issues will be discussed in the next section.

8.3 Analysisof SmithPredictorControl
The closed-loop system obtained when a process is controlled using a Smith predictor will now be investigated. Let the process transfer function be P, the
27L

Chapter 8. Predictiue Control L:7

-1

ReCpred

L:4

L :2.5

L--8

ReCpred

Figure 8.5 Nyquist plots of the transfer function Cpr"d.for the system in Example 8.2 with L : l, 2.5,4, and 8. The plot for L : I and 2.5 all circles clockwise, the plot for L : 4 fi.rst makes one counterclockwise loop before making the clockwise loops, the plot for L :8 flrst makes tow counterclockwise the remaining loops are clockwise.

transfer function of the Smith predictor (8.3), and we find

PC Grt"o: I+PC

Gvd: -Gun:

P I+PC
C I+PC

-Gy,:

1 L+PC

PCo

--

PoCo
_o

-er. ""

1*PoCo+(P-P)Co 1+ PoCo"

r ( r + ( & - P ) c o ) - - p- ( t -

Poca -\ n-'"

1 * P o C o + ( P - P ) C o \ - 1 + P o cvo /)

Co

cs

1*PoCo+(P-P)Co 1+ PoCo

1+(ro -P)Co

. PoCo -.sr.

.._f.__n"-

'

lrPoCo+(P-P)Co

1*PoCoc

(8'9)

where the last equality is obtained by assuming that the model is perfect, i.., P - P. The form of the transfer function from set point to process output Grr,o shows that apart from the time delay the set-point responses are the same as for the system without time delays. The transfer Gun from measurement noise to the control signal is the same as the transfer function from set point to controller output. This transfer function is the same as for a system without a delay.

272

8.3 Analysis of Smith Predictor Control

Stability
It follows from (8.9) that the closed-loop system has poles at the open-loop process poles and at the zeros of of the function
r + ACo+ (P- eTCox 1+ PoCo,
where the approximation is valid when i'* P. The zeros of this function can be chosen to be stable by . proper controller Co.To have a stable closed-loop system it must also be required $at the processbe stable. This means that the Smith predictor does not work for processeswith unstable open-loop dynamics. Modifications to eliminate this difficulty will be given in Section 8.5.
Responseto LoadDisturbances
When modeling errors are neglected the response to a load disturbance at the process input is given by the transfer function

Gyd:p(r-
\^

.t ++P3o: nc o- ""

'

)

,
)

'

see (8.9). The secondterm has a time delay L.If a disturbance occurs at time 0 it follows that the response in the interval 0 < t < Z is the same as the response of the open-loop system. A typical illustration is given in Figure 8.3.
Assume that the processP is stable with static gain Ko and that controller
Cs has integral action with integral gain ki. A series expansion of Gra for small s gives

G,a(*s)Kp(-r :#,(1 - z,)): Kp:## - ( * , " . ; ) '
(8.10) Since Gya(O) - 0 there is no steady-state error for a step changein the load disturbance. Furthermore, the integrated error for a load disturbancein the form of a unit step is

IE - KrL. ;,

(8.11)

Notice that the first term KoL only depends on the processand that the second term Ilki only depends on the controller.

The transfer function P has a pole at the origin for processesthat have integral action. For such processes and a controller with integral action we have P(s) n: K"ls and C(s) x kif s for small values of s. This implies that

? ( ' - G y a ( s )*

##^(1-z,)):?+f*#xKuL (812)

This means that there will be a steady-state error for processeswith integration
even if the controller has integral action. The recovery from load disturbances
will therefore be very slow fo. processeswith slow dynamics. Notice that the closed-loopsystem is stable even though P contains an integrator. The reason is that the integrator of P is canceled with a zero of the transfer function I - PC0l(1 + PoCo). Several modifications of the Smith predictor have been proposed for processeswith integration. This will be discussed in Section 8.5.

273

Chapter 8. Predictiue Control

.^o =rv
ca

10

-' 1

0-2-

-.no
3
F-i
' t 0- 1 ' 1 0-2

Figure L :0

8'6 Gain curves for the sensitivity functions for the system (dash-dotted),0.25 (solid), 1 (dashed), and 8 (dotted).

in

Example

g.3 with

TheSensitivityFunctions

In the ideal .at" ^P : P, it follows from complementary sensitivity functions are

(8.9) that

the

sensitivity

and the

s-

1-

-I:+3P:

s

C

s

1-

-,

1

Pogoo * p s L se

-

,

1:

r-

r

-

-

!

91+

P

e

C

e-

1 +f oPgooC^ oe - ' , 1- r o e - , I ,

Tos--,I

(8.13)

cwwuihtrhevoreeuot ?f sdtheielsayct.ohNemopctlioecmempethlneatmat reytnhtesaergynasiinstievcnitusyritvifevuistnycotfifo?unnacitnsiodinnTdsefoparernethdiedeennntotiomcfaiLnl..alThseysgtaeimn

Exenaplp B.B-SvsrEM oF Fmsr oRnrn wrrH Trur Dplay

For the first-order system in Example 8.1 where to give a)o:2. The sensitivity functions are

the

controller

Cewas

designed

? (\s )/ -

r

7,,.

(,

1

+

Kr{( s7)

l +

+ Kp

t4) K(l

S(s): 1-

"(s).

o - s L-+s",)tr

2 olrQ s2+

( @oT-
2( ross+

,)!
@'o

,

3,

-,'

wMiaF1nnii,"ctgdahru:ne2r1diea'n'2sc88,er,A'ers6weralsashssoppiihncieondhgcwoltycZtisvio.cwetrehilryteeth.hsFgapLaoto;irnntwhdLceesut>horsaveae7vnss.es2LiMottifh-v, etith:0yem,0Ifa.so.Ibex,rin,ml1so2ui.w,t4maiv1nfi.rtd6yes.,qe1faun6unes.ndirctT,ict2vhiioieetfnysolsairnrriecfgomre_erasaLit0sns,es-0es.nc20rsla,4oipt,s0ii0ev.d2.ilt4tyboy.,

274

8.3 Analysis of Smith Predictor Control

The differences between the low-frequency properties of the sensitivity func-

tions in Figure 8.6 are easily explained from (8.10). The low-frequency asymp-

tote of the gain curves of the sensitivity function intersects the unit magnitude

line for a - lzil(I + kiKoZ). For the system in the figure we have Kp : 1 and

ki : 4, and the intersections are denoted by circles in Figure 8.6.

n

The sensitivity functions shown in Figure 8.6 are typical for systems with Smith predictors. The complementary sensitivity function is close to one for
frequencies up to the bandwidth ott of the nominal system without time delay.
The sensitivity function has the typical oscillatory behavior shown in the figure. It intersects the line lSl - 1 several times. For large delays the sensitivity crossover frequency is approximately a," : kil(\ + kiKoL), reflecting the fact that the attenuation of load disturbances is poor for large Z. Also notice that the largest peaks of the sensitivity function are close to M, : 2 in the frequency range where lf Qrtt)lo 1.

Robustness
For controllers with integral action we have 7(0) : 1. Let 06 be a frequency such thatlT(iat)l is closeto l for 0 3at Satu.lf a6L) n it then follows from (8.13) that the maximum sensitivity is around M, : 2.In order to have smaller sensitivities it is therefore necessary to require that atL is not too large. It follows from (4.32) that it is possible to have perturbations in the processsuch that
llP(tar)l.- I lP(iat)l lrQrtt)l
without making the system unstable. For frequencies less than rD6t}i.e righthand side is equal to one. The inequality then implies that the uncertainty region is a circle with center at P(irtt) that passes through the origin. If we only consider variations in the phase admissible variations are therefore 60' or x f 3 rad. Since the phase change is otL we find

7f
l a 4 L L l( ; . J

which gives the following estimate of permissible variations in the time delay

lALl - 7T '- 1 L \ar,L otL'

(8.14)

Controllers with large values of a4L thus require that the time delay be known accurately. Consider, for example, the system in Figure 8.3 with L : 8.In this case we have a6L - 16, which implies that the permissible error in the time
delay is at mo"st6 percent.

TheLoopTransfeFr unction
Analysis of the sensitivity functions indicates that the robustness of a closedloop system with a Smith predictor may be poor when rtt6L is large. An analysis of the loop transfer function gives additional insight.

275

Chapter 8. Predictiue Control L:7

r -c)

L:4

L:g

Figure 8.7 Nyquist plots of the loop transfer function for a FODT system, (8.5), with a Smith predictor controller. The critical point -1 is marked with a *.

When there are no modeling errors the loop transfer function obtained using a Smith predictor is

PC:

PCo 1 + Co(Po- P)

PsCse-'L 1 * P o C o ( 1- e - ' L )

(8.15)

Figure 8.7 shows the Nyquist plots of the loop transfer function for different values of L. For Z : 1 the Nyquist plot has a loop of moderate size. The loop increases with increasing L, as is seenby comparing the casesL : I and L :2 in Figure 8.7. The loop is almost circular for L larger than 2. For L : 2.99
the loop is infinitely large, and for 2.99 < L < 6.40 the loop transfer function has two encirclements of the critical point, one for positive and another for negative al. Notice that we have only shown the branch of the Nyquist plot corresponding to 0 ( a < 6. The unstable poles are the poles of the predictor transfer function (8.7). The number of encirclements increases as L increases. For L - 8 there are four encirclements of the critical point.
Figure 8.8 shows the Bode plots of the loop transfer function for the cases L : I and L - 8. The loop transfer functions change drastically with L. The gain crossoverfrequency is 0.82 for L: 1 and decreasesto about 0.13 for L :8. These values agree quite well with the performance limit o)s"L nz 1 given by (4.57). Notice that the gain curve for L : 8 has several crossings at higher frequencies. The gain crossover frequency is smaller for L - 8 even if the rise

276

8.3 Analysis of Smith Predictor Control

L:7
^
r\

10'
aru
-> \, 10-

L:B

0 ----------\

.>-
tl

- rroe nv

\

v eAn b! fr

-540

0
F -rao
v -360
ti
-540

1o - '

100

1ot

100

(t)

a)

Figure 8.8 Bode plots of the loop transfer function (solid) and the process transfer function (dashed) for a FOTD system (8.5) with a Smith predictor. The curves on the left are for L : l, and those on the right for L : 8.

time for set-point changes are the same for both systems. The high peaks of the gain curve correspond to the loops in the Nyquist plot in Figure 8.7.
The Bode plot of the open-loopsystem is shown in dashed lines in Figure 8.8. Notice that the controller gives a large phase advance at the frequencies corresponding to the first two peaks, which represent the unstable poles of the controller.
The Delay Margin
The classical robustness measures, gain margin and phase margin, do not capture the properties of Nyquist curves of the type shown in Figure 8.7, where the Nyquist curve has large loops. This is illustrated in Figure 8.9, which shows Nyquist plots of the loop transfer function for the case L - 2 and for a system where the time delay of the processhas been increased with 30 percent. The figure shows that the system becomes unstable when the time delay is increased by 30 percent. Notice that it is the large loop that crossesthe critical point -1 and not the part of the Nyquist curve close to the gain margin. The robustness measure called the delay margin is introduced to capture this effect. The delay margin is defined as the change in the time delay required to make a system unstable. For the systems with L - 2 and Z : 8 in Figure 8.7 the delay margins are 27 percent and 7 percent, respectively.
Notice that the sensitivity functions also capture the robustness in the cases of loop transfer functions like the ones shown in Figure 8.7. The sensitivity to variations in the time delay can be estimated by (8.14), which gives delay margins of 25 percent and 6 percent for the systems in Figure 8.7 with L : 2 and ,L : 8. These numbers are close to the numbers obtained by using the delay margin.
Another way to quantify robustness is to explore the sensitivity of the closed

277

Chapter B. Predictiue Control

Figure 8'9 Nyquist plots of the loop transfer functions for the system in Example g.1

with Z : 2 in the nominal percent (dashed line).

case (solid line)

and when the

time

delay is increased by S0

loop to variations in the processparameters. For the FOTD processwe have
P(-sr)fu,-"

Hence, Differentiation

IogP - logKp - log(1 + s?) - sL this gives

dP - i -dKT"i E - ssddTL^
P

-_ dKo _ sdTo ^, dL K, 1+r"r-tu L

For systems with large time delays the last term is dominating, which means that the sensitivity to time variations in the time delay is the crilical constraint. Equation (4.32) then gives

l

dL L

l.-

r o L l T( i a t ) l '

and we obtain the following estimate of the delay margin:

dm :

trr&')i ldLl

<

m

a

xo

1
LEO

t)

l

l

Summary

The Smith predictormakesit possibleto obtain dramaticimprovementsof

the set-point response as illustrated in Figure 8.3. The controller is obtained

in a very simple way by first designing a controller Cs for a nominal system

Pe that does not have the time delay. The Smith predictor is then obtained

by cascading Co with a predictor C-pS,"mdi,twh hich effectively eliminates the time

delay' An interesting feature of the

predictor is that it uses past control

278

8.4 The PPI Controller
actions for prediction. It is in principle possible to compensate for any delay. The controller may, however, have unstable poles. The prodact al6L, where al6 is the bandwidth of the nominal closed-loopsystem To : P0C0lUPsCs) and Z is the time delay L, are crucial parameters. The number of unstable controller poles grows with ouL. Controllers with poles in the right half plane have poor robustness. Admissible variations in the time delay are inversely proportional to a6L. To have a robust closed-loopsystem it is therefore necessary to restrict ouL. In Example 8.3 we found, for example, that to have M, : 1.4 it was necessaryto have c)6L <0.5.

8.4 ThePPIController

In this section we will discuss special cases of the Smith predictor that give

controllers of a particularly simple form. The Smith predictor discussed in

Example 8.1 was based on the FOTD model. The design criterion was to find a

controller that gives a second-ordersystem with poles having relative damping

( and frequency ao for the system without delay. Another possible design

is to choose a controller that cancels the process pole and makes the other closed-looppole equal to s - -7lTa, where T4 is the desired response time

of the closed-loop system. This design method gives the following controller

parameters;

K_ T

Tt:7.

TaKp'

The loop transfer function of the nominal system without delay is PeCe : Il@7,1), and the controller has the transfer function

c ( s )-

1+sZ K o s T , I1+ h ( 1

1 -e-"r;

(8.16)

The loop transfer function is

P(s)c(s)- s T a1 + # ( L- e - ' t 1 '

(8.17)

Since the process pole is canceled it should be required that the process pole is fast in comparison with the dominant closed-loopdynamics; see Section 6.6. There is one tuning parameter: the closed-loopresponse time ?"7.
The input-output relation of the controller (8.16) can be written as

U

(

'

): f
:

fl +i Es 7(-',), - 7 ,

fl,(I-e-

1+s
ffi

?

((,",,r, '-l

ifKr(r

'

L)U(')
- ' - " )u,(, \'

):)

1-+f

fsi?'-'

G

)

'

(8.18)

rvhere Eo(r) is the Laplace transform of the predicted error

er(t): t,o(t) - y(t) - y(t),

279

Chapter 8. Predictiue Control

Figure 8.10 Block diagram of an implementation the PPI controller with 7"1 : T : Ti.

and

r1r; :,

K!:(r 1+s?\^

e-'\

U(r).

The term y(t) represents the effect on the output of control actions taken in the interval (t - L, /). The controller can thus be interpreted as a PI controller that acts on a predicted error, which is the actual error compensatedfor past control actions that have not yet appeared at the output. The controller is called the predicting PI controller or t}i'e PPI controller.
The controller is particularly simple if T4 - T. The input-output relation
of the controller then becomes

p-tL
U ( r ): K E ( s ) * r * r e t / ( r ) .

A block diagram describing this equation is given in Figure 8.10. Notice the strong similarity with the PI controller shown in Figure 3.3. There are also versions of this controller where the gain is replaced by a PD controller.

The Predictor
The PPI controller (8.16) is a cascade combination of a PI controller and a predictor with the transfer function

Cp,ed.(r) : 1+#(r-e-sr1

(8.le)

Apart from frequency scaling the predictor is completely characterized by the ratio Ta lL.It can be shown that the predictor does not have poles in the right half plane for any values of 7"1. The reason for this is that the loop transfer function of the nominal system without delay has constant phase.
A series expansion of the transfer function (8.19) for small s gives

Cp,ed(r) o | + L l T 4 - s T a Q l r a ) ' 1 2+ . . .
- *+n('*;##r",,+)

(8.20)

The static gain is Cp,,d(0) : I I Q + L lTa), and it also follows that Cp,"4goesto 1as s goesto infinity. Figure 8.11 shows the Bode plot of the predictor (8.19).

280

8.4 The PPI Controller

6 roo
fi<

100

ria tr
IU
Figure 8.11 Bode plots for the predictor (8.19) (solid), a predictor based on differentiation (dotted), and the ideal predictor e"" (dashed).

For comparison we have also given the Bode plots for an ideal predictor esrn'"d,

where

mt p r e d : | ( L l T , t ) z zr+ Llrrt

(8.21)

and a predictor based on differentiation. The predictor based on differentiation has been adjusted to give the same maximum gain as the predictor (8.19). There are differences between the predictors. The ideal predictor has unit gain for all frequencies; the other predictors have higher gains at high frequencies and lower gains at lower frequencies. The predictor (8.19) provides larger phase advance than the predictor based on differentiation, but the phase advance falls off rapidly for higher frequencies.

Design Choices

The choice of the design parameter T4 is a compromise between robustness
and performance. The responsetime is directly given by Ta; fast responsetime requires a small [7. Robustness is governed by the ratio Ta I L.The sensitivity function is given by

e-1

e-tL

1+s"d

Figure 8.12 shows the maximum sensitivity as a function of TalL.Notice that the largest sensitivity has the property M, < 2. To have M, S 1.6 requires Trt ) 0.66L and M, < 7.4 requires Ta ) L.4L. To have a reasonable robustness the desired response time cannot be chosen much shorter than L. lt follows from (8.14) that the largest relative error in the time delay is given by

l ^ r l < Trl

L

L

28I

Chapter 8. Predictiue Control

z

1.8

t.b
\J
1.4

1.2

1

o

o.2 0.4 0.6 0.8

1.2 1.4 1.6 '1.8 2

,,1t"

Figure 8.12 Maximum sensitivity M" for the closed-loopsystemwith the PPI controller (8.16)as a functionof T4f L.

If maximum sensitivities as high as Ms : 2 are allowed and if the time delay is known precisely it is possible to allow smaller ratios TalL.
For well-damped systems the integrated error IE is a performance measure that is easy to compute. From (8.18), the PPI controller in time domain is

u ( t )- T l f t l f t Ete(t)

+ En

J oe @ a-t

,;,

Jr@(,)

u ( t-

L))dt.

(8.22)

To compute the integral error for the PPI controller it will be assumed that the system is initially at rest and that a load disturbance in the form of a unit step is applied to the process input. Since the controller has integral action, we have u(oo) - 1. Therefore,

f6
J,

@ U )-

u ( t-

L ) ) d t-

L.

After a unit load disturbance, it follows from (8.22) that

u ( c c-)u ( 0 ) -=1r- : i

Krrr,

[Jo

e\t)dt-

L n

The integral error thus becomes

IEPPT: Kp(L 1Ta).
The integrated error consists of two terms. The first term, KoL, is due to the time delay and cannot be influenced by the controller. The second term, KpT,t, may be made small by specifying a short closed-looptime constant ?"7. A small value of T"1will, however, result in poor robustness.
It is interesting to compare the performance of the PPI controller with the performance of PID controller. In Section 4.9, it was shown that the integral error for a PID controller is
Ti1 I Epli :
Kki

282

8.5 Predictors for Integrating Processes
la
V

Figure 8.13 Modified smith predictor for integrating processes.
It follows from (7.7) that a PID controller for delay-dominated processestuned for M, - r. has kiKoL - 0.5. This gives I E - zKpL,which is cl,oseto the value I E - 2.4KpL obtained for the PPI controller. W" thns obtain the conclusion that the PPI controller does not give significantly better performance at load disturbances than a PI controller if both controllers have the same robustness. The main advantage of the PPI controller is its ability to improve set-point responses;see Figure 8.8.

8.5 Predictorsfor Integratingprocesses

The basic Smith predictor has useful properties, but it also has some severe drawbacks. It cannot be used for unstable systems, and it gives a steady-state error for load disturbances for processeswith integration. Several modifications have therefore been proposed.

For processes with integration it has been suggested to modify the Smith predictor, as shown in Figure 8.13, in order to obtain zero steady-state error for a constant load disturbance. The reason for the modification can be understood from the principle of internal model control. The sign al d, that is fed back is an estimate of the load disturbance.

From Figure 8.13 the transfer functions from set point xr

a1$

distur-

foad

' ,:

iiti:"*;1r ,

28s

:, I

Chapter B. Predictiue Control

Figure 8.14 Modified Smith predictor for integrating processes.

bance d to output y are given by

Y

P C o ( 7+ K P )

1 + Co(Po-

P) + P(K

+ KCoPoa

Ysp
Co)

+

1+

P ( 1+ C o ( & - P l l Co(Po- P) + P(K -t KCsPs 1

D. Co)

(8.23)

When s --+0, the following approximations hold:

bK C oo
?

Po- P*;(1-e-'r)x

K,L.

If we also assume that F : P, it can be shown that the transfer function between .yspand y becomes one, and the transfer function between d and y becomeszero when s --+0.
Another modification for integrating processesis given in Figure 8.14. The variable 3lpis an estimate of the undelayed measurement signal

Y-Po(U+D).

The estimation is given by
Yp: Po(U+ K(Y - Yll

When 4 i. stable, the value K : 0 can be used, corresponding to the original
Smith predictor. For integrating processes,it is, however, necessary to have
K+0.

284

8.6 Model Predictiue Control

From Figure 8.14 the transfer functions from set point y' and load disturbance d to output y are given by

Y-

l+KP

PCo(r+ K P)

*Po -P+

Ysp
PCo(l+KPo)

,-T

p(r+Kp+&-r;

D.

I+KP *Po -P+PCo(1 +KPo)

(8.24)

Under the assumption that i': P, it can be shown that the transfer func-
tion between ysp and y becomesone, and the transfer function between d and y becomeszero when s --+0.

8.6 ModelPredictiveControl
Model predictive control is based on the prediction of future process behavior based on a process model and optimizaLion of the process behavior over a finite time horizon. Feedback is obtained by applying the initial part of the control signal and repeating the process over a shifted time horizon. This procedure is called receding horizon control or mouing horizon control. Referring to Figure 8.15 the algorithm can be described as follows:
1: Develop a processmodel.
2: Consider the situation at time f . Past process inputs u and past process outputs y are observed;seeFigure 8.15.The future behavior of the process is predicted under the assumption that the processmodel and the future control signals uf : u(t), t I r < t + t6 are known.
3: The control signal u1 is determined to give the desired future behavior.
4: The initial part of control signal uy is applied over the interval ft,t + hl.
5: Change time to f * h, and repeat the procedure from Step 2.
The steps can be performed in many different ways, and there are a large number of algorithms. Different process models can be used; physical models, input-output models, and state models. The method can be applied both to single-input single-output systems and to systems with many inputs and many outputs.
The desired behavior can be specified in many ways. A common procedure is to specify the desired future behavior by a mathematical model, for example, one that tells how to approach the set point. The deviation from the desired behavior can be formulated as an optimization problem to minimize the deviation between actual and desired behavior, possibly with a penalty on control actions. Step 2 is an open-loopoptimization problem where optimization is carried out over a finite time horizon. Feedback is obtained by only applying the initial part of the control signal. The horizon is then shifted forward, and the optimization is then repeated.
285

Chapter 8. Predictiue Control
Past +-
-
+l
+)
a a 0) !

Future
______-_____>

Time

-

d

|

-

-l

a

I

a

ti

fime t
Figure 8.15 Illustration of the model predictive control.

Model predictive control is particularly simple for sampled systems where the control signal is constant over the sampling intervals. Parameter h canthen be chosen as the sampling interval, and the prediction horizon /7, is typically chosen as a small number of sampling intervals. Most predictive controllers are also developed for sampled systems.
A very useful property of model predictive control is that constraints on the control signal and the process output can be taken into account. A common choice is to formulate the problem so that efficient algorithms for quadratic programming can be used. A key difficulty with model predictive control is to ensure stability when the prediction horizon is finite. Much research has been devoted to this problem.

A Simple Example
To illustrate the ideas we will give details in a simple case.Consider the sampled process model

y ( t ) + a t y ( t - h ) + . . . * a nt ( t - n h ) - b p ( t - h ) + b 2 u ( t- z h ) + . . . + b , u ( t - n h ) ,
(8.25) where y is the process output and u the process input. Consider the situation at time /. The past behavior is completely characterized by

/ , : ( y ( t ) y, ( t - h ) , .. . , u ( t - h ) , u ( t- 2 h ) , . . . ) .

(8.26)

Using the model it is straightforward to predict future values of process output

286

8.6 Model Predictiue Control

as a function of current and future control signals: L I t: ( u ( t ) , u ( +t h ) , .. . , u ( t+ N h ) ) .

(8.27)

The desired future behavior can be characterized by specifying a reference trajectory for future process outputs, as indicated in Figure 8.15 and giving a loss function that penalizes deviations e(t) - y(t) - ta(t) from the desired output ya(t) and the increments of the control actions Lu(t) : u(t) - u(t - h)
r+N
J ( u ( t ) , u (+t h ) , ... , u ( t + N h ) ) : t e ( t+ t z h )+2 p ( L , u (+t ( k- I ) h ) ) ' . ( 8 . 2 8 )
k:r
There may also be constraints on processinputs and outputs and on the increment of the control signal.
Future control signals A1 vre then computed by minimizing J subject to the constraints. The control signal u(t) is then applied, and the whole procedure is repeated. The control signal is a function of past inputs and past outputs
u ( t ) - - F ( y ( t ) ,y ( t - h ) ,. . . , y ( t - n h ) , u ( t - h ) ,y ( t - 2 h ) , .. . , u ( t - n h ) ) ,

where the function F is obtained implicitly by solving an optimization problem. A particularly simple case is when the process model is of first order in the
increments of process inputs and outputs, which we illustrate by an example.

Exelaplp 8.4-MPC pon Fmst-OnonR Svsmvt Let the process model be

Ly(t + h) - -aLy(t) + ba,u(t),

where Ay(t) : y(t) - y(t - h) and Au(t) : u(t) - u(t - h). Let the desired

trajectory be a signal ya(t) which starts at y(t) and approaches the set point

Jsp xponentially with time constant 7"1. The desired process output at time

t+histhen

y a (t + h ) : y (t) + (l - n-nt," ,)(l ,o - y(r)).

Assuming that there are no penalties on the control actions the desired process output can then be achieved in the next sampling period. Equating y(t + h) with ya(t + h) gives

y(t+h): y(t)+Ly(t+h) : y(t) -aLy(t)+bA,u(t) : y(t)+(r-e-ht'*)lr,o-y(t)).

Solving this equation for Lu(t) gives

Lu(t):

|-

e-hlr'l
u

( J , o - y Q ) ) * iao t ! ) .

which is a PI controller with gains

k-9b
o, i : 1 - e-hlT"' b

287

Chapter 8. Predictiue Control

Notice that the proportional gain only depends on the process model and that

the integral gains depend on the desired response rate 7,1.

I

It is straightforward to deal with systems having many inputs and outputs. It is also possible to include constraints. There are many special cases and variants of model predictive control. A few of them will be discussed briefly; for more details we refer to the references.

The Dahlin-Higham Algorithm
One of the earliest model predictive controllers was developed for control of paper machines. The algorithm is based on a process model in terms of the FOTD model
P(s:) #r'1,
and the desiredresponseto set-pointchangesis given by

G rYr "s^p-

-J-.n-.',t I + sT"1

Assuming that the control signal is constant over sampling intervals of length h - Lln, where n is an integer, gives the sampled process model

y(t + h) : ay(t) + Kp(r - a)u(t - nh).

The desired response to set points is given by the difference equation y d (t + h ) : a a ta (r) + ( r - oa)y,o(t- nh1.

Introducing the backward shift operator q-1 defined by

q-t y(t) - y(t - h),

(8.29)

the process model can be written as

K^n-@-t)

y(t):

u(t):P(q-')"(t).

Let the controller be characterized by u(t) - C(q-')(y,r(t) - y(r)).
The input-output relation for the closed-loopsystem is then
v(t)-ffiv,p(t).

Using the backward shift operator the desired response is given by

v

a, ,?\

)

:

(J-
ffi'

o

a

)

q

-

(

n

*

r)
v

,

p, .(\

t-)

Ga(q-')v,r(t).

288

8.6 Model Predictiue Control

where ad : e-hlr"'. Equating this with the process output gives

P(q-t)C(q-') @:rrd\q

_

n

, / ^ - 1)\:_

( r - a a ) q - ( " +t ) .
1_ooUt

Solving this equation with respect to C(q-l) gives

C. \(r q - t' 1 :

Go@-\
P(q-t)(f-Ga@-t))

-

(I-oa)(L-oq-')

KoG - aae-7 - (1 - a6)q-(n+t)1'

The controllercan then be describedby

u ( t ) - -I--fr! @ Q ) - a e ( t- h ) ) + a d u ( t- h ) + ( r - a a ) u ( t- ( n + r ) h ) . nD

This controller has integral action, and past inputs are used for prediction.

Dynamic Matrix Control (DMC)

In dynamic matrix control the processis modeled by the finite impulse response

model

y ( t ) - b p ( t - h ) + b 2 u ( -t 2 h ) + . . + b , u ( t- n h ) ,

(8.30)

and the criterion is to minimize the lossfunction

J ( u ( t ) , u (+t h ) , ... , u ( t+ ( n- L ) h ) )- t e 2Q+ k h ) ,

where
e ( t+ h h ) - y a ( t + l r h )- bp ( t + l e h- h ) + b 2 u ( t+ k h - 2 h ) + . . . + b , u ( t + k h - n h ) .
Since e is a linear function of future control variables and the loss function is quadratic the optimization is straightforward. Notice that the model (8.30) also holds if there are many inputs and outputs. The coefficients b; are then matrices. They were called dynamic matrices since they reflect the dynamics of the response in the original paper, which motivated the name DMC. In standard control terminology the parameters are simply the coefficients of the impulse response. In the early use of dynamic matrix control it was common practice to determine the matrices b; from a simple impulse or step response measurement.
A drawback with DMC is that a large number of parameters may be required if the process dynamics are slow. The DMC algorithm was later generalized to QDMC (Quadratic Dynamic Matrix Control), which also can handle constraints on the control signal.
Minimum Variance Control
The minimum variance controller is a predictive controller for systems with random disturbances where the criterion is to minimize the variance of the tluctuations in processoutput. The algorithm was originally developedfor conlrol of paper machines where the stochastic nature of the disturbances is as :mportant as the process dynamics. We start by a simple example.

289

Chapter 8. Predictiue Control

Exaupln 8.5-MTmMUM VenmNcp CoNrnol Consider a model
v(t + h) : -av(t) + bu(t)+ e(t+ h) + ce(t),

where u is the control variable, y the process output, and e a sequence of

independent random variables with zero mean value and standard deviation

o. The sampling period is h.

Consider the situation at time /. The process output y(r) is known and the

output at time tlh can be given arbitrary values by choosing the control signal

a(t). The random signal e(t + h) is independent of past inputs and outputs

/s glven by (8.26). Furthermore, e(t) can be computed from past inputs and

outputs /t. The control law that minimizes the deviation from the set point

/rp is given bY

u (t), b-- a Y(t) - ce(t)

If this control law is used we find that y(t) : e(t), which means that the output

is white noise. The computation of e(t) from past inputs is thus trivial, and the

control law becomes

It) --

a

_
u

c

ttt).

T

In the general case,the processmodel is

o(q-') v (t) : b(q-t)"(t) * t(q-t) u(t).

(8.31)

where u is the process input, y the process output, and e is a sequence of independent Gaussian random variables with zero mean and variance o.a(q-L), b(q-t), and c(q-l) are polynomials in the backward shift operator

a.@-\ - 1* ate-r +ozq-' +... *ane-n b(q-') - bq-t I b+tq-r-l + . . . * bne-" c@-1) - 1 * cte-r + cze-z+ ... * cne-n.

For simplicity we have chosen to let all polynomials be of the same degree. This is no lack of generality because we can allow trailing coefficients to be zero. The coefficient bz is the first non-vanishing coefficient in the polynomial b(q-t). The number (.is an important parameter called the input-output delay, and we also introduce the polynomial b'(q-t) : qtb(q-r).
It is natural to assume that there are no factors common to all three polynomials a(q-t), b(q-'), and c(q-r). The polynomial c(q-\) is assumed to have all its zeros outside the unit disc. The model (8.31) captures the dynamics both of the process and its disturbances.
Minimum variance control is closely related to prediction, and we will therefore first determine a predictor for the process output when the input u is zero. The prediction of y (. steps ahead is given by

,(q-')y(t + () - s@-\ y(t),

290

8.7 Summary

where the polynomial g(q-r) is given by

o(q-') f (q-t) + q-' s(q-r) - c(q-1).

Notice that the dynamics of the predictor are given by the polynomial c(q-1) in the model (8.31). The prediction error

e(r): f(q-')r(t)

has the variance

I_1
E2- o'\fi.

(8.32)

The simple minimum variance control stratery is given by

u,(.t\ ):

-{s-( q - l ) y,(.t,)-

- g(s-t ) F6i;qy?),

..

(8.33)

and the control error is

y(t) : f (q-')n(t).

(8.34)

The error under minimum variance control is thus equal to the error in predict-
ing the output I steps ahead. The control error is a moving average of order (. - l. It is thus easy to determine if a process is under minimum variance
control simply by computing the correlation function of the output. Since the control error is a moving average of order (.- I its covariance function is zero for all lags greater than (..
The robustness of minimum variance control is strongly influenced by the choice of sampling interval. It is good practice to choose hLarger than Ll2.

8.7 Summary
The performance of a PI controller can be improved by adding predictive capability. Derivative action is one possibility, but there are many other alternatives. The Smith predictor and model predictive control are useful for systems with time delays when good models are available. Drastic improvements in the response to set-point changes can be obtained when good models are available. The predictive PI controller is a simple version of the Smith predictor. It has the advantage over a PID controller that the achievable phase advance is larger. A paradox is that the predictive controller only gives modest improvements compared to PI controllers for processeswith delay-dominated dynamics but the performance improvements can be significant for lag-dominated processes. Model predictive controllers are more general than Smith predictors, and they can also deal with systems having many inputs and many outputs. Constraints can also be taken into account.
Since predictive controllers are based on mathematical models it is important that the models are accurate. It is particularly important to have a good estimate of the time delay. A fairly complete robustness analysis was given
29r

Chapter B. Predictiue Control
for the Smith predictor. Similar results are available for other predictive controllers. The key result is that sensitivity to modeling errors is closely related to the parametet a6L, where @6rs the closed-loopbandwidth or LlTa where T4 is the desired closed-loopresponse time when time delay L is neglected. Robustness required that both parameters are not too small. A reasonable rule of thumb is that the parameters should be larger than 0.5.
8.8 Notesand References
A controller for systems having time delay was proposed by [Smith, 1957]; it is also treated in the book [Smith, 19581.An explanation of the mechanism that generates the large phase advance is given in [Astrdm, Lg77l. Many modifications of the Smith predictor have been presented; see [Astrtim et al., 1994; Matausek and Micic, 1996; Matausek and Micic, 1999; Kaya and Atherton, 1999; Kristiansson and Lennartson, 1999]. The controller in [Haalman, 1965], the PPI controller in [Hiigglund, 1996], and the PIDr controller in [Shinskey, 20021are all special casesof the Smith predictor. The papers [Ross, L977; Meyer et al., 1976; Ingimundarson and Hiigglund, 2002] compare Smith predictors with PID controllers.
Minimum variance control was developed in the early phase of computer control of paper machines as an attempt to find a control stratery that minimizes fluctuations in quality variables. A key result is that the smallest variance that can be achieved is the variance of the error in predicting the output over the time delay of the process. Minimum variance control was first published by [Astr0m, 1967] and a perspective on its use is given in [Astrtim, 2001]. Minimum variance control requires a model of disturbances and process dy-
namicsA. methodto obtainthis informationdirectlyfromprocesesxperiments
was developed in [Astrdm and Bohlin, 1965] and applied to modeling and control of paper machines [Astrcim, 1970]. The self-tuning controller [Astrdm and Wittenmark, 19731can be viewed as automation of system identification and minimum variance control.
The controller presented in [Dahlin, 1968] and [Higham, 1968] can be viewed as a discrete-time version of the Smith predictor. Both the Smith Predictor and the Dahlin-Higham controller, which are early versions of model predictive control [Shinskey, 1991b], were first developedfor processcontrol applications. There are many versions of model predictive control; see [Richalet et a1.,1976], [Cutler and Ramaker, 19801and [Garcia and Morshedi, 1986]. There are several recent books on model predictive control [Allgower and Zheng, 2000; Kouvaritakis and Cannon, 2001; Maciejowski, 20021.The survey papers [Rawlings, 2000; Qin and Badgwell, 20031contain many references.The papers [Kulhavy et a1.,20011, [Downs, 2001] and [Young et a]., 20011and the book [Blevins et a1.,2003] give an industrial perspective. Although model predictive control was originally intended for multi-variable systems it has also been suggested to use it as a replacement for PID control; see [Lu, 2004]1.
292

Automatic Tuning and Adaptation
9.1 Introduction
Automatic tuning, or auto-tuning, is a method where the controller is tuned automatically on demand from a user. Tlpically, the user wiii either push a button or send a command to the controller. Automatic tuning of PID controllers can be accomplished by combining the methods for determining process dynamics, described in Chapter 2, with the methods for computing the parameters of a PID controller, described in Chapters 4, 6, and 7. An automatic tuning procedure consists of three steps:
o Generation of a process disturbance. r Evaluation of the disturbance response. . Calculation of controller parameters. This is the same procedure that an experienced engineer uses when tuning a controller manually. The process must be disturbed in some way in order to determine the process dynamics. This can be done in many ways, e.g., by adding steps, pulses, or sinusoids to the process input. The evaluation of the disturbance response may include a determination of a process model or a simple charactertzation of the response. Industrial experience has clearly shown that automatic tuning is a highly desirable and useful feature. Automatic tuning is sometimes called tuning on demand or one-shot tuning. Commercial PID controllers with automatic tuning facilities have been available since the beginning of the eighties. Automatic tuning can be built into a controller. It can also be performed using external devices that are connected to the control loop only during the tuning phase. Controller parameters are displayed when the tuning experiment is finished. Since the tuning devices are supposed to work together with controllers from different manufacturers, they must be provided with a lot of information about the controller in order to give an appropriate parameter suggestion.
293

Chapter 9. Automatic TLning and Adaptation
Even when automatic tuning devices are used, it is important to obtain a certain amount of processknowledge. This is discussedin the Section9.2. Automatic tuning is only one way to use the adaptive technique. Section 9.3 gives an overview of several adaptive techniques, as well as a discussion about their use. The automatic tuning approaches can be divided into two categories, namely, model-based approaches and rule-based approaches. In the model-based approaches, a model of the processis obtained explicitly, and the tuning is based on this model. Section 9.4 fueats approaches where the model is obtained from transient response experiments, frequency response experiments, and parameter estimation. In the rule-based approaches, no explicit process model is obtained. The tuning is instead based on rules similar to those rules that an experienced operator uses to tune the controller manually. The rule-based approach is treated in Section 9.5. Section 9.7 treats iterative feedback tuning, which is an iterative method to tune the controllers.
A few industrial products with adaptive facilities are presented in Section 9.8. This section illustrates how some of the ideas are used in products. It is not intended as an exhaustive presentation of products. The chapter ends with conclusions and references in Sections 9.9 and 9.10.
9.2 ProcessKnowledge
In this chapter we will discuss several methods for automatic tuning. Before going into details we must remark that poor behavior of a control loop can not always be corrected by tuning the controller. It is absolutely necessary to understand the reason for the poor behavior.
The processmay be poorly designed so that there are long dead times, long time constants, nonlinearities, and inverse responses. Sensors and actuators may be poorly placed or badly mounted, and they may have bad dynamics. T}lpical examples are thermocouples with heavy casings that make their response slow or on-off valve motors with long travel time. Valves may be over-sized so that they only act over a small region. The sensor span may be too wide so that poor resolution is obtained, or it may also have excessivesensor noise.
There may also be failure and wear in the process equipment. Valves may have excessivestiction. There may be backlash due to wear. Sensors may drift and change their properties because of contamination.
If a control loop is behaving unsatisfactorily, it is essential that we first determine the reason for this before tuning is attempted. It would, of course, be highly desirable to have aids for the process engineer to do the diagnosis. Automatic tuning may actually do the wrong thing if it is not applied with care. For example, consider a control loop that oscillates because of friction in the actuator. Practically all tuning devices will attempt to stabilize the oscillation by reducing the controller gain. This will only increase the period of the oscillation! These important questions are treated in a separate chapter in this book, Chapter 10. Remember that no amount of so called "intelligence" in equipment can replace real process knowledge.
294

9.3 Adaptiue Techniques

9.3 AdaptiveTechniques

Techniques for automatic tuning grew out of research in adaptive control. Adaptation was originally developed to deal with processeswith characteristics that were changing with time or with operating conditions. Practically all adaptive techniques can be used for automatic tuning. The adaptive controller is simply run until the parameters have converged, and the parameters are then kept constant. The drawback with this approach is that adaptive controllers may require prior information. There are many special techniques that can be used. Industrial experience has shown that automatic tuning is probably the most useful application of adaptive techniques. Gain scheduling is also a very effective technique to cope with processes that change their characteristics with operating conditions. An overview of these techniques will be given in this section. In this book the phrase adaptiue techniqueswill include auto-tuning, gain scheduling, and adaptation.

Adaptive Control
An adaptive controller adjusts its parameters continuously to accommodate changesin processdynamics and disturbances. Adaptation can be applied both to feedback and feedforward control parameters. It has proved particularly useful for feedforward control. The reason for this is that model fidelity is crucial for feedforward control. Adaptive control is sometimes called continuous adaptation to emphasize that parameters are changed continuously.
There are two types of adaptive controllers based on direct and indirect methods. In a direct method, controller parameters are adjusted directly from data in closed-loopoperation. In indirect methods, the controller parameters are obtained indirectly by first updating a process model on line, and then determining the controller parameters from some method for control design. The model reference system is a direct adaptive controller. The self-tuning regulator can be implemented both for direct and indirect control. There is a large number of methods available both for direct and indirect methods. They can conveniently be described in terms of the methods used for modeling and control design.
A block diagram of an indirect adaptive controller is shown in Figure 9.1. There is a parameter estimator that determines the parameters of the model based on observations of process inputs and outputs. There is also a design block that computes controller parameters from the model parameters. If the system is operated as a tuner, the process is excited by an input signal. The parameters can either be estimated recursively or in batch mode. Controller parameters are computed, and the controller is commissioned. If the system is operated as an adaptive controller, parameters are computed recursively, and controller parameters are updated when new parameter values are obtained.

AutomaticTuning

t

By automatic tuning (or auto-tuning) we mean a method where a controller

1

.I

is tuned automatically on demand from a user. Tlpically, the user will either

push a button or send a command to the controller. Industrial experience has

clearly indicated that this is a highly desirable and useful feature. Automatic

295

Chapter 9. Automatic Tfuning and Adaptation

i Self-tuninsrezulator
t"

Specifications

Parameter estimates

Controller design
Controller parameter
Controller

Parameter estimation
I
I

Figure 9.1 Block diagram of an adaptive controller.
tuning is sometimes called tuning on demand or one-shot tuning. Auto-tuning can be built into the controllers. Practically all controllers can benefit from tools for automatic tuning. This will drastically simplify the use of controllers. Single-loop controllers and distributed systems for process control are important application areas. Most of these controllers are of the PID type. Automatic tuning is currently widely used in PID controllers.
Auto-tuning can also be performed with external devices that are connected to a process.Since these systems have to work with controllers from different manufacturers, they must be provided with information about the controller structure in order to give an appropriate parameter suggestion. Such information includes controller structure (standard, series, or parallel form), sampling rate, filter time constants, and units of the different controller parameters (gain or proportional band, minutes or seconds,time or repeats/time).
Gain Scheduling Gain scheduling is a technique that deals with nonlinear processes,processes with time variations, or situations where the requirements on the control change with the operating conditions. To use the technique it is necessary to find measurable variables, called scheduling variables, that correlate well with changesin processdynamics. The scheduling variable can be, for instance, the measured signal, the control signal, or an external signal. For historical reasons the phrase gain scheduling is used even if other parameters than the gain, e.g., derivative time or integral time, are changed. Gain scheduling is a very effective way of controlling systems whose dynamics change with the operating conditions. Gain scheduling has not been used much because of the effort required to implement it. When combined with auto-tuning, however, gain scheduling is very easy to use.
A block diagram of a system with gain scheduling is shown in Figure 9.2. The system can often be viewed as having two loops. There is an inner loop, composed of the process and the controller, and an outer loop, which adjusts the controller parameters based on the operating conditions. There are also
296

ES
'ol
.r)' ell ce. cal the lis the the )\'er,
9.2. looP, lusts ' also

Controller parameters
Controller

9.3 Adaptiue Techniques
Scheduling variable

Figure 9.2 Block diagr:am of a system with gain scheduling.
situations when there is no outer loop, and the scheduling variable is unaffected by the controller output.
The notion of gain scheduling was originally used for flight control systems, but it is being used increasingly in process control. It is, in fact, a standard ingredient in some single-loop PID controllers. For processcontrol applications significant improvements can be obtained by using just a few sets of controller parameters.
Gain scheduling is often an alternative to adaptation. It has the advantage that it can follow rapid changes in the operating conditions. The key problem is finding suitable scheduling variables. Possible choicesare the control signal, the process variable, or an external signal. Production rate is often a good choice in process control applications, since time constants and time delays are often inversely proportional to production rate.
Development of a schedule may take a substantial engineering effort. The availability of automatic tuning can significantly reduce the effort because the schedules can then be determined experimentally. A scheduling variable is first determined. Its range is quantified into a number of discrete operating conditions. The controller parameters are then determined by automatic tuning when the system is running in one operating condition. The parameters are stored in a table. The procedure is repeated until all operating conditions are covered. In this way it is easy to install gain scheduling into a computercontrolled system by programming a table for storing and recalling controller parameters and appropriate commands to accomplish this.
Uses of Adaptive Techniques
We have described three techniques that are useful in dealing with processes that have properties changing with time or with operating conditions. In Figure 9.3 is a diagram to guide in choosing the different adaptive techniques.
Controller performance is the first thing to consider. If the requirements are modest, a controller with constant parameters and conservative tuning can be used. With higher demands on performance, other solutions should be considered. If the process dynamics are constant, a controller with constant parameters should be used. The parameters of the controller can be obtained using auto-tuning.
If the process dynamics or the nature of the disturbances are changing, it
297

Chapter 9. Automatic Tfu.ningand Adaptation

Varying

Use a controller with varying parameters

Use a controller with constant parameters

Unpredictable variations

Predictable variations

Use an adaptive controller

Use gain scheduling

Figure 9.3 When to use different adaptive techniques.

is useful to compensate for these changes by changing the controller. If the variations can be predicted from measured signals, gain scheduling should be used because it is simpler and gives superior and more robust performance than the continuous adaptation. Tlpical examples are variations caused by nonlinearities in the control loop. Auto-tuning can be used to build up the gain schedules.
There are also cases where the variations in process dynamics are not predictable. Tlpical examples are changes due to unmeasurable variations in raw material, wear, fouling, etc. These variations cannot be handled by gain scheduling, since no scheduling variable is available, but must be dealt with by adaptation. An auto-tuning procedure is often used to initialize the adaptive controller. It is then sometimes called pre-tuning or initial tuning.
Feedforward control deserves special mentioning. It is a very powerful method for dealing with measurable disturbances. Use of feedforward control, however, requires good models of process dynamics. It is difficult to tune feedforward control loops automatically on demand, since the operator often cannot manipulate the disturbance used for the feedforward control. To tune the feedforward controller it is necessary to wait for an appr.opriate disturbance. Adaptation, therefore, is particularly useful for the feedforward controller.

9.4 Model-BaseMd ethods
This section gives an overview of automatic tuning approaches that are based on an explicit derivation of a process model. Models can be obtained in many
298

9.4 Model-Based Methods
ways, as seenin Chapter 2. In this section we discussapproachesbased on transient responses,frequency responses,and parameter estimation. The methods can also be characterized in terms of open and closed loop methods.
Transient Response Methods
Auto-tuners can be based on open-loop or closed-looptransient response analysis. Methods for determining the transient response were discussed in Section 2.7. The most common methods are based on step or pulse responses,but there are also methods that can use many other types of perturbations.
Open-Loop Tt^cning A simple process model can be obtained from an openloop transient response experiment. A step or a pulse is injected at the process input, and the response is measured. To perform such an experiment, the process must be stable. If a pulse test is used, the process may include an integrator. It is important that the processbe in equilibrium when the experiment is begun.
There are only one or two parameters that must be set a priori, namely, the amplitude and the signal duration. The amplitude should be chosen sufficiently large so that the response is easily visible above the noise level. On the other hand, it should be as small as possible in order not to disturb the process more than necessary and to keep the dynamics linear. The noise level can be determined automatically at the beginning of the tuning experiment. However, even if the noise level is known, we cannot decide a suitable magnitude of a step in the control signal without knowing the gain of the process. Therefore, it must be possible for the operator to decide the magnitude.
The duration of the experiment is the second parameter that normally is set a priori.If the processis unknown, it is very difficult to determine whether a step response has settled or not. An intuitive approach is to say that the measurement signai has reached its new steady state if its rate of change is sufficiently small. The rate of change is related, however, to the time constants of the process,which are unknown. If a pulse test is used, the duration of the pulse should also be related to the process time constants.
Many methods can be used to extract process characteristics from a transient response experiment. Most auto-tuners determine the static gain, the apparent time constant, and the apparent dead time. The static gain is easy to find accurately from a step-response experiment by comparing the stationary values of the control signal and the measurement signal before and after the step change. The time constant and the dead time can be obtained in several ways, see Section 2.7.
The transient response methods are often used in a pre-tuning mode in more complicated tuning devices.The main advantage of the methods, namely, that they require little prior knowledge, is then exploited. It is also easy to explain the methods to plant personnel. The main drawback with the transient responsemethods is that they are sensitive to disturbances. This drawback is less important if they are used only in the pre-tuning phase.
Closed-Loop Tfu,ning Automatic tuning based on transient response identification can also be performed in closedloop. The steps or pulses are then added
299

Chapter 9. Automatic TLning and Adaptation
Figure 9.4 The relay auto-tuner. In the tuning mode the process is connected to relay feedback.
either to the set point or to the control signal. There are also auto-tuners that do not introduce any transient disturbances. Perturbations caused by set-point changes or load disturbances are used instead. In these casesit is necessaryto detect that the perturbations are sufficiently large compared to the noise level.
Closed-loop tuning methods cannot be used on unknown processes.Some kind of pre-tuning must always be performed in order to close the loop in a satisfactory way. On the other hand, they do not usually require any additional a priori information. The magnitude of the step changes in set point are easily determined from the desired, or accepted,change in the measurement signal.
Since a proper closed-loop transient response is the goal for the design, it is appealing to base tuning on closed-loopresponses. It is easy to give design specifications in terms of the closed-looptransient response,e.g., damping, overshoot, closed-looptime constants, etc. The drawback is that the relation between these specifications and the PID parameters is normally quite involved. Heuristics and logic are required therefore.
FrequencyResponseMethods
There are also auto-tuners that are based on frequency response methods. In Section 2.7, it was shown how frequency response techniques could be used to determine process dynamics.
Use of the Relay Method In traditional frequency response methods, the transfer function of a processis determined by measuring the steady-state responsesto sinusoidal inputs. A difficulty with this approach is that appropriate frequencies of the input signal must be chosena priori. A special method, where an appropriate frequency of the input signal is generated automatically, was described in Section2.7. The idea was simply to introduce a nonlinear feedback of the relay type in order to generate a limit cycle oscillation. With an ideal relay the method gives an input signal to the processwith a period closeto the ultimate frequency of the open-loop system.
A block diagram of an auto-tuner based on the relay method is shown in Figure 9.4. Notice that there is a switch that selects either relay feedback or ordinary PID feedback.When it is desired to tune the system, the PID function is disconnected and the system is connected to relay feedback control. The system then starts to oscillate. The period and the amplitude of the oscillation is determined when steady-state oscillation is obtained. This gives the ultimate
300

9.4 Model-Based Methods
period and the ultimate gain. The parameters of a PID controller can then be determined from these values. The PID controller is then automatically switched in again, and the control is executed with the new PID parameters.
The initial amplitude of the relay must be specified in advance. A feedback loop from measurement of the amplitude of the oscillation to the relay amplitude can be used to ensure that the output is within reasonable bounds during the oscillation. It is also useful to introduce hysteresis in the relay. This reduces the effects of measurement noise and also increases the period of the oscillation. With hysteresis there is an additional parameter. This can be set automatically, however, based on a determination of the measurement noise level. Notice that there is no need to know time scalesa priori since the ultimate frequency is determined automatically from the experiment.
In the relay method, an oscillation with suitable frequency is generated by a static nonlinearity. Even the order of magnitude of the time constant of the process can be unknown. Therefore, this method is not only suitable as a tuning device; it can also be used in pre-tuning. It is also suitable for the determination of sampling periods in digital controllers.
The relay tuning method also can be modified to identify several points on the Nyquist curve. This can be accomplished by making several experiments with different values of the amplitude and the hysteresis of the relay. A filter with known characteristics can also be introduced in the loop to identify other points on the Nyquist curve.
On-Line Methods Frequency response analysis can also be used for on-line tuning of PID controllers. By introducing bandpass filters, the signal content at different frequencies can be investigated. From this knowledge, a process model given in terms of points on the Nyquist curve can be identified and tracked on line. In this auto-tuner the choice of frequencies in the bandpass filters is crucial. This choice can be simplified by using the tuning procedure described above in a pre-tuning phase.
Parameter Estimation Methods
A common tuning procedure is to use recursive parameter estimation to determine a low-order discrete time model of the process. The parameters of the low-order model obtained are then used in a design scheme to calculate the controller parameters. An auto-tuner of this type can also be operated as an adaptive controller that changes the controller parameters continuously. Auto-tuners based on this idea, therefore, often have an option for continuous adaptation.
The main advantage of auto-tuners of this type is that they do not require any specific type of excitation signal. The control signal can be a sequence of manual changes of the control signal, for example, or the signals obtained during normal operation. A drawback with auto-tuners of this type is that they require significant prior information. A sampling period for the identification procedure must be specified; it should be related to the time constants of the closed-loopsystem. Since the identification is performed on line, a controller that at least manages to stabilize the system is required. Systems based on
301

Chapter 9. Automatic Tl^tning and Adaptation

Table 9.1 Rules of thumb for the effects of the controller parameters on speed and stability in the control loop.

Speed Stability

K increases fi increases 74 increases

increases reduces increases

reduces increases increases

this identification proced.ureneed a pre-tuning phase, which can be based on the methods presented earlier in this section.
9.5 Rule-BaseMd ethods
This section treats automatic tuning methods that do not use an explicit model of the process. T[rning is based instead on the idea of mimicking manual tuning by an experienced process engineer.
Controller tuning is a compromise between performance and robustness. Table 9.1 shows how stability and speed change when the PID controller parameters are changed. Note that the table only contains rules of thumb. There are exceptions. For example, an increased gain often results in more stable control when the process contains an integrator. The same rules can also be illustrated in tuning maps. See, for example, the tuning map for PI control in Figure 6.7.
The rule-based automatic tuning procedures wait for transients, set-point changes, or load disturbances in the same way as the model-based methods. When such a disturbance occurs, the behavior of the controlled process is observed. If the control deviates from the specifications,the controller parameters are adjusted based on some rules.
Figures 9.5 and 9.6 show set-point changes of control loops with a poorly tuned PI controller. The response in Figure 9.5 is very sluggish. Here, a correct rule is to increase the gain and to decrease the integral time. Figure 9.6 also shows a sluggish response because of a too large integral time. The response is also oscillatory because of a too high gain. A correct rule, therefore, is to decrease both the gain and the integral time.
If graphs like those in Figures 9.5 and 9.6 are provided, it is easy for an experienced operator to apply correct rules for controller tuning. To obtain a rule-based automatic tuning procedure, the graphs must be replaced by quantities that characterize the responses.Commonly used quantities are overshoot and decay ratio to characterize the stability of the control loop and time constant and oscillation frequency to characterize the speed of the loop.
It is rather easy to obtain relevant rules that tell whether the different controller parameters should be decreased or increased. However, it is more difficult to determine how much they should be decreased or increased. The rule-based methods are, therefore, more suitable for continuous adaptation
302

9.5 Rule-Based Methods
Figure 9.5 A set-point response where a correct rule is to increase the gain and decrease the integral time. The upper diagram shows set-point y* and process output y, and the lower diagram shows control signal u.
Figure 9.6 A set-point response where a correct rule is to decrease the gain and decrease the integral time. The upper diagram shows set point y", and process output y, and the lower diagram shows control signal u.
where rather small successivechanges in the controller parameters are performed after each transient.
The rule-based methods have a great advantage compared to the modelbased approaches when they are used for continuous adaptation, namely, that they handle load disturbances efficiently and in the same way as set-point changes. The model-based approaches are well suited for set-point changes. However, when a load disturbance occurs, the transient response is caused by an unknown input signal. To obtain an input-output processmodel under such circumstances is not so easy.
A drawback with the rule-base approaches is that they normally assume that the set-point changes or load disturbances are isolated steps or pulses.
303

Chapter 9. Automatic Tl"tningand Adaptation
Trvo set-point changes or load disturbances applied shortly after each other may result in a process output that invokes an erroneous controller tuning rule.
9.6 Supervisionof AdaptiveControllers
Automatic tuning and gain scheduling have been well acceptedby the process industry and are now common both in single-station controllers and distributed control systems. There are many well-engineered auto-tuners that are very easy to use. The industrial use of the "true" adaptive controller is, however, more limited. There are several reasons for this. One is that many controllers that have been tested industrially have not been sufficiently robust. This has tarnished the technique with a somewhat bad reputation. The adaptive algorithms must be provided with a supervisory shell that takes care of those operating conditions that the algorithm is not designed for.
The problem is not unique to adaptive controllers. Euery controller needs a supervisory shell. The simple PID controller, .9., has antiwindup functions to treat the situation when the control signal saturates, functions for bumpless transfer at mode switches between manual and automatic control, functions for bumpless transfer at parameter changes, and sometimes dead-zonesand control signal rate limitations. This section discussessome supervisory functions for adaptive controllers.
Initialization
The first topic to consider is the initialization of the adaptive controller. Initialrzation should ensure that suitable controller parameters are used when the adaptation starts. An adaptive controller also requires additional parameters that should be obtained in the initialization phase. For example, the adaptive controllers, both the model based and the rule based, need to know the time scale of the process. It is used to set sampling periods and time constants.
In special-purpose adaptive controllers, the initialization can be performed manually by an experienced user. However, in multi-purpose adaptive controllers, this phase should not be left to unexperienced users. It should be performed automatically. Therefore, almost all industrial multi-purpose adaptive controllers have some kind of automatic tuning or pre-tuning function that initializes the adaptive controller. These procedures may be based on step responseexperiments, which provide the time scaleof the processin terms of the apparent dead time and the apparent time constant. They can also be based on a relay feedback experiment. In this case the time scale of the process is obtained in terms of the ultimate frequency au.
In the following, it is assumed that the time scale of the process has been obtained and is available in the adaptive controller. It is denoted by To.It is also assumed that the design calculations are performed in such a way that 7o also is proportional to the closed-looptime constant. The initialization procedure is not only invoked once when the adaptive controller is installed. Parts of the initialization procedure have to be used at mode transitions and parameter changes too.
304

9.6 Superuision of Adaptiue Controllers

Estimator

BP filter

BP filter

Controller

Figure 9.7 Filtering of control and measurement signals.

An important feature of the initialization procedure is to obtain suitable time constants of filters. Low-frequency components of the signals should be reduced in order to eliminate bias terms. High-frequency components are normally corrupted with measurement noise that disturbs the parameter estimator. Therefore, the control signal and the measurement signal should be band-pass filtered before entering the parameter estimator. See Figure 9.7.
It is important that parameter estimation is based on relevant data. If the model order is low, it is particularly important that the model be fitted to data in a frequency region that is suitable for controller design, namely, the frequency range around the ultimate frequency. This frequency range is determined by the choice of time constants in the band-pass filters. The frequency range can be made narrow or wide, depending on the control objective and the estimated model order. In the ECA600 controller, see Section 9.8, a narrow band-pass filter is used, and a processmodel consisting of only two parameters is identified. Models with more parameters require wider filters.

Excitation Detection
The parameter estimator is the central part of an adaptive controller. A recursive least squares estimator is normally used. This can be described by

e1t1- e(t- 1)+ P(t)rp(t)e(t)

 ( t )- y ( t )- E ( t ) re ( t- t )

P(t)-

P(r-

1)-

P ( t- I ) a @ e @ rP ( t- r ) I + qQ)rP(t - t)q(t) '

(e.1)

where I is the parameter estimates, P is the covariance matrix, and p is the regression vector, which normally contains delayed measurement and control signals. To be able to track variations in process dynamics, it is necessary to rely more on recent data than on older. This is often ensured by introducing a

305

Chapter 9. Automatic Tfuning and Adaptation

forgetting factor ), and modifying the covariance matrix according to

P(t:) i

(rr,- 1)-

Pg
1I I

t ) p (t ) q
a ( t )r4

g):
t

P(t 1)
r ) qG

(e.2)

A forgetting factor in the range 0 < A < 1 prevents the covariance matrix from converging to zero. The choice of 2 is a compromise between adaptation rate and robustness. Decreasing 1will, e.g., result in an increased adaptation rate but also decreased robustness. The introduction of a forgetting factor may cause problems if the excitation is not good enough. Suppose, e.9., that p is zero for a certain period. From Equation 9.2 it then follows that the covariance matrix will increase exponentially. There are ways to overcome this problem, e.9., by using a variable forgetting factor or by using directional forgetting. It has also been proposed to reinitialize the covariance matrix periodically to ensure that P stays within certain bounds. This will surely solve the numerical problem but in such a way that the estimation uncertainty is varying periodically, which is unsatisfactory.
The excitation problem is not only a numerical problem. The problem is also to ensure that the parameter estimator is provided with enough relevant data to produce a reliable process model. There are in principle two solutions to this problem:
1. Ensure that excitation always is present by adding excitation signals to the process input.
2. Ensure that estimation is performed only when there is enough natural excitation of the process.
The first approach might seem appealing. An excitation signal that is so small that it is hardly noticeable compared to the normal measurement noise will not do much harm. Unfortunately, such an excitation is not of much help for parameter estimation. The excitation signal must have a significant amplitude to be of any use. Friction or other nonlinearities may otherwise distort or even eliminate the response from the process output, and the excitation is lost. An excitation signal with a significant amplitude causes degradation of the control, and can therefore only be accepted during short periods such as during an automatic tuning experiment. For these reasons, the first approach is seldom used in industrial controllers. Instead, the second approach is used.
To ensure that estimation is only performed after significant changes in set point or load, when there is enough excitation, a procedure that measures the excitation is needed.
A convenient approach for excitation detection that is similar to the one used in the ECA600 controller will now be described.The basic idea is to make a high-pass filtering of the measurement signal. When the magnitude of the filtered variable exceedsa certain threshold, it is concluded that the excitation is high enough for adaptation. The high-pass filter is given by

Y h' o :

l-Y, s+Ohp

(e.3)

306

9.6 Superuision of Adaptiue Controllers

0.1

-0.1

10

40

Figure 9.8 Excitation detection using high-pass filtering of the measurement signal. The figure shows responsesto a set-point change at t :5 and a load disturbance at t :20.

where Y is the Laplace transform of the processoutput y, and Y6, is the corresponding high-pass filtered signal. The filter has unit gain at high frequencies. The frequency o1o is chosen to be inversely proportional to the process time scale {0.
Figure 9.8 shows a simulation where the measurement signal is passed through the high-pass filter (9.3). From the figure, it is obvious that the output from the high-pass filter is suitable for excitation detection. Excitation is high and adaptation can be initiated when the magnitude of lynpl becomeslarge.
The next problem is to decide when the excitation is so low that the estimation should be interrupted again. One approach is to allow adaptation as Iong as iynrl remains large. A drawback with this approach is that there are delays in the estimator. This means that even if lynol is small, there might still be excitation in the filtered signals in the parameter estimator. A solution to the problem is to simply allow adaptation for a fixed time after excitation has been detected.
LoadDisturbanceDetection
Model-based adaptive controllers have problems with load disturbances. To see this, consider the block diagram in Figure 9.9. The process output y is given by
Y(s)- P(') (t/(') + D(s))* N(s),
rvhere P(s) is the process transfer function, U(r) is the Laplace transform of control signal u, D(s) is the Laplace transform of load disturbance d, and -V(r) is the Laplace transform of measurement noise n.It is assumed that the

307

Chapter 9. Automatic Tining and Adaptation Controller

Figure 9.9 Block diagram of a simple feedback loop.

measurement noise only contains high frequencies and that these are filtered out by the filters in the controller. The noise term is therefore not considered in the sequel. The process output can be decomposedinto two terms,

y(t):y"(t)+ya(t).

(e.4)

where J,, is caused by the control signal and y6 is caused by the load disturbance.

In Equation 9.1, the prediction error in the least-squares estimator is given

by

(t)- y(t)- i(t) : y(t)- q(t)r01t- 11.

(e.b)

The least-squares estimator tries to minimize e(t), i.e., to make the predicted process output i'(r) equal to the true process output y(t). It is implicitly assumed that
y ( t ) - y " ( t ) - r p ( t ) r0 ( r - 1 ) ,

where 0(t) arc the true process parameters. If this assumption is valid, i.e., if y(t) : y"(t), parameter estimates d(/) will converge to the true values e(t), provided that the excitation is sufficient. However, if the process output is given by Equation 9.4, and if ya\) has frequency components in the estimation region, the parameter estimates will not converge to their true values.
This is a very serious problem in process control applications. In process
control, set-point changes are often performed only during production changes. (Exceptions are secondary controllers in cascade configurations.) This means that load disturbances often are the only excitation signals. For rule-based as well as model-based adaptive controllers there are possibilities to obtain useful information provided that the load disturbances come in the form of isolated transients. Such a solution will now be presented.
Figure 9.10 shows the different components of the process output after a step change in the load disturbance. Shortly after the load change, y(t) * ya(t), i.e., the changesin the processoutput are caused by load d only.After a while, the contribution from the control signal z is the dominating component.
A solution to the identification problem is to avoid adaptation during the first phase of the response,where la dominates over yr. Adaptation should be initiated in the second phase where the major excitation in y(r) is caused by the control signal.

308

9.6 Superuision of Adaptiue Controllers

Figure 9.10 The upper diagram shows set point lrp : 0, measurement signal y, its load component y4, and its control signal component yr. The lower diagram shows load
disturbance d and control sisnal u.

To use this solution, a procedure that detects load disturbances is needed. This detection must be fast, so that adaptation is interrupted as quickly as possible. The detection can be done in the following way. First, the control signal is high-pass filtered in the same way as the measurement signal in Equation 9.3:

(

J

h
'

o:

--L-71
s+Qhp

(e.6)

Figure 9.11 illustrates the same experiment as in Figure 9.8, but the highpass filtered value of the control signal is also presented. In the following, it is assumed that the processhas a positive static gain, i.e., P(0) ) 0, and that all zeros are in the left-half plane. After a set-point change, both lnp and u7o then go in the same direction, whereas they go in opposite directions when a load disturbance occurs. This difference can be used to distinguish between set-point changes and load disturbances. In this way, it is possible to delay the adaptation and avoid adaptation during the first phase of the load disturbance response, and perform adaptation only during the second phase.
Another simpler way to avoid adaptation during the first phase of a load disturbance response can be obtained from the prediction error e(/); seeEquation 9.5. The prediction error can be written as

(t)- y(t)- rp(t)er (t- t) : ( y u ( r-) E Q ) rA ( t- 1 ) )+ y a ( t ) .

(e.7)

309

Chapter 9. Automatic Tbning and Adaptation
Figure 9.11 Excitation detection using high-pass filters. The figure shows responses to a set-point change at time t:5 and a load disturbance at time t:20.
Hence, e(/) consists of two terms, the true prediction error that we want to minimize and the load disturbance component of the process output. If we assume that process dynamics change slowly, the first term will remain bounded, and large load disturbances can be detected through the magnitude of le(t)1.If we restrict adaptation to those periods when le(t)l is small, we will be able to track slow variations in the process, and we will also avoid adaptation when ly a( t ) l bec om e sl a rg e . Oscillation Detection Oscillations with a high-frequency content near the ultimate frequency form an ideal excitation for adaptive control if they are caused by set-point variations or high controller gains resulting in small stability margins. In these cases,
v(t)- v"(t).
Unfortunately, oscillations in control loops are normally generated by other sources. A common cause of oscillations is stick-slip motion because of valve friction. See Section 10.2. If no precautions are taken, the adaptive controller will interpret these oscillations as caused by a too high loop gain. This means that the controller will be detuned. This happens both for model-based and rule-based adaptive controllers. Stick-slip motion can be modeled as a load disturbance.
Another reason for oscillations in control loops might be that an external oscillating load disturbs the process. This disturbance may, e.g., be caused by a neighboring control loop with stick-slip motion.
In these cases,it is no longer true that y(t) - y"(t), but the load component
310

9.6 Superuision of Adaptiue Controllers
ya\) dominates. This means that these disturbances will provide the process estimator with disinformation in the same way as the load disturbances discussed in the previous subsection. To avoid the problem, oscillations have to be detected in the same way as load disturbances, so that adaptation can be inhibited when these disturbances are present. Such detection procedures are presented in Section 10.4.
SignalSaturation
When the process output saturates, it is no longer true that y(t) : y"(t). Suppose that the process output becomes saturated at the limit y5-11. The process output can then described in the following way:
y (t) - y " (t) * (yu.,,t- y" (t)).
The second term on the right-hand side can be interpreted as a load disturbance component. Hence, we have the same problem as was discussedin the previous subsections.Therefore, the estimation should be interrupted when y saturates. Again, it is useful to have a timer connected to this interrupt, so that the estimation is kept off for a while after the saturation period. This is to avoid erroneous estimates during the transients.
It may also be desirable to interrupt adaptation when control signal u saturates. This might seem confusing, since y(t) : y"(t) in this case. However, if Ioad disturbances are present it may no longer be true that yu(/) dominates over !4(t) in the second phase of a load disturbance response in this case.
Mode Transitions A constant-parameter controller runs mainly in two modes:
r Manual mode
o Automatic mode
Bumpless transfer between the different operating modes is performed by ensuring that all states are assigned suitable values at the transitions. If this is not done properly, "bumps" will occur in the control signal at the mode transitions. See Section 13.5.
An adaptive controller has three modes of operation:
. Manual mode
o Automatic mode
. Adaptive mode
Here, it is important to ensure bumpless transfer also between the first two modes and the third adaptive mode. The parameter estimation is normally disconnected when the controller is in manual mode and often also when it is in automatic mode without adaptation. It is therefore important to initialize all the additional states that are given in the parameter estimator when the adaptive controller is started.
311

Chapter 9. Automatic T|ning and Adaptation
An erroneous initialization of the parameter estimator will result in "bumps" in the parameter estimates. These bumps are not always immediately visible as a "bump" in the control signal, but they may deteriorate the control in other ways since they provide an erroneous process model.
The most important states of the parameter estimator are given by Equations 9.1 and 9.2. The covariance matrix P(/) should be assigned a large value when the parameter estimates are uncertain. However, when the controller parameters are initialized by an automatic tuning procedure or when they for other reasons are believed to be accurate, P(t) should not be reinitialized to a large value but kept close to its stationary value.
The residual vector A(t) normally contains delayed control and measurement signals. This vector should be initialized by actual values of these signals.
It is also important that filters as well as the supervisory functions be provided with correct states. This can sometimes be accomplishedby introducing a delay in the estimator. Suppos,.9.,that the controller is switched from manual to adaptive mode and that the process output is not close to the set point. This means that we immediately get a transient at the mode switch. If the excitation detection procedure is active, the adaptation mechanism may then start before the states have got their appropriate values. This problem can be avoided by delaying the excitation detection procedure at the mode transition.
A re-initialization of the adaptive controller must also be made if parameters related to the adaptation are changed. Suppose, e.g., that the sampling period is changed by the user or that an automatic tuning procedure is run, resulting in new values of the sampling period. This means that a total reinitialization of the adaptive controller must be made, with new filter-time constants, etc.
Another mode transition occurs if the adaptive controller is combined with gain scheduling. In this case,a re-initialization should be performed whenever there is a switch in the gain schedule.
It is also often possible to reset the adaptive controller, so that the parameter estimates e(r) are reinitialized to some pre-specifiedvalues, normally those obtained during the initialization phase.
Boundson ParameteEr stimates
There is a region in the parameter space where the information provided during the initialization phase is relevant. Inside this region, the a priori information about the processtime To ts correct, sampling periods and filter-time constants are suitable. If the process dynamics change so much that the parameter estimates tend to go outside this region, the behavior of the controller might be poor.
It is therefore advantageous to bound the parameter estimates to an allowable region. The adaptation may continue outside the region, but the algorithm should be reinitialized so that new parameters suitable for the new region are obtained. Using gain scheduling it is, e.g.,possible to have several regions with different sampling periods and filter-time constants.
It may be difficult to find such regions if the estimated model is of high order. It is easier when the model order is lower, and it perhaps is possible to find physical interpretations of the parameters. In adaptive PID controllers,
312

9.7 Iteratiue Feedback Tfuning
there are often bounds on the gain, integral time, and derivative time. There is another reason for bounding the parameter estimates, which is
related to the excitation needed for the parameter estimation. Suppose, e.g., that the parameter estimates change so much that a very low closed-loopbandwidth is obtained. The excitation in the interesting frequency band will then be low, and we will get a very slow adaptation.
It may also be advantageous to have bounds on the rate of estimate changes. This is done to decrease the effects of sudden outliers or other errors. This feature can be compared with the rate limiters that often are used in standard controllers.

9.7 lterativeFeedbackTuning

Iterative feedback tuning, IFT, is an iterative on-line method for adjusting controller parameters. The key idea is a clever way of computing the gradient of the controller error with respect to controller parameters.
Consider a standard system with error feedback. Assume that it is desired to minimize the loss function
, : . l o 'f (y(t).u(t))dt

for a PID controller with the parametrization

L C(s) :

1 x1

-t kas. s

To minimize the criterion it is useful to know the gradient of the loss function with respect to the controller parameters. The partial derivative of J with respect to controller gain h is given by

H : 1(, ,af jft). u(t))ay 0f (y(t),u(t))

0y Ak

0u #)o'

( e8 )

To evaluate the right-hand side we need the partial derivatives

0y Yu: ak'

up

0u
()k

They can conveniently be computed from the Laplace transforms. We have

Yn:

OYOC
ac ak

1'l nr7-i :

0Y ac
--

AC Aki

,-f 17R d

aY ac oc oka

AY

AC IAY

s0C

" Oa

Y
c

'

(e.e)

313

Chapter 9. Automatic Tl^rningand Adaptation

The processoutput is given by

Y:#Y*tivr'*1fun

:

r1
(1

-r

P1
T

.

F

d

)

"

'

o

*

,

* PCD+ 1*pc,N'

and the control error is given by

E:Y,p-Y - i*Ysp-;*n
Using this expression for the error we find

]uw.

aY
dd

-1*

P
n

c

y_^v'_o

P2

-

(1+ PC)rD

P
(1+ pcf

N

:

PrtPl
T;PC(+.6I'P- ,i*n

-,*""t,)

Hence,

aYPnLPCn 0C- l+PC"-

Cl+PC"'

(e.10)

The partial derivatives of the output with respect to the controller parameters can be computed in a similar way. We have

v,, ,fR, --

0u ac ac ak-

Tf OUAC " R i i t ' a C a k i -

tr- ,tKt :d_ _ _arua Ca.c AC )kd

0u ac
TAU
sdC
au

(e.11)

Straightforward is given by

calculations show that the sensitivity derivative of the output

a

u

1-

_ _

H

.

AC !+PC"'

(e.12)

Equations 9.10 and 9.12 can be used to compute the sensitivity derivatives needed for the optimization. The error E is known, but there is a difficulty because the process transfer function P is not known. This difficulty can be circumvented in the following way:

. Make an experiment, and store the output y1 and the control error signal
1.

. Make a second experiment of the same duration where the set point is chosen as the control error e1 from the first experiment. Store the output !2 and the control error e2 of this experiment.

314

).7 lteratiue FeedbackTLning

The output and the control error of the secondexperiment are given by

Y_ Lr - , P C = = E r+pc,

, .+

1

P +p

c

_D"

_. ,l

1 *pgNz

:

r0Y1
e oc

+

P
r+pcDz*

1
4uNz

Er:

I

1 --

r+pCE1- L.FdD2- 9.*pgNz

-!Y,

*'

1

-

-

P
rp

g

D,z--,

-

-1

oc

lapgNz

The terms Dz and N2 are uncorrelated with h if the experiments are well separated in time. Their effect can be made arbitrarily smatl by choosing long data sequences.Hence,

9! * cy,
ff*n,

(e.13)

The second experiment thus gives an estimate of the sensitivity derivatives of the input and the output with respect to the controller parameters. Combining this with the input and the output from the first experiment we can now compute the gradient of the loss function with respect to the controller parameter from (9.8). The controller parameters can then be adjusted recursively. Summarizing we obtain the following algorithm.

Ar,coRltsrvr 9.1-ITERATTvE Fnnoeecx TuNrNc 1. Make an experiment of fixed duration, and store the output y1 and the control error signal e1.
2. Make a second experiment of the same duration where the set point is chosen as the control error e1 from the first experiment. Store the output !2 and the control error e2 of this experiment.
3. Compute the gradient of the loss function from Equations g.8, g.g, g.11, and 9.13.
4. Modify the controller parameters using the gradient.
5. Repeat from 1 until the gradient is sufficientlv small.
L-J
The same idea can be applied to a controller with two degrees of freedom but a third experiment is then required. A nice property of iterative feedback tuning is that it can be used for many different controllers and criteria. It is particularly well suited to optimization with respect to stationary stochastic disturbances.

315

Chapter 9. Automatic Tining and Adaptation
9.8 CommerciaPl roducts
To illustrate how adaptive techniques are used industrially we present some features of industrial controllers. Rather than to give an exhaustive presentation we have selected a few products to show the wide range of techniques, and we have chosen products that have a good track record. We have also selected products where reasonably detailed descriptions are published; more products are described in the book [Van Doren, 2003] and in reviews in trade journals.
Foxboro EXACTTMF60 1761) Foxboro was one of the first companies to announce products using adaptive techniques. The single-loop controller Foxboro EXACTTMIZAOllAl) , which used adaptation based on pattern recognition , was released by Foxboro in October 1984. The controller was later augmented with more features and Foxboro has continued to expand their use of adaptation in a range of products including their DCS system Foxboro I/Att. The ideas are described in [Bristol et al., 1970] and [Bristol, 1977] and details about the system are found in [Bristol and Kraus, 1984] and [Bristol, 1986]. Foxboro continued the development of adaptation, and auto-tuning and adaptation are now available in their distributed control system under the trade name Exact MVTM. A presentation of the details of the system are found in [Hansen, 2003]. Three function blocks, PIDA, FBTUNE, and FFTUNE, are used to implement the controller. PIDA is an advanced PID controller, FBTUNE, which handles tuning of the feedback gains, has functions for pretuning and adaptation, and FFTUNE has functions for tuning of feedforward gains and gain scheduling.
Controller Structure Foxboro uses a controller structure where integral action is implemented with positive feedback around a lag as illustrated in Figure 3.3. This implementation gives a controller in series form, see (3.8). A controller with a special structure called PIDc is also available in the system. This controller is a PID controller where the integral action is implemented with positive feedback around a lag with a time delay as shown in Figure 8.10. This arrangement gives a controller with more phase lead than an ordinary PID controller. Since phase lead is also associated with high gain it is necessary to provide good filtering if there is measurement noise. The controller can be interpreted as a controller where the future output is predicted with a combination of past controller inputs and controller outputs, seethe discussion of the PPI controller in Section 8.4. The controller PIDr can also be regarded as a special form of a Smith predictor. The controller PIDr gives significant improvement of performance for lag-dominated processesbut it requires careful tuning.
Pattern Recognition Adaptation based on pattern recognition can be viewed as an automation of the procedure used by an experienced process engineer when he tunes a controller. The following description follows the presentation in [Bristol and Kraus, 1984]. The control error after process perturbations are analyzed and the controller parameters are modified. If the controller parameters are reasonable, a transient error response of the type shown in Figure 9.12
316

9.8 Commercial Products

Figure g.l2 Response in control error to a step change of set point (left curve) and load (right curve).

is obtained. Heuristic rules are used to detect that a proper disturbance has occurred and to detect peaks er, 2,3,orld oscillation period lo. Heuristics are also used to change the controller parameters if the response is overdamped. The transient is characterizedquantitatively in terms of two parameters, over-
shoot (o) and damping (D), which are defined as

o:

l e2l l-l

let I

g-z

D-

t

t-z

(e.14)

where er, e2,and egare the peaks of the transients shown in Figure 9.t2. Note that the definition of damping used. is equal to the square root of the decay ratio (2.4g). Quarter amplitude damping thus corresponds to D - 0.5'
The controller parameters are adjusted using heuristic rules to obtain desired damping urrd orr.rshoot. Some rules are discussedin Section 6.3, and the effect of controller parameters on the transient are illustrated in the tuning map in Figure 6.7.

pre-Tfuning is Foxboro's notation for auto-tuning. The controller has a set of parameters that must be given either by the user from prior knowledge of
the loop or estimated using the pre-tune function'

o Initial values of PB, T!, and Tj.

o Noise band NB). The controller starts adaptation whenever the error signal exceedstwo times NB.

o Maximum wait time (!V,ou*).The controller waits for a time of W-u* for the occurrence of the second Peak.

c
I

If the user is unable to provide the required parameters, a pre-tune function that estimates these quantities can be activated. To activate the pre-tune function, the controller must flrst be put in manual. When the pre-tune function

r

is activated, a step input is generated. The process parameters static gannKp, dead time L, and.time constant T are then obtained from a simple analysis

.)

of the process reaction curve. The controller parameters are calculated using

3t7

Chapter 9. Automatic Tl^tningand Adaptation

a Ziegler-Nichols -like formula :
PB : I2jKILlT, Ti : L\L, TJ: Til6.

(e.15)

Maximum wait time, V[*.*, is also determined from the step response by W^^*: 5L'
The noise band is determined during the last phase of the pre-tune mode. The control signal is first returned to the level before the step change. With the controller still in manual and the control signal held constant, the output is passed through a high-pass filter. The noise band is calculated as an estimate of the peak-to-peak amplitude of the output from the high-pass filter. The estimated noise band is also used to adjust derivative action.
There are a number of optional parameters. If these are not supplied by the user then the default values will be used. The optional parameters are as follows (default values in parenthesis):
o Maximum allowed damping (0.3)
o Maximum allowed overshoot (0.5)
o Derivative factot (1). The derivative term is multiplied by the derivative factor. This allows the derivative influence to be adjusted by the user. Setting the derivative factor to zero results in PI control.
. Change Limit (10). This factor limits the controller parameters to a certain range. Thus, the controller will not set the PB, Ti and Tj values higher than ten times or lower than one tenth of their initial values if the default of 10 is used for the change limit.
The pretuning has been improved in the later Foxboro products. The process is excited with a doublet pulse, see Figure 2.33, instead of the step used in the original system. An FOTD or SOTD model is fitted to the data from the experiment, as described in [Shinskey, 1994]. The controller parameters are calculated from the model based on a novel robust analytic design method described in [Hansen, 2003]. Adaptation of feedback gain parameters are still done using the pattern recognition method.
The controllers in the Foxboro DCS system have lead-lag filters for feedforward from measured disturbances. The feedforward gains are tuned by fitting a low-order continuous-time model using the method of moments, see [Hansen,
2oo3l.

ABB
Adaptation in the ABB's systems has its roots in a auto-tuners based on relay feedback first developed by the company NAF in the early 1980's. The first system was part of a small (about 50 loops) DCS system called SDM-20rM introduced in 1982 and a single-loop controller ECA-40rM introduced in 1986. These systems also used auto-tuning to build gain schedules. The company NAF went through a series of acquisitions, SattControl, Alfa Laval Automation, and is now part of ABB. The adaptive techniques were developed by adding continuous adaptation, adaptation of feedback and feedforward gains,

318

9.8 Commercial Products

and diagnostics. These features were all introduced in the ECA600rM which was announced in 1988. The technology is now an integral part of the ABB DCS system Industrial IT System 800xArM, which also has facilities for fuzzy control and for model predictive control. There are several types of PID controllers; the advanced versions give accessto more parameters. There is also a PPI controller for systems with time delay.
Essential parts of the technology are described in [Astriim and Htigglund, 1984c; Astrrim and Hiigglund, I984a; Astrcim and H4gglund, 1988; Astrdm and Hdgglund, 1990; Astr6m and Hiigglund, 1995a; Astriim and Hiigglund, 1995b; HAgglund, 1999; Hdgglund and Astrtim, 2000; ABB, 20021.

Bi-directional Data Flout Distributed control systems are traditionally programmed graphically using a block oriented language. One drawback with traditional systems is that data-flow is unidirectional. This leads to unpredictable latency in the system, which is particularly noticeable in large systems and when back calculations to avoid windup are propagated through several loops. An interesting novel feature of the ABB System 800xA is a data structure called control connection. that permits bi-directional data flow between the control modules. This feature makes it possible to implement windup protection in an elegant way which avoids latency even in complex systems with many cascades.
Relay Auto-Tfu.ning The auto-tuning is performed using the relay method discussedin Section 2.7. The tuner is typically operated as follows. The process is brought to a desired operating point, either by the operator in manual mode or by a previously tuned controller in automatic mode. When the loop is stationary, the operator presses a tuning button. After a short period, when the noise level is measured automatically, a relay with hysteresis is introduced in the loop, and the PID controller is temporarily disconnected (see Figure 9.4). The width of the hysteresis is set automatically, based on measurement of the noise level in the process. The lower the noise level, the lower the amplitude required from the measured signal. The relay amplitude is controlled so that the oscillation is kept at a minimum level above the noise level. When an oscillation with constant amplitude and period is obtained, the relay experiment is interrupted and P(ias), i.e., the value of the transfer function P at oscillation frequency ao, is calculated using describing function analysis.

Control Structures and Controller Design Several PID and PPI con-

trollers are available in the ABB systems. The advanced versions give the user

access to many parameters. The PID algorithm in the ECA600rM controller is

of series form, the controllers in the DCS system use the parallel form.

The identification procedure provides a process model in terms of one point

P(iots) on the Nyquist curve. There is also a test to determine if process dy-

namics is lag dominated. The frequency oo depends on the hysteresis in the

relay. It is typically less than @180w, hich is advantageous; see Section 7.5. By

introducing the PID controller C(ico) in the control loop, it is possible to move

the point corresponding to a,tson the Nyquist curve of the
'i:T.1ryr'",;i$)t*'e''"ls',fe' r

to a
319

Chapter 9. Automatic Tt^tningand Adaptation

desired location. In the normal case the desired point is P (iah) C (ias) - o.\e-ir3ltrI r8o.

(e.16)

Since there are three parameters, K, T;, and 76, and the design criterion (9.16) only specifies two parameters the additional constraint

ri - 4rJ.

(e.17)

is introduced. The normal procedure can give very high gains for lag-dominated systems.
If this is detected a PI controller with the conservative tuning

K : o.5llP(iraos)1,Tt - Alrtto

(9.18)

is used. A different tuning can also be used for processes which are delay dominated. A PI controller with the tuning rule

K - 0.25llP(iah)|, Tt - I.6l(Do

(e.1e)

is then used. In the early versions of the controller (ECA-4OrM and ECA-600rM; the user
can influence tuning by selecting normallPlltime-delay. Later versions of the controller obtain more information about the process by making a step change after the relay experiment. This gives the static gain of the process and gain ratio r, and tuning can be improved without any user interaction. In the ABB 800xArM system this is accomplished by using the tuning rules in [Astrdm and Hiigglund, 1995a]. Further improvements are possible by using the results in Chapter 7.

Gain Seheduling Gain scheduling was introduced in the early controllers SDM-20rM and ECA-4OrM. It was very easy to build the schedules by using auto-tuning and the feature was well accepted by the users. Gain scheduling therefore became a standard feature of almost all controllers. The users can select the scheduling variable as the control signal, the measured process output, or an external signal. It is important that the scheduling variables do not change too quickly, filtering and hysteresis are used for signals like the process output that can change rapidly. Three sets of parameter values were available in the early systems but larger tables can be used in the later versions. The parameters are obtained by using the auto-tuner once at every operating condition. The ranges of the scheduling variable where different parameters are used can also be given by the user.

Adaptiae Feedbaeh Information from the relay feedback experiment is used to initialize the adaptive controller. Figure 9.7 shows the principle of the adaptive controller. The key idea is to track the point on the Nyquist curve obtained by the relay auto-tuner. It is performed in the following way. The control signal u and the measurement signal y are filtered through narrow band-pass filters centered at frequenc! (Ds.This frequency is obtained from the relay experiment. The signals are then analyzed in a least-squares estimator, which provides an estimate of the point P(ias).

320

9.8 Commercial Products

F

Adaptive Feedforwq.rd Feedforward from measured disturbances can fre-

f
t

quently improve performance significantly. Adaptive feedforward has been a

feature in all controllers starting with the ECA400rM. Diagnostics for on-line

assessmentof the potential value of feedforward is an active research topic; see

[Peterssonet a1.,,2001],[Peterssonet a1.,2002],and [Peterssonet a1.,20031. The adaptive feedforward control is based on the simple model

y(t) : au(t - 4h)+ bu(t- 4h).

(e.20)

where y is the measurement signal, u is the control signal and u is the disturbance signal that should be fed forward. The sampling interval h is determined from the relay experiment as h: Tol8, where 76 is the oscillation period. The parameters o and b are estimated recursively by a least-squares algorithm. The feedforward compensator has the simple structure

Ar.rr(t) : kff(t)Au(r),

(e.21)

where the feedforward gain ky is calculated from the estimated process pa-

rameters

I' "z1rr1(t\\- /

- 0".'8"

W). a(t)',

(e.22)

The ManlMaehine Interface The auto-tuners based on relay feedback can be implemented with very simple man-machine interfaces. In many casesit is sufficient to provide the controllers with just one button to initiate tuning. Gain scheduling can also be implemented in a very user-friendly fashion. Many of the problems normally associated with implementation of adaptive controllers can be avoided because the auto-tuner gives good initial values.
Industrial experience has also indicated that there is a significant advantage to combine adaptation with diagnostics and supervision. For example, it is meaningless to tune a controller if there is a bad actuator in the loop.

EmersonProcessManagement
The adaptive techniques used in Emerson's systems go back to the DCS systems ProvoxrM and RS3rM, where the Fisher-Rosemount Intelligent Tb.nerand Gain Scheduler were introduced. Use of adaptation has been expanded in the Delta V system. Fairly detailed information about the techniques used is available in the book [Blevins et a1.,2003],which also contains many references.The system has facilities for auto-tuning, gain scheduling, and adaptation. There is also software for fuzzy control and for model predictive control.
The automatic tuning is based on relay feedback. The range of the relay oscillation is typically a few percent of the full signal range. An estimate of the apparent time delay is obtained by analysing the initial portion of the first step. When an estimate of the time delay is available it is also possible to obtain an FOTD model. The parameters Kp, T, and Z of the FOTD model can be displayed. T\rning is typically accomplished in a few periods of the oscillation. Since a FOTD model is available it is possible to use several tuning techniques. The available options include Ziegler-Nichols tuning, IMC tuning, and Lambda

32L

Chapter 9. Automatic Tt^rningand Adaptation

tuning to mention a few. The system is structured so that an inexperienced user has few choices,but an experienced user has many options. There is also a built-in simulator so that tuning can be tested against the process model before committing it to the process.
Adaptive control is based on data from the process during normal operation; excitation can also be provided. The system consists of a supervisor, an excitation generator, adaptors for gain, integration time, and derivative time, and a safety net. The goal of the adaptation is to obtain a well damped slightly oscillatory response.The approach is similar to that used in the Foxboro Exact.
Gain scheduling is done by estimating static process characteristics. Interpolation is done using fuzzy techniques.

Honeywell
Honeywell products using adaptive control started with the single-loop controller UDC 6000rM which had an adaptive function called Accutune. The adaptive techniques were developed further and they are essential components of Honeywells DCS system TDC 3000rM.

UDC 6000rM Adaptation in the UDC 6000rM combines model-based procedures and rule-based procedures. Modeling is based on a step-responseexperiment. The user brings the processvariable to a point some distance away from the desired set point in manual and waits for steady state. Switching to tuning mode initiates an open-loop step response experiment, where the size of the step is calculated to be so large that it is supposedto take the processvariable to the set point.
During the experiment, the process variable and its derivative are continuously monitored. Dead time Z is calculated as the time interval between the step change and the moment the process variable crosses a certain small limit.
If the derivative of the process variable continuously decreases from the start, it is concluded that the process is of first order and an FOTD model is determined from a few points on the step response. The calculations can be performed before the steady-state is reached, and it is claimed that the process is identified in a time less than one third of the time constant.
If the derivative of the process variable increases to a maximum and then decreases,the process is identified as a second-order process and an SOTD model is determined from the step response. The controller is then switched to automatic mode and controlled to the set point using preliminary controller parameters when the maximum slope of the processoutput has been reached, bu it is necessary to wait for steady state to obtain the complete model. More details about the modeling procedure are given in [Astrcim and Hiigglund, 1995b].
When the model has been obtained the controller parameters are calculated from the model and the controller is switched to automatic control mode.
The controller used is on series form with the transfer function

C(s)-

K

( 1+ s T i) ( 1+ s { ) sri$ + 0.r2lsTj)'

Notice that the filter time constant is 1/8th of the derivative time. Controller design is based on pole placement of the Dahlin-Higham type procedure where

322

9.8 Commercial Products

the processpoles are cancelled.There are several different versions depending on system order and time delay. For systems with time delay the closed loop time constant is chosen as T4 : L * f 13.The UDC 6000 controller also has continuous adaptation which is activated when the process variable changes more than 0.3 percent from the set point or if the set point changes more than a prescribed value.
Honeywelt LOOPTUNETM The DCS system TDC3000 has a wide range of controllers ; Basic Controllers, Extended Controllers, Multifunction Controllers, ProcessManagers and Application Modules. LOOPTUNE is a software package in the system that tunes loops with PID controllers.
The tuning algorithm does not rely on any particular model of the system. Performance is evaluated using the quadratic loss function

1N
,t : * I(tt

- p ) ( y ( t )- ! , p ( t ) ) ' +p ( u ( t )- u ( t - 1 ) ) ' ) ,

NU"

(e.23)

where N is the evaluation horizon and p a weighting factor that balances control error against actuator changes. The controller parameters are changed one at a time and the loss function is evaluated over a given time horizon N. A large value of N is required to obtain a reliable estimate but the evaluation takes long time. Processknowledge can be used to improve the search for good controller parameters by biasing the search towards higher controller gain and lower integration time.

Yokogawa SLPC-1 81, 281
The Yokogawa SLPC-181 and 281 both use a processmodel as a first-order system with dead time for calculating the PID parameters. A nonlinear programming technique is used to obtain the model. The PID parameters are calculated from equations developed from extensive simulations. The exact equations are not published.
TWo different controller structures are used.

1: u:K (-r*+ ledt-r,#)

(e.24)

2: u:K ("*+ ledt-r,#)

where yf ir generated by filtering y with a first order filter having time constant
TaI N .The first structure is recommended if load disturbance rejection is most important, and structure 2 if set-point responses are most important. The set
point can also be passed through two filters in series:

F i l t e rt , L !Lo+"s=TTi'

F

i

l

t

e

r

zf1ft

n
i

,

g

!

O

(e.25)

where ai ar'd d6 arreparameters set by the user, mainly to adjust the overshoot of the set-point response. The effects of these two filters are essentially

323

Chapter 9. Automatic Tl^tningand Adaptation

Table 9.2 Set-point response specifications used in the Yokogawa SLPC-181 and 281.

Tlpe

Features

Criteria

1

no overshoot

no overshoot

2 \Vo overshoot ITAE minimum

3 ljVo overshoot IAE minimum

4 lSVo overshoot ISE minimum

equivalent to set-point weighting. It can be shown that ui: b, where b is the set-point weighting factor.
The user specifies the type of set-point response performance according to Table 9.2. A high overshoot will, of course, yield a faster response. The controller has four adaptive modes:
Auto mode. The adaptive control is on. PID parameters are automatically updated.
Monitoring mode. In this mode, the computed model and the PID parameters are only displayed. This mode is useful for validating the adaptive function or checking the process dynamics variations during operation.
Auto startup mode. This is used to compute the initial PID parameters. An open loop step response is used to estimate the model.
On-demand mode. This mode is used to make a set-point change. When the on-demand tuning is requested, a step change is applied to the processinput in closed loop. The controller estimates the process model using the subsequent closed-loopresponse.
The controller constantly monitors the performance of the system by computing the ratio of the variances of processoutput and model output. This ratio is expected to be about 1. If it is greater than 2 or less than 0.5, a warning message for retuning of the controller is given. Dead time and feedforward compensation are available for the constant gain controller, but they are not recommended by the manufacturer to be used in conjunction with adaptation.

Techmation Protuner
The Protuner is a process analyzer from Techmation Inc. It consists of a software package for personal computers and an interface module with cables to be connected to the process output and the control signal of the control loop to be analyzed. The Protuner monitors a step-responseexperiment, calculates the frequency response of the process based on the experimental data, and suggests controller parameters based on several methods for controller tuning.

Prior Information

Before the process analysis is performed, the user must

provide some information about the process and the controller. This is done

using a couple of "Set-up menus." The following process information must be

given:

r The ranges of the control and the measurement signals.

324

9.8 Commercial Products

o It must be determined if the processis stable or if it has integral action.
To be able to set relevant controller parameters, the following data about the controller must be provided:
. P-type (gain or proportional band)
. I-type (seconds,seconds/repeat, minutes, or minutes/repeat)
o Controller structure (ideal, series, or parallel)
. Sampling rate
o Filter time constant (if there is a low-pass filter connected to the measurement signal).
Before the tuning experiment can be performed, the user must also specify a sample time. This is the time during which data will be collected during the experiment. It is important to choosethe sample time long enough, so that the step response settles before the sample time has ended. In caseof an open-loop experiment of an integrating process,the response must reach a constant rate of change when the experiment ends.

Deternining the Process Model The tuning procedure is based on a stepresponse experiment. It can be performed either in open or closed loop. The open-loop experiment is recommended. When the user gives a start command, the process output and the control signal are displayed on the screen, with a time axis that is given by the sample time defined by the user. The user then makes a step change in the control signal. If the experiment is performed in closed loop a step is instead introduced in the set point.
There are several facilities for editing the data obtained from the stepresponse experiment. Outliers can be removed, and data can be filtered. These features are very useful because they make it possible to overcome problems that are often encountered when making experiments on industrial processes.
When the data has been edited the Protuner calculates the frequency responseof the process.The result can be displayed in a Bode diagram, a Nyquist diagram, or a Nichols diagram. The static gain, the dominant time constant, and the apparent dead time are also displayed, as well as the ultimate gain and the ultimate period.

Design Calculations

The controller parameters are calculated from the

frequency response. A special technique is used. This is based on cancellation

of process poles by controller zeros. The integral time and the derivative time

are first determined to perform this cancellation. The gain is then determined

to meet predetermined gain and phase margins.

The Protuner provides several design options. Controller parameters are

given for the following closed-loopresponses slow (critically damped), medium

(slightly underdamped) and fast (decay ratio 0.38) responses. The different

design options are obtained by specifying different values of the gain and the

phase margins. The Protuner provides different controller parameters depend-

ing on whether set point or load disturbances are considered. Both P, PI, and

Chapter 9. Automatic Tltning and Adaptation

PID controller parameters are provided. The set-point weightings for proportional and derivative action and the high-frequency gain at the derivative part must be supplied by the user.

Eualuation

It is possible to evaluate the performance of the closed-loop

system in several ways. The combined frequency response, i.e., the frequency response of the loop transfer function G; (ia) - P(ia)C(iat), can be plotted in

a Bode diagram, a Nyquist diagram, or a Nichols diagram. In this way, the

phase and amplitude margins or the M" value can be checked.

The Protuner also has a simulation facility. It is possible to simulate the

closed-loop response of the process and the suggested controller. To do this,

it is necessary to provide some additional controller parameters, namely, set-

point weightings b and c, and derivative gain limitation factor N. Using the

simulation facility, it is also possible to investigate the effects of noise and to

design filters to reduce these effects.

Some Personal Reflections
Adaptive techniques have been used extensively in industry since the mid 1980s.The techniques are proven useful and the products continue to develop, but there is clearly a potential to improve current products.
Several lessons can be learned from the results of Chapter 7. One observation is that it is useful to charactefize process dynamics with three parameters. Dynamics can then be classified as delay dominant, balanced, or lag dominant. Tight control can be obtained by using an FOTD model for systems with balanced and delay-dominated dynamics but control performance can be improved significantly for lag-dominated systems by using a better model. In Section 2.7 it was also shown that it is difficult to obtain an SOTD model from a step response experiment. Hence, it is not possible to design auto-tuners for tight control based on a step response or on knowledge of ultimate gain and ultimate frequency. An indication of this is that Foxboro switched to using a doublet instead of a step. The doublet can actually be regarded as a short version of an experiment with relay feedback.
It is highly desirable to accomplish tuning in a short time, as is illustrated by the Honeywell UDC 6000rM. One advantage of the relay auto-tuner is that tuning often is accomplished in a time that is much shorter than the average settling time of the system. In particular, the time can be much shorter for systems with lag-dominated dynamics. An interesting question is therefore what information can be derived from an experiment with relay feedback. The Emerson experience indicates that at least an FOTD model can be determined from an experiment with relay feedback. To explore in detail the information that can be deduced from a relay experiment is therefore an interesting and useful research task. If improved models are obtained it is also possible to use the algorithms presented in Chapter 7 that give tight control. The potential gains are particularly large for lag-dominated process.
The model-free approaches to adaptive control have many attractive features but their main disadvantage is that tuning takes a long time. T\rning can be made more effective by using iterative feedback tuning, which also computes estimates of the gradient of the loss function; see Section 9.7. Adaptive

326

9.9 Summarv
controllers based on more elaborate models like the self-tuning controller discussed in Section 9.3 is an alternative to model based control. Such controllers work very well but so far they have required very knowledgeable users. There may be a possibility to make them simpler to use by exploiting the information obtained from automatic tuning. This may also be the road to introduce adaptation in the model predictive controllers.
Tools like Techmations Protuner, which permit simulation of a process with different controller settings, are very useful for the advanced user. Many components to build such a system are already available in current DCS systems. It is therefore natural to provide such tools as an integral part of the systems.

9.9 Summary
An essential feature of feedback is that it can be used to design systems that are insensitive to process variations. When there are large variations, performance may be improved by adjusting the controller parameters. Adaptive techniques are therefore increasingly being used in PID controllers to adapt the controller parameters to the changesin processdynamics or disturbances. In this chapter we have given a broad presentation of a variety of adaptive methods covering automatic tuning, gain scheduling, and continuous adaptation. The techniques are used in several ways.
In automatic tuning the controller parameters are adjusted on demand from the user. Gain scheduling can be used when there is a measured scheduling variable that correlate well with the process changes. The controller parameters are obtained from a table, which gives controller parameters as a function of the scheduling variable. Auto-tuning can be used to build the table. Adaptive control can be used when a scheduling variable is not available.
Model based and feature based methods are discussed,particular attention is given to use of relay feedback for auto-tuning, parameter estimation, and iterative feedback tuning.
The adaptive controller derives the knowledge required from the input and output of the process. Adaptive control is less robust than gain scheduling and it requires supervisory functions. Supervision of adaptive controllers is therefore discussed.
A short presentation of some industrial adaptive controller where adaptive methods have been used successfullv are also discussed.

9.10Notesand References

Controllers with automatic tuning grew out of research on adaptive control.

Overviews of adaptive techniques are found in [Dumont, 1986; Astrdm, t987a;

B' Hr iasrtroi sl ,

1970;Astrtjm, 1990]. More detailed treatments are found in the and Billings, 1981;Hang et a1.,1993b;Astrtjm and Wittenmark,

books 19951.

Overviews of different approaches and different products are found in [Isermann, 1982; Gawthrop, 1986; Kaya and fitus, 1988; Morris, 1987; Yamamoto,

1991;A s t r t im e t a \.,1 9 9 3 ].

327

Chapter 9. Automatic Tfu.ningand Adaptation
Many different approaches are used in the automatic tuners. The systems described in [Nishikawa et al., 1984; Kraus and Myron, 1984; Takatsu et a1.,1991j are based on transient responsetechniques.The paper [Hang and Sin, 19911is based on cross correlation. The use of orthonormal series representation of the step response of the system is proposed in [Zervos et al., 1988; Huzrrrezan et al., 20031. Pattern recognition, which was the basis for Foxboros EXACTTM controller, is discussedin [Bristol,1967; Bristol, 1970;Bristol et al., 1970; Bristol, 1977; Bristol and Kraus, 1984; Bristol, 1986; Porter et a1. , 1987;An d e rs o n e t a 1 .,1 9 8 8 ;K l e i n e t a1.,1991;P agano,1991; S w i ni arski , 19911.Auto-tuning based on relay feedback is treated in [Astrdm and Hagglund, 1984b;Astrdm and Hagglund, 1988;Hrigglund and Astrcim, 1991; Schei, 1992; Hang et al., 1993a; Leva, 1993; Schei, 1994; Voda and Landau, 1995]. Iterative feedback tuning is discussedin [Hjalmarsson ef al., LggS].It is more effective than direct search because gradient information is used.
Tbaditional adaptive techniques based on system identification and control design have also been applied to PID control. Identification is often based on estimation of parameters in a transfer function model. Examples of this approach are given in [Hawk, 1983; Hoopes et al., 1983; Yarber, 1984a; Yarber, 1984b; Cameron and Seborg, 1983]. There are also systems where the controller is updated directly as in [Radke and Isermann, 1987; Marsik and Strejc, 1989; Rad and Gawthrop, 19911.Supervision of adaptive controllers is discussed in [Isermann and Lachmann, 1985; Sullivan, 1996; Clarke and Hinton, 1997; Liu, 1998; Hiigglund and Astrdm, 20001.
An overview of several products that use adaptation is given by [Van Doren, 2003]. Several tuning aids are implemented in hand-held computers or as software in PCs where the user is entering the process information through a keyboard; see [Blickley, 1988; T]reus, 1987; Yamamoto, 1991].
The papers [McMillan et al., 1993b; McMillan et al., 1993a] describe the Fisher Rosemount products for tuning and gain scheduling. The implementations in the Delta VrM OCS system is described in the book [Blevins et al., 2003]. The Yokogawa systems are discussed in [Takatsu el al., l99l] and [Yamamoto, 1991].
There have been comparisons of different auto-tuners and adaptive controllers, but few results from those studies have reached the public domain. Some papers that deal with the issue are [Nachtigal, 1986a; Nachtigal, 1986b; Dumont, 1986; Dumont et a1.,1989j.Some operational experienceis described in [Higham, 1985; Callaghan et a1.,19861.
328

10
Loop and Performance Assessment
10.1Introduction
The design, tuning, and implementation of control strategies and controllers is only the first phase in the solution of a control problem. The second phase includes operation, supervision, and maintenance. This phase has traditionally been handled manually, but the interest for automatic supervisory functions has increased significantly in recent years becauseof the reduction of personnel in the process industry.
This chapter treats methods for commissioning, supervision, and diagnosis of control loops. The adaptation methods presented in Chapter g were divided into two categories, tuning on demand and continuous adaptation. Procedures for supervision and diagnosis can be classified in the same way. We call them Ioop assessmentand performance assessment.Loop assessmentprocedures are used to investigate properties of the control loop, e.g.,signal levels, noise levels, nonlinearities, and equipment conditions. Performance assessmentprocedures are used to supervise the control loops during operation and ensure that they meet the specifications. Failure to meet the specifications may be caused by equipment problems, nonlinearities, or other variations in processdynamics or the surroundings.
The chapter begins with a presentation of problems occurring in valves. These problems are identified as one of the major reasons for bad control loop performance. Sections 10.3 and 10.4 treat loop assessment and performance assessment,respectively. Ttrning and diagnosis have many aspectsin common. These aspects are discussed in Section 10.5.
10.2 Valves
Control valves are subject to wear. After some time in operation, this wear results in friction and hysteresis that deteriorates the control performance. Furthermore, valves are often both nonlinear and over-sized.T!g5*re, valves
:r:r'\i;,i; B2s
' r:i
. ._:i.,:'i .
' .-j)'

Chapter 10. Loop and Perforn'LanceAssessment
0.4
0.2
0.4
0.2
0
Figure 10.1 Procedure to check the amount of valve friction. The upper diagram shows process output y and the lower diagram shows control signal u.
have been identified as the major source of problems at the loop level in process control. We therefore devote a section to these problems.
Friction in the Valve High friction in the valve is a common cause of problems. There is, of course, always static friction (stiction) in the valve, but if valve maintenance is insufficient, friction may be so large that the control performance degrades. The amount of friction can easily be measured by making small changes in the control signal and observing how the process outputs react. The procedure is shown in Figure 10.1. In the figure, the process output only responds to the control signal when the changes in the control signal are large enough to overcome the static friction.
Friction in the valve results in stick-slip motion. This phenomenon is illustrated in Figure I0.2. Suppose that the valve is stuck at a certain position due to friction. If there is a control error, the integral action of the controller will cause the controller output to increase until the pressure in the actuator is high enough to overcome the static friction. At this moment, the valve moves (slips) to a new position where it is stuck again. This valve position is normally such that the process output is moved to the other side of the set point, which means that the procedure is repeated. The process output will therefore oscillate around the set point. The pattern in Figure L0.2, where the measurement signal is close to a square wave and the control signal is close to a triangular wave, is typical for stick-slip motion.
Many operators detune the controller when they see oscillations like the one in Figure 10.2, since they believe that the oscillations are caused by a bad controller tuning. Unfortunately, most adaptive controllers do the same. What should be done when a control loop starts to oscillate is to first determine the cause of the oscillation. A good way to do this is presented in Figure 10.3.
The first problem to determine is whether the oscillations are generated inside or outside the control loop. This can be done by disconnecting the feed-
330

10.2 Values
Figure 10.2 Stick-slip motion caused by valve friction and integral action. The upper diagram shows process output y, and the lower diagram shows control signal u.
back, e.g., by switching the controller to manual mode. If the oscillation is still present, the disturbances must be generated outside the loop, otherwise they were generated inside the loop. There might be a situation when the control loop oscillates because of valve friction even when the controller is in manual mode, namely, if the friction occurs in the pilot valve of the positioner instead of the valve itself.
If the disturbances are generated inside the loop, the cause can be either friction in the valve or a badly tuned controller. Whether friction is present or not can be determined by making small changes in the control signal and checking if the measurement signal follows, as shown in Figure 10.1. If friction is causing the oscillations, the solution to the problem is valve maintenance.
If the disturbances are generated outside the control loop, one should try, of course, to find the source of the disturbances and try to eliminate it. This is not always possible, even if the source is found. One can then try to feed the disturbances forward to the controller and in this wav reduce their effect on the actual control loop. See Section 5.6.
Hysteresis in the Valve Because of wear, there is often hysteresis (backlash) in the valve or actuator. The amount of hysteresis can be measured as shown in Figure I0.4. The experiment starts with two step changes in the control signal in the same direction. The hysteresis gap will close if the first step is sufficiently large. This means that the second step is performed without hysteresis. The third step is then made in the opposite direction. The control signal then has to pass the whole gap before the valve moves. If the last two steps are of the same size, the hysteresis is A,ylKo, where Ay is the difference between the process outputs after the second and the third step (see Figure 10.4), and Ko is the static process gain (also easily obtained from Figure 10.4).
The hysteresis can also be determined from a continuous sweep over parts of the operating range. Figure 10.5 shows the process outputs from a process
331

Chapter 10. Loop and Perforrnance Assessment
P u tc o n t r o l l eirn m a n u a lm o d e

No

srill

Yes

oscillating

\?-

Check the valve

S e a r c hf o r t h e source

P Yes
Undertakevalve maintenance
Check c o n t r o l l etru n i n g

4",bTy Yes

Eliminate disturbances

-K';"y -lorg;D\

Yes

No Usefeedforward

R e d u c ed i s t u r b a n c e s by controlletruning
Figure 10.3 Diagnosis procedure to discover the cause of oscillations and recommended actions to eliminate them.
with friction and a processwith hysteresis, respectively,when the processinput is ramped from zero to one and then back to zero again. The corresponding phase plots are presented in Figure 10.6. One can easily measure the amount of hysteresis from the phase plot. Sweeps of this type are conveniently done during commissioning.
Figure 10.7 shows closed-loopcontrol of a processwith 10 percent hysteresis in the valve. The process is
P(s)- d.#ttFn-03s,
and the controller is a PI controller with O"m-"r"rs K - 0.35 andT, i: 0.15. The control signal has to travel through the gap in order to move the valve.
332

10.2 Values 0.4 0.2
0.4 0.2
Figure 10.4 Procedure to check valve hysteresis. The upper diagram shows process output y, and the lower diagram shows control signal u.

0

0

150

L

Figure 10.5 Process outputs (solid lines) and control signals (dashed lines) for process with friction (upper graph) and hysteresis (lower graph).

Therefore, we get the typical linear drifts in the control signal as shown in Figure I0.7.
If a relay auto-tuner is applied to a process with hysteresis, the estimated processgain will be smaller than the true value. This gives a too large controller gain. An auto-tuner based on a step-responseexperiment will work properly if the gap is closedbefore the step-responseexperiment is performed. (Compare with the second step in Figure 10.4).
333

Chapter 10. Loop and Performance Assessment

Figure 10.6 Phase plots of the signals in Figure 10.5 for the process with friction (left) and hysteresis (right).

0.1

t\

t'

h 0.05

I

1

0

4

5

6

7

8

I

10

0

-U.U5 -0.1
- 0 . 15

4

5

6

7

8

9

10

t

Figure 10.7 Closed-loop control with valve hysteresis. The upper diagram shows process output y, and the lower diagram shows control signal u. The dotted lines show control without hysteresis. The solid lines show control with a hysteresis of 10 percent (0.1).

1 0 . 3 L o o pA s s e s s m e n t
This section suggeststests that are useful to perform on the control loop. These tests should be performed regularly, and especially in connection with controller tuning. The tests for friction and hysteresis, presented in Section L0.2, are two important loop assessment procedures. The experiments suggested in Section 2.7 to obtain the processdynamics are also loop assessmentprocedures for tuning the controllers. The checks and tests added in this section are basic, but often forgotten or neglected.
Signal Ranges The signal range of the measurement signal is related to the resolution of the sensor.A large signal range means that the resolution becomeslow. To obtain

334

10.3 Loop Assessment

0

0

0.2 0.4 0.6 0.8

0

Figure 10.8 The left diagrams show a procedure to determine the static process characteristic. Control signal u is changed stepwise, and the corresponding changes in process output y are determined. The right diagram shows the static process characteristic, i.e., process output y as function of control signal u.

a high resolution, it is therefore important to restrict the signal range to those values that are relevant for the control.
If the final control element is a valve, the output range is determined by the size of the valve. Valves are normally over-sized. The main reasons are insecurity among engineers combined with a fear of installing a valve that is too small to deliver the maximum possible flows.
A large valve has not the same accuracy as a smaller one. The friction and backlash problems discussed in the previous section are more severe if the valve is over-sized.
If the signal ranges are properly chosen and if the process is linear, the ideal static processgain is P(0) - 1. If the static gain is one, the measurement signal reaches its maximum value when the control signal is at its maximum value. Because of over-sizedvalves, the static processgain is often larger than one in process control applications.
Staticlnput-OutpuRt elations
From a control point of view, it is desirable to have a linear static input-output relation. This relation is, however, often nonlinear, mainly because of a nonIinear valve characteristic. Nonlinearities may also occur in sensors or in the process itself.
If the processis nonlinear, the control may be improved using gain scheduling or other forms of linearization. As pointed out in Section 9.3, it is important to understand the cause of the nonlinearity in order to determine a suitable gain-scheduling reference.
The static characteristic of the process can be obtained by determining the static relation between the control signal and the measured signal. This can be done by performing step changes in the control signal and measuring the corresponding changes in process output; see Figure 10.8.
The characteristic shown in Figure 10.8 is obviously nonlinear. It has a higher gain at larger control signals. If the stationary values of the measured
335

Chapter 10. Loop and PerforrrLe.nceAssessment
signal are plotted against the control signal, we obtain the static process characteristic. See Figure 10.8. A plot like this reveals whether gain scheduling is suitable or not.
Disturbances
Another important issue to consider before tuning the controller is the disturbances acting on the control loop. We have pointed out that it is important to know if the major disturbances are set-point changes (the servo problem) or load disturbances (the regulator problem).
It is also important to investigate the level of the measurement noise and its frequency content. Compare with Section 2.6. If the noise level is high, it may be necessary to filter the measurement signal before it enters the control algorithm. This is an easy way to get rid of high-frequency noise. If there are disturbances with a large frequency content near the ultimate frequency, it is not possible to use low-pass filtering to remove them. Feedforward is one possibility, if the disturbances can be measured at their source. Notch filters can be used if the noise is concentrated in a narrow frequency range. See Section 2.6 where noise modeling and measurements were discussed.
1 0 . 4 P e r f o r m a n cAe s s e s s m e n t
The loop assessment, followed by appropriate actions like valve maintenance, selection of signal ranges, linearization of nonlinearities, and controller tuning, should leave the control loop in good shape.
After some time in operation, the performance may, however, deteriorate because of variations in the processand the operation. Therefore, it is important to supervise the control loops and detect these degradations. This supervision has traditionally been made by humans, but the reduction of personnel in the processindustry combined with increasing quality demands have been a driving force behind developing procedures for automatic performance monitoring and assessment.This section provides some procedures for automatic supervision of control loop performance.
TheStaticInput-OutpuRt elation
If a detector for stationarity is available, it is simple to keep a statistic for the fraction of time that the system is stationary. The static input-output relation can then be obtained simply by logging the process input and output during stationary conditions. To obtain good data the signals should be filtered with respect to the time scale of the closed loop. Graphs like the ones shown in Figure 10.9 are then obtained. From these curves it can be determined whether the major variations in the output are due to set-point changes or load disturbances, i.e., whether we are dealing with a servo problem or a regulation problem. We have a servo problem if the experimental data gives a well-defined curve and a regulation problem if there is no definite relation between inputs and outputs. A simple statistic of the fraction of the total time when there are
336

.;i r!'
+
-++' t.
..ir
.f
:i. :i
:i

10.4 Performance Assessment

Figure 10.9 Examples of static input-output data logged during normal operation. The results shown in A, B, and C indicate a pure servo problem. The results in F indicate a pure regulation problem. Case D and E are mixed cases. Case B indicates poor resolution ofthe sensor,and case E indicates poor actuator sizing.
set-point changes or transients due to set-point changes is also a useful indicator. Of course, there are also systems that are mixtures of servo and regulation problems.
For a servo problem the variations in the static gain of a system can also be determined. This gives a valuable indication as to whether gain scheduling is required. The static gain curve can also be used for diagnostic purposes. Changes in the curve indicate changes in the process.By comparing the slope of the static gain curve with the incremental process gain measured during tuning or adaptation, we can also get indications of whether there is some hysteresis in the loop or not. It also indicates if actuators are properly sized.
Model-Based Diagnosis Most automatic supervisory procedures are, in principle, based on the idea shown in Figure 10.10. If a model of the processis available, the control signal can be fed to the input of the process model. By comparing the output of the model with the true processoutput, one can detect when the processdynamics change. If the model is good, the difference between the model output and the processoutput (e) is small. If the processdynamics change, e will no longer be small, since the two responses to the control signal are different.
HarrisIndex
One of the most widely applied supervisory functions is based on the Harris index. The idea is to calculate the variance of the processoutput, either on line or off line, and then compare it with the minimum variance obtainable. The
337

Chapter 10. Loop and Perforrnance Assessment
Controller
Figure 10.10 Model-based fault detection.
problem was discussed in Section 2.6. The Harris index is defined as
Iu:t-gfu-. oi
where o'r, is the minimum variance of the process output, and,o2nis the actual process output variance. The Harris index, Is, takes values between zero and one. If the index is close to zero, the actual variance is close to the minimum variance, which means that the control loop behaves satisfactorily. If the actual variance is large, the Harris index is close to one.
The method requires that the minimum variance o'uv is known. A nice feature of the method is that the minimum variance can be determined from the deadtime only, which means that the modeling can be made relatively simple. A drawback is that the minimum variance normally cannot be achieved with a controller as simple as the PID controller, which means that it is difficult to determine reasonable values of the Harris index. Furthermore, even if it is possible to obtain minimum variance control, this control is often undesirable since it may be very aggressive.
For these reasons, many variations of the Harris index have been presented where the minimum variance o2r, is replaced with the variance obtained using other design objectives and *hei" the limitations to the PID control structure are taken into account. The main drawback of these approaches is that they require a more accurate process model.
The performance monitoring tools based on the Harris index approach provides information about the loop performance compared to some ideal performance. There is no intention to detect any causes of possible bad performance. There are other performance monitoring tools that do not look at the overall performance, but instead try to detect certain types of problems. Some of these are discussed in the following subsections.
Oscillating Control Loops The most serious problem at the loop level is that many control loops oscillate. There are several possible causes of these oscillations; see Section 10.2. One reason might be that an oscillating load is disturbing the loop. Low-frequency load disturbances are eliminated efficiently by the controller, since a controller with integral action gives a high loop gain at low frequencies. Since the process normally has a low-pass character, high-frequency load disturbances are
338

10.4 Performance Assessment
s36
n h! a oJ+ L
O
r20
Figure 10.11 Stick-slip motion in a flow control loop.
filtered by the process.Therefore, high-frequency components in the measurement signal are normally not introduced in the processbut in the sensor or on the connections between the sensor and the controller. Since they do not contain any valuable information about the status of the process, they should be filtered out by the controller. It is also important not to transfer these signals to the controller output, since they may cause wear on the actuating equipment.
Disturbances with much energ'y near the ultimate frequency a)u are too fast to be treated efficiently by the controller, and they are too slow to be filtered out. These disturbances might even be amplified because of the feedback.
A badly tuned controller may be another reason for oscillations, in particular in nonlinear plants where a change in operating point might result in a too high loop gain. However, controllers in process control plants are ofben tuned conseryatively, and bad controller tuning is not the most likely cause of oscillations.
The most common reason for oscillations in control loops is, however, friction in the valve, resulting in "stick-slip" motion as discussed in Section 70.2.
Deteetion Oscillations in control loops can be detected in several ways. One way is to make a spectral analysis of the measured signal and look for peaks in the spectrum. A difficulty is that the oscillations often are far from pure sine waves, which means that no distinct peaks appear in the spectrum.
Figure 10.11 shows a recording from a flow control loop in a paper mill with high valve stiction. The figure shows the result of a step change in the set point. The controller used was a PI controller with gain K - 0.30 and integral time Tr : 34 s. Notice that the oscillations are far from a pure sine wave. A retuning of the controller gave controller parameters K - 0.19 and Ti : 2 s. Notice that the integral time was decreasedfrom 34 s to 2 s! A step
339

Chapter 10. Loop and Performance Assessment

s36
6 a
+li ) O

0

30

60

90

120

s

Figure 10.12 Stick-slip motion in a flow control loop - retuned controller.

responseexperiment using the new controller settings is shown in Figure L0.12. The settling time is significantly shorter than in Figure 10.11. It is also more obvious that the oscillations really are caused by friction, since the typical pattern of the measurement signal is close to a square wave and the control signal is close to a triangular wave.
Another approach to detect oscillations is to investigate the characteristics of the control error. The idea behind this detection procedure is to study the magnitude of the integrated absolute error (IAE) between successivezero crossings of the control error, i.e.,

rt;

J,,_, I A E :

le(t)ldt,

(10.1)

where /;-1 and ti arretwo consecutive instances of zero crossings. It is assumed that the controller has integral action, so that the average error is zero.
During periods of good control, the magnitude of the control error is small and the times between the zero crossings are relatively short. This means that t}re IAE values calculated from (10.1) are small when control is good.
When a load disturbance occurs, the magnitude of e(t) increases, and there is a relatively long period without zero crossings. This means that the corresponding IAE value becomeslarge.
When the control loop starts to oscillate, there will be a high frequency of large I AE values. This observation is used to detect oscillations in the control loop.

Exevpln 10.1-PuLp CoNCENTRATToCNoNrnol The following example is taken from a pulp concentration control section in a paper mill, where pulp is diluted with water to a desired concentration.

340

10.4 Performance Assessment
Process output y and estimated set point y'o

Control sisnal u

IAE and

0

200

400

Rate of load detections and rate limit n1,- : 1 0

0

200

400

600

FigUre 10.13 The oscillation detection procedure applied on a pulp concentration control loop.

The water valve had too high friction, and an oscillation detection procedure was connected to the controller. The controller was a PI controller with gain K - 0.33 and integral time Ti :24 s.
Figure 10.13 shows 10 minutes of data from the concentration control loop. The first graph shows the process output, the pulp concentration in percent. Because of high friction in the water valve, the process is oscillating with an
34r

Chapter 10. Loop and Performance Assessment
amplitude of a few percent. The first graph also shows an estimate of the set point, since this variable was not recorded. The estimate is simply obtained by a low-pass filtering of the process output.
The second glaph shows the control signal in percent. It is obvious that the controller tries to eliminate the oscillation but without success.
The third graph shows the IAE calculated between successivezero crossings of the control error. The graph also shows IAEIi^, which is the limit of what is considered large values of IAE.In this implementation, the value of IAEIi* is determined automatically from the controller parameters in each loop. The IAE values are significantly larger than IAE6^, indicating that the loop is oscillating.
The fourth graph finally shows the rate of load detections and the rate limit tlti* :10. The rate exceedsthe rate limit after about three minutes, and the detection procedure gives an alarm.
This example shows how the oscillation detection procedure manages to detect oscillations in control loops. The actual oscillations are easily noticed in Figure 10.13. However, process operators seldom have accessto these kinds of graphs, but are often left with a bar graph with a low resolution. The present oscillation had been present for a long time without being discovered by the process operators.
Diagnosis Since a control loop may oscillate for various reasons, it is important not only to detect the oscillation, but also to find the reason for oscillations. This can be done manually as described in Section 10.2.
Attempts have also been made to develop procedures for automatic diagnosis. Here, the difference in the spectrum can be used. When a control loop oscillates because of too high loop gain, the control error is often close to a sine wave, resulting in one single peak in the spectrum. The same holds in most cases when the loop is oscillating because of external disturbances. However, when the control loop is oscillating because of valve stiction, several peaks in the spectrum can be found.
SluggishControlLoops
Oscillations in control loops are common, but the opposite situation is also common, namely, that the control loops are sluggish because of conservative tuning. This causes unnecessarily large and long deviations from the set point at load disturbances.
The main reason for the controllers being conservatively tuned is lack of time. The engineers tune the controllers until they are considered "good enough." They do not have the time to optimize the control. Many controllers are tuned once they are installed, and then never again. To retain stability when operating conditions change, the controllers are tuned for the "worst case." A better solution would, of course, be to use gain scheduling and perhaps adaptation. When a controller is retuned, it is mostly becausethe process conditions cause oscillatory control. In other words, when the controllers are retuned, they are detuned. When the process conditions change to sluggish control, the controller is normally not retuned again.
342

-0.2 ' -o.4
-0.6 -0.8

1
0.5
0 01020304050
Figure 10.14 A good (solid lines) and a sluggish (dashed lines) response to a step change in load at the process input.

Detection Figure 10.14 shows two responses to load disturbances in the form of step changes at the process input. One response is good, with a quick recovery without any overshoot. The second response is very sluggish. One feature that characterizes the second response is that there is a long period where both process output y and control signal u drift slowly in the same direction. This feature is used for detection.
Both responses have an initial phase where the two signals go in opposite directions, i.e., A'uL,y < 0, where Au and a,y are the increments of the two signals. What characterizes the sluggish response is that after this initial phase there is a very long time period where the correlation between the two signal increments is positive. This observation forms the base for the Idle index, which expresses the relation between the times of positive and negative correlation between the signal increments.
To form the Idle index, the time periods when the correlations between the signal increments are positive and negative, respectively, are first calculated. The following procedures are updated every sampling instant

+'p-os I tro+"
\ roo'

if AuAy > 0 if AuAy S 0

tneg: IIht"""r*+ h

If LuA,y< 0 if A,uA,y) 0,

where h is the sampling peri od. The Idle index .I7is then definedby

t.,o"-tn..,g 7- r _
/posf /nes

(10.2)

Note that Ir is bounded to the interval [-1, 1]. A positive value of 17closeto 1 means that the control is sluggish. The Idle index for the sluggish response in

343

Chapter 10. Loop and Performance Assessment
Figure 10.14 is | : 0.82. A negative value of ,I7closeto -1 may be obtained in a well-tuned control loop. The Idle index for the good response in Figure 10.14 is | - -0.63. However, negative Idle indices close to -1 are also obtained in oscillatory control loops. Therefore, it is desirable to combine the Idle index calculation with an oscillation detection procedure like the one described above.
Calculation of the Idle index can be made both off line and on line using a recursive version. Since the method is based on the characteristics of signal increments, it is sensitive to noise. Therefore, it is important to filter the signals properly before they are differentiated.
Exaupln 10.2-CoNTRoL oF A Hnar ExcrnNcnR This example is taken from an industrial heat exchanger. The control objective is to control the water temperature on the secondary side by controlling the water steam flow on the primary side.
The upper graphs in Figure 10.15 show load responses obtained with a conservatively tuned PI controller. The controller parameters were K : 0.01 and fl : 30s. The signals are relatively noisy because of the low resolution, 1 percent, of the controller output. The control is sluggish. This is also well reflected by the Idle index, which was calculated to I7 - 0.8.
The controller structure was changed to a PID controller and tuned properly, resulting in the controller parameters K - 0.025, Ti :8s, and Ta :2s. The improved control behavior is illustrated in the lower graphs in Figure 10.15. The recovery after load disturbances is significantly faster, still without any noticeable overshoot. The integral gain ki is increased by almost a factor of ten. The improvements are also demonstrated by the Idle, which index that was reduced to /r : 0.3.
1 0 . 5 I n t e g r a t eTd u n i n ga n d D i a g n o s i s
The diagnosis procedures are related to the adaptive techniques in several ways. We have pointed out the importance of checking valves before applying an automatic tuning procedure. If not done, the automatic tuning procedure will not provide the appropriate controller parameters. For this reason, it would be desirable to have these checks incorporated in the automatic tuning procedures. Such devices are not yet available, and the appropriate checks, therefore, must be made by the operator.
The on-line detection methods are related to the continuous adaptive controller. The adaptive controller monitors the control loop performance and changes the controller parameters, if the process dynamics change. The performance assessment procedures also monitor the control-loop performance. They give an alarm instead of changing the controller parameters if the process dynamics change. As an example, in Figure 10.3 we have seen that it is important to determine why tll'e performance has changed before actions are taken. Most adaptive controllers applied to a processwith stiction will detune the controller, since they interpret the oscillations as caused by a badly tuned controller. Consequently, it is desirable to supply the adaptive controllers with
344

70 65
- 60 55 50 45
70 60
\qn
40 30
70 65
- 60 55 50

Figure 10.15 Control of a heat exchanger. The graphs show responses to load disturbances for a sluggish control loop with Idle index 1r : 0.8 (upper), and a properly tuned loop with Idle index Ir :0.3 (lower).

.ri

on-line detection methods, so that reasons for bad control-loop performance,

other than poor controller tuning, are detected. The lack of these kinds of de-

tection procedures in adaptive controllers are perhaps the major reason for the
tr-
relatively few applications of continuous adaptive control available today.
It

''l 'c -'

is.

1 0 . 6S u m m a r y

)n-

nd

It is important to make an assessment of the control loop before tuning the

eI'-

controller. This assessment includes checks of equipment such as sensors and

,ce.

valves, signal ranges, nonlinearities, and disturbances.

rfO-

When the loop assessment and the controller tuning is performed, the con-

tis

trol loop should behave well. Due to changes in the process and its operation,

are

the control loop may degrade after some time in operation. It is therefore im-

une

portant to supervise the control loops. This is traditionally done by humans,

ned

but methods for automatic supervision are becoming more and more used in

vith

process control.

345

Chapter 10. Loop and Performance Assessment
In this section, some examples of loop and performance monitoring tools have been presented. The section has only provided a short overview of the area. It has focused on methods for the single loops only. In recent years, many attempts have been made to derive methods for the performance monitoring of process sections including several control loops. However, these procedures are seldom general, but often developed for specific plants.
10.7 Notesand References
Early work on fault-detection was done by [Himmelblau, 1978]. Problems associated with the control valves were brought to a broader audience in the early nineties; see [Endea 1993; Bialkowski, 1994]. At that time there was also an awareness that it was beneficial to assess the performance of the control loops; see [Shinskey, 1990; Shinskey, 1991a; Astrtim, 1991]. The Harris index [DeWries and Wu, 1978], [Harris, 1989] is bassd on comparison with performance obtained by minimum variance control [Astrdm, 1970]. The concept has been extended and applied in various processcontrol applications; see e.g. [Desborough and Harris, 1992; Stanfelj et a1.,1993; Harris et al., 1996; Kozub and Garcia, 1993; Kozub and Garcia, 1996; Harris et al., 1996; Owen et al., 1996; Lynch and Dumont, 1996;Harris et a1.,1999;Thornhill et a1.,19991T. he oscillation detection procedure is described in [Hagglund, 1995] and [Thornhill and Hiigglund, 19971,and the Idle index is presented in [Hiigglund, 1999]. Good surveys of the area are presented in [Qin, 1998; Huang and Shah, 1999; Horch, 20001.A method for reducing the effect of friction in valves was developed by [Hagglun d, 2002].
346

11
Interaction
1 1 . 1I n t r o d u c t i o n
So far we have focusedon control of simple loops with one sensor,one actuator, and one controller. In practical applications, a control system can have many loops, sometimes thousands. In spite of this, a large control system can often be dealt with loop by loop since the interaction between the loops is negligible. There are, however, situations when there may be considerable interaction between different control loops. A typical case is when several streams are blended to obtain a desired mixture. In such a case it is clear that the loops interact. Other cases are control of boilers, paper machines, distillation towers, chemical reactors, heat exchangers, steam distribution networks, drive systems, and systems for air-conditioning. Processes that have many control variables and many measured variables are called multi-input multi-output (MIMO) systems. Because of the interactions it may be difficult to control such systems loop by loop.
A reasonably complete treatment of multivariable systems is far outside the scopeof this book. In this chapter we will briefly discuss some issues in interacting loops that are of particular relevance for PID control. Section 11.2 gives simple examples that illustrate what may happen in interacting loops. In particular it is shown that controller parameters in one loop may have significant influence on dynamics of other loops. Bristol's relative gain array, which is a simple way to characterize the interactions, is also introduced. The problem of pairing inputs and outputs is discussed, and it is shown that the interactions may generate zeros of a multivariable system. In Section 11.3 we present a design method based on decoupling, which is a natural extension of the tuning methods for single-input single-output systems. Section 11.4 presents problems that occur in drive systems with parallel motors. The chapter ends with a summary and references.
11.2Interactionof SimpleLoops
In this section we will illustrate some effects of interaction in the simplest case
347

Chapter 11. Interaction

Process

Figure 11.1 Block diagram of a system with two inputs and two outputs (TITO).

of a systemnrith two inputs and two outputs. Such a systemis calleda TITO system.The systemcan be representedby the equations

Yr(r):pn(r)Ur(r) + pnUz(s) Y z ( s ): p z t ( r ) U r ( r ) + p z z U z ( s ) ,

(11.1)

where pi1@) is the transfer function from the 7:th input to the l:th output. The transfer functions pn, pn(t), prr(s), and p22czn be combined into the matrix

P(s)- t;;[;:;];l[]

(11.2)

which is called the transfer function or the matrix transfer function of the system. Some effects of interaction will be illustrated by an example.

Exeupln 11.I-ETFECTS oF INTERACTToN Consider the system describedby the block diagram in Figure 11.1.The system has two inputs and two outputs. There are two controllers, the controller C1 controls the output yr by the input u1 and C2 controls the output y2 by the input u2. One effect of interaction is that the tuning of one loop can influence the other loop. This is illustrated in Figure 1I.2, which shows a simulation of the first loop when C1is a PI controller and C2 : kz ts a proportional controller.
The example shows that the gain of the second loop has a significant influence on the behavior of the first loop. The response of the first loop is good when the second loop is disconnected, kz : 0, but the system becomes more sluggish when the gain of the secondloop is increased. The system is unstable for k2: 0.8.
Simple analysis gives insight into what happens. In the particular case the system is described by
r'(,:) #-Fu'(,.)#-puz(,) Yz(: ,#) aru,(,.)#-Fuz(,)

348

'I
0.5
-0
AR
J I
10

11.2 Interaction of Simple Loops

sc

0

v

t

4

6

I

10

12

14

16

18

20

Figure 11.2 Simulation of responses to steps in set points for loop 1 of the system in Figure 11.1.Controller C1 is a PI controller with gains kr: l, ki: I, and the G is a proportional controller with gains k2 : 0,0.8, and 1.6.

The feedbackin the secondloop is Uz(t) - -kzYz(s). Introducing this in the second equation gives

uz(s)

kz

s21 2s*kz*I-'

and insertion of this expression for Ur(t) in the first equation gives

Y1(r): e1'r(r)U,(-r)

s 2 + 2 s J - I _ k , , u,(s).

This equation shows clearly that the gain k2 inthe secondloop has a significant effect on the dynamics relating uy and y1. The static gain is

i

s^i it .(^u. ):

l-k,
T+ kr.

i

Notice that the gain decreasesas k2 increases and that the gain becomesneg-

e

ative for k, > l.

T

e

The example indicates that there is a need to have some way to determine if

interactions may cause difficulties. A simple measure of interaction will now

IC

be discussed.

Bristol'sRelativeGainArray
A simple way to investigate the effect of the interaction is to investigate how the static processgain of one loop is influenced by the gains in the other loops. Consider first the system with two inputs and two outputs shown in Figure 11.1. We will investigate how the static gain in the first loop is influenced by the

349

Chapter 11. Interaction

controller in the second loop. To avoid making specific assumptions about the controller, Bristol assumed that the secondloop was in perfect control, meaning that the output of the second loop is zero.It then follows from (11.1) that

h(s) : pn(s)Ur(r) + pnUz(s) 0 - pzt(r)Ur(r) + pzzUz(s).

Eliminating U2(s) from the first equation gives \rzt (,s- /\ : p n ( s ) p z z ( t )- P n ( s ) p 2 r ( t )u, ,t (,s- ,/ . prdr)

The ratio of the static gains of loop 1 when the second loop is open and when the second loop is closed is thus

p r r( o ) p z(zo ) ) , - pn(O)pzz(0-) prz(0)pz(r0)'

(11.3)

Parameter 2 is called Bristol's interuction index for TITO systems. Notice that the index refers to static conditions. In practice this can also be interpreted as interaction for low-frequency signals. There is no interaction if pn(O)pzt(O) : 0, which implies that )" - 1. Small or negative values of 2 indicate that there are interactions. Consider, for example, the system in Example 11.1 where the interaction index is )" : -1, which indicates that interactions pose severe
difficulties. The interaction index can be generalized to systems with many inputs and
many outputs. The idea is to compare the static gains for one output when all other loops are open with the gains when all other outputs are zero. The result can be summarized in Bristol's relatiue gain array (RGA) which is defined as

R:P(o).*P-"(o),

(11.4)

where P(0) is the static gain of the system, P-"(0) the transpose of the inverse of P(0), and .* denotes component-wise multiplication of matrices. The element r;7 is the ratio between the open-loopand closed-loopstatic gains from the input signal ui to the output yi. lt can be shown that the matrix .R is symmetric and that all rows and columns sum to one. Notice that Bristol's relative gain array only captures the behavior of the process at low frequencies.
For the system (11.1) the relative gain array becomes

R-l,!^';^)

(11.5)

where 2 is the interaction index (11.3). There is no interaction if )" : t. This means that the second loop has no impact on the first loop and vice versa. If 2 is between 0 and 1 the closed loop has higher gain than the open loop. The effect is most severe for 7: 0.5. If 2 is larger than 1 the closed loop has lower gain than the open loop. When 2 is negative the gain of the first loop changes sign when the second loop is closed. The effect of the interactions is thus severe.

350

11.2 Interaction of Simple Loops

Pairing
To control a system loop by loop we must first decide how the controllers should be connected, i.e., if .7r in Figure 11.1 should be controlled by u1 or u2. This is called the pairing problem.
The relative gain aftay can be used as a guide for pairing. There is no interaction if )" : 1. If )" : 0 there is also no interaction, but the loops should be interchanged. The loops should be interchanged when 1 < 0.5.If 0 < )" < I the gain of the first loop increases when the second loop is closed, and if ), > I the closed-loop gain is less than the open-Ioop gain. Bristol recommended that pairing should be made so that the corresponding relative gains are positive and as close to one as possible. Pairing of signals with negative relative gains should be avoided. If the gains are outside the interval 0.67 < 1 < 1.5, decoupling can improve the control significantly. We illustrate pairing with an example.

Exauplp ll.2-ParRrNG oF STcNALS Consider the system in Example 11.1. The static gain matrix is
P(:0t)l ?l

Its inverseis

r _ 1 1 0:; [;,

_ r ,]

and the relative gain arcay becomes

t; _ila: ::,) R

:

P

( o.)*

P

- r\(/o:)

(:
11

?r )l

-

which means that )" - -1. The pairing rule says that y1 should be paired with
U2.
When uL : -kzyz the relation betwae-ru' 2 and y1 becomes

Y'(r) : s"rtz(s)Uz(-r-)

UrG),

and the static gain is

2+kz
g'rlr(o) : L+kz

The gain decreaseswith increasing kz, but it is never negative for k2 ) 0. There

is interaction but not as severe as for the pairing of y1 with a1. The properties

of the closed-loop system are illustrated in Figure 11.3. A comparison with

Figure 11.2 shows that there is a drastic reduction in the interaction when the

inputs are switched.

T

351

Chapter 11. Interaction

1
il
' '0.5
0 1

Sos

0

Figure 11.3 Simulation of responses to a step in the set point for y1 of the system in
Figure 11.1 when the loops are switched so that the controller for yl is U2: Cr(s)(%pr Y1) and the controllerfor y2isu1: -kz!2 with fr2:0,0.8, and 1.6.The controller G is a PI controller with gains &1 : l, ki : l.

MultivariablZeeros
In Section 4.3 we found that right-half plane zeros imposed severe restriction on the achievable performance. For single-input single-output systems the zeros can be found by inspection. For multivariable systems zeros can, however, also be created by interaction. One definition of zeros that also works for multivariable systems is that the zeros are the poles of the inverse system. The zeros of the system (11.1) are given by

detP(s) : prr(t)prt(r) - pn(s)pzr(s): 0.

(11.6)

Zeros in the right half plane are of particular interest becausethey impose limitations on the achievableperformanceW. e illustrate this with an example.

Exauplo 11.3-RosENBRocK'ssysrEM Considera systemwith the transfer function

P(s): ti;l;i;:;Jl[:t]++l (11.7) ts+1 r+1.,

The dynamics of the subsystems are very benign. There are no dynamics limitations in control of any individual loop. The relative gain array is

R" _

(L t1

rlt) 1)

.(3 l.-z

-3JB )-

[3 |.-z

-2) B )'

which shows that there are significant interactions. Using the rules for pairing we find that it is reasonable to pair u1 with y1 and u2 with y2. Since I > I.s

352

11.2 Interaction of Simple Loops

1 0.5
0
1
N
U.J
0 4
s'2
0
0
1
N
-z

Figure 11.4 Step responses of the process (11.7) with PI control of both loops. Both PI controllers have gains k : 2 and ki : 2. A step in J"pt is flrst applied at time 0, and a step in Jspzis then applied at time 15.

we can expect difficulties becauseof the interaction. It follows from (11.6) that the zeros ofthe system are given by

detP(:s#)(#-*)

:

1-s

-0.

(s+1)2(s+3)

There is a zero at s : 1 in the right half plane, and we can therefore expect

difficulties when control loops are designed to have bandwidth larger than

0o:I.

Consider, for example, the problem of controlling the variable y1. If the

second loop is open we can achieve very fast response with a PI controller.

When the second loop is closed there wiII, however, be severe performance

limitations due to the interactions, and the control loop has to be detuned. Figure 11.4 shows responsesobtained with controllers having gains k - 2 and ki - 2 in both loops. In the figure we have first made a unit step in the set

point of the first controller and then a set-point change in the secondcontroller.

The figrre shows that there are considerable interactions. The system becomes

unstable if the gain is increased by a factor of 3.

n

Example 11.3 illustrates that an innocent-looking multivariable system may have zeros in the right half plane. The opposite is also possible, as is illustrated by the next example.

353

Chapter11. Interaction

Exaupln ll.4-BnNEFrcrAL lNrnnacuox Considerthe system

P(s):

;;[J::] I rrr(s)
( pzr(t)

l s-1

(s+1)(s+2) (s+1)(s+2)

-6

s-2

( s+ 1 ) ( s+ 2 ) ( s+ 1 ) ( s+ 2 )

(11.8)

The system has the relative gain array

R-

(r
lo

0\
r)'

which indicates that y1 should be paired with u1 and that y2 should be paired

with u2. Th.e multivariable system has no zeros. We thus have the interesting

situation that there are severe limitations to control either the first or the

second loop individually because of the right-half plane zeros in the elements

p11 and p22. Since the multivariable system does not have any right-half plane

zeros it is possible to control the multivariable system with high bandwidth.

This is illustrated in Figure II.4, where both loops are controlled with PI

controllers having gains ft : 100 and k; - 2000. Notice the fast response of the

system. One difficulty is, however, that the system becomes unstable if one of

the loops is broken.

t]

1 1 . 3D e c o u p l i n g

Decoupling is a simple way to deal with the difficulties created by interactions

between loops. The idea is to design a controller that reduces the effects of the

interaction. Ideally, changes in one set point should only affect the correspond-

ing process output. This can be accomplished by a precompensator that mixes

the signals sent from the controller to the process inputs. The details will be

given for systems with two inputs and two outputs, but the method can be

applied to signals with many inputs and many outputs.

Assume that the process has the transfer function (11.2) and that P(0)

is nonsingular. We first introduce a static decoupler u. : Du, where D is a

constant matrix

D- l1:':,:)

The transfer function from u to y is then given by P(s)D. The choice

D:P-:,n(o")rir[l:;;li];,l?ilJ' (11.e)

makes P(O)D the identity matrix. The system P(s)D is thus statically decoupled, and the coupling is small for low frequencies. The coupling remains small if the system is controlled by decoupled controllers, provided that the bandwidths of the control loops are sufficiently small.

354

1.5
1
-H
0.5
0
1<
1
c\

11.3 Decoupling

100 50
\
0 -50 100
S50
0
Figure 11.5 Step responsesof PI control of the process(11.8) when both loops are closed. PI controllers with gains A : 100 and &; : 2000 are used in both loops.

Assuming that the controllers are PID controllers we find that the statically decoupled controller is described by

f
(

d
.2

'(
(r

r)%
)Y,p

p r(sz ( s )-

)

c c

1(s)Y1(s l
z ( s ) Y z G)

)

where [/ is the control signal, Y the processoutput, and Y"othe set point. The controllers are PID controllers with set-pointweighting,hence,

ci :

k" hpi + I

kpis,

Ei : bikp, + Lli

ss

where b; is the set-point weight. The set-point weights influence the interaction between the loops. Choosing bi :0 gives the smallest interaction.
355

Chapter11. Interaction

The DecoupledSystem The transfer function of the decoupledsystemis Q(t) : P(s)D, where

9 r r ( s )-

p r r ( s ) p z z ( o-) p r z ( s ) p z(ro ) d e tP ( 0 )

qt (t) :

p n ( s ) p tt ( 0 ) - p r z( 0 ) p u( s ) d e tP ( 0 )

pzr(s)pzz(O-) pu,(O)pzz(s)

qrt(t) :

d e tP ( 0 )

pzz(s)pn(0)- pzr(s)prz(0)

Q z z ( s )-

d e tP ( 0 )

It follows from the construction that 8(0) is the identity matrix. A Taylor series expansion of the transfer function Q(s) for small lsl gives

Q(s' )-

(t
(Kzrs

t':''l
II

for some constants K12and r21. For low frequencies al, the diagonal elements

of Q(s) are equal to one, and the off'diagonal elements are proportional to s. If the bandwidth of the decentralized PID controller is sufficiently low, the

off-diagonal terms will thus be small, and the system will be approximately

decoupled. The closed-loopsystem can be described by

- ',::::J (I+Qnct J (1:,7, I

Qtzcz

" ",", ( gzrcr l*q22c2

where the dependencyon s is suppressed to simplify the notation. This equation

can be written as

Y : HY,p,

where

hn htz: ;
tt2\:
hn -

e t E t ( l - l q 2 2 c z-) Q n q z r E ( z ( 1+ q r r c r ) ( 1-t-Qzzcz-) QtzQzrcrcz
q p c 2 ( I * qzzcz)- QnQzzczcz ( 1 * g r r c r ) ( t + Q z z c z-) Q n Q z t c t c z
Q z t c t ( 1* c r g r r ) * Q n q z t c i t ( 1 * q r r c , ) ( 1 + q z z c z -) Q n Q z ( r c z
e z z c z ( l* q 1 1rc) - Q n q z ( t E z ( 1 * Q r r c r ) ( t + q z z c z-) Q n Q z ( t c z

Since we designed the controllers so that the interactions are small, the term erzezt is smaller than enezz.The matrr* H can then be approximated by

HxH:

( Qttct
lI Qztct
lt+qrp,

lQtzcz
L * q1c1 QzzEz
| * q22c2

356

^l

The diagonal elements of H are the same as for SISO c(,r:::- -,,standard methodsfor designof PI controllerspresentedin Chapi.'r'-, beusedtofindthecontro1Iersc1andcz.ByanaIysingtheoff-dlii$rlJ1.' we can estimate how severe the interactions are. The controllers mar r..:.. be detuned to make sure that the interactions are tolerable. The interi.rr:. :. can be reduced arbitrarily by making the control loops sufficiently slori'. Tir.interaction analysis also gives the performance loss due to the interaction. It much performance is lost it is advisable to consider other design methods.

Estimating Effects of Interaction
A simple way to estimate the effects of the interactions will now be developed. The off-diagonal elements of H are given by

h r o: Q n e z I * qscl
' y e 1: Qzti t I I q22c2
Notice that grr(0) : qzt(O) - 1 and that qp x K12sand q21(") o K21sfor small s. Since the controllers have integral action, we have for small s

n| n \,s, ) *

Kpk72S tr,r '

|h

z

t/(, s

J

N

K2 -k;

1 -

k

1

f

The interaction is thus very small at low frequencies, and we can thus guarantee that the interaction is arbitrarily small by having sufficiently slow controllers. To estimate the maximum of the interaction. we observe that

h n : Qn c z S r hzt : QztESt z,

where Sr : (1*grtcr)-l and Sz : (l*q22c2)-1 are the sensitivity functions for

the loops when the interaction is neglected.A crude estimate of the interaction

terms is thus

m1x lh n(t at)l * lrctzlknMg

mgx lh2r(f ot)l = lrculk1M,z,

where Ms and M,2 arc the maximum sensitivities of the individual loops and where we have also used the estimate

qrz(s)x K12s, qzr(s)x K21s

and E1x k l y f s , E 2x k72fs.
The interaction can thus be captured by the interaction indices

Kl : lrcrrkrzlMt, Kz: lKztkrtlMrz.

(11.10)

The index K1 describes how the second loop influences the first loop, and rc2 describes how the first loop influences the second loop. Note that the term tcp depends on the system and the integral gain kp rn the secondloop. Interaction can thus be reduced by making the integral gains lower. The estimates are not precise because of the approximations made. They are not reliable when there is a significant difference in the bandwidths of the loops.

357

Chapter 11. Interaction

Examples
The design method will be illustrated by two examples. We will start by investigating Rosenbrock's system.

Exaupln 11.5-RosENBRocK's Sysrnna Consider the system in Example 11.3 where the processhas the transfer function (LI.T). We have

D:P-r(o:) (:'ltl-'-
[1 r )

[|-.3t ^

-:l
3)

If we introduce static decoupling, the compensated transfer function becomes

3(1- s)

4s

(s+ 1)(s+ 3) (s+ 1)(s+ 3)

8(:"I) ] - ['-:''ui1:] 01

s*1

The interaction is given by rct : 413 and r21 - 0. Since Ka.: 0, interaction gives no performance limitations for the second loop. There are, however, limitations because of the right half-plane zero at s : 1. Designing a PI controller that maximizes integral gain subject to the constraints that the maximum sensitivity Ms and the maximum complementary sensitivity Mpr are less than 1.6, g i v e s k p t : 0 . 2 9 7 5 a n d k 7 1: 0 . 3 4 2 0 .
Since Kr2 : 413 there are constraints on the design of the first loop because of the coupling. Requiring that the coupling 11 be less than 0.5 and the maximum sensitivity M,z be less than 1.6, we find that the integral gain of the secondloop fr72must be less than rclf(rceM,tMrz) :0.23. To design a PI controller, we use a placement procedure where the fast process pole s - -1 is canceled.The gain in the secondloop is then kpz:0.23.
Figure 11.6 shows the frequency responsesof hn, hn, and h22.The largest magnitude of the term hp is 0.26, which is half of the estimated value. The reason for the discrepancy is that the the simple estimate qtz N K12soverestimates the term.
Figure 11.7 shows simulations of set point responsesfor the closed-loopsystem. The solid lines show the responsesfor controllers with set-point weighting bt : 0 and bz :0. The dashed line shows the responses for controllers with error feedback. The plots show the proposed design with set-point weighting (bt : bz : 0). A unit step in the set point of the first controller is applied at time t -- 0, and a step in the set point of the second controller is then applied at time t : 20. Figure 11.7 shows the step responses for a controller without set-point weighting. The figure clearly indicates the advantage of set-point weighting for multivariable systems. The reason why there is such a large difference is that the control signal is much smoother with set-point weighting.
The effect of set-point weighting is illustrated also in Figure 11.6, which shows the frequency responseof the closed-loopsystem with (solid) and without (dashed) set-point weighting. The interaction increases considerably when no set-point weighting is applied.

358

lfrrrl
100
-1
10

lhnl
100
10-'

11.3 Decoupling lhrrl
100
_1
10

1n -

1

_
0

-2

100

1

0-21

_
0

2-

100

-L 1 01 0_9-

100

Figure 11.6 Frequency responses of the closed-loop system with set-point weighting (dashed) and without (solid). Note that without set-point weighting the interaction 1nrr1irr1l is larger and extends to higher frequencies.

Distillation columns are typical industrial processeswhere interaction is significant. The next example deals with such a case.

Exeupln 11.6-TnE WooD-Bpnnv BnIARv Dtstu-t RTIoN Colur,tN

The Wood-Berry binary distillation column is a multivariable system that has been studied extensively. A simple model of the system is given by the transfer

function

P(:s)t2.8e-' _18.9e-3r 16.7s*1 21.0s*1 I 6.60e-7' _Ig.4e-3' 10.9s*1 14.4s*l

Designing a static decoupler we find that

Q ( r ):

P

(

s

)

P

-

t

(-o

) [|

t:lt-o.s

is rs

a

-t':t' s1 - r z .

J

sI

)

'

Hence, Krz: -I2.3I and r21 - -0.5138. Designing PI controller for the diago-

nal elements by maximizing integral gain subject to the robustness constraint

M , : 1. 6 g i v e s k t :2 .3 4 8 1 , k i t : 1 .5 378,kz :0.5859, and ki 2 - 0.2978.The

sensitivity frequencies are o)sr : 0.30 and @s2:0.11. Notice that the second loop is slower than the first loop. We have Kt :5.8 and K2 - L.26, which indi-

cates that the interaction imposes constraints on the achievable performance

and it is necessary to detune the controllers. This is illustrated by the dashed

curves in the simulation shown in Figure 11.8. To reduce the interactions we

will detune the controllers by decreasing the integral gains. As a first attempt

we will reduce both integral gains by a factor of four. This implies that the

integrated error for load disturbances is four times larger than for an uncou-

pled loop. Using the simple gain reduction rule developed in Section 7.9 we

find that the proportional gains should then be reduced by a factor of two; see

(7.27). The solid lines in Figure 11.8 show that the responsesgive a significant

reduction of the interactions. The interaction can be reduced further at the

price of lowered performance.

n

359

Chapter 11. Interaction
-
1
Sos
0 4 SZ I

\t

\

I

10

1q

Figure 11.7 Simulation of the design method applied to Rosenbrock's system. The figure shows the response of the outputs to steps in the command signals. The PI controllers have gains Ap1 : 0.30, krt : 0.34, kp2 : 0.23, kn :0.23. The dashed lines show results with error feedback, and the solid lines show results with zero set-point weights.

11.4ParalleSl ystems
Systems that are connected in parallel are quite common, particularly in drive systems. Tlpical examples are motors that are driving the same load, power systems, and networks for steam distribution. Control of such systems requires special consideration. To illustrate the difficulties that may arise we will consider the situation with two motors driving the same load. A schematic diagram of the system is shown in Figure 11.9.
Let at be the angular velocity of the shaft, J the total moment of inertia, and D the damping coefficient. The system can then be described by the equation

J#rDa-Mt*Mz-My,

(11.11)

where M1 and M2 are the torques from the motors and My is the load torque.
ProportionaGl ontrol Assume each motor is provided with a proportional controller. The control

360

11.4 Parallel Sttstems

n
1T

i

,l

h o.s

0

16
1
-N " 'N A " / t r
0I I

I =./
I

0.6 f,
0.4r t ) u.z
0

0.2 I I
0.1
U \z
-0.1

\

100

150

Figure 11.8 Simulation of decoupling control of Wood-Berry's distillation column. The figure shows the response of the outputs to steps in the command signals. The dashed curves show responses with PI controllers having gains kp1 : 2.348, krt : I.537, kpz : 0.586, and k72: 0.298. The solid lines show responses with detuned PI controllers. The g a i n s a r e k p r : 1 . 1 1 9 , k r r : 0 . 3 8 4 , k p 2 : 0 . 2 9 3 , a n d k p : 0 . 0 7 4 5 . T h e s e t - p o i n tw e i g h t s ate zero in all cases.

Figure 11.9 Schematic diagram of two motors that drive the same load.

strategies are then

M1 - MrclKt(tD,o-o) Mz:Mzo*Kz(orp-o).

(11.12)

In these equations the parameters Mn and M2s give the torquesprovidedby

361

Chapter 11. Interaction

each motor when , - asp and K1 and K2 are the controller gains. It follows from (11.11)and (11.12)that

- dat J dt +

@

*

Kt*

K2)a - Mn*

Mzo- Mr + (Kr * K2)rtt,o'

The closed-loop system is, thus, a dynamical system of first order. After perturbations, the angular velocity reaches its steady state with a time constant

'r-y t _

J
D+Kl

+K{

The response speed is thus given by the sum of the damping and the controller gains. The stationary value of the angular velocity is given by

Kt*Kz

Mrc*Mzo-Mr

A) : A)0:
D-fKt*Kz

orp t

D+Kr-lKz

This implies that there normally will be a steady-state error. Similarly, we find

from (11.12) that

Mr-Mrc

Ky

M, - Mn: K{

The ratio of the controller gains wiII indicate how the load is shared between the motors.

Proportional and Integral Control
The standard way to eliminate a steady-state error is to introduce integral action. In Figure 11.10 we show a simulation of the system in which the motors have identical PI controllers. The set point is changed at time 0. A load disturbance in the form of a step in the load torque is introduced at time 10, and a pulse-like measurement disturbance in the second motor controller is introduced at time 20. When the measurement error occurs the balance of the torques is changed so that the first motor takes up much more of the load after the disturbance. In this particular case the second motor is actually breaking. This is highly undesirable, of course.
To understand the phenomenon we show the block diagram of the system in Figure 11.11. The figure shows that there are two parallel paths in the system that contain integration. This is a standard case where observability and controllability is lost. Expressed differently, it is not possible to change the signals M1 and M2 individually from the error. Since the uncontrollable state is an integrator, it does not go to zero after the disturbance. This means that the torques can take on arbitrary values after disturbance. For example, it may happen that one of the motors takes practically all the load, clearly an undesirable situation.

How to Avoid the Difficulties
Having understood the reason for the difficulty, it is easy to modify the controller as shown in Figure lI.l2.In this case only one controller with integral

362

11.4 Parallel Systems

1 0.5
0

0.4

,"-..-3- ]

M2 0

0 -1
Figure 11.10 Simulation of a system with two motors with PI controllers that drive the same load. The figure shows set point ,)sp, process output a,t,control signals M1 and M2, load disturbance My, and measurement disturbance n.
Motor 1

Figure 11.11 Block diagram for the system in Figure 11.10.

Figure 11.12 Block diagram of an improved control system.

363

Chapter 11. Interaction
Figure 11.13 Simulation of the system with the modified controller. The figure shows set point ,)sp, process output a;, control signals My and M2, load disturbance M7, and measurement disturbance n.
action is used. The output of this drives proportional controllers for each motor. A simulation of such a system is shown in Figure 11.13. The difficulties are clearly eliminated.
The difficulties shown in the examples with two motors driving the same load are accentuated even more if there are more motors. Good control in this case can be obtained by using one PI controller and distributing the outputs of this PI controller to the different motors, each of which has a proportional controller. An alternative is to provide one motor with a PI controller and let the other have proportional control. To summarize, we have found that there may be difficulties with parallel systems having integral action. The difficulties are caused by the parallel connection of integrators that produce unstable subsystems that are neither controllable nor observable. With disturbances these modes can change in an arbitrary manner. The remedy is to change the control strategies so there is only one integrator.
1 1 . 5S u m m a r y
Even if a large control system may have many sensors and many actuators it can often be controlled by simple controllers of the PID type. This is particularly easy when there is little interaction in the system. In this chapter we have presented simple measures of interaction. They can be used to judge if the 364

11.6 Notes and References
control problem can be solved using simple loops. Bristol's relative gain array can also be used to find pairs of inputs and outputs that are suitable for singleloop control. A simple design method that can be applied to systems with interaction has also been presented. This method combines static decoupling with the methods for design of single-loop controllers presented earlier in the book. Control of drive systems with parallel motors has also been discussed. For such systems there are particular problems with controllers having integral action.
1 1 . 6N o t e sa n d R e f e r e n c e s
Some fundamental issues related to interaction in systems are treated in [Rijnsdorp, 1965a; Rijnsdorp, 1965b; McAvoy, 1933]. The relative gain array was introduced in [Bristol, 1966]. It has been used widely and successfully in the process industries [Shinskey, 1981; McAvoy, 1983]. The most well-known results on the RGA are that a plant with large or negative elements in its RGA is difficult to control and that input and output variables should be paired such that the diagonal elements of the RGA are as close as possible to unity [Grosdidier et al., 1985; Skogestad and Morari, 1987]. The RGA is based on the static gain of the process; an extension to account for dynamics is given in [McAvoy, 1983] . An alternative measure called the steady-state interaction indices was developed in [Chang and Davison, 1987] and it may provide a more accurate representation. Static and dynamic decoupling are treated in many textbooks in process control, e.g., [Seborg et al., 2004]. Recent contributions to the design of decoupled PID control include the work by [Adusumilli et al., 19981.Detuning for multi-variable PID control, as discussed in the paper, was treated in a heuristic setting by [Niederlinski, 1971]. The particular method presented in Section 11.3 is based on [Astrdm et a1.,20021,other methods for design of non-interacting systems are given in [Yuzu et al., 20021 and [Wang et aL.,2003]. Control of systems with strong interaction between many loops requires techniques that are very different from those discussed in this chapter; see [Cutler and Ramaker, 1930] and [Seborg et a]., 19861.Multivariable systems are treated in standard textbooks on process control such as [Luyben, 1990; Marlin, 2000; Bequette, 2003; Seborg et al., 20041.There are also books that focus on multivariable systems: see [Shinskey, 1981; Skogestad and Postlethwaite, 1996].
365

T2
Control Paradigms
12.1Introduction
Process control systems are normally complex with many control variables and many measured signals. The bottom-up approach is one way to design such systems. In this procedure the system is built up from simple components. The systems can be implemented in many different ways. Originally, it was done by interconnection of separate boxes built of pneumatic or electronic components. Today, the systems are typically implemented in distributed control systems consisting of several hierarchically connected computers. The software for the distributed control system is typically constructed so that programming can be done by selecting and interconnecting the components. The key component, the PID controller, has already been discussedin detail. In this chapter, we present some of the components required to build complex automation systems. We also present some of the key paradigms that guide the construction of complex systems.
A collection of paradigms for control is used to build complex systems from simple components. The components are controllers of the PID type, linear filters, and static nonlinearities. Tlpical nonlinearities are amplitude and rate limiters and signal selectors.Feedback is an important paradigm. Simple feedback loops are used to keep processvariables constant or to make them change in specified ways. Feedback has been discussed extensively in the previous chapters. Another important paradigm is feedforward. This was discussed in Chapter 5. The key problem is to determine the control variables that should be chosen to control given process variables. Another problem is that there may be interaction between different feedback loops. This was discussed in Chapter 11.
Section 12.2 glves an overview of the problem to design complex systems, and the two approaches top-down and bottom-up design are compared. This section also gives an overview and presents the outline of the chapter. The chapter ends with an example to illustrate how the different components and paradigms can be used. The process considered is a chemical reactor, and the design is given in Sectionl2.9. Some important observations made in the chapter are finally summarized in Section L2.10.
366

12.2 Bottom-Up and Top-Down Approaches
12.2 Bottom-Upand Top-DownApproaches
There are two general approaches for designing a complex system: bottom up and top down. In the bottom-up or Lego approach the system is designed by combining small subsystems. The top-down approach starts with a general overall design that is refined successively. In practice the approaches are often combined. In both approaches we need knowledge about the elementary building blocks or components of the system. The bottom-up approach requires principles for combining basic components, and the top-down approach requires principles for refining or decomposing a high-level objective so that it can be accomplished by the basic system components. Several components and control principles for composition and decomposition have been described earlier in the book. In this section we will give an overview of the approaches, and in later sections we will describe components and paradigms that have not been discussed previously.
The Bottom-Up Approach
Large control systems can be built from controllers, filters, and nonlinear elements. The components can either be separate pieces of hardware or function blocks implemented in software that can be combined graphically using cut and paste. Controllers and filters have been discussed in Chapters 3, 5, 9, and 11. The nonlinear elements will be discussed in Section 12.6.
Control principles like feedback, feedforward, and model following have been discussed extensively in Chapters 3 and 5. Other important control principles such as repetitiue control, cascadecontrol, mid-range control, split-range control, ratio control, and selector control will be discussed in Sections 12.3, 12.4,I2.5. and 12.6.
An advantage with the bottom-up approach is that the system can be commissioned and tuned loop by loop. There may be difficulties when the loops are interacting. The disadvantage is that it is not easy to judge if additional loops will bring benefits. The system can also be unwieldy when loops are added.
Top-Down Solutions
Top-down paradigms often start with a problem formulation in terms of an optimization problem. Paradigms that support a top-down approach are optimization, state feedback, observers, predictive control, and linearization. In the top-down approach it is natural to deal with many inputs and many outputs simultaneously. Since this is not the main topic of this book we will only give a brief discussion. The top-down approach often leads to the controller structure shown in Figure I2.l.In this system all measured processvariables y together with the control variables u are sent to an observer, which uses the sensor information and a mathematical model to generate a vector i of good estimates of internal process variables and important disturbances. The estimated state i is then compared with the ideal state r- produced by the feedforward generator, and the difference is fed back to the process. The feedforward generator also gives a feedforward signal uy, which is sent directly to the processinputs. The controller shown in Figure 12.1 is useful for process segments where there are several inputs and outputs that interact, but the
367

Chapter 12. Control Paradigms
Model and Feedforward
Generator

Figure 12.1 Block diagram of a controller based on model following, state feedback, and an observer.
system becomesvery complicated when there is a large number of inputs and outputs. In such a case it may be better to decomposethe system into several subsystems.
An advantage with the top-down approach is that the total behavior of the system is taken into account. A systematic approach based on mathematical modeling and simulation makes it easy to understand the fundamental limitations. Commissioning of the system is, however, difficult because many feedback loops have to be closed simultaneously. When using the top-down approach it is therefore good practice to first tune loops based on simulation, possibly also hardware in the loop simulation.
SoftComputing
Because of the widespread use of computers in control there has also been an influence on control from computer science. TWo particular paradigms that originated from artificial intelligence are neural networks and fuzzy control, which both emerged from research in artificial intelligence. These paradigms are presented in Section I2.7 and Section L2.8.This branch of computer science is also called soft computing.

12.3 RepetitiveControl
Attenuation of disturbances has been an essential theme in this book. For PID control we have focusedon elimination of constant or slow disturbances. In this section we will show that similar ideas can be used to eliminate other types of disturbances, particularly periodic disturbances. Problems of this type are common when there are cyclic operations.
In Section 4.3 it was shown that attenuation of disturbances is captured by the transfer function from load disturbance to process output

Gvd: L+PC,

(12.1)

where P is the process transfer function and C the controller transfer function, respectively. By designing a controller that has high gain at a particular fre-

368

12.3 RepetitiueControl

G r( ' )

Figure 12.2 Block diagram of a controller with positive feedback of a filtered signal.

quency disturbances with that frequency are effectively reduced. The control error is zero in steady-state if the gain is infinite.
Consider the controller in Figure l2.2.Intuitively the system works as follows. The filter Gr filters out the signal component that we would like to eliminate, and the output of GI is fed back to the input with positive feedback. The net effect is to create a high gain for the frequencies in the pass band of the filter G1.

Constant and Sinusoidal Disturbances
To investigate the properties of the system analytically we observe that the controller has the transfer function

C\(-s'l ):

--!-.
1 - G1(s)

(12.2)

When Gr(r) is a low-pass fiIter with transfer function

G1(s)- 1+s7'

we find that

c ( s:) n ( t + l ) , \ sl',/

which is the transfer function of a PI controller. Notice that the controller transfer function C(s) has infinite gain at zero frequency, which implies that the steady-state error is zero for constant disturbances.
When Gr(r) is the band-pass filter

G1(s)-

2( ross s2+ 2( atss* arfr'

we find that
c(s) - l'2^(ootu s"+a6
Notice that this transfer function has infinite gain for s : ia)g,which implies that the steady-stateerror is zerofor a sinusoidaldisturbanceof frequency(Do.

369

Chapter 12. Control Paradigms

PeriodicDisturbances
Periodic disturbances can be reduced by choosing

Gr (t) : e-'L ,

where .L is the period of the disturbance. With this filter we find

c)"( s )-

h T_ -n

The relation between control error and control variable is

(L2.3)

u(t):ke(t)+u(t-L)'

The control action at time / is thus a sum of the control error and the control signal at time t - L.
The controllerhas infinite gain for s -2nxiIL, n:0, 1,.... A controllerof this type is particularly useful when disturbances or set-point variations are periodic.
The transfer function from load disturbance to output (12.1) is

Gn/\) ya(s):r.#e1,;:ffi

The relation between load disturbance and output is then (I - e-'r + kP(s))Y(r) - p(r) (I - e-'L)D(r).
Notice that the time function corresponding to (1 - e-'L)O(s) is

werrhoircchvauasneidsbhy eiarsDperiisod"icod"i's,

ouL(ki'l*.?;,r, p
turbance is thus zero.

er

iozd.

rhe

steady

-sta

te

The effective disturbance rejection does, however, come at a price that is

illustrated with the following example.

Exalrplp 12.1-AN ExrRnuB Casn Consider a process with the transfer function

P(s) : -'L,

with the controller

1 C (\ s/) : l - e - t L = .

that attenuates periodic disturbances.

The loop transfer function

G',\(s/) :

n-tt =
I-e-tL

370

12.3 Repetitiue Control

is periodic with period 2nf L, and its gain is infinite for at - 2nnlL. The frequency response is

: - r - , G1(ia)

1

sintttL

2 (I - c osatL)

.1 _ t -" tan(aL l2)'

The Nyquist curve is a vertical line through the point Gt : -0.5 and a half circletotheright.Thiscurveistransversedoncefor0{o< infinitely many times when at increases towards infinity.
The system has the gain margin 2 and the phase margin is 60". The sensitivity functions are

S(s)- !-e-'L ?(s) - -'L,

and we find that M, : 2 and Mt : I. A superficial look at traditional robustness measures like gain margin gm :
2, phase margin g* -- 60", and maximum sensitivities M' : 2 and Mt : 1 may indicate that the system is robust to process perturbations.
The fact that T (ia) : 1 for all frequencies is, however, an indication that the system has unusual properties. Further insight is obtained by analysing the effect of parameter variations. The system has only one parameter, the time delay L, and we will investigate the effects of variations in the time delay. To use the robustness inequality (4.32) *u will convert time delay variations to an additive process perturbation. Assume that the time delay changes from L toL+dZ.then
n-s(L+|L) : s-sL r-s6L - e-tL + r-sL 1u-s6, _ f).

A variation in the time delay can thus be represented by the additive perturbation
AP(s):s-sL(e-'6r -1)'
Hence ltP(iat)l: ls-ia'L - \. Since lP(io)l : 1, the robustness inequality @.32) becomes
t r # : l s - i , " ' r - 1 t< 1 r [ 6-1,

This inequality is not satisfied for any 6 L > 0 because the left-hand side is 2

and the right hand side is 1, and we cannot guarantee stability for an arbitrary

small perturbation in the time delay.

n

The example shows that the effective attenuation of periodic disturbances comes at the cost of the system being extremely sensitive to parameter variations. A compromise between disturbance attenuation can be made by replacing G1(s) in Figure 12.2 by aG1@) with a < 1. The controllers obtained for

371

Chapter 12. Control Paradigms

102
^ Er o '
rY
1 0100_?-
102

rY
100 10 - 1
102

-q
- 10-

1o-3

1o-2

1o-t

1oo

101

a lao

Figure 12.3 Gain curves of Bode plots for the controllers C.onrs(top), C.i.," (middle), and
Cp". (bottom). The parameter a is 0.99 in all cases, which means that the largest gains of the controllers are 100. For the band-pass filter we have ( - 0.1, and for the repetitive controller we have T : 2r lao.

constant, sinusoidal, and periodic signals then become

C.or'.t(s) : C.ir,"(t) : Cp".(s) :

1+s? l-a*s?
s2+2(rloss*afi s2+ 2(L - u)( ass* af;
1
| - ae-tT'

The largest gains of the transfer functions arc 1l(I - a) in all cases.Choosing a < t diminishes disturbance attenuation but improves the robustness. The properties of the controllers CconstC, .i.,., and Cpe.are illustrated in Figure 12.3 which shows the gain curves of the Bode plots for the controllers. The controller C.or,rthas high gain for low frequencies, the controller Gi.," has high gain for a : a0, and the controller Cp",.has high gain for the frequencies &)s,2as,Sa)s, etc.

372

rp.**.

12.4 CascadeControl
- - - -l
I

Figure 12.4 Block diagram of a system with cascadecontrol.

12.4CascadeControl

Cascade control can be used when there are several measurement signals and one control variable. It is particularly useful when there are significant dynamics, e.g., long dead times or long time constants, between the control variable and the processvariable. Tighter control can then be achieved by using an intermediate measured signal that responds faster to the control signal. Cascade control is built up by nesting the control loops, as shown in the block diagram in Figure L2.4. The system in this figure has two loops. The inner loop is called the secondary loop; the outer loop is called the primary loop. The reason for this terminology is that the outer loop deals with the primary measured signal. It is also possible to have a cascadecontrol with more nested loops. The performance of a system can be improved with a number of measured signals, up to a certain limit. If all state variables are measured, it is often not worthwhile to introduce other measured variables. In such a case the cascade control is the same as state feedback. We will illustrate the benefits of cascade control by an example.

Exaupln l2.2-lxtpRovED Lonn DrsruRsANCE REJECTToN Consider the system shown in Figure 12.4. Let the transfer functions be

1 P -, : s * 1

and

^1

P"r :

'

,-.

(s+1)'

Assume that a load disturbance enters at the input of the process. There are significant dynamics from the control variable to the primary output. The secondary output does respond much faster than the primary output. Thus, cascade control can be expected to give improvements.
The dashed lines in Figure 12.5 show the response obtained with conventional feedback using a PI controller with the parameters K - 0.37 and Ti : 2.2. Since the response of the secondary measured variable to the control

373

Chapter 12. Control Paradigms

Figure 12.5 Responses to a load disturbance for a system with (solid line) and without (dashed line) cascade control. The upper diagram shows process output y, and the lower diagram shows control signal u.

signal is quite fast, it is possible to use high loop gains in the secondary loop. If the controller in the inner loop is proportional with gain Kr, the dynamics from the set point of C, to process output becomes

G ( s )-

K, (s+1+K,)(s+r;s'

With K, :5 in the inner loop and PI control with K - 0.55 and fi - 1.9 in the outer loop, the responses shown in solid lines Figure I2.5 are obtained. The figure shows that the disturbance response is improved substantially by using cascade control. Notice in particular that the control variable drops very much faster with cascade control. The main reason for this is the fast inner feedback loop, which detects the disturbance much faster than the outer loop.
The secondary controller is proportional, and the loop gain is 5. A large part of the disturbance is eliminated by the inner loop. The remaining error is eliminated at a slower rate through the action of the outer loop. In this case integral action in the inner loop will always give an overshoot in the disturbance response.

Choice of Secondary Measured Variables
It is important to be able to judge whether cascade control can give improvement and to have a methodolory for choosing the secondary measured variable. This is easy to do if we just remember that the key idea of cascadecontrol is to arrange a tight feedback loop around a disturbance. In the ideal case the secondary loop can be so tight that the secondary loop is a perfect servo wherein the secondary measured variable responds very quickly to the control signal. The basic rules for selecting the secondary variable are:
o There should be a well-defined relation between the primary and secondary measured variables.

374

12.4 Cascade Control

+ (B)

(c)
l-f--L.1-,

+'

-ll-----l

Y
[*

Figure 12.6 Examples of different process and measurement configurations.

. Essential disturbances should act in the inner loop.
o The inner loop should be faster than the outer loop. The typical rule of thumb is that the average residence times should have a ratio of at least five.
o It should be possible to have a high gain in the inner loop.
A common situation is that the inner loop is a feedback around an actuator. The reference variable in the inner loop can then represent a physical quantity, like flow, pressure, torque, velocity, etc., while the control variable of the inner loop could be valve pressure, control current, etc. This is also a typical example where feedback is used to make a system behave in a simple predictive way. It is also a very good way to linearize nonlinear characteristics.
A number of different control systems with one control variable and two measured signals are shown in Figurc L2.6.In the figure the control variable is represented by u, the primary measured variable by y, the secondarymeasured variable by y,, and the essential disturbance is u. With the rules given above it is only case A that is suitable for cascade control.
Choice of Control Modes
When the secondary measured signal is chosen it remains to choose the appropriate control modes for the primary and secondary controllers and to tune their parameters. The choice is based on the dynamics of the process and the nature of the disturbances. It is difficult to give general rules because the conditions can vary significantly. In critical cases it is necessary to analyze and simulate. It is, however, useful to have an intuitive feel for the problems.
Consider the system in Figure I2.4. To have a useful cascade control, it is necessary that the process P2 be slower than P1 and that the essential disturbances act on P1. We assume that these conditions are satisfied. The secbndary controller can often be chosen as a pure proportional controller or a PD controller. In some cases integral action can be useful to improve rejection of low-frequency disturbances. With controllers that lack integral action, there

375

Chapter 12. Control Paradigms
may be a static error in the secondaryloop. This may not be a serious drawback. The secondary loop, as a rule, is used to eliminate fast disturbances. Slow disturbances can easily be eliminated by the primary loop, which will typically have integral action. There are also drawbacks to using integral control in the secondary loop. With such a system there will always be an overshoot in the response of the primary control loop. Integral action is needed if the process P2 contains essential time delays and the processP1 is such that the loop gain in the secondary loop must be limited.
The special case when the process P2 is a pure integrator is quite common. In this case integral action in the inner loop corresponds to proportional control in the outer loop. If integral action is used in the inner loop, the proportional action in the outer loop must be reduced. This is a significant disadvantage for the performance of the system. A good remedy is to remove the integrator in the inner loop and to increase the gain in the outer loop.
Tuning and Commissioning Cascadecontrollers must be tuned in a correct sequence.The outer loop should first be put in manual when the inner loop is tuned. The inner loop should then be put in automatic when tuning the outer loop. The inner loop is often tuned for critical or over-critical damping or equivalently for a small sensitivity (M,). If this is not done there is little margin for using feedback in the outer loop.
Commissioning of cascadeloops also requires some considerations. The following procedure can be used, starting with both controllers in manual mode.
1. Adjust the set point of the secondary controller to the value of the secondary process variable.
2. Set the secondary controller in automatic with internal set point selected.
3. Adjust the primary controller so that its set point is equal to the process variable and so that its control signal is equal to the set point of the secondary controller.
4. Switch the secondary controller to external set point.
5. Switch the primary controller to automatic mode.
The steps given above are automated to different degrees in different controilers. If the procedure is not done in the right way there will be switching transients.
Integral Windup If integral action is used in both the secondary and primary control loops, it is necessary to have a scheme to avoid integral windup. The inner loop can be handled in the ordinary way, but it is not a trivial task to avoid windup in the outer loop. There are three situations that must be covered:
1. The control signal in the inner loop can saturate.
2. The secondary control loop may be switched to internal set point.
3. The secondarv controller is switched from automatic to manual mode.
376

12.4 Cascade Control

The feedback loop, as viewed from the primary controller, is broken in all these cases,and it is necessary to make sure that its integral mode is dealt with properly. This problem is solved automatically in a number of process controllers that have cascade control capabilities, but if we build up the cascade control using two independent controllers we have to solve the problem ourselves. This requires being able to inject a tracking signal into the primary controller.
If the output signal of the secondary controller is limited, the processvariable of the secondary controller should be chosen as the tracking signal in the primary controller. This also requires a digital transfer from the secondary to the primary controller telling it when the tracking is to take place.
In the casewhere the secondary controller switches to work according to its local set point instead of the external one from the primary controller, the local set point should be sent back to the primary controller as a tracking signal. In this way one can avoid both integrator windup and jumps in the transition to cascade control.
When the secondary controller switches over to manual control, the process variable from the secondary controller should be sent back to the primary controller as a tracking signal.

Some Applications
Cascadecontrol is a convenientway to use extra measurements to improve controlperformance.The following examplesillustrate some applications.

Exavpln 12.3-Ver,vo PosrrroNERS

Control loops with pneumatic valves are a very common application. In this

casethe inner loop is a feedback around the valve itself where the valve position

is measured. The inner loop reduces the influences of pressure variations and

various nonlinearities in the pneumatic system.

f

Exenrpr,n 72.4-MoroR CoNTRoL

Figure 72.7 is a block diagram of a typical motor control system. This sys-

tem has three cascadedloops. The innermost loop is a current loop where the

current is measured. The next loop is the velocity loop, which is based on mea-

surement of the velocity. The outer loop is a position loop. In this case integral

action in the velocity loop is equivalent to proportional action in the position

loop. Furthermore, it is clear that the derivative action in the position loop

is equivalent to proportional action in the velocity loop. From this it follows

directly that there is no reason to introduce integral action in the velocity con-

troller or derivative action in the position controller.

f

Exaupln 12.5-HoAr ExcHANGER
A schematic diagram of a heat exchanger is shown in Figure 12.8. The purpose of the control system is to control the outlet temperature on the secondary side by changing the valve on the primary side. The control system shown uses cascade control. The secondary loop is a flow control system around the valve. The control variable of the primary loop is the set point of the flow

377

Chapter 12. Control Paradigms
Amplifier
Figure 12.7 Block diagram of a system for position control. The system has three cascaded loops with a current controller (CC) with feedback from current (/), a velocity controller (VC) with feedback from velocity (r), and a position controller (PC) with feedback from position (y).

Figure 12.8 Schematic diagram of a heat exchanger with cascade control.

controller. The effect of nonlinearities in the valve, as well as flow and pressure

disturbances, is thus reduced by the secondary controller.

tr

1 2 . 5 M i d - R a n g ea n d S p l i t - R a n g eC o n t r o l
Cascade control is a stratery where one control signal and two measurement signals are used to meet the control objective. The dual situation is when two control signals are used to control one measurement signal. The two control signals are sometimes used one at a time. This is the case in split-range control. In other situations it is necessary to use the two control signals simultaneously. A common situation is mid-range control or mid-rangrng. Mid-range and splitrange control are discussed in this section.
Mid-Range Control The problem treated by mid-range control is illustrated in Figure 12.9. The figure illustrates an example where two valves are used to control a flow. One valve, u1, is small but has a high resolution. The other valve, u2, is large but has a low resolution.
Suppose that the small valve u1 is in the middle of its operating range and that only small disturbances are acting on the system. In this case, one controller that manipulates valve ur is able to take care of the control problem.
378

12.5 Mid-Range and Split-Range Control
Figure 12.9 Tlvo valves are used to control the flow.
Figure 12.f0 Mid-rangecontrol
However, when larger disturbances occur, valve u1 will saturate. In this case, the larger valve u2 must also be manipulated.
The mid-range control stratery is illustrated in Figure 12.10. Controller C1 takes the set point Jsp and flow signal y as inputs and manipulates the small valve ut.A secondcontrollet, C2,takes the control signal from Cr as input and tries to control it to a set point u,, in the middle of its operating range by manipulating the large valve u2. If both controllers have integral action, the flow will be at the set point /sp and the valve u1 will be at the set point uro in steady state.
A block diagram of the mid-range control strategy is given in Figure l2.LI. Process P1 and controller C1 together form a fast feedback loop. The midranging controller C2 controls the valve position of controller C1via the process output y. This means that the output of controller C1is controlled by driving the process output y away from the set point. If this is done slowly, the deviation

Figure 12.11 Block diagram of a system with mid-range control.

379

Chapter 12. Control Paradigms
Figure 12.12 Block diagram of a system with mid-range control.
from the set point can be kept small. If not, it is recommended to use the structure given in Figure 12.12.
In Figure L2.12 a feedforward signal is added from control signal u2 to controller Ct. If the feedforward compensator is
C; f f\'7s\) : - pPr (zr()s.)
controller Cz will perform the mid-ranging control without any disturbance of the process output y.
It is likely that the small valve will saturate. In spite of this, it is not necessary that the controller C1 has anti-windup. Since the control signal is controlled by the controllet Cz,controller C2prevents controller Cr from winding up.
Split-Range Control In split-range control, the control is shared by two controllers that perform the control one at a time. Systems of this type are common, e.g., in connection with heating and cooling. One physical device is used for heating and another for cooling. The heating and cooling systems often have different static and dynamic characteristics. The principle of split-range control is illustrated in Figure I2.L3, which shows the static relation between the measured variables and the control variables. When the temperature is too low, it is necessary to supply heat. The heater, therefore, has its maximum value when the measured variable is zero. It then decreaseslinearly until mid-range, where no heating is supplied. Similarly, there is no cooling when the measured variable is below mid-range. Cooling, however, is applied when the process variable is above mid-range, and it then increases.
There is a critical region when switching from heating to cooling. To avoid both heating and cooling at the same time, there is often a small dead zorte where neither heating nor cooling is supplied. Switching between the different control modes may cause difficulties and oscillations.
380

12.6 Nonlinear Elements

Heating valve Cooling valve

0.5

1.0

Figure 12.13 Illustration of the concept of split-range control.

Split-range control is commonly used in systems for heating and ventilation. It is also useful applications when the control variable ranges over a very large range. The flow is then separated into parallel paths, each controlled with a valve.

12.6NonlineaEr lements

Nonlinear elements have been discussed before. In Section 3.5 we used a limiter to avoid integral windup in a controller with integral action. In Chapter 9 it was shown that controllers could be tuned by relay feedback and that performance could be improved by gain scheduling. In this section we describe more nonlinear elements and also present some control paradigms that guide the use of these elements.

Linearization
The nonlinearity in sensors and actuators can be compensated in a straightforward way. Consider, for example, an actuator that has the characteristics

u:f(u),

where u is the actual process input signal, and u is the control signal. To compensate for the nonlinearity we simply compute the control signal u, as 7f the actuator was linear with unit gain. The control law

u:

-t(u"), f

where /-t ir the inverse of the actuator nonlinearity, then gives

, : f(u) : f(f-1@,)) : Ltc.

The actuated process signal is then identical to u, as was desired. The same idea can be applied to sensors. Consider, for example, a sensor
that has the nonlinearity g(x).By designing a linear controller based on the assumption that the sensor is linear with unit gain and feeding the signal

- t - \/ Y \) lc:9

381

Chapter 12. Control Paradigms

Figure 12.14 Block diagram of a simple amplitude limiter (upper left), a rate limiter (upper right), and a jump and rate limiter or a ramp unit (lower).

to the controller, the sensor nonlinearity is eliminated. Similar ideas can be applied to processnonlinearities, but the compensation
is not ideal because of dynamics. There is a technique for compensating for nonlinearities called feedback linearization, but this is outside the scope of this book. There are also situations when the nonlinearities are beneficial.

Limiters

Since all physical values are limited, it is useful to have limiting devices in control systems too. Limiters are used in many different ways. They can be used to limit the command signals so that we are not generating set points that are demanding larger or faster changes than a system can cope with.
A block diagram of a simple amplitude limiter is shown in upper left part of Figure I2.L4. The limiter can mathematically be described as the static nonlinearity

! : s a t ( u , u r , u h: {)

ifu{u7 if u 1u .--u1
:r, ifulul

where e and u7, artethe saturation limits. It is also useful to limit the rate of change of signals. This can be done with
t}aerate limiter or the ratnp unit shown in the upper right part of Figure L2.I4. The output follows the input signal if the rate of change of the input is smaller than the rate limit. In steady state the inputs and the outputs are identical because there is integral action in the system. Since the output is generated by an integrator with limited input signal, the rate of change of the output will be limited to the bounds given by the limiter. It is possible to use different limits for increasing or decreasing rates.

382

12.6 Nonlinear Elements
1 0.5
0
'I
0.5 0
-0.5
1
Figure 12.15 Simulation of a rate limiter (upper), and a jump and rate limiter (lower). The thin line shows the input to the limiter and the thick line shows the output of the limiter
A more sophisticated limiter called a jump and rq,te limiter is shown in the lower part of Figure L2.I4. The output will follow the input for small changes in the input signal. At large changes, the output will follow the input with a limited rate. The jump and rate limiter can be described by
dx - s a t ( r z- x , - a , a ) i
!:x*sat(u-x,-a,a),
lf lu - xl 3 a it follows from the equations describing the system that y - u, and if u ) x -f a it follows that dx I dt : a. Thus, the output signal will approach the input signal at the rate a.
The properties of the different limiters are illustrated in the simulation shown in Figure L2.I5. The input signal consists of a few steps and a sinusoid. The upper curve shows a rate limiter where the rate limit is 4. The figure shows that the rate of change of the output is limited. The response to a sinusoidal input shows clearly that the rate limiter gives a phase lag. The lower curve shows the response of a jump and rate limiter. Notice that the output follows rapid changes in the input as long as the difference between r and z are less than the jump limit, which is 0.5. The rate is limited to 4.
SurgeTankControl
The control problems that were discussed in Chapter 4 were all regulation problems where the task was to keep a process variable as close to a given set point as possible. There are many other control problems that also are important. Surge tank control is one example. The purpose of a surge tank is to act as a buffer between different production processes. Flow from one
383

Chapter 12. Control Paradigms
(A)
(B)
Figure 12.16 Different structures for surge tank control. The material flow is from the left to the right. The scheme in A is called control in the direction of the flow. The scheme in B is called control in the direction opposite to the flow.
process is fed to another via the surge tank. Variations in production rate can be accommodated by letting the level in the surge tank vary. Conventional level control, which attempts to keep the level constant, is clearly not appropriate in this case. To act as a buffer the level should indeed change. It is, however, important that the tank neither become empty nor overflow.
There are many approaches to surge tank control. A common, simple solution is to use a proportional controller with a low gain. Controllers with dead zones or nonlinear PI controllers are also used. Gain scheduling is a better method. The scheduling variable is chosen as the tank level. A controller with low gain is chosen when the level is between, .9., 10 percent and 90 percent, and a controller with high gain is used outside the limits. There are also special schemes for surge tank control.
In many casesthere are long sequencesof surge tanks and production units, as illustrated in Figure 12.16. TWo different control structures, control in the direction of the flow or opposite to the flow, are shown in the figure. Control in the direction opposite to the flow is superior because then all control loops are characterized by first-order dynamics. With control in the direction of the flow, it is easy to get oscillations or instabilities because of the feedback from the end of the chain to the beginning.
RatioControl
Ratio control is applied when the control objective is to keep the ratio between two variables, often flows, at a certain ratio o. In combustion, for example, it is desired to control the fuel-to-air supply ratio, in order for the combustion to be as efficient as possible. Blending of chemicals is another example where it is desired to keep the ratio between different flows constant. In in-line blending systems, when there are no downstream mixing tanks, this is of special importance. If the composition is not maintained, quality problems may occur.
Ratio control is normally solved in the way shown in Figurc 12.6. There are two control loops.The main loop consists of processP1 and controller Ct. Output Jt is the main flow, and the external set point 11 is the desired main flow. In the second loop, consisting of process P2 and controller Cz, it is attempted to
384

12 6 -\'

Figure 12.17 Ratio control using a Ratio station (ftS) applied to main flow y1.

control the flow lz so that the ratio yzlyt is equal to ratio o. In Figure 12.6 this is obtained using a Ratio station where set point 12 is determined by

r2(t) : a,yr(t),

(r2.4)

i.e., simply by multiplying the main flow y1 with the desired ratio o. In Equation L2.4, parameter o is assumed to be constant. This is not nec-
essary. The desired ratio o is often time-varying. In combustion, for example, the ratio a is often adjusted based on 02 measurements in the exhaust.
Provided the controllers have integral action, the soiution given in Figure 12.6 will work in steady state, i.e., yr - 11 and y2 : d!r.However, the simple Ratio station is not efficient during transients. The second flow y2 will always be delayed compared to the desired flow ay1. The length of this delay is determined by the dynamics of the second loop.
When set point 11 is increasing, the delay causes an under-supply of the media corresponding to flow J2, and conversely when 11 is decreasing there is an excess of the media corresponding to flow y2. There are cases when it is important never to get any under-supply of one of the two media. In the combustion case, one gets an under-supply of air during the transient part when the external set point increases, but an excessof air when the set point decreases.To prevent the fuel from not being fully burnt by an under-supply of air, the solution in Figure 12.6 has to be complemented with some logic using selectors. This is discussed in the next section.
The main drawback with the simple Ratio station approach shown in Figure 12.6 is that the secondary flow y2 is delayed compared to the desired flow oy1. This problem can be solved if not only y1 is used to form the secondary set point, but also the main set point 11. The structure, called the Blend station, is shown in Figure 12.18.
In the Blend station, the secondary set point is determined as

, z ( t ) : a ( T r t ( r )+ ( r - y ) y t ( y ) )

(r2.5)

Gain y is a weighting factor that determines the relation between set point 11

385

Chapter 12. Control Paradigms
rI
Figure 12.18 Ratiocontrolusingthe Blendstation(BS).
and main flow y1 when forming secondary set point 12.When T :0, the Blend station is identical to the Ratio station.
Exaupln 12.6-PuLp BLEACHTNGCoxtnol The Ratio station and the Blend station have been applied on a bleaching section in a paper mill. The pulp is bleached by adding Hydrosulphite to the pulp flow. The goal is to keep the ratio between the pulp flow and the Hydrosulphite flow constant.
The upper diagram in Figure 12.19 shows control using the Ratio station. The pulp flow controller, Cr, is a PI controller with setting K1 : 0.2 and Tir - 4s. The Hydrosulphite controllet, C2, is also a PI controller with setting K2: 0.078 and T;2 - 1.07s. The figure shows responses to two set-point changes in the pulp flow. The Hydrosulphite flow is scaled with the desired ratio and translated, so that the desired flow rates become identical. The figure shows that the Ratio station provides the correct ratio in steady state, but also that there is a deviation between the two flows during the transients. The Hydrosulphite flow is delayed compared to the pulp flow.
The lower diagram in Figure tz.tg shows the results obtained when using the Blend station with gain factor T : 0.75. Here, the difference between the two flows is almost eliminated.
u
Selector Gontrol Selector control can be viewed as the inverse of split-range control. In split range there is one measured signal and several actuators. In selector control there are many measured signals and only one actuator. A selector is a static device with many inputs and one output. There are two types of selectors: maximum and minimum. For a maximum selector the output is the largest of the input signals.
There are situations where several controlled process variables must be taken into account. One variable is the primary controlled variable, but it is also required that other process variables remain within given ranges. Selector
386

12.6 Nonlinear Elements
Figure l2.lg Ratio control of a pulp bleaching process using the original Ratio station (upper) and the Blend station with gain T : 0.75 (lower). The figure shows two changes in the pulp set point, the pulp flow (fastest response) and the Hydrosulphite flow (slowest response).
tu ,-u, SP
tt ,-,,, PV
Figure 12.20 Selectocrontrol. control can be used to achieve this. The idea is to use several controllers and to have a selector that choosesthe controller that is most appropriate. One example of use is where the primary controlled variable is temperature and we must ensure that pressure does not exceed a certain range for safety reasons.
The principle of selector control is illustrated in Figure 12.20. The primary controlled variable is the process output y. There is an auxiliary measured variable z that should be kept within the limits zmin and zmax.The primary controller C has processvariable y, set point /sp, &nd output un. There are also secondary controllers with measured process variables that are the auxiliary variable z and with set points that are bounds of the variable z. The outputs of these controllers are un and u1. The controller C is an ordinarv PI or PID
387

Chapter 12. Control Paradigms

controller that gives good control under normal circumstances. The output of the minimum selector is the smallest of the input signals; the output of the maximum selector is the largest of the inputs.
Under normal circumstances the auxiliary variable is Iarger than the minimum value Z6i1 &od smaller than the maximum value zmax.Thismeans that the output ul is large and the output rz7is small. The maximum selector,therefore, selects u.n,antdthe minimum selector also selectsur. The system acts as if the maximum and minimum controller were not present. If the variable z reaches its upper limit, the variable ul becomes small and is selected by the minimum selector.This means that the control system now attempts to control the variable z and drive it towards its limit. A similar situation occurs if the variable z becomes smaller than zmin.
In a system with selectors, only one control loop at a time is in operation. The controllers can be tuned in the same way as single-loop controllers. There may be some difficulties with conditions when the controller switches. With controllers having integral action, it is also necessary to track the integral states of those controllers that are not in operation. Selector control is very common in order to guarantee that variables remain within constraints. The technique is commonly used in the power industry for control in boilers, power systems, and nuclear reactors. The advantage is that it is built up of simple nonlinear components and PI and PID controllers. An alternative to selector control is to make a combination of ordinary controllers and logic. The following example illustrates the use of selector control.

ExRnrple t2.7 -A;n-Fupr, Cowrnol

In the previous section we discussed air-fuel control using ratio control. When

the Ratio station is used, there may be lack of air because the set point of the

air controller increases first when the fuel controller has increased the oil flow.

One way to solve this problem is to use the Blend station. However, the system

cannot compensate for perturbations in the air channel. This problem can be

treated using selectors,such as is shown in Figure 12.2L.The system uses one

minimum and one maximum selector. There is one PI controller for fuel flow

and one PI controller for the air flow. The set point for the air controller is the

larger of the command signal and the fuel flow. This means that the air flow

will increase as soon as more energy is demanded. Similarly, the set point to

the fuel flow is the smaller of the demand signal and the air flow. This means

that when demand is decreased,the set point to the dual flow controller will

immediately be decreased,but the set point to the air controller will remain

high until the oil flow has actually decreased. The system thus ensures that

there will always be an excessof air.

n

Median Selectors
A median selector is a device with many inputs and many outputs. Its output selects the input that represents the current median of the input signals. A special caseis the two-out-of-three selector,commonly used for highly sensitive systems. To achieve high reliability it is possible to use redundant sensors and controllers. By inserting median selectors it is possible to have a system that will continue to function even if several components fail.

388

12.7 Neural Network Control

Figure 12.21 Air-fuel controllerbasedon selectors.

12.7 NeuralNetworkControl
In the previous section, we have seen that simple nonlinearities can be used very effectively in control systems. In this and the following section, we will discuss some techniques based on nonlinearities, where the key idea is to represent functions of several variables in a compact way. The ideas have been introduced under the names of neural and fuzzy control. At first sight, these methods may seemquite complicated, but oncethe colorful language is stripped off we find that the algorithms have natural representations as implementations of nonlinear functions. It is a nontrivial problem to find good representations of a nonlinear function. If we simply try to grid the variables and use an interpolation we find that the number of entries in the table for representing the function grows very rapidly with the number of variables. For example, if n variables are gridded in N points each we find that the number of entries are -ly'". For a function of five variables with l/ - 100 we find that 1010entries are required. Another useful property of neural networks is that there are methods to fit the parameters of the function to data.

Neural Networks
Neural networks originated in attempts to make simple models for neural activity in the brain and attempts to make devices that could recognize patterns and carry out simple learning tasks. A brief description that captures the essential idea follows.

A Sirnple Neuron A schematic diagram of a simple neuron is shown in Figure 72.22. The system has many inputs and one output. If the output is y

I

389

.t

Chapter 12. Control Paradigms
Figure 12.22 Schematic diagram of a simple neuron.

-202 Figure 12.23 Sigmoidfunctions.

and the inputs &te tL1,u2, ... , un the input-output relation is described by

( f , , , , ) , y : f ( w t u t * w z u z + ' . . * w n u n ): f \f/

(12.6)

where the numbats wi are called weights. The function / is a so-called sigmoid function, illustrated in Figure 12.23. Such a function can be represented as

f (*) :

sinh ar :

eax _ e-ax eax + e-ex

(r2.7)

where a is a parameter. This model of a neuron is thus simply a nonlinear function. Some special classesof functions can be approximated by (12.6).

Neural Networks More complicated models can be obtained by connecting neurons together as shown in Figure 12.24. This system is called a neural network or a neural net. The adjective feedforward is often added to indicate that the neurons are connected in a feedforward manner. There are also other types of neural networks. In the feedforward network, the input neurons are connected to a layer of neurons, the outputs of the neurons in the first layer are connected to the neurons in the secondlayer, and so on, until we have the outputs. The intermediate layers in the net are called hidden layers.
Each neuron is described by Equation (L2.6). The input-output relation of a neural net is thus a nonlinear static function. Conversely, we can consider a neural net as one way to construct a nonlinear function of several variables. The neural network representation implies that a nonlinear function of several variables is constructed from two components: a single nonlinear function, the sigmoid function 12.7), which is a scalar function of one variable; and linear operations. It is thus a simple way to construct a nonlinearity from simple operations. A key reason why neural networks are interesting is that practicalll'

390

12.7 Neural Network Control

Figure 12.24 A feedforward neural network.

all continuous functions can be approximated by neural networks having one hidden layer. It has been found practical to use more hidden layers because then fewer weights can be used. Another practical feature of the sigmoidal functions is that the approximations are local.

Learning

Notice that there are many parameters (weights) in a neural

network. Assuming that there are n neurons in a layer, if all neurons are con-

nected, n2 parameters are then required to describe the connections between

two layers.

Another interesting property of a neural network is that there are so-called

learning procedures. This is an algorithm that makes it possible to find param-

eters (weights) so that the function matches given input-output values. The

parameters are typically obtained recursively by giving an input value to the

function and the desired output value. The weights are then adjusted so that

the data is matched. A new input-output pair is then given, and the parameters

are adjusted again. The procedure is repeated until a good fit has been obtained

for a reasonable data set. This procedure is called training a network. A pop-

ular method for training a feedforward network is called back propagation.

For this reason the feedforward net is sometimes called a back-propagation

network. Fitting a neural network to experimental data is illustrated in Fig-

ure 12.25. A nice feature is that it is possible to find both the function and its

inverse. The inverse function is useful when compensating for nonlinearities

in sensors and actuators.

Control Applications

A feedforward neural network can be viewed as a

nonlinear function of several variables with a training procedure. The function

has many parameters (weights) that can be adjusted by the training procedure

so that the function will match given data. Even if this is an extremely simplis-

tic model of a real neuron, it is a useful system component. In process control

we can often make good use of nonlinear functions. Sensor calibration is one

case. There are many situations where an instrument has many different sen-

sors, the outputs of which must be combined nonlinearly to obtain the desired

measured value. Nonlinear functions can also be used for pattern recognition.

391

Chapter 12. Control Paradigms
Desired response

Neural network
Figure 12.25 Illustration of training of a simple feedforward network. The block diagram on the left shows training of a function, and the figure on the right shows training of an inverse function.

f (x,u)

s(x,u)

Figure 12.26 Implementation of a nonlinear dynamical system using integrators and neural networks.

It is also possible to model dynamic systems by combining the neural network with integrators as is illustrated in Figure 12.26. The system in the figure implements the nonlinear system

dx dt

-

f (x,u)

v - g(x,u),

where the nonlinear functions are represented by neural networks.

12,8 FuzzyControl
Ftzzy control is an old control paradigm that has received a lot of attention recently. In this section we will give a brief description of the key ideas. We will start with fuzzy logic, which has inspired the development.
FuzzyLogic
Ordinary Boolean logic deals with quantities that are either true or false. Fazzy logic is an attempt to develop a method for logic reasoning that is less sharp. This is achieved by introducing linguistic variables and associating them with membership functions, which take values between 0 and 1. In fuzzy control the logical operations and, or, and not are operations on linguistic variables. These operations can be expressed in terms of operations on the membership functions of the linguistic variables. Consider two linguistic variables with the
392

1 2 . 8 F I z . - . - r( '
cold and moderate
cold or moderate
-10
Figure 12.27 Illustration of fuzzy logic. The upper diagram shows the membership functions of cold, moderate, and hot. The middle diagram shows the membership functions for cold and moderate the lower diagram shows the membership functions for cold or moderate.
membership functions fa(r) and f a(*). The logical operations are defined by the following operations on the membership functions.
f e u,'d.B : min (fe(*), f a(*)) f.+or B - rriax(fe(*),f n(*)) fnotA-1-fe(*).
A linguistic variable, where the membership function is zero everywhere except for one particular value, is called a crisp variable.
Assume, for example, that we want to reason about temperature. For this purpose we introduce the linguistic variables cold, moderate, and hot, and we associate them with the membership functions shown in Figure 12.27. The membership function for the linguistic variables cold and moderate and cold or moderate are also shown in the figure.
A FuzzyController
A block diagram of a fuzzy PD controller is shown in Figure 12.28. The control error, which is a continuous signal, is fed to a linear system that generates the derivative of the error. The error and its derivative are converted to socalled linguistic variables in a process called "fuzzrfication." This procedure converts continuous variables to a collection of linguistic variables. The number of linguistic variables is typically quite small, for example: negative large
393

Chapter 12. Control Paradigms

Linguistic variables de dt
Defizzifter
I
L--
Figure 12.28 A fuzzyPD controller.

(NL), negative medium (NM), negative small (NS), zerc (Z), positive small (PS), positive medium (PM), and positive large (PL).The control strategy is expressed in terms of a function that maps linguistic variables to linguistic variables. This function is defined in terms of a set of rules expressedinfuzzy logic. As an illustration we give the rules for a PD controller where the error and its derivative are each characterized by three linguistic variables (N, Z, P) and the control variable is characterized by five linguistic variables (NL, NM, Z, PM, and PZ).

Rule 1: If Rul-e 2: If Rule 3: If Rule 4: If Rul-e 5: If Rul-e 6: If Rule 7: If Rule B: If Rule 9: If

e is N and deldt e is N and deldt e is N and deldt e is Z and deldt e ts Z and deldt e ts Z and de/dt e is P and deldt e is P and deldt e i.s P and deldt

is P then u is Z ts Z then u is NM is N then u is NL is P then u is PM is Z then u is Z is N then u i.s NM is P then u is PL is Z then u is PM is N then u is Zj

These rules can also be expressed in table form; see Table Iz.L. The membership functions representing the linguistic variables normally overlap (see Figure 12.27). Due to this, several rules contribute to the control signal. The Iinguistic variable representing the control signal is calculated as a weighted sum of the linguistic variables of the control signal. The linguistic variable representing the control signal is then mapped into a real number by an operation called "defuzzrfication." More details are given in the following.

Fuzzy Inference Many different shapes of membership functions can be used. In fuzzy control it is common practice to use overlapping triangular shapes like the ones shown in Figure t2.27 for both inputs and control variables. Tlpically only a few membership functions are used for the measured variables.
Fuzzy logic is only used to a moderate extent in fuzzy control. A key issue is to interpret logic expressions of the type that appears in the description of the fvzzy controller. Some special methods are used in fuzzy control. To describe these we assume that fe, fn, and fg are the membership functions associated with the linguistic variables A, B, and C. Furthermore let r and y represent

394

12.8 Fuzzy Control

Table 12.1 Representation of the fuzzy PD controller as a table.

N eZ
P

de dt PZN
ZNMNL PMZNM PLPMZ

measurements. If the values rs and /s are measured, they are considered as crisp values. The fuzzy statement
IfxisAandyisB
is then interpreted as the crisp variable
zo : min(fe(*o), fa?il)
where and is equivalent to minimization of the membership functions. The linguistic variable u defined by
If x i-s A or y is B then u is C
is interpreted as a linguistic variable with the membership function
f" (* ) : zofc(x).
If there are several rules, as in the description of the PD controller, each rule is evaluated individually. The results obtained for each rule are combined using the or operator. This corresponds to taking the maximum of the membership functions obtained for each individual rule.
Figure 12.29 is a graphical illustration for the case of the first two rules of the PD controller. The figure shows how the linguistic variable corresponding to each rule is constructed and how the control signal is obtained by taking the maximum of the membership functions obtained from all rules.
The inference procedure described is called "product-max." This refers to the operations on the membership functions. Other inference procedures are also used in fuzzy control. The and operation is sometimes represented by taking the product of two membership functions and the or operator by taking a saturated sum. Combinations of the schemes are also used. In this wav it is possible to obtain "product-max" and "min-sum" inferences.
Defuzzifi.cation Fuzzy inference results in a control variable expressed as a linguistic variable and defined by its membership function. To apply a control signal we must have a real variable. Thus, the linguistic variable defining the control signal must be converted to a real number through the operation of "defuzzification." This can be done in several different wavs. Consider a
395

Chapter 12. Control Paradigms

Rule 1: If e is N and de ldt is P then u i s Z

N

P

Rule 2: If e is N and de ldt is Z then u is NM

N

Z

de dt
Figure 12.29 Illustration of fuzzy inference with two rules using the min-max rule,
linguistic variable A with the membership function fe@). Defuzzification by mean values gives the value
ro: [ * fe@)dx f-|^@w
Defuzzification bv the centro id gives a real variable rs that satisfies
L ffe(x)dx: I fo(x)dx. Jxo
Nonlinear Control Having gone through the details, we return to the fuzzy PD controller in Figure L2.28. We first notice that the operations fuzzification, fuzzv logic, and defizzifi,cation can be described in a very simple way. Stripping away the vocabulary and considering the final result, a fuzzy controller is nothing but a nonlinear controller. The system in Figure 12.28 can in fact be expressed as
u- F (r.4\.
\ dt/ where F is a nonlinear function of two variables. Thus, the fuzzy PD controller is a controller where the output is a nonlinear function of the error e and its derivative deldt.In Figure 12.30 we give a graphic illustration of the
396

12.8 Fuzzy Control
Figure 12.30 Graphic illustration of the nonlinearity of the fuzzy controller showing control signal a as function of control error e and its derivative.
lF,x lS ZEAND z lS P$'{HENy lS NL lF x lS NL AND z ,5 PL THENy lS NS lF x lS PLAND"uiS NL fiEN y lS ZE rFx rs PSAND'zr$ 4erHeruy rs NL lFx lS ZEANDa IS.NSTI{ENy lS PL rFx rs Ns ANDz t$lFLTHENy tSPS lF x lS NLANDz lS ZETHENv IS'NS Figure 12.31 TWo views of a fuzzy controller. The figure on the left shows that the fuzzy controller can be viewed as a nonlinear controller. The figure on the right instead emphasizes the rules.
nonlinearity defined by given rules for the PD controller with standard triangular membership functions and product fuzzification. The figure shows that the function is close to linear. In this particular case the fuzzy controller will behave similarly to an ordinary linear PD controller.
Fuzzy control may be considered as a way to represent a nonlinear function. This is illustrated in Figure L2.37. Notice that it is still necessary to deal with the generation of derivatives or integrals, integral windup, and all the other matters in the same way as for ordinary PID controllers. We may also inquire as to when it is useful to introduce the nonlinearities and what shape they should have.
Representation of a nonlinearity by fizzification, fitzzy logic, and defuzzification is not very different from representation of a nonlinear function as a table with an interpolation procedure. Roughly speaking, the function val-
397

Chapter 12. Control Paradigms
ues correspond to the rules; the membership functions and the fuzzification and defuzzification procedures correspond to the interpolation mechanism. To illustrate this we consider a function of two variables. Such a function can be visualized as a surface in two dimensions. A linear function is simply a tilted plane. This function can be described completely by three points on a plane, i.e., three rules. More complex surfaces or functions are obtained by using more function values. The smoothness of the surface is expressed by the interpolation procedures.
From the point of view of control, the key question is understanding when nonlinearities are useful and what shape they should have. These are matters where much research remains to be done. There are cases where the nonlinearities can be very beneficial but also cases where the nonlinearities cause problems. It is also a nontrivial task to explore what happens. A few simulations of the behavior is not enough becausethe response of a nonlinear system is strongly amplitude dependent.
Let us also point out that the properties of the controller in Figurc 12.28 are strongly influenced by the linear filter used. It is thus necessary to limit the high-frequency gain of the approximation of the derivative. It is also useful to take derivatives of the processoutput instead of the error, as was discussed in Section 3.3. Other filters can also be used; by adding an integrator to the output of the system in Figure 12.28, we obtain a fuzzy PI controller.
Applications The representation of the control law as a collection of rules for linguistic variables has a strong intuitive appeal. It is easy to explain heuristically how the control system works. This is useful in communicating control strategies to persons with little formal training. It is one reason why fuzzy control is a good tool for automation of tasks that are normally done by humans. In this approach it is attempted to model the behavior of an operator in terms of linguistic rules. Ftzzy control has been used in a number of simple control tasks for appliances. It has also been used in controllers for processesthat are complicated and poorly known. Control of a cement kiln is one example of this type of application. Fuzzy control has also been used for controller tuning.
1 2 . 9 S y s t e mS t r u c t u r i n g
In this section we illustrate how complex control systems can be built from simple components by using the paradigms we have discussed.The problem is quite complex. It involves selection of measured variables and control variables, and it requires significant physical understanding of the process.
TheProcess
The processto consider is a chemical reactor. A schematic diagram is shown in Figure 12.32. TWo substances A and B are mixed in the reactor. They react to form a product. The reaction is exothermic, which means that it will generate heat. The heat is dissipated through water that is circulating in cooling pipes
398

12.9 System Structuring

Steam

Cooling pipes

qA qB
Figure 12.32 Schematic diagram of a chemical reactor.

r"

Temperature

Figure 12.33 Static process model for the exothermic reactor.

in the reactor. The reaction is very fast; equilibrium is achieved after a time that is much shorter than the residence time of the reactor. The flow et of substance A is considerably larger than qs. Efficiency of the reaction and the heat generation is essentially proportional to the flow gs.
A static processmodel is useful in order to understand the control problem. Figure 12.33 shows the efficiency and the heat generation as a function of temperature. A model of this type was derived in Section 2.5.In the figure we have drawn a straight line that corresponds to the cooling power. There are equilibria where the power generated by the reaction is equal to the cooling power represented at points P and Q in the figure. The point P corresponds to an unstable equilibrium. It follows from Figure 12.33 that if the temperature is increased above P the power generated by the reaction is larger than the cooling power. Temperature wiII thus increase. The catalyst in the reactor may be damaged if the temperature becomes too high. Similarly, if the temperature decreasesbelow point P it will continue to decreaseand the reaction stops. This

399

Chapter 12. Control Paradigms
phenomenon is called "freezing." Freezing starts at the surface of the cooling tube and will spread rapidly through the reactor. If this happens the reactor must be switched off and restarted again.
Design Requirements
There are considerable risks in running an exothermic reactor. The reactor can explode if the temperature is too high. To reduce the risk of explosion, the reactors are placed in special buildings far away from the operator. Because of the risk of explosion, it is not feasible to experiment with controller tuning. Consequently, it is necessary to compute controller setting beforehand and verify that the settings are correct before starting the reactor. Safety is the overriding requirement of the control system. It is important to guarantee that the reaction temperature will not be too high. It is also important to make sure that process upsets do not lead to loss of coolant flow and that stirring does not lead to an explosion. It is also desirable to operate the reactor efficiently. This means that freezing must be avoided. Besides, it is desirable to keep the efficiency as high as possible. Because of the risks, it is also necessary to automate start and stop as well as normal operation. It is desirable to avoid having to run the reactor under manual control. In this particular case the operator can set two variables: the reactor temperature and the ratio between the flows ea and qs. The reaction efficiency and the product quality can be influenced by these two variables.
ControlleSr tructure
The reactor has five valves. TWo of them, Vr and V2, influence the coolant temperature. The flow of the reactor is controlled by V3 and Va, and the product flow is controlled by the valve Vs. In this particular application the valve V5 is controlled by process steps downstream. (Compare this with the discussion of surge tanks in Section 12.6).
There are five measured signals: the reactor temperature Tr, the level in the reactor tank L, the cooling temperature 7r, and the flows ea and ga. The physical properties of the process give a natural structuring of the control system. A mass balance for the material in the reactor tank shows that the level is essentially influenced by the flow qa and the demanded production. It follows from the stoichiometry of the reaction that the ratio of the flows ea and q3 should be kept constant for an efficient reaction. The reactor temperature is strongly influenced by the water temperature, by the temperature of the coolant flo\r', and the flows ea and qp. Coolant temperature is influenced by the valve V1 that controls the amount of flow and by the steam valve V2.
This simple physical discussion leads to the diagram shown in Figure 12.34, which shows the causality of the variables in the process. The valve V5 can be regarded as a disturbance because it is set by downstream process units. Figure 72.34 suggests that there are three natural control loops:
o Level control: Controlling the tank level with valve V3.
o Temperature control: Control of the reactor temperature with valves V1 and V2.
400

12.9 SystemStructurirtg V5
qB QI Figure 12.34 Causality diagram for the process variable.
T,
L,, L L
Figure 12.35 Block diagram for the level control through valve V3.
o Flow ratio control: Control of ratio qnlqe with valve Va. These control loops are discussed in detail. Level Control The block diagram for the level control is shown in Figure 12.35. The primary function is a proportional feedback from the level to the flow q6, which is controlled by the valve V3. The reactor is also used as a surge tank to smooth out the difference between actual production and commanded production. The Ievel in the tank will vary during normal operations. Reasonablelimits are that the level should be between 50 percent and 100 percent. If the proportional band of the controller is chosen as 50 percent, the control variable will be
401

Chapter 12. Control Paradigms

7,, T,

T,

Figure 12.36 Block diagram showing temperature control through valves Vy and V2.

fully closed when the tank is full and half-open when the tank is half-full. It is important that the reactor temperature remains within given bounds. The flow qa is constrained, therefore, by two selectors based on measurements of the temperature in the reactor tank (",") and the coolant temperature (Tr). When starting the reactor the level is kept at the lower limit until the coolant temperature becomes sufficiently high. This is achieved by a combination of limiters, multipliers, and selectors, as shown in Figure 12.35.

TemperatureControl
Figure L2.36 gives a block diagram for controlling the reactor temperature. Since the chemical reaction is fast compared to temperature and flow dynamics, the reactor can be viewed as a heat exchanger from the control point of view. During normal conditions the temperature is controlled by adjusting the coolant flow through the valve V1. The primary control function is a feedback from temperature to the valves Vr and V2. The set point in this control loop can be adjusted manually. The parameters of this control loop can be determined as follows. The transfer function from coolant flow to the reactor temperature is approximately given by

G ( s ):

Kp
( 1+ s " r ) ( t + s T z ) '

(12.8)

where the time constant typically has values ?r : 300 s and T2 - 50 s. The following rough calculation gives approximate values of the controller parameter. A proportional controller with gain K gives the loop transfer function

G6(s):

KKo

(1+s"l)(1 +s"2)'

(12.e)

The characteristic equation of the closed loop becomes

s, -

+

s

\/

.

n1

*

r

r

)1*\

*

l

*

K

Ko
,*

:0
:

.

The closed system is thus of second order. The relative damping ( and the undamped natural frequency a) are given by

2 ( a : -1+ -1A1r -
Tr T2 T2

(12.10)

402

12.9 System Structuring

and

I+KKo 2(a2:

(12.11)

TtTz

The approximation in the first expression is motivated by 7r ) ?2. With a relative damping ( :0.5 the Equation (12.10) then gives a x lf 7:2.Furthermore,

it follows from Equation (12.11) that

t+KKo--+,:ff-u.

The loop gain is thus essentially determined by the ratio of the time constants. The controller gain becomes
rT\ ' 5-Kp'
and the closed-loopsystem has the undamped natural frequency.
a - llTz : 0'02 rad/s.
If PI control is chosen instead, it is reasonable to choose a value of the integration time
T1 x 5T2.
Control can be improved by using derivative action. The achievable improvement depends on the time constant of the temperature sensor.In typical cases this time constant is between 10 s and 40 s. If it is as low as 10 s it is indeed possible to obtain improved control by introducing a derivative action in the controller. The derivative time can be chosen to eliminate the time constant T2.We then obtain a system with the time constants 300 s and 10 s. The gain can then be increased so that
300 L + , rKr K. o - 1 0 - 3 0
and the undamped natural frequency of the system then becomesro x 0.1 rad/s. If the time constant of the temperature sensor is around 40 s, the derivative action gives only marginal improvements.
The heat generated by the chemical reaction is proportional to the flow ee. To make sure that variations in qa are compensated rapidly we have also introduced a feedforward from the flow qa. This feedforward will only operate when the tank level is larger than 50 percent in order to avoid freezing when the reactor is started.
To start the reaction the reactor must be heated so that the temperature in the reaction vessel is larger than Q (compare with Figure 12.33). This is done by using the steam valve %. Split-range control is used for the steam and water valves (compare Section 12.6). The water valve is open for low signals (3-9 PSI), and the steam valve is open for large pressures (9-15 PSI).
To avoid having the reactor freeze, it is necessary to make sure that the reaction temperature is always larger than 7.. This is the reason for the extra feedback from water temperature to ?, through a maximum selector. This feedback makes sure that the steam valve opens if the temperature in the coolant flow becomes too low. Cascade control would be an alternative to this arrangement.

403

Chapter 12. Control Paradigms
Figure 12.97 Reaction yield as a function of qs at constant 94.
Flow Ratio Control The ratio of the flows ea and es must be kept constant. Figure 12.87 shows how the efficiency of the reaction depends on ea when ea is kept constant. The flow qp is controlled with a ratio control system (as shown m figure 12.8g), which is the primary control function. The reaction rate depends strongly on Qa. To diminish the risk of explosion, there is a nonlinearity in the feedback that increases the gain when aa lqe is large. The flow loop has several selectors. At startup it is desirable that substance B not be added until the water temperature has reached the critical value T" and the reactor tank is half-full. To achieve this the feedback from water temperature and tank level has been introduced through limiters and a minimum selector. There are also limiters and a selector that closesvalve V4 if flow qa is lost. There is also a direct feedback from qa through limiters and selectors and a feedback from the reactor temperature that closesvalve Va, if the reactor temperature becomestoo high. Override Control of the Outlet Valve The flow out of the reactor is determined by valve V5. This valve is normally controlled by process steps downstream. The control of the reactor can be improved by introducing an override, which depends on the state of the reactor. When starting the reactor, it is desirable to have the outlet valve closed until the reactor tank is half-full and the reaction has started. This is achieved by introducing the tank level and the tank temperature to the set point of the valve controller via limiters and minimum selectors as is shown in Figur e l2.Bg. The valve V5 is normally controlled by grp. The minimum selector overrides the command qro when the level L or the iemperature T, are too low.
1 2 . 1 0S u m m a r y
In this chapter we have illustrated how complex control systems can be built from simple components such as PID controllers, linear filters, gain schedules, 404

12.10 Summary

Qa

SP

PI

Qe

MV

Figure 12.38 Block diagram for controlling the mixing ratio qs/qa through valve Va.
L#
Qtp
T,
Figure 12.39 Block diagram for controlling the outflow of the reactor through valve V5.
and simple nonlinear functions. A number of control paradigms have been introduced to guide system design.
The primary linear control paradigms are feedback by PID control and feedforward. Cascade control can be used to enhance control performance through the use of extra measurements. State feedback may be viewed as an extreme case of cascade control where all states of a system are measured. Observers can be used to infer values of variables that are not measured by combining mathematical models with available measurements. Mid-range and split-range control are paradigms for control when there are several control signals but only one measured signal. These paradigms are the dual of cascade control. Repetitive control is a technique that is efficient for cases where the disturbances are periodic. The idea is to create a high loop gain at the frequency of the disturbance.
We also discussed several nonlinear components and related paradigms including nonlinear functions, gain schedules,limiters, and selectors.Recall that it was shown in Section 3.5 how PID controllers could be enhanced by simple nonlinear functions to avoid windup. Ratio control is a nonlinear strategy that
405

Chapter 12. Control Paradigms
admits control of two process variables so that their ratio is constant. In Section 9.3 we showed how gain schedules could be used to cope with changes in process dynamics. Gain schedules and nonlinear functions are also useful for control of buffers, where the goal is not to keep constant levels in the buffers but to allow them to vary within given ranges. Selector control is another important paradigm that is used for constraint control where certain process variables have to be kept within given constraints. Neural and fuzzy techniques were also discussed briefly. It was shown that they could be interpreted both as rule-based control and as nonlinear control.
We also gave an example how the components and the paradigms could be used to develop a control system for a chemical process.
12.11Notesand References
Many aspects of the material in this chapter are found in classical textbooks on processcontrol such as [Buckley, 1964; Shinskey, 1988; Bequette, 2003; Seborg et al., 20041and in the books [Shinskey, 1981; Klefenz, 1986] which focus on energJ systems. A more specialized presentation is given in [Hagglund, 1991].
The methods discussedin this chapter can all be characterized as bottom-up procedures in the sensethat a complex system is built up by combining simple components. An interesting view of this is given in [Bristol, 1980]. A top-down approach is another possibility. A discussion of this, which is outside the scope of this book, is found in [Seborg et al., 1986] and [Morari and Zafiriou, 1989].
Cascade and feedforward control are treated in the standard texts on control. A presentation with many practical aspects is found in [T\rcker and Wills, 1960]. Selector control is widely used in practice. A general presentation is given in [Astrdm, 1987b]. It is difficult to analyse nonlinear systems. A stability analysis of a system with selectors is given in [Foss, 1981]. The Blend station is presented in [Hiigglund, 2001].
Fuzzy control has been around for a long time; see [Mamdani, 1974; Mamdani and Assilian, 1974; King and Mamdani, 1977; Torg, 19771.It has received a lot of attention particularly in Japan: see [Zadeh, 1988; Tong, 1984; Sugeno, 1985; Driankov et a1.,1993; Wang, 1994]. The technique has been used for automation of complicated processes that have previously been controlled manually. Control of cement kilns is a typical example; see [Holmblad and Qster gaard, 1981].There has been a similar development in neural networks; see,for example, [Hecht-Nielsen, 1990; Pao, 1990; Astrrim and McAvoy, 1992]. There was a lot of activity in neural networks during the late 1960s, which vanished rapidly. There was a rapid resurgence of interest in the 1980s. There are a lot of exaggerations both in fuzzy and neural techniques, and no balanced view of the relevance of the fields for control has yet emerged. The paper [Willis et aI., 1991] gives an overview of possible uses of neural networks for process control, and the paper [Pottman and Seborg, 1993] describes an application to control of pH. The papers [Lee, 1990; Huang, 1991; Swiniarski, 1991] describe applications to PID controllers and their tuning. There have also been attempts to merge fuzzy and neural control; see [Passino and Antsaklis, 19921and [Brown and Harris, 19941.Section 12.9 is based on [Buckley, 1970].
406

13
Implementation
13.1Introduction
PID controllers were originally implemented using analog techniques. Early systems used pneumatic relays, bellows, and needle-valve constrictions. Electric motors with relays and feedback circuits and operational amplifiers were used later. Many of the features like anti-windup and derivation of process output instead of control error were incorporated as "tricks" in these implementations.
It is now common practice to implement PID controllers using microprocessors, and some of the old tricks have been rediscovered. Several digital PID controllers in use today have features that are inherited from old techniques when the controllers were implemented using pneumatic devices. This is a typical example of the fact that ideas sometimes change at a much slower rate than hardware. Several additional issues must be considered in connection with digital implementations. The most important ones have to do with sampling, discreti zation, and quantization.
This chapter presents some implementation issues related to PID control. Section 13.2 gives a short overview of the early analog pneumatic and electronic implementations. Section 13.3 treats computer implementation aspects such as sampling, prefiltering, and discretization of the PID algorithm. Velocity algorithms, or incremental algorithms, are needed in applications where the integration is performed outside the controller. The most common application is electrical motors. These algorithms, which are shown to be useful even when the integration is performed inside the controller, are presented in Section I3.4. Operational aspects, such as bumpless transfers at mode switches and parameter changes, are presented in Section 13.5. A controller may have different outputs depending on which actuating device is used. Controller outputs are discussed in Section 13.6. The chapter ends with a summary and references.
407

Chapter 13. Implementation

Figure 13.1 Schematic diagram of a pneumatic P controller based on the force balance principle.

13,2Analoglmplementations

The early implementations of PID controllers were all analog. This section presents the pneumatic controller implementation and the analog electronic implementation.

The Pneumatic Controller
This section presents the basic function of pneumatic controllers. To make this clear, lots of details have been removed from the presentation and the drawings. We refer to the references for details.

The Pneurnatie P Controller A schematic diagram of a pneumatic P controller based on force balance is shown in Figure 13.1. The system consists of a beam that can rotate around a pivot point. The beam is provided with three bellows, a spring, a position sensor, and a pneumatic amplifier. The bellows can exert forces on the beam proportional to the pressure in the bellows. The position sensor is a flapper valve, which gives a pressure signal that is approximately inversely proportional to the distance between t}irenozzle and the beam. The pneumatic amplifier A can amplify pneumatic signals.
To understand the operation of the system it is assumed that the forces of all bellows are proportional to the air pressure in the bellows. The two left bellows receive pressures psp and p, proportional to the set point and the measured variable, respectively.The pressure amplifier A receivessupply pressure p, and provides output pressure p,, which is the controller output. The right bellow labeled P is the feedback bellow or the proportional bellow. In the P controller the pressure in this bellow, pp, is equal to the output pressure pu.
A torque balance gives the following relation between the pressures:

pu-bias - K(p,o- py).

(13.1)

The bias term is the force given by the spring. The gain K is determined by the position of the balance point, and can therefore be chosen by adjusting this point. Equation 13.1 is obviously the equation for a P controller.

408

13.2 Analog Implementations

Figure 13.2 Schematic diagram of a pneumatic PD controller based on the force balance principle.

Suppose, for example, that the set-point pressure psp increases. The beam will then rotate in positive direction, leading to a decrease in the outflow from the nozzle valve. This will cause an increase of the output pressura pu.

The Pneumatic PD Controller

A pneumatic PD controller is shown in

Figure I3.2.In this controller, a valve and a volume V6 is introduced between

the amplifier A and the feedback bellow P. Because of this valve, it is no longer

true that pp : pr, but the following dynamic relation between the two pressures

holds:

P o ( ':)i * r & ( ' ) '

(13.2)

The value of the time constant T6 can be adjusted by the valve position. Since a counteraction caused by the feedback bellow P is delayed compared
with the P controller, a change in py or p,p will initially result in a larger reaction in the output pressure pu.
A torque balance gives the following relations between the pressures:

Pp-bias:K(P,o-Pv)' From (13.2) this gives the following output pressure;
&(r) : bias + K(l + sT|)(P,o - Pr), which is the equation of a PD controller with derivative time Ta.

The Pneuntatic PID Controller A pneumatic PID controller is shown in Figure 13.3. In this controller, the spring is replaced by a bellow labeled I. This bellow is connectedto the presstre pp through a volume % and a valve labeled fl. The pressure in the bellow I is

4(s):

Po(t), l+sTi

(13.3)

409

Chapter 13. Implementation

Figure 13.3 Schematic diagram of a pneumatic PID controller based on the force balance principle.

where the time constant Ti ma! be adjusted by the valve labeled 4. A torque balance gives the following relations between the pressures:

PP-Pi:K(P'P-PY)'

From (13.2) and (13.3) this gives the following output pressure:
P " ( s ) : 6 (1+ s4)(1 + sza)(p,o1r_; pr(r)).
sTi

(13.4)

This equation shows that the system is a PID controller on interacting form (see Section 3.2) with gain K, integral time fr, and derivative time ?a.
The idea of using feedback in the controller was a major invention. Both the flapper valve and the pneumatic amplifier are strongly nonlinear. The arrangement with the feedback loop implies that the input-output relation of the controller does not change much even if the component changes, provided that the gain is sufficiently large. This idea, which is called force feedback, gave drastic improvements in the performance of the controllers. A typical example of the impact of feedback.

TheAnalogElectronicController
A PID controller may be implemented by analog electronic components in many ways. This section presents some basic implementations based on operational amplifiers. Lots of details have been left out for the sake of simplicity. As for the pneumatic controllers, we refer to the references for details.

The Eleetronie PI Controller An electronic PI controller is shown in Fig-

ure 13.4.

An approximate relation between the input voltage e and the output voltage

u is obtained by

u - - ^Zt 't

410

13.2 Analog Implementations

Figure 13.4 Schematic an operational amplifier.

diagram

of an electronic

PI

controller

based on feedback around

Figure 13.5 Schematic diagram an operational amplifier.

of an electronic PD controller

based on feedback around

where Zs the input amplifier

is the impedance between the negative input of voltage e' and 21 is the impedance betweln the and the output voltage rz.These impedances are

the zer

amplifi o input

er o

f

and the

Zo: Ro

Z r : E r + :u,tp
where p is the differential operator. This gives the following relation between the input voltage e and the output voltage z:

t- t : - 4 uZ:L

- nRtt l (t*

This is a PI controller with parameters

1\
o"t*)'

K-* r[g

Ti:Rtcr.

A P controller is obtained by removing the capacitor.

The Electronie PD controiler Figure 13.5.

An electronic pD controller is shown in

The impedances between the negative input of the amplifier and the input and output voltages, respectively, become

t7
Z r O"

:

Zt:

Rg
1 * RgCsp Rt.

4II

Chapter 13. Implementation

Figure 13.6 Schematic diagram of an electronic PID controller based on feedback around an operational amplifier.

This gives the following relation between the input voltage e and the output

voltage u:

u- -"2f1ie- -fDi (1+Rocoep.)

This is a PD controller with parameters

K:y

Ta:Roco.

Ho

A P controller is obtained by removing the capacitor.

The Electronie PID Controller

An electronic PID controller may be ob-

tained by combining the two previous schemes.This is shown in Figure 13.6.

The impedances between the negative input of the amplifier and the input and output voltages, respectively, become

zo:-**-

Z s : R r* + Ltp

This gives the following relation betweenthe input voltage e and the output

voltage u:

i t - - ^2"1: - nErr (1 + RsCsp)(l+ Rr Clp). .

This is a PID controller on interacting form with parameters

Kr7 : R^ 1; :

T; : RtCt

Ta: RoCo.

1 3 . 3C o m p u t elrm p l e m e n t a t i o n s
Most controllers are implemented nowadays in computers. There are some topics that have to be considered due to the fact that the signals are sampled at discrete time instances. These topics are treated in this section.
4r2

13.3 Computer Implementations

Sampling
When the controller is implemented in a computer, the analog inputs are read, and the outputs are set with a certain sampling period. This is a drawback compared to the analog implementations, since the sampling introduces dead time in the control loop.
When a digital computer is used to implement a control law, the ideal sequence of operation is the following.
1. Wait for clock interrupt
2. Read analog input
3. Compute control signal
4. Set analog output
5. Update controller variables
6. Gotol
With this implementation, the delay is minimized.If the analog input is read with a sampling period h, the average delay of the measurement signal is hl2. T}i'e computation time is often short compared to the sampling period. This means that the total delay is about hl2.However, most controllers and instrument systems do not organize the calculation in this way. Therefore, the delays introduced because of the sampling are often several sampling periods.

Aliasing The sampling mechanism introduces some unexpected phenomena, which must be taken into account in a good digrtal implementation of a PID controller. To explain these, consider the signals
s(t) - cos(nro"t+ail)

and s"(t) : cos(a;f)'
where (0s: 2ttlh [rad/s] is the sampling frequency. Well-known formulas for the cosine function imply that the values of the signals at the sampling instants l k h , k : 0 , 1 , 2 , . . . ]h a v e t h e p r o p e r t y
s(kh) : cos(nkha, r atkh) - cos(akh) : s"(akh).

The signals s and so thus have the same values at the sampling instants. This means that there is no way to separate the signals if only their values at the sampling instants are known. Signal so is, therefore, called an alias of signal s. This is illustrated in Figure I3.7. A consequenceof the aliasing effect is that a high-frequency disturbance after sampling may appear as a low-frequency signal. In Figure 13.7 the sampling period is 1 s, and the sinusoidal disturbance has a period of 615 s. After sampling, the disturbance appears as a sinusoid with the frequency

fo:l-::

116Hz.

6I

This low-frequency signal with time period 6 s is seen in the figure.

4L3

Chapter 13. Implementation

Figure 13.7 Illustration of the aliasing effect. The diagram shows signal s and its alias s'r'

Prefiltering
The aliasing effect can create significant difficulties if proper precautions are not taken. High frequencies, which in analog controllers normally are effectively eliminated by low-pass filtering, may, becauseof aliasing, appear as lowfrequency signals in the bandwidth of the sampled control system. To avoid these difficulties, an analog prefilter (which effectively eliminates all signal components with frequencies above half the sampling frequency) should be introduced. Such a filter is called an antialiasing filter. A second-order Butterworth filter is a common antialiasing filter. Higher-order filters are also used in critical applications. An implementation of such a filter using operational amplifiers is shown in Figure 13.8. The selection of the filter bandwidth is illustrated by the following example.

Exaupln 13.1-SSLECTToNoF PRnrrlrnR BANDwTDTH Assume it is desired that the prefilter attenuate signals by a factor of 16 at half the sampling frequency. If the filter bandwidth is o6 and the sampling frequency is alr, we get
(a,l2rtt6)z: L6.

Hence.

1 ab: g @r.

T
Notice that the dynamics of the prefilter will be combined with the process dynamics.

Discretization
To implement a continuous-time control law, such as a PID controller in a digital computer, it is necessary to approximate the derivatives and the integral that appear in the control law. A few different ways to do this are presented below.

474

13.3 Computer ImPlernentations

Figure 13.8 Circuit diagram of a second-order Butterworth filter.

Proportional Aetion

The proportional term is p-K(bt,p-t).

This term is implemented simply by replacing the continuous variables with their sampled versions. Hence,

P ( t n )- K ( b y , o ( t u ) - y ( t n ) ) ,

(13.5)

where {re} denotes the samplinginstants, i.e., the times when the computer reads the analog inPut.

Integral Action The integral term is given bY

I

(

t

1- f

Ki

'

f

l

e

.
b

.
)

a

s

.

0

It follows that

d I Kdt Ti"'

(13.6)

There are several ways of approximating this equation. Approximating the derivative by a forward difference gives

I ( t n + t ) _r_( t e ): : e e n ) .

h

Ti-

This leads to the following recursive equation for the integral term

I ( t e * t-) I ( t e ) . + e U k ) .

(13'7)

If the derivative in Equation 13.6 is approximated instead by a backward difference, the following is obtained:

I(tn)-I(th-r)

:

K e(te)'

T

4r5

Chapter 13. Implementqtion

This leads to the following recursive equation for the integral term:

I ( t n * r ) :I ( t e ) .+ e | n + ) .

(13.8)

Another simple approximation method is due to T\rstin. This approximation

is

I(tn*) -

I

(

t

n

)+

rTy ;

e
2

(

t

n

*-r+) e

(

t

n.)

(13.e)

Yet another method is called ramp equivalence. This method gives exact outputs at the sampling instants if the input signal is continuous and piecewise linear between the sampling instants. The ramp equivalence method gives the same approximation of the integral term as the T\rstin approximation, i.e., Equation 13.9.
Notice that all approximations have the same form, i.e.,

I ( t n * r ) - I ( t k ) * b n e ( t p 1 r )* b i z e ( t n ) ,

(19.10)

but with different values of parameters b1 and bi2.

Deriaatiae Action The derivative term with the classical first-order filter is given by Equation 3.14, i.e.,

## rD:-*r,#

(13.11)

This equation can be approximated in the same way as the integral term. Approximating the derivative by a forward difference gives

T"JP+DGk):-Krary

This can be rewritten as

D(tu*') :

I
( I-
\

AIfi\
;t d /

)

D

(

t

u

)-

KN

( y ( t e * r )-

y(tn)).

(1s.12)

If the derivative in Equation 13.11 is approximated by a backward difference, the following equation is obtained:

# ' J + + D f t ) : - K r a r y Ta D(tu) - D(tn_t) , r\/t \

r.z,t1y!h) - y(tn-r)

This can be rewritten as

D ( t u )-

-f!-- D(tu-; -
Ta+Nh"\uR-L)

!!o!, (v(t1,-) y(te-)).
Ta*I{h\r

(13.13)

Using the T\rstin approximation to approximate the derivative term gives
D(tn- )ffi#DQ,,-,)-:!I4- 14il- y4e-)) (13.14)

4L6

13.3 Computer Implementations

Figure 13.9 Phase curves for PD controllers obtained by different discretizations of the derivative term sT6f (1+ sTalN) with ?a : 1,N : 10 and a sampling period 0.02. The discretizations are forward differences (FD), backward differences (BD), T\rstin's approximation (T), and ramp equivalence (RE). The lower diagram shows the differences between the approximations and the true phase curve.

Finally, the ramp equivalence approximation is D ( t u ) - e - N h l r dD ( t n _ ' ) - K T a ( l - e - N n l r a l ( y ( t n )- y ( r r - ' ) ) .

(13.15)

All approximations have the same form,

D (tn): aaD(tn-r)- baO(tn) - y(tn_l)),

(13.16)

but with different values of parameters a6 and ba. The approximations of the derivative term are stable only when loal < L.
When using the forward difference approximation stability requires that Ta ) Nh12. The approximation becomesunstable for small values of Ta. The other approximations are stable for all values of 7a. Notice, however, that T[rstin's approximation and the forward difference approximation give negative values of a6 if T6 is small. This is undesirable because the approximation will then exhibit ringing. The backward difference approximation give good results for all values of 74, including Ta : 0.
For reasonable fast sampling there are only small differences between the approximations as long as they are stable. There are, however, practical differences.In a general-purpose controller it is desirable that derivative action can be switched off. A natural way to do this is to set Ta :0. This can easily be accomplished when the derivative is approximated by a backward difference. All other methods will either give instability or overflow for Ta :0. The backward difference is therefore a reasonable choice for approximating the derivative.
Figure 13.9 shows the phase curves for the different discrete time approximations. T\r.stin's approximation and the ramp equivalence approximation give the best agreement with the continuous time case, the backward approximation gives less phase advance, and the forward approximation gives more phase

4L7

Chapter 13. Implementation

advance. The forward approximation is seldom used because of the problems with instability for small values of derivative time 7a. T\rstin's algorithm is used quite frequently because of its simplicity and its close agreement with the continuous time transfer function. The backward difference is used when an algorithm that is well behaved for small ?4 is needed.
All approximations of the PID controller can be represented as

R ( q ) u ( k h ) : T ( q ) y , o ( k n 1- S ( q ) y ( k h ) ,

(13.17)

where q is the forward shift operator, and the polynomials .R,S, and T are of second order. The polynomials R, S, and 7 have the forms

R(q):(q-1)(q-oo) S ( q ) - s o q 2* s 1 e * s 2 f @ ) - to e 2* t9 * tz,
which means that Equation 73.17 can be written as u(kh) : to!,p(kh) + t1v'p(kh - h) + t2v'p(kh - 2h) - s s y ( k h )- t t y ( k h - h ) - s z y ( k j - 2 h ) + (1 + aa)u(kh - h) - aau(kh - h).

(13.18)

The coefficients in the S and ? polynomials are

so:K-lbrlba sr : -K(I + a4) - bnaa I biz- 2ba s z : K a a - b i 2 a aI ba to : Kb * bit tt: -Kb(I + a6) - bnaa -f biz tz: Kbaa-bizaa.

(13'19)

The coefficients in the polynomials for different approximation methods are given in Table 13.1.

Controllewr ith SecondOrderFilter

A nice implementation of a PID controller is to combine a second order filtering of the measured signal with an ideal PID controller; see Section 3.3. We will now discuss how such controllers can be implemented. Let y be the measured signal and ys the filtered signal. We have

rr(r-) G1(s)Y: f(fsi)v(r).

(13.20)

Introducing the state variables xr: t1 and x2:

represented as

,r#:*,

Tfdyf ldt t}re filter can be

rr# -2(-xt-xz*t).

(13.21)

418

13.3 Computer Implementations

Table 13.1 Coefficients in different approximations of the continuous time PID controller.

Forward Backward

T\rstin

Ramp equivalence

broKh{!

b. Kizh

^

K

h ,r

-i

a 4 L, - Nh h

ba

KN

T;
0
Ta
rr+Nh KTaN Ta*Nh

2Ti
2Ti ZTa - Nh
2rd+Nh 2K- -T- ua-N' 2Ta*Nh

Kh nt Kh nt
Lo _ N h l r d
K- -T- ua\(I - e-rtnlrol h

The filtered derivative dyS ldt - xzlTf can be extracted from the filter and the controller is then given by

u : k(by,p- !r) + kilo'0*{4 - yrQ\dr + kr#

(8 . 2 2 )

If the PID controller (13.22) is implemented digitaly, both xr : j,1 and x2 : TSdySldl have to be converted to digital form. This implementation is suitable for special-purpose systems. For general-purpose systems the filter can be implemented digitally. Assume that the sampling has period h and let the sampling instants be tp. Approximating the derivative in (13.21) with a backward difference we find

, t ( t ) : x t ( t - h+) f f i x 2 Q - h ) I' -ffiu@-*,(t-h))

* ' ( t )-

r?

-

T 2+rz h r r+ 2 w * ' ( t

h )+

2hrr ffi(v(t)

- * ' ( t- h ) ) '

To obtain an algorithm which permits the parameter Ty to be zero we introduce the state variables

lt: xt
h Jz: Tr*r.

419

Chapter 13. Implementation

External integrator

Figure 13.10 Block diagram of a PID algorithm in velocity form.

The equation for the controller can then be written as

y ! t ) : y { t - h ) + p t v z ( t - h ) + p z ( v ( t )- v { t - h ) ) - v r ( t - h ) + v z ( t )
y z ( t ): p r y 2 ( t- h ) + p z ( y Q )- t { t - h ) ) u(t): K(by,o- y) - p+iz(t)+ I(t - h)
: K(by,p- vt)- pz(K + p+)v(t) + ( p r ( r (+ p + ) - K ) n ( t - h ) + ( K - p ' ( k + p n ) )n Q - h ) + I ( t - h )

u(t) : sat(u) r ( t ) : I ( t - h ) + p s ( t , p ( r-)y ' ( r ) ) * p s ( u ( t )- r ( t ) ) .

(13.23)

where the integral term has been approximatedby a forward differenceand protectionfor windup has been introduced.The parametersof the controller

are given by

rr

2h2

P t : T ? + 2 h T r + 2 h 2 P z - T f + 2 h T s+ 2 h 2

JI

Kh Pe: ^
ti

KTa P+: h

P

u

:

h
n

(t3.24)

13.4VelocityAlgorithms
The algorithms described so far are called positional algorithms because the output of the algorithms is the control variable. In certain cases the control system is arranged in such a way that the control signal is driven directly by an integrator, e.g., amotor. It is then natural to arrange the algorithm in such a way that it gives the velocity of the control variable. The control variable is then obtained by integrating its velocity. An algorithm of this type is called a velocity algorithm. A block diagram of a velocity algorithm for a PID controller is shown in Figure 13.10.
420

13.4 VelocityAlgorithms
Velocity algorithms were commonly used in many early controllers that were built around motors. In several cases,the structure was retained by the manufacturers when technology was changed in order to maintain functional compatibility with older equipment. Another reason is that many practical issues, like wind-up protection and bumpless parameter changes, are easy to implement using the velocity algorithm. This is discussed further in Sections 3.5 and 13.5. In digital implementations velocity algorithms are also called incremental algorithms.
Incremental Algorithm The incremental form of the PID algorithm is obtained by computing the time differences of the controller output and adding the increments
Lu(te) : u(tn) - u(tn r) : AP(tu) + LI(tk) + a'D(tp).
In some casesintegration is performed externally. This is natural when a stepper motor is used. The output of the controller should then represent the increments of the control signal, and the motor implements the integrator. The increments of the proportional part, the integral part, and the derivative part are easily calculated from Equations 13.5, 13.10,and 13.16:
LP(tk)- P(tn)-P(tn_r) - K(by,r(tu)- y(tk)-by,o(tn_r) + y(tn_r)) LI(tk) : I(tn) - I(tu-t) : bit e(tk)* bize(tn_t) LD(tk) : D(tn) - D(tu_l) - oo\D(tn-l) - baOUn) - 2y(tr-r) * y(tn-z)).
One advantage with the incremental algorithm is that most of the computations are done using increments only. Short word-Iength calculations can often be used. It is only in the final stage where the increments are added that precision is needed.
Velocity Algorithms for Controllers without Integral Action A velocity algorithm cannot be used directly for a controller without integral action because such a controller cannot keep the stationary value. This can be understood from the block diagram in Figure 13.114, which shows a proportional controller in velocity form. Stationarity can be obtained for any value of the control error e, since the output from the derivation block is zero for any constant input. The problem can be avoided with the modification shown in Figure 13.118. Here, stationarity is only obtained when u - Ke * ub, where u6 rs the bias term.
If a sampled PID controller is used, a simple version of the method illustrated in figure 13.118 is obtained by implementing the P controller as
\rz(r)- u(t) - u(t - h) : Ke(t) * ut - u(t - h),
where h is the sampling period.
421

Chapter 13. Implementation
(A)
Figure 13.11 Illustrates the difficulty with a proportional controller in velocity form (A) and a way to avoid it (B).
FeedforwardControl Feedforwardcontrol was discussedin Chapter 5. In feedforwardcontrol, the control signal is composedof two terms,
tr:ufb*uff. Here uy6 is the feedback component and uSSis the feedforward component, either from a measurable disturbance or from the set point.
To avoid integrator windup, it is important that the antiwindup mechanism acts on the final control signal a, and not only on the feedback componentuSu.
Unfortunately, many of the block-oriented instrument systems available today have the antiwindup mechanisms inside the feedback controller blocks, without any possibility to add feedforward signals to these blocks. Hence, the feedforward signals must be added after the controller blocks. This may lead to windup. Because of this, several tricks, like feeding the feedforward signal through high-pass filters, are used to reduce the windup problem. These strategies do, however, lead to a less effective feedforward.
Incremental algorithms are efficient for feedforward implementation. By first adding the incremenls of the feedback and feedforward components,
A,u:A,u1u*A,uy and then forming the control signal as
u(t):u(t-h)+A'u(t), windup is avoided. This requires that the feedback control blocks have inputs for feedforward signals.
422

13.5 Operational Aspects
!tp
Inc PID
v
Figure 13.12 Bumpless transfer in a controller with incremental output. MCU stands for manual control unit.
13.5OperationaAl spects
Practically all controllers can be run in two modes: manual or automatic. In manual mode the controller output is manipulated directly by the operator, typically by pushing buttons that increase or decrease the controller output. A controller may also operate in combination with other controllerr, .rr.h as in a cascadeor ratio connection, or with nonlinear elements, such as multipliers and selectors. This gives rise to more operational modes. The controllers also have parameters that can be adjusted in operation. When there are changes of modes and parameters, it is essential to avoid switching transients. The way the mode switchings and the parameter changes are made depends on the structure chosen for the controller.
BumplessTransfeBr etweenManuaal ndAutomatic
Since the controller is a dynamic system, it is necessary to make sure that the state of the system is correct when switching the controller between manual and automatic mode. When the system is in manual mode, the control algorithm produces a control signal that may be different from the manually generated control signal. It is necessary to make sure that the two outputs coincide at the time of switching. This is called bumpless transfer.
Bumpless transfer is easy to obtain for a controller in incremental form. This is shown in Figure I3.I2. The integrator is provided with a switch so that the signals are either chosen from the manual or the automatic increments. Since the switching only influences the increments there will not be any large transients.
A similar mechanism can be used in the series, or interacting, implementation of a PID controller shown in Figure 3.3, see Figure 13.18. In this case there will be a switching transient if the output of the PD part is not zero at the switching instant.
For controllers with parallel implementation, the integrator of the PID controller can be used to add up the changesin manual mode. The controller shown in Figure 13.14 is such a system. This system gives a smooth transition between manual and automatic mode provided that the switch is made when the output of the PD block is zero. If this is not the case,there will be a switching transient.
It is also possible to use a separate integrator to add the incremental
423

Chapter 13. Implementation
!tp
v
Figure f3.13 Bumpless transfer in a PID controller with a special series implementation.
AI
+
Figure 13.14 A PID controller where one integrator is used both to obtain integral action in automatic mode and to sum the incremental commands in manual mode.
changes from the manual control device. To avoid switching transients in such a system, it is necessaryto make sure that the integrator in the PID controller is reset to a proper value when the controller is in manual mode. Similarly, the integrator associated with manual control must be reset to a proper value when the controller is in automatic mode. This can be realized with the circuit shown in Figure 13.15.With this system the switch between manual and automatic is smooth even if the control error or its derivative is different from zero at the switching instant. When the controller operates in manual mode, as is shown in Figure 13.15, the feedback from the output u of the PID controller tracks the output u. With efficient tracking the signal u will thus be close to u at all times. There is a similar tracking mechanism that ensures that the integrator in the manual control circuit tracks the controller output.
BumplessParameteCr hanges
A controller is a dynamical system. A change of the parameters of a dynamical system will naturally result in changes of its output. Changes in the output can be avoided, in some cases,by a simultaneous change of the state of the system. The changes in the output will also depend on the chosen realization. With a PID controller it is natural to require that there be no drastic changes in the
424

13.5 Operational Aspects

Figure 13.15 PID controller with parallel implementation that switches smoothly between manual and automatic control.

output if the parameters are changed when the error is zero. This will hold for all incremental algorithms because the output of an incremental algorithm is zero when the input is zero, irrespective of the parameter values. For a position algorithm it depends, however, on the implementation.
Assume that the state is chosen as

r c r:

f
I e(r)dt

when implementing the algorithm. The integral term is then

,
t

K:

,*''

Any change of K or 4 will then result in a change of 1. To avoid bumps when the parameters are changed, it is essential that the state be chosen as

t

rc1--

I |

ffiee)dc

when implementing the integral term. With sensible precautions, it is easy to ensure bumpless parameter changes
if parameters are changed when the error is zero. There is, however, one case where special precautions have to be taken, namely, if set-point weighting is used. To have bumpless parameter changes in such a case it is necessary that the quantity P * 1 be invariant to parameter changes. This means that when parameters are changed, the state / should be changed as follows:

/.'"* : /ora * Kora(boralrp - !) - Kn *(b'"* ltp - J).

(13.25)

425

Chapter 13. Implementation

---------lM-ltR*JI _
Figure 13.16 Manual control module.

Manual input

TRM M

Manual set point
External set point H Measured value

TiM

Figure 13.17 A reasonable complete PID controller with antiwindup, automatic-manual mode, and manual and external set point.

To build automation systems it is useful to have suitable modules. Figure 13.16 shows the block diagram for a manual control module. It has two inputs: a tracking input and an input for the manual control commands. The system has two parameters: the time constant T* for the manual control input and the reset time constant T1.In digital implementations it is convenient to add a feature so that the command signal accelerates as long as one of the increasedecreasebuttons is pushed. Using the module for PID control and the manual control module in Figure 13.16, it is straightforward to construct a complete controller. Figure 13.17 shows a PID controller with internal or external set points via increase-decreasebuttons and manual automatic mode. Notice that the system only has two switches.
426

13.6 Controller Outouts
ComputerCode
As an illustration we will give computer codes for two PID controllers. A PID controller with first order filtering of the derivative term where the derivative term is approximated by backward differences is described by Equations 13.5, 13.7,13.9, and 13.13. Anti-windup is provided using the scheme described in Section 3.5. A skeleton code for the controller is given in Figure 13.18. The main loop has two states, the integral term I, and x which is used to implement derivative action. The parameters pr, . . . ,p6 vte precomputed to save computing time in the main loop. These parameters have to be computed only when parameters are changed. The integral term is also reset as described by (13.25) to avoid transients when parameters are changed. The main loop in the control algorithm requires eight additions and six multiplications. Notice that the calculations are structured so that there are only three additions and two multiplications between reading the analog inputs are setting the digital output. The states are updated after setting the digtal output.
A PID controller with second order filtering of the process variable is described by Equation 13.23, where the filter is implemented using backward differences and the integral term is approximated using forward differences. Anti-windup is obtained by the scheme shown in Figure 3.13. The algorithm has three states yI, y2, and I, which represent the states of the measurement filter and the integral term. The main loop in the control algorithm requires ten additions and seven multiplications. Using a second order filter only requires a marginal increase of computing time. The time between reading the analog inputs and setting the digital output can be reduced by changing the coordinates of the representation of the filter.
13.6ControlleOr utputs
AnalogOutputs
The inputs and outputs of a controller are normally analog signals, typically 0-20 mA or 4-20 mA. The main reason for using 4 mA instead of 0 mA as the lower limit is that many transmitters are designed for two-wire connection. This means that the same wire is used for both driving the sensor and transmitting the information from the sensor. It would not be possible to drive the sensor with a current of 0 mA. The main reason for using current instead of voltage is to avoid the influence of voltage drops along the wire due to resistance in the (perhaps long) wire. In pneumatic controllers, the standard range is 3-15 psi.
T h y r i s t o r sa n d T r i a c s
In temperature controllers it is common practice to integrate the power amplifier with the controller. The power amplifier could be a thyristor or a triac. With a thyristor, an AC voltage is switched to the load at a given angle of the AC voltage. Since the relation between angle and power is nonlinear, it is crucial to use a transformation to maintain a linear relationship. A triac is
427

Chapter 13. Implementation

" C o m p u t ec o n t r o l - l e r c o e f f i c i e n t s p1=K*b p 2 = K + K x T d(/ T f + h ) p3=Tfl (Tt+1; p4=K*Td*h/( (Tf +fr)*,(Tf+h) ) p5=K*h/Ti p6=h/Tt

"set-point gain "PD gain "fil-ter constant "derlvative gain "integral gain "antl-windup gai-n

"Bumpless parameter changes I=I+Kold* (bold*ysp-y) -Knew* (bnew*ysp-y)

"Control- algorithm adin(ysp) adin(y) v=p1*ysp-p2xy+x+I u=sat (v, ulow ,uhigh) daout (u) x=p3xx+p4xy l=l+pbx (ysp-y) +p6*(u-v)

"read set point "read process variable "compute noninal output "saturate output "set analog output "update derivative "update integral

Figure 13.18 Skeleton code for implementing a PID controller with first order filtering of the derivative term.

" C o m p u t ec o n t r o l l e r c o e f f i c i e n t s den=TfxTf +2*hxTf +2*h*h n 1 = T fx T f , / d e n
p2=2xh*h/den p3=K*h/Ti p4=K*Tdlh p5=h,/Tt

"denominator "filter constant "filter constant rrintegral gain
"derivative gain "anti-windup gain

"Bump1ess parameter changes t=f+(eld* (bold*ysp-y1) -Knew* (fnsw*ysp-y1)

"Control algorithn r=adin (ysp) y=adin (y) x2=pI*y2+p2* (y-y1)
yI=yI+y2 ,7=14(*f *ysp-y1 ) -p4*y2+I u=sat (v ,ulow, uhigh) daout (u) f=f+p3* (ysp-y1)+p5*(u-v)

"read set point "read process variable "update fj-lter state x2 "update filter state x1 "compute nominal output "saturate output "set anal-og output "update integral

Figure 13.19 Skeleton code for implementing a PID controller with second order filtering of the measured signal.

428

l:'j ,: (

07o Time
Figure 13.20 Illustration of controller output based on pulse width modulation

also a device that implements switching of an AC signal, but only at the zero crossing. Such a device is similar to a pulse output.

Pulse Width Modulation
In some cases,such as with the triac, there is an extreme quantization in the sense that the actuator only accepts two values, on or off. In such a case, a cycle time T"y"t"is specified, and the controller gives a pulse with width

? o' r r r " ( r ):

u(t) - u^in ?.v.r".
umax - Umin

(13.26)

A similar, but slightly different, situation occurs when the actuator has three levels: max, min, and zero. A typical example is a motor-driven valve where the motor can stand still, go forward, or go backward.
Figure 13.20 illustrates the pulse width modulation. The figure shows the output from a P controller with pulse width modulation for different values of the control error.

Three-PositioPnulseOutput

If a valve is driven by a constant-speed electrical motor, the valve can be in

three states: "increase," "stop," and "decrease."Control of valves with electrical

actuators is performed with a controller output that can be in three states.

Three-position pulse output is performed using two digital outputs from the

controller. When the first output is conducting, the valve position will increase.

When the secondoutput is conducting, the valve position will decrease.If none

of the outputs are conducting, the valve position is constant. The two outputs

must never be conducting at the same time.

There is normally both a dead zor.e and a dead time in the controller to

ensure that the change of direction of the motor is not too frequ"l!,,?#l$.lot too

..r'",'.i.i1:T,f-.f_ii.',"".;,g:;$:+Z

.r

i , , . .I

I:,

' ' - ',.'..i.

Chapter 13. ImPlementation

Controller

Actuator

Figure 13.21 A PID controllerwith three-position pulse output combined with an electrical actuator.

fast. It means that of the control error

the controller is within the

output is constant dead zorteand that

as long as the the output is

magnitude stopped for

aimwaatttttihrhochfooPteeetnaeltAurIwo,rkDeasoereretwsusoserhttcehrovphroafceovuueonisoro-stfretpmni-rantmusdo,hotthtslheoetlcfoeo.begtoboworrmeryn.-arofnsowotSuaiittrsoiiat,tonentprhnhnrpcueaiFtphtttmtoiotasshgiimsrforeprugr"aeuroereoacveenmfeltouf-ltedirop-rsorm1,twtoAihmhzi3dsoetueee.eitd.2rtdoiotin1oePArntt.tnrboIssrhmswDyoaucreiidpltonpihlnctuunepsadowlcigdosnnneepresgctausoerbersonsoesyaluntudiatlhthendit?iisnaorperd.eegtnu,ie'nc.iutannw,ttt'itcelocoiceyiAmcsgrnoetorhh'emwbeaaraedlaqstbovo?ienuineconr'-taogktoehlatiudt,tednototsoripwwa.tituenghthisthtacriheicaendrihemcyscaape-osicnsosntdotesahteentitrtehtsledoiehoeculcesnrscteiltibrotitcrimiuuicnvoonaaogepong-l-,'f-

'tft t L,u- ; - I r d t :
Tr,.n J 0

Tl run

To have Au equal to a,u, the integration must be stopped after time t -- LuTru...

In a digital increasing

controller, this valve Position is

means to be

that the digrtal output corresponding to an cond.ucting for ru sampling periods' where n

is given by

LuTru.
tt---1-.
n

wti(nhBhaueFtTfrifeogs-uhibhnroeecuisrldae1bta3hblse.ee2es2tsoe.aaFnmnopt drpeolruBtifnhtou.gerfAmfsp-cadeokaermiecocrpdooeufraotrsesefirmectht)cpeolmtihdccureiotesyfneot,t-rbrpdoteohellsureteiasrteii'eols-dnptososupihcutihoolslndaestphoduueeltsapneduuotmz'uobttrpewtuerotaonifbsdpugufdiflveeseraesnds tcitnishmaoesoteAeubcctoaeoscfrnioeodttrhrebdoorteimlatnehigian-ettplegetodocodsorwiFintitinihitotgrmhnoutohlrlueeeprtrue,c1laison3ilenldfy.o2eotr1'hcmu,eottapnhtuateiatoc.intncuTosahontaoeftrnrto.hinleilTnteehtrvegiasgrolarvualsetlopppluuapottraistoiristnt'oioAfPcntuah, uaesinsneecsdeotsePFnnaiDtgordoulpcroeroafonlubg1trlo3eoirn'ml1ith1stchm'aeinf

430

13.7 Summary

ifdelta_u)0then

if valve-is-increasing

then

Buff_increase = Buff_lncrease

+ n;

else Buff-decrease

= Buff_decrease - n;

if Buff-decrease < 0 then

Buff_increase = - Buff_decrease;

Buff_decrease = 0;

val-ve_is_decreasing valve_is_increasing

= false ; = true;

end;

end;

else if delta_u < O then

if valve_is_increasing

then

Buff-decrease = Buff_decrease + n;

else Buff_increase

= Buff_increase

- n;

if Buff_increase < 0 then

Buff-decrease = - Buff_increase;

Buff_increase = O;

val-ve-is-increasing

= false ;

valve_is_decreasj-ng = true ;

end;

end;

end;

if Buff_increase > 0 then Increaseoutput = 1; Decreaseoutput = 0; Buff_increase = Buff_increase

- 1;

else if Buff-decrease > 0 then Increaseoutput = 0; Decreaseoutput = 1; Buff_decrease = Buff_decrease

- 1;

end;

Figure 13.22 Skeleton code for three-position pulse output.
13.7Summary
In this chapter we have described implementation of PID controllers. We have followed the historical development starting with pneumatic and electronic implementation of analog controllers. Computer implementation are presented in detail including skeleton code.The reason for doing this is that many features of modern implementation have inherited several features of the old analog computers; the preference for the series form is one example.
It is interesting to consider the development of the controllers. During
431

Chapter 13. Implementution
each phase of the development the technology has matured and improved, but knowledge has often been lost in the technology shifts. For example, it took quite a while before the importance of measurement filtering and antiwindup were appreciated in the computer implementations. One reason for it is that many details were not well documented and thus easily forgotten when technology changed. Another was that some good features were obtained automatically becauseof particular features of the technology.The important issues of operational aspects and human-machine interfaces have also discussed in this chapter.

13.8Notesand References

The book [Holzbock, 1958] presents many early implementations of PID controllers using pneumatic, hydraulic, and electric technologies. Implementation

of pneumatic controllers are discussed in [Lloyd and Anderson, 1971; Pavlik and Machei, 1960]. Electronic implementations are discussed by [Anderson, 19721.It in interesting that all books mentioned above are written by equip-

ment vendors. The paper by lGoff, 1966b] describes early efforts in digital implementation of PID controllers. Digital- implementations are treated in de-

tail in [Clarke, 1984; Hanselmann, 1987; Astr<im and Wittenmark, 1997]. The paper [Thrnbull, 1988] gives a broad description of the development of Eurotherm's temperature controller spanning a period of more than two decades

and technologies from electronic to digital. The book [Dote, 1972]1describes implementation of controllers for motion control. Code for implementation on

signal processorsthat admits very fast sampling is found in [Astrdm and Ste-

ingrfmsson, 1991].

.",,:,::.:.=.."\\,

' : i il::'l\\

aj

. . ' t\):s;i . .

;.

li ''

:ji:i}

!-

':l- .'1 -tt

t''..

\,;*5;"'. "

432

ii

Index

ABB, 319 ABB SOOXATM3,19 AccutuneTM, 322 actuator, 2 adaptive techniques, 295
adaptive control, 295 adaptive feedforward, 321 automatic tuning, 293, 295 gain scheduling, 295, 296 supervision, 304 uses of,297 air-fuel ratio control. 388 algebraic design, 189 aliasing, 413 AMIGO, Approximate MIGO design,
225 based on SOTD model,242 comparisons,24T detuning, 253 frequency responsemethods, 238 noise filtering, 251 PI control,22B PID control, 230 test batch.226 analog implementation, 408 anti-windup, 76 antialiasing filter, 414 apparent lag,26 apparent time constant, 26 apparent time deIay,26 approximate inverses, 141, 194 auto-tuning, 293, 295 automatic reset, 67 automatic tuning, 293, 295 average residencetime, Tor,23, 48 averaging control, I22

back propagation, 391 back-calculation. 79 backlash, 331 bandwidth, 132 bandwidth rise time product, 133 basic feedback loop, 96 batch unit, 86 blend station, 385 blending, 384 BO, modulus optimum, 198 Bode plot,22 Bode's integral, 114 bottom-up approach, 367 Bristol's relative gain, 349 bump test, 47 bumpless transfer, 423, 424 Butterworth filter, 4I4
cancellation of poles and zeros, 119, I9I, 194,,201,325
cascadecontrol, 373 applications, 377 control modes, 375 disturbance rejection, 373 tuning, 376 use of. 374 windup, 376
characteristic equation, 103 characteristic polynomial, 17 Chien, Hrones, and Reswick method,
166 CHR method, 166 Cohen-Coonmethod, 167 combined sensitivities, 117 complementary sensitivity function,
116

456

computer code,427 computer implementation, 412 conditional integration, 84 continuous stirred tank reactor, 40 control ettot,4 control paradigms, 366 control variable, 2 controllability ratio, 26 controller design, 95 controller gain, K, 5, 65 controller outputs, 427 correlation techniques, 52 crisp variable, 393 critical gain,26 critical point, 104 cut-back, 85
D-term, 5, 64 Dahlin-Higham method, 2BB DCS, distributed control systems, 8 dead time, seetime delay decay ratio, 52, I30 decoupling, SS4 defuzzification, 395 delay margin, 105, l2l, 277 derivative action, 68
computer implementation, 4I7 derivative cllff.2L4 derivative time, 76, 5, 65 design parameters, 135 differential equations, 20 direct adaptive control, 295 discretization, 414 distributed lags, 31, 38 disturbance models,44 disturbance rejecti on, 204 DMC, dynamic matrix control, 289 dominant pole design, 183 dominant poles, 109 doublet pulse, 49 drum level control, 155 dynamic matrices, 289 dynamic matrix control, DMC, 289 dynamic model, 14
ECA4OTM,319 ECA600TM,37g s . - . . . , . : ^ ! -3)2 1

empirical tuning, 169 error feedback, 74, 98 EXACTTM, 316 excitation detection, 305
feature-based models, 23 f e e d b a c k ,1 , 3 6 6 feedback fundamentals. 96 feedback loop, 96 feedforward control, 139
adaptive, 321 from disturbance, 154 from set point, 139, 150 incremental algorithm, 422 neutral, 146 filtering, 73,99, I25 Fisher-Rosemount, 321 force balance, 408 force feedback,4I0 FOTD model, 20, 28, 48 FOTDI model, 36 Foxboro, 316 FPGA, 6 frequency curve,22 frequency response,2I friction, 330 fundamental limitations, 101 fuzzy control, 392 fuzzy inference, 394 fuzzy logic, 392
gain crossover frequency, 105, 132 gain curve,22 gain margin, 104, I21 gain ratio, K, 27 gain scheduling, 43, 295, 296 Gang of Four, 98 Gang of Six, 98
Haalman's method, 190 half rule, 58 Hammerstein model, 42 Harris index, 337 heat conduction, ST heat exchange4 39,377 high freqency roll-off, 73 Honeywell, 322 hvsteresis. 331

457

Bibliography

I-PD controlle4 74 f-term, 5,64 IAE, integrated absolute error, 128 Idle index, 343 IE, integrated error, 128,278 IFI iterative feedback tuning, 318 IMC, internal model control, 198 implementation, 407
analog electronic, 4I0 computer based,412 incremental algorithm, 421 pneumatic, 408 impulse response, 19 incremental algorithm, 421 windup, 78 indirect adaptive control, 29b integral action, 4,67 integral control, 4 integral time, Ti,5,65 integrated absolute error, IAE, 128 integrated error, IE, I28,273 integrated squared error, ISE, 129 integrated time multiplied absolute
error, ITAE, 128 integrating processes,35 integrator clampin g, 84 integrator windup, see windup interacting tanks, 31 interaction index, 350 interaction of simple loops, 342 internal model control, IMC, 1gg internal stability, 106 inverse response, 36 ISE, integrated squared error, 129 ITAE, integrated time multiplied ab-
solute error, 128 iterative feedback tuning, IFT, B1g
jump- and rate limiter, BBB
lag, 28 lambda tuning, 186 limiters, 382 linear time-invariant system, 15 linearization, 381 load disturbances, 44
detection, 307 specifications, 123

loop assessment, 334 loop gain, 66 loop shaping, 104, 206 loop transfer function, 108 LOOPTUNETM, 323
manipulated variable, MV, 2 manual tuning, 169 maximum error, e^ur, 128 maximum selector, 386 maximum sensitivity, 118 measurement noise, 44 median selector, 388 membership functions, 392 MEMS, 6 mid-range control, 378 MIGO, M -constrained Integral Gain
Optimization, 218 minimum phase, 15 minimum selector. 386 minimum variance control, 46, 289 mode switches, 423 model predictive control, MPC, 28b model reduction. 56 model-based diagnosis, BB7 model-based tunin g, 298 modeling from data, 47 modulus optimum, BO, 198 motion control, 122 moving horizon control, 28b multiple lag, 29 MV, manipulated variable, 2
negative feedback, 3 neural network, 389
hidden layers, 890 learning, 391 neuron, 389 neutral feedforw ard, I4G non-minimum phase, 1b noninteracting tanks, 29 nonlinear elements, 381 normalized dead time r,2G normalized time delay, t,2G NOTD model, 142 Nyquist plot,22 Nyquist's stability criterion, 108
on-off control, 3

458

operational aspects,423 optimization methods, 196 oscillation detection, 310, 338 oscillatory systems, 34 overshoot, 130
P-term, 5, 64 Pairing, 351 parallel systems, 360 parameter estimation, 301 pattern recognition, 316 performance assessment,133, 336 periodic disturbances, 370 periodic variations, 370 phase crossover frequency, I04 phase cuwe,22 phase margin, 105 phase margin design, 163 physical modeling, 47 PI control, 5 PI-D controller, T4 PID control,5,64 PID controller
classical implementation, 70 discretization,4I4 ideal form,12 implementation, 407 interacting form, 70 ISA form, 72 non-interacting form, 70 parallel form,72 series fotm,T2 standard form,72 PIDr controller, 316 pneumatic implementation, 408 pole placement design, 174 poles, 17 PPI controller, 279,,}LG prediction ability of controllers, 5 using derivative action, 5 using model, 266 predictive control, 266 predictive PI controller, PPI,279 prefiltering,4L4 preload, 85 process garn,24 processvariable, PV,2

proportional action, 65 proportional band, 82 proportional control, 4 ProtunerTM, 324 P r o v o x T M ,S 2 I pulse step control, 151 pulse width modulati on, 42g pV, process variable, 2
quadratic programming, 2g6 quarter amplitude damping, 130
ramp unit, 382 rate constant, Kr,23 rate limiter,382 ratio control, 384 ratio station, 385 reaction curve, 14, LB receding horizon control, 28b reference value, 2 relative gain array, RGA, B4g relay auto-tuning, 300 relay feedback, bB repetitive control, 868 reset, 65,,67 resonance peaks, 722, l3I response time, T^u*, I28 RGA, Bristol's relative gain array, B4g rise time, l2g robust loop shaping, 206 robustness, 118, 19b robustness measure, Peter Hansen,
I2L Rosenbrock's system, Bb2 RSBTM,821 rule-based methods. 802 rule-basedtuning, 169
sampling, 4\3 SDM-2OrM, 319 selector control, 386
of air-fuel, 388 sensitivity crossover frequency, 113 sensitivity frequency, L32 sensitivity functions, 111 set point
limitation, 78 s p e c i f i c a t i o n s ,1 2 9
459

Bibliography

weighting,74, I45 weights, 74 set point, SP, 2 settling time, 130 SIMC - Skogestad's Internal Model
Controller, 195 Skogestad'shalf rule, 58 Skogestad'sInternal Model Controller,
SIMC, 195 SLPC-18I,28T, 323 sluggish control loops, 342 Smith predictor, 89, 267
analysis, 271 ideal time delay, 370 integrating processes,283 SO, symmetrical optimum, 198 SOTD model, 5I,54 SP, set point, 2 specifications, 128 spectral density, 46 split-range control, 378, 380, 403 stability, 102 margins, I04, L05, IL4 regions, 106 relation to poles, 103 state, 18 state models, 18 static gain, 13 static models, 13, 47 static process characteristic, 13 steady-state error, 66, 130 s t ep r es pon s e ,1 4 ,1 8 integrating, 15 monotone, 15 oscillating, 15 stick-slip motion, 330 stiction, 330 superposition principle, 15 supervision, 304 surge tank control, 722,383 symmetrical optimum, SO, 198 system structuring, 398
tanks continuous stirred reactor, 40 interacting, 31 noninteracting, 29
Techmation, 324
460

three-position pulse output, 429 thyristors, 427 time constant, 28 time delay,15, 17,28,266
apparent, 26 compensation, 89 normaliz ed, 26 TITO system, 348 top-down approach, 367 tracking, 79, 424 tracking time constant, 80, 83 transfer function, 19 transient response,18 transport delay, 17,20 ttracs, 427 tuning maps, 169 two degrees of freedom, 76, 96
UDC 6OOOTM3,22 ultimate frequency,26 ultimate gain,26
valves, 329 friction. 330 hysteresis, 331
velocity algorithms, 420
Wiener model, 42 windup, 76
back-calculation. 79 cascadecontrol, 376 conditional integration, 84 incremental algorithm, 78 selector control, 388 set-point limitation, 78 tracking, 79
Yokogawa, 323
zeros, 17 multivariable systems, 352
Ziegler-Nichols methods, 159 commentary, 168 frequency response method, 161 integration time inequality, I73 loop-shaping interpretation, 162 relations, 165 step response method, 159
't,
..t:'

