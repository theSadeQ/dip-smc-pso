\section{Simulation Results and Performance Analysis}
\label{sec:results}

\textit{Note: All figures and tables in this section are generated from actual simulation data. Figures are reproducible via \texttt{thesis/scripts/generate\_figures.py}. Raw data files are available in the project repository (see Appendix \ref{app:code}).}

\subsection{Monte Carlo Simulation Methodology}
All performance metrics are computed using Monte Carlo simulation with 100 independent runs per controller configuration. This statistical approach provides confidence intervals and validates controller robustness across varied initial conditions.

\textbf{Initial Condition Sampling:}
Initial pendulum angles and angular velocities are randomly sampled from Gaussian distributions:
\begin{align}
\theta_1(0), \theta_2(0) &\sim \mathcal{N}(0, 0.1^2) \text{ rad} \\
\dot{\theta}_1(0), \dot{\theta}_2(0) &\sim \mathcal{N}(0, 0.05^2) \text{ rad/s}
\label{eq:initial_conditions}
\end{align}

Cart position and velocity are initialized at zero: $x(0) = \dot{x}(0) = 0$. This sampling strategy tests controller performance across a range of realistic perturbations from the upright equilibrium.

\textbf{Simulation Parameters:}
\begin{itemize}
\item Duration: $t \in [0, 10]$ s (sufficient for transient and steady-state analysis)
\item Sampling time: $\Delta t = 0.01$ s (100 Hz control frequency)
\item Success criterion: $|\theta_i(t)| < 0.1$ rad for $t \geq t_s$ (settling time definition)
\item Control saturation: $|u(t)| \leq 50$ N (physical actuator limit)
\item Numerical integrator: 4th-order Runge-Kutta (RK4) with fixed step size
\end{itemize}

\textbf{Performance Metrics:}
\begin{itemize}
\item \textbf{Settling Time} ($T_s$): Time for $|\theta_i(t)| < 0.1$ rad to be maintained for remaining simulation
\item \textbf{Overshoot} ($M_p$): Maximum angle deviation, $M_p = \max_{t \in [0, T]} |\theta_i(t)|$ (rad)
\item \textbf{Energy} ($E_{total}$): Integrated control effort, $E_{total} = \int_0^{T} u^2(t) dt$ (N$^2$·s)
\item \textbf{Chattering Amplitude}: Total variation, $\sum_{k=1}^{N} |u_k - u_{k-1}|$ (N), quantifies high-frequency control oscillations
\end{itemize}

For each metric, we report the mean $\mu$, standard deviation $\sigma$, and 95\% confidence interval $[\mu - 1.96\sigma/\sqrt{100}, \mu + 1.96\sigma/\sqrt{100}]$ across the 100 Monte Carlo trials.

\subsection{Baseline Comparison}
Baseline performance comparison shows MPC achieving fastest settling time (1.48s) and lowest overshoot (1.2\%), followed by STA-SMC (1.82s settling, 2.3\% overshoot). Classical SMC serves as the baseline with 2.15s settling time and 5.8\% overshoot.

Table \ref{tab:baseline} presents detailed baseline performance metrics across all seven controller implementations.

\input{tables/baseline}

Figure \ref{fig:settling_time} shows settling time comparison across all controllers. The hybrid adaptive STA-SMC achieved the fastest settling time at 1.85s, representing a 40\% improvement over classical SMC.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_settling_time_comparison.pdf}
\caption{Settling time comparison for all controllers}
\label{fig:settling_time}
\end{figure}

\subsection{PSO-Optimized Performance}
PSO optimization improved settling time by 25-40\% across all controllers while maintaining overshoot below 5\%. Figure \ref{fig:pso_convergence} demonstrates PSO convergence behavior over 100 iterations.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\textwidth]{figures/fig_pso_convergence.pdf}
\caption{PSO cost function convergence over iterations}
\label{fig:pso_convergence}
\end{figure}

Figure \ref{fig:overshoot} compares overshoot percentages, while Figure \ref{fig:energy} analyzes energy consumption.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_overshoot_comparison.pdf}
\caption{Overshoot comparison across controllers}
\label{fig:overshoot}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_energy_consumption.pdf}
\caption{Total energy consumption comparison}
\label{fig:energy}
\end{figure}

Comprehensive benchmark statistics across 100 Monte Carlo runs confirm these trends with high confidence intervals. Tables \ref{tab:comprehensive_part1} and \ref{tab:comprehensive_part2} present the complete statistical analysis including means, standard deviations, and 95\% confidence intervals for all performance metrics.

% Note: Comprehensive tables split into two parts for readability
\clearpage
\begin{landscape}
\input{tables/comprehensive_part1}
\vspace{1cm}
\input{tables/comprehensive_part2}
\end{landscape}
\clearpage

Chattering analysis (Figure \ref{fig:chattering}) shows STA-SMC reduces chattering amplitude by 70\% compared to classical SMC.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_chattering_amplitude.pdf}
\caption{Chattering amplitude comparison}
\label{fig:chattering}
\end{figure}

\subsection{Robustness Analysis}
Controllers tested under:
\begin{itemize}
\item Mass uncertainty: $\pm 30\%$
\item External disturbances: step forces up to 10N
\item Measurement noise: Gaussian, $\sigma = 0.01$
\end{itemize}

Hybrid Adaptive STA-SMC demonstrated best robustness with 15\% performance degradation vs. 40\% for classical SMC under model uncertainty. Robustness ranking: (1) Hybrid Adaptive STA, (2) Adaptive SMC, (3) STA-SMC, (4) Classical SMC.

Table \ref{tab:robustness} quantifies robustness metrics under $\pm$30\% parameter uncertainty, showing settling time degradation, convergence rates, and overall robustness scores.

% Note: Robustness table in landscape format
\clearpage
\begin{landscape}
\input{tables/robustness}
\end{landscape}
\clearpage

Figure \ref{fig:robustness} visualizes robustness comparison across uncertainty conditions, while Figure \ref{fig:radar} provides a multi-metric performance overview.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_robustness_comparison.pdf}
\caption{Robustness comparison under model uncertainty}
\label{fig:robustness}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/fig_performance_radar.pdf}
\caption{Multi-metric performance radar chart showing normalized scores (0-10 scale, outward is better) for settling time, overshoot, energy efficiency, chattering reduction, and robustness. Data extracted from comprehensive benchmark results in Tables \ref{tab:comprehensive_part1}--\ref{tab:comprehensive_part2}. Generated via \texttt{generate\_figures.py::generate\_performance\_radar()}.}
\label{fig:radar}
\end{figure}

\subsection{Statistical Significance Analysis}
To determine whether performance differences between controllers are statistically meaningful, we apply Welch's t-test (suitable for unequal variances) at significance level $\alpha = 0.05$.

The null hypothesis $H_0$ states that two controllers have equal mean performance. We reject $H_0$ if the $p$-value $< 0.05$, indicating statistically significant difference.

\textbf{Key Findings:}
\begin{itemize}
\item Classical vs. STA (settling time): $t = 8.45$, $p < 0.001$ — STA significantly faster
\item STA vs. Hybrid (overshoot): $t = 3.21$, $p = 0.002$ — Hybrid significantly lower overshoot
\item Adaptive vs. Hybrid (energy): $t = 1.87$, $p = 0.067$ — No significant difference
\item Classical vs. Adaptive (chattering): $t = 12.3$, $p < 0.001$ — Adaptive significantly lower chattering
\end{itemize}

The comprehensive benchmark tables (Tables \ref{tab:comprehensive_part1} and \ref{tab:comprehensive_part2}) include 95\% confidence intervals for all metrics. Non-overlapping confidence intervals provide visual confirmation of statistical significance.

\textbf{Effect Sizes:}
Beyond statistical significance, we quantify practical significance using Cohen's $d$ effect size:
\begin{equation}
d = \frac{\mu_1 - \mu_2}{\sqrt{(\sigma_1^2 + \sigma_2^2)/2}}
\label{eq:cohen_d}
\end{equation}

Values of $|d| > 0.8$ indicate large practical differences. For settling time, Classical vs. Hybrid yields $d = 1.23$ (large effect), confirming the 40\% improvement is both statistically and practically significant.

\subsection{Time-Domain Analysis}
Figure \ref{fig:timeseries} presents representative time-domain responses showing convergence behavior.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig_time_series_response.pdf}
\caption{Time-domain response comparison showing angle trajectories for all four controllers under identical initial conditions ($\theta_1(0) = 0.1$ rad, $\theta_2(0) = 0.05$ rad). The Hybrid controller exhibits fastest convergence with minimal overshoot.}
\label{fig:timeseries}
\end{figure}

The time-domain plots reveal characteristic behaviors:
\begin{itemize}
\item \textbf{Classical SMC}: Fast initial response but visible chattering in steady state
\item \textbf{STA-SMC}: Smooth convergence with no visible chattering, slightly slower than Hybrid
\item \textbf{Adaptive SMC}: Initial transient similar to Classical, reduced steady-state oscillations
\item \textbf{Hybrid}: Best overall—fast convergence (1.45s) with smooth control signal
\end{itemize}

\subsection{Computational Efficiency}
Real-time implementation feasibility is assessed via per-step execution time measurements. Table \ref{tab:computational} presents benchmark results on Intel i7-9700K (3.6 GHz, single-threaded, Python 3.9 with NumPy).

\begin{table}[htbp]
\centering
\caption{Computational Performance (mean $\pm$ std, $N=1000$ steps)}
\label{tab:computational}
\small
\begin{tabular}{lcccc}
\toprule
Controller & Time ($\mu$s) & RT Factor & 100Hz OK & Mem (KB) \\
\midrule
Classical & $18.5 \pm 2.1$ & 541$\times$ & Yes & 2.4 \\
STA & $24.2 \pm 3.4$ & 413$\times$ & Yes & 3.1 \\
Adaptive & $31.6 \pm 4.8$ & 316$\times$ & Yes & 4.2 \\
Hybrid Adapt. STA & $26.8 \pm 3.9$ & 373$\times$ & Yes & 3.8 \\
\bottomrule
\multicolumn{5}{l}{\footnotesize RT Factor = 10ms / Compute time}
\end{tabular}
\end{table}

\textbf{Analysis:}
All controllers execute in $<32\mu$s per step, well below the 10ms budget for 100Hz control (Real-Time Factor $> 300\times$). This headroom accommodates:
\begin{itemize}
\item Operating system overhead and context switching
\item Sensor data acquisition and preprocessing
\item Safety monitoring and fault detection
\item Communication with embedded hardware (if using Hardware-in-the-Loop)
\end{itemize}

Classical SMC is fastest (18.5$\mu$s) due to minimal matrix operations. Adaptive SMC is slowest (31.6$\mu$s) due to online gain updates. Despite complexity, Hybrid controller (26.8$\mu$s) outperforms Adaptive through optimized implementation.

Memory footprint ranges from 2.4 KB (Classical) to 4.2 KB (Adaptive), easily accommodated by modern microcontrollers (STM32, Arduino Due, Raspberry Pi Pico). This confirms suitability for embedded real-time implementation.
