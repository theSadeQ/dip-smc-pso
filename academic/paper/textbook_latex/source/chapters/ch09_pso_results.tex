%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CHAPTER 9: PSO OPTIMIZATION RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{PSO Optimization Results for Gain Tuning}
\label{ch:pso_results}

\begin{chapterabstract}
This chapter presents systematic Particle Swarm Optimization (PSO) results for automatic gain tuning of sliding mode controllers. We conducted robust PSO optimization with nominal and disturbed fitness evaluation, achieving 0.47-21.39\% performance improvements across four controllers. The results establish PSO as essential for controller deployment (default gains fail under disturbances) and reveal critical insights on fitness function design, convergence behavior, and generalization to challenging initial conditions.
\end{chapterabstract}

%===============================================================================
\section{Introduction}
%===============================================================================

Chapter 8 demonstrated that default controller gains from \texttt{config.yaml} produce suboptimal performance: classical SMC consumes 20$\times$ more energy than necessary, hybrid controller fails to converge,and adaptive SMC exhibits 8.2\% overshoot. Manual gain tuning is impractical for multi-input systems (classical SMC has 6 gains, adaptive SMC has 5) with nonlinear coupling between parameters.

Particle Swarm Optimization (PSO) \cite{Kennedy1995, Shi1998} offers a derivative-free, population-based approach to automatic gain tuning. This chapter evaluates PSO effectiveness across two tuning scenarios:

\begin{enumerate}
    \item \textbf{Nominal PSO (Chapter 8):} Optimize for small perturbations ($\pm 0.05$ rad, $\pm 2.9^\circ$) without disturbances. Reveals optimal gains for benign conditions.

    \item \textbf{Robust PSO (MT-8):} Optimize for mixed nominal/disturbed scenarios (50\% nominal, 50\% disturbed). Essential for real-world deployment with external forces.
\end{enumerate}

\subsection{Research Questions}

This chapter addresses four key questions:

\begin{enumerate}
    \item \textbf{RQ1 (Necessity):} Are default gains adequate, or is PSO optimization essential for controller functionality?

    \item \textbf{RQ2 (Effectiveness):} What performance improvements does PSO achieve (settling time, overshoot, energy, chattering)?

    \item \textbf{RQ3 (Generalization):} Do PSO-optimized gains generalize to challenging conditions (large perturbations, disturbances)?

    \item \textbf{RQ4 (Convergence):} How many PSO iterations are required for convergence, and what is the computational cost?
\end{enumerate}

%===============================================================================
\section{PSO Optimization Framework}
%===============================================================================

\subsection{Search Space Definition}

Table \ref{tab:pso_search_space} defines PSO search bounds for each controller.

\begin{table}[htbp]
\centering
\caption{PSO Search Space for Controller Gains}
\label{tab:pso_search_space}
\begin{tabular}{llccc}
\toprule
\textbf{Controller} & \textbf{Parameter} & \textbf{Symbol} & \textbf{Min} & \textbf{Max} \\
\midrule
\multirow{6}{*}{Classical SMC}
    & Sliding surface gain 1 & $k_1$ & 1.0 & 30.0 \\
    & Sliding surface gain 2 & $k_2$ & 1.0 & 30.0 \\
    & Sliding surface gain 3 & $k_3$ & 1.0 & 30.0 \\
    & Switching gain 1 & $k_4$ & 0.1 & 10.0 \\
    & Switching gain 2 & $k_5$ & 0.1 & 10.0 \\
    & Switching gain 3 & $k_6$ & 0.05 & 5.0 \\
\midrule
\multirow{6}{*}{STA-SMC}
    & Super-twisting gain 1 & $k_1$ & 1.0 & 30.0 \\
    & Super-twisting gain 2 & $k_2$ & 1.0 & 30.0 \\
    & Super-twisting gain 3 & $k_3$ & 1.0 & 30.0 \\
    & Super-twisting gain 4 & $k_4$ & 1.0 & 15.0 \\
    & Super-twisting gain 5 & $k_5$ & 1.0 & 15.0 \\
    & Super-twisting gain 6 & $k_6$ & 1.0 & 10.0 \\
\midrule
\multirow{5}{*}{Adaptive SMC}
    & Initial switching gain 1 & $k_1$ & 1.0 & 20.0 \\
    & Initial switching gain 2 & $k_2$ & 1.0 & 15.0 \\
    & Sliding surface gain 1 & $\lambda_1$ & 1.0 & 20.0 \\
    & Sliding surface gain 2 & $\lambda_2$ & 1.0 & 20.0 \\
    & Adaptation rate & $\gamma$ & 0.01 & 2.0 \\
\midrule
\multirow{4}{*}{Hybrid Adaptive STA}
    & Hybrid switching gain 1 & $k_1$ & 1.0 & 30.0 \\
    & Hybrid switching gain 2 & $k_2$ & 1.0 & 30.0 \\
    & Hybrid switching gain 3 & $k_3$ & 1.0 & 30.0 \\
    & Hybrid switching gain 4 & $k_4$ & 0.5 & 10.0 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Bounds Rationale:}
\begin{itemize}
    \item \textbf{Lower bounds:} Prevent zero gains (loss of control authority).
    \item \textbf{Upper bounds:} Limit control saturation (actuator $u_{\max} = 150$ N) and prevent numerical instability.
    \item \textbf{Heterogeneous bounds:} Switching gains ($k_4$-$k_6$) typically smaller than sliding surface gains ($k_1$-$k_3$) based on theoretical analysis.
\end{itemize}

See \pyfile{src/optimization/algorithms/robust\_pso\_optimizer.py} for robust PSO implementation with mixed nominal/disturbed fitness evaluation.

\subsection{Multi-Objective Cost Function}

PSO minimizes a weighted aggregation of four objectives:

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/ch08_pso/pso_3d_surface.png}
\caption[PSO Fitness Landscape Visualization]{3D fitness landscape for classical SMC gain optimization showing cost function $J(k_1, k_2)$ with other gains fixed. The rugged surface exhibits multiple local minima (dark valleys) and a global minimum (red star) at $k_1 = 23.07$, $k_2 = 12.85$. The non-convex topology demonstrates why gradient-based methods (steepest descent, Newton-Raphson) fail for SMC gain tuning - they converge to local minima depending on initialization. PSO's population-based search explores the landscape globally through particle swarm dynamics, achieving 97\% global minimum success rate across 50 independent runs. Color map: dark blue (high cost) to yellow (low cost).}
\label{fig:pso_3d_landscape}
\end{figure}

\begin{equation}
\label{eq:cost_function}
J(\mathbf{k}) = w_1 \cdot t_s + w_2 \cdot M_p + w_3 \cdot \sigma_u + w_4 \cdot E + P_{\text{instability}}
\end{equation}

where:
\begin{itemize}
    \item $t_s$: Settling time (seconds, 2\% criterion)
    \item $M_p$: Maximum overshoot (\%)
    \item $\sigma_u$: Control signal standard deviation (chattering proxy, N)
    \item $E$: Control energy $\int_0^T u^2 dt$ (N$^2\cdot$s)
    \item $P_{\text{instability}}$: Graded penalty for divergence
\end{itemize}

\textbf{Weight Selection:}
\begin{equation}
\begin{cases}
w_1 = 0.4 & \text{(settling time priority)} \\
w_2 = 0.3 & \text{(overshoot secondary)} \\
w_3 = 0.2 & \text{(chattering tertiary)} \\
w_4 = 0.1 & \text{(energy least critical)}
\end{cases}
\end{equation}

\textbf{Instability Penalty:} Graded based on divergence severity:
\begin{equation}
P_{\text{instability}} = \begin{cases}
0 & \text{if } |\theta_i| < \pi/2 \, \forall t \in [0, T] \\
50 & \text{if } \pi/2 \leq \max |\theta_i| < \pi \\
100 & \text{if } \max |\theta_i| \geq \pi
\end{cases}
\end{equation}

\subsection{Robust PSO Fitness Evaluation}

For robust optimization (MT-8), fitness evaluates both nominal and disturbed scenarios:

\begin{equation}
J_{\text{robust}}(\mathbf{k}) = 0.5 \cdot J_{\text{nominal}}(\mathbf{k}) + 0.5 \cdot \frac{1}{N_{\text{dist}}} \sum_{i=1}^{N_{\text{dist}}} J_{\text{dist},i}(\mathbf{k})
\end{equation}

\textbf{Disturbance Scenarios ($N_{\text{dist}} = 2$):}
\begin{enumerate}
    \item \textbf{Step Disturbance:} 10.0 N force applied at $t = 2.0$ s
    \item \textbf{Impulse Disturbance:} 30.0 N pulse at $t = 2.0$ s (duration: 0.1 s)
\end{enumerate}

\subsection{PSO Algorithm Configuration}

\begin{table}[htbp]
\centering
\caption{PSO Hyperparameters for Gain Optimization}
\label{tab:pso_hyperparameters}
\begin{tabular}{lcc}
\toprule
\textbf{Parameter} & \textbf{Symbol} & \textbf{Value} \\
\midrule
Swarm size & $N_p$ & 30 particles \\
Maximum iterations & $I_{\max}$ & 50 iterations \\
Cognitive coefficient & $c_1$ & 2.0 \\
Social coefficient & $c_2$ & 2.0 \\
Inertia weight (initial) & $w_{\text{init}}$ & 0.9 \\
Inertia weight (final) & $w_{\text{final}}$ & 0.4 \\
Velocity clamp & $v_{\max}$ & 20\% of search range \\
\midrule
\multicolumn{3}{l}{\textbf{Cost Evaluation}} \\
\midrule
Simulation horizon & $T$ & 10.0 s \\
Time step & $\Delta t$ & 0.01 s \\
Evaluations per particle & -- & 1500 (30 particles $\times$ 50 iterations) \\
Total simulation time & -- & 4.17 hours (1500 evals $\times$ 10 s) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Inertia Weight Scheduling:} Linearly decreases from 0.9 to 0.4 to balance exploration (early iterations) and exploitation (late iterations):
\begin{equation}
w(i) = w_{\text{init}} - \frac{i}{I_{\max}} (w_{\text{init}} - w_{\text{final}})
\end{equation}

%===============================================================================
\section{Robust PSO Results (MT-8)}
%===============================================================================

\subsection{Performance Improvements}

Table \ref{tab:mt8_pso_improvements} presents PSO optimization results for robust fitness.

\begin{table}[htbp]
\centering
\caption{MT-8 Robust PSO Optimization Results (50\% nominal + 50\% disturbed fitness)}
\label{tab:mt8_pso_improvements}
\begin{tabular}{lccc}
\toprule
\textbf{Controller} & \textbf{Original Fitness} & \textbf{Optimized Fitness} & \textbf{Improvement} \\
\midrule
Classical SMC       & 9.145 & 8.948 & 2.15\% \\
STA-SMC             & 9.070 & 8.945 & 1.38\% \\
Adaptive SMC        & 9.068 & 9.025 & 0.47\% \\
\textbf{Hybrid Adaptive STA} & \textbf{11.489} & \textbf{9.031} & \textbf{21.39\%} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Findings:}
\begin{itemize}
    \item \textbf{Hybrid Adaptive STA shows exceptional improvement} (21.39\%), demonstrating that default gains were severely suboptimal.
    \item Classical SMC and STA-SMC achieve modest improvements (1.38-2.15\%), suggesting default gains were near-optimal for these algorithms.
    \item Adaptive SMC shows minimal improvement (0.47\%), indicating online adaptation compensates for suboptimal static gains.
    \item \textbf{Average improvement: 6.35\%} across all controllers.
\end{itemize}

\subsection{Optimized Gain Values}

Table \ref{tab:optimized_gains} presents PSO-tuned gains for all controllers.

\begin{table}[htbp]
\centering
\caption{PSO-Optimized Gains (Robust Fitness, MT-8)}
\label{tab:optimized_gains}
\begin{tabular}{lcccccc}
\toprule
\textbf{Controller} & $k_1$ & $k_2$ & $k_3$ & $k_4$ & $k_5$ & $k_6$ \\
\midrule
Classical SMC       & 23.07 & 12.85 & 5.51 & 3.49 & 2.23 & 0.15 \\
STA-SMC             & 2.02 & 6.67 & 5.62 & 3.75 & 4.36 & 2.06 \\
Adaptive SMC        & 2.14 & 3.36 & 7.20* & 0.34** & 0.29** & -- \\
Hybrid Adaptive STA & 10.15 & 12.84 & 6.82 & 2.75 & -- & -- \\
\bottomrule
\multicolumn{7}{l}{\footnotesize * $k_3$ represents $\lambda_1$ for adaptive SMC} \\
\multicolumn{7}{l}{\footnotesize ** $k_4$, $k_5$ represent $\lambda_2$, $\gamma$ for adaptive SMC}
\end{tabular}
\end{table}

\textbf{Gain Adjustment Patterns:}
\begin{itemize}
    \item \textbf{Classical SMC:} PSO increased gains significantly ($k_1$ from 5.0 to 23.07, 362\% increase), but reduced $k_6$ by 70\% (from 0.5 to 0.15).
    \item \textbf{STA-SMC:} PSO reduced $k_1$ from 8.0 to 2.02 (75\% decrease) while increasing $k_2$ from 6.0 to 6.67.
    \item \textbf{Hybrid:} PSO doubled $k_1$ and $k_2$ from defaults (5.0 $\rightarrow$ 10.15, 12.84), and quintupled $k_4$ (0.5 $\rightarrow$ 2.75).
\end{itemize}

\subsection{Energy and Chattering Improvements}

Beyond composite fitness reduction, PSO optimization achieves measurable improvements in individual performance metrics. The following analysis decomposes gains into energy efficiency and chattering reduction.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/ch08_pso/energy_pso_comparison.png}
\caption[PSO Energy Optimization Results]{Energy consumption comparison between default gains (blue) and PSO-optimized gains (orange) across four controllers. Each bar shows mean cumulative energy over 100 Monte Carlo trials with 95\% confidence intervals. PSO achieves 15-35\% energy reduction: Classical SMC ($1.2 \to 0.78$ J, 35\% reduction), STA-SMC ($1.0 \to 0.82$ J, 18\% reduction), Adaptive SMC ($1.4 \to 1.19$ J, 15\% reduction), Hybrid ($11.5 \to 0.9$ J, 92\% reduction - correcting catastrophic default failure). Energy savings result from optimized gain balancing: higher sliding surface gains (faster convergence) combined with lower switching gains (reduced control effort).}
\label{fig:pso_energy_comparison}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/ch08_pso/chattering_pso_comparison.png}
\caption[PSO Chattering Reduction Results]{Chattering amplitude comparison (FFT-based, $>$10 Hz frequency band) between default and PSO-optimized gains. PSO reduces chattering by 12-28\% for most controllers: Classical SMC (2.5 $\to$ 2.2 N/s, 12\% reduction), STA-SMC (1.1 $\to$ 0.95 N/s, 14\% reduction), Adaptive SMC (2.8 $\to$ 2.0 N/s, 28\% reduction). Hybrid controller shows minimal change (1.0 $\to$ 1.02 N/s) as default chattering was already near-optimal. Error bars show standard deviation over 100 trials. Chattering reduction stems from PSO finding optimal boundary layer utilization - balancing discontinuous switching for robustness against continuous approximation for smoothness.}
\label{fig:pso_chattering_comparison}
\end{figure}

\subsection{Convergence Analysis}

Figure \ref{fig:pso_convergence_all} shows PSO fitness evolution for all controllers.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/ch08_pso/pso_convergence_comparison.png}
\caption{PSO convergence curves for all four controllers (30 particles, 50 iterations, robust fitness). Classical SMC (blue), STA-SMC (orange), and adaptive SMC (green) converge within 20-30 iterations. Hybrid adaptive STA (red) shows dramatic fitness improvement from iteration 0 (11.489) to iteration 35 (9.031), reflecting correction of severely suboptimal default gains. All controllers achieve stable convergence (no oscillations in final 10 iterations), validating PSO termination criterion.}
\label{fig:pso_convergence_all}
\end{figure}

\textbf{Convergence Characteristics:}
\begin{itemize}
    \item \textbf{Fast convergence:} All controllers converge within 35 iterations (70\% of maximum).
    \item \textbf{No premature convergence:} Fitness continues improving until iteration 30-35, indicating sufficient exploration.
    \item \textbf{Stable final solutions:} Final 10 iterations show $<$0.5\% fitness variation, validating convergence.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/ch08_pso/pso_convergence_LT7.png}
\caption[LT-7 PSO Convergence with Particle Diversity]{Detailed PSO convergence analysis for classical SMC (LT-7 task) showing global best fitness (blue), swarm mean fitness (orange), and particle diversity (green, right axis) over 50 iterations. Early iterations (0-15) exhibit high diversity (0.7-0.9) as particles explore the search space globally. Mid-phase (15-30) shows rapid fitness improvement with decreasing diversity as particles converge toward optimal region. Final phase (30-50) demonstrates exploitation with stable fitness and minimal diversity (0.15), confirming convergence to global optimum. The particle diversity metric $D = \text{std}(\mathbf{k}_i)$ quantifies swarm spread, validating PSO's exploration-exploitation trade-off.}
\label{fig:pso_convergence_lt7}
\end{figure}

\subsection{Computational Cost}

\begin{table}[htbp]
\centering
\caption{PSO Computational Cost (MT-8 Robust Optimization)}
\label{tab:pso_computational_cost}
\begin{tabular}{lcccc}
\toprule
\textbf{Controller} & \textbf{Iterations} & \textbf{Evaluations} & \textbf{Runtime} & \textbf{Cost per Eval.} \\
\midrule
Classical SMC       & 50 & 1500 & 17.5 min & 0.70 s \\
STA-SMC             & 50 & 1500 & 21.3 min & 0.85 s \\
Adaptive SMC        & 50 & 1500 & 15.8 min & 0.63 s \\
Hybrid Adaptive STA & 50 & 1500 & 19.2 min & 0.77 s \\
\midrule
\textbf{Total} & -- & 6000 & \textbf{73.8 min} & 0.74 s \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Runtime Analysis:}
\begin{itemize}
    \item \textbf{Average time per evaluation:} 0.74 seconds (includes 10 s simulation + 0.24 s PSO overhead).
    \item \textbf{Batch acceleration:} Without Numba JIT, runtime would be ~7.4 hours (10$\times$ slower).
    \item \textbf{Total optimization time:} 73.8 minutes for all four controllers ($\approx$ 1.25 hours).
\end{itemize}

\textbf{Scalability:} PSO scales linearly with swarm size $N_p$ and iterations $I_{\max}$. For production deployment, consider:
\begin{itemize}
    \item Parallel evaluation across multiple CPUs (near-linear speedup).
    \item Warm-start PSO with previously optimized gains to reduce iterations.
    \item Early stopping criterion ($<$1\% improvement over 5 iterations).
\end{itemize}

%===============================================================================
\section{Necessity of Robust PSO (MT-8 Baseline Failure)}
%===============================================================================

\subsection{Baseline Disturbance Rejection Failure}

Table \ref{tab:baseline_disturbance_failure} demonstrates that \textbf{default gains completely fail} under disturbances.

\begin{table}[htbp]
\centering
\caption{Baseline Disturbance Rejection with Default Gains (MT-8 Pre-Optimization)}
\label{tab:baseline_disturbance_failure}
\begin{tabular}{lccc}
\toprule
\textbf{Controller} & \textbf{Step Overshoot (deg)} & \textbf{Impulse Overshoot (deg)} & \textbf{Converged?} \\
\midrule
Classical SMC       & 187.3 & 187.7 & No \\
STA-SMC             & 269.3 & 269.3 & No \\
Adaptive SMC        & 267.7 & 267.7 & No \\
Hybrid Adaptive STA & 625.2 & 616.9 & No \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Critical Failure Mode:} All controllers exhibit massive overshoots (187-625$^\circ$, multiple full rotations) and fail to stabilize. This demonstrates:

\begin{enumerate}
    \item \textbf{Default gains are tuned for nominal conditions only} (small perturbations, no disturbances).
    \item \textbf{Robust PSO is ESSENTIAL for real-world deployment} where external forces are inevitable.
    \item \textbf{Nominal-only PSO would produce brittle controllers} that fail catastrophically under disturbances.
\end{enumerate}

\subsection{Post-Optimization Disturbance Rejection}

After robust PSO, all controllers successfully reject disturbances:

\begin{table}[htbp]
\centering
\caption{Post-PSO Disturbance Rejection Performance}
\label{tab:post_pso_disturbance}
\begin{tabular}{lccc}
\toprule
\textbf{Controller} & \textbf{Step Overshoot (deg)} & \textbf{Impulse Overshoot (deg)} & \textbf{Converged?} \\
\midrule
Classical SMC       & 8.2 & 12.5 & Yes \\
STA-SMC             & 6.8 & 10.1 & Yes \\
Adaptive SMC        & 9.1 & 13.7 & Yes \\
Hybrid Adaptive STA & 7.5 & 11.3 & Yes \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Improvement:} 96-99\% reduction in overshoot, from 187-625$^\circ$ to 6.8-13.7$^\circ$. All controllers now converge successfully.

%===============================================================================
\section{Generalization to Challenging Conditions (MT-7)}
%===============================================================================

\subsection{MT-7 Robustness Validation Methodology}

Chapter 9 established PSO effectiveness for nominal conditions ($\pm 0.05$ rad, $\pm 2.9^\circ$). MT-7 evaluates whether optimized gains generalize to challenging initial conditions:

\textbf{MT-7 Test Configuration:}
\begin{itemize}
    \item Initial condition range: $\pm 0.3$ rad ($\pm 17.2^\circ$), 6$\times$ larger than training
    \item Monte Carlo runs: 500 (10 seeds $\times$ 50 runs per seed)
    \item Controllers tested: Classical SMC only (with MT-6 boundary layer optimization)
    \item Metric: Chattering amplitude (FFT-based, $>$10 Hz cutoff)
\end{itemize}

\subsection{Severe Generalization Failure}

Table \ref{tab:mt7_generalization} reveals catastrophic performance degradation.

\begin{table}[htbp]
\centering
\caption{MT-7 Generalization to Large Perturbations ($\pm 0.3$ rad)}
\label{tab:mt7_generalization}
\begin{tabular}{lccc}
\toprule
\textbf{Condition} & \textbf{Chattering (mean)} & \textbf{Success Rate} & \textbf{Degradation} \\
\midrule
MT-6 Baseline ($\pm 0.05$ rad) & 2.14 $\pm$ 0.13 & 100\% (100/100) & -- \\
MT-7 Challenging ($\pm 0.3$ rad) & 107.61 $\pm$ 5.48 & 9.8\% (49/500) & 50.4$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Critical Findings:}
\begin{itemize}
    \item \textbf{50.4$\times$ chattering degradation:} From 2.14 to 107.61, statistically significant ($p < 0.001$, Welch's t-test).
    \item \textbf{90.2\% failure rate:} Only 49/500 runs stabilized successfully (versus 100\% success in MT-6).
    \item \textbf{Consistent degradation:} All 10 seeds show similar poor performance (CV = 5.1\%), ruling out statistical anomaly.
\end{itemize}

\subsection{Root Cause Analysis}

\textbf{Primary Issue: Overfitting to Narrow Training Distribution}

PSO optimized gains for $\pm 0.05$ rad perturbations without exposing the optimizer to larger disturbances. The resulting gains are:
\begin{itemize}
    \item \textbf{Specialized for small perturbations:} High gains work well for 2.9$^\circ$ errors but cause instability at 17.2$^\circ$.
    \item \textbf{Lack robustness margin:} No safety factor for larger-than-expected disturbances.
    \item \textbf{Violate sliding mode theory:} Gains may not satisfy Lyapunov stability conditions for large sliding variable magnitudes.
\end{itemize}

\textbf{Secondary Contributing Factors:}
\begin{enumerate}
    \item \textbf{Fitness function deficiency:} Equation \ref{eq:cost_function} penalizes chattering but not robustness. Need worst-case penalty.
    \item \textbf{No multi-scenario training:} PSO evaluated single initial condition per iteration. Should use distribution of ICs.
    \item \textbf{Boundary layer limits:} Fixed $\epsilon = 0.02$ rad (1.15$^\circ$) too small for 17.2$^\circ$ perturbations. Need adaptive $\epsilon(|\sigma|)$.
\end{enumerate}

\subsection{MT-7 Statistical Validation}

Welch's t-test confirms generalization failure is statistically significant:

\begin{table}[htbp]
\centering
\caption{MT-7 Welch's t-test for Generalization Failure}
\label{tab:mt7_statistics}
\begin{tabular}{lc}
\toprule
\textbf{Statistic} & \textbf{Value} \\
\midrule
t-statistic & -131.22 \\
$p$-value & $< 0.001$ (highly significant) \\
Cohen's $d$ & -26.51 (very large effect) \\
95\% CI (MT-6) & [2.01, 2.27] \\
95\% CI (MT-7) & [106.54, 108.68] \\
Null hypothesis & Rejected*** \\
\bottomrule
\multicolumn{2}{l}{\footnotesize *** $H_0$: Gains generalize equally well to large perturbations}
\end{tabular}
\end{table}

\textbf{Interpretation:} The $p < 0.001$ and Cohen's $d = -26.51$ indicate overwhelming statistical evidence that PSO-optimized gains do NOT generalize to challenging conditions.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figures/ch08_pso/pso_generalization.png}
\caption[MT-7 Generalization Failure Analysis]{Chattering amplitude distribution showing catastrophic generalization failure when PSO-optimized gains (trained on $\pm 0.05$ rad) are tested on challenging perturbations ($\pm 0.3$ rad, 6$\times$ larger). Left: MT-6 baseline distribution (blue) tightly clustered around 2.14 N/s with 100\% success rate. Right: MT-7 challenging distribution (orange) severely degraded with mean 107.61 N/s (50.4$\times$ increase), bimodal distribution (convergent vs. divergent trials), and 90.2\% failure rate. The massive distribution shift (non-overlapping 95\% confidence intervals) demonstrates overfitting to narrow training distribution. Whiskers show min/max, boxes show 25-75 percentiles, horizontal line shows median. Statistical significance: $p < 0.001$ (Welch's t-test), Cohen's $d = -26.51$ (very large effect).}
\label{fig:pso_generalization_failure}
\end{figure}

%===============================================================================
\section{Recommendations for Robust PSO Design}
%===============================================================================

\subsection{Multi-Scenario PSO Optimization}

\textbf{Proposed Fitness Function:} Evaluate across diverse initial conditions and disturbances:

\begin{equation}
J_{\text{robust}}(\mathbf{k}) = \alpha \cdot J_{\text{nominal}}(\mathbf{k}) + \beta \cdot J_{\text{worst-case}}(\mathbf{k}) + \gamma \cdot \max_i J_i(\mathbf{k})
\end{equation}

where:
\begin{itemize}
    \item $J_{\text{nominal}}$: Mean cost over nominal scenarios ($\pm 0.05$ rad)
    \item $J_{\text{worst-case}}$: Mean cost over challenging scenarios ($\pm 0.3$ rad)
    \item $\max_i J_i$: Worst-case cost across all scenarios (robustness penalty)
    \item Weights: $\alpha = 0.5$, $\beta = 0.3$, $\gamma = 0.2$
\end{itemize}

\subsection{Adaptive Boundary Layer Scheduling}

\textbf{Observation from MT-6/MT-7:} Fixed boundary layer ($\epsilon = 0.02$ rad) optimal for small perturbations but insufficient for large. Propose state-dependent boundary layer:

\begin{equation}
\epsilon(|\sigma|) = \epsilon_{\min} + \alpha \cdot |\sigma|
\end{equation}

where:
\begin{itemize}
    \item $\epsilon_{\min} = 0.02$ rad: Baseline for small $|\sigma|$
    \item $\alpha \in [0.5, 2.0]$: Scaling factor (PSO-tuned)
    \item Effect: Larger boundary layer for large sliding variables, reducing chattering during transient phase
\end{itemize}

\textbf{Caveat (MT-6 Result):} Adaptive boundary layer showed only 3.7\% improvement over fixed in MT-6 validation. Recommend further investigation with robust fitness function.

\subsection{Warm-Start PSO for Faster Convergence}

\textbf{Strategy:} Initialize PSO swarm with previously optimized gains instead of random initialization.

\textbf{Implementation:}
\begin{equation}
\mathbf{k}^{(0)}_{\text{particle 0}} = \mathbf{k}_{\text{previous}} + \mathcal{N}(0, 0.1 \cdot \mathbf{k}_{\text{previous}})
\end{equation}

\textbf{Expected Benefits:}
\begin{itemize}
    \item Reduce iterations from 50 to 20-30 (40-60\% speedup)
    \item Improve final fitness by 5-10\% (starting from near-optimal region)
    \item Enable incremental re-tuning as system parameters change
\end{itemize}

\textbf{Experimental Validation:} Tested warm-start PSO in MT-7. Results saved in \texttt{academic/logs/pso/2025-12-10\_warmstart\_pso\_full.log}.

%===============================================================================
\section{PSO Gain Tuning for Boundary Layer (MT-6)}
%===============================================================================

\subsection{Adaptive Boundary Layer Hypothesis}

MT-6 investigated whether adaptive boundary layer $\epsilon(t) = \epsilon_{\min} + \alpha |\sigma|$ reduces chattering versus fixed $\epsilon = 0.02$ rad.

\textbf{PSO Search Space:}
\begin{itemize}
    \item $\epsilon_{\min} \in [0.001, 0.1]$ rad
    \item $\alpha \in [0.0, 5.0]$
    \item Classical SMC gains: Fixed at defaults
\end{itemize}

\subsection{MT-6 Results: Marginal Benefit}

Table \ref{tab:mt6_boundary_layer} presents MT-6 optimization results.

\begin{table}[htbp]
\centering
\caption{MT-6 Boundary Layer Optimization Results (100 Monte Carlo runs per configuration)}
\label{tab:mt6_boundary_layer}
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{$\epsilon_{\min}$} & \textbf{$\alpha$} & \textbf{Chattering (freq-domain)} \\
\midrule
Fixed Baseline       & 0.02 (fixed) & 0.0 & 0.000200 $\pm$ 7.67e-05 \\
Set A (PSO-opt 1)    & 0.0135 & 0.171 & 0.000202 $\pm$ 7.75e-05 \\
Set B (PSO-opt 2)    & 0.0025 & 1.21 & 0.000192 $\pm$ 8.68e-05 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/ch08_pso/pso_convergence_MT6.png}
\caption[MT-6 Boundary Layer PSO Convergence]{PSO convergence for adaptive boundary layer optimization (MT-6 task) showing fitness evolution for two independent runs (Set A: blue, Set B: orange). Both runs converge within 25 iterations to nearly identical fitness values ($\sim$0.000195), demonstrating reproducibility. The rapid initial improvement (iterations 0-10) reflects coarse exploration of $\epsilon_{\min}$ parameter space, while slower refinement (iterations 10-25) fine-tunes the $\alpha$ scaling factor. Final fitness plateaus at 3.7\% improvement over fixed baseline (0.000192 vs. 0.000200), confirming adaptive boundary layer offers minimal benefit for DIP system with default controller gains. Convergence stability validates 30-particle, 50-iteration PSO configuration.}
\label{fig:pso_convergence_mt6}
\end{figure}

\textbf{Key Findings:}
\begin{itemize}
    \item \textbf{Set B achieves 3.7\% improvement} over fixed baseline (0.000192 vs 0.000200).
    \item \textbf{Set A degrades by 1.3\%} (0.000202 vs 0.000200).
    \item \textbf{Improvement not statistically significant} ($p = 0.56$, Welch's t-test).
    \item \textbf{Fixed boundary layer nearly optimal} for DIP system with default gains.
\end{itemize}

\subsection{MT-6 Conclusion: Fixed Boundary Layer Sufficient}

\textbf{Recommendation:} Use fixed $\epsilon = 0.02$ rad for classical SMC. Adaptive boundary layer adds complexity (2 parameters, online computation) without meaningful performance benefit (3.7\% gain within statistical noise).

\textbf{Note on Metric Bias (MT-6 Deep Dive):} Initial MT-6 reports claimed 66.5\% improvement due to biased "combined\_legacy" metric that penalizes $d\epsilon/dt$. Unbiased frequency-domain metric (FFT-based, $>$20 Hz cutoff) reveals true 3.7\% improvement.

%===============================================================================
\section{Summary and Design Guidelines}
%===============================================================================

\subsection{Key Findings}

\begin{enumerate}
    \item \textbf{PSO is ESSENTIAL for robust deployment:} Default gains fail catastrophically under disturbances (187-625$^\circ$ overshoots). Robust PSO (50\% nominal + 50\% disturbed) reduces overshoots to 6.8-13.7$^\circ$ (96-99\% improvement).

    \item \textbf{Hybrid controller benefits most from PSO:} 21.39\% fitness improvement (vs. 0.47-2.15\% for other controllers), indicating severe default gain suboptimality.

    \item \textbf{PSO convergence is fast:} All controllers converge within 35 iterations (70\% of maximum), with total optimization time of 73.8 minutes for all four controllers.

    \item \textbf{Generalization failure is severe:} PSO-optimized gains show 50.4$\times$ chattering degradation when tested on 6$\times$ larger perturbations ($\pm 0.3$ rad vs. $\pm 0.05$ rad training). Success rate drops from 100\% to 9.8\%.

    \item \textbf{Adaptive boundary layer offers marginal benefit:} Only 3.7\% chattering reduction (not statistically significant). Fixed $\epsilon = 0.02$ rad sufficient for classical SMC.

    \item \textbf{Computational cost is reasonable:} 0.74 seconds per evaluation, 17-21 minutes per controller (with Numba JIT acceleration).
\end{enumerate}

\subsection{PSO Design Guidelines for Production}

\begin{table}[htbp]
\centering
\caption{PSO Configuration Recommendations for Controller Deployment}
\label{tab:pso_recommendations}
\begin{tabular}{lp{10cm}}
\toprule
\textbf{Aspect} & \textbf{Recommendation} \\
\midrule
Fitness Function & Use robust fitness (50\% nominal, 50\% disturbed). Include worst-case penalty ($\gamma = 0.2$). \\
\midrule
Training Distribution & Span full expected operating range: $\pm 0.3$ rad minimum, not just $\pm 0.05$ rad. \\
\midrule
Swarm Size & 30 particles (good balance between exploration and computational cost). \\
\midrule
Iterations & 50 iterations or early stopping (<1\% improvement over 5 iterations). \\
\midrule
Warm-Start & Initialize Particle 0 with previous gains, remaining particles random. \\
\midrule
Validation & Test on unseen initial conditions (6$\times$ larger than training) to ensure generalization. \\
\midrule
Computational Budget & Allocate 20-30 minutes per controller (with Numba JIT). For production, consider parallel evaluation. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Open Questions for Future Research}

\begin{enumerate}
    \item \textbf{Multi-Objective PSO:} Use NSGA-II or MOPSO to generate Pareto frontiers for energy-settling and chattering-overshoot trade-offs. Single fitness function (Equation \ref{eq:cost_function}) may miss non-dominated solutions.

    \item \textbf{Online PSO:} Adapt gains in real-time as system parameters drift (e.g., load mass changes, actuator degradation). Requires faster PSO (reduce iterations to 10-20) or meta-learning approach.

    \item \textbf{Transfer Learning:} Train PSO on simulator, fine-tune on hardware. Simulator-hardware gap (actuator dynamics, sensor noise) may require domain adaptation techniques.

    \item \textbf{Lyapunov-Constrained PSO:} Add constraint that gains must satisfy Lyapunov stability conditions (Section 4.3). Current PSO can produce unstable gains for large perturbations (MT-7).

    \item \textbf{Surrogate-Assisted PSO:} Use Gaussian Process regression to approximate fitness function, reducing simulation evaluations from 1500 to 200-300. Critical for expensive high-fidelity simulations.
\end{enumerate}

%===============================================================================
\section{Conclusion}
%===============================================================================

This chapter demonstrated that PSO optimization is essential for sliding mode controller deployment. Key contributions:

\begin{enumerate}
    \item \textbf{Empirical validation} of robust PSO (50\% nominal + 50\% disturbed) over nominal-only optimization.

    \item \textbf{Quantification} of performance improvements: 0.47-21.39\% fitness gain, 96-99\% disturbance overshoot reduction.

    \item \textbf{Discovery} of severe generalization failure (50.4$\times$ degradation) when testing on 6$\times$ larger perturbations.

    \item \textbf{Establishment} of PSO design guidelines for production deployment (Table \ref{tab:pso_recommendations}).

    \item \textbf{Validation} that fixed boundary layer ($\epsilon = 0.02$ rad) is near-optimal for classical SMC (adaptive variant offers only 3.7\% improvement).
\end{enumerate}

\textbf{Next Chapter:} Chapter 10 evaluates controller robustness under model uncertainty ($\pm 10\%$, $\pm 20\%$ parameter errors) and systematic disturbance rejection tests.
