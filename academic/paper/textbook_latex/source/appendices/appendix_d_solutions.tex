%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX D: EXERCISE SOLUTIONS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Selected Exercise Solutions}
\label{app:solutions}

This appendix provides detailed solutions to selected exercises from each chapter.

%===============================================================================
\section{Chapter 1 Solutions}
%===============================================================================

\textbf{Exercise 1.1}: Calculate the degree of underactuation for the double-inverted pendulum.

\textbf{Solution}: The DIP has 3 degrees of freedom ($x, \theta_1, \theta_2$) and 1 control input ($u$, horizontal force on cart). Degree of underactuation = $3 - 1 = 2$.

\vspace{1em}

\textbf{Exercise 1.3}: Explain three mechanisms that cause chattering in SMC.

\textbf{Solution}:
\begin{enumerate}
    \item \textbf{Time discretization}: Finite sampling rate cannot implement infinite-frequency switching.
    \item \textbf{Actuator bandwidth}: Physical actuators have finite response time, causing delays.
    \item \textbf{Sensor noise}: Measurement noise near sliding surface triggers erratic switching.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.2}: The double-inverted pendulum has 3 degrees of freedom and 1 actuator. Calculate the degree of underactuation. If we add a second actuator directly controlling $\theta_1$, would the system become fully actuated?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Degree of underactuation}:
    \begin{equation}
    \text{Underactuation} = n - m = 3 - 1 = 2
    \end{equation}
    where $n = 3$ degrees of freedom ($x_{\text{cart}}, \theta_1, \theta_2$) and $m = 1$ control input ($u$ acting on cart).

    \item \textbf{Adding second actuator}: With an additional torque $\tau_1$ directly on joint 1, we would have $m = 2$ actuators controlling $n = 3$ DOF. The system would still be underactuated with degree $3 - 2 = 1$. To become fully actuated, we need $m = n = 3$ actuators (force on cart, torque on $\theta_1$, torque on $\theta_2$).
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.4}: A discrete-time controller samples at 1 kHz. If the sliding surface value oscillates with amplitude $\pm 0.01$ and the system derivative $\dot{\sigma} \approx 10$, estimate the chattering frequency. How does doubling the sampling rate affect this?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Chattering frequency estimation}: The sliding surface crosses zero every half-period. Time for one crossing:
    \begin{equation}
    \Delta t \approx \frac{2 \cdot \sigma_{\text{amp}}}{|\dot{\sigma}|} = \frac{2 \times 0.01}{10} = 0.002 \text{ s}
    \end{equation}
    Chattering frequency:
    \begin{equation}
    f_{\text{chatter}} = \frac{1}{2\Delta t} = \frac{1}{0.004} = 250 \text{ Hz}
    \end{equation}

    \item \textbf{Effect of doubling sampling rate}: At 2 kHz sampling ($\Delta t_{\text{sample}} = 0.5$ ms instead of 1 ms), the chattering frequency increases because the controller can switch faster. For quasi-sliding mode, $f_{\text{chatter}} \approx f_{\text{sample}}/2 = 1000$ Hz (doubling from 500 Hz). However, the amplitude $\sigma_{\text{amp}}$ decreases proportionally to $\Delta t_{\text{sample}}$, so the steady-state tracking error improves.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.5}: Write the total mechanical energy of the DIP system as $E = T + V$ (kinetic + potential). At the upright equilibrium $(\theta_1 = \theta_2 = 0, \dot{\theta}_1 = \dot{\theta}_2 = 0)$, is this energy a local minimum, maximum, or saddle point?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Total energy}:
    \begin{align}
    E &= T + V \\
    T &= \frac{1}{2} M \dot{x}^2 + \frac{1}{2} m_1 (\dot{x}_1^2 + \dot{y}_1^2) + \frac{1}{2} m_2 (\dot{x}_2^2 + \dot{y}_2^2) + \frac{1}{2} I_1 \dot{\theta}_1^2 + \frac{1}{2} I_2 \dot{\theta}_2^2 \\
    V &= m_1 g L_1 (1 - \cos\theta_1) + m_2 g [L_1(1 - \cos\theta_1) + L_2(1 - \cos\theta_2)]
    \end{align}

    \item \textbf{Energy at upright equilibrium}: At $(\theta_1 = \theta_2 = 0, \dot{\theta}_1 = \dot{\theta}_2 = 0, \dot{x} = 0)$:
    \begin{equation}
    E_{\text{eq}} = V(0, 0) = 0 \quad \text{(reference potential)}
    \end{equation}

    \item \textbf{Local behavior}: Perturb slightly: $\theta_1 = \epsilon_1, \theta_2 = \epsilon_2$ (small). Taylor expand potential:
    \begin{equation}
    V \approx -\frac{1}{2} m_1 g L_1 \epsilon_1^2 - \frac{1}{2} m_2 g (L_1 \epsilon_1^2 + L_2 \epsilon_2^2) < 0
    \end{equation}
    Since $V$ decreases for small perturbations, the upright position is a \textbf{local maximum} of potential energy (unstable equilibrium). The total energy $E$ has a \textbf{saddle point} structure: minimum in velocity directions (kinetic energy is positive definite), maximum in angular directions.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.6}: For the sliding surface $\sigma = k_1 \theta + k_2 \dot{\theta}$ with $k_1, k_2 > 0$, verify that $V = \frac{1}{2} \sigma^2$ is a valid Lyapunov function (positive definite, radially unbounded). Under what conditions is $\dot{V} < 0$?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Positive definiteness}:
    \begin{equation}
    V = \frac{1}{2} \sigma^2 \geq 0, \quad V = 0 \iff \sigma = 0
    \end{equation}
    Positive definite: $\checkmark$

    \item \textbf{Radial unboundedness}:
    \begin{equation}
    |\sigma| = |k_1 \theta + k_2 \dot{\theta}| \to \infty \implies V \to \infty
    \end{equation}
    Radially unbounded: $\checkmark$

    \item \textbf{Lyapunov derivative}:
    \begin{equation}
    \dot{V} = \sigma \dot{\sigma} = \sigma (k_1 \dot{\theta} + k_2 \ddot{\theta})
    \end{equation}
    For the control law $u = -K \sign(\sigma) - k_d \sigma + u_{\text{eq}}$, if the switching gain satisfies $K > \|d\|_{\max}$ (where $d$ is matched uncertainty), then:
    \begin{equation}
    \dot{V} = \sigma (-K \sign(\sigma) - k_d \sigma + \text{bounded terms}) \leq -K |\sigma| - k_d \sigma^2 + c |\sigma|
    \end{equation}
    Condition for $\dot{V} < 0$: $K > c$ (switching gain dominates uncertainty). This ensures $\dot{V} \leq -(K - c) |\sigma| - k_d \sigma^2 < 0$ for $\sigma \neq 0$.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.7}: If the boundary layer thickness $\epsilon$ is doubled, how does the steady-state tracking error change? How does the chattering frequency change? Derive these relationships analytically assuming a first-order approximation.

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Steady-state tracking error}: Inside the boundary layer $|\sigma| \leq \epsilon$, the control law uses $\sat(\sigma/\epsilon)$ instead of $\sign(\sigma)$:
    \begin{equation}
    u = -K \frac{\sigma}{\epsilon} \quad \text{for } |\sigma| \leq \epsilon
    \end{equation}
    At steady state, $\dot{\sigma} \approx 0$, leading to a residual sliding surface error $\sigma_{\text{ss}} \sim \epsilon$. The tracking error in angle is:
    \begin{equation}
    |\theta_{\text{ss}}| \sim \frac{\epsilon}{k_1} \quad \text{(assuming } \sigma = k_1 \theta + k_2 \dot{\theta} \text{ and } \dot{\theta}_{\text{ss}} \approx 0 \text{)}
    \end{equation}
    \textbf{Relationship}: If $\epsilon$ is doubled, the steady-state tracking error doubles: $|\theta_{\text{ss}}|_{\text{new}} = 2 |\theta_{\text{ss}}|_{\text{old}}$.

    \item \textbf{Chattering frequency}: The chattering frequency is inversely proportional to boundary layer thickness. Larger $\epsilon$ creates a wider "dead zone" where switching is avoided, reducing the rate of sign changes in the control. Approximation:
    \begin{equation}
    f_{\text{chatter}} \propto \frac{1}{\epsilon}
    \end{equation}
    \textbf{Relationship}: If $\epsilon$ is doubled, chattering frequency is halved: $f_{\text{new}} = \frac{1}{2} f_{\text{old}}$.

    \item \textbf{Trade-off}: The boundary layer method presents a fundamental trade-off between chattering reduction and tracking accuracy. Increasing $\epsilon$ reduces chattering but worsens steady-state error.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 1.8}: Research Vadim Utkin's 1977 paper (Utkin, V.I., "Variable Structure Systems with Sliding Modes," IEEE Trans. Automatic Control, 1977). Summarize the three main theoretical contributions and explain how they differ from prior variable structure control work.

\textbf{Solution}:

\textbf{Three Main Contributions}:

\begin{enumerate}
    \item \textbf{Reaching Condition ($\sigma \dot{\sigma} < 0$)}: Utkin formalized the condition ensuring finite-time convergence to the sliding surface. Prior work (Emelyanov et al., 1960s) discussed variable structure systems but lacked rigorous convergence criteria. Utkin proved that $\sigma \dot{\sigma} < 0$ guarantees $\sigma \to 0$ in finite time:
    \begin{equation}
    T_{\text{reach}} \leq \frac{|\sigma(0)|}{\eta}, \quad \text{where } \eta = \min_{\sigma \neq 0} |\dot{\sigma}|
    \end{equation}

    \item \textbf{Equivalent Control Method}: Introduced a systematic approach to analyze sliding mode dynamics by setting $\dot{\sigma} = 0$ and solving for $u_{\text{eq}}$:
    \begin{equation}
    u_{\text{eq}} = (\nabla \sigma \cdot \mat{B})^{-1} [-\nabla \sigma \cdot f(\vect{x})]
    \end{equation}
    This method reveals the "ideal" sliding mode behavior, separating the reaching phase from the sliding phase dynamics. Prior work treated VSS as purely discontinuous systems without this decomposition.

    \item \textbf{Invariance to Matched Disturbances}: Utkin proved that SMC is invariant to disturbances entering through the control channel (matched disturbances):
    \begin{equation}
    \dot{\vect{x}} = \vect{f}(\vect{x}) + \mat{B} [u + d(t, \vect{x})], \quad |d| \leq d_{\max}
    \end{equation}
    If $K > d_{\max}$, the sliding mode is unaffected by $d$. This robustness property was a major theoretical advancement, enabling SMC application to uncertain systems.
\end{enumerate}

\textbf{Difference from Prior Work}: Pre-1977 variable structure research (Emelyanov, Barbashin) focused on stability of switching systems but lacked:
\begin{itemize}
    \item Quantitative convergence rates (finite-time vs. asymptotic)
    \item Systematic design methods (equivalent control)
    \item Robustness guarantees (matched disturbance rejection)
\end{itemize}
Utkin's work transformed VSS from an empirical technique into a rigorous nonlinear control theory.

%===============================================================================
\section{Chapter 2 Solutions}
%===============================================================================

\textbf{Exercise 2.1}: Derive the kinetic energy $T_1$ for link 1 of the DIP from first principles, starting with the position vector $\vect{r}_1$. Verify that your result matches the expected form.

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Position of link 1 center of mass}:
    \begin{equation}
    \vect{r}_1 = \begin{bmatrix} x + \frac{L_1}{2} \sin\theta_1 \\ \frac{L_1}{2} \cos\theta_1 \end{bmatrix}
    \end{equation}

    \item \textbf{Velocity}:
    \begin{equation}
    \dot{\vect{r}}_1 = \begin{bmatrix} \dot{x} + \frac{L_1}{2} \cos\theta_1 \cdot \dot{\theta}_1 \\ -\frac{L_1}{2} \sin\theta_1 \cdot \dot{\theta}_1 \end{bmatrix}
    \end{equation}

    \item \textbf{Kinetic energy (translational + rotational)}:
    \begin{align}
    T_1 &= \frac{1}{2} m_1 |\dot{\vect{r}}_1|^2 + \frac{1}{2} I_1 \dot{\theta}_1^2 \\
    &= \frac{1}{2} m_1 \left[ \left(\dot{x} + \frac{L_1}{2} \cos\theta_1 \cdot \dot{\theta}_1\right)^2 + \left(-\frac{L_1}{2} \sin\theta_1 \cdot \dot{\theta}_1\right)^2 \right] + \frac{1}{2} I_1 \dot{\theta}_1^2 \\
    &= \frac{1}{2} m_1 \left[ \dot{x}^2 + L_1 \dot{x} \dot{\theta}_1 \cos\theta_1 + \frac{L_1^2}{4} \dot{\theta}_1^2 \right] + \frac{1}{2} I_1 \dot{\theta}_1^2
    \end{align}
    where $I_1 = \frac{1}{12} m_1 L_1^2$ (rod moment of inertia about COM).
\end{enumerate}

\vspace{1em}

\textbf{Exercise 2.2}: Prove that the inertia matrix $\mat{M}(\vect{q})$ is symmetric by showing $M_{12} = M_{21}$ and $M_{13} = M_{31}$ using explicit expressions.

\textbf{Solution}:

The inertia matrix for the DIP has the form:
\begin{equation}
\mat{M}(\vect{q}) = \begin{bmatrix}
M_{11} & M_{12}(\theta_1) & M_{13}(\theta_2) \\
M_{21}(\theta_1) & M_{22} & M_{23}(\theta_2 - \theta_1) \\
M_{31}(\theta_2) & M_{32}(\theta_2 - \theta_1) & M_{33}
\end{bmatrix}
\end{equation}

\textbf{Symmetry $M_{12} = M_{21}$}:

The $M_{12}$ term arises from coupling between cart velocity $\dot{x}$ and $\dot{\theta}_1$ in the kinetic energy:
\begin{equation}
T = \ldots + m_1 L_1 \dot{x} \dot{\theta}_1 \cos\theta_1 + m_2 L_1 \dot{x} \dot{\theta}_1 \cos\theta_1 + \ldots
\end{equation}

From Lagrangian mechanics, the inertia matrix is the Hessian of kinetic energy with respect to velocities:
\begin{equation}
M_{12} = \frac{\partial^2 T}{\partial \dot{x} \partial \dot{\theta}_1} = (m_1 + m_2) L_1 \cos\theta_1
\end{equation}

By symmetry of second derivatives:
\begin{equation}
M_{21} = \frac{\partial^2 T}{\partial \dot{\theta}_1 \partial \dot{x}} = (m_1 + m_2) L_1 \cos\theta_1 = M_{12} \quad \checkmark
\end{equation}

\textbf{Symmetry $M_{13} = M_{31}$}: Similarly:
\begin{equation}
M_{13} = \frac{\partial^2 T}{\partial \dot{x} \partial \dot{\theta}_2} = m_2 L_2 \cos\theta_2 = M_{31} \quad \checkmark
\end{equation}

The inertia matrix is symmetric for all Lagrangian systems (consequence of kinetic energy being a quadratic form in velocities).

\vspace{1em}

\textbf{Exercise 2.3}: Linearize the gravity vector $\vect{G}(\vect{q})$ around the upright equilibrium $\theta_1 = \theta_2 = 0$. Show that the linearized system has the form $\vect{G}_{\text{lin}} = -\mat{K}\vect{\theta}$ where $\mat{K}$ is a "negative stiffness" matrix.

\textbf{Solution}:

The gravity vector for DIP is:
\begin{equation}
\vect{G}(\vect{q}) = \begin{bmatrix} 0 \\ -(m_1 + m_2) g L_1 \sin\theta_1 \\ -m_2 g L_2 \sin\theta_2 \end{bmatrix}
\end{equation}

\textbf{Taylor expansion around $\theta_1 = \theta_2 = 0$}:

For small angles, $\sin\theta \approx \theta$:
\begin{equation}
\vect{G}_{\text{lin}} = \begin{bmatrix} 0 \\ -(m_1 + m_2) g L_1 \theta_1 \\ -m_2 g L_2 \theta_2 \end{bmatrix} = -\begin{bmatrix}
0 & 0 & 0 \\
0 & (m_1 + m_2) g L_1 & 0 \\
0 & 0 & m_2 g L_2
\end{bmatrix} \begin{bmatrix} x \\ \theta_1 \\ \theta_2 \end{bmatrix}
\end{equation}

The "stiffness" matrix is:
\begin{equation}
\mat{K} = \begin{bmatrix}
0 & 0 & 0 \\
0 & (m_1 + m_2) g L_1 & 0 \\
0 & 0 & m_2 g L_2
\end{bmatrix}
\end{equation}

\textbf{Interpretation}: This is a \textit{negative stiffness} matrix because gravitational torque pushes the pendulum \textit{away} from upright equilibrium (destabilizing spring with $k < 0$). For a stable spring, force opposes displacement ($F = -kx$); here, gravity amplifies displacement, making the upright position unstable.

\vspace{1em}

\textbf{Exercise 2.4}: Derive the Lagrangian for a single link pendulum and verify the equation of motion.

\textbf{Solution}: For a pendulum with mass $m$, length $L$, angle $\theta$:

Kinetic energy: $T = \frac{1}{2} m L^2 \dot{\theta}^2$

Potential energy: $U = m g L (1 - \cos\theta)$

Lagrangian: $\mathcal{L} = T - U = \frac{1}{2} m L^2 \dot{\theta}^2 - m g L (1 - \cos\theta)$

Euler-Lagrange equation:
\begin{equation}
\frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot{\theta}} - \frac{\partial \mathcal{L}}{\partial \theta} = 0
\end{equation}

Yields: $m L^2 \ddot{\theta} + m g L \sin\theta = 0$, or $\ddot{\theta} = -\frac{g}{L} \sin\theta$.

\vspace{1em}

\textbf{Exercise 2.5}: Linearize the DIP dynamics around the upright equilibrium to obtain $\dot{\vect{x}} = \mat{A}\vect{x} + \mat{B}u$. Compute the controllability matrix and verify that it has full rank (system is controllable).

\textbf{Solution}:

\textbf{Linearized Dynamics}: Around $(\theta_1, \theta_2, \dot{\theta}_1, \dot{\theta}_2, x, \dot{x}) = (0, 0, 0, 0, x_0, 0)$:
\begin{equation}
\mat{A} = \begin{bmatrix}
\mat{0}_{3 \times 3} & \mat{I}_{3 \times 3} \\
\mat{M}^{-1} \mat{K} & \mat{0}_{3 \times 3}
\end{bmatrix}, \quad \mat{B} = \begin{bmatrix} \mat{0}_{3 \times 1} \\ \mat{M}^{-1} \mat{B}_u \end{bmatrix}
\end{equation}

where $\mat{M} = \mat{M}(0, 0)$ (constant), $\mat{K}$ is the negative stiffness matrix from Exercise 2.3, and $\mat{B}_u = [1, 0, 0]^T$.

\textbf{Controllability Matrix}:
\begin{equation}
\mathcal{C} = \begin{bmatrix} \mat{B} & \mat{A}\mat{B} & \mat{A}^2\mat{B} & \cdots & \mat{A}^{5}\mat{B} \end{bmatrix} \in \Real^{6 \times 6}
\end{equation}

\textbf{Rank Test}: For the DIP, direct computation shows $\text{rank}(\mathcal{C}) = 6$ (full rank), proving the system is controllable. \textbf{Physical intuition}: The cart force can accelerate the cart directly, which couples to both pendulum angles through inertia matrix terms, allowing indirect control of all 3 DOF.

\vspace{1em}

\textbf{Exercise 2.6}: Consider the system $\dot{x} = -x + u + d$ where $|d| \leq d_{\max} = 2$. Design a sliding mode control law $u = -K \sign(\sigma)$ where $\sigma = x$ such that $x \to 0$. What is the minimum value of $K$ required?

\textbf{Solution}:

\textbf{System Dynamics with Control}:
\begin{equation}
\dot{x} = -x - K \sign(x) + d
\end{equation}

\textbf{Lyapunov Function}: $V = \frac{1}{2} x^2$

\textbf{Lyapunov Derivative}:
\begin{align}
\dot{V} &= x \dot{x} = x(-x - K \sign(x) + d) \\
&= -x^2 - K |x| + x d \\
&\leq -x^2 - K |x| + |x| |d| \\
&= -x^2 + |x| (|d| - K)
\end{align}

\textbf{Reaching Condition}: For $\dot{V} < 0$ when $x \neq 0$, we need:
\begin{equation}
K > |d| \leq d_{\max} = 2
\end{equation}

\textbf{Minimum Gain}: $K_{\min} = 2 + \epsilon$ where $\epsilon > 0$ is a small stability margin (e.g., $\epsilon = 0.1 \Rightarrow K_{\min} = 2.1$).

\textbf{Physical Interpretation}: The switching gain must dominate the worst-case disturbance to ensure the control can always drive $x$ toward zero.

\vspace{1em}

\textbf{Exercise 2.7}: Analyze the stability of the Euler method for the test equation $\dot{x} = \lambda x$ with $\lambda < 0$. Derive the maximum timestep $h_{\max}$ such that the numerical solution remains bounded.

\textbf{Solution}:

\textbf{Euler Method}:
\begin{equation}
x_{n+1} = x_n + h f(x_n) = x_n + h \lambda x_n = (1 + h\lambda) x_n
\end{equation}

\textbf{Recursive Solution}:
\begin{equation}
x_n = (1 + h\lambda)^n x_0
\end{equation}

\textbf{Stability Condition}: For $|x_n| \to 0$ as $n \to \infty$ (stable numerical solution), we need:
\begin{equation}
|1 + h\lambda| < 1
\end{equation}

Since $\lambda < 0$, let $\lambda = -\alpha$ where $\alpha > 0$:
\begin{equation}
|1 - h\alpha| < 1 \quad \Rightarrow \quad -1 < 1 - h\alpha < 1
\end{equation}

The right inequality is always satisfied. The left inequality gives:
\begin{equation}
-1 < 1 - h\alpha \quad \Rightarrow \quad h\alpha < 2 \quad \Rightarrow \quad h < \frac{2}{|\lambda|}
\end{equation}

\textbf{Maximum Timestep}:
\begin{equation}
h_{\max} = \frac{2}{|\lambda|}
\end{equation}

\textbf{Example}: For $\lambda = -10$, $h_{\max} = 0.2$ s. Using $h = 0.3$ s would cause numerical oscillations (instability).

\vspace{1em}

\textbf{Exercise 2.8}: Run RK4 with $h$, $h/2$, and $h/4$ on a test problem with known analytical solution. Compute the global error at $t = 5$ for each case and verify that the error ratio is approximately $2^4 = 16$.

\textbf{Solution}:

\textbf{Test Problem}: $\dot{x} = -x$, $x(0) = 1$. Analytical solution: $x(t) = e^{-t}$.

\textbf{RK4 Implementation}: Fourth-order Runge-Kutta:
\begin{align}
k_1 &= f(t_n, x_n) \\
k_2 &= f(t_n + h/2, x_n + h k_1/2) \\
k_3 &= f(t_n + h/2, x_n + h k_2/2) \\
k_4 &= f(t_n + h, x_n + h k_3) \\
x_{n+1} &= x_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{align}

\textbf{Numerical Experiment} ($t = 5$, $x_{\text{exact}}(5) = e^{-5} \approx 0.00674$):

\begin{table}[htbp]
\centering
\begin{tabular}{cccc}
\toprule
Timestep & $x_{\text{RK4}}(5)$ & Error & Error Ratio \\
\midrule
$h = 0.1$ & 0.006738 & $1.7 \times 10^{-6}$ & --- \\
$h/2 = 0.05$ & 0.006738 & $1.1 \times 10^{-7}$ & 15.5 \\
$h/4 = 0.025$ & 0.006738 & $6.8 \times 10^{-9}$ & 16.2 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Verification}: Error ratio $\approx 16 = 2^4$, confirming RK4 has fourth-order convergence (error $\sim h^4$). Halving timestep reduces error by factor of 16.

%===============================================================================
\section{Chapter 3 Solutions}
%===============================================================================

\textbf{Exercise 3.1}: Design a linear sliding surface for the DIP system ensuring $\theta_1, \theta_2 \to 0$ exponentially when in sliding mode.

\textbf{Solution}: Unified sliding surface combining both pendulum angles:
\begin{equation}
\sigma = k_1 \theta_1 + k_2 \dot{\theta}_1 + k_3 \theta_2 + k_4 \dot{\theta}_2
\end{equation}

On sliding surface ($\sigma = 0, \dot{\sigma} = 0$), the reduced-order dynamics are:
\begin{equation}
\begin{bmatrix} \dot{\theta}_1 \\ \dot{\theta}_2 \end{bmatrix} = -\begin{bmatrix} k_1/k_2 & 0 \\ 0 & k_3/k_4 \end{bmatrix} \begin{bmatrix} \theta_1 \\ \theta_2 \end{bmatrix}
\end{equation}

For exponential stability, choose $k_1/k_2 > 0$ and $k_3/k_4 > 0$. Typical values: $k_1 = k_3 = 5$ rad$^{-1}$, $k_2 = k_4 = 1$ s.

\vspace{1em}

\textbf{Exercise 3.2}: For classical SMC $u = -K \sign(\sigma)$, derive the reaching time to the sliding surface from initial condition $\sigma(0) = \sigma_0$.

\textbf{Solution}: Reaching dynamics: $\dot{\sigma} = -K \sign(\sigma)$ for $\sigma \neq 0$.

For $\sigma > 0$: $\dot{\sigma} = -K < 0$, so $\sigma(t) = \sigma_0 - Kt$ until $\sigma = 0$ at $t_r = \sigma_0/K$.

\textbf{Reaching time}:
\begin{equation}
t_r = \frac{|\sigma_0|}{K}
\end{equation}

Example: If $\sigma_0 = 0.5$ and $K = 10$, then $t_r = 0.05$ s (50 ms).

\vspace{1em}

\textbf{Exercise 3.3}: Compare boundary layer methods: tanh vs. saturation. Which provides smoother control?

\textbf{Solution}:

\textbf{Saturation (linear)}:
\begin{equation}
\sat(\sigma/\epsilon) = \begin{cases} \sigma/\epsilon & |\sigma| \leq \epsilon \\ \sign(\sigma) & |\sigma| > \epsilon \end{cases}
\end{equation}
Derivative: $\frac{d}{d\sigma}\sat(\sigma/\epsilon)$ has \textit{jump discontinuity} at $|\sigma| = \epsilon$.

\textbf{Tanh (smooth)}:
\begin{equation}
\tanh(\sigma/\epsilon) = \frac{e^{\sigma/\epsilon} - e^{-\sigma/\epsilon}}{e^{\sigma/\epsilon} + e^{-\sigma/\epsilon}}
\end{equation}
Derivative: $\frac{d}{d\sigma}\tanh(\sigma/\epsilon) = \frac{1}{\epsilon} \sech^2(\sigma/\epsilon)$ is \textit{continuous everywhere}.

\textbf{Comparison}: Tanh provides smoother control (continuously differentiable), reducing high-frequency content and actuator jerk. Preferred for systems sensitive to control derivatives.

\vspace{1em}

\textbf{Exercise 3.4}: Compute equivalent control $u_{\text{eq}}$ for DIP assuming perfect model knowledge.

\textbf{Solution}: From $\dot{\sigma} = 0$:
\begin{equation}
\dot{\sigma} = \nabla \sigma \cdot \dot{\vect{x}} = \nabla \sigma \cdot [\mat{M}^{-1}(\mat{B}u - \vect{C}\dot{\vect{q}} - \vect{G})] = 0
\end{equation}

Solving for $u$:
\begin{equation}
u_{\text{eq}} = (\nabla \sigma \cdot \mat{M}^{-1} \mat{B})^{-1} [\nabla \sigma \cdot \mat{M}^{-1} (\vect{C}\dot{\vect{q}} + \vect{G})]
\end{equation}

For DIP with $\sigma = k_1\theta_1 + k_2\dot{\theta}_1 + k_3\theta_2 + k_4\dot{\theta}_2$, this involves inverting inertia matrix and computing Coriolis/gravity terms.

\vspace{1em}

\textbf{Exercise 3.5}: Prove that the sliding surface $s = k_1 \dot{\theta}_1 + \lambda_1 \theta_1$ is exponentially stable if $k_1, \lambda_1 > 0$.

\textbf{Solution}: On the sliding surface ($s = 0$):
\begin{equation}
\dot{\theta}_1 = -\frac{\lambda_1}{k_1} \theta_1
\end{equation}

This is a first-order ODE with solution $\theta_1(t) = \theta_1(0) e^{-(\lambda_1/k_1) t}$.

Since $\lambda_1/k_1 > 0$, we have exponential decay: $|\theta_1(t)| \leq |\theta_1(0)| e^{-\alpha t}$ with $\alpha = \lambda_1/k_1 > 0$.

\vspace{1em}

\textbf{Exercise 3.6}: Analyze chattering amplitude vs. boundary layer thickness $\epsilon$ relationship.

\textbf{Solution}: Inside boundary layer $|\sigma| \leq \epsilon$, control is $u \approx -K \sigma/\epsilon$ (linear).

\textbf{Steady-state sliding surface error}:
\begin{equation}
\sigma_{\text{ss}} \sim \epsilon \cdot \frac{d_{\max}}{K}
\end{equation}
where $d_{\max}$ is disturbance bound.

\textbf{Tracking error}: For $\sigma = k\theta + \dot{\theta}$:
\begin{equation}
|\theta_{\text{ss}}| \leq \frac{\epsilon d_{\max}}{Kk}
\end{equation}

\textbf{Trade-off}: Doubling $\epsilon$ doubles tracking error but halves chattering frequency. Optimal $\epsilon = 0.01$-$0.1$ rad balances accuracy and smoothness.

\vspace{1em}

\textbf{Exercise 3.7}: Design SMC for cart position regulation: keep $x_{\text{cart}} \approx 0$ while stabilizing pendula.

\textbf{Solution}: Modified sliding surface including cart recentering:
\begin{equation}
\sigma = k_x x + k_{\dot{x}} \dot{x} + k_1 \theta_1 + k_2 \dot{\theta}_1 + k_3 \theta_2 + k_4 \dot{\theta}_2
\end{equation}

Control law:
\begin{equation}
u = u_{\text{eq}} - K \sat(\sigma/\epsilon) - k_d \sigma
\end{equation}

Typical gains: $k_x = 2$ m$^{-1}$, $k_{\dot{x}} = 1$ s, ensuring cart returns to origin without compromising pendulum stabilization.

\vspace{1em}

\textbf{Exercise 3.8}: Prove that classical SMC is robust to matched disturbances $|d| \leq d_{\max}$ if $K > d_{\max}$.

\textbf{Solution}: System with matched disturbance:
\begin{equation}
\dot{\sigma} = -K \sign(\sigma) + d(t), \quad |d| \leq d_{\max}
\end{equation}

Lyapunov function: $V = \frac{1}{2}\sigma^2$

Derivative:
\begin{align}
\dot{V} &= \sigma \dot{\sigma} = \sigma(-K \sign(\sigma) + d) \\
&= -K|\sigma| + \sigma d \\
&\leq -K|\sigma| + |d||\sigma| \\
&= |\sigma|(|d| - K)
\end{align}

If $K > d_{\max} \geq |d|$, then $\dot{V} < 0$ for $\sigma \neq 0$, ensuring finite-time convergence to $\sigma = 0$ regardless of disturbance. This is the \textit{invariance property} of SMC.

%===============================================================================
\section{Chapter 4 Solutions}
%===============================================================================

\textbf{Exercise 4.1}: Derive the STA stability condition $k_1^2 \geq 4L_m k_2 (k_2 + L_m)/(k_2 - L_m)$ where $L_m$ is the Lipschitz constant.

\textbf{Solution}: For system $\dot{s} = -K_1\sqrt{|s|}\sign(s) + z + \phi(t,x)$ where $|\phi| \leq L_m$ and $|\dot{\phi}| \leq L_M$, finite-time stability requires:

\textbf{Gain condition 1}:
\begin{equation}
k_2 > L_M
\end{equation}

\textbf{Gain condition 2} (derived via Lyapunov analysis):
\begin{equation}
k_1^2 \geq \frac{4L_M k_2 (k_2 + L_M)}{k_2 - L_M}
\end{equation}

For DIP with $L_M \approx 15$, choosing $k_2 = 20$ and $k_1 = 12$ satisfies both conditions.

\vspace{1em}

\textbf{Exercise 4.2}: Verify that the super-twisting control $u = -K_1 \sqrt{|s|} \sign(s) + z$ is continuous even though $\dot{z} = -K_2 \sign(s)$ is discontinuous.

\textbf{Solution}: The discontinuity in $\dot{z}$ is integrated to produce $z(t)$:
\begin{equation}
z(t) = z(0) - K_2 \int_0^t \sign(s(\tau)) d\tau
\end{equation}

Since integration smooths discontinuities, $z(t)$ is continuous (piecewise linear). The term $-K_1 \sqrt{|s|} \sign(s)$ is also continuous everywhere except at $s = 0$, where it equals zero. Therefore, $u(t) = -K_1 \sqrt{|s|} \sign(s) + z(t)$ is continuous.

\vspace{1em}

\textbf{Exercise 4.3}: Estimate the finite-time convergence time for STA with $k_1 = 10$, $k_2 = 15$, $|s(0)| = 0.2$.

\textbf{Solution}: Finite-time convergence bound:
\begin{equation}
T_{\text{conv}} \leq \frac{2|s(0)|^{1/2}}{k_1 - \sqrt{2L_M}} + \frac{2\sqrt{2L_M}}{k_2 - L_M}
\end{equation}

For $L_M = 10$ (typical for DIP), $s(0) = 0.2$:
\begin{align}
T_{\text{conv}} &\leq \frac{2(0.2)^{1/2}}{10 - \sqrt{20}} + \frac{2\sqrt{20}}{15 - 10} \\
&\leq \frac{0.894}{5.53} + \frac{8.94}{5} \approx 0.16 + 1.79 \approx 1.95 \text{ s}
\end{align}

\vspace{1em}

\textbf{Exercise 4.4}: Compare chattering frequency: classical SMC ($K=10$, 1 kHz sampling) vs. STA ($k_1=10$, $k_2=15$).

\textbf{Solution}:

\textbf{Classical SMC}: Switching function $\sign(s)$ causes chattering at half the sampling rate:
\begin{equation}
f_{\text{chatter, classical}} \approx \frac{f_{\text{sample}}}{2} = 500 \text{ Hz}
\end{equation}

\textbf{STA}: Discontinuity in $\dot{z}$ is hidden by integration. Control $u$ varies continuously, so no high-frequency switching. Effective chattering frequency:
\begin{equation}
f_{\text{chatter, STA}} \approx 0 \text{ Hz (continuous control)}
\end{equation}

\textbf{Advantage}: STA eliminates chattering entirely while maintaining finite-time convergence.

\vspace{1em}

\textbf{Exercise 4.5}: Implement STA with integral term anti-windup to prevent saturation during large disturbances.

\textbf{Solution}: Modified STA with windup protection:
\begin{equation}
\dot{z} = \begin{cases}
-k_2 \sat(s/\epsilon) & \text{if } |u_{\text{total}}| \leq u_{\max} \\
0 & \text{if } |u_{\text{total}}| > u_{\max}
\end{cases}
\end{equation}

where $u_{\text{total}} = -k_1\sqrt{|s|}\sign(s) + z + u_{\text{eq}}$.

\textbf{Mechanism}: Integral term $z$ freezes when control saturates ($|u| > u_{\max}$), preventing unbounded accumulation.

\vspace{1em}

\textbf{Exercise 4.6}: Derive the relationship between STA gains $(k_1, k_2)$ and convergence rate.

\textbf{Solution}: Convergence rate (eigenvalue of linearized system near $s=0$) scales with:
\begin{equation}
\text{Convergence rate} \propto \min(k_1^2, k_2)
\end{equation}

\textbf{Trade-off}:
- Larger $k_1, k_2$: Faster convergence but higher control effort and sensitivity to noise
- Smaller $k_1, k_2$: Slower convergence but smoother control

\textbf{Balanced tuning}: Choose $k_1 \approx k_2/1.5$ to balance both effects.

\vspace{1em}

\textbf{Exercise 4.7}: Compare STA robustness to unmatched disturbances vs. matched disturbances.

\textbf{Solution}:

\textbf{Matched disturbances} ($d$ enters through control channel):
\begin{equation}
\dot{s} = -k_1\sqrt{|s|}\sign(s) + z + d(t)
\end{equation}
STA is robust if $|d| \leq L_M$ and $|\dot{d}| \leq L_M$ (Lipschitz condition). Disturbance is \textit{completely rejected} in sliding mode.

\textbf{Unmatched disturbances} ($d$ enters elsewhere):
\begin{equation}
\dot{s} = -k_1\sqrt{|s|}\sign(s) + z + \phi(x, d_{\text{unmatched}})
\end{equation}
STA provides \textit{partial rejection} only. Residual tracking error $\propto \|d_{\text{unmatched}}\|$.

\textbf{Conclusion}: STA (like all SMC) is most effective against matched disturbances.

\vspace{1em}

\textbf{Exercise 4.8}: Design a gain-scheduled STA where $(k_1, k_2)$ adapt based on $|s|$ to improve transient response.

\textbf{Solution}: Gain scheduling function:
\begin{equation}
k_1(s) = k_{1,\text{nom}} + k_{1,\text{boost}} \cdot e^{-|s|/\epsilon}, \quad k_2(s) = k_{2,\text{nom}} + k_{2,\text{boost}} \cdot e^{-|s|/\epsilon}
\end{equation}

\textbf{Behavior}:
- Far from surface ($|s|$ large): High gains $(k_{1,\text{boost}})$ for fast reaching
- Near surface ($|s|$ small): Nominal gains for smooth convergence

\textbf{Example}: $k_{1,\text{nom}} = 8$, $k_{1,\text{boost}} = 5$, $k_{2,\text{nom}} = 12$, $k_{2,\text{boost}} = 8$, $\epsilon = 0.1$ rad.

%===============================================================================
\section{Chapter 5 Solutions}
%===============================================================================

\textbf{Exercise 5.1}: Explain why adaptive gain tuning is necessary when model uncertainty is large. What happens if $K$ is (a) too small, (b) too large, and (c) how does online adaptation resolve this trade-off?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{K too small (underestimated)}: The switching gain $K$ must satisfy $K > \|d\|_{\max} + \eta$ where $d$ is the matched uncertainty/disturbance and $\eta > 0$ is a stability margin. If $K < \|d\|$, the control $u = -K \sign(s)$ cannot dominate the disturbance, violating the reaching condition $s\dot{s} < 0$. The system fails to reach the sliding surface, resulting in:
    \begin{itemize}
        \item Loss of tracking: $|\theta - \theta_{\text{ref}}| > \epsilon_{\max}$ (unacceptable error)
        \item Potential instability: pendulum angles diverge
    \end{itemize}

    \item \textbf{K too large (overestimated)}: If $K \gg \|d\|_{\max}$, the control provides excessive authority, causing:
    \begin{itemize}
        \item Severe chattering: high-frequency oscillations in $u(t)$ due to discontinuous $\sign(s)$
        \item Wear on actuators: repeated direction reversals damage motors
        \item Energy waste: $\int |u(t)| dt$ is unnecessarily large
    \end{itemize}
    Example: If $\|d\|_{\max} = 5$ N but $K = 50$ N, the controller uses 10x more control effort than needed.

    \item \textbf{Online adaptation resolution}: Adaptive SMC dynamically adjusts $\hat{K}(t)$ based on observed sliding surface magnitude:
    \begin{equation}
    \dot{\hat{K}} = \gamma |s| - \alpha \hat{K}
    \end{equation}
    \textbf{Trade-off resolution}:
    \begin{itemize}
        \item When $|s|$ is large (disturbance not rejected), $\dot{\hat{K}} > 0$ increases gain
        \item When $|s|$ is small (disturbance rejected), leak term $-\alpha \hat{K}$ reduces gain
        \item Converges to optimal $\hat{K}^* \approx \|d\|_{\max} + \eta$ balancing tracking and chattering
    \end{itemize}
\end{enumerate}

\vspace{1em}

\textbf{Exercise 5.2}: Derive the gradient adaptation law for the adaptive gain $K$ from the Lyapunov function $V = \frac{1}{2} s^2 + \frac{1}{2\gamma} \tilde{K}^2$.

\textbf{Solution}: Taking the time derivative:
\begin{equation}
\dot{V} = s \dot{s} + \frac{1}{\gamma} \tilde{K} \dot{\tilde{K}}
\end{equation}

For sliding dynamics $\dot{s} = -K |s| + d(t)$ where $d(t)$ is bounded disturbance, we have:
\begin{equation}
\dot{V} = s(-K |s| + d) + \frac{1}{\gamma} \tilde{K} \dot{\tilde{K}}
\end{equation}

To ensure $\dot{V} < 0$, choose $\dot{\tilde{K}} = \gamma |s| \sign(s)$. Since $\tilde{K} = K - K^*$ where $K^*$ is constant, we get:
\begin{equation}
\dot{K} = \gamma |s| \sign(s)
\end{equation}

This is the gradient adaptation law that minimizes the Lyapunov function.

\vspace{1em}

\textbf{Exercise 5.3}: The leak term $-\alpha K$ in the adaptation law serves multiple purposes. (a) Explain why it prevents unbounded gain growth. (b) How does it help with time-varying disturbances? (c) What is the trade-off of increasing $\alpha$?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Prevents unbounded gain growth}:

    Consider the piecewise adaptation law without leak:
    \begin{equation}
    \dot{\hat{K}} = \begin{cases}
    \gamma |\sigma| & \text{if } |\sigma| \geq \delta \\
    0 & \text{if } |\sigma| < \delta
    \end{cases}
    \end{equation}

    Problem: If $|\sigma| \geq \delta$ persists (e.g., due to unmodeled dynamics), $\hat{K}(t)$ monotonically increases without bound:
    \begin{equation}
    \hat{K}(t) = \hat{K}(0) + \gamma \int_0^t |\sigma(\tau)| d\tau \to \infty
    \end{equation}

    This causes:
    \begin{itemize}
        \item Actuator saturation: $|u| > u_{\max}$ (physical limit violated)
        \item Numerical overflow in simulation ($\hat{K} > 10^{10}$)
        \item Excessive control effort even after disturbance is rejected
    \end{itemize}

    The leak term $-\alpha \hat{K}$ provides negative feedback:
    \begin{equation}
    \dot{\hat{K}} = \gamma |\sigma| - \alpha \hat{K}
    \end{equation}

    At equilibrium ($\dot{\hat{K}} = 0$):
    \begin{equation}
    \hat{K}^* = \frac{\gamma |\sigma_{\text{ss}}|}{\alpha}
    \end{equation}

    Since $|\sigma_{\text{ss}}|$ is bounded by Lyapunov stability, $\hat{K}^*$ is bounded. Typical values: $\alpha = 0.1$ s$^{-1}$, resulting in $\hat{K}^* < 50$ N for DIP.

    \item \textbf{Helps with time-varying disturbances}:

    Time-varying disturbances $d(t) = A(t) \sin(\omega t)$ with decreasing amplitude $A(t) = A_0 e^{-\beta t}$ require adaptive gain tracking.

    Without leak ($\alpha = 0$): $\hat{K}$ ratchets upward during initial high-amplitude phase but cannot decrease when $A(t)$ reduces. Result: overestimated gain causes unnecessary chattering.

    With leak ($\alpha > 0$): The term $-\alpha \hat{K}$ allows $\hat{K}$ to decay when $|\sigma|$ decreases:
    \begin{itemize}
        \item During high-disturbance phase ($t < 5$ s): $\gamma |\sigma| \gg \alpha \hat{K}$ → gain increases
        \item During low-disturbance phase ($t > 5$ s): $\gamma |\sigma| \ll \alpha \hat{K}$ → leak dominates → gain decreases
    \end{itemize}

    This bidirectional adaptation matches gain to current disturbance level, improving control effort economy.

    \item \textbf{Trade-off of increasing $\alpha$}:

    \textbf{Benefits} (larger $\alpha$):
    \begin{itemize}
        \item Faster forgetting: $\hat{K}$ decays quickly when disturbance disappears
        \item Tighter gain bounds: $\hat{K}^* = \frac{\gamma |\sigma|}{\alpha}$ is smaller
        \item Reduced overshoot: prevents gain from accumulating during transients
    \end{itemize}

    \textbf{Drawbacks} (larger $\alpha$):
    \begin{itemize}
        \item Slower adaptation: leak opposes gain increase, delaying convergence
        \item Steady-state error: if $\alpha$ too large, $\hat{K}^*$ may undershoot required gain
        \item Poor disturbance rejection: gain cannot rise sufficiently during high-disturbance events
    \end{itemize}

    Optimal $\alpha$ selection: Use $\alpha = 0.1 \tau_{\text{dist}}^{-1}$ where $\tau_{\text{dist}}$ is disturbance time constant. For DIP with $\tau_{\text{dist}} \approx 10$ s, use $\alpha \approx 0.01$ s$^{-1}$.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 5.4}: Design an adaptive law with saturation to prevent gain from exceeding actuator limits.

\textbf{Solution}: Modified adaptation law with gain saturation:
\begin{equation}
\dot{\hat{K}} = \begin{cases}
\gamma |\sigma| - \alpha \hat{K} & \text{if } \hat{K}_{\min} < \hat{K} < \hat{K}_{\max} \\
\max(0, \gamma |\sigma| - \alpha \hat{K}) & \text{if } \hat{K} = \hat{K}_{\min} \\
\min(0, \gamma |\sigma| - \alpha \hat{K}) & \text{if } \hat{K} = \hat{K}_{\max}
\end{cases}
\end{equation}

\textbf{Bounds}: For DIP with actuator limit $|u_{\max}| = 50$ N, choose $\hat{K}_{\min} = 1$ N, $\hat{K}_{\max} = 40$ N to prevent saturation while allowing adaptation range.

\vspace{1em}

\textbf{Exercise 5.5}: Compare adaptation rates: fast ($\gamma = 10$) vs. slow ($\gamma = 1$). Which provides better transient response?

\textbf{Solution}:

\textbf{Fast adaptation} ($\gamma = 10$):
- \textbf{Pros}: Rapid gain increase during disturbance onset, shorter reaching time
- \textbf{Cons}: Sensitive to noise, potential overshoot, gain oscillations

\textbf{Slow adaptation} ($\gamma = 1$):
- \textbf{Pros}: Smooth gain evolution, robust to noise
- \textbf{Cons}: Delayed response to sudden disturbances, longer convergence

\textbf{Optimal strategy}: Use gain scheduling: $\gamma(|\sigma|) = \gamma_{\text{fast}} \cdot e^{-t/\tau} + \gamma_{\text{slow}}$ where $\tau = 2$ s. Start fast, taper to slow.

\vspace{1em}

\textbf{Exercise 5.6}: Explain why a dead-zone $\delta = 0.01$ rad prevents chattering-induced adaptation.

\textbf{Solution}: Chattering causes rapid oscillations of the sliding surface around zero ($|s| < \delta$). Without a dead-zone, the adaptation law $\dot{K} = \gamma |s| \sign(s)$ would continuously update gains in response to these high-frequency oscillations, causing:
\begin{itemize}
    \item Unnecessary gain variation
    \item Amplification of sensor noise
    \item Instability in the adaptive mechanism
\end{itemize}

The dead-zone freezes adaptation when $|s| < \delta$:
\begin{equation}
\dot{K} = \begin{cases}
\gamma (|s| - \delta)_+ \sign(s) & \text{if } |s| \geq \delta \\
0 & \text{if } |s| < \delta
\end{cases}
\end{equation}

This ensures adaptation only occurs when the system is genuinely far from the sliding surface, not during normal chattering behavior.

\vspace{1em}

\textbf{Exercise 5.7}: Derive the steady-state adapted gain $\hat{K}^*$ for constant disturbance $d = 5$ N.

\textbf{Solution}: At equilibrium, $\dot{\hat{K}} = 0$:
\begin{equation}
\gamma |\sigma_{\text{ss}}| - \alpha \hat{K}^* = 0 \quad \Rightarrow \quad \hat{K}^* = \frac{\gamma |\sigma_{\text{ss}}|}{\alpha}
\end{equation}

For classical SMC with $\dot{\sigma} = -\hat{K} \sign(\sigma) + d$, steady-state requires $\hat{K}^* \geq d = 5$ N. With $\alpha = 0.1$ s$^{-1}$, $\gamma = 5$, and typical $|\sigma_{\text{ss}}| = 0.1$ rad:
\begin{equation}
\hat{K}^* = \frac{5 \times 0.1}{0.1} = 5 \text{ N}
\end{equation}

This exactly matches the disturbance magnitude, confirming optimal adaptation.

\vspace{1em}

\textbf{Exercise 5.8}: Implement dead-zone with hysteresis to prevent rapid switching at boundary.

\textbf{Solution}: Hysteresis dead-zone:
\begin{equation}
\dot{\hat{K}} = \begin{cases}
\gamma |\sigma| - \alpha \hat{K} & \text{if } |\sigma| > \delta_{\text{upper}} \\
-\alpha \hat{K} & \text{if } |\sigma| < \delta_{\text{lower}} \\
\text{maintain} & \text{if } \delta_{\text{lower}} \leq |\sigma| \leq \delta_{\text{upper}}
\end{cases}
\end{equation}

Typical values: $\delta_{\text{lower}} = 0.008$ rad, $\delta_{\text{upper}} = 0.012$ rad. The hysteresis band $[\delta_{\text{lower}}, \delta_{\text{upper}}]$ prevents chattering of the adaptation mechanism itself.

%===============================================================================
\section{Chapter 6 Solutions}
%===============================================================================

\textbf{Exercise 6.1}: Why combine adaptive gain tuning with super-twisting? What unique advantages does the hybrid approach provide over using each technique separately?

\textbf{Solution}:

The hybrid adaptive STA-SMC combines two powerful techniques to address complementary limitations:

\textbf{Classical SMC + Adaptation (Chapter 5) Limitations:}
\begin{itemize}
    \item \textbf{Chattering persists}: Adaptive gain $\hat{K}(t)$ still switches discontinuously via $\sign(\sigma)$, causing 2-3 N/s control rate oscillations even with optimal $\hat{K}$
    \item \textbf{Slow convergence}: First-order sliding mode $\dot{\sigma} = -K \sign(\sigma)$ converges asymptotically, not finite-time
    \item \textbf{Measurement noise sensitivity}: Direct $\sign(\sigma)$ switching amplifies sensor noise
\end{itemize}

\textbf{Fixed-Gain STA-SMC (Chapter 4) Limitations:}
\begin{itemize}
    \item \textbf{Conservative tuning}: Gains $(k_1, k_2)$ must satisfy worst-case stability conditions $k_2 > L_m$ and $k_1^2 \geq 4 L_m k_2 (k_2 + L_m) / (k_2 - L_m)$ where $L_m$ is Lipschitz bound. For uncertain $L_m$, conservative overestimation wastes control effort.
    \item \textbf{Poor disturbance adaptation}: Fixed $k_1, k_2$ cannot respond to time-varying disturbances $d(t) = A(t) \sin(\omega t)$ with varying amplitude $A(t)$
    \item \textbf{Initialization sensitivity}: Performance degrades if initial $(k_1^0, k_2^0)$ are poorly chosen
\end{itemize}

\textbf{Hybrid Advantages (Synergistic Combination):}

\begin{enumerate}
    \item \textbf{Continuous control + Adaptive robustness}:
    \begin{itemize}
        \item STA provides continuous $u = -k_1 \sqrt{|\sigma|} \sign(\sigma) + u_1$ (no discontinuous switching)
        \item Adaptation adjusts $(k_1, k_2)$ online: $\dot{k}_1 = \gamma_1 \sqrt{|\sigma|}$, $\dot{k}_2 = \gamma_2 |\sigma|$
        \item Result: Chattering amplitude reduced to 1.0 N/s (vs. 2.5 N/s classical SMC, 56\% reduction) while maintaining disturbance rejection
    \end{itemize}

    \item \textbf{Finite-time convergence + Time-varying robustness}:
    \begin{itemize}
        \item STA achieves finite-time convergence to $\sigma = 0$ in $T_{\text{reach}} = O(\sigma_0^{1/2})$ (vs. asymptotic for classical SMC)
        \item Adaptation tracks changing $L_m(t)$ due to model uncertainty or disturbances
        \item Settling time: 1.58 s (hybrid) vs. 1.82 s (classical SMC), 13\% faster
    \end{itemize}

    \item \textbf{Optimal gain convergence + Stability preservation}:
    \begin{itemize}
        \item Adaptation drives $(k_1, k_2) \to (k_1^*, k_2^*)$ that minimize control effort while satisfying stability conditions
        \item Projection operators ensure $k_1^2 \geq 4 L_m k_2 (k_2 + L_m) / (k_2 - L_m)$ at all times
        \item Energy consumption: 0.9 J (hybrid) vs. 1.2 J (classical SMC), 25\% reduction
    \end{itemize}

    \item \textbf{Reduced tuning burden}:
    \begin{itemize}
        \item Fixed STA requires careful offline gain selection via PSO (1500 evaluations $\times$ 10 s = 4.2 hours)
        \item Hybrid STA adapts online from conservative initial $(k_1^0, k_2^0)$, converging to optimal in $< 2$ s
        \item Trade-off: Increased implementation complexity (dual adaptation laws + projection)
    \end{itemize}
\end{enumerate}

\textbf{Summary}: The hybrid approach achieves:
\begin{itemize}
    \item \textbf{Best of both worlds}: Continuous control (STA) + online robustness (adaptation)
    \item \textbf{Performance gains}: 13\% faster settling, 25\% energy reduction, 56\% chattering reduction
    \item \textbf{Practical benefits}: Reduced tuning time, improved disturbance rejection, actuator-friendly operation
\end{itemize}

\vspace{1em}

\textbf{Exercise 6.3}: For the hybrid controller with dual-gain adaptation, verify that both $K_1$ and $K_2$ must satisfy the STA stability conditions at all times.

\textbf{Solution}: The STA stability conditions (Moreno-Osorio) require:
\begin{align}
K_2 &> L_m \quad \text{(disturbance Lipschitz bound)} \\
K_1^2 &\geq \frac{4 L_m K_2 (K_2 + L_m)}{K_2 - L_m}
\end{align}

For the hybrid controller, both gains evolve:
\begin{align}
\dot{K}_1(t) &= \gamma_1 \sqrt{|s|} (|s| - \delta)_+ \sign(s) - \alpha_1 K_1 \\
\dot{K}_2(t) &= \gamma_2 (|s| - \delta)_+ \sign(s) - \alpha_2 K_2
\end{align}

At initialization, we must choose $K_1(0), K_2(0)$ satisfying the stability conditions. The leak rates $\alpha_1, \alpha_2$ ensure gains remain bounded. However, during transients, the adaptive gains may temporarily violate the coupling condition $K_1^2 \geq \frac{4 L_m K_2 (K_2 + L_m)}{K_2 - L_m}$, which can cause loss of finite-time convergence. To prevent this, we add a projection operator:
\begin{equation}
K_1(t) \gets \max\left( K_1(t), \sqrt{\frac{4 L_m K_2(t) (K_2(t) + L_m)}{K_2(t) - L_m}} \right)
\end{equation}

This ensures the stability conditions are maintained throughout adaptation.

\vspace{1em}

\textbf{Exercise 6.5}: Derive the state-dependent lambda scheduling function and explain its effect on sliding surface dynamics.

\textbf{Solution}: The scheduled lambda is:
\begin{equation}
\lambda_i(t) = \lambda_i^0 \cdot f(\|\vect{\theta}\|) = \lambda_i^0 \cdot \left(1 + \beta \exp\left( -\frac{\|\vect{\theta}\|^2}{2\sigma^2} \right)\right)
\end{equation}

Effect on sliding surface:
\begin{itemize}
    \item \textbf{Near equilibrium} ($\|\vect{\theta}\| \approx 0$): $f \approx 1 + \beta$, so $\lambda_i \approx (1 + \beta) \lambda_i^0$. Larger lambda increases convergence speed: $\dot{\theta}_i = -\frac{\lambda_i}{k_i} \theta_i$ has faster decay.
    \item \textbf{Far from equilibrium} ($\|\vect{\theta}\| \gg \sigma$): $f \approx 1$, so $\lambda_i \approx \lambda_i^0$. Nominal lambda reduces overshoot during large transients.
\end{itemize}

The scheduling improves local convergence (near equilibrium) while maintaining global stability (far from equilibrium).

%===============================================================================
\section{Chapter 7 Solutions}
%===============================================================================

\textbf{Exercise 7.1}: Explain why linear controllers (LQR, SMC) cannot swing up a pendulum from hanging-down position ($\theta = \pi$) to upright ($\theta = 0$). What fundamental limitation do they face?

\textbf{Solution}:

Linear controllers (LQR, linearized SMC) are designed around the upright equilibrium $\theta = 0$ using linearized dynamics:
\begin{equation}
\ddot{\theta} \approx \frac{g}{L} \theta + \frac{1}{mL} u
\end{equation}

This approximation assumes $\sin\theta \approx \theta$ and $\cos\theta \approx 1 - \frac{\theta^2}{2}$, valid only for $|\theta| < 0.3$ rad ($\approx 17°$).

\textbf{Fundamental Limitation (Loss of Controllability):}

At hanging-down position ($\theta = \pi$, $\dot{\theta} = 0$), the linearized system is:
\begin{equation}
\delta\ddot{\theta} = -\frac{g}{L} \delta\theta + \frac{1}{mL} u
\end{equation}
where $\delta\theta = \theta - \pi$ is deviation from hanging-down.

This system is \textbf{unstable} in the wrong direction: disturbances $\delta\theta > 0$ cause $\ddot{\theta} < 0$ (pendulum falls further down), while disturbances $\delta\theta < 0$ cause $\ddot{\theta} > 0$ (pendulum swings toward upright). However:

\begin{enumerate}
    \item \textbf{Local basin of attraction}: Linear controllers can only stabilize within a region $|\theta| < \theta_{\max} \approx 0.5$ rad around upright. From $\theta = \pi$, the controller sees $\theta - 0 = \pi$ rad error, which is outside its design range.

    \item \textbf{Control authority insufficient}: At $\theta = \pi$, gravitational torque is $\tau_g = mgL \sin(\pi) = 0$ (no restoring force). The cart force $u$ couples to pendulum angle via:
    \begin{equation}
    \tau_{\text{cart}} = u \cdot L \cos\theta = u \cdot L \cos(\pi) = -uL
    \end{equation}
    This coupling is \textbf{sign-reversed} compared to upright ($\cos(0) = +1$ vs. $\cos(\pi) = -1$), causing linear controller to apply force in wrong direction.

    \item \textbf{Energy barrier}: To swing from $\theta = \pi$ (potential energy $V = 0$) to $\theta = 0$ (potential energy $V = 2mgL$), the controller must pump $\Delta E = 2mgL$ joules into the system. Linear controllers lack energy-based planning and instead react to instantaneous error $e = \theta - \theta_{\text{ref}}$, which is insufficient to overcome the barrier.
\end{enumerate}

\textbf{Example}: LQR controller with gains $Q = \text{diag}(10, 1, 50, 5)$ and $R = 0.01$ applied from $\theta(0) = \pi$:
\begin{itemize}
    \item Time $t = 0$ s: $u = -K [\pi, 0, 0, 0]^T \approx -50$ N (pushes cart left)
    \item Expected: Cart moves left → pendulum tilts right → $\theta$ decreases
    \item Actual: At $\theta = \pi$, cart-pendulum coupling reversed → pendulum tilts left → $\theta$ increases to $1.1\pi$ (diverges!)
\end{itemize}

\textbf{Solution}: Use energy-based swing-up controller to pump energy until $\theta \approx 0$, then switch to linear SMC for stabilization. The switching threshold is typically $|\theta| < 0.3$ rad and $|\dot{\theta}| < 2$ rad/s.

\vspace{1em}

\textbf{Exercise 7.2}: The swing-up controller pumps energy into the system until the pendulum reaches the upright equilibrium. Give a physical analogy (e.g., playground swing). How does the controller know when to switch from swing-up to stabilization?

\textbf{Solution}:

\textbf{Physical Analogy (Playground Swing):}

Imagine pushing a child on a playground swing to build amplitude:

\begin{itemize}
    \item \textbf{Energy pumping}: You push in sync with the swing's motion (when $\dot{x} > 0$, push forward; when $\dot{x} < 0$, push backward). Each push adds kinetic energy: $\Delta E = F \cdot \Delta x > 0$.

    \item \textbf{Resonance}: Timing the pushes to match the swing's natural frequency $\omega_n = \sqrt{g/L}$ maximizes energy transfer efficiency. Random pushes would add/subtract energy unpredictably.

    \item \textbf{Amplitude control}: You stop pushing when the swing reaches the desired angle (e.g., $\theta_{\max} = 45°$). Further pushing would make the swing go too high (potentially dangerous/unstable).

    \item \textbf{Stabilization}: Once at the target amplitude, you switch to damping control (gentle resistance) to maintain $\theta_{\max}$ against friction losses.
\end{itemize}

For the DIP swing-up:
\begin{itemize}
    \item \textbf{Energy pumping}: Cart force $u = k_E \dot{x} (E - E_{\text{desired}}) \cos\theta_1$ mimics pushing in sync with cart velocity $\dot{x}$
    \item \textbf{Target energy}: $E_{\text{desired}} = 2m_1 g L_1 + m_2 g (2L_1 + 2L_2)$ corresponds to upright equilibrium
    \item \textbf{Switching}: When $E \approx E_{\text{desired}}$ and $|\theta_1| < 0.3$ rad, controller switches to SMC stabilization
\end{itemize}

\textbf{Switching Logic (When to Switch from Swing-Up to Stabilization):}

The controller monitors three conditions:

\begin{enumerate}
    \item \textbf{Energy threshold}: $E(t) \geq E_{\text{switch}} = 0.95 \cdot E_{\text{desired}}$

    Check that pendulum has sufficient energy to reach upright. Using 95\% threshold (not 100\%) accounts for:
    \begin{itemize}
        \item Energy measurement noise ($\pm 2\%$ typical)
        \item Friction losses during final approach
        \item Actuator response delay
    \end{itemize}

    \item \textbf{Angle threshold}: $|\theta_1| < \theta_{\text{switch}} = 0.3$ rad \textbf{and} $|\theta_2| < \theta_{\text{switch}}$

    Ensure pendulum is near upright equilibrium where linear SMC is valid. At $\theta_1 = 0.3$ rad ($17°$):
    \begin{itemize}
        \item Linearization error: $|\sin(0.3) - 0.3| / 0.3 \approx 1.6\%$ (acceptable)
        \item Basin of attraction: SMC can stabilize from this deviation
    \end{itemize}

    \item \textbf{Angular velocity threshold}: $|\dot{\theta}_1| < \dot{\theta}_{\text{switch}} = 2$ rad/s \textbf{and} $|\dot{\theta}_2| < 3$ rad/s

    Prevent switching during fast swings where:
    \begin{itemize}
        \item SMC cannot apply sufficient braking torque to prevent overshoot
        \item High velocity amplifies chattering due to $u = -K \sign(\sigma)$ discontinuity
    \end{itemize}

    \textbf{Hysteresis (Anti-Chattering):}
    \begin{equation}
    \text{Switch to SMC if:} \quad E \geq 0.95 E_d \text{ and } |\theta_1| < 0.3 \text{ and } |\dot{\theta}_1| < 2
    \end{equation}
    \begin{equation}
    \text{Revert to swing-up if:} \quad E < 0.85 E_d \text{ or } |\theta_1| > 0.5
    \end{equation}

    The 10\% hysteresis gap ($0.85 E_d$ vs. $0.95 E_d$) prevents rapid mode switching (chattering between controllers) when conditions fluctuate near the threshold.
\end{enumerate}

\textbf{Implementation Example}:
\begin{lstlisting}[language=Python]
if mode == 'swing_up':
    if (E >= 0.95 * E_desired and
        abs(theta1) < 0.3 and abs(theta2) < 0.3 and
        abs(dtheta1) < 2.0 and abs(dtheta2) < 3.0):
        mode = 'stabilize'
        print(f"Switched to stabilization at t={t:.2f}s")
elif mode == 'stabilize':
    if E < 0.85 * E_desired or abs(theta1) > 0.5:
        mode = 'swing_up'
        print(f"Reverted to swing-up at t={t:.2f}s")
\end{lstlisting}

\vspace{1em}

\textbf{Exercise 7.3}: Derive the total mechanical energy for the DIP system and design the energy-based swing-up control law.

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Kinetic energy} $T$ (cart + two pendula):
    \begin{align}
    T = \frac{1}{2} M \dot{x}^2 &+ \frac{1}{2} m_1 (\dot{x}_1^2 + \dot{y}_1^2) + \frac{1}{2} I_1 \dot{\theta}_1^2 \nonumber \\
    &+ \frac{1}{2} m_2 (\dot{x}_2^2 + \dot{y}_2^2) + \frac{1}{2} I_2 \dot{\theta}_2^2
    \end{align}
    where $(x_1, y_1) = (x + L_1 \sin\theta_1, L_1 \cos\theta_1)$ and $(x_2, y_2) = (x_1 + L_2 \sin\theta_2, y_1 + L_2 \cos\theta_2)$ are center-of-mass positions.

    Substituting and simplifying:
    \begin{equation}
    T = \frac{1}{2}(M + m_1 + m_2)\dot{x}^2 + \frac{1}{2}(I_1 + m_1 L_1^2) \dot{\theta}_1^2 + \frac{1}{2}(I_2 + m_2 L_2^2) \dot{\theta}_2^2 + \text{coupling terms}
    \end{equation}

    \item \textbf{Potential energy} $V$ (gravitational, zero at hanging-down):
    \begin{equation}
    V = m_1 g L_1 (1 + \cos\theta_1) + m_2 g (L_1(1 + \cos\theta_1) + L_2(1 + \cos\theta_2))
    \end{equation}

    \item \textbf{Desired energy} $E_{\text{desired}}$ at upright equilibrium ($\theta_1 = \theta_2 = 0$, all velocities = 0):
    \begin{equation}
    E_{\text{desired}} = V(0, 0) = 2 m_1 g L_1 + m_2 g (2 L_1 + 2 L_2)
    \end{equation}
    This is the energy at the upright unstable equilibrium.

    \item \textbf{Control law design}: The swing-up control pumps energy into the system:
    \begin{equation}
    u = k_E \dot{x} (E(t) - E_{\text{desired}}) \cos\theta_1
    \end{equation}
    where $E(t) = T(t) + V(t)$ is total energy.

    \item \textbf{Physical explanation of each term}:
    \begin{itemize}
        \item $k_E > 0$: energy control gain (typical value: 50 N$\cdot$s/J)
        \item $\dot{x}$: cart velocity couples energy transfer (move with pendulum)
        \item $(E - E_{\text{desired}})$: energy error drives adaptation
        \item $\cos\theta_1$: modulates force direction based on pendulum angle:
        \begin{itemize}
            \item When $\theta_1 \approx \pm\pi$ (hanging down): $\cos\theta_1 \approx -1$, control opposes cart motion to pump energy
            \item When $\theta_1 \approx 0$ (near upright): $\cos\theta_1 \approx 1$, control reduces (switch to stabilization)
        \end{itemize}
    \end{itemize}
\end{enumerate}

\vspace{1em}

\textbf{Exercise 7.4}: For a PSO with swarm size $N_p = 30$ and maximum iterations $I_{\max} = 50$, compute the total number of fitness evaluations required.

\textbf{Solution}: Each iteration evaluates fitness for all $N_p$ particles. Total evaluations:
\begin{equation}
N_{\text{eval}} = N_p \times I_{\max} = 30 \times 50 = 1500 \text{ evaluations}
\end{equation}

If each evaluation requires 10 s simulation time, total optimization time is:
\begin{equation}
T_{\text{opt}} = 1500 \times 10 \text{ s} = 15{,}000 \text{ s} = 4.17 \text{ hours}
\end{equation}

With Numba JIT acceleration (10x speedup), this reduces to $\sim$25 minutes.

\vspace{1em}

\textbf{Exercise 7.6}: Explain why inertia weight $\omega$ should decrease from 0.9 to 0.4 during PSO iterations.

\textbf{Solution}: The inertia weight balances exploration and exploitation:
\begin{equation}
\vect{v}_{k+1} = \omega \vect{v}_k + c_1 r_1 (\vect{p}_k - \vect{x}_k) + c_2 r_2 (\vect{g}_k - \vect{x}_k)
\end{equation}

\begin{itemize}
    \item \textbf{Early iterations} ($\omega = 0.9$): High inertia maintains particle momentum, enabling global exploration of the search space. Particles can escape local minima.
    \item \textbf{Late iterations} ($\omega = 0.4$): Low inertia reduces momentum, allowing particles to converge tightly around the global best. Exploitation phase refines the solution.
\end{itemize}

Linear decrease:
\begin{equation}
\omega(i) = 0.9 - \frac{i}{50} (0.9 - 0.4) = 0.9 - 0.01 \cdot i
\end{equation}

This adaptive strategy prevents premature convergence while ensuring final solution quality.

%===============================================================================
\section{Chapter 8 Solutions}
%===============================================================================

\textbf{Exercise 8.1}: Compare PSO to gradient descent for controller gain tuning. (a) Why is gradient computation difficult for SMC systems? (b) What advantages does PSO provide? (c) When would gradient methods be preferred?

\textbf{Solution}:
\begin{enumerate}[label=(\alph*)]
    \item \textbf{Gradient computation difficulty in SMC}:

    The cost function for SMC gain tuning is:
    \begin{equation}
    J(\vect{g}) = f(\text{simulation}(\vect{g}))
    \end{equation}
    where $\vect{g} = [K_1, K_2, \lambda_1, \lambda_2, \epsilon]$ are gains and $f$ computes tracking error, control effort, chattering.

    Gradient descent requires $\nabla_{\vect{g}} J$, but:
    \begin{itemize}
        \item \textbf{Discontinuities}: The $\sign(s)$ function in SMC creates non-differentiable control law. $\frac{\partial u}{\partial K}$ is undefined at $s = 0$.
        \item \textbf{Simulation dependency}: $J$ depends on simulation output, not an analytical expression. Computing $\frac{\partial J}{\partial K}$ requires either:
        \begin{enumerate}
            \item Finite differences: $\frac{\partial J}{\partial K} \approx \frac{J(K + \Delta K) - J(K)}{\Delta K}$ (expensive, $2d$ simulations per iteration)
            \item Adjoint method: requires reverse-mode differentiation through ODE solver (complex implementation)
        \end{enumerate}
        \item \textbf{Noisy gradients}: Numerical errors in simulation (Euler/RK4 discretization) propagate to gradient estimates, causing optimizer instability.
    \end{itemize}

    \item \textbf{PSO advantages for SMC tuning}:
    \begin{itemize}
        \item \textbf{Derivative-free}: PSO only requires function evaluations $J(\vect{g})$, no gradient computation
        \item \textbf{Global search}: Swarm explores multiple regions simultaneously, avoids local minima. Example: for multimodal $J$ with 5 local minima, gradient descent may converge to any depending on initialization, while PSO finds global minimum with 90\% probability.
        \item \textbf{Parallel evaluation}: All $N_p$ particles can be simulated independently (embarrassingly parallel), reducing wall time by $N_p$x on multi-core systems.
        \item \textbf{Robustness to noise}: Stochastic updates ($r_1, r_2$ randomness) naturally handle noisy $J$, while gradient methods require careful step size tuning.
    \end{itemize}

    \item \textbf{When gradient methods are preferred}:
    \begin{itemize}
        \item \textbf{Smooth, convex objectives}: If $J$ is differentiable and convex (e.g., LQR gain tuning via Riccati equation), gradient descent converges faster than PSO ($O(\log(1/\epsilon))$ iterations vs. $O(1/\epsilon)$).
        \item \textbf{High dimensionality}: PSO requires $N_p = 10d$ to $30d$ particles for $d$-dimensional problems. For $d > 50$ (e.g., neural network weights), gradient methods scale better.
        \item \textbf{Real-time adaptation}: Gradient descent with line search converges in 10-100 iterations, while PSO requires 500-5000 evaluations. For online tuning during operation, gradient methods are faster.
    \end{itemize}
\end{enumerate}

\vspace{1em}

\textbf{Exercise 8.2}: A good PSO cost function balances tracking error, control effort, and chattering. Explain the trade-offs: (a) Minimizing tracking error alone may cause excessive control. (b) Minimizing control effort alone may sacrifice tracking accuracy. (c) How do weighting coefficients $w_{\text{tracking}}, w_{\text{effort}}, w_{\text{chattering}}$ affect the Pareto frontier?

\textbf{Solution}:

\begin{enumerate}[label=(\alph*)]
    \item \textbf{Minimizing tracking error alone causes excessive control}:

    Single-objective cost: $J = w_{\text{track}} \cdot \text{RMS}(\theta)$ where $\text{RMS}(\theta) = \sqrt{\frac{1}{N}\sum_{i=1}^N \theta_i^2}$.

    PSO optimization drives gains $(\lambda_1, \lambda_2, K) \to (\lambda_1^*, \lambda_2^*, K^*)$ that minimize $\text{RMS}(\theta)$. This results in:
    \begin{itemize}
        \item \textbf{Aggressive gains}: $K^* \gg K_{\text{nominal}}$ (e.g., $K = 50$ N vs. $K_{\text{nom}} = 15$ N)
        \item \textbf{Fast sliding surface convergence}: $|\sigma| \to 0$ within 0.5 s → $|\theta| < 0.01$ rad quickly
        \item \textbf{Excessive control effort}: $u(t) = u_{\text{eq}} - K \sign(\sigma)$ with large $K$ causes:
        \begin{itemize}
            \item High control rate: $|du/dt| > 100$ N/s (chattering)
            \item Large total effort: $E = \int_0^T |u(t)| dt > 5$ J (vs. 1.2 J nominal)
            \item Actuator saturation risk: $|u| > u_{\max} = 20$ N
        \end{itemize}
    \end{itemize}

    \textbf{Example}: PSO finds $K = 45$ N achieving $\text{RMS}(\theta) = 0.008$ rad, but control effort $E = 4.5$ J (3.75$\times$ nominal), causing actuator wear.

    \item \textbf{Minimizing control effort alone sacrifices tracking}:

    Single-objective cost: $J = w_{\text{effort}} \cdot \text{IAE}(u)$ where $\text{IAE}(u) = \int_0^T |u(t)| dt$.

    PSO optimization drives $(K, \lambda_i) \to (K^*, \lambda_i^*)$ that minimize $\text{IAE}(u)$. This results in:
    \begin{itemize}
        \item \textbf{Conservative gains}: $K^* \ll K_{\text{required}}$ (e.g., $K = 5$ N vs. $K_{\text{req}} = 15$ N for $d_{\max} = 10$ N disturbance)
        \item \textbf{Low control authority}: Insufficient gain to reject disturbances
        \item \textbf{Poor tracking}: $|\theta_{\max}| > 0.5$ rad (vs. $<0.05$ rad nominal), possibly unstable
    \end{itemize}

    \textbf{Example}: PSO finds $K = 3$ N achieving $\text{IAE}(u) = 0.8$ J, but $\text{RMS}(\theta) = 0.15$ rad (18.75$\times$ nominal), violating $|\theta| < 0.1$ rad specification.

    \textbf{Fundamental conflict}: Controller must apply effort $u$ to reject $d$ and track $\theta_{\text{ref}}$. Minimizing $\text{IAE}(u)$ inevitably increases $\text{RMS}(\theta)$ for fixed disturbance level.

    \item \textbf{Weighting coefficients affect Pareto frontier}:

    Multi-objective cost:
    \begin{equation}
    J = w_{\text{track}} \cdot \text{RMS}(\theta) + w_{\text{effort}} \cdot \text{IAE}(u) + w_{\text{chatter}} \cdot \mathcal{C}
    \end{equation}
    where $\mathcal{C} = \text{RMS}(du/dt)$ is chattering metric.

    \textbf{Pareto frontier}: Set of non-dominated solutions where improving one objective degrades another. For DIP:
    \begin{itemize}
        \item Point A: $w_{\text{track}} = 1.0, w_{\text{effort}} = 0, w_{\text{chatter}} = 0$ → $(K = 45$ N, $\text{RMS}(\theta) = 0.008$ rad, $E = 4.5$ J$)$ (tracking-optimal)
        \item Point B: $w_{\text{track}} = 0, w_{\text{effort}} = 1.0, w_{\text{chatter}} = 0$ → $(K = 3$ N, $\text{RMS}(\theta) = 0.15$ rad, $E = 0.8$ J$)$ (efficiency-optimal)
        \item Point C: $w_{\text{track}} = 0.6, w_{\text{effort}} = 0.3, w_{\text{chatter}} = 0.1$ → $(K = 15$ N, $\text{RMS}(\theta) = 0.02$ rad, $E = 1.2$ J$)$ (balanced)
    \end{itemize}

    \textbf{Effect of varying weights}:
    \begin{itemize}
        \item Increasing $w_{\text{track}}$: Moves optimal solution toward Point A (high $K$, low $\text{RMS}(\theta)$, high $E$)
        \item Increasing $w_{\text{effort}}$: Moves toward Point B (low $K$, high $\text{RMS}(\theta)$, low $E$)
        \item Increasing $w_{\text{chatter}}$: Reduces boundary layer $\epsilon$ and gain $K$, trades tracking for smoothness
    \end{itemize}

    \textbf{Recommended weighting (DIP application)}:
    \begin{equation}
    w_{\text{track}} : w_{\text{effort}} : w_{\text{chatter}} = 0.6 : 0.3 : 0.1
    \end{equation}
    Rationale: Tracking is primary objective (60\%), control economy important for actuator life (30\%), chattering reduction desirable but secondary (10\%).

    This weighting achieves Point C: near-optimal tracking ($\text{RMS}(\theta) = 0.02$ rad, 2.5$\times$ Point A) with moderate effort ($E = 1.2$ J, 1.5$\times$ Point B), satisfying both $|\theta| < 0.05$ rad and $E < 2$ J constraints.
\end{enumerate}

\vspace{1em}

\textbf{Exercise 8.3}: Compute the PSO velocity update for a particle with current position $\vect{x} = [1, 2]$, velocity $\vect{v} = [0.5, -0.3]$, personal best $\vect{p} = [0.8, 1.5]$, global best $\vect{g} = [0.6, 1.2]$, using $\omega = 0.7$, $c_1 = c_2 = 2.0$, $r_1 = 0.4$, $r_2 = 0.6$.

\textbf{Solution}:
\begin{align}
\vect{v}_{\text{new}} &= \omega \vect{v} + c_1 r_1 (\vect{p} - \vect{x}) + c_2 r_2 (\vect{g} - \vect{x}) \\
&= 0.7 [0.5, -0.3] + 2.0 \cdot 0.4 \cdot ([0.8, 1.5] - [1, 2]) + 2.0 \cdot 0.6 \cdot ([0.6, 1.2] - [1, 2]) \\
&= [0.35, -0.21] + 0.8 \cdot [-0.2, -0.5] + 1.2 \cdot [-0.4, -0.8] \\
&= [0.35, -0.21] + [-0.16, -0.40] + [-0.48, -0.96] \\
&= [-0.29, -1.57]
\end{align}

%===============================================================================
\section{Chapter 9 Solutions}
%===============================================================================

\textbf{Exercise 9.2}: Compute the robust fitness function for a controller that achieves $J_{\text{nominal}} = 8.5$ and $J_{\text{disturbed}} = [10.2, 9.8]$ (step and impulse disturbances). Use 50\% nominal, 50\% disturbed weighting.

\textbf{Solution}: The robust fitness is:
\begin{equation}
J_{\text{robust}} = 0.5 \cdot J_{\text{nominal}} + 0.5 \cdot \frac{1}{N_{\text{dist}}} \sum_{i=1}^{N_{\text{dist}}} J_{\text{dist},i}
\end{equation}

With $N_{\text{dist}} = 2$ disturbance scenarios:
\begin{align}
J_{\text{robust}} &= 0.5 \cdot 8.5 + 0.5 \cdot \frac{1}{2} (10.2 + 9.8) \\
&= 4.25 + 0.5 \cdot 10.0 \\
&= 4.25 + 5.0 \\
&= 9.25
\end{align}

\vspace{1em}

\textbf{Exercise 9.7}: Given that PSO-optimized gains show 50.4x chattering degradation when tested on 6x larger perturbations (MT-7 result), explain the root cause and propose a solution.

\textbf{Solution}: \textbf{Root Cause}: Overfitting to narrow training distribution. PSO optimized gains for $\pm 0.05$ rad perturbations, but test used $\pm 0.3$ rad (6x larger). The resulting gains are specialized for small errors and violate Lyapunov stability conditions for large sliding variable magnitudes.

\textbf{Proposed Solutions}:
\begin{enumerate}
    \item \textbf{Multi-scenario training}: Modify fitness function to include worst-case penalty:
    \begin{equation}
    J_{\text{robust}} = 0.5 \cdot J_{\text{nominal}} + 0.3 \cdot J_{\text{large}} + 0.2 \cdot \max_i J_i
    \end{equation}
    where $J_{\text{large}}$ evaluates performance on $\pm 0.3$ rad perturbations.

    \item \textbf{Adaptive boundary layer}: Use state-dependent $\epsilon(|\sigma|) = \epsilon_{\min} + \alpha |\sigma|$ to accommodate varying sliding surface magnitudes.

    \item \textbf{Lyapunov-constrained PSO}: Add constraint that gains must satisfy $K_2 > L_m$ and $K_1^2 \geq \frac{4 L_m K_2 (K_2 + L_m)}{K_2 - L_m}$ for the worst-case sliding variable magnitude.
\end{enumerate}

%===============================================================================
\section{Chapter 10 Solutions}
%===============================================================================

\textbf{Exercise 10.3}: A controller achieves 8.2° overshoot under 10 N step disturbance. Using the linear degradation model (0.7°/N), predict the overshoot under 15 N and 20 N disturbances.

\textbf{Solution}: Linear model: $M_p = M_{p,0} + \beta (F - F_0)$ where $\beta = 0.7$ °/N.

At $F_0 = 10$ N: $M_p = 8.2$°

\textbf{At 15 N}:
\begin{equation}
M_p(15) = 8.2 + 0.7 \cdot (15 - 10) = 8.2 + 3.5 = 11.7°
\end{equation}

\textbf{At 20 N}:
\begin{equation}
M_p(20) = 8.2 + 0.7 \cdot (20 - 10) = 8.2 + 7.0 = 15.2°
\end{equation}

\textbf{Validity}: Model valid up to divergence threshold (typically 25 N for DIP). Above 20 N, nonlinear effects dominate.

\vspace{1em}

\textbf{Exercise 10.8}: Given that Adaptive SMC shows 5.1\% settling time degradation under ±20\% parameter uncertainty while Classical SMC shows 31.6\% degradation, calculate the relative robustness improvement.

\textbf{Solution}: Relative improvement:
\begin{equation}
\text{Improvement} = \frac{\text{Classical degradation} - \text{Adaptive degradation}}{\text{Classical degradation}} \times 100\%
\end{equation}

\begin{equation}
= \frac{31.6\% - 5.1\%}{31.6\%} \times 100\% = \frac{26.5\%}{31.6\%} \times 100\% = 83.9\%
\end{equation}

Adaptive SMC reduces settling time degradation by 83.9\% compared to Classical SMC under ±20\% uncertainty. This demonstrates the effectiveness of online gain adaptation for compensating model mismatch.

%===============================================================================
\section{Chapter 11 Solutions}
%===============================================================================

\textbf{Exercise 11.2}: Design a Kalman filter for the DIP system with encoder measurement noise $\sigma_\theta = 0.1$° and zero process noise. Write the measurement equation.

\textbf{Solution}: State vector: $\vect{x} = [x, \theta_1, \theta_2, \dot{x}, \dot{\theta}_1, \dot{\theta}_2]^T$

Measurement equation (angles only):
\begin{equation}
\vect{y} = \begin{bmatrix} \theta_1 \\ \theta_2 \end{bmatrix} = \begin{bmatrix} 0 & 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 & 0 \end{bmatrix} \vect{x} + \vect{v}
\end{equation}

Measurement noise covariance:
\begin{equation}
R = \begin{bmatrix} \sigma_\theta^2 & 0 \\ 0 & \sigma_\theta^2 \end{bmatrix} = \begin{bmatrix} (0.1 \pi/180)^2 & 0 \\ 0 & (0.1 \pi/180)^2 \end{bmatrix} \text{ rad}^2
\end{equation}

The Kalman filter provides optimal state estimates $\hat{\vect{x}}$ by fusing the noisy measurements with the DIP dynamics model, reducing velocity estimation noise by $\sim$70\% compared to numerical differentiation.

\vspace{1em}

\textbf{Exercise 11.5}: Explain three advantages of model-free reinforcement learning over PSO for controller gain optimization.

\textbf{Solution}:
\begin{enumerate}
    \item \textbf{Online adaptation}: RL agents (e.g., TD3, SAC) adapt gains in real-time based on observed state-action-reward, while PSO requires offline batch optimization.

    \item \textbf{No fitness function engineering}: RL learns directly from sparse rewards (e.g., +1 for upright, -1 for fall), while PSO requires carefully weighted multi-objective fitness $J = w_1 t_s + w_2 M_p + w_3 \sigma_u + w_4 E$.

    \item \textbf{Generalization to unseen states}: RL policies generalize via neural network function approximation, while PSO gains are static lookup tables that fail on out-of-distribution states (MT-7 50.4x degradation example).
\end{enumerate}

\textbf{Tradeoffs}: RL requires 10-100x more training samples, lacks theoretical guarantees, and is sensitive to hyperparameters. PSO is sample-efficient and interpretable.

%===============================================================================
\section{Chapter 12 Solutions}
%===============================================================================

\textbf{Exercise 12.3}: In the HIL validation experiment, simulation predicted 8.2° overshoot but hardware achieved 9.7° (18.3\% gap). Identify three sources of this sim-hardware gap.

\textbf{Solution}:
\begin{enumerate}
    \item \textbf{Actuator dynamics}: Simulation assumes instantaneous torque, but real DC motors have 0.05 s time constant causing phase lag. This delay increases overshoot by $\sim$10-15\%.

    \item \textbf{Sensor quantization}: Encoders have 0.01° resolution. Near the sliding surface, quantization causes discrete jumps in control signal, increasing chattering and transient overshoot by $\sim$5\%.

    \item \textbf{Model mismatch}: Real DIP has friction (Coulomb + viscous), joint flexibility, and cable drag not modeled in simulation. Combined effect adds $\sim$3-5\% performance degradation.
\end{enumerate}

\textbf{Mitigation}: Include second-order actuator model $\ddot{u} + 2\zeta\omega_n \dot{u} + \omega_n^2 u = \omega_n^2 u_{\text{cmd}}$ with $\omega_n = 2\pi \cdot 20$ rad/s (20 Hz bandwidth) to capture motor dynamics. Add Coulomb friction term $F_c \sign(\dot{x})$ to cart dynamics. These improvements reduce sim-hardware gap to $<$10\%.

\vspace{1em}

\textbf{Exercise 12.6}: For a plant-controller HIL setup with 50 Hz sampling rate and 10 ms communication delay, determine if the system remains stable under the Nyquist criterion.

\textbf{Solution}: Sampling period: $\Delta t = 1/50 = 0.02$ s = 20 ms

Total loop delay: $\tau = 10$ ms (communication) + 5 ms (computation) = 15 ms

Phase lag at Nyquist frequency ($f_N = 25$ Hz):
\begin{equation}
\phi = -360° \cdot f_N \cdot \tau = -360° \cdot 25 \cdot 0.015 = -135°
\end{equation}

For a typical SMC open-loop system with gain margin GM = 12 dB and phase margin PM = 45°:
\begin{itemize}
    \item Required PM for stability: $>$ 0°
    \item Actual PM with delay: $45° - 135° = -90°$ (unstable!)
\end{itemize}

\textbf{Conclusion}: System becomes unstable. \textbf{Solutions}:
\begin{enumerate}
    \item Increase sampling rate to 100 Hz ($\Delta t = 10$ ms, $\phi = -90°$, PM = -45° still unstable)
    \item Increase to 200 Hz ($\Delta t = 5$ ms, $\phi = -54°$, PM = -9° marginally stable)
    \item Add Smith predictor to compensate 10 ms delay: $u_{\text{comp}}(t) = u(t + \tau)$ restores PM to 45°
\end{enumerate}

%===============================================================================
% END OF APPENDIX D
%===============================================================================
