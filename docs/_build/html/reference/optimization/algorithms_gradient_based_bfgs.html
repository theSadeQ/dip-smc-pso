<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" />

    <!-- Generated with Sphinx 7.4.7 and Furo 2024.08.06 -->
        <title>optimization.algorithms.gradient_based.bfgs - DIP_SMC_PSO Documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=5349f25f" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=f5a89ef9" />
    
    


<style>
  body {
    --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">DIP_SMC_PSO Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">DIP_SMC_PSO Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">📚 Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../README.html">Optimal Sliding Mode Control for a Double-Inverted Pendulum via PSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../theory_overview.html">1. Theoretical Background â€” Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture.html">3. System Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plant_model.html">1.x Plant Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hil_quickstart.html">Hardware-in-the-Loop (HIL) Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../streamlit_dashboard_guide.html">Streamlit Dashboard User Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">🎮 Control Systems &amp; Optimization</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../controllers/index.html">Controllers Module Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Controllers Module Documentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/classical_smc_technical_guide.html">Classical Sliding Mode Control Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/adaptive_smc_technical_guide.html">Adaptive Sliding Mode Control Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/sta_smc_technical_guide.html">Super-Twisting Sliding Mode Control Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/hybrid_smc_technical_guide.html">Hybrid Adaptive Super-Twisting SMC Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/mpc_technical_guide.html">Model Predictive Control Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/swing_up_smc_technical_guide.html">Swing-Up SMC Technical Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/factory_system_guide.html">SMC Controller Factory System Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../controllers/control_primitives_reference.html">Control Primitives Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematical_foundations/smc_complete_theory.html">Complete Sliding Mode Control Mathematical Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematical_foundations/controller_comparison_theory.html">SMC Controller Comparison Theory</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../controllers/index.html">Controllers Module</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Controllers Module</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../controllers/adaptive_smc.html">controllers.adaptive_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/classic_smc.html">controllers.classic_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory.html">controllers.factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/mpc_controller.html">controllers.mpc_controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/sta_smc.html">controllers.sta_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/swing_up_smc.html">controllers.swing_up_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/__init__.html">controllers.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/base_controller_interface.html">controllers.base.controller_interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/base_control_primitives.html">controllers.base.control_primitives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/base___init__.html">controllers.base.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_deprecation.html">controllers.factory.deprecation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_fallback_configs.html">controllers.factory.fallback_configs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_legacy_factory.html">controllers.factory.legacy_factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_optimization.html">controllers.factory.optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_pso_integration.html">controllers.factory.pso_integration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_smc_factory.html">controllers.factory.smc_factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_thread_safety.html">controllers.factory.thread_safety</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory___init__.html">controllers.factory.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/mpc_mpc_controller.html">controllers.mpc.mpc_controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/mpc___init__.html">controllers.mpc.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_adaptive_smc.html">controllers.smc.adaptive_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_classic_smc.html">controllers.smc.classic_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_hybrid_adaptive_sta_smc.html">controllers.smc.hybrid_adaptive_sta_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_sta_smc.html">controllers.smc.sta_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc___init__.html">controllers.smc.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/specialized_swing_up_smc.html">controllers.specialized.swing_up_smc</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/specialized___init__.html">controllers.specialized.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_core_protocols.html">controllers.factory.core.protocols</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_core_registry.html">controllers.factory.core.registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_core_threading.html">controllers.factory.core.threading</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_core_validation.html">controllers.factory.core.validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/factory_core___init__.html">controllers.factory.core.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms___init__.html">controllers.smc.algorithms.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_core_equivalent_control.html">controllers.smc.core.equivalent_control</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_core_gain_validation.html">controllers.smc.core.gain_validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_core_sliding_surface.html">controllers.smc.core.sliding_surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_core_switching_functions.html">controllers.smc.core.switching_functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_core___init__.html">controllers.smc.core.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_adaptation_law.html">controllers.smc.algorithms.adaptive.adaptation_law</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_config.html">controllers.smc.algorithms.adaptive.config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_controller.html">controllers.smc.algorithms.adaptive.controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_parameter_estimation.html">controllers.smc.algorithms.adaptive.parameter_estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_adaptive___init__.html">controllers.smc.algorithms.adaptive.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_classical_boundary_layer.html">controllers.smc.algorithms.classical.boundary_layer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_classical_config.html">controllers.smc.algorithms.classical.config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_classical_controller.html">controllers.smc.algorithms.classical.controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_classical___init__.html">controllers.smc.algorithms.classical.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_config.html">controllers.smc.algorithms.hybrid.config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_controller.html">controllers.smc.algorithms.hybrid.controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_switching_logic.html">controllers.smc.algorithms.hybrid.switching_logic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_hybrid___init__.html">controllers.smc.algorithms.hybrid.<strong>init</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_config.html">controllers.smc.algorithms.super_twisting.config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_controller.html">controllers.smc.algorithms.super_twisting.controller</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_twisting_algorithm.html">controllers.smc.algorithms.super_twisting.twisting_algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting___init__.html">controllers.smc.algorithms.super_twisting.<strong>init</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mathematical_foundations/index.html">Mathematical Foundations</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Mathematical Foundations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mathematical_foundations/smc_complete_theory.html">Complete Sliding Mode Control Mathematical Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mathematical_foundations/controller_comparison_theory.html">SMC Controller Comparison Theory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../plant/models_guide.html">Plant Models Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization_simulation/guide.html">Optimization &amp; Simulation Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../controllers/index.html">Controllers Module</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Controllers Module</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../controllers/adaptive_smc.html">controllers.adaptive_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/classic_smc.html">controllers.classic_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory.html">controllers.factory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/mpc_controller.html">controllers.mpc_controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/sta_smc.html">controllers.sta_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/swing_up_smc.html">controllers.swing_up_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/__init__.html">controllers.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/base_controller_interface.html">controllers.base.controller_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/base_control_primitives.html">controllers.base.control_primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/base___init__.html">controllers.base.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_deprecation.html">controllers.factory.deprecation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_fallback_configs.html">controllers.factory.fallback_configs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_legacy_factory.html">controllers.factory.legacy_factory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_optimization.html">controllers.factory.optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_pso_integration.html">controllers.factory.pso_integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_smc_factory.html">controllers.factory.smc_factory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_thread_safety.html">controllers.factory.thread_safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory___init__.html">controllers.factory.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/mpc_mpc_controller.html">controllers.mpc.mpc_controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/mpc___init__.html">controllers.mpc.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_adaptive_smc.html">controllers.smc.adaptive_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_classic_smc.html">controllers.smc.classic_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_hybrid_adaptive_sta_smc.html">controllers.smc.hybrid_adaptive_sta_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_sta_smc.html">controllers.smc.sta_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc___init__.html">controllers.smc.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/specialized_swing_up_smc.html">controllers.specialized.swing_up_smc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/specialized___init__.html">controllers.specialized.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_core_protocols.html">controllers.factory.core.protocols</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_core_registry.html">controllers.factory.core.registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_core_threading.html">controllers.factory.core.threading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_core_validation.html">controllers.factory.core.validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/factory_core___init__.html">controllers.factory.core.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms___init__.html">controllers.smc.algorithms.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_core_equivalent_control.html">controllers.smc.core.equivalent_control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_core_gain_validation.html">controllers.smc.core.gain_validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_core_sliding_surface.html">controllers.smc.core.sliding_surface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_core_switching_functions.html">controllers.smc.core.switching_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_core___init__.html">controllers.smc.core.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_adaptation_law.html">controllers.smc.algorithms.adaptive.adaptation_law</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_config.html">controllers.smc.algorithms.adaptive.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_controller.html">controllers.smc.algorithms.adaptive.controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_adaptive_parameter_estimation.html">controllers.smc.algorithms.adaptive.parameter_estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_adaptive___init__.html">controllers.smc.algorithms.adaptive.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_classical_boundary_layer.html">controllers.smc.algorithms.classical.boundary_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_classical_config.html">controllers.smc.algorithms.classical.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_classical_controller.html">controllers.smc.algorithms.classical.controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_classical___init__.html">controllers.smc.algorithms.classical.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_config.html">controllers.smc.algorithms.hybrid.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_controller.html">controllers.smc.algorithms.hybrid.controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_hybrid_switching_logic.html">controllers.smc.algorithms.hybrid.switching_logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_hybrid___init__.html">controllers.smc.algorithms.hybrid.<strong>init</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_config.html">controllers.smc.algorithms.super_twisting.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_controller.html">controllers.smc.algorithms.super_twisting.controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting_twisting_algorithm.html">controllers.smc.algorithms.super_twisting.twisting_algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../controllers/smc_algorithms_super_twisting___init__.html">controllers.smc.algorithms.super_twisting.<strong>init</strong></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../optimizer/index.html">Optimizer Module</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Optimizer Module</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../optimizer/pso_optimizer.html">optimizer.pso_optimizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimizer/__init__.html">optimizer.<strong>init</strong></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../analysis_plan.html">5. Analysis &amp; Verification Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks_methodology.html">Benchmarks &amp; Methodology</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">🧪 Development &amp; Testing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../TESTING.html">Testing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../test_protocols.html">5.x Test Protocols</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../use_cases.html">4. Use Cases &amp; Operating Modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../context.html">2. Application Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fault_detection_guide.html">Fault Detection &amp; Isolation (FDI) Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">📊 Research &amp; Theory</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../presentation/index.html">Research Presentation Materials</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Research Presentation Materials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html">Abstract</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#introduction-and-motivation">Introduction and Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#the-double-inverted-pendulum-as-a-canonical-control-problem">The Double Inverted Pendulum as a Canonical Control Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#the-primary-control-objectives-and-challenges">The Primary Control Objectives and Challenges</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#sliding-mode-control-as-a-robust-solution">Sliding Mode Control as a Robust Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#the-gain-tuning-dilemma-and-the-need-for-optimization">The Gain Tuning Dilemma and the Need for Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#particle-swarm-optimization-for-automated-design">Particle Swarm Optimization for Automated Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#synthesis-and-motivation">Synthesis and Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/introduction.html#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/problem-statement.html">Problem Statement for Double‑Inverted Pendulum (DIP) Control with SMC and PSO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/previous-works.html">Previous Work Before the Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/system-modeling.html"><strong>A Comprehensive Technical Report on the Modeling and Configuration of a Cart‑Based Double Inverted Pendulum System</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/smc-theory.html">Sliding Mode Control for a Double‑Inverted Pendulum: Bridging Theory and Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html">Abstract</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#introduction">1 Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#system-modelling-and-problem-formulation">2 System Modelling and Problem Formulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#simulation-methodology">3 Simulation Methodology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#classic-sliding-mode-control">4 Classic Sliding Mode Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-i-boundary-layer-method">5 Chattering Mitigation Strategy I: Boundary Layer Method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-ii-supertwisting-algorithm">6 Chattering Mitigation Strategy II: Super‑Twisting Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-iii-adaptive-sliding-mode-control">7 Chattering Mitigation Strategy III: Adaptive Sliding Mode Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-iv-hybrid-adaptivesta">8 Chattering Mitigation Strategy IV: Hybrid Adaptive–STA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#synthesis-and-comparative-analysis">9 Synthesis and Comparative Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/chattering-mitigation.html#references">References</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/pso-optimization.html"><strong>Comprehensive Simulation Analysis and Enhancements for the Double Inverted Pendulum Control System</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/simulation-setup.html">Particle Swarm Optimization for Sliding‑Mode Controller Tuning of a Double Inverted Pendulum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/results-discussion.html">8 – Results and Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../presentation/results-discussion.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#introduction-and-motivation">Introduction and Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#the-double-inverted-pendulum-as-a-canonical-control-problem">The Double Inverted Pendulum as a Canonical Control Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#the-primary-control-objectives-and-challenges">The Primary Control Objectives and Challenges</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#sliding-mode-control-as-a-robust-solution">Sliding Mode Control as a Robust Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#the-gain-tuning-dilemma-and-the-need-for-optimization">The Gain Tuning Dilemma and the Need for Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#particle-swarm-optimization-for-automated-design">Particle Swarm Optimization for Automated Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#synthesis-and-motivation">Synthesis and Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/introduction.html#references">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/problem-statement.html">Problem Statement for Double‑Inverted Pendulum (DIP) Control with SMC and PSO</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/previous-works.html">Previous Work Before the Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/system-modeling.html"><strong>A Comprehensive Technical Report on the Modeling and Configuration of a Cart‑Based Double Inverted Pendulum System</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/smc-theory.html">Sliding Mode Control for a Double‑Inverted Pendulum: Bridging Theory and Implementation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#introduction">1 Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#system-modelling-and-problem-formulation">2 System Modelling and Problem Formulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#simulation-methodology">3 Simulation Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#classic-sliding-mode-control">4 Classic Sliding Mode Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-i-boundary-layer-method">5 Chattering Mitigation Strategy I: Boundary Layer Method</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-ii-supertwisting-algorithm">6 Chattering Mitigation Strategy II: Super‑Twisting Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-iii-adaptive-sliding-mode-control">7 Chattering Mitigation Strategy III: Adaptive Sliding Mode Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#chattering-mitigation-strategy-iv-hybrid-adaptivesta">8 Chattering Mitigation Strategy IV: Hybrid Adaptive–STA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#synthesis-and-comparative-analysis">9 Synthesis and Comparative Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/chattering-mitigation.html#references">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/pso-optimization.html"><strong>Comprehensive Simulation Analysis and Enhancements for the Double Inverted Pendulum Control System</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/simulation-setup.html">Particle Swarm Optimization for Sliding‑Mode Controller Tuning of a Double Inverted Pendulum</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/results-discussion.html">8 – Results and Discussion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../presentation/results-discussion.html#references">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">📖 API Reference &amp; Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/index.html">API Reference Documentation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography &amp; Academic References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">🔧 Project Management</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../CONTRIBUTING.html">Contributing – ResearchPlanSpec Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../RELEASE_CHECKLIST.html">Release Checklist</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../CHANGELOG.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../symbols.html">Symbols &amp; Units</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../results_readme.html">Results &amp; Plots</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/theSadeQ/DIP_SMC_PSO/blob/main/docs/reference/optimization/algorithms_gradient_based_bfgs.md?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div><div class="edit-this-page">
  <a class="muted-link" href="https://github.com/theSadeQ/DIP_SMC_PSO/edit/main/docs/reference/optimization/algorithms_gradient_based_bfgs.md" title="Edit this page">
    <svg><use href="#svg-pencil"></use></svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="optimization-algorithms-gradient-based-bfgs">
<h1>optimization.algorithms.gradient_based.bfgs<a class="headerlink" href="#optimization-algorithms-gradient-based-bfgs" title="Link to this heading">¶</a></h1>
<p><strong>Source:</strong> <code class="docutils literal notranslate"><span class="pre">src\optimization\algorithms\gradient_based\bfgs.py</span></code></p>
<section id="module-overview">
<h2>Module Overview<a class="headerlink" href="#module-overview" title="Link to this heading">¶</a></h2>
<p>BFGS quasi-Newton optimization algorithm with numerical gradients.</p>
</section>
<section id="complete-source-code">
<h2>Complete Source Code<a class="headerlink" href="#complete-source-code" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="c1">#======================================================================================\\\</span>
<span class="linenos">  2</span><span class="c1">#================= src/optimization/algorithms/gradient_based/bfgs.py =================\\\</span>
<span class="linenos">  3</span><span class="c1">#======================================================================================\\\</span>
<span class="linenos">  4</span>
<span class="linenos">  5</span><span class="sd">&quot;&quot;&quot;BFGS quasi-Newton optimization algorithm with numerical gradients.&quot;&quot;&quot;</span>
<span class="linenos">  6</span>
<span class="linenos">  7</span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">annotations</span>
<span class="linenos">  8</span>
<span class="linenos">  9</span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="linenos"> 10</span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="linenos"> 11</span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="linenos"> 12</span><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="kn">from</span><span class="w"> </span><span class="nn">..base</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizationAlgorithm</span>
<span class="linenos"> 15</span><span class="kn">from</span><span class="w"> </span><span class="nn">...core.interfaces</span><span class="w"> </span><span class="kn">import</span> <span class="n">OptimizationProblem</span><span class="p">,</span> <span class="n">ParameterSpace</span><span class="p">,</span> <span class="n">OptimizationResult</span>
<span class="linenos"> 16</span><span class="kn">from</span><span class="w"> </span><span class="nn">...core.parameters</span><span class="w"> </span><span class="kn">import</span> <span class="n">ContinuousParameterSpace</span>
<span class="linenos"> 17</span>
<span class="linenos"> 18</span>
<span class="linenos"> 19</span><span class="nd">@dataclass</span>
<span class="linenos"> 20</span><span class="k">class</span><span class="w"> </span><span class="nc">BFGSConfig</span><span class="p">:</span>
<span class="linenos"> 21</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for BFGS algorithm.&quot;&quot;&quot;</span>
<span class="linenos"> 22</span>    <span class="n">max_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="linenos"> 23</span>    <span class="n">max_evaluations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="linenos"> 24</span>    <span class="n">gradient_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="linenos"> 25</span>    <span class="n">function_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-9</span>
<span class="linenos"> 26</span>    <span class="n">step_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos"> 27</span>    <span class="n">initial_step_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="linenos"> 28</span>    <span class="n">gradient_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos"> 29</span>    <span class="n">line_search_max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>
<span class="linenos"> 30</span>    <span class="n">wolfe_c1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="linenos"> 31</span>    <span class="n">wolfe_c2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="linenos"> 32</span>    <span class="n">gradient_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;central&#39;</span>
<span class="linenos"> 33</span>    <span class="n">hessian_reset_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos"> 34</span>    <span class="n">random_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 35</span>
<span class="linenos"> 36</span>
<span class="linenos"> 37</span><span class="k">class</span><span class="w"> </span><span class="nc">BFGSOptimizer</span><span class="p">(</span><span class="n">OptimizationAlgorithm</span><span class="p">):</span>
<span class="linenos"> 38</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;BFGS quasi-Newton optimization algorithm.</span>
<span class="linenos"> 39</span>
<span class="linenos"> 40</span><span class="sd">    The BFGS (Broyden-Fletcher-Goldfarb-Shanno) algorithm is a quasi-Newton</span>
<span class="linenos"> 41</span><span class="sd">    method that approximates the Hessian matrix using gradient information.</span>
<span class="linenos"> 42</span><span class="sd">    It builds up curvature information iteratively to achieve superlinear</span>
<span class="linenos"> 43</span><span class="sd">    convergence near the optimum.</span>
<span class="linenos"> 44</span>
<span class="linenos"> 45</span><span class="sd">    Features:</span>
<span class="linenos"> 46</span><span class="sd">    - Numerical gradient computation (forward, backward, central differences)</span>
<span class="linenos"> 47</span><span class="sd">    - Line search with Wolfe conditions</span>
<span class="linenos"> 48</span><span class="sd">    - Hessian approximation updates</span>
<span class="linenos"> 49</span><span class="sd">    - Boundary constraint handling</span>
<span class="linenos"> 50</span><span class="sd">    - Robust convergence criteria</span>
<span class="linenos"> 51</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 52</span>
<span class="linenos"> 53</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BFGSConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="linenos"> 54</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize BFGS algorithm.</span>
<span class="linenos"> 55</span>
<span class="linenos"> 56</span><span class="sd">        Parameters</span>
<span class="linenos"> 57</span><span class="sd">        ----------</span>
<span class="linenos"> 58</span><span class="sd">        config : BFGSConfig, optional</span>
<span class="linenos"> 59</span><span class="sd">            Algorithm configuration. If None, uses default values.</span>
<span class="linenos"> 60</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos"> 61</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos"> 62</span>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">BFGSConfig</span><span class="p">()</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span>        <span class="c1"># Initialize random number generator</span>
<span class="linenos"> 65</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 66</span>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="linenos"> 67</span>
<span class="linenos"> 68</span>        <span class="c1"># Algorithm state</span>
<span class="linenos"> 69</span>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 70</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 71</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 72</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 73</span>        <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 74</span>
<span class="linenos"> 75</span>        <span class="c1"># Current optimization state</span>
<span class="linenos"> 76</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 77</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 78</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 79</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 80</span>
<span class="linenos"> 81</span>    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 82</span>                <span class="n">problem</span><span class="p">:</span> <span class="n">OptimizationProblem</span><span class="p">,</span>
<span class="linenos"> 83</span>                <span class="n">parameter_space</span><span class="p">:</span> <span class="n">ParameterSpace</span><span class="p">,</span>
<span class="linenos"> 84</span>                <span class="n">initial_guess</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 85</span>                <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResult</span><span class="p">:</span>
<span class="linenos"> 86</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run BFGS optimization.</span>
<span class="linenos"> 87</span>
<span class="linenos"> 88</span><span class="sd">        Parameters</span>
<span class="linenos"> 89</span><span class="sd">        ----------</span>
<span class="linenos"> 90</span><span class="sd">        problem : OptimizationProblem</span>
<span class="linenos"> 91</span><span class="sd">            The optimization problem to solve</span>
<span class="linenos"> 92</span><span class="sd">        parameter_space : ParameterSpace</span>
<span class="linenos"> 93</span><span class="sd">            Parameter space defining bounds and constraints</span>
<span class="linenos"> 94</span><span class="sd">        initial_guess : np.ndarray, optional</span>
<span class="linenos"> 95</span><span class="sd">            Initial parameter guess</span>
<span class="linenos"> 96</span>
<span class="linenos"> 97</span><span class="sd">        Returns</span>
<span class="linenos"> 98</span><span class="sd">        -------</span>
<span class="linenos"> 99</span><span class="sd">        OptimizationResult</span>
<span class="linenos">100</span><span class="sd">            Optimization results</span>
<span class="linenos">101</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos">102</span>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter_space</span><span class="p">,</span> <span class="n">ContinuousParameterSpace</span><span class="p">):</span>
<span class="linenos">103</span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;BFGS currently only supports ContinuousParameterSpace&quot;</span><span class="p">)</span>
<span class="linenos">104</span>
<span class="linenos">105</span>        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span> <span class="o">=</span> <span class="n">problem</span>
<span class="linenos">106</span>        <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span> <span class="o">=</span> <span class="n">parameter_space</span>
<span class="linenos">107</span>        <span class="bp">self</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">)</span>
<span class="linenos">108</span>
<span class="linenos">109</span>        <span class="c1"># Initialize optimization</span>
<span class="linenos">110</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_optimization</span><span class="p">(</span><span class="n">initial_guess</span><span class="p">)</span>
<span class="linenos">111</span>
<span class="linenos">112</span>        <span class="c1"># Optimization loop</span>
<span class="linenos">113</span>        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_termination</span><span class="p">():</span>
<span class="linenos">114</span>            <span class="bp">self</span><span class="o">.</span><span class="n">_perform_iteration</span><span class="p">()</span>
<span class="linenos">115</span>            <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">116</span>
<span class="linenos">117</span>        <span class="c1"># Create result</span>
<span class="linenos">118</span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_result</span><span class="p">()</span>
<span class="linenos">119</span>        <span class="k">return</span> <span class="n">result</span>
<span class="linenos">120</span>
<span class="linenos">121</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="linenos">122</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize optimization state.&quot;&quot;&quot;</span>
<span class="linenos">123</span>        <span class="c1"># Set initial point</span>
<span class="linenos">124</span>        <span class="k">if</span> <span class="n">initial_guess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">125</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">initial_guess</span><span class="p">,</span>
<span class="linenos">126</span>                                   <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">127</span>                                   <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos">128</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">129</span>            <span class="c1"># Random start point within bounds</span>
<span class="linenos">130</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
<span class="linenos">131</span>                <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">132</span>                <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span>
<span class="linenos">133</span>            <span class="p">)</span>
<span class="linenos">134</span>
<span class="linenos">135</span>        <span class="c1"># Evaluate initial point</span>
<span class="linenos">136</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">)</span>
<span class="linenos">137</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">)</span>
<span class="linenos">138</span>
<span class="linenos">139</span>        <span class="c1"># Initialize inverse Hessian approximation as identity</span>
<span class="linenos">140</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">141</span>
<span class="linenos">142</span>        <span class="c1"># Initialize history</span>
<span class="linenos">143</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span>
<span class="linenos">144</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">))</span>
<span class="linenos">145</span>
<span class="linenos">146</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_perform_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">147</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform one BFGS iteration.&quot;&quot;&quot;</span>
<span class="linenos">148</span>        <span class="c1"># Compute search direction</span>
<span class="linenos">149</span>        <span class="n">search_direction</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
<span class="linenos">150</span>
<span class="linenos">151</span>        <span class="c1"># Ensure descent direction</span>
<span class="linenos">152</span>        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">search_direction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">153</span>            <span class="c1"># If not descent direction, reset Hessian and use steepest descent</span>
<span class="linenos">154</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Non-descent direction detected, resetting Hessian&quot;</span><span class="p">)</span>
<span class="linenos">155</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">156</span>            <span class="n">search_direction</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
<span class="linenos">157</span>
<span class="linenos">158</span>        <span class="c1"># Line search</span>
<span class="linenos">159</span>        <span class="n">step_size</span><span class="p">,</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_line_search</span><span class="p">(</span>
<span class="linenos">160</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">,</span> <span class="n">search_direction</span>
<span class="linenos">161</span>        <span class="p">)</span>
<span class="linenos">162</span>
<span class="linenos">163</span>        <span class="k">if</span> <span class="n">step_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">new_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">164</span>            <span class="c1"># Line search failed</span>
<span class="linenos">165</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Line search failed&quot;</span><span class="p">)</span>
<span class="linenos">166</span>            <span class="k">return</span>
<span class="linenos">167</span>
<span class="linenos">168</span>        <span class="c1"># Compute new gradient</span>
<span class="linenos">169</span>        <span class="n">new_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
<span class="linenos">170</span>
<span class="linenos">171</span>        <span class="c1"># BFGS update</span>
<span class="linenos">172</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_update_hessian_inverse</span><span class="p">(</span>
<span class="linenos">173</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">,</span> <span class="n">new_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">,</span> <span class="n">new_gradient</span>
<span class="linenos">174</span>        <span class="p">)</span>
<span class="linenos">175</span>
<span class="linenos">176</span>        <span class="c1"># Update current state</span>
<span class="linenos">177</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">new_x</span>
<span class="linenos">178</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="o">=</span> <span class="n">new_f</span>
<span class="linenos">179</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="o">=</span> <span class="n">new_gradient</span>
<span class="linenos">180</span>
<span class="linenos">181</span>        <span class="c1"># Update history</span>
<span class="linenos">182</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span>
<span class="linenos">183</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">))</span>
<span class="linenos">184</span>        <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_size</span><span class="p">)</span>
<span class="linenos">185</span>
<span class="linenos">186</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="linenos">187</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute numerical gradient using finite differences.&quot;&quot;&quot;</span>
<span class="linenos">188</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">189</span>        <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_epsilon</span>
<span class="linenos">190</span>
<span class="linenos">191</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span> <span class="o">==</span> <span class="s1">&#39;forward&#39;</span><span class="p">:</span>
<span class="linenos">192</span>            <span class="n">f_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">193</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">194</span>                <span class="n">x_plus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">195</span>                <span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">196</span>                <span class="n">f_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span>
<span class="linenos">197</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_plus</span> <span class="o">-</span> <span class="n">f_x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">198</span>
<span class="linenos">199</span>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span> <span class="o">==</span> <span class="s1">&#39;backward&#39;</span><span class="p">:</span>
<span class="linenos">200</span>            <span class="n">f_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">201</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">202</span>                <span class="n">x_minus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">203</span>                <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">204</span>                <span class="n">f_minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_minus</span><span class="p">)</span>
<span class="linenos">205</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_x</span> <span class="o">-</span> <span class="n">f_minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">206</span>
<span class="linenos">207</span>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># central differences (default)</span>
<span class="linenos">208</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">209</span>                <span class="n">x_plus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">210</span>                <span class="n">x_minus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">211</span>
<span class="linenos">212</span>                <span class="n">h_plus</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">213</span>                <span class="n">h_minus</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">214</span>
<span class="linenos">215</span>                <span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">h_plus</span>
<span class="linenos">216</span>                <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">h_minus</span>
<span class="linenos">217</span>
<span class="linenos">218</span>                <span class="n">f_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span>
<span class="linenos">219</span>                <span class="n">f_minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_minus</span><span class="p">)</span>
<span class="linenos">220</span>
<span class="linenos">221</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_plus</span> <span class="o">-</span> <span class="n">f_minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">h_plus</span> <span class="o">+</span> <span class="n">h_minus</span><span class="p">)</span>
<span class="linenos">222</span>
<span class="linenos">223</span>        <span class="k">return</span> <span class="n">gradient</span>
<span class="linenos">224</span>
<span class="linenos">225</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_hessian_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos">226</span>                               <span class="n">x_old</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">227</span>                               <span class="n">x_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">228</span>                               <span class="n">grad_old</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">229</span>                               <span class="n">grad_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="linenos">230</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Update inverse Hessian approximation using BFGS formula.&quot;&quot;&quot;</span>
<span class="linenos">231</span>        <span class="n">s</span> <span class="o">=</span> <span class="n">x_new</span> <span class="o">-</span> <span class="n">x_old</span>  <span class="c1"># Step vector</span>
<span class="linenos">232</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">grad_new</span> <span class="o">-</span> <span class="n">grad_old</span>  <span class="c1"># Gradient change</span>
<span class="linenos">233</span>
<span class="linenos">234</span>        <span class="n">sy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="linenos">235</span>
<span class="linenos">236</span>        <span class="c1"># Check curvature condition</span>
<span class="linenos">237</span>        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sy</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hessian_reset_threshold</span><span class="p">:</span>
<span class="linenos">238</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Curvature condition violated, resetting Hessian&quot;</span><span class="p">)</span>
<span class="linenos">239</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">240</span>            <span class="k">return</span>
<span class="linenos">241</span>
<span class="linenos">242</span>        <span class="c1"># BFGS update formula</span>
<span class="linenos">243</span>        <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">sy</span>
<span class="linenos">244</span>        <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">245</span>
<span class="linenos">246</span>        <span class="c1"># Two-step BFGS update</span>
<span class="linenos">247</span>        <span class="n">V</span> <span class="o">=</span> <span class="n">I</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="linenos">248</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="n">V</span> <span class="o">+</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="linenos">249</span>
<span class="linenos">250</span>        <span class="c1"># Ensure positive definiteness</span>
<span class="linenos">251</span>        <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">252</span>        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">eigenvals</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
<span class="linenos">253</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Hessian approximation not positive definite, regularizing&quot;</span><span class="p">)</span>
<span class="linenos">254</span>            <span class="n">min_eigenval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span>
<span class="linenos">255</span>            <span class="n">regularization</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_eigenval</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
<span class="linenos">256</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">+=</span> <span class="n">regularization</span> <span class="o">*</span> <span class="n">I</span>
<span class="linenos">257</span>
<span class="linenos">258</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_line_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos">259</span>                    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">260</span>                    <span class="n">f</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="linenos">261</span>                    <span class="n">gradient</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">262</span>                    <span class="n">direction</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="linenos">263</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Line search with Wolfe conditions.&quot;&quot;&quot;</span>
<span class="linenos">264</span>        <span class="c1"># Initial step size</span>
<span class="linenos">265</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initial_step_size</span>
<span class="linenos">266</span>        <span class="n">gradient_dot_direction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">direction</span><span class="p">)</span>
<span class="linenos">267</span>
<span class="linenos">268</span>        <span class="c1"># Check if direction is descent</span>
<span class="linenos">269</span>        <span class="k">if</span> <span class="n">gradient_dot_direction</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">270</span>            <span class="k">return</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
<span class="linenos">271</span>
<span class="linenos">272</span>        <span class="c1"># Backtracking line search</span>
<span class="linenos">273</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">line_search_max_iter</span><span class="p">):</span>
<span class="linenos">274</span>            <span class="c1"># Compute trial point</span>
<span class="linenos">275</span>            <span class="n">x_trial</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">direction</span>
<span class="linenos">276</span>
<span class="linenos">277</span>            <span class="c1"># Apply bounds</span>
<span class="linenos">278</span>            <span class="n">x_trial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_trial</span><span class="p">,</span>
<span class="linenos">279</span>                             <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">280</span>                             <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos">281</span>
<span class="linenos">282</span>            <span class="c1"># Evaluate trial point</span>
<span class="linenos">283</span>            <span class="n">f_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">284</span>
<span class="linenos">285</span>            <span class="c1"># Check Armijo condition (sufficient decrease)</span>
<span class="linenos">286</span>            <span class="n">armijo_condition</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_trial</span> <span class="o">&lt;=</span> <span class="n">f</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c1</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">gradient_dot_direction</span><span class="p">)</span>
<span class="linenos">287</span>
<span class="linenos">288</span>            <span class="k">if</span> <span class="n">armijo_condition</span><span class="p">:</span>
<span class="linenos">289</span>                <span class="c1"># Check curvature condition if needed</span>
<span class="linenos">290</span>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c2</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
<span class="linenos">291</span>                    <span class="n">gradient_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">292</span>                    <span class="n">curvature_condition</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gradient_trial</span><span class="p">,</span> <span class="n">direction</span><span class="p">)</span> <span class="o">&gt;=</span>
<span class="linenos">293</span>                                         <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c2</span> <span class="o">*</span> <span class="n">gradient_dot_direction</span><span class="p">)</span>
<span class="linenos">294</span>
<span class="linenos">295</span>                    <span class="k">if</span> <span class="n">curvature_condition</span><span class="p">:</span>
<span class="linenos">296</span>                        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">297</span>                <span class="k">else</span><span class="p">:</span>
<span class="linenos">298</span>                    <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">299</span>
<span class="linenos">300</span>            <span class="c1"># Reduce step size</span>
<span class="linenos">301</span>            <span class="n">alpha</span> <span class="o">*=</span> <span class="mf">0.5</span>
<span class="linenos">302</span>
<span class="linenos">303</span>            <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mf">1e-16</span><span class="p">:</span>
<span class="linenos">304</span>                <span class="k">break</span>
<span class="linenos">305</span>
<span class="linenos">306</span>        <span class="c1"># If line search failed, try smaller step</span>
<span class="linenos">307</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos">308</span>        <span class="n">x_trial</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">direction</span>
<span class="linenos">309</span>        <span class="n">x_trial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_trial</span><span class="p">,</span>
<span class="linenos">310</span>                         <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">311</span>                         <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos">312</span>        <span class="n">f_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">313</span>
<span class="linenos">314</span>        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">315</span>
<span class="linenos">316</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_safe_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">317</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely evaluate objective function.&quot;&quot;&quot;</span>
<span class="linenos">318</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">319</span>            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">320</span>            <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">321</span>            <span class="k">return</span> <span class="n">value</span>
<span class="linenos">322</span>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="linenos">323</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">324</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">325</span>
<span class="linenos">326</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_check_termination</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="linenos">327</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Check termination conditions.&quot;&quot;&quot;</span>
<span class="linenos">328</span>        <span class="c1"># Maximum iterations</span>
<span class="linenos">329</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_iterations</span><span class="p">:</span>
<span class="linenos">330</span>            <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">331</span>
<span class="linenos">332</span>        <span class="c1"># Maximum evaluations</span>
<span class="linenos">333</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_evaluations</span><span class="p">:</span>
<span class="linenos">334</span>            <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">335</span>
<span class="linenos">336</span>        <span class="c1"># Gradient norm tolerance</span>
<span class="linenos">337</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">338</span>            <span class="n">gradient_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span>
<span class="linenos">339</span>            <span class="k">if</span> <span class="n">gradient_norm</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_tolerance</span><span class="p">:</span>
<span class="linenos">340</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">341</span>
<span class="linenos">342</span>        <span class="c1"># Function tolerance</span>
<span class="linenos">343</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">344</span>            <span class="n">function_change</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="linenos">345</span>            <span class="k">if</span> <span class="n">function_change</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">function_tolerance</span><span class="p">:</span>
<span class="linenos">346</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">347</span>
<span class="linenos">348</span>        <span class="c1"># Step tolerance</span>
<span class="linenos">349</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">350</span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">step_tolerance</span><span class="p">:</span>
<span class="linenos">351</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">352</span>
<span class="linenos">353</span>        <span class="k">return</span> <span class="kc">False</span>
<span class="linenos">354</span>
<span class="linenos">355</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_create_result</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResult</span><span class="p">:</span>
<span class="linenos">356</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Create optimization result.&quot;&quot;&quot;</span>
<span class="linenos">357</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">358</span>            <span class="k">return</span> <span class="n">OptimizationResult</span><span class="p">(</span>
<span class="linenos">359</span>                <span class="n">best_parameters</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
<span class="linenos">360</span>                <span class="n">best_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span>
<span class="linenos">361</span>                <span class="n">n_evaluations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">362</span>                <span class="n">convergence_history</span><span class="o">=</span><span class="p">[],</span>
<span class="linenos">363</span>                <span class="n">success</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">364</span>                <span class="n">algorithm_info</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">}</span>
<span class="linenos">365</span>            <span class="p">)</span>
<span class="linenos">366</span>
<span class="linenos">367</span>        <span class="k">return</span> <span class="n">OptimizationResult</span><span class="p">(</span>
<span class="linenos">368</span>            <span class="n">best_parameters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
<span class="linenos">369</span>            <span class="n">best_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span>
<span class="linenos">370</span>            <span class="n">n_evaluations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">371</span>            <span class="n">convergence_history</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
<span class="linenos">372</span>            <span class="n">success</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
<span class="linenos">373</span>                    <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span> <span class="ow">and</span>
<span class="linenos">374</span>                    <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_tolerance</span><span class="p">),</span>
<span class="linenos">375</span>            <span class="n">algorithm_info</span><span class="o">=</span><span class="p">{</span>
<span class="linenos">376</span>                <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">,</span>
<span class="linenos">377</span>                <span class="s1">&#39;iterations&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="linenos">378</span>                <span class="s1">&#39;final_gradient_norm&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span>
<span class="linenos">379</span>                <span class="s1">&#39;gradient_method&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span><span class="p">,</span>
<span class="linenos">380</span>                <span class="s1">&#39;hessian_condition_number&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_hessian_condition_number</span><span class="p">(),</span>
<span class="linenos">381</span>                <span class="s1">&#39;average_step_size&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="linenos">382</span>            <span class="p">}</span>
<span class="linenos">383</span>        <span class="p">)</span>
<span class="linenos">384</span>
<span class="linenos">385</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_hessian_condition_number</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">386</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute condition number of Hessian approximation.&quot;&quot;&quot;</span>
<span class="linenos">387</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">388</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">389</span>
<span class="linenos">390</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">391</span>            <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">392</span>            <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">eigenvals</span><span class="p">[</span><span class="n">eigenvals</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Only positive eigenvalues</span>
<span class="linenos">393</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">394</span>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span>
<span class="linenos">395</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">396</span>                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">397</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">398</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">399</span>
<span class="linenos">400</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_optimization_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="linenos">401</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get detailed optimization information.&quot;&quot;&quot;</span>
<span class="linenos">402</span>        <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">403</span>            <span class="s1">&#39;iteration&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="linenos">404</span>            <span class="s1">&#39;n_evaluations&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">405</span>            <span class="s1">&#39;current_function_value&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span>
<span class="linenos">406</span>            <span class="s1">&#39;gradient_norm&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">407</span>            <span class="s1">&#39;hessian_condition_number&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_hessian_condition_number</span><span class="p">(),</span>
<span class="linenos">408</span>            <span class="s1">&#39;convergence_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_convergence_rate</span><span class="p">()</span>
<span class="linenos">409</span>        <span class="p">}</span>
<span class="linenos">410</span>
<span class="linenos">411</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">412</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;current_parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="linenos">413</span>
<span class="linenos">414</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">:</span>
<span class="linenos">415</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;last_step_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos">416</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;average_step_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span>
<span class="linenos">417</span>
<span class="linenos">418</span>        <span class="k">return</span> <span class="n">info</span>
<span class="linenos">419</span>
<span class="linenos">420</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_estimate_convergence_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">421</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimate convergence rate from function value history.&quot;&quot;&quot;</span>
<span class="linenos">422</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
<span class="linenos">423</span>            <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">424</span>
<span class="linenos">425</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">426</span>            <span class="c1"># Estimate linear convergence rate</span>
<span class="linenos">427</span>            <span class="n">recent_history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
<span class="linenos">428</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">recent_history</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># All values the same</span>
<span class="linenos">429</span>                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>  <span class="c1"># Already converged</span>
<span class="linenos">430</span>
<span class="linenos">431</span>            <span class="c1"># Compute successive ratios</span>
<span class="linenos">432</span>            <span class="n">ratios</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos">433</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">recent_history</span><span class="p">)):</span>
<span class="linenos">434</span>                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">1e-12</span><span class="p">:</span>
<span class="linenos">435</span>                    <span class="n">ratio</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos">436</span>                    <span class="n">ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
<span class="linenos">437</span>
<span class="linenos">438</span>            <span class="k">if</span> <span class="n">ratios</span><span class="p">:</span>
<span class="linenos">439</span>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span>
<span class="linenos">440</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">441</span>                <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">442</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">443</span>            <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">444</span>
<span class="linenos">445</span>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_hessian</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">446</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset Hessian approximation to identity.&quot;&quot;&quot;</span>
<span class="linenos">447</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dimension</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">448</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">449</span>
<span class="linenos">450</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_hessian_eigenvalues</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="linenos">451</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get eigenvalues of current Hessian approximation.&quot;&quot;&quot;</span>
<span class="linenos">452</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">453</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="linenos">454</span>
<span class="linenos">455</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">456</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">457</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">458</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="linenos">459</span>
<span class="linenos">460</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_search_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="linenos">461</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get current search direction.&quot;&quot;&quot;</span>
<span class="linenos">462</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">463</span>            <span class="k">return</span> <span class="kc">None</span>
<span class="linenos">464</span>
<span class="linenos">465</span>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Link to this heading">¶</a></h2>
<section id="bfgsconfig">
<h3><code class="docutils literal notranslate"><span class="pre">BFGSConfig</span></code><a class="headerlink" href="#bfgsconfig" title="Link to this heading">¶</a></h3>
<p>Configuration for BFGS algorithm.</p>
<section id="source-code">
<h4>Source Code<a class="headerlink" href="#source-code" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="nd">@dataclass</span>
<span class="linenos"> 2</span><span class="k">class</span><span class="w"> </span><span class="nc">BFGSConfig</span><span class="p">:</span>
<span class="linenos"> 3</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for BFGS algorithm.&quot;&quot;&quot;</span>
<span class="linenos"> 4</span>    <span class="n">max_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="linenos"> 5</span>    <span class="n">max_evaluations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="linenos"> 6</span>    <span class="n">gradient_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="linenos"> 7</span>    <span class="n">function_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-9</span>
<span class="linenos"> 8</span>    <span class="n">step_tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos"> 9</span>    <span class="n">initial_step_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="linenos">10</span>    <span class="n">gradient_epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos">11</span>    <span class="n">line_search_max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>
<span class="linenos">12</span>    <span class="n">wolfe_c1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="linenos">13</span>    <span class="n">wolfe_c2</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="linenos">14</span>    <span class="n">gradient_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;central&#39;</span>
<span class="linenos">15</span>    <span class="n">hessian_reset_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos">16</span>    <span class="n">random_seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="bfgsoptimizer">
<h3><code class="docutils literal notranslate"><span class="pre">BFGSOptimizer</span></code><a class="headerlink" href="#bfgsoptimizer" title="Link to this heading">¶</a></h3>
<p><strong>Inherits from:</strong> <code class="docutils literal notranslate"><span class="pre">OptimizationAlgorithm</span></code></p>
<p>BFGS quasi-Newton optimization algorithm.</p>
<p>The BFGS (Broyden-Fletcher-Goldfarb-Shanno) algorithm is a quasi-Newton
method that approximates the Hessian matrix using gradient information.
It builds up curvature information iteratively to achieve superlinear
convergence near the optimum.</p>
<p>Features:</p>
<ul class="simple">
<li><p>Numerical gradient computation (forward, backward, central differences)</p></li>
<li><p>Line search with Wolfe conditions</p></li>
<li><p>Hessian approximation updates</p></li>
<li><p>Boundary constraint handling</p></li>
<li><p>Robust convergence criteria</p></li>
</ul>
<section id="id1">
<h4>Source Code<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="k">class</span><span class="w"> </span><span class="nc">BFGSOptimizer</span><span class="p">(</span><span class="n">OptimizationAlgorithm</span><span class="p">):</span>
<span class="linenos">  2</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;BFGS quasi-Newton optimization algorithm.</span>
<span class="linenos">  3</span>
<span class="linenos">  4</span><span class="sd">    The BFGS (Broyden-Fletcher-Goldfarb-Shanno) algorithm is a quasi-Newton</span>
<span class="linenos">  5</span><span class="sd">    method that approximates the Hessian matrix using gradient information.</span>
<span class="linenos">  6</span><span class="sd">    It builds up curvature information iteratively to achieve superlinear</span>
<span class="linenos">  7</span><span class="sd">    convergence near the optimum.</span>
<span class="linenos">  8</span>
<span class="linenos">  9</span><span class="sd">    Features:</span>
<span class="linenos"> 10</span><span class="sd">    - Numerical gradient computation (forward, backward, central differences)</span>
<span class="linenos"> 11</span><span class="sd">    - Line search with Wolfe conditions</span>
<span class="linenos"> 12</span><span class="sd">    - Hessian approximation updates</span>
<span class="linenos"> 13</span><span class="sd">    - Boundary constraint handling</span>
<span class="linenos"> 14</span><span class="sd">    - Robust convergence criteria</span>
<span class="linenos"> 15</span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos"> 16</span>
<span class="linenos"> 17</span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BFGSConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="linenos"> 18</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize BFGS algorithm.</span>
<span class="linenos"> 19</span>
<span class="linenos"> 20</span><span class="sd">        Parameters</span>
<span class="linenos"> 21</span><span class="sd">        ----------</span>
<span class="linenos"> 22</span><span class="sd">        config : BFGSConfig, optional</span>
<span class="linenos"> 23</span><span class="sd">            Algorithm configuration. If None, uses default values.</span>
<span class="linenos"> 24</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos"> 25</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos"> 26</span>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">BFGSConfig</span><span class="p">()</span>
<span class="linenos"> 27</span>
<span class="linenos"> 28</span>        <span class="c1"># Initialize random number generator</span>
<span class="linenos"> 29</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">random_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 30</span>            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="linenos"> 31</span>
<span class="linenos"> 32</span>        <span class="c1"># Algorithm state</span>
<span class="linenos"> 33</span>        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 34</span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 35</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 36</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 37</span>        <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 38</span>
<span class="linenos"> 39</span>        <span class="c1"># Current optimization state</span>
<span class="linenos"> 40</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 41</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 42</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 43</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos"> 44</span>
<span class="linenos"> 45</span>    <span class="k">def</span><span class="w"> </span><span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos"> 46</span>                <span class="n">problem</span><span class="p">:</span> <span class="n">OptimizationProblem</span><span class="p">,</span>
<span class="linenos"> 47</span>                <span class="n">parameter_space</span><span class="p">:</span> <span class="n">ParameterSpace</span><span class="p">,</span>
<span class="linenos"> 48</span>                <span class="n">initial_guess</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos"> 49</span>                <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResult</span><span class="p">:</span>
<span class="linenos"> 50</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run BFGS optimization.</span>
<span class="linenos"> 51</span>
<span class="linenos"> 52</span><span class="sd">        Parameters</span>
<span class="linenos"> 53</span><span class="sd">        ----------</span>
<span class="linenos"> 54</span><span class="sd">        problem : OptimizationProblem</span>
<span class="linenos"> 55</span><span class="sd">            The optimization problem to solve</span>
<span class="linenos"> 56</span><span class="sd">        parameter_space : ParameterSpace</span>
<span class="linenos"> 57</span><span class="sd">            Parameter space defining bounds and constraints</span>
<span class="linenos"> 58</span><span class="sd">        initial_guess : np.ndarray, optional</span>
<span class="linenos"> 59</span><span class="sd">            Initial parameter guess</span>
<span class="linenos"> 60</span>
<span class="linenos"> 61</span><span class="sd">        Returns</span>
<span class="linenos"> 62</span><span class="sd">        -------</span>
<span class="linenos"> 63</span><span class="sd">        OptimizationResult</span>
<span class="linenos"> 64</span><span class="sd">            Optimization results</span>
<span class="linenos"> 65</span><span class="sd">        &quot;&quot;&quot;</span>
<span class="linenos"> 66</span>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameter_space</span><span class="p">,</span> <span class="n">ContinuousParameterSpace</span><span class="p">):</span>
<span class="linenos"> 67</span>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;BFGS currently only supports ContinuousParameterSpace&quot;</span><span class="p">)</span>
<span class="linenos"> 68</span>
<span class="linenos"> 69</span>        <span class="bp">self</span><span class="o">.</span><span class="n">problem</span> <span class="o">=</span> <span class="n">problem</span>
<span class="linenos"> 70</span>        <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span> <span class="o">=</span> <span class="n">parameter_space</span>
<span class="linenos"> 71</span>        <span class="bp">self</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">)</span>
<span class="linenos"> 72</span>
<span class="linenos"> 73</span>        <span class="c1"># Initialize optimization</span>
<span class="linenos"> 74</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_optimization</span><span class="p">(</span><span class="n">initial_guess</span><span class="p">)</span>
<span class="linenos"> 75</span>
<span class="linenos"> 76</span>        <span class="c1"># Optimization loop</span>
<span class="linenos"> 77</span>        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_termination</span><span class="p">():</span>
<span class="linenos"> 78</span>            <span class="bp">self</span><span class="o">.</span><span class="n">_perform_iteration</span><span class="p">()</span>
<span class="linenos"> 79</span>            <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos"> 80</span>
<span class="linenos"> 81</span>        <span class="c1"># Create result</span>
<span class="linenos"> 82</span>        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_result</span><span class="p">()</span>
<span class="linenos"> 83</span>        <span class="k">return</span> <span class="n">result</span>
<span class="linenos"> 84</span>
<span class="linenos"> 85</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_initialize_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initial_guess</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="linenos"> 86</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize optimization state.&quot;&quot;&quot;</span>
<span class="linenos"> 87</span>        <span class="c1"># Set initial point</span>
<span class="linenos"> 88</span>        <span class="k">if</span> <span class="n">initial_guess</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos"> 89</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">initial_guess</span><span class="p">,</span>
<span class="linenos"> 90</span>                                   <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos"> 91</span>                                   <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos"> 92</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos"> 93</span>            <span class="c1"># Random start point within bounds</span>
<span class="linenos"> 94</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
<span class="linenos"> 95</span>                <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos"> 96</span>                <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span>
<span class="linenos"> 97</span>            <span class="p">)</span>
<span class="linenos"> 98</span>
<span class="linenos"> 99</span>        <span class="c1"># Evaluate initial point</span>
<span class="linenos">100</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">)</span>
<span class="linenos">101</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">)</span>
<span class="linenos">102</span>
<span class="linenos">103</span>        <span class="c1"># Initialize inverse Hessian approximation as identity</span>
<span class="linenos">104</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">105</span>
<span class="linenos">106</span>        <span class="c1"># Initialize history</span>
<span class="linenos">107</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span>
<span class="linenos">108</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">))</span>
<span class="linenos">109</span>
<span class="linenos">110</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_perform_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">111</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform one BFGS iteration.&quot;&quot;&quot;</span>
<span class="linenos">112</span>        <span class="c1"># Compute search direction</span>
<span class="linenos">113</span>        <span class="n">search_direction</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
<span class="linenos">114</span>
<span class="linenos">115</span>        <span class="c1"># Ensure descent direction</span>
<span class="linenos">116</span>        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">search_direction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">117</span>            <span class="c1"># If not descent direction, reset Hessian and use steepest descent</span>
<span class="linenos">118</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Non-descent direction detected, resetting Hessian&quot;</span><span class="p">)</span>
<span class="linenos">119</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">120</span>            <span class="n">search_direction</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
<span class="linenos">121</span>
<span class="linenos">122</span>        <span class="c1"># Line search</span>
<span class="linenos">123</span>        <span class="n">step_size</span><span class="p">,</span> <span class="n">new_x</span><span class="p">,</span> <span class="n">new_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_line_search</span><span class="p">(</span>
<span class="linenos">124</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">,</span> <span class="n">search_direction</span>
<span class="linenos">125</span>        <span class="p">)</span>
<span class="linenos">126</span>
<span class="linenos">127</span>        <span class="k">if</span> <span class="n">step_size</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">new_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">128</span>            <span class="c1"># Line search failed</span>
<span class="linenos">129</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Line search failed&quot;</span><span class="p">)</span>
<span class="linenos">130</span>            <span class="k">return</span>
<span class="linenos">131</span>
<span class="linenos">132</span>        <span class="c1"># Compute new gradient</span>
<span class="linenos">133</span>        <span class="n">new_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
<span class="linenos">134</span>
<span class="linenos">135</span>        <span class="c1"># BFGS update</span>
<span class="linenos">136</span>        <span class="bp">self</span><span class="o">.</span><span class="n">_update_hessian_inverse</span><span class="p">(</span>
<span class="linenos">137</span>            <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="p">,</span> <span class="n">new_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">,</span> <span class="n">new_gradient</span>
<span class="linenos">138</span>        <span class="p">)</span>
<span class="linenos">139</span>
<span class="linenos">140</span>        <span class="c1"># Update current state</span>
<span class="linenos">141</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="o">=</span> <span class="n">new_x</span>
<span class="linenos">142</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="o">=</span> <span class="n">new_f</span>
<span class="linenos">143</span>        <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="o">=</span> <span class="n">new_gradient</span>
<span class="linenos">144</span>
<span class="linenos">145</span>        <span class="c1"># Update history</span>
<span class="linenos">146</span>        <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span>
<span class="linenos">147</span>        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_norm_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">))</span>
<span class="linenos">148</span>        <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_size</span><span class="p">)</span>
<span class="linenos">149</span>
<span class="linenos">150</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_numerical_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="linenos">151</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute numerical gradient using finite differences.&quot;&quot;&quot;</span>
<span class="linenos">152</span>        <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">153</span>        <span class="n">epsilon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_epsilon</span>
<span class="linenos">154</span>
<span class="linenos">155</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span> <span class="o">==</span> <span class="s1">&#39;forward&#39;</span><span class="p">:</span>
<span class="linenos">156</span>            <span class="n">f_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">157</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">158</span>                <span class="n">x_plus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">159</span>                <span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">160</span>                <span class="n">f_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span>
<span class="linenos">161</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_plus</span> <span class="o">-</span> <span class="n">f_x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">162</span>
<span class="linenos">163</span>        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span> <span class="o">==</span> <span class="s1">&#39;backward&#39;</span><span class="p">:</span>
<span class="linenos">164</span>            <span class="n">f_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">165</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">166</span>                <span class="n">x_minus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">167</span>                <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">168</span>                <span class="n">f_minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_minus</span><span class="p">)</span>
<span class="linenos">169</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_x</span> <span class="o">-</span> <span class="n">f_minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">170</span>
<span class="linenos">171</span>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># central differences (default)</span>
<span class="linenos">172</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">):</span>
<span class="linenos">173</span>                <span class="n">x_plus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">174</span>                <span class="n">x_minus</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="linenos">175</span>
<span class="linenos">176</span>                <span class="n">h_plus</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">177</span>                <span class="n">h_minus</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="linenos">178</span>
<span class="linenos">179</span>                <span class="n">x_plus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">h_plus</span>
<span class="linenos">180</span>                <span class="n">x_minus</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">h_minus</span>
<span class="linenos">181</span>
<span class="linenos">182</span>                <span class="n">f_plus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span>
<span class="linenos">183</span>                <span class="n">f_minus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_minus</span><span class="p">)</span>
<span class="linenos">184</span>
<span class="linenos">185</span>                <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_plus</span> <span class="o">-</span> <span class="n">f_minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">h_plus</span> <span class="o">+</span> <span class="n">h_minus</span><span class="p">)</span>
<span class="linenos">186</span>
<span class="linenos">187</span>        <span class="k">return</span> <span class="n">gradient</span>
<span class="linenos">188</span>
<span class="linenos">189</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_update_hessian_inverse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos">190</span>                               <span class="n">x_old</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">191</span>                               <span class="n">x_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">192</span>                               <span class="n">grad_old</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">193</span>                               <span class="n">grad_new</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
<span class="linenos">194</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Update inverse Hessian approximation using BFGS formula.&quot;&quot;&quot;</span>
<span class="linenos">195</span>        <span class="n">s</span> <span class="o">=</span> <span class="n">x_new</span> <span class="o">-</span> <span class="n">x_old</span>  <span class="c1"># Step vector</span>
<span class="linenos">196</span>        <span class="n">y</span> <span class="o">=</span> <span class="n">grad_new</span> <span class="o">-</span> <span class="n">grad_old</span>  <span class="c1"># Gradient change</span>
<span class="linenos">197</span>
<span class="linenos">198</span>        <span class="n">sy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="linenos">199</span>
<span class="linenos">200</span>        <span class="c1"># Check curvature condition</span>
<span class="linenos">201</span>        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sy</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hessian_reset_threshold</span><span class="p">:</span>
<span class="linenos">202</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Curvature condition violated, resetting Hessian&quot;</span><span class="p">)</span>
<span class="linenos">203</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">204</span>            <span class="k">return</span>
<span class="linenos">205</span>
<span class="linenos">206</span>        <span class="c1"># BFGS update formula</span>
<span class="linenos">207</span>        <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">sy</span>
<span class="linenos">208</span>        <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">209</span>
<span class="linenos">210</span>        <span class="c1"># Two-step BFGS update</span>
<span class="linenos">211</span>        <span class="n">V</span> <span class="o">=</span> <span class="n">I</span> <span class="o">-</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="linenos">212</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="n">V</span> <span class="o">+</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="linenos">213</span>
<span class="linenos">214</span>        <span class="c1"># Ensure positive definiteness</span>
<span class="linenos">215</span>        <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">216</span>        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">eigenvals</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
<span class="linenos">217</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Hessian approximation not positive definite, regularizing&quot;</span><span class="p">)</span>
<span class="linenos">218</span>            <span class="n">min_eigenval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span>
<span class="linenos">219</span>            <span class="n">regularization</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_eigenval</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span>
<span class="linenos">220</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">+=</span> <span class="n">regularization</span> <span class="o">*</span> <span class="n">I</span>
<span class="linenos">221</span>
<span class="linenos">222</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_line_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<span class="linenos">223</span>                    <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">224</span>                    <span class="n">f</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="linenos">225</span>                    <span class="n">gradient</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="linenos">226</span>                    <span class="n">direction</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="linenos">227</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Line search with Wolfe conditions.&quot;&quot;&quot;</span>
<span class="linenos">228</span>        <span class="c1"># Initial step size</span>
<span class="linenos">229</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initial_step_size</span>
<span class="linenos">230</span>        <span class="n">gradient_dot_direction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">direction</span><span class="p">)</span>
<span class="linenos">231</span>
<span class="linenos">232</span>        <span class="c1"># Check if direction is descent</span>
<span class="linenos">233</span>        <span class="k">if</span> <span class="n">gradient_dot_direction</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">234</span>            <span class="k">return</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
<span class="linenos">235</span>
<span class="linenos">236</span>        <span class="c1"># Backtracking line search</span>
<span class="linenos">237</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">line_search_max_iter</span><span class="p">):</span>
<span class="linenos">238</span>            <span class="c1"># Compute trial point</span>
<span class="linenos">239</span>            <span class="n">x_trial</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">direction</span>
<span class="linenos">240</span>
<span class="linenos">241</span>            <span class="c1"># Apply bounds</span>
<span class="linenos">242</span>            <span class="n">x_trial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_trial</span><span class="p">,</span>
<span class="linenos">243</span>                             <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">244</span>                             <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos">245</span>
<span class="linenos">246</span>            <span class="c1"># Evaluate trial point</span>
<span class="linenos">247</span>            <span class="n">f_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">248</span>
<span class="linenos">249</span>            <span class="c1"># Check Armijo condition (sufficient decrease)</span>
<span class="linenos">250</span>            <span class="n">armijo_condition</span> <span class="o">=</span> <span class="p">(</span><span class="n">f_trial</span> <span class="o">&lt;=</span> <span class="n">f</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c1</span> <span class="o">*</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">gradient_dot_direction</span><span class="p">)</span>
<span class="linenos">251</span>
<span class="linenos">252</span>            <span class="k">if</span> <span class="n">armijo_condition</span><span class="p">:</span>
<span class="linenos">253</span>                <span class="c1"># Check curvature condition if needed</span>
<span class="linenos">254</span>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c2</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
<span class="linenos">255</span>                    <span class="n">gradient_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_numerical_gradient</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">256</span>                    <span class="n">curvature_condition</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">gradient_trial</span><span class="p">,</span> <span class="n">direction</span><span class="p">)</span> <span class="o">&gt;=</span>
<span class="linenos">257</span>                                         <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">wolfe_c2</span> <span class="o">*</span> <span class="n">gradient_dot_direction</span><span class="p">)</span>
<span class="linenos">258</span>
<span class="linenos">259</span>                    <span class="k">if</span> <span class="n">curvature_condition</span><span class="p">:</span>
<span class="linenos">260</span>                        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">261</span>                <span class="k">else</span><span class="p">:</span>
<span class="linenos">262</span>                    <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">263</span>
<span class="linenos">264</span>            <span class="c1"># Reduce step size</span>
<span class="linenos">265</span>            <span class="n">alpha</span> <span class="o">*=</span> <span class="mf">0.5</span>
<span class="linenos">266</span>
<span class="linenos">267</span>            <span class="k">if</span> <span class="n">alpha</span> <span class="o">&lt;</span> <span class="mf">1e-16</span><span class="p">:</span>
<span class="linenos">268</span>                <span class="k">break</span>
<span class="linenos">269</span>
<span class="linenos">270</span>        <span class="c1"># If line search failed, try smaller step</span>
<span class="linenos">271</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="linenos">272</span>        <span class="n">x_trial</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">direction</span>
<span class="linenos">273</span>        <span class="n">x_trial</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_trial</span><span class="p">,</span>
<span class="linenos">274</span>                         <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">lower_bounds</span><span class="p">,</span>
<span class="linenos">275</span>                         <span class="bp">self</span><span class="o">.</span><span class="n">parameter_space</span><span class="o">.</span><span class="n">upper_bounds</span><span class="p">)</span>
<span class="linenos">276</span>        <span class="n">f_trial</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_evaluate</span><span class="p">(</span><span class="n">x_trial</span><span class="p">)</span>
<span class="linenos">277</span>
<span class="linenos">278</span>        <span class="k">return</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">x_trial</span><span class="p">,</span> <span class="n">f_trial</span>
<span class="linenos">279</span>
<span class="linenos">280</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_safe_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">281</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Safely evaluate objective function.&quot;&quot;&quot;</span>
<span class="linenos">282</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">283</span>            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">problem</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos">284</span>            <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="linenos">285</span>            <span class="k">return</span> <span class="n">value</span>
<span class="linenos">286</span>        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="linenos">287</span>            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Evaluation failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="linenos">288</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">289</span>
<span class="linenos">290</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_check_termination</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="linenos">291</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Check termination conditions.&quot;&quot;&quot;</span>
<span class="linenos">292</span>        <span class="c1"># Maximum iterations</span>
<span class="linenos">293</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_iterations</span><span class="p">:</span>
<span class="linenos">294</span>            <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">295</span>
<span class="linenos">296</span>        <span class="c1"># Maximum evaluations</span>
<span class="linenos">297</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_evaluations</span><span class="p">:</span>
<span class="linenos">298</span>            <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">299</span>
<span class="linenos">300</span>        <span class="c1"># Gradient norm tolerance</span>
<span class="linenos">301</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">302</span>            <span class="n">gradient_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span>
<span class="linenos">303</span>            <span class="k">if</span> <span class="n">gradient_norm</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_tolerance</span><span class="p">:</span>
<span class="linenos">304</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">305</span>
<span class="linenos">306</span>        <span class="c1"># Function tolerance</span>
<span class="linenos">307</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">308</span>            <span class="n">function_change</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="linenos">309</span>            <span class="k">if</span> <span class="n">function_change</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">function_tolerance</span><span class="p">:</span>
<span class="linenos">310</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">311</span>
<span class="linenos">312</span>        <span class="c1"># Step tolerance</span>
<span class="linenos">313</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos">314</span>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">step_tolerance</span><span class="p">:</span>
<span class="linenos">315</span>                <span class="k">return</span> <span class="kc">True</span>
<span class="linenos">316</span>
<span class="linenos">317</span>        <span class="k">return</span> <span class="kc">False</span>
<span class="linenos">318</span>
<span class="linenos">319</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_create_result</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizationResult</span><span class="p">:</span>
<span class="linenos">320</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Create optimization result.&quot;&quot;&quot;</span>
<span class="linenos">321</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">322</span>            <span class="k">return</span> <span class="n">OptimizationResult</span><span class="p">(</span>
<span class="linenos">323</span>                <span class="n">best_parameters</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]),</span>
<span class="linenos">324</span>                <span class="n">best_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span>
<span class="linenos">325</span>                <span class="n">n_evaluations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">326</span>                <span class="n">convergence_history</span><span class="o">=</span><span class="p">[],</span>
<span class="linenos">327</span>                <span class="n">success</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="linenos">328</span>                <span class="n">algorithm_info</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">}</span>
<span class="linenos">329</span>            <span class="p">)</span>
<span class="linenos">330</span>
<span class="linenos">331</span>        <span class="k">return</span> <span class="n">OptimizationResult</span><span class="p">(</span>
<span class="linenos">332</span>            <span class="n">best_parameters</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
<span class="linenos">333</span>            <span class="n">best_value</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span>
<span class="linenos">334</span>            <span class="n">n_evaluations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">335</span>            <span class="n">convergence_history</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
<span class="linenos">336</span>            <span class="n">success</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
<span class="linenos">337</span>                    <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">)</span> <span class="ow">and</span>
<span class="linenos">338</span>                    <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_tolerance</span><span class="p">),</span>
<span class="linenos">339</span>            <span class="n">algorithm_info</span><span class="o">=</span><span class="p">{</span>
<span class="linenos">340</span>                <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;BFGS&#39;</span><span class="p">,</span>
<span class="linenos">341</span>                <span class="s1">&#39;iterations&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="linenos">342</span>                <span class="s1">&#39;final_gradient_norm&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span>
<span class="linenos">343</span>                <span class="s1">&#39;gradient_method&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">gradient_method</span><span class="p">,</span>
<span class="linenos">344</span>                <span class="s1">&#39;hessian_condition_number&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_hessian_condition_number</span><span class="p">(),</span>
<span class="linenos">345</span>                <span class="s1">&#39;average_step_size&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span> <span class="k">else</span> <span class="mf">0.0</span>
<span class="linenos">346</span>            <span class="p">}</span>
<span class="linenos">347</span>        <span class="p">)</span>
<span class="linenos">348</span>
<span class="linenos">349</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_hessian_condition_number</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">350</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute condition number of Hessian approximation.&quot;&quot;&quot;</span>
<span class="linenos">351</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">352</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">353</span>
<span class="linenos">354</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">355</span>            <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">356</span>            <span class="n">eigenvals</span> <span class="o">=</span> <span class="n">eigenvals</span><span class="p">[</span><span class="n">eigenvals</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Only positive eigenvalues</span>
<span class="linenos">357</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">358</span>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">eigenvals</span><span class="p">)</span>
<span class="linenos">359</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">360</span>                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">361</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">362</span>            <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
<span class="linenos">363</span>
<span class="linenos">364</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_optimization_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="linenos">365</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get detailed optimization information.&quot;&quot;&quot;</span>
<span class="linenos">366</span>        <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">367</span>            <span class="s1">&#39;iteration&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span><span class="p">,</span>
<span class="linenos">368</span>            <span class="s1">&#39;n_evaluations&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_evaluations</span><span class="p">,</span>
<span class="linenos">369</span>            <span class="s1">&#39;current_function_value&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_f</span><span class="p">,</span>
<span class="linenos">370</span>            <span class="s1">&#39;gradient_norm&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<span class="linenos">371</span>            <span class="s1">&#39;hessian_condition_number&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_hessian_condition_number</span><span class="p">(),</span>
<span class="linenos">372</span>            <span class="s1">&#39;convergence_rate&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_estimate_convergence_rate</span><span class="p">()</span>
<span class="linenos">373</span>        <span class="p">}</span>
<span class="linenos">374</span>
<span class="linenos">375</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">376</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;current_parameters&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="linenos">377</span>
<span class="linenos">378</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">:</span>
<span class="linenos">379</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;last_step_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos">380</span>            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;average_step_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_size_history</span><span class="p">)</span>
<span class="linenos">381</span>
<span class="linenos">382</span>        <span class="k">return</span> <span class="n">info</span>
<span class="linenos">383</span>
<span class="linenos">384</span>    <span class="k">def</span><span class="w"> </span><span class="nf">_estimate_convergence_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="linenos">385</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimate convergence rate from function value history.&quot;&quot;&quot;</span>
<span class="linenos">386</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
<span class="linenos">387</span>            <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">388</span>
<span class="linenos">389</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">390</span>            <span class="c1"># Estimate linear convergence rate</span>
<span class="linenos">391</span>            <span class="n">recent_history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convergence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
<span class="linenos">392</span>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">recent_history</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># All values the same</span>
<span class="linenos">393</span>                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>  <span class="c1"># Already converged</span>
<span class="linenos">394</span>
<span class="linenos">395</span>            <span class="c1"># Compute successive ratios</span>
<span class="linenos">396</span>            <span class="n">ratios</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos">397</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">recent_history</span><span class="p">)):</span>
<span class="linenos">398</span>                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">1e-12</span><span class="p">:</span>
<span class="linenos">399</span>                    <span class="n">ratio</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">recent_history</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos">400</span>                    <span class="n">ratios</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ratio</span><span class="p">)</span>
<span class="linenos">401</span>
<span class="linenos">402</span>            <span class="k">if</span> <span class="n">ratios</span><span class="p">:</span>
<span class="linenos">403</span>                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ratios</span><span class="p">)</span>
<span class="linenos">404</span>            <span class="k">else</span><span class="p">:</span>
<span class="linenos">405</span>                <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">406</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">407</span>            <span class="k">return</span> <span class="mf">0.0</span>
<span class="linenos">408</span>
<span class="linenos">409</span>    <span class="k">def</span><span class="w"> </span><span class="nf">reset_hessian</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos">410</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset Hessian approximation to identity.&quot;&quot;&quot;</span>
<span class="linenos">411</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dimension</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="linenos">412</span>            <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dimension</span><span class="p">)</span>
<span class="linenos">413</span>
<span class="linenos">414</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_hessian_eigenvalues</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="linenos">415</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get eigenvalues of current Hessian approximation.&quot;&quot;&quot;</span>
<span class="linenos">416</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">417</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="linenos">418</span>
<span class="linenos">419</span>        <span class="k">try</span><span class="p">:</span>
<span class="linenos">420</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span><span class="p">)</span>
<span class="linenos">421</span>        <span class="k">except</span><span class="p">:</span>
<span class="linenos">422</span>            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
<span class="linenos">423</span>
<span class="linenos">424</span>    <span class="k">def</span><span class="w"> </span><span class="nf">get_search_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="linenos">425</span><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get current search direction.&quot;&quot;&quot;</span>
<span class="linenos">426</span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">427</span>            <span class="k">return</span> <span class="kc">None</span>
<span class="linenos">428</span>
<span class="linenos">429</span>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">hessian_inv</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_gradient</span>
</pre></div>
</div>
</section>
<section id="methods-16">
<h4>Methods (16)<a class="headerlink" href="#methods-16" title="Link to this heading">¶</a></h4>
<section id="init-self-config">
<h5><code class="docutils literal notranslate"><span class="pre">__init__(self,</span> <span class="pre">config)</span></code><a class="headerlink" href="#init-self-config" title="Link to this heading">¶</a></h5>
<p>Initialize BFGS algorithm.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-__init__"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="optimize-self-problem-parameter-space-initial-guess">
<h5><code class="docutils literal notranslate"><span class="pre">optimize(self,</span> <span class="pre">problem,</span> <span class="pre">parameter_space,</span> <span class="pre">initial_guess)</span></code><a class="headerlink" href="#optimize-self-problem-parameter-space-initial-guess" title="Link to this heading">¶</a></h5>
<p>Run BFGS optimization.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-optimize"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="initialize-optimization-self-initial-guess">
<h5><code class="docutils literal notranslate"><span class="pre">_initialize_optimization(self,</span> <span class="pre">initial_guess)</span></code><a class="headerlink" href="#initialize-optimization-self-initial-guess" title="Link to this heading">¶</a></h5>
<p>Initialize optimization state.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_initialize_optimization"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="perform-iteration-self">
<h5><code class="docutils literal notranslate"><span class="pre">_perform_iteration(self)</span></code><a class="headerlink" href="#perform-iteration-self" title="Link to this heading">¶</a></h5>
<p>Perform one BFGS iteration.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_perform_iteration"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="compute-numerical-gradient-self-x">
<h5><code class="docutils literal notranslate"><span class="pre">_compute_numerical_gradient(self,</span> <span class="pre">x)</span></code><a class="headerlink" href="#compute-numerical-gradient-self-x" title="Link to this heading">¶</a></h5>
<p>Compute numerical gradient using finite differences.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_compute_numerical_gradient"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="update-hessian-inverse-self-x-old-x-new-grad-old-grad-new">
<h5><code class="docutils literal notranslate"><span class="pre">_update_hessian_inverse(self,</span> <span class="pre">x_old,</span> <span class="pre">x_new,</span> <span class="pre">grad_old,</span> <span class="pre">grad_new)</span></code><a class="headerlink" href="#update-hessian-inverse-self-x-old-x-new-grad-old-grad-new" title="Link to this heading">¶</a></h5>
<p>Update inverse Hessian approximation using BFGS formula.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_update_hessian_inverse"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="line-search-self-x-f-gradient-direction">
<h5><code class="docutils literal notranslate"><span class="pre">_line_search(self,</span> <span class="pre">x,</span> <span class="pre">f,</span> <span class="pre">gradient,</span> <span class="pre">direction)</span></code><a class="headerlink" href="#line-search-self-x-f-gradient-direction" title="Link to this heading">¶</a></h5>
<p>Line search with Wolfe conditions.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_line_search"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="safe-evaluate-self-x">
<h5><code class="docutils literal notranslate"><span class="pre">_safe_evaluate(self,</span> <span class="pre">x)</span></code><a class="headerlink" href="#safe-evaluate-self-x" title="Link to this heading">¶</a></h5>
<p>Safely evaluate objective function.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_safe_evaluate"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="check-termination-self">
<h5><code class="docutils literal notranslate"><span class="pre">_check_termination(self)</span></code><a class="headerlink" href="#check-termination-self" title="Link to this heading">¶</a></h5>
<p>Check termination conditions.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_check_termination"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="create-result-self">
<h5><code class="docutils literal notranslate"><span class="pre">_create_result(self)</span></code><a class="headerlink" href="#create-result-self" title="Link to this heading">¶</a></h5>
<p>Create optimization result.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_create_result"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="compute-hessian-condition-number-self">
<h5><code class="docutils literal notranslate"><span class="pre">_compute_hessian_condition_number(self)</span></code><a class="headerlink" href="#compute-hessian-condition-number-self" title="Link to this heading">¶</a></h5>
<p>Compute condition number of Hessian approximation.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_compute_hessian_condition_number"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="get-optimization-info-self">
<h5><code class="docutils literal notranslate"><span class="pre">get_optimization_info(self)</span></code><a class="headerlink" href="#get-optimization-info-self" title="Link to this heading">¶</a></h5>
<p>Get detailed optimization information.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-get_optimization_info"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="estimate-convergence-rate-self">
<h5><code class="docutils literal notranslate"><span class="pre">_estimate_convergence_rate(self)</span></code><a class="headerlink" href="#estimate-convergence-rate-self" title="Link to this heading">¶</a></h5>
<p>Estimate convergence rate from function value history.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-_estimate_convergence_rate"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="reset-hessian-self">
<h5><code class="docutils literal notranslate"><span class="pre">reset_hessian(self)</span></code><a class="headerlink" href="#reset-hessian-self" title="Link to this heading">¶</a></h5>
<p>Reset Hessian approximation to identity.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-reset_hessian"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="get-hessian-eigenvalues-self">
<h5><code class="docutils literal notranslate"><span class="pre">get_hessian_eigenvalues(self)</span></code><a class="headerlink" href="#get-hessian-eigenvalues-self" title="Link to this heading">¶</a></h5>
<p>Get eigenvalues of current Hessian approximation.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-get_hessian_eigenvalues"><span class="xref myst">View full source →</span></a></p>
</section>
<section id="get-search-direction-self">
<h5><code class="docutils literal notranslate"><span class="pre">get_search_direction(self)</span></code><a class="headerlink" href="#get-search-direction-self" title="Link to this heading">¶</a></h5>
<p>Get current search direction.</p>
<p><a class="reference internal" href="#method-bfgsoptimizer-get_search_direction"><span class="xref myst">View full source →</span></a></p>
</section>
</section>
</section>
</section>
<hr class="docutils" />
<section id="dependencies">
<h2>Dependencies<a class="headerlink" href="#dependencies" title="Link to this heading">¶</a></h2>
<p>This module imports:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">__future__</span> <span class="pre">import</span> <span class="pre">annotations</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">typing</span> <span class="pre">import</span> <span class="pre">Any,</span> <span class="pre">Dict,</span> <span class="pre">List,</span> <span class="pre">Optional,</span> <span class="pre">Callable,</span> <span class="pre">Tuple</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">numpy</span> <span class="pre">as</span> <span class="pre">np</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">warnings</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">dataclasses</span> <span class="pre">import</span> <span class="pre">dataclass</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">..base</span> <span class="pre">import</span> <span class="pre">OptimizationAlgorithm</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">...core.interfaces</span> <span class="pre">import</span> <span class="pre">OptimizationProblem,</span> <span class="pre">ParameterSpace,</span> <span class="pre">OptimizationResult</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">...core.parameters</span> <span class="pre">import</span> <span class="pre">ContinuousParameterSpace</span></code></p></li>
</ul>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Research Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            <div class="last-updated">
              Last updated on Oct 04, 2025</div>
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">optimization.algorithms.gradient_based.bfgs</a><ul>
<li><a class="reference internal" href="#module-overview">Module Overview</a></li>
<li><a class="reference internal" href="#complete-source-code">Complete Source Code</a></li>
<li><a class="reference internal" href="#classes">Classes</a><ul>
<li><a class="reference internal" href="#bfgsconfig"><code class="docutils literal notranslate"><span class="pre">BFGSConfig</span></code></a><ul>
<li><a class="reference internal" href="#source-code">Source Code</a></li>
</ul>
</li>
<li><a class="reference internal" href="#bfgsoptimizer"><code class="docutils literal notranslate"><span class="pre">BFGSOptimizer</span></code></a><ul>
<li><a class="reference internal" href="#id1">Source Code</a></li>
<li><a class="reference internal" href="#methods-16">Methods (16)</a><ul>
<li><a class="reference internal" href="#init-self-config"><code class="docutils literal notranslate"><span class="pre">__init__(self,</span> <span class="pre">config)</span></code></a></li>
<li><a class="reference internal" href="#optimize-self-problem-parameter-space-initial-guess"><code class="docutils literal notranslate"><span class="pre">optimize(self,</span> <span class="pre">problem,</span> <span class="pre">parameter_space,</span> <span class="pre">initial_guess)</span></code></a></li>
<li><a class="reference internal" href="#initialize-optimization-self-initial-guess"><code class="docutils literal notranslate"><span class="pre">_initialize_optimization(self,</span> <span class="pre">initial_guess)</span></code></a></li>
<li><a class="reference internal" href="#perform-iteration-self"><code class="docutils literal notranslate"><span class="pre">_perform_iteration(self)</span></code></a></li>
<li><a class="reference internal" href="#compute-numerical-gradient-self-x"><code class="docutils literal notranslate"><span class="pre">_compute_numerical_gradient(self,</span> <span class="pre">x)</span></code></a></li>
<li><a class="reference internal" href="#update-hessian-inverse-self-x-old-x-new-grad-old-grad-new"><code class="docutils literal notranslate"><span class="pre">_update_hessian_inverse(self,</span> <span class="pre">x_old,</span> <span class="pre">x_new,</span> <span class="pre">grad_old,</span> <span class="pre">grad_new)</span></code></a></li>
<li><a class="reference internal" href="#line-search-self-x-f-gradient-direction"><code class="docutils literal notranslate"><span class="pre">_line_search(self,</span> <span class="pre">x,</span> <span class="pre">f,</span> <span class="pre">gradient,</span> <span class="pre">direction)</span></code></a></li>
<li><a class="reference internal" href="#safe-evaluate-self-x"><code class="docutils literal notranslate"><span class="pre">_safe_evaluate(self,</span> <span class="pre">x)</span></code></a></li>
<li><a class="reference internal" href="#check-termination-self"><code class="docutils literal notranslate"><span class="pre">_check_termination(self)</span></code></a></li>
<li><a class="reference internal" href="#create-result-self"><code class="docutils literal notranslate"><span class="pre">_create_result(self)</span></code></a></li>
<li><a class="reference internal" href="#compute-hessian-condition-number-self"><code class="docutils literal notranslate"><span class="pre">_compute_hessian_condition_number(self)</span></code></a></li>
<li><a class="reference internal" href="#get-optimization-info-self"><code class="docutils literal notranslate"><span class="pre">get_optimization_info(self)</span></code></a></li>
<li><a class="reference internal" href="#estimate-convergence-rate-self"><code class="docutils literal notranslate"><span class="pre">_estimate_convergence_rate(self)</span></code></a></li>
<li><a class="reference internal" href="#reset-hessian-self"><code class="docutils literal notranslate"><span class="pre">reset_hessian(self)</span></code></a></li>
<li><a class="reference internal" href="#get-hessian-eigenvalues-self"><code class="docutils literal notranslate"><span class="pre">get_hessian_eigenvalues(self)</span></code></a></li>
<li><a class="reference internal" href="#get-search-direction-self"><code class="docutils literal notranslate"><span class="pre">get_search_direction(self)</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#dependencies">Dependencies</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=4ebf8126"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=08e7b316"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../_static/back-to-top.js?v=840797bb"></script>
    <script src="../../_static/lazy-load.js?v=dc25293c"></script>
    <script src="../../_static/dark-mode.js?v=bf328970"></script>
    </body>
</html>