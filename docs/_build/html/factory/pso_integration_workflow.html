<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark">
<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
<style>
.chartjs-container {
    margin: 1.5em auto;
    padding: 1em;
    background: #f8f9fa;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
.chart-note {
    text-align: center;
    color: #6c757d;
    font-size: 0.9em;
    margin-top: 0.5em;
}
</style>
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html">

    <!-- Generated with Sphinx 8.2.3 and Furo 2025.09.25 -->
        <title>PSO Integration Workflow and Best Practices ## Overview This document provides guidance for integrating the SMC Controller Factory with Particle Swarm Optimization (PSO) workflows. The integration enables automated controller parameter tuning while maintaining factory validation, thread safety, and performance requirements. ## PSO Integration Architecture ### High-Level PSO-Factory Integration Flow ``` - DIP_SMC_PSO Documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5349f25f" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=8a7e329d" />
    
    


<style>
  body {
    --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">DIP_SMC_PSO Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">DIP_SMC_PSO Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">ğŸ“š Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Optimal Sliding Mode Control for a Double-Inverted Pendulum via PSO  ## How to validate a ResearchPlan JSON Run the validator locally: ```bash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory_overview.html">Theory Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">3. System Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plant_model.html">1.x Plant Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hil_quickstart.html">Hardware-in-the-Loop (HIL) Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../streamlit_dashboard_guide.html">Streamlit Dashboard User Guide</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="https://github.com/theSadeQ/DIP_SMC_PSO/blob/main/docs/factory/pso_integration_workflow.md?plain=true" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div><div class="edit-this-page">
  <a class="muted-link" href="https://github.com/theSadeQ/DIP_SMC_PSO/edit/main/docs/factory/pso_integration_workflow.md" rel="edit" title="Edit this page">
    <svg><use href="#svg-pencil"></use></svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="pso-integration-workflow-and-best-practices-overview-this-document-provides-guidance-for-integrating-the-smc-controller-factory-with-particle-swarm-optimization-pso-workflows-the-integration-enables-automated-controller-parameter-tuning-while-maintaining-factory-validation-thread-safety-and-performance-requirements-pso-integration-architecture-high-level-pso-factory-integration-flow">
<h1>PSO Integration Workflow and Best Practices ## Overview This document provides guidance for integrating the SMC Controller Factory with Particle Swarm Optimization (PSO) workflows. The integration enables automated controller parameter tuning while maintaining factory validation, thread safety, and performance requirements. ## PSO Integration Architecture ### High-Level PSO-Factory Integration Flow ```<a class="headerlink" href="#pso-integration-workflow-and-best-practices-overview-this-document-provides-guidance-for-integrating-the-smc-controller-factory-with-particle-swarm-optimization-pso-workflows-the-integration-enables-automated-controller-parameter-tuning-while-maintaining-factory-validation-thread-safety-and-performance-requirements-pso-integration-architecture-high-level-pso-factory-integration-flow" title="Link to this heading">Â¶</a></h1>
<p>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PSO Engine â”‚â”€â”€â”€â–¶â”‚ Factory-PSO â”‚â”€â”€â”€â–¶â”‚ Controller â”‚
â”‚ Optimizer â”‚ â”‚ Interface â”‚ â”‚ Validation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚ â–¼ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ Parameter â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Bounds &amp; Specs â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â–¼ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ Fitness â”‚ â”‚ Evaluation â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">PSO-Compatible</span> <span class="pre">Controller</span> <span class="pre">Factory</span> <span class="pre">Interface</span></code>python</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="example-metadata">
<h1>example-metadata:<a class="headerlink" href="#example-metadata" title="Link to this heading">Â¶</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="runnable-false-class-psofactoryinterface-specialized-interface-for-pso-optimization-integration-features-vectorized-controller-creation-for-swarm-populations-automatic-parameter-validation-and-bounds-checking-performance-optimized-fitness-evaluation-thread-safe-parallel-optimization-support-def-init-self-controller-type-str-plant-config-any-self-controller-type-controller-type-self-plant-config-plant-config-self-setup-optimization-environment-def-setup-optimization-environment-self-none-initialize-pso-optimization-environment-get-controller-specifications-self-gain-spec-smc-gain-specs-smctype-self-controller-type-self-n-gains-self-gain-spec-n-gains-self-bounds-self-gain-spec-gain-bounds-performance-monitoring-self-evaluation-count-0-self-successful-evaluations-0-self-failed-evaluations-0-thread-safe-operations-self-lock-threading-rlock-def-create-pso-controller-factory-self-callable-gainsarray-psocontrollerwrapper-create-pso-optimized-controller-factory-function-returns-factory-function-that-takes-gains-and-returns-pso-wrapped-controller-def-controller-factory-gains-gainsarray-psocontrollerwrapper-pso-controller-factory-with-validation-with-self-lock-self-evaluation-count-1-try-validate-gains-if-not-self-validate-pso-gains-gains-self-failed-evaluations-1-return-self-create-fallback-controller-gains-create-controller-via-factory-controller-create-controller-controller-type-self-controller-type-config-self-plant-config-gains-gains-wrap-for-pso-optimization-wrapper-psocontrollerwrapper-controller-controller-controller-type-self-controller-type-validation-enabled-true-add-pso-required-attributes-wrapper-n-gains-self-n-gains-wrapper-controller-type-self-controller-type-wrapper-max-force-getattr-controller-max-force-150-0-self-successful-evaluations-1-return-wrapper-except-exception-as-e-logger-warning-f-pso-controller-creation-failed-e-self-failed-evaluations-1-return-self-create-fallback-controller-gains-add-pso-required-attributes-to-factory-function-controller-factory-n-gains-self-n-gains-controller-factory-controller-type-self-controller-type-controller-factory-bounds-self-bounds-controller-factory-max-force-150-0-return-controller-factory-def-validate-pso-gains-self-gains-gainsarray-bool-validate-gains-for-pso-optimization-try-gains-array-np-asarray-gains-check-dimensions-if-len-gains-array-self-n-gains-return-false-check-bounds-for-i-gain-min-val-max-val-in-enumerate-zip-gains-array-self-bounds-if-not-min-val-gain-max-val-return-false-check-numerical-validity-if-not-np-all-np-isfinite-gains-array-return-false-controller-specific-validation-return-validate-smc-gains-smctype-self-controller-type-gains-array-except-exception-return-false-def-create-fallback-controller-self-gains-gainsarray-psocontrollerwrapper-create-fallback-controller-for-invalid-parameters-use-default-gains-as-fallback-default-gains-get-default-gains-self-controller-type-try-controller-create-controller-controller-type-self-controller-type-config-self-plant-config-gains-default-gains-wrapper-psocontrollerwrapper-controller-controller-controller-type-self-controller-type-validation-enabled-false-disable-validation-for-fallback-wrapper-n-gains-self-n-gains-wrapper-controller-type-self-controller-type-wrapper-is-fallback-true-return-wrapper-except-exception-emergency-fallback-return-minimal-controller-return-self-create-emergency-fallback-def-get-optimization-statistics-self-dict-str-any-get-pso-optimization-statistics-with-self-lock-success-rate-self-successful-evaluations-max-1-self-evaluation-count-return-total-evaluations-self-evaluation-count-successful-evaluations-self-successful-evaluations-failed-evaluations-self-failed-evaluations-success-rate-success-rate-optimization-health-good-if-success-rate-0-8-else-warning-if-success-rate-0-5-else-poor">
<h1>runnable: false class PSOFactoryInterface: â€œâ€â€ Specialized interface for PSO optimization integration. Features: - Vectorized controller creation for swarm populations - Automatic parameter validation and bounds checking - Performance-optimized fitness evaluation - Thread-safe parallel optimization support â€œâ€â€ def <strong>init</strong>(self, controller_type: str, plant_config: Any): self.controller_type = controller_type self.plant_config = plant_config self._setup_optimization_environment() def _setup_optimization_environment(self) -&gt; None: â€œâ€â€Initialize PSO optimization environment.â€â€â€ # Get controller specifications self.gain_spec = SMC_GAIN_SPECS[SMCType(self.controller_type)] self.n_gains = self.gain_spec.n_gains self.bounds = self.gain_spec.gain_bounds # Performance monitoring self.evaluation_count = 0 self.successful_evaluations = 0 self.failed_evaluations = 0 # Thread-safe operations self._lock = threading.RLock() def create_pso_controller_factory(self) -&gt; Callable[[GainsArray], PSOControllerWrapper]: â€œâ€â€ Create PSO-optimized controller factory function. Returns: Factory function that takes gains and returns PSO-wrapped controller â€œâ€â€ def controller_factory(gains: GainsArray) -&gt; PSOControllerWrapper: â€œâ€â€PSO controller factory with validation.â€â€â€ with self._lock: self.evaluation_count += 1 try: # Validate gains if not self._validate_pso_gains(gains): self.failed_evaluations += 1 return self._create_fallback_controller(gains) # Create controller via factory controller = create_controller( controller_type=self.controller_type, config=self.plant_config, gains=gains ) # Wrap for PSO optimization wrapper = PSOControllerWrapper( controller=controller, controller_type=self.controller_type, validation_enabled=True ) # Add PSO-required attributes wrapper.n_gains = self.n_gains wrapper.controller_type = self.controller_type wrapper.max_force = getattr(controller, â€˜max_forceâ€™, 150.0) self.successful_evaluations += 1 return wrapper except Exception as e: logger.warning(fâ€PSO controller creation failed: {e}â€) self.failed_evaluations += 1 return self._create_fallback_controller(gains) # Add PSO-required attributes to factory function controller_factory.n_gains = self.n_gains controller_factory.controller_type = self.controller_type controller_factory.bounds = self.bounds controller_factory.max_force = 150.0 return controller_factory def _validate_pso_gains(self, gains: GainsArray) -&gt; bool: â€œâ€â€Validate gains for PSO optimization.â€â€â€ try: gains_array = np.asarray(gains) # Check dimensions if len(gains_array) != self.n_gains: return False # Check bounds for i, (gain, (min_val, max_val)) in enumerate(zip(gains_array, self.bounds)): if not (min_val &lt;= gain &lt;= max_val): return False # Check numerical validity if not np.all(np.isfinite(gains_array)): return False # Controller-specific validation return validate_smc_gains(SMCType(self.controller_type), gains_array) except Exception: return False def _create_fallback_controller(self, gains: GainsArray) -&gt; PSOControllerWrapper: â€œâ€â€Create fallback controller for invalid parameters.â€â€â€ # Use default gains as fallback default_gains = get_default_gains(self.controller_type) try: controller = create_controller( controller_type=self.controller_type, config=self.plant_config, gains=default_gains ) wrapper = PSOControllerWrapper( controller=controller, controller_type=self.controller_type, validation_enabled=False # Disable validation for fallback ) wrapper.n_gains = self.n_gains wrapper.controller_type = self.controller_type wrapper.is_fallback = True return wrapper except Exception: # Emergency fallback - return minimal controller return self._create_emergency_fallback() def get_optimization_statistics(self) -&gt; Dict[str, Any]: â€œâ€â€Get PSO optimization statistics.â€â€â€ with self._lock: success_rate = self.successful_evaluations / max(1, self.evaluation_count) return { â€˜total_evaluationsâ€™: self.evaluation_count, â€˜successful_evaluationsâ€™: self.successful_evaluations, â€˜failed_evaluationsâ€™: self.failed_evaluations, â€˜success_rateâ€™: success_rate, â€˜optimization_healthâ€™: â€˜GOODâ€™ if success_rate &gt; 0.8 else â€˜WARNINGâ€™ if success_rate &gt; 0.5 else â€˜POORâ€™ }<a class="headerlink" href="#runnable-false-class-psofactoryinterface-specialized-interface-for-pso-optimization-integration-features-vectorized-controller-creation-for-swarm-populations-automatic-parameter-validation-and-bounds-checking-performance-optimized-fitness-evaluation-thread-safe-parallel-optimization-support-def-init-self-controller-type-str-plant-config-any-self-controller-type-controller-type-self-plant-config-plant-config-self-setup-optimization-environment-def-setup-optimization-environment-self-none-initialize-pso-optimization-environment-get-controller-specifications-self-gain-spec-smc-gain-specs-smctype-self-controller-type-self-n-gains-self-gain-spec-n-gains-self-bounds-self-gain-spec-gain-bounds-performance-monitoring-self-evaluation-count-0-self-successful-evaluations-0-self-failed-evaluations-0-thread-safe-operations-self-lock-threading-rlock-def-create-pso-controller-factory-self-callable-gainsarray-psocontrollerwrapper-create-pso-optimized-controller-factory-function-returns-factory-function-that-takes-gains-and-returns-pso-wrapped-controller-def-controller-factory-gains-gainsarray-psocontrollerwrapper-pso-controller-factory-with-validation-with-self-lock-self-evaluation-count-1-try-validate-gains-if-not-self-validate-pso-gains-gains-self-failed-evaluations-1-return-self-create-fallback-controller-gains-create-controller-via-factory-controller-create-controller-controller-type-self-controller-type-config-self-plant-config-gains-gains-wrap-for-pso-optimization-wrapper-psocontrollerwrapper-controller-controller-controller-type-self-controller-type-validation-enabled-true-add-pso-required-attributes-wrapper-n-gains-self-n-gains-wrapper-controller-type-self-controller-type-wrapper-max-force-getattr-controller-max-force-150-0-self-successful-evaluations-1-return-wrapper-except-exception-as-e-logger-warning-f-pso-controller-creation-failed-e-self-failed-evaluations-1-return-self-create-fallback-controller-gains-add-pso-required-attributes-to-factory-function-controller-factory-n-gains-self-n-gains-controller-factory-controller-type-self-controller-type-controller-factory-bounds-self-bounds-controller-factory-max-force-150-0-return-controller-factory-def-validate-pso-gains-self-gains-gainsarray-bool-validate-gains-for-pso-optimization-try-gains-array-np-asarray-gains-check-dimensions-if-len-gains-array-self-n-gains-return-false-check-bounds-for-i-gain-min-val-max-val-in-enumerate-zip-gains-array-self-bounds-if-not-min-val-gain-max-val-return-false-check-numerical-validity-if-not-np-all-np-isfinite-gains-array-return-false-controller-specific-validation-return-validate-smc-gains-smctype-self-controller-type-gains-array-except-exception-return-false-def-create-fallback-controller-self-gains-gainsarray-psocontrollerwrapper-create-fallback-controller-for-invalid-parameters-use-default-gains-as-fallback-default-gains-get-default-gains-self-controller-type-try-controller-create-controller-controller-type-self-controller-type-config-self-plant-config-gains-default-gains-wrapper-psocontrollerwrapper-controller-controller-controller-type-self-controller-type-validation-enabled-false-disable-validation-for-fallback-wrapper-n-gains-self-n-gains-wrapper-controller-type-self-controller-type-wrapper-is-fallback-true-return-wrapper-except-exception-emergency-fallback-return-minimal-controller-return-self-create-emergency-fallback-def-get-optimization-statistics-self-dict-str-any-get-pso-optimization-statistics-with-self-lock-success-rate-self-successful-evaluations-max-1-self-evaluation-count-return-total-evaluations-self-evaluation-count-successful-evaluations-self-successful-evaluations-failed-evaluations-self-failed-evaluations-success-rate-success-rate-optimization-health-good-if-success-rate-0-8-else-warning-if-success-rate-0-5-else-poor" title="Link to this heading">Â¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">##</span> <span class="pre">Controller-Specific</span> <span class="pre">PSO</span> <span class="pre">Integration</span> <span class="pre">Patterns</span> <span class="pre">###</span> <span class="pre">Classical</span> <span class="pre">SMC</span> <span class="pre">PSO</span> <span class="pre">Integration</span></code>python</p>
<p>def setup_classical_smc_pso_optimization( plant_config: Any, optimization_config: Optional[Dict[str, Any]] = None
) -&gt; Dict[str, Any]: â€œâ€â€ Setup PSO optimization for Classical SMC with enhanced performance. Classical SMC Parameters: [k1, k2, Î»1, Î»2, K, kd] - k1, k2: Pendulum surface gains (convergence rate) - Î»1, Î»2: Sliding coefficients (surface slope) - K: Switching gain (uncertainty rejection) - kd: Damping gain (chattering reduction) â€œâ€â€ # Enhanced bounds for double-inverted pendulum bounds = { â€˜lowerâ€™: [5.0, 5.0, 3.0, 3.0, 10.0, 1.0], # Conservative lower bounds â€˜upperâ€™: [50.0, 40.0, 30.0, 25.0, 80.0, 15.0] # Aggressive upper bounds } # PSO-specific configuration default_config = { â€˜swarm_sizeâ€™: 30, â€˜max_iterationsâ€™: 100, â€˜cognitive_paramâ€™: 2.0, # Personal best weight â€˜social_paramâ€™: 2.0, # Global best weight â€˜inertia_weightâ€™: 0.9, # Exploration vs exploitation â€˜inertia_decayâ€™: 0.95, # Dynamic inertia reduction â€˜convergence_thresholdâ€™: 1e-6, â€˜parallel_evaluationâ€™: True, â€˜thread_countâ€™: 4 } if optimization_config: default_config.update(optimization_config) # Create PSO factory interface pso_interface = PSOFactoryInterface(â€˜classical_smcâ€™, plant_config) controller_factory = pso_interface.create_pso_controller_factory() # Fitness function for classical SMC def fitness_function(gains: GainsArray) -&gt; float: â€œâ€â€ Multi-objective fitness function for Classical SMC optimization. Objectives: 1. Stabilization performance (primary) 2. Control effort minimization (secondary) 3. Chattering reduction (tertiary) â€œâ€â€ try: controller = controller_factory(gains) # Test scenarios scenarios = [ (â€˜small_disturbanceâ€™, np.array([0.1, 0.05, 0.03, 0.0, 0.0, 0.0])), (â€˜medium_anglesâ€™, np.array([0.3, 0.4, 0.2, 0.1, 0.0, 0.0])), (â€˜high_velocityâ€™, np.array([0.1, 0.1, 0.1, 1.5, 1.0, 0.8])) ] total_cost = 0.0 scenario_weights = [0.5, 0.3, 0.2] # Weight different scenarios for weight, (scenario_name, initial_state) in zip(scenario_weights, scenarios): scenario_cost = evaluate_scenario_performance( controller, initial_state, simulation_time=2.0 ) total_cost += weight * scenario_cost # Penalize extreme gains gain_penalty = compute_gain_penalty(gains, bounds) total_cost += 0.1 * gain_penalty return total_cost except Exception as e: logger.warning(fâ€Fitness evaluation failed: {e}â€) return 1000.0 # High penalty for failed evaluations return { â€˜controller_factoryâ€™: controller_factory, â€˜fitness_functionâ€™: fitness_function, â€˜boundsâ€™: bounds, â€˜pso_configâ€™: default_config, â€˜pso_interfaceâ€™: pso_interface, â€˜n_gainsâ€™: 6, â€˜optimization_typeâ€™: â€˜classical_smc_dipâ€™ } def evaluate_scenario_performance( controller: PSOControllerWrapper, initial_state: StateVector, simulation_time: float = 2.0, dt: float = 0.001
) -&gt; float: â€œâ€â€Evaluate controller performance for a specific scenario.â€â€â€ from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics # Create dynamics model dynamics = SimplifiedDIPDynamics() # Simulation parameters n_steps = int(simulation_time / dt) state = initial_state.copy() # Performance metrics position_errors = [] control_efforts = [] control_variations = [] previous_control = 0.0 for step in range(n_steps): try: # Compute control control = controller.compute_control(state) control_value = control[0] # Store metrics position_error = np.linalg.norm(state[:3]) # Position error magnitude position_errors.append(position_error) control_efforts.append(abs(control_value)) # Control variation (chattering metric) control_variation = abs(control_value - previous_control) control_variations.append(control_variation) previous_control = control_value # Simulate dynamics result = dynamics.compute_dynamics(state, control) if not result.success: break # Integrate state = state + dt * result.state_derivative # Stability check if np.any(np.abs(state) &gt; 10.0): return 1000.0 # Instability penalty except Exception: return 1000.0 # Simulation failure penalty # Compute composite cost avg_position_error = np.mean(position_errors) avg_control_effort = np.mean(control_efforts) avg_control_variation = np.mean(control_variations) final_position_error = position_errors[-1] # Multi-objective cost function cost = ( 10.0 * avg_position_error + # Primary: tracking performance 0.1 * avg_control_effort + # Secondary: control effort 1.0 * avg_control_variation + # Tertiary: chattering 5.0 * final_position_error # Final: steady-state error ) return cost def compute_gain_penalty(gains: GainsArray, bounds: Dict[str, List[float]]) -&gt; float: â€œâ€â€Compute penalty for gains near boundaries.â€â€â€ gains_array = np.asarray(gains) lower_bounds = np.array(bounds[â€˜lowerâ€™]) upper_bounds = np.array(bounds[â€˜upperâ€™]) # Normalize gains to [0, 1] range normalized_gains = (gains_array - lower_bounds) / (upper_bounds - lower_bounds) # Penalty for gains too close to boundaries boundary_penalty = 0.0 for g in normalized_gains: if g &lt; 0.1 or g &gt; 0.9: # Within 10% of boundaries boundary_penalty += 1.0 return boundary_penalty
<code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">Adaptive</span> <span class="pre">SMC</span> <span class="pre">PSO</span> <span class="pre">Integration</span></code>python
def setup_adaptive_smc_pso_optimization( plant_config: Any, adaptation_focused: bool = True
) -&gt; Dict[str, Any]: â€œâ€â€ Setup PSO optimization for Adaptive SMC with adaptation-focused tuning. Adaptive SMC Parameters: [k1, k2, Î»1, Î»2, Î³] - k1, k2: Pendulum surface gains - Î»1, Î»2: Sliding coefficients - Î³: Adaptation rate (critical parameter) â€œâ€â€ # Adaptation-focused bounds if adaptation_focused: bounds = { â€˜lowerâ€™: [8.0, 8.0, 5.0, 5.0, 1.0], # Higher surface gains â€˜upperâ€™: [60.0, 50.0, 40.0, 35.0, 8.0] # Conservative adaptation rate } else: bounds = { â€˜lowerâ€™: [5.0, 5.0, 3.0, 3.0, 0.5], â€˜upperâ€™: [50.0, 40.0, 30.0, 25.0, 10.0] } # PSO configuration with emphasis on exploration for adaptation pso_config = { â€˜swarm_sizeâ€™: 40, # Larger swarm for adaptation exploration â€˜max_iterationsâ€™: 150, # More iterations for convergence â€˜cognitive_paramâ€™: 2.5, # Higher personal exploration â€˜social_paramâ€™: 1.5, # Lower social influence â€˜inertia_weightâ€™: 0.9, â€˜inertia_decayâ€™: 0.98, # Slower decay for exploration â€˜adaptation_penalty_weightâ€™: 0.2, # Penalty for poor adaptation â€˜convergence_thresholdâ€™: 5e-7 } # Create PSO interface pso_interface = PSOFactoryInterface(â€˜adaptive_smcâ€™, plant_config) controller_factory = pso_interface.create_pso_controller_factory() def adaptive_fitness_function(gains: GainsArray) -&gt; float: â€œâ€â€Fitness function emphasizing adaptation performance.â€â€â€ try: controller = controller_factory(gains) # Extract adaptation rate for analysis gamma = gains[4] # Adaptive-specific test scenarios scenarios = [ (â€˜adaptation_test_1â€™, np.array([0.2, 0.3, 0.1, 0.0, 0.0, 0.0])), (â€˜adaptation_test_2â€™, np.array([0.4, 0.5, 0.3, 0.5, 0.3, 0.2])), (â€˜parameter_changeâ€™, np.array([0.1, 0.1, 0.1, 0.0, 0.0, 0.0])) # For adaptation testing ] total_cost = 0.0 for i, (scenario_name, initial_state) in enumerate(scenarios): if scenario_name == â€˜parameter_changeâ€™: # Test adaptation to parameter changes cost = evaluate_adaptation_performance(controller, initial_state) else: # Standard performance evaluation cost = evaluate_scenario_performance(controller, initial_state, simulation_time=3.0) total_cost += cost # Adaptation rate penalty if gamma &lt; 0.5 or gamma &gt; 8.0: total_cost += 50.0 * abs(gamma - 3.0) # Penalty for extreme adaptation rates # Convergence bonus for reasonable adaptation rates if 1.0 &lt;= gamma &lt;= 5.0: total_cost *= 0.9 # 10% bonus for good adaptation rate return total_cost except Exception as e: logger.warning(fâ€Adaptive fitness evaluation failed: {e}â€) return 1500.0 return { â€˜controller_factoryâ€™: controller_factory, â€˜fitness_functionâ€™: adaptive_fitness_function, â€˜boundsâ€™: bounds, â€˜pso_configâ€™: pso_config, â€˜pso_interfaceâ€™: pso_interface, â€˜n_gainsâ€™: 5, â€˜optimization_typeâ€™: â€˜adaptive_smc_dipâ€™, â€˜special_featuresâ€™: [â€˜adaptation_monitoringâ€™, â€˜parameter_change_testingâ€™] } def evaluate_adaptation_performance( controller: PSOControllerWrapper, initial_state: StateVector, simulation_time: float = 4.0
) -&gt; float: â€œâ€â€Evaluate adaptation performance with parameter changes.â€â€â€ from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics dynamics = SimplifiedDIPDynamics() dt = 0.001 n_steps = int(simulation_time / dt) state = initial_state.copy() adaptation_errors = [] pre_change_errors = [] post_change_errors = [] change_step = n_steps // 2 # Parameter change at midpoint for step in range(n_steps): try: # Simulate parameter change at midpoint if step == change_step: # Introduce disturbance to test adaptation state += np.array([0.1, 0.1, 0.0, 0.0, 0.0, 0.0]) control = controller.compute_control(state) result = dynamics.compute_dynamics(state, control) if not result.success: break state = state + dt * result.state_derivative position_error = np.linalg.norm(state[:3]) if step &lt; change_step: pre_change_errors.append(position_error) else: post_change_errors.append(position_error) adaptation_errors.append(position_error) if np.any(np.abs(state) &gt; 8.0): return 2000.0 # Adaptation failure penalty except Exception: return 2000.0 # Analyze adaptation performance pre_change_avg = np.mean(pre_change_errors) if pre_change_errors else 1.0 post_change_avg = np.mean(post_change_errors) if post_change_errors else 1.0 # Adaptation quality metric adaptation_ratio = post_change_avg / (pre_change_avg + 1e-6) # Cost emphasizing good adaptation adaptation_cost = ( 5.0 * np.mean(adaptation_errors) + # Overall performance 10.0 * max(0, adaptation_ratio - 2.0) + # Penalty for poor adaptation 2.0 * post_change_avg # Post-change performance ) return adaptation_cost
<code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">Super-Twisting</span> <span class="pre">SMC</span> <span class="pre">PSO</span> <span class="pre">Integration</span></code>python</p>
<p>def setup_super_twisting_smc_pso_optimization( plant_config: Any, high_performance_mode: bool = True
) -&gt; Dict[str, Any]: â€œâ€â€ Setup PSO optimization for Super-Twisting SMC. STA-SMC Parameters: [K1, K2, k1, k2, Î»1, Î»2] - K1, K2: Super-twisting algorithm gains (K1 &gt; K2 typically) - k1, k2: Surface gains - Î»1, Î»2: Sliding coefficients â€œâ€â€ # High-performance bounds for aggressive STA tuning if high_performance_mode: bounds = { â€˜lowerâ€™: [15.0, 10.0, 8.0, 8.0, 5.0, 5.0], â€˜upperâ€™: [100.0, 70.0, 60.0, 50.0, 40.0, 35.0] } else: bounds = { â€˜lowerâ€™: [10.0, 8.0, 5.0, 5.0, 3.0, 3.0], â€˜upperâ€™: [80.0, 60.0, 50.0, 40.0, 30.0, 25.0] } # STA-specific PSO configuration pso_config = { â€˜swarm_sizeâ€™: 35, â€˜max_iterationsâ€™: 120, â€˜cognitive_paramâ€™: 2.2, â€˜social_paramâ€™: 1.8, â€˜inertia_weightâ€™: 0.85, â€˜inertia_decayâ€™: 0.97, â€˜sta_constraint_weightâ€™: 0.3, # Weight for STA-specific constraints â€˜convergence_thresholdâ€™: 1e-6 } pso_interface = PSOFactoryInterface(â€˜sta_smcâ€™, plant_config) controller_factory = pso_interface.create_pso_controller_factory() def sta_fitness_function(gains: GainsArray) -&gt; float: â€œâ€â€Fitness function for Super-Twisting SMC optimization.â€â€â€ try: controller = controller_factory(gains) K1, K2 = gains[0], gains[1] # STA constraint penalty sta_penalty = 0.0 if K1 &lt;= K2: sta_penalty += 100.0 * (K2 - K1 + 1.0) # Strong penalty for K1 &lt;= K2 # Test with challenging scenarios for STA performance scenarios = [ (â€˜precision_trackingâ€™, np.array([0.05, 0.03, 0.02, 0.0, 0.0, 0.0])), (â€˜large_disturbanceâ€™, np.array([0.6, 0.8, 0.4, 0.3, 0.2, 0.1])), (â€˜high_frequencyâ€™, np.array([0.2, 0.2, 0.2, 2.0, 1.5, 1.0])) ] total_cost = 0.0 scenario_weights = [0.4, 0.4, 0.2] for weight, (scenario_name, initial_state) in zip(scenario_weights, scenarios): if scenario_name == â€˜precision_trackingâ€™: # STA excels at precision - test with tighter tolerance cost = evaluate_sta_precision_performance(controller, initial_state) elif scenario_name == â€˜large_disturbanceâ€™: # Test robustness with large disturbances cost = evaluate_sta_robustness_performance(controller, initial_state) else: # Standard evaluation cost = evaluate_scenario_performance(controller, initial_state) total_cost += weight * cost total_cost += sta_penalty # Bonus for optimal K1/K2 ratio k_ratio = K1 / K2 if 1.2 &lt;= k_ratio &lt;= 2.0: # Optimal STA ratio range total_cost *= 0.95 # 5% bonus return total_cost except Exception as e: logger.warning(fâ€STA fitness evaluation failed: {e}â€) return 1800.0 return { â€˜controller_factoryâ€™: controller_factory, â€˜fitness_functionâ€™: sta_fitness_function, â€˜boundsâ€™: bounds, â€˜pso_configâ€™: pso_config, â€˜pso_interfaceâ€™: pso_interface, â€˜n_gainsâ€™: 6, â€˜optimization_typeâ€™: â€˜sta_smc_dipâ€™, â€˜special_featuresâ€™: [â€˜finite_time_convergenceâ€™, â€˜chattering_reductionâ€™, â€˜robustness_testingâ€™] } def evaluate_sta_precision_performance( controller: PSOControllerWrapper, initial_state: StateVector, precision_threshold: float = 0.01
) -&gt; float: â€œâ€â€Evaluate STA precision performance with tight tolerances.â€â€â€ from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics dynamics = SimplifiedDIPDynamics() dt = 0.001 simulation_time = 3.0 n_steps = int(simulation_time / dt) state = initial_state.copy() precision_errors = [] convergence_time = None for step in range(n_steps): try: control = controller.compute_control(state) result = dynamics.compute_dynamics(state, control) if not result.success: break state = state + dt * result.state_derivative position_error = np.linalg.norm(state[:3]) precision_errors.append(position_error) # Check for convergence to precision threshold if convergence_time is None and position_error &lt; precision_threshold: convergence_time = step * dt if np.any(np.abs(state) &gt; 5.0): return 1500.0 # Precision failure except Exception: return 1500.0 # Precision-focused cost function avg_precision_error = np.mean(precision_errors) final_precision_error = precision_errors[-1] # Convergence time bonus convergence_bonus = 0.0 if convergence_time is not None: convergence_bonus = max(0, 2.0 - convergence_time) # Bonus for fast convergence precision_cost = ( 20.0 * avg_precision_error + 30.0 * final_precision_error - 5.0 * convergence_bonus ) return max(0.1, precision_cost) # Minimum positive cost def evaluate_sta_robustness_performance( controller: PSOControllerWrapper, initial_state: StateVector
) -&gt; float: â€œâ€â€Evaluate STA robustness with large disturbances.â€â€â€ from src.plant.models.simplified.dynamics import SimplifiedDIPDynamics dynamics = SimplifiedDIPDynamics() dt = 0.001 simulation_time = 4.0 n_steps = int(simulation_time / dt) state = initial_state.copy() robustness_errors = [] max_recovery_time = 0.0 disturbance_steps = [n_steps // 4, n_steps // 2, 3 * n_steps // 4] for step in range(n_steps): try: # Apply disturbances at specific intervals if step in disturbance_steps: disturbance = np.array([0.1, 0.1, 0.05, 0.2, 0.1, 0.1]) state += disturbance control = controller.compute_control(state) result = dynamics.compute_dynamics(state, control) if not result.success: break state = state + dt * result.state_derivative position_error = np.linalg.norm(state[:3]) robustness_errors.append(position_error) if np.any(np.abs(state) &gt; 8.0): return 2000.0 # Robustness failure except Exception: return 2000.0 # Robustness cost emphasizing disturbance rejection avg_robustness_error = np.mean(robustness_errors) max_error = np.max(robustness_errors) robustness_cost = ( 15.0 * avg_robustness_error + 10.0 * max_error + 5.0 * robustness_errors[-1] # Final steady-state error ) return robustness_cost
<code class="docutils literal notranslate"><span class="pre">##</span> <span class="pre">Advanced</span> <span class="pre">PSO</span> <span class="pre">Integration</span> <span class="pre">Features</span> <span class="pre">###</span> <span class="pre">Parallel</span> <span class="pre">PSO</span> <span class="pre">Evaluation</span></code>python</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>example-metadata:<a class="headerlink" href="#id1" title="Link to this heading">Â¶</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="runnable-false-class-parallelpsoevaluator-thread-safe-parallel-evaluation-system-for-pso-optimization-features-multi-threaded-fitness-evaluation-load-balancing-across-cpu-cores-memory-efficient-swarm-processing-progress-monitoring-and-early-termination-def-init-self-controller-factory-callable-fitness-function-callable-n-threads-int-4-batch-size-int-8-self-controller-factory-controller-factory-self-fitness-function-fitness-function-self-n-threads-n-threads-self-batch-size-batch-size-thread-management-self-thread-pool-threadpoolexecutor-max-workers-n-threads-self-evaluation-lock-threading-rlock-performance-monitoring-self-evaluation-times-self-success-count-0-self-failure-count-0-def-evaluate-swarm-parallel-self-swarm-positions-np-ndarray-timeout-seconds-float-30-0-list-float-evaluate-entire-swarm-in-parallel-with-timeout-protection-args-swarm-positions-array-of-shape-swarm-size-n-dimensions-timeout-seconds-maximum-time-for-evaluation-returns-list-of-fitness-values-for-each-particle-swarm-size-swarm-positions-shape-0-fitness-values-float-inf-swarm-size-submit-evaluation-tasks-future-to-index-for-i-in-range-swarm-size-future-self-thread-pool-submit-self-evaluate-particle-safe-swarm-positions-i-i-future-to-index-future-i-collect-results-with-timeout-completed-count-0-start-time-time-time-for-future-in-as-completed-future-to-index-timeout-timeout-seconds-try-particle-index-future-to-index-future-fitness-value-future-result-timeout-1-0-individual-timeout-fitness-values-particle-index-fitness-value-with-self-evaluation-lock-self-success-count-1-completed-count-1-except-exception-as-e-particle-index-future-to-index-future-logger-warning-f-particle-particle-index-evaluation-failed-e-with-self-evaluation-lock-self-failure-count-1-use-penalty-value-for-failed-evaluations-fitness-values-particle-index-5000-0-check-for-timeout-if-time-time-start-time-timeout-seconds-logger-warning-f-swarm-evaluation-timeout-after-timeout-seconds-s-break-cancel-remaining-futures-for-future-in-future-to-index-if-not-future-done-future-cancel-return-fitness-values-def-evaluate-particle-safe-self-gains-gainsarray-particle-index-int-float-thread-safe-particle-evaluation-with-error-handling-start-time-time-time-try-create-controller-controller-self-controller-factory-gains-evaluate-fitness-fitness-value-self-fitness-function-gains-controller-record-evaluation-time-evaluation-time-time-time-start-time-with-self-evaluation-lock-self-evaluation-times-append-evaluation-time-return-fitness-value-except-exception-as-e-logger-warning-f-particle-particle-index-failed-e-return-3000-0-high-penalty-for-failures-def-get-evaluation-statistics-self-dict-str-any-get-parallel-evaluation-performance-statistics-with-self-evaluation-lock-total-evaluations-self-success-count-self-failure-count-success-rate-self-success-count-max-1-total-evaluations-avg-time-np-mean-self-evaluation-times-if-self-evaluation-times-else-0-0-max-time-np-max-self-evaluation-times-if-self-evaluation-times-else-0-0-return-total-evaluations-total-evaluations-success-count-self-success-count-failure-count-self-failure-count-success-rate-success-rate-avg-evaluation-time-avg-time-max-evaluation-time-max-time-total-evaluation-time-sum-self-evaluation-times-parallel-efficiency-avg-time-self-n-threads-max-max-time-0-001-def-cleanup-self-clean-up-thread-pool-resources-self-thread-pool-shutdown-wait-true">
<h1>runnable: false class ParallelPSOEvaluator: â€œâ€â€ Thread-safe parallel evaluation system for PSO optimization. Features: - Multi-threaded fitness evaluation - Load balancing across CPU cores - Memory-efficient swarm processing - Progress monitoring and early termination â€œâ€â€ def <strong>init</strong>( self, controller_factory: Callable, fitness_function: Callable, n_threads: int = 4, batch_size: int = 8 ): self.controller_factory = controller_factory self.fitness_function = fitness_function self.n_threads = n_threads self.batch_size = batch_size # Thread management self.thread_pool = ThreadPoolExecutor(max_workers=n_threads) self.evaluation_lock = threading.RLock() # Performance monitoring self.evaluation_times = [] self.success_count = 0 self.failure_count = 0 def evaluate_swarm_parallel( self, swarm_positions: np.ndarray, timeout_seconds: float = 30.0 ) -&gt; List[float]: â€œâ€â€ Evaluate entire swarm in parallel with timeout protection. Args: swarm_positions: Array of shape (swarm_size, n_dimensions) timeout_seconds: Maximum time for evaluation Returns: List of fitness values for each particle â€œâ€â€ swarm_size = swarm_positions.shape[0] fitness_values = [float(â€˜infâ€™)] * swarm_size # Submit evaluation tasks future_to_index = {} for i in range(swarm_size): future = self.thread_pool.submit( self._evaluate_particle_safe, swarm_positions[i], i ) future_to_index[future] = i # Collect results with timeout completed_count = 0 start_time = time.time() for future in as_completed(future_to_index, timeout=timeout_seconds): try: particle_index = future_to_index[future] fitness_value = future.result(timeout=1.0) # Individual timeout fitness_values[particle_index] = fitness_value with self.evaluation_lock: self.success_count += 1 completed_count += 1 except Exception as e: particle_index = future_to_index[future] logger.warning(fâ€Particle {particle_index} evaluation failed: {e}â€) with self.evaluation_lock: self.failure_count += 1 # Use penalty value for failed evaluations fitness_values[particle_index] = 5000.0 # Check for timeout if time.time() - start_time &gt; timeout_seconds: logger.warning(fâ€Swarm evaluation timeout after {timeout_seconds}sâ€) break # Cancel remaining futures for future in future_to_index: if not future.done(): future.cancel() return fitness_values def _evaluate_particle_safe(self, gains: GainsArray, particle_index: int) -&gt; float: â€œâ€â€Thread-safe particle evaluation with error handling.â€â€â€ start_time = time.time() try: # Create controller controller = self.controller_factory(gains) # Evaluate fitness fitness_value = self.fitness_function(gains, controller) # Record evaluation time evaluation_time = time.time() - start_time with self.evaluation_lock: self.evaluation_times.append(evaluation_time) return fitness_value except Exception as e: logger.warning(fâ€Particle {particle_index} failed: {e}â€) return 3000.0 # High penalty for failures def get_evaluation_statistics(self) -&gt; Dict[str, Any]: â€œâ€â€Get parallel evaluation performance statistics.â€â€â€ with self.evaluation_lock: total_evaluations = self.success_count + self.failure_count success_rate = self.success_count / max(1, total_evaluations) avg_time = np.mean(self.evaluation_times) if self.evaluation_times else 0.0 max_time = np.max(self.evaluation_times) if self.evaluation_times else 0.0 return { â€˜total_evaluationsâ€™: total_evaluations, â€˜success_countâ€™: self.success_count, â€˜failure_countâ€™: self.failure_count, â€˜success_rateâ€™: success_rate, â€˜avg_evaluation_timeâ€™: avg_time, â€˜max_evaluation_timeâ€™: max_time, â€˜total_evaluation_timeâ€™: sum(self.evaluation_times), â€˜parallel_efficiencyâ€™: avg_time * self.n_threads / max(max_time, 0.001) } def cleanup(self): â€œâ€â€Clean up thread pool resources.â€â€â€ self.thread_pool.shutdown(wait=True)<a class="headerlink" href="#runnable-false-class-parallelpsoevaluator-thread-safe-parallel-evaluation-system-for-pso-optimization-features-multi-threaded-fitness-evaluation-load-balancing-across-cpu-cores-memory-efficient-swarm-processing-progress-monitoring-and-early-termination-def-init-self-controller-factory-callable-fitness-function-callable-n-threads-int-4-batch-size-int-8-self-controller-factory-controller-factory-self-fitness-function-fitness-function-self-n-threads-n-threads-self-batch-size-batch-size-thread-management-self-thread-pool-threadpoolexecutor-max-workers-n-threads-self-evaluation-lock-threading-rlock-performance-monitoring-self-evaluation-times-self-success-count-0-self-failure-count-0-def-evaluate-swarm-parallel-self-swarm-positions-np-ndarray-timeout-seconds-float-30-0-list-float-evaluate-entire-swarm-in-parallel-with-timeout-protection-args-swarm-positions-array-of-shape-swarm-size-n-dimensions-timeout-seconds-maximum-time-for-evaluation-returns-list-of-fitness-values-for-each-particle-swarm-size-swarm-positions-shape-0-fitness-values-float-inf-swarm-size-submit-evaluation-tasks-future-to-index-for-i-in-range-swarm-size-future-self-thread-pool-submit-self-evaluate-particle-safe-swarm-positions-i-i-future-to-index-future-i-collect-results-with-timeout-completed-count-0-start-time-time-time-for-future-in-as-completed-future-to-index-timeout-timeout-seconds-try-particle-index-future-to-index-future-fitness-value-future-result-timeout-1-0-individual-timeout-fitness-values-particle-index-fitness-value-with-self-evaluation-lock-self-success-count-1-completed-count-1-except-exception-as-e-particle-index-future-to-index-future-logger-warning-f-particle-particle-index-evaluation-failed-e-with-self-evaluation-lock-self-failure-count-1-use-penalty-value-for-failed-evaluations-fitness-values-particle-index-5000-0-check-for-timeout-if-time-time-start-time-timeout-seconds-logger-warning-f-swarm-evaluation-timeout-after-timeout-seconds-s-break-cancel-remaining-futures-for-future-in-future-to-index-if-not-future-done-future-cancel-return-fitness-values-def-evaluate-particle-safe-self-gains-gainsarray-particle-index-int-float-thread-safe-particle-evaluation-with-error-handling-start-time-time-time-try-create-controller-controller-self-controller-factory-gains-evaluate-fitness-fitness-value-self-fitness-function-gains-controller-record-evaluation-time-evaluation-time-time-time-start-time-with-self-evaluation-lock-self-evaluation-times-append-evaluation-time-return-fitness-value-except-exception-as-e-logger-warning-f-particle-particle-index-failed-e-return-3000-0-high-penalty-for-failures-def-get-evaluation-statistics-self-dict-str-any-get-parallel-evaluation-performance-statistics-with-self-evaluation-lock-total-evaluations-self-success-count-self-failure-count-success-rate-self-success-count-max-1-total-evaluations-avg-time-np-mean-self-evaluation-times-if-self-evaluation-times-else-0-0-max-time-np-max-self-evaluation-times-if-self-evaluation-times-else-0-0-return-total-evaluations-total-evaluations-success-count-self-success-count-failure-count-self-failure-count-success-rate-success-rate-avg-evaluation-time-avg-time-max-evaluation-time-max-time-total-evaluation-time-sum-self-evaluation-times-parallel-efficiency-avg-time-self-n-threads-max-max-time-0-001-def-cleanup-self-clean-up-thread-pool-resources-self-thread-pool-shutdown-wait-true" title="Link to this heading">Â¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">PSO</span> <span class="pre">Progress</span> <span class="pre">Monitoring</span> <span class="pre">and</span> <span class="pre">Early</span> <span class="pre">Termination</span></code>python</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id2">
<h1>example-metadata:<a class="headerlink" href="#id2" title="Link to this heading">Â¶</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="runnable-false-class-psoprogressmonitor-pso-optimization-progress-monitoring-features-convergence-detection-performance-tracking-early-termination-criteria-optimization-health-assessment-def-init-self-convergence-threshold-float-1e-6-stagnation-threshold-int-20-max-evaluation-time-float-0-1-self-convergence-threshold-convergence-threshold-self-stagnation-threshold-stagnation-threshold-self-max-evaluation-time-max-evaluation-time-progress-tracking-self-iteration-history-self-best-fitness-history-self-diversity-history-self-evaluation-time-history-convergence-state-self-converged-false-self-stagnation-count-0-self-best-fitness-float-inf-def-update-progress-self-iteration-int-swarm-positions-np-ndarray-fitness-values-list-float-evaluation-time-float-dict-str-any-update-optimization-progress-and-assess-termination-criteria-returns-progress-update-with-termination-recommendations-update-best-fitness-current-best-min-fitness-values-improvement-self-best-fitness-current-best-if-improvement-self-convergence-threshold-self-best-fitness-current-best-self-stagnation-count-0-else-self-stagnation-count-1-calculate-swarm-diversity-diversity-self-calculate-swarm-diversity-swarm-positions-record-history-self-iteration-history-append-iteration-self-best-fitness-history-append-current-best-self-diversity-history-append-diversity-self-evaluation-time-history-append-evaluation-time-assess-convergence-convergence-status-self-assess-convergence-diversity-improvement-performance-assessment-performance-status-self-assess-performance-evaluation-time-termination-recommendation-should-terminate-termination-reason-self-should-terminate-convergence-status-performance-status-return-iteration-iteration-best-fitness-current-best-improvement-improvement-diversity-diversity-stagnation-count-self-stagnation-count-convergence-status-convergence-status-performance-status-performance-status-should-terminate-should-terminate-termination-reason-termination-reason-evaluation-time-evaluation-time-def-calculate-swarm-diversity-self-swarm-positions-np-ndarray-float-calculate-swarm-diversity-metric-if-len-swarm-positions-2-return-0-0-calculate-pairwise-distances-distances-for-i-in-range-len-swarm-positions-for-j-in-range-i-1-len-swarm-positions-distance-np-linalg-norm-swarm-positions-i-swarm-positions-j-distances-append-distance-return-np-mean-distances-if-distances-else-0-0-def-assess-convergence-self-diversity-float-improvement-float-str-assess-convergence-status-if-improvement-self-convergence-threshold-and-diversity-0-01-return-converged-elif-self-stagnation-count-self-stagnation-threshold-return-stagnated-elif-diversity-0-1-return-low-diversity-elif-improvement-1-0-return-improving-else-return-searching-def-assess-performance-self-evaluation-time-float-str-assess-computational-performance-if-evaluation-time-self-max-evaluation-time-return-slow-elif-evaluation-time-self-max-evaluation-time-0-5-return-moderate-else-return-fast-def-should-terminate-self-convergence-status-str-performance-status-str-tuple-bool-str-determine-if-optimization-should-terminate-early-if-convergence-status-converged-return-true-convergence-achieved-if-convergence-status-stagnated-return-true-f-stagnation-detected-self-stagnation-count-iterations-if-performance-status-slow-and-len-self-evaluation-time-history-10-avg-time-np-mean-self-evaluation-time-history-10-if-avg-time-self-max-evaluation-time-2-return-true-performance-degradation-detected-return-false-continue-optimization-def-generate-optimization-report-self-dict-str-any-generate-optimization-report-return-optimization-summary-total-iterations-len-self-iteration-history-best-fitness-achieved-min-self-best-fitness-history-if-self-best-fitness-history-else-float-inf-final-diversity-self-diversity-history-1-if-self-diversity-history-else-0-0-convergence-status-converged-if-self-converged-else-incomplete-performance-metrics-avg-evaluation-time-np-mean-self-evaluation-time-history-if-self-evaluation-time-history-else-0-0-max-evaluation-time-np-max-self-evaluation-time-history-if-self-evaluation-time-history-else-0-0-total-optimization-time-sum-self-evaluation-time-history-convergence-analysis-fitness-improvement-rate-self-calculate-improvement-rate-diversity-trend-self-calculate-diversity-trend-stagnation-periods-self-identify-stagnation-periods-def-calculate-improvement-rate-self-float-calculate-average-fitness-improvement-rate-if-len-self-best-fitness-history-2-return-0-0-improvements-for-i-in-range-1-len-self-best-fitness-history-improvement-self-best-fitness-history-i-1-self-best-fitness-history-i-improvements-append-max-0-improvement-return-np-mean-improvements-def-calculate-diversity-trend-self-str-calculate-diversity-trend-over-time-if-len-self-diversity-history-10-return-insufficient-data-recent-diversity-np-mean-self-diversity-history-5-earlier-diversity-np-mean-self-diversity-history-10-5-if-recent-diversity-earlier-diversity-0-8-return-decreasing-elif-recent-diversity-earlier-diversity-1-2-return-increasing-else-return-stable-def-identify-stagnation-periods-self-list-tuple-int-int-identify-periods-of-stagnation-in-optimization-stagnation-periods-current-start-none-stagnation-threshold-5-for-i-in-range-1-len-self-best-fitness-history-improvement-self-best-fitness-history-i-1-self-best-fitness-history-i-if-improvement-self-convergence-threshold-if-current-start-is-none-current-start-i-1-else-if-current-start-is-not-none-and-i-current-start-stagnation-threshold-stagnation-periods-append-current-start-i-1-current-start-none-handle-final-stagnation-period-if-current-start-is-not-none-and-len-self-best-fitness-history-current-start-stagnation-threshold-stagnation-periods-append-current-start-len-self-best-fitness-history-1-return-stagnation-periods">
<h1>runnable: false class PSOProgressMonitor: â€œâ€â€ PSO optimization progress monitoring. Features: - Convergence detection - Performance tracking - Early termination criteria - Optimization health assessment â€œâ€â€ def <strong>init</strong>( self, convergence_threshold: float = 1e-6, stagnation_threshold: int = 20, max_evaluation_time: float = 0.1 ): self.convergence_threshold = convergence_threshold self.stagnation_threshold = stagnation_threshold self.max_evaluation_time = max_evaluation_time # Progress tracking self.iteration_history = [] self.best_fitness_history = [] self.diversity_history = [] self.evaluation_time_history = [] # Convergence state self.converged = False self.stagnation_count = 0 self.best_fitness = float(â€˜infâ€™) def update_progress( self, iteration: int, swarm_positions: np.ndarray, fitness_values: List[float], evaluation_time: float ) -&gt; Dict[str, Any]: â€œâ€â€ Update optimization progress and assess termination criteria. Returns: Progress update with termination recommendations â€œâ€â€ # Update best fitness current_best = min(fitness_values) improvement = self.best_fitness - current_best if improvement &gt; self.convergence_threshold: self.best_fitness = current_best self.stagnation_count = 0 else: self.stagnation_count += 1 # Calculate swarm diversity diversity = self._calculate_swarm_diversity(swarm_positions) # Record history self.iteration_history.append(iteration) self.best_fitness_history.append(current_best) self.diversity_history.append(diversity) self.evaluation_time_history.append(evaluation_time) # Assess convergence convergence_status = self._assess_convergence(diversity, improvement) # Performance assessment performance_status = self._assess_performance(evaluation_time) # Termination recommendation should_terminate, termination_reason = self._should_terminate( convergence_status, performance_status ) return { â€˜iterationâ€™: iteration, â€˜best_fitnessâ€™: current_best, â€˜improvementâ€™: improvement, â€˜diversityâ€™: diversity, â€˜stagnation_countâ€™: self.stagnation_count, â€˜convergence_statusâ€™: convergence_status, â€˜performance_statusâ€™: performance_status, â€˜should_terminateâ€™: should_terminate, â€˜termination_reasonâ€™: termination_reason, â€˜evaluation_timeâ€™: evaluation_time } def _calculate_swarm_diversity(self, swarm_positions: np.ndarray) -&gt; float: â€œâ€â€Calculate swarm diversity metric.â€â€â€ if len(swarm_positions) &lt; 2: return 0.0 # Calculate pairwise distances distances = [] for i in range(len(swarm_positions)): for j in range(i + 1, len(swarm_positions)): distance = np.linalg.norm(swarm_positions[i] - swarm_positions[j]) distances.append(distance) return np.mean(distances) if distances else 0.0 def _assess_convergence(self, diversity: float, improvement: float) -&gt; str: â€œâ€â€Assess convergence status.â€â€â€ if improvement &lt; self.convergence_threshold and diversity &lt; 0.01: return â€˜CONVERGEDâ€™ elif self.stagnation_count &gt;= self.stagnation_threshold: return â€˜STAGNATEDâ€™ elif diversity &lt; 0.1: return â€˜LOW_DIVERSITYâ€™ elif improvement &gt; 1.0: return â€˜IMPROVINGâ€™ else: return â€˜SEARCHINGâ€™ def _assess_performance(self, evaluation_time: float) -&gt; str: â€œâ€â€Assess computational performance.â€â€â€ if evaluation_time &gt; self.max_evaluation_time: return â€˜SLOWâ€™ elif evaluation_time &gt; self.max_evaluation_time * 0.5: return â€˜MODERATEâ€™ else: return â€˜FASTâ€™ def _should_terminate( self, convergence_status: str, performance_status: str ) -&gt; Tuple[bool, str]: â€œâ€â€Determine if optimization should terminate early.â€â€â€ if convergence_status == â€˜CONVERGEDâ€™: return True, â€˜Convergence achievedâ€™ if convergence_status == â€˜STAGNATEDâ€™: return True, fâ€™Stagnation detected ({self.stagnation_count} iterations)â€™ if performance_status == â€˜SLOWâ€™ and len(self.evaluation_time_history) &gt; 10: avg_time = np.mean(self.evaluation_time_history[-10:]) if avg_time &gt; self.max_evaluation_time * 2: return True, â€˜Performance degradation detectedâ€™ return False, â€˜Continue optimizationâ€™ def generate_optimization_report(self) -&gt; Dict[str, Any]: â€œâ€â€Generate optimization report.â€â€â€ return { â€˜optimization_summaryâ€™: { â€˜total_iterationsâ€™: len(self.iteration_history), â€˜best_fitness_achievedâ€™: min(self.best_fitness_history) if self.best_fitness_history else float(â€˜infâ€™), â€˜final_diversityâ€™: self.diversity_history[-1] if self.diversity_history else 0.0, â€˜convergence_statusâ€™: â€˜CONVERGEDâ€™ if self.converged else â€˜INCOMPLETEâ€™ }, â€˜performance_metricsâ€™: { â€˜avg_evaluation_timeâ€™: np.mean(self.evaluation_time_history) if self.evaluation_time_history else 0.0, â€˜max_evaluation_timeâ€™: np.max(self.evaluation_time_history) if self.evaluation_time_history else 0.0, â€˜total_optimization_timeâ€™: sum(self.evaluation_time_history) }, â€˜convergence_analysisâ€™: { â€˜fitness_improvement_rateâ€™: self._calculate_improvement_rate(), â€˜diversity_trendâ€™: self._calculate_diversity_trend(), â€˜stagnation_periodsâ€™: self._identify_stagnation_periods() } } def _calculate_improvement_rate(self) -&gt; float: â€œâ€â€Calculate average fitness improvement rate.â€â€â€ if len(self.best_fitness_history) &lt; 2: return 0.0 improvements = [] for i in range(1, len(self.best_fitness_history)): improvement = self.best_fitness_history[i-1] - self.best_fitness_history[i] improvements.append(max(0, improvement)) return np.mean(improvements) def _calculate_diversity_trend(self) -&gt; str: â€œâ€â€Calculate diversity trend over time.â€â€â€ if len(self.diversity_history) &lt; 10: return â€˜INSUFFICIENT_DATAâ€™ recent_diversity = np.mean(self.diversity_history[-5:]) earlier_diversity = np.mean(self.diversity_history[-10:-5]) if recent_diversity &lt; earlier_diversity * 0.8: return â€˜DECREASINGâ€™ elif recent_diversity &gt; earlier_diversity * 1.2: return â€˜INCREASINGâ€™ else: return â€˜STABLEâ€™ def _identify_stagnation_periods(self) -&gt; List[Tuple[int, int]]: â€œâ€â€Identify periods of stagnation in optimization.â€â€â€ stagnation_periods = [] current_start = None stagnation_threshold = 5 for i in range(1, len(self.best_fitness_history)): improvement = self.best_fitness_history[i-1] - self.best_fitness_history[i] if improvement &lt; self.convergence_threshold: if current_start is None: current_start = i - 1 else: if current_start is not None and i - current_start &gt;= stagnation_threshold: stagnation_periods.append((current_start, i - 1)) current_start = None # Handle final stagnation period if current_start is not None and len(self.best_fitness_history) - current_start &gt;= stagnation_threshold: stagnation_periods.append((current_start, len(self.best_fitness_history) - 1)) return stagnation_periods<a class="headerlink" href="#runnable-false-class-psoprogressmonitor-pso-optimization-progress-monitoring-features-convergence-detection-performance-tracking-early-termination-criteria-optimization-health-assessment-def-init-self-convergence-threshold-float-1e-6-stagnation-threshold-int-20-max-evaluation-time-float-0-1-self-convergence-threshold-convergence-threshold-self-stagnation-threshold-stagnation-threshold-self-max-evaluation-time-max-evaluation-time-progress-tracking-self-iteration-history-self-best-fitness-history-self-diversity-history-self-evaluation-time-history-convergence-state-self-converged-false-self-stagnation-count-0-self-best-fitness-float-inf-def-update-progress-self-iteration-int-swarm-positions-np-ndarray-fitness-values-list-float-evaluation-time-float-dict-str-any-update-optimization-progress-and-assess-termination-criteria-returns-progress-update-with-termination-recommendations-update-best-fitness-current-best-min-fitness-values-improvement-self-best-fitness-current-best-if-improvement-self-convergence-threshold-self-best-fitness-current-best-self-stagnation-count-0-else-self-stagnation-count-1-calculate-swarm-diversity-diversity-self-calculate-swarm-diversity-swarm-positions-record-history-self-iteration-history-append-iteration-self-best-fitness-history-append-current-best-self-diversity-history-append-diversity-self-evaluation-time-history-append-evaluation-time-assess-convergence-convergence-status-self-assess-convergence-diversity-improvement-performance-assessment-performance-status-self-assess-performance-evaluation-time-termination-recommendation-should-terminate-termination-reason-self-should-terminate-convergence-status-performance-status-return-iteration-iteration-best-fitness-current-best-improvement-improvement-diversity-diversity-stagnation-count-self-stagnation-count-convergence-status-convergence-status-performance-status-performance-status-should-terminate-should-terminate-termination-reason-termination-reason-evaluation-time-evaluation-time-def-calculate-swarm-diversity-self-swarm-positions-np-ndarray-float-calculate-swarm-diversity-metric-if-len-swarm-positions-2-return-0-0-calculate-pairwise-distances-distances-for-i-in-range-len-swarm-positions-for-j-in-range-i-1-len-swarm-positions-distance-np-linalg-norm-swarm-positions-i-swarm-positions-j-distances-append-distance-return-np-mean-distances-if-distances-else-0-0-def-assess-convergence-self-diversity-float-improvement-float-str-assess-convergence-status-if-improvement-self-convergence-threshold-and-diversity-0-01-return-converged-elif-self-stagnation-count-self-stagnation-threshold-return-stagnated-elif-diversity-0-1-return-low-diversity-elif-improvement-1-0-return-improving-else-return-searching-def-assess-performance-self-evaluation-time-float-str-assess-computational-performance-if-evaluation-time-self-max-evaluation-time-return-slow-elif-evaluation-time-self-max-evaluation-time-0-5-return-moderate-else-return-fast-def-should-terminate-self-convergence-status-str-performance-status-str-tuple-bool-str-determine-if-optimization-should-terminate-early-if-convergence-status-converged-return-true-convergence-achieved-if-convergence-status-stagnated-return-true-f-stagnation-detected-self-stagnation-count-iterations-if-performance-status-slow-and-len-self-evaluation-time-history-10-avg-time-np-mean-self-evaluation-time-history-10-if-avg-time-self-max-evaluation-time-2-return-true-performance-degradation-detected-return-false-continue-optimization-def-generate-optimization-report-self-dict-str-any-generate-optimization-report-return-optimization-summary-total-iterations-len-self-iteration-history-best-fitness-achieved-min-self-best-fitness-history-if-self-best-fitness-history-else-float-inf-final-diversity-self-diversity-history-1-if-self-diversity-history-else-0-0-convergence-status-converged-if-self-converged-else-incomplete-performance-metrics-avg-evaluation-time-np-mean-self-evaluation-time-history-if-self-evaluation-time-history-else-0-0-max-evaluation-time-np-max-self-evaluation-time-history-if-self-evaluation-time-history-else-0-0-total-optimization-time-sum-self-evaluation-time-history-convergence-analysis-fitness-improvement-rate-self-calculate-improvement-rate-diversity-trend-self-calculate-diversity-trend-stagnation-periods-self-identify-stagnation-periods-def-calculate-improvement-rate-self-float-calculate-average-fitness-improvement-rate-if-len-self-best-fitness-history-2-return-0-0-improvements-for-i-in-range-1-len-self-best-fitness-history-improvement-self-best-fitness-history-i-1-self-best-fitness-history-i-improvements-append-max-0-improvement-return-np-mean-improvements-def-calculate-diversity-trend-self-str-calculate-diversity-trend-over-time-if-len-self-diversity-history-10-return-insufficient-data-recent-diversity-np-mean-self-diversity-history-5-earlier-diversity-np-mean-self-diversity-history-10-5-if-recent-diversity-earlier-diversity-0-8-return-decreasing-elif-recent-diversity-earlier-diversity-1-2-return-increasing-else-return-stable-def-identify-stagnation-periods-self-list-tuple-int-int-identify-periods-of-stagnation-in-optimization-stagnation-periods-current-start-none-stagnation-threshold-5-for-i-in-range-1-len-self-best-fitness-history-improvement-self-best-fitness-history-i-1-self-best-fitness-history-i-if-improvement-self-convergence-threshold-if-current-start-is-none-current-start-i-1-else-if-current-start-is-not-none-and-i-current-start-stagnation-threshold-stagnation-periods-append-current-start-i-1-current-start-none-handle-final-stagnation-period-if-current-start-is-not-none-and-len-self-best-fitness-history-current-start-stagnation-threshold-stagnation-periods-append-current-start-len-self-best-fitness-history-1-return-stagnation-periods" title="Link to this heading">Â¶</a></h1>
<div class="highlight-This notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Research Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            <div class="last-updated">
              Last updated on Oct 10, 2025</div>
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=4ebf8126"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=08e7b316"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../_static/back-to-top.js?v=840797bb"></script>
    <script src="../_static/lazy-load.js?v=dc25293c"></script>
    <script src="../_static/dark-mode.js?v=bf328970"></script>
    </body>
</html>