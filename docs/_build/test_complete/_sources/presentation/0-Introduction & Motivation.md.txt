# Abstract This project presents a holistic software framework for the automated design and validation of robust nonlinear controllers. By synergizing sliding mode control (SMC) with particle swarm optimization (PSO), the framework delivers a toolchain to solve the canonical double inverted pendulum problem. It integrates multiple controller architectures, a dual‑model simulation environment, an interactive command‑line interface and a web‑based dashboard, a lightweight fault detection module and networked hardware‑in‑the‑loop testing. Together, these components bridge the gap between theoretical controller design and practical deployment, illustrating a generalizable methodology for the robust control of complex nonlinear systems.

## Introduction and Motivation

The pursuit of high‑performance, robust control for complex nonlinear systems remains a central challenge in modern engineering \[6\]. Such systems, characterized by inherent instabilities, coupled dynamics and susceptibility to uncertainties, are ubiquitous in fields ranging from robotics and aerospace to energy systems \[3\]. Designing controllers that can guarantee stability and performance in the face of real‑world variability is not merely an academic exercise but a critical necessity for the development of reliable and autonomous technologies \[6\]. This work addresses this challenge through the lens of a canonical benchmark problem – the double inverted pendulum (DIP) – and proposes a systematic design methodology that synergizes the inherent robustness of sliding mode control (SMC) with the global search features of particle swarm optimization (PSO) to automate the synthesis of a high‑performance, resilient controller \[15\]. **A Software Framework** In addition to the algorithmic contributions, the project provides a complete software framework for interactive exploration and deployment. A command‑line interface (`simulate.py`) exposes tasks such as running simulations, tuning controllers using PSO, performing hardware‑in‑the‑loop (HIL) experiments and exporting results. For non‑experts, an intuitive Streamlit dashboard (`streamlit_app.py`) offers sliders and drop‑downs to select the controller type, modify physical parameters, adjust optimization weights and inject disturbances, all while visualizing state trajectories and control signals in real time. This dual interface lowers the barrier to entry and allows both researchers and practitioners to explore the effects of controller design choices without writing code. **Bridging Simulation and Deployment** Finally, the framework supports networked hardware‑in‑the‑loop experiments. The plant server (`src/hil/plant_server.py`) runs the pendulum model in a separate process and communicates over UDP with a controller client (`src/hil/controller_client.py`). Adjustable sensor noise and network latency emulate the uncertainties of a real laboratory setup. By validating controllers under these conditions, the toolchain bridges the gap between simulation and physical deployment and ensures that the tuned gains are not brittle to implementation artefacts. ### The Double Inverted Pendulum as a Canonical Control Problem Within control theory, certain systems serve as canonical benchmarks for developing and validating advanced control strategies. Among these, the double inverted pendulum (DIP) mounted on a cart stands out as a particularly formidable challenge \[3\]. Its popularity as a testbed stems from its rich dynamic behaviour, which encapsulates many of the difficulties encountered in real‑world engineering applications \[3\]. The DIP system is defined by several key characteristics that make it an ideal platform for rigorous controller evaluation: \- **Highly nonlinear dynamics:** The equations of motion governing the DIP are derived from Lagrangian mechanics and contain trigonometric coupling between states; this nonlinearity precludes the effective use of simple linear controllers (e.g. PID) for global stabilization \[3\]. - **Inherent instability:** The desired operating point – both pendulums balanced in the upright position – is an unstable equilibrium. Without continuous and precise control action, the system will rapidly diverge and collapse \[2\]. - **Underactuation (i.e., fewer control inputs than degrees of freedom):** The system has three degrees of freedom (the cart’s horizontal position and two pendulum angles) but only a single actuator (a horizontal force on the cart). This property, where the number of control inputs is less than the number of degrees of freedom, is a hallmark of many complex mechanical systems and represents a significant control design challenge \[3\]. - **Multiple‑input, multiple‑output nature:** From a control perspective, the single input must simultaneously regulate multiple outputs (the two pendulum angles and the cart position), effectively yielding a multi‑output system driven by one control signal \[3\]. Due to this confluence of challenging properties, the DIP serves as a crucial analogue for a wide array of practical systems. Its stabilization dynamics are representative of problems in bipedal robotics (humanoid balancing), attitude control of aerospace vehicles and active vibration damping in structures. Consequently, a control strategy that demonstrates robust performance on the DIP provides a strong indication of its potential applicability to these more complex, real‑world domains \[2\]. A notable feature of our implementation is the **dual‑model simulation framework**. Two distinct dynamical models are provided: a simplified model (`src/core/dynamics.py`) and a full, high‑fidelity nonlinear model (`src/core/dynamics_full.py`). The simplified model uses approximate expressions for the inertia and coupling terms and is computationally cheap, making it well suited for iterative tuning and PSO searches. The full model retains exact expressions for the inertia matrix, Coriolis and centrifugal forces and gravitational effects, thereby capturing subtle dynamical phenomena ignored in the simplified model. Controllers can therefore be tuned on the simplified plant for speed and validated on the full plant to evaluate robustness against modelling errors. This dual‑model approach mirrors common engineering practice, where control design uses an approximate model while testing relies on a more accurate model or the real system. ### The Primary Control Objectives and Challenges The control problem for the DIP is typically defined by two primary (and often concurrent) objectives: 1. **Stabilization:** Maintain both pendulums in their unstable upright equilibrium (i.e. angles close to zero) despite initial deviations or perturbations.
2. **Tracking:** Command the cart’s horizontal position to follow a desired trajectory (e.g. set‑point changes or a reference path) without destabilizing the pendulums. Achieving these objectives is complicated by the central challenge of **robustness**. A theoretically sound controller designed for a nominal model may fail in practice due to discrepancies between the model and the real system. These discrepancies arise from two main sources: **parametric uncertainties** and **external disturbances** \[3\]. Parametric uncertainties include variations or unknown values in physical parameters (masses of the cart/pendulums, link lengths, friction coefficients, etc.) that may not be known precisely or can change over time \[5\]. External disturbances encompass unmodelled forces acting on the system (e.g. wind gusts, impacts or sensor noise) \[3\]. A truly effective controller must exhibit resilience to these factors, maintaining stability and performance despite their presence. To address the challenge of unforeseen faults and disturbances, the project incorporates a **fault detection and isolation (FDI) system**. The FDI module (`src/fault_detection/fdi.py`) monitors the residual between a model‑based one‑step prediction of the state and the actual sensor measurements. If this residual norm exceeds a user‑specified threshold for a specified number of consecutive samples, the system flags a fault. The FDI is lightweight and modular: it can be attached to any dynamics model conforming to a simple protocol and can be extended to incorporate an extended Kalman filter for state estimation. By detecting anomalies such as sensor failures or unmodelled disturbances early, the FDI improves reliability and supports fault‑tolerant control. Moreover, the Streamlit dashboard enables **interactive disturbance injection**. Users can define deterministic or stochastic disturbances – for example, a sinusoidal force applied to the cart or an impulsive push – and apply them during a simulation run. Sliders control the amplitude, duration and time of application of the disturbance, and the resulting state trajectories are plotted in real time. This interactive testing environment allows researchers to directly assess the controller’s resilience and disturbance rejection capability, complementing the automated robustness analysis performed during PSO tuning. ### Sliding Mode Control as a Robust Solution To address the critical need for robustness, this work employs **sliding mode control**, a nonlinear control technique renowned for its insensitivity to a class of uncertainties and disturbances \[3\]. The fundamental mechanism of SMC involves a two‑stage process \[6\]. First, a **sliding surface** (a defined manifold or stable path in the state space) is designed such that any trajectory constrained to this surface exhibits desired stable behaviour (e.g. convergence of pendulum angles to zero). Second, a discontinuous control law is synthesized to drive the system’s state trajectory onto this surface in finite time and maintain it there indefinitely \[4\]. Once the system state reaches the sliding surface, the subsequent motion is governed by the reduced‑order dynamics of that surface rather than the full system dynamics. In this **sliding mode**, the closed‑loop system becomes theoretically invariant to matched uncertainties or disturbances, yielding exceptional robustness \[4\]. This property makes SMC an ideal candidate for underactuated systems like the DIP, where precise model knowledge is often unavailable \[6\]. However, the discontinuous nature of a conventional SMC control law introduces a significant practical drawback: the **chattering** phenomenon. Chattering manifests as high‑frequency, finite‑amplitude oscillations in the control signal – essentially a high‑frequency vibration – as the state repeatedly crosses the sliding surface \[8\]. This effect is undesirable since it can excite unmodelled high‑frequency dynamics and cause excessive wear in mechanical actuators \[7\]. To mitigate chattering, various improvements to SMC have been developed. One common approach is to introduce a thin **boundary layer** around the sliding surface, replacing the ideal discontinuous switching with a continuous saturation function. This continuous approximation trades off perfect accuracy on the sliding manifold for reduced high‑frequency switching, thereby alleviating chattering at the expense of a small steady‑state error \[1, 2\]. Alternatively, higher‑order sliding mode techniques avoid direct discontinuous control altogether \[9\]. This research specifically considers the **super‑twisting algorithm (STA)** – a second‑order SMC method that achieves the robustness of sliding mode control while generating a continuous control signal, effectively suppressing chattering without sacrificing performance \[7, 8\]. The software implements a suite of SMC variants to systematic comparison of different control philosophies: 1. **ClassicalSMC:** The classical first‑order SMC controller (`src/controllers/classic_smc.py`) implements a linear sliding surface and an equivalent control term combined with a robust switching term. A boundary‑layer modification uses a hyperbolic tangent to saturate the switching term, reducing chattering and allowing the control to be saturated within a user‑specified boundary layer \[4\].
2. **AdaptiveSMC:** The adaptive sliding mode controller (`src/controllers/adaptive_smc.py`) dynamically adjusts the switching gain *K* online according to an adaptation law. A leak term pulls *K* towards an initial value, a dead‑zone around the sliding surface prevents wind‑up and a rate limit on the adaptation constrains abrupt changes. This online tuning allows the controller to compensate for time‑varying uncertainties without manual retuning \[6\].
3. **SwingUpSMC:** Because the inverted equilibrium is hard to reach from a downward hanging configuration, the swing‑up controller (`src/controllers/swing_up_smc.py`) uses an energy‑based law to pump energy into the pendulums until they are sufficiently upright and then hands control over to a stabilizing SMC. Hysteresis based on energy thresholds and angle tolerances ensures a smooth transition between the swing‑up and stabilization modes \[1\].
4. **HybridAdaptiveSTASMC:** The hybrid adaptive super‑twisting controller (`src/controllers/hybrid_adaptive_sta_smc.py`) combines a second‑order sliding surface with adaptive gain adjustment. The super‑twisting algorithm generates a continuous control signal that is proportional to the square root of the sliding variable, and two adaptive gains (*k₁* and *k₂*) are updated online using adaptation rates γ₁ and γ₂. A dead‑zone freezes the adaptation when the sliding variable is small, preventing gain wind‑up. This variant marries the robustness of the STA with the flexibility of adaptive gain tuning and has been particularly successful at suppressing chattering \[8\]. The availability of these controllers within a unified framework allows researchers to explore how boundary‑layer tuning, adaptive laws, energy‑based swing‑up and higher‑order SMC interact with the DIP dynamics. Users can switch between controllers in the Streamlit app or CLI and directly observe differences in transient response, control effort and robustness. ### The Gain Tuning Dilemma and the Need for Optimization The efficacy of any SMC (including STA) is critically dependent on the judicious selection of its design parameters. These include the coefficients that define the sliding surface (e.g. *λ₁*, *λ₂*) and the gains that dictate the speed of convergence and the magnitude of the control action (e.g. the switching gain *K*). Determining these parameters – known as **gain tuning** – presents a significant challenge. Traditionally, gain tuning is a manual, iterative process that relies heavily on expert insight and trial‑and‑error. This approach is labour‑intensive, time‑consuming and often yields sub‑optimal results \[10, 11\]. The core difficulty lies in the fact that tuning the controller involves an inherently multi‑objective optimization problem \[11\]. Multiple performance criteria must be balanced, and these criteria can conflict with one another. For instance, aggressive gains yield rapid convergence but large control forces, while conservative gains reduce control effort but result in sluggish response and poorer disturbance rejection. Manually exploring this high‑dimensional trade‑off space to find an acceptable balance is impractical and unlikely to yield a truly optimal solution. In our project this trade‑off is formalised through an explicit **multi‑objective cost function** defined in `config.yaml`. The cost function is a weighted sum of four terms: the integrated squared state error, the integrated squared control effort, the integrated squared control rate (slew) and the integrated squared sliding variable. In the default configuration, the weights are 50.0 for state error, 0.2 for control effort, 0.1 for control rate and 0.1 for stability, reflecting a strong preference for accurate tracking while penalising excessive control magnitude and rapid changes. A large penalty of 1000 is applied if the system becomes unstable (e.g. the pendulum angles exceed ±90° or the state diverges). By casting performance requirements into a concrete scalar objective, this formulation turns the abstract trade‑off into a solvable optimization problem and allows systematic tuning without subjective judgement \[11, 12\]. ### Particle Swarm Optimization for Automated Design To overcome the inefficiencies and sub‑optimality of manual tuning, we uses **particle swarm optimization** – a metaheuristic algorithm inspired by the collective social behaviour observed in bird flocking and fish schooling \[13\]. PSO is a population‑based, stochastic optimization technique that has demonstrated remarkable success in solving complex, high‑dimensional and non‑differentiable optimization problems \[14\]. In a PSO algorithm, a population of candidate approaches (called “particles”) explores the search space simultaneously. Each particle’s position encodes a set of controller parameters, and its trajectory through the space is influenced by both its own best‑found solution and the best‑known solution of the entire swarm. Through this cooperative mechanism, the swarm iteratively converges toward a globally optimal or near‑optimal solution. PSO offers several distinct advantages in the context of controller tuning: - **Derivative‑free optimization:** PSO does not require gradient information of the objective function, making it well suited for simulation‑based optimization where analytical gradients are unavailable or expensive to obtain \[16\].
- **Global search capability:** The stochastic, population‑based nature of PSO helps it avoid entrapment in local minima, a common pitfall for traditional gradient‑based search methods \[15\].
- **Computational efficiency:** Compared to many other evolutionary algorithms, PSO is relatively easy to implement and has been shown to converge quickly on a wide range of problems \[10\].
- **Automated tuning process:** PSO provides a systematic, automated framework for exploring the controller parameter space, replacing the ad‑hoc nature of manual tuning with a repeatable, data‑driven design procedure. The practical viability of PSO in this domain is evidenced by its integration into our project’s architecture: a dedicated PSO tuner module (`src/optimizer/pso_optimizer.py`) implements a high‑throughput, vectorised PSO. The tuner evaluates an entire swarm of candidate gain vectors simultaneously using a batch simulator, computes the cost function defined above and updates the particles’ positions according to PSO dynamics. Hyperparameters such as inertia weight and cognitive/social coefficients are themselves subject to a hyperparameter search, and convergence criteria can be adjusted via the YAML configuration. Critically, the tuner supports **robust optimization via perturbation**. Each particle’s candidate gains are not only evaluated on the nominal plant but also on multiple **perturbed physics models** drawn from uncertainty ranges specified in `physics_uncertainty`. For example, the masses, lengths, centres of mass and friction coefficients of the pendulums and cart are randomly varied by ±5 % over ten evaluations, and the cost across these runs is combined using a convex combination of the mean and maximum to penalise poor performance on any draw. A large instability penalty is applied if any trajectory diverges. The resulting best gains therefore maximise performance on average while hedging against worst‑case parameter variations, enhancing the controller’s resilience to modelling errors \[12\]. ### Synthesis and Motivation This research is ultimately motivated by the need to bridge the gap between advanced theoretical control concepts and their practical, optimized implementation for challenging real‑world systems. The double inverted pendulum, with its complex and unstable dynamics, serves as an ideal representative of this class of problems. While sliding mode control offers a theoretically robust framework for such systems, its performance in practice hinges on proper tuning of its parameters – a task poorly suited to manual methods due to the multi‑objective and complex nature discussed above. The proposed methodology automates this design process by combining PSO with SMC and augments it with modern software engineering practices. The resulting framework achieves several key objectives: - **Performance:** By automatically tuning gains according to a multi‑objective cost function, the method attains superior stabilization and tracking performance that surpasses typical manual tuning.
- **Multi‑objective design:** The explicit weighting of state error, control effort, control rate and stability captures the designer’s priorities and allows PSO to balance conflicting objectives in a principled manner.
- **Reduced tuning effort:** The automated search eliminates the need for laborious trial‑and‑error, making advanced SMC techniques accessible to practitioners without specialist expertise.
- **Robustness:** Robust optimization via perturbed models and adaptive SMC variants enhances resilience to parametric uncertainties and external disturbances.
- **tooling:** A dual‑model simulation environment, integrated FDI system, interactive CLI and Streamlit dashboard and HIL support provide a path from theoretical design to practical deployment. A rigorous automated test suite ensures reliability and reproducibility throughout the software stack. Ultimately, this work presents a holistic framework that not only solves a classic, difficult control problem but also provides a generalizable methodology for the automated design, testing and deployment of high‑performance robust controllers in a wide range of complex, nonlinear dynamical systems.

### References

1.  **Double Inverted Pendulum – Will Beattie** – *accessed August 24, 2025*, available at: <http://willbeattie.ca/post/engineering/pendulum/>
2. **PEARL: Dual Mode Control of an Inverted Pendulum – Design and Implementation** – *accessed August 24, 2025*, available at: <https://researchportal.plymouth.ac.uk/files/46139792/ASTESJ_080613.pdf>
3. **Inverted Pendulum System Disturbance and Uncertainty Effects Reduction using Sliding Mode‑Based Control Design** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/351759418_Inverted_Pendulum_System_Disturbance_and_Uncertainty_Effects_Reduction_using_Sliding_Mode-Based_Control_Design>
4. **Sliding Mode Control of a Class of Underactuated System With Non‑Integrable Momentum – Queen’s University Belfast** – *accessed August 24, 2025*, available at: <https://pureadmin.qub.ac.uk/ws/files/214238289/multi_link_robot_r1_M3.pdf>
5. **Project Documentation: SMC via PSO for DIP (text file)** – *accessed August 24, 2025*, *internal project document*
6. **Sliding Mode Control Design for Stabilization of Underactuated Mechanical Systems** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/332301486_Sliding_mode_control_design_for_stabilization_of_underactuated_mechanical_systems>
7. **Chattering Analysis of the System with Higher Order Sliding Mode Control** – *OhioLINK Electronic Theses, accessed August 24, 2025*, available at: <https://rave.ohiolink.edu/etdc/view?acc_num=osu1444243591>
8. **Chattering Analysis of Conventional and Super Twisting Sliding Mode Control Algorithms** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/306064507_Chattering_analysis_of_conventional_and_super_twisting_sliding_mode_control_algorithm>
9. **Analysis of Chattering in Continuous Sliding Mode Control** – *Proc. American Control Conference 2005, accessed August 24, 2025*, available at: <https://skoge.folk.ntnu.no/prost/proceedings/acc05/PDFs/Papers/0430_ThB05_3.pdf>
10. **Tuning of PID Controller Using Particle Swarm Optimization (PSO)** – *accessed August 24, 2025*, available at: <https://ijaseit.insightsociety.org/index.php/ijaseit/article/view/93>
11. **Tuning Equations for Sliding Mode Controllers: An Optimal Multi‑Objective Approach for Non‑minimum Phase Systems** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/383074023_Tuning_Equations_for_Sliding_Mode_Controllers_An_Optimal_Multi-Objective_Approach_for_Non-minimum_Phase_Systems>
12. **Multi‑Objective Optimization‑Based Tuning of Two Second‑Order Sliding‑Mode Controller Variants for DFIGs Connected to Non‑Ideal Grid Voltage** – *MDPI Energies 12(19):3782, 2019; accessed August 24, 2025*, available at: <https://www.mdpi.com/1996-1073/12/19/3782>
13. **A Review of Particle Swarm Optimization** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/301272239_A_Comprehensive_Review_of_Particle_Swarm_Optimization>
14. **Set‑Based Particle Swarm Optimisation: A Review** – *MDPI Mathematics 11(13):2980, 2023; accessed August 24, 2025*, available at: <https://www.mdpi.com/2227-7390/11/13/2980>
15. **An Optimal PSO‑Based Sliding‑Mode Control Scheme for the Robot Manipulator** – *accessed August 24, 2025*, available at: <https://www.researchgate.net/publication/366016236_An_Optimal_PSO-Based_Sliding-Mode_Control_Scheme_for_the_Robot_Manipulator>
16. **Advantages of Particle Swarm Optimization over Bayesian Optimization for Hyperparameter Tuning? – Cross Validated (StackExchange)** – *accessed August 24, 2025*, available at: <https://stats.stackexchange.com/questions/194056/advantages-of-particle-swarm-optimization-over-bayesian-optimization-for-hyperparameter-tuning> ------------------------------------------------------------------------ ------------------------------------------------------------------------
