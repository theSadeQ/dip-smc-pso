<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="Validation Examples: Practical Implementation Guide Document Status: Phase 3.3 Completion - Executable Examples" href="validation_examples.html"><link rel="prev" title="Simulation Validation Guide &gt; Note: Simulation validation is covered in multiple guides. ## Quick Links - Validation Examples - Practical validation patterns" href="simulation_validation_guide.html">

    <!-- Generated with Sphinx 7.4.7 and Furo 2025.09.25 -->
        <title>Simulation Result Validation Methodology Document Status: Phase 3.3 Completion - Monte Carlo and Statistical Testing Framework - DIP_SMC_PSO Documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">DIP_SMC_PSO Documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">DIP_SMC_PSO Documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../ACADEMIC_INTEGRITY_STATEMENT.html">Academic Integrity Statement <strong>Status:</strong> To be completed in Phase B (Citation System Implementation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOG.html">Changelog All notable changes to the ResearchPlan validation system will be documented in this file. The format is based on Keep a Changelog,</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CITATIONS.html">Citations &amp; Academic Attribution <strong>Project:</strong> Double Inverted Pendulum - Sliding Mode Control with PSO Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CITATIONS_ACADEMIC.html">Academic Theory Citations &amp; References <strong>Project:</strong> Double Inverted Pendulum - Sliding Mode Control with PSO Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CITATION_SYSTEM.html">Citation System Documentation <strong>Status:</strong> To be completed in Phase B (Citation System Implementation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing – ResearchPlanSpec Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTROLLER_FACTORY.html">Controller Factory Documentation &gt; <strong>Note:</strong> This document has been consolidated into the Factory System Guide. ## Quick Links - <strong><span class="xref myst">Factory System Guide</span></strong> - Complete controller factory documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CROSS_REFERENCE_AUDIT_REPORT.html">Documentation Cross-Reference Audit Report <strong>Report Date:</strong> 2025-10-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DEPENDENCIES.html">Software Dependencies &amp; Citations <strong>Project:</strong> Double Inverted Pendulum - Sliding Mode Control with PSO Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DOCUMENTATION_COVERAGE_MATRIX.html">Documentation Coverage Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DOCUMENTATION_IMPLEMENTATION_PLAN.html">Documentation Coverage Implementation Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DOCUMENTATION_INVENTORY_SUMMARY.html">DIP-SMC-PSO Documentation Inventory Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DOCUMENTATION_STYLE_GUIDE.html">Documentation Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../DOCUMENTATION_SYSTEM.html">📚 World-Class Documentation System for DIP_SMC_PSO ## 🌟 Overview This repository now features a <strong>world-class technical documentation system</strong> designed for research-grade publications. The system provides LaTeX-quality mathematical rendering, professional citation management, and cross-referencing features. ## ✨ Features ### 🔬 Research-Grade Mathematics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../EXAMPLE_VALIDATION_REPORT.html">Documentation Code Example Validation Report <strong>Report Date:</strong> 2025-10-07</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LICENSES.html">License Compliance &amp; Attribution <strong>Project:</strong> Double Inverted Pendulum - Sliding Mode Control with PSO Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PACKAGE_CONTENTS.html">Sphinx Documentation Implementation Package ## 📁 Package Contents for ChatGPT Review This package contains the complete implementation of production-grade Sphinx documentation with GitHub CI/CD based on expert recommendations. ### 🚀 Core Implementation Files #### GitHub Workflows (Enhanced CI/CD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PATTERNS.html">Software Design Patterns &amp; Architecture Attribution <strong>Project:</strong> Double Inverted Pendulum - Sliding Mode Control with PSO Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PATTERNS.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PATTERNS.html#runnable-false-src-controllers-factory-py-lines-507-543-def-create-controller-controller-type-str-config-optional-any-none-gains-optional-union-list-np-ndarray-none-any-create-a-controller-instance-of-the-specified-type-this-function-is-thread-safe-and-can-be-called-concurrently-supported-types-classical-smc-sta-smc-adaptive-smc-hybrid-adaptive-sta-smc-mpc-controller-normalize-controller-type-handles-aliases-controller-type-canonicalize-controller-type-controller-type-retrieve-from-registry-controller-info-get-controller-info-controller-type-controller-class-controller-info-class-resolve-gains-from-config-defaults-controller-gains-resolve-controller-gains-gains-config-controller-type-validate-gains-with-controller-specific-rules-validate-controller-gains-controller-gains-controller-info-create-and-return-configured-instance-return-controller-class-controller-gains-kwargs">runnable: false # src/controllers/factory.py (lines 507-543) def create_controller(controller_type: str, config: Optional[Any] = None, gains: Optional[Union[list, np.ndarray]] = None) -&gt; Any: “”” Create a controller instance of the specified type. This function is thread-safe and can be called concurrently. Supported types: ‘classical_smc’, ‘sta_smc’, ‘adaptive_smc’, ‘hybrid_adaptive_sta_smc’, ‘mpc_controller’ “”” # Normalize controller type (handles aliases) controller_type = _canonicalize_controller_type(controller_type) # Retrieve from registry controller_info = _get_controller_info(controller_type) controller_class = controller_info[‘class’] # Resolve gains from config/defaults controller_gains = _resolve_controller_gains(gains, config, controller_type) # Validate gains with controller-specific rules _validate_controller_gains(controller_gains, controller_info) # Create and return configured instance return controller_class(controller_gains, **kwargs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PATTERNS.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PATTERNS.html#runnable-false-src-utils-validation-parameter-validators-py-def-validate-gains-n-expected-int-decorator-to-validate-gain-array-length-def-decorator-func-def-wrapper-self-gains-args-kwargs-if-len-gains-n-expected-raise-valueerror-f-expected-n-expected-gains-got-len-gains-return-func-self-gains-args-kwargs-return-wrapper-return-decorator-usage">runnable: false # src/utils/validation/parameter_validators.py def validate_gains(n_expected: int): “””Decorator to validate gain array length.””” def decorator(func): def wrapper(self, gains, *args, **kwargs): if len(gains) != n_expected: raise ValueError(f”Expected {n_expected} gains, got {len(gains)}”) return func(self, gains, *args, **kwargs) return wrapper return decorator # Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PLANT_CONFIGURATION.html">Plant Configuration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PSO_Documentation_Validation_Report.html">PSO Documentation Validation Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PSO_INTEGRATION_GUIDE.html">PSO Integration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../QUICKSTART_VALIDATION.html">Quick Start: Issue #12 Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Optimal Sliding Mode Control for a Double-Inverted Pendulum via PSO </a></li>
<li class="toctree-l1"><a class="reference internal" href="../RELEASE_CHECKLIST.html">Release Checklist Use this checklist when preparing a new release of the ResearchPlan validation system. ## Pre-Release ### Code &amp; Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_100_PERCENT_COMPLETION_REPORT.html">Sphinx Documentation - 100% Warning Elimination Complete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE10_COMPLETION_REPORT.html">Sphinx Phase 10 Completion Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE11_COMPLETION_REPORT.html">Sphinx Phase 11 Completion Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE2_COMPLETION_REPORT.html">Phase 2 Completion Report: Live Python Code Execution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE3_COMPLETION_REPORT.html">Phase 3 Completion Report: Plotly Interactive Charts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE4_COMPLETION_REPORT.html">Phase 4: Jupyter Notebooks Integration - Completion Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE5_COMPLETION_REPORT.html">Phase 5 Completion Report: Mathematical Visualization Library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE6_COMPLETION_REPORT.html">Phase 6 Completion Report: Progressive Web App (PWA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE8_SUMMARY.html">Sphinx Documentation Phase 8 - Final Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SPHINX_PHASE9_PROGRESS_REPORT.html">Sphinx Documentation Phase 9 - Final Progress Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TESTING.html">Testing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis_plan.html">5. Analysis &amp; Verification Plan ## 🔧 <strong>Recent Testing Infrastructure Improvements</strong> (September 2024) ### <strong>Vector Simulation Engine Robustness</strong> The vector simulation engine (<code class="docutils literal notranslate"><span class="pre">src/simulation/engines/vector_sim.py</span></code>) has been enhanced with edge case handling and improved reliability: #### <strong>✅ Fixes Applied</strong> 1. <strong>Scalar Control Input Support</strong> - <strong>Issue</strong>: <code class="docutils literal notranslate"><span class="pre">IndexError</span></code> when control input was 0-dimensional scalar - <strong>Fix</strong>: Added proper scalar handling with <code class="docutils literal notranslate"><span class="pre">.item()</span></code> extraction for 0D arrays - <strong>Benefit</strong>: Supports simplified test scenarios and edge cases 2. <strong>Flexible Control Sequence Length</strong> - <strong>Issue</strong>: Crashes when simulation horizon exceeded control input sequence length - <strong>Fix</strong>: Implemented graceful bounds checking with <code class="docutils literal notranslate"><span class="pre">min(i,</span> <span class="pre">length-1)</span></code> indexing strategy - <strong>Benefit</strong>: Uses last available control input when sequence is exhausted 3. <strong>Empty State Array Handling</strong> - <strong>Issue</strong>: Tests expected exceptions for empty arrays, but function handled them gracefully - <strong>Fix</strong>: Updated test expectations to match actual behavior (returns <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">0)</span></code> shaped array) - <strong>Benefit</strong>: Consistent behavior for degenerate cases 4. <strong>Mock Function Accuracy</strong> - <strong>Issue</strong>: Test mocks didn’t reflect actual physics-based state evolution - <strong>Fix</strong>: Updated mock dynamics to properly simulate <code class="docutils literal notranslate"><span class="pre">state</span> <span class="pre">+</span> <span class="pre">dt</span> <span class="pre">*</span> <span class="pre">state_derivative</span></code> evolution - <strong>Benefit</strong>: Tests now validate realistic controller-plant interactions #### <strong>✅ Test Coverage Improvements</strong> <strong>Vector Simulation Test Suite</strong>: Now <strong>100% passing</strong> (20/21 tests pass, 1 skipped)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">API Reference Documentation</a><input aria-label="Toggle navigation of API Reference Documentation" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/controller_api_reference.html">Controller API Reference &gt; <strong>Note:</strong> Controller API documentation has been consolidated into references. ## Quick Links - <strong><span class="xref myst">Factory System API</span></strong> - Complete factory and controller creation API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/controller_theory.html">Controller Theory Reference <strong>Status:</strong> 🚧 Under Construction This document will contain controller theory documentation including: ## Planned Content ### Sliding Mode Control Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html">Factory System API Reference <strong>Module:</strong> <code class="docutils literal notranslate"><span class="pre">src.controllers.factory</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-thread-safe-factory-operations-with-timeout-protection">runnable: false # Thread-safe factory operations with timeout protection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-def-list-available-controllers-list">runnable: false def list_available_controllers() -&gt; list</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#example-return-values">Example return values</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id2">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-controller-registry-dict-str-dict-str-any-controller-type-class-controllerclass-controller-class-reference-config-class-configclass-configuration-class-reference-default-gains-list-float-default-gain-vector-gain-count-int-expected-number-of-gains-description-str-human-readable-description-supports-dynamics-bool-whether-controller-uses-dynamics-model-required-params-list-str-required-configuration-parameters">runnable: false CONTROLLER_REGISTRY: Dict[str, Dict[str, Any]] = { ‘controller_type’: { ‘class’: ControllerClass, # Controller class reference ‘config_class’: ConfigClass, # Configuration class reference ‘default_gains’: List[float], # Default gain vector ‘gain_count’: int, # Expected number of gains ‘description’: str, # Human-readable description ‘supports_dynamics’: bool, # Whether controller uses dynamics model ‘required_params’: List[str] # Required configuration parameters }</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id3">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-class-psocontrollerwrapper-wrapper-for-smc-controllers-to-provide-pso-compatible-interface-def-init-self-controller-n-gains-int-controller-type-str-self-controller-controller-self-n-gains-n-gains-self-controller-type-controller-type-self-max-force-getattr-controller-max-force-150-0-self-dynamics-model-getattr-controller-dynamics-model-none-def-validate-gains-self-particles-np-ndarray-np-ndarray-validate-gain-particles-for-pso-optimization-checks-gain-count-finiteness-positivity-and-controller-specific-constraints-def-compute-control-self-state-np-ndarray-np-ndarray-pso-compatible-control-computation-interface-simplified-interface-for-pso-fitness-evaluation">runnable: false class PSOControllerWrapper: “””Wrapper for SMC controllers to provide PSO-compatible interface.””” def <strong>init</strong>(self, controller, n_gains: int, controller_type: str): self.controller = controller self.n_gains = n_gains self.controller_type = controller_type self.max_force = getattr(controller, ‘max_force’, 150.0) self.dynamics_model = getattr(controller, ‘dynamics_model’, None) def validate_gains(self, particles: np.ndarray) -&gt; np.ndarray: “””Validate gain particles for PSO optimization.””” # Checks gain count, finiteness, positivity, and controller-specific constraints … def compute_control(self, state: np.ndarray) -&gt; np.ndarray: “””PSO-compatible control computation interface.””” # Simplified interface for PSO fitness evaluation …</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id4">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-src-controllers-new-controller-py-import-numpy-as-np">runnable: false # src/controllers/new_controller.py import numpy as np</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id5">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-src-controllers-new-controller-config-py-from-dataclasses-import-dataclass">runnable: false # src/controllers/new_controller_config.py from dataclasses import dataclass</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#import-new-controller">Import new controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#add-aliases-for-convenience">Add aliases for convenience</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id6">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false-add-to-smctype-enum">runnable: false # Add to SMCType enum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#test-new-controller-py-from-src-controllers-factory-import-create-controller-get-default-gains">test_new_controller.py from src.controllers.factory import create_controller, get_default_gains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id7">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#runnable-false">runnable: false “””</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id8">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_system_api_reference.html#id9">runnable: false “””</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_reference.html">Factory API Reference ## Controller Factory System - GitHub Issue #6 Implementation ### Overview The Controller Factory System provides a unified, type-safe interface for creating and managing sliding mode control (SMC) controllers in the DIP-SMC-PSO project. This system implements the factory pattern to ensure consistent controller instantiation, parameter validation, and optimization integration. ### Architecture #### Core Components 1. <strong>Main Factory</strong> (<code class="docutils literal notranslate"><span class="pre">src/controllers/factory.py</span></code>) - Central controller registry and creation interface - Thread-safe operations with RLock protection - error handling and validation - Legacy compatibility support 2. <strong>SMC Factory</strong> (<code class="docutils literal notranslate"><span class="pre">src/controllers/factory/smc_factory.py</span></code>) - Specialized factory for SMC controllers - PSO optimization integration - Type-safe parameter handling 3. <strong>Legacy Factory</strong> (<code class="docutils literal notranslate"><span class="pre">src/controllers/factory/legacy_factory.py</span></code>) - Backward compatibility interface - Deprecation handling and migration support ### Supported Controllers | Controller Type | Class | Gains | Description |</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html">Factory Methods API Reference ## Overview This document provides API reference documentation for the Enterprise Controller Factory system. The factory provides thread-safe, type-safe controller instantiation with deep PSO integration and robust error handling. ## Table of Contents 1. <span class="xref myst">Core Factory Functions</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#basic-usage-with-default-parameters">Basic usage with default parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-def-list-available-controllers-list-str">runnable: false def list_available_controllers() -&gt; List[str]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#output-classical-smc-sta-smc-adaptive-smc-hybrid-adaptive-sta-smc">Output: [‘classical_smc’, ‘sta_smc’, ‘adaptive_smc’, ‘hybrid_adaptive_sta_smc’]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#note-mpc-controller-only-included-if-optional-dependencies-available">Note: ‘mpc_controller’ only included if optional dependencies available</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-def-get-default-gains-controller-type-str-list-float">runnable: false def get_default_gains(controller_type: str) -&gt; List[float]</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id2">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-get-default-gains-for-different-controllers">runnable: false # Get default gains for different controllers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#output-20-0-15-0-12-0-8-0-35-0-5-0-adaptive-gains-get-default-gains-adaptive-smc">Output: [20.0, 15.0, 12.0, 8.0, 35.0, 5.0] adaptive_gains = get_default_gains(‘adaptive_smc’)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#output-25-0-18-0-15-0-10-0-4-0-use-as-starting-point-for-optimization">Output: [25.0, 18.0, 15.0, 10.0, 4.0] # Use as starting point for optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id3">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-create-factory-once-expensive-operation">runnable: false # Create factory once (expensive operation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id4">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-def-validate-smc-gains-smc-type-smctype-gains-union-list-np-ndarray-bool">runnable: false def validate_smc_gains(smc_type: SMCType, gains: Union[list, np.ndarray]) -&gt; bool</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id5">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-validate-gains-before-expensive-simulation">runnable: false # Validate gains before expensive simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#pattern-1-direct-controller-configuration">Pattern 1: Direct controller configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#type-aliases-for-better-type-safety">Type aliases for better type safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#id6">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/factory_methods_reference.html#runnable-false-class-controllerprotocol-protocol-protocol-defining-the-standard-controller-interface-def-compute-control-self-state-statevector-last-control-float-history-configdict-controloutput-compute-control-output-for-given-state-def-reset-self-none-reset-controller-internal-state-property-def-gains-self-list-float-return-controller-gains">runnable: false class ControllerProtocol(Protocol): “””Protocol defining the standard controller interface.””” def compute_control( self, state: StateVector, last_control: float, history: ConfigDict ) -&gt; ControlOutput: “””Compute control output for given state.””” … def reset(self) -&gt; None: “””Reset controller internal state.””” … @property def gains(self) -&gt; List[float]: “””Return controller gains.””” …</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html">Optimization Module API Reference <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#runnable-false-usr-bin-env-python3">runnable: false #!/usr/bin/env python3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#configuration">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#config-path-config-yaml">============================================================================ CONFIG_PATH = “config.yaml”</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#convergence-monitoring-callback">Convergence Monitoring Callback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#class-convergencemonitor-callback-for-real-time-convergence-monitoring-def-init-self-analyzer-enhancedconvergenceanalyzer-self-analyzer-analyzer-self-metrics-history-def-call-self-iteration-int-best-fitness-float-mean-fitness-float-fitness-std-float-swarm-positions-np-ndarray-check-convergence-at-each-iteration-status-metrics-self-analyzer-check-convergence-iteration-iteration-best-fitness-best-fitness-mean-fitness-mean-fitness-fitness-std-fitness-std-swarm-positions-swarm-positions-self-metrics-history-append-metrics-log-key-metrics-if-iteration-10-0-print-f-iter-iteration-3d-status-status-value-20s-f-best-metrics-best-fitness-6f-f-diversity-metrics-population-diversity-4f-f-conv-velocity-metrics-convergence-velocity-4e-f-predicted-remaining-metrics-predicted-iterations-remaining-3d-early-stopping-if-status-convergencestatus-converged-print-f-n-convergence-detected-at-iteration-iteration-return-true-signal-early-stop-elif-status-convergencestatus-stagnated-print-f-n-stagnation-detected-at-iteration-iteration-return-true-signal-early-stop-return-false-continue">============================================================================ class ConvergenceMonitor: “””Callback for real-time convergence monitoring.””” def <strong>init</strong>(self, analyzer: EnhancedConvergenceAnalyzer): self.analyzer = analyzer self.metrics_history = [] def <strong>call</strong>(self, iteration: int, best_fitness: float, mean_fitness: float, fitness_std: float, swarm_positions: np.ndarray): “””Check convergence at each iteration.””” status, metrics = self.analyzer.check_convergence( iteration=iteration, best_fitness=best_fitness, mean_fitness=mean_fitness, fitness_std=fitness_std, swarm_positions=swarm_positions ) self.metrics_history.append(metrics) # Log key metrics if iteration % 10 == 0: print(f”Iter {iteration:3d} | Status: {status.value:20s} | “ f”Best: {metrics.best_fitness:.6f} | “ f”Diversity: {metrics.population_diversity:.4f} | “ f”Conv. Velocity: {metrics.convergence_velocity:.4e} | “ f”Predicted Remaining: {metrics.predicted_iterations_remaining:3d}”) # Early stopping if status == ConvergenceStatus.CONVERGED: print(f”\n&gt;&gt;&gt; CONVERGENCE DETECTED at iteration {iteration} &lt;&lt;&lt;”) return True # Signal early stop elif status == ConvergenceStatus.STAGNATED: print(f”\n&gt;&gt;&gt; STAGNATION DETECTED at iteration {iteration} &lt;&lt;&lt;”) return True # Signal early stop return False # Continue # ============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#main">Main</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#def-main-load-configuration-config-load-config-config-path-initialize-convergence-analyzer-with-custom-criteria-criteria-convergencecriteria-fitness-tolerance-1e-6-relative-improvement-threshold-1e-4-min-diversity-threshold-1e-3-max-stagnation-iterations-50-enable-performance-prediction-true-premature-convergence-detection-true-analyzer-enhancedconvergenceanalyzer-criteria-criteria-controller-type-smctype-sta-monitor-convergencemonitor-analyzer-create-controller-factory-controller-factory-partial-create-controller-controller-type-controller-type-config-config-initialize-pso-tuner-tuner-psotuner-controller-factory-controller-factory-config-config-seed-seed-run-optimization-with-monitoring-print-f-running-pso-optimization-with-real-time-convergence-monitoring-print-f-120-result-tuner-optimise-print-f-120-n-plot-convergence-metrics-metrics-monitor-metrics-history-iterations-m-iteration-for-m-in-metrics-best-fitness-m-best-fitness-for-m-in-metrics-diversity-m-population-diversity-for-m-in-metrics-conv-velocity-m-convergence-velocity-for-m-in-metrics-fig-axes-plt-subplots-3-1-figsize-12-10-best-fitness-axes-0-plot-iterations-best-fitness-linewidth-2-color-blue-axes-0-set-ylabel-best-fitness-fontsize-12-axes-0-set-yscale-log-axes-0-set-title-convergence-monitoring-sta-smc-fontsize-14-fontweight-bold-axes-0-grid-true-alpha-0-3-population-diversity-axes-1-plot-iterations-diversity-linewidth-2-color-green-axes-1-set-ylabel-population-diversity-fontsize-12-axes-1-grid-true-alpha-0-3-convergence-velocity-axes-2-plot-iterations-conv-velocity-linewidth-2-color-red-axes-2-set-ylabel-convergence-velocity-fontsize-12-axes-2-set-xlabel-iteration-fontsize-12-axes-2-grid-true-alpha-0-3-plt-tight-layout-plt-savefig-pso-convergence-monitoring-png-dpi-300-print-convergence-monitoring-plot-saved-pso-convergence-monitoring-png-if-name-main-main">============================================================================ def main(): # Load configuration config = load_config(CONFIG_PATH) # Initialize convergence analyzer with custom criteria criteria = ConvergenceCriteria( fitness_tolerance=1e-6, relative_improvement_threshold=1e-4, min_diversity_threshold=1e-3, max_stagnation_iterations=50, enable_performance_prediction=True, premature_convergence_detection=True ) analyzer = EnhancedConvergenceAnalyzer( criteria=criteria, controller_type=SMCType.STA ) monitor = ConvergenceMonitor(analyzer) # Create controller factory controller_factory = partial( create_controller, controller_type=CONTROLLER_TYPE, config=config ) # Initialize PSO tuner tuner = PSOTuner( controller_factory=controller_factory, config=config, seed=SEED ) # Run optimization with monitoring print(f”Running PSO optimization with real-time convergence monitoring…”) print(f”{‘=’*120}”) result = tuner.optimise() print(f”{‘=’*120}\n”) # Plot convergence metrics metrics = monitor.metrics_history iterations = [m.iteration for m in metrics] best_fitness = [m.best_fitness for m in metrics] diversity = [m.population_diversity for m in metrics] conv_velocity = [m.convergence_velocity for m in metrics] fig, axes = plt.subplots(3, 1, figsize=(12, 10)) # Best fitness axes[0].plot(iterations, best_fitness, linewidth=2, color=’blue’) axes[0].set_ylabel(‘Best Fitness’, fontsize=12) axes[0].set_yscale(‘log’) axes[0].set_title(‘Convergence Monitoring - STA SMC’, fontsize=14, fontweight=’bold’) axes[0].grid(True, alpha=0.3) # Population diversity axes[1].plot(iterations, diversity, linewidth=2, color=’green’) axes[1].set_ylabel(‘Population Diversity’, fontsize=12) axes[1].grid(True, alpha=0.3) # Convergence velocity axes[2].plot(iterations, conv_velocity, linewidth=2, color=’red’) axes[2].set_ylabel(‘Convergence Velocity’, fontsize=12) axes[2].set_xlabel(‘Iteration’, fontsize=12) axes[2].grid(True, alpha=0.3) plt.tight_layout() plt.savefig(‘pso_convergence_monitoring.png’, dpi=300) print(“Convergence monitoring plot saved: pso_convergence_monitoring.png”) if <strong>name</strong> == “<strong>main</strong>”: main()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#expected-output-running-pso-optimization-with-real-time-convergence-monitoring"><code class="docutils literal notranslate"><span class="pre">**Expected</span> <span class="pre">Output:**</span></code>
Running PSO optimization with real-time convergence monitoring…</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#id2">runnable: false #!/usr/bin/env python3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#id3">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#id4">============================================================================ CONFIG_PATH = “config.yaml”</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#id5">Main</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/optimization_module_api_reference.html#def-main-load-configuration-config-load-config-config-path-initialize-meta-optimizer-print-initializing-pso-hyperparameter-optimizer-meta-optimizer-psohyperparameteroptimizer-config-run-meta-optimization-print-f-nrunning-meta-optimization-for-controller-type-value-print-f-max-evaluations-max-meta-evaluations-print-f-trials-per-evaluation-n-trials-per-eval-print-f-objective-optimizationobjective-multi-objective-value-print-80-result-meta-optimizer-optimize-hyperparameters-controller-type-controller-type-objective-optimizationobjective-multi-objective-max-evaluations-max-meta-evaluations-n-trials-per-evaluation-n-trials-per-eval-display-results-print-n-80-print-hyperparameter-optimization-results-print-80-print-f-noptimized-hyperparameters-print-f-inertia-weight-w-result-hyperparameters-w-6f-print-f-cognitive-c1-result-hyperparameters-c1-6f-print-f-social-c2-result-hyperparameters-c2-6f-print-f-swarm-size-result-hyperparameters-n-particles-print-f-nbaseline-hyperparameters-print-f-inertia-weight-w-result-baseline-hyperparameters-w-6f-print-f-cognitive-c1-result-baseline-hyperparameters-c1-6f-print-f-social-c2-result-baseline-hyperparameters-c2-6f-print-f-swarm-size-result-baseline-hyperparameters-n-particles-print-f-nperformance-improvements-vs-baseline-print-f-convergence-speedup-result-convergence-improvement-2f-x-print-f-quality-improvement-result-quality-improvement100-2f-print-f-robustness-improvement-result-robustness-improvement100-2f-print-f-efficiency-score-result-efficiency-score-4f-print-80-visualize-comparison-fig-axes-plt-subplots-2-2-figsize-12-10-categories-w-c1-c2-n-baseline-values-result-baseline-hyperparameters-w-result-baseline-hyperparameters-c1-result-baseline-hyperparameters-c2-result-baseline-hyperparameters-n-particles-optimized-values-result-hyperparameters-w-result-hyperparameters-c1-result-hyperparameters-c2-result-hyperparameters-n-particles-x-np-arange-len-categories-width-0-35-axes-0-0-bar-x-width-2-baseline-values-width-label-baseline-alpha-0-7-axes-0-0-bar-x-width-2-optimized-values-width-label-optimized-alpha-0-7-axes-0-0-set-ylabel-value-axes-0-0-set-title-hyperparameter-comparison-axes-0-0-set-xticks-x-axes-0-0-set-xticklabels-categories-axes-0-0-legend-axes-0-0-grid-true-alpha-0-3-performance-metrics-metrics-convergence-nspeed-solution-nquality-robustness-improvements-result-convergence-improvement-1-result-quality-improvement-1-result-robustness-improvement-axes-0-1-bar-metrics-improvements-color-blue-green-orange-alpha-0-7-axes-0-1-axhline-y-1-0-color-red-linestyle-label-baseline-axes-0-1-set-ylabel-improvement-factor-axes-0-1-set-title-performance-improvements-axes-0-1-legend-axes-0-1-grid-true-alpha-0-3-convergence-history-if-available-if-hasattr-result-optimization-history-axes-1-0-plot-result-optimization-history-best-objective-linewidth-2-axes-1-0-set-xlabel-meta-optimization-iteration-axes-1-0-set-ylabel-objective-value-axes-1-0-set-title-meta-optimization-convergence-axes-1-0-grid-true-alpha-0-3-hide-unused-subplot-axes-1-1-axis-off-plt-tight-layout-plt-savefig-pso-hyperparameter-optimization-png-dpi-300-print-nvisualization-saved-pso-hyperparameter-optimization-png-if-name-main-main">============================================================================ def main(): # Load configuration config = load_config(CONFIG_PATH) # Initialize meta-optimizer print(“Initializing PSO Hyperparameter Optimizer…”) meta_optimizer = PSOHyperparameterOptimizer(config) # Run meta-optimization print(f”\nRunning meta-optimization for {CONTROLLER_TYPE.value}…”) print(f”Max evaluations: {MAX_META_EVALUATIONS}”) print(f”Trials per evaluation: {N_TRIALS_PER_EVAL}”) print(f”Objective: {OptimizationObjective.MULTI_OBJECTIVE.value}”) print(“=”*80) result = meta_optimizer.optimize_hyperparameters( controller_type=CONTROLLER_TYPE, objective=OptimizationObjective.MULTI_OBJECTIVE, max_evaluations=MAX_META_EVALUATIONS, n_trials_per_evaluation=N_TRIALS_PER_EVAL ) # Display results print(“\n” + “=”<em>80) print(“HYPERPARAMETER OPTIMIZATION RESULTS”) print(“=”<em>80) print(f”\nOptimized Hyperparameters:”) print(f” Inertia weight (w): {result.hyperparameters.w:.6f}”) print(f” Cognitive (c1): {result.hyperparameters.c1:.6f}”) print(f” Social (c2): {result.hyperparameters.c2:.6f}”) print(f” Swarm size: {result.hyperparameters.n_particles}”) print(f”\nBaseline Hyperparameters:”) print(f” Inertia weight (w): {result.baseline_hyperparameters.w:.6f}”) print(f” Cognitive (c1): {result.baseline_hyperparameters.c1:.6f}”) print(f” Social (c2): {result.baseline_hyperparameters.c2:.6f}”) print(f” Swarm size: {result.baseline_hyperparameters.n_particles}”) print(f”\nPerformance Improvements vs. Baseline:”) print(f” Convergence speedup: {result.convergence_improvement:.2f}x”) print(f” Quality improvement: {result.quality_improvement</em>100:.2f}%”) print(f” Robustness improvement: {result.robustness_improvement</em>100:.2f}%”) print(f” Efficiency score: {result.efficiency_score:.4f}”) print(“=”*80) # Visualize comparison fig, axes = plt.subplots(2, 2, figsize=(12, 10)) categories = [‘w’, ‘c1’, ‘c2’, ‘N’] baseline_values = [ result.baseline_hyperparameters.w, result.baseline_hyperparameters.c1, result.baseline_hyperparameters.c2, result.baseline_hyperparameters.n_particles ] optimized_values = [ result.hyperparameters.w, result.hyperparameters.c1, result.hyperparameters.c2, result.hyperparameters.n_particles ] x = np.arange(len(categories)) width = 0.35 axes[0, 0].bar(x - width/2, baseline_values, width, label=’Baseline’, alpha=0.7) axes[0, 0].bar(x + width/2, optimized_values, width, label=’Optimized’, alpha=0.7) axes[0, 0].set_ylabel(‘Value’) axes[0, 0].set_title(‘Hyperparameter Comparison’) axes[0, 0].set_xticks(x) axes[0, 0].set_xticklabels(categories) axes[0, 0].legend() axes[0, 0].grid(True, alpha=0.3) # Performance metrics metrics = [‘Convergence\nSpeed’, ‘Solution\nQuality’, ‘Robustness’] improvements = [ result.convergence_improvement, 1 + result.quality_improvement, 1 + result.robustness_improvement ] axes[0, 1].bar(metrics, improvements, color=[‘blue’, ‘green’, ‘orange’], alpha=0.7) axes[0, 1].axhline(y=1.0, color=’red’, linestyle=’–’, label=’Baseline’) axes[0, 1].set_ylabel(‘Improvement Factor’) axes[0, 1].set_title(‘Performance Improvements’) axes[0, 1].legend() axes[0, 1].grid(True, alpha=0.3) # Convergence history (if available) if hasattr(result, ‘optimization_history’): axes[1, 0].plot(result.optimization_history[‘best_objective’], linewidth=2) axes[1, 0].set_xlabel(‘Meta-Optimization Iteration’) axes[1, 0].set_ylabel(‘Objective Value’) axes[1, 0].set_title(‘Meta-Optimization Convergence’) axes[1, 0].grid(True, alpha=0.3) # Hide unused subplot axes[1, 1].axis(‘off’) plt.tight_layout() plt.savefig(‘pso_hyperparameter_optimization.png’, dpi=300) print(“\nVisualization saved: pso_hyperparameter_optimization.png”) if <strong>name</strong> == “<strong>main</strong>”: main()</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/pso_optimization.html">PSO Optimization Guide <strong>Status:</strong> 🚧 Under Construction This document will contain PSO optimization documentation including: ## Planned Content ### PSO Algorithm Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html">Simulation Engine API Reference <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#runnable-false-class-dynamicsmodel-protocol-protocol-for-plant-dynamics-models-def-compute-dynamics-self-state-np-ndarray-control-input-np-ndarray-time-float-0-0-kwargs-any-dynamicsresult-compute-system-dynamics-at-given-state-and-input-def-get-physics-matrices-self-state-np-ndarray-tuple-np-ndarray-np-ndarray-np-ndarray-get-physics-matrices-m-c-g-at-current-state-def-validate-state-self-state-np-ndarray-bool-validate-state-vector-format-and-bounds-def-get-state-dimension-self-int-get-dimension-of-state-vector-def-get-control-dimension-self-int-get-dimension-of-control-input-vector">runnable: false class DynamicsModel(Protocol): “””Protocol for plant dynamics models.””” def compute_dynamics( self, state: np.ndarray, control_input: np.ndarray, time: float = 0.0, **kwargs: Any ) -&gt; DynamicsResult: “””Compute system dynamics at given state and input.””” … def get_physics_matrices( self, state: np.ndarray ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]: “””Get physics matrices M, C, G at current state.””” … def validate_state(self, state: np.ndarray) -&gt; bool: “””Validate state vector format and bounds.””” … def get_state_dimension(self) -&gt; int: “””Get dimension of state vector.””” … def get_control_dimension(self) -&gt; int: “””Get dimension of control input vector.””” …</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#runnable-false-abstractmethod">runnable: false @abstractmethod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id2">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#runnable-false-class-orchestrator-abc-base-interface-for-simulation-execution-strategies-abstractmethod-def-execute-self-initial-state-np-ndarray-control-inputs-np-ndarray-dt-float-horizon-int-kwargs-resultcontainer-execute-simulation-with-specified-strategy-pass">runnable: false class Orchestrator(ABC): “””Base interface for simulation execution strategies.””” @abstractmethod def execute( self, initial_state: np.ndarray, control_inputs: np.ndarray, dt: float, horizon: int, **kwargs ) -&gt; ResultContainer: “””Execute simulation with specified strategy.””” pass</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id3">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#runnable-false-class-batchorchestrator-baseorchestrator-batch-simulation-orchestrator-for-vectorized-execution-def-execute-self-initial-state-np-ndarray-control-inputs-np-ndarray-dt-float-horizon-int-kwargs-resultcontainer-execute-batch-simulation">runnable: false class BatchOrchestrator(BaseOrchestrator): “””Batch simulation orchestrator for vectorized execution.””” def execute( self, initial_state: np.ndarray, control_inputs: np.ndarray, dt: float, horizon: int, **kwargs ) -&gt; ResultContainer: “””Execute batch simulation.”””</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-1-load-configuration">STEP 1: Load Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id4">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-2-create-controller">STEP 2: Create Controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id5">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-3-create-dynamics-model">STEP 3: Create Dynamics Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id6">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-4-run-simulation">STEP 4: Run Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id7">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-5-analyze-results">STEP 5: Analyze Results</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id8">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#step-6-plot-results">STEP 6: Plot Results</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/simulation_engine_api_reference.html#id9">============================================================================</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/performance_benchmarks.html">Performance Benchmarks Reference <strong>Status:</strong> 🚧 Under Construction This document will contain performance benchmarking documentation including: ## Planned Content ### Benchmark Methodology</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/configuration_schema.html">Configuration Schema Reference <strong>Status:</strong> 🚧 Under Construction This document will contain configuration schema documentation including: ## Planned Content ### YAML Configuration Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_1_completion_report.html">Phase 4.1 Controller API Documentation Completion Report <strong>Date:</strong> 2025-10-07</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_1_completion_report.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_1_completion_report.html#runnable-false">runnable: false</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_1_completion_report.html#examples-section">Examples section</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_2_completion_report.html">Phase 4.2 Completion Report: Factory System API Documentation <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_2_completion_report.html#tests-test-factory-examples-py-import-pytest">tests/test_factory_examples.py import pytest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_3_progress_report.html">Phase 4.3 Progress Report: Optimization Module API Documentation <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_3_progress_report.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_3_progress_report.html#runnable-false-def-optimize-bounds-for-controller-self-controller-type-smctype-strategy-boundsoptimizationstrategy-boundsoptimizationstrategy-hybrid-max-optimization-time-float-300-0">runnable: false def optimize_bounds_for_controller( self, controller_type: SMCType, strategy: BoundsOptimizationStrategy = BoundsOptimizationStrategy.HYBRID, max_optimization_time: float = 300.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_3_completion_report.html">Phase 4.3 Completion Report: Optimization Module API Documentation <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/phase_4_4_completion_report.html">Phase 4.4 Completion Report: Simulation Engine API Documentation <strong>Project:</strong> Double-Inverted Pendulum SMC Control System</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">3. System Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture_control_room.html">System Architecture Control Room</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../benchmarks/index.html">Performance Benchmarks</a><input aria-label="Toggle navigation of Performance Benchmarks" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/controller_performance_benchmarks.html">Controller Performance Benchmarks with Statistical Analysis <strong>Project:</strong> Double-Inverted Pendulum Sliding Mode Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/phase_3_2_completion_report.html">Phase 3.2 Completion Report: Controller Performance Benchmarks <strong>Project:</strong> Double-Inverted Pendulum Sliding Mode Control</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html">Benchmarks &amp; Methodology This project includes benchmarking features for statistical analysis and performance comparison of sliding mode controllers. The benchmarking system provides standardized evaluation protocols and robust statistical metrics. ## Overview The benchmarking framework evaluates controllers across multiple dimensions: - <strong>Performance metrics</strong>: ISE, ITAE, RMS control effort, overshoot, constraint violations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#base-seed-for-reproducibility">Base seed for reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#configurable-noise-standard-deviation">Configurable noise standard deviation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#example-5-degree-initial-angle-variation">Example: ±5 degree initial angle variation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#test-with-physics-uncertainty-and-sensor-noise">Test with physics uncertainty and sensor noise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#runnable-false-controllers-classical-smc-sta-smc-adaptive-smc">runnable: false controllers = [‘classical_smc’, ‘sta_smc’, ‘adaptive_smc’]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks_methodology.html#runnable-false-benchmark-metadata-timestamp-datetime-now-isoformat-config-hash-hashlib-md5-config-content-hexdigest-random-seed-1234-n-trials-30-environment-python-version-sys-version-numpy-version-np-version-platform-platform-platform">runnable: false benchmark_metadata = { ‘timestamp’: datetime.now().isoformat(), ‘config_hash’: hashlib.md5(config_content).hexdigest(), ‘random_seed’: 1234, ‘n_trials’: 30, ‘environment’: { ‘python_version’: sys.version, ‘numpy_version’: np.<strong>version</strong>, ‘platform’: platform.platform() }</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography &amp; Academic References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../claude-backup.html">Automated Git Backup System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html">Configuration Integration Documentation ## Overview This document provides guidance on integrating the configuration system with the Enterprise Controller Factory. The DIP SMC-PSO project features a sophisticated configuration architecture that supports multiple sources, type safety, validation, and integration with controller creation workflows. ## Table of Contents 1. <span class="xref myst">Configuration Architecture</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#config-yaml-complete-configuration-example-global-settings">config.yaml - Complete configuration example # Global settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#runnable-false-from-pydantic-import-basemodel-field-validator">runnable: false from pydantic import BaseModel, Field, validator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#runnable-false-def-resolve-controller-gains-gains-optional-union-list-float-np-ndarray-config-optional-any-controller-type-str-controller-info-dict-str-any">runnable: false def _resolve_controller_gains( gains: Optional[Union[List[float], np.ndarray]], config: Optional[Any], controller_type: str, controller_info: Dict[str, Any]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#id2">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#runnable-false-nested-dictionary-configuration">runnable: false # Nested dictionary configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#id3">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#runnable-false-class-attributeconfig-configuration-using-attributes-def-init-self-create-controller-configurations-as-attributes-self-classical-smc-type-config-gains-25-20-15-10-40-6-max-force-160-0-boundary-layer-0-025-dt-0-001-self-adaptive-smc-type-config-gains-30-22-18-12-5-0-max-force-160-0-dt-0-001-leak-rate-0-02-initialize-controllers-namespace">runnable: false class AttributeConfig: “””Configuration using attributes.””” def <strong>init</strong>(self): # Create controller configurations as attributes self.classical_smc = type(‘Config’, (), { ‘gains’: [25, 20, 15, 10, 40, 6], ‘max_force’: 160.0, ‘boundary_layer’: 0.025, ‘dt’: 0.001 })() self.adaptive_smc = type(‘Config’, (), { ‘gains’: [30, 22, 18, 12, 5.0], ‘max_force’: 160.0, ‘dt’: 0.001, ‘leak_rate’: 0.02 })() # Initialize controllers namespace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_integration_documentation.html#generated-configuration-for-system-name">Generated configuration for {{ system_name }}</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_schema_validation.html">Configuration Schema Validation Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration_schema_validation.html#config-yaml-master-configuration-file">config.yaml - Master Configuration File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../context.html">2. Application Context</a></li>
<li class="toctree-l1"><a class="reference internal" href="../control_law_testing_standards.html">Control Law Testing Standards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controller_pso_interface_api_documentation.html">Controller-PSO Interface API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../coverage_analysis_methodology.html">Coverage Analysis Methodology Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../coverage_analysis_methodology.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../coverage_analysis_methodology.html#runnable-false-mathematical-model-for-isolated-coverage">runnable: false # Mathematical Model for Isolated Coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/DEPLOYMENT_GUIDE.html">🚀 Sphinx Documentation System - Deployment Guide ## ✅ System Successfully Deployed! Your production-grade Sphinx documentation system is now <strong>ready for use</strong>. All expert recommendations have been implemented and the system has been committed to your repository. ## 📋 Next Steps for Activation ### 1. GitHub Repository Settings To activate the documentation system, configure these GitHub settings: #### <strong>GitHub Pages:</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/STREAMLIT_DEPLOYMENT.html">Streamlit Deployment Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/docker.html">Docker Deployment Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment_validation_checklists.html">Deployment Validation Checklists and Quality Gates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../documentation_structure.html">Documentation Structure &amp; Site Map</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fault_detection_guide.html">Fault Detection &amp; Isolation (FDI) Guide ## Overview The DIP_SMC_PSO system includes a Fault Detection and Isolation (FDI) module that monitors system health in real-time. The FDI system compares model predictions with actual measurements to detect deviations that may indicate component failures, sensor faults, or unexpected disturbances. ## Architecture The FDI system uses a <strong>model-based residual approach</strong>: ```</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fault_detection_system_documentation.html">Fault Detection and Isolation (FDI) System - Technical Documentation ## Table of Contents 1. <span class="xref myst">Mathematical Foundations</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../fdi_threshold_calibration_methodology.html">FDI Threshold Calibration Methodology <strong>Issue</strong>: #18 - FDI Threshold Too Sensitive - False Positives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/getting-started.html#or-on-some-systems">OR on some systems:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/getting-started.html#clone-repository">Clone repository</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/getting-started.html#you-should-see-simulate-py-config-yaml-src-tests-docs-etc">You should see: simulate.py, config.yaml, src/, tests/, docs/, etc.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/getting-started-validation-report.html">Getting Started Guide Validation Report <strong>Phase 5.1: Getting Started Guide Validation</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../hil_quickstart.html">Hardware-in-the-Loop (HIL) Quickstart Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html">Mathematical Algorithm Validation Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#runnable-false-def-compute-control-self-state-np-ndarray-target-np-ndarray-float-compute-smc-control-signal-extract-state-variables-theta1-theta2-x-theta1-dot-theta2-dot-x-dot-state-compute-errors-e1-theta1-target-0-position-error-pendulum-1-e2-theta2-target-1-position-error-pendulum-2-e1-dot-theta1-dot-target-3-velocity-error-pendulum-1-e2-dot-theta2-dot-target-4-velocity-error-pendulum-2-sliding-surface-s-1e1-2e2-e1-e2-s-self-lambda1-e1-self-lambda2-e2-e1-dot-e2-dot-control-law-u-u-eq-u-sw-u-equivalent-self-compute-equivalent-control-state-target-u-switching-self-k-np-sign-s-return-u-equivalent-u-switching">runnable: false def compute_control(self, state: np.ndarray, target: np.ndarray) -&gt; float: “””Compute SMC control signal.””” # Extract state variables theta1, theta2, x, theta1_dot, theta2_dot, x_dot = state # Compute errors e1 = theta1 - target[0] # Position error pendulum 1 e2 = theta2 - target[1] # Position error pendulum 2 e1_dot = theta1_dot - target[3] # Velocity error pendulum 1 e2_dot = theta2_dot - target[4] # Velocity error pendulum 2 # Sliding surface: s = λ₁e₁ + λ₂e₂ + ė₁ + ė₂ s = self.lambda1 * e1 + self.lambda2 * e2 + e1_dot + e2_dot # Control law: u = u_eq + u_sw u_equivalent = self._compute_equivalent_control(state, target) u_switching = -self.K * np.sign(s) return u_equivalent + u_switching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#runnable-false-def-compute-control-self-state-np-ndarray-target-np-ndarray-float-compute-super-twisting-control-signal-compute-sliding-surface-s-self-compute-sliding-surface-state-target-super-twisting-control-law-u1-1-s-1-2-sign-s-u1-self-alpha1-np-power-np-abs-s-0-5-np-sign-s-u2-2-sign-s-dt-self-integral-term-self-alpha2-np-sign-s-self-dt-return-u1-self-integral-term">runnable: false def compute_control(self, state: np.ndarray, target: np.ndarray) -&gt; float: “””Compute Super-Twisting control signal.””” # Compute sliding surface s = self._compute_sliding_surface(state, target) # Super-Twisting control law # u₁ = -α₁|s|^(1/2) sign(s) u1 = -self.alpha1 * np.power(np.abs(s), 0.5) * np.sign(s) # u₂ = ∫(-α₂ sign(s)) dt self.integral_term += -self.alpha2 * np.sign(s) * self.dt return u1 + self.integral_term</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#id2">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#runnable-false-def-update-particles-self-update-particle-velocities-and-positions-for-i-in-range-self-n-particles-random-coefficients-r1-r2-np-random-random-2-velocity-update-with-constriction-factor-self-velocities-i-self-chi-self-w-self-velocities-i-self-c1-r1-self-personal-best-positions-i-self-positions-i-self-c2-r2-self-global-best-position-self-positions-i-position-update-self-positions-i-self-velocities-i-boundary-handling-self-positions-i-np-clip-self-positions-i-self-bounds-min-self-bounds-max">runnable: false def update_particles(self): “””Update particle velocities and positions.””” for i in range(self.n_particles): # Random coefficients r1, r2 = np.random.random(2) # Velocity update with constriction factor self.velocities[i] = self.chi * ( self.w * self.velocities[i] + self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i]) + self.c2 * r2 * (self.global_best_position - self.positions[i]) ) # Position update self.positions[i] += self.velocities[i] # Boundary handling self.positions[i] = np.clip(self.positions[i], self.bounds_min, self.bounds_max)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#id3">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#runnable-false-class-testmathematicalcorrectness-test-mathematical-properties-of-implementations-def-test-lyapunov-function-properties-self-test-lyapunov-function-is-positive-definite-controller-classicalsmc-for-in-range-1000-state-np-random-uniform-6-v-controller-compute-lyapunov-function-state-property-1-v-0-assert-v-0-property-2-v-0-only-at-equilibrium-if-not-np-allclose-state-0-assert-v-0-def-test-sliding-surface-stability-self-test-sliding-surface-leads-to-stable-dynamics-controller-classicalsmc-lambda1-2-0-lambda2-1-5-test-exponential-stability-on-sliding-surface-dt-0-01-times-np-arange-0-5-dt-for-initial-error-in-0-1-0-5-1-0-e1-history-initial-error-e2-history-initial-error-for-t-in-times-1-sliding-dynamics-e1-1e1-0-e2-2e2-0-e1-new-e1-history-1-np-exp-controller-lambda1-dt-e2-new-e2-history-1-np-exp-controller-lambda2-dt-e1-history-append-e1-new-e2-history-append-e2-new-verify-exponential-decay-assert-e1-history-1-0-01-initial-error-assert-e2-history-1-0-01-initial-error">runnable: false class TestMathematicalCorrectness: “””Test mathematical properties of implementations.””” def test_lyapunov_function_properties(self): “””Test Lyapunov function is positive definite.””” controller = ClassicalSMC() for _ in range(1000): state = np.random.uniform(-π, π, 6) V = controller.compute_lyapunov_function(state) # Property 1: V ≥ 0 assert V &gt;= 0 # Property 2: V = 0 only at equilibrium if not np.allclose(state, 0): assert V &gt; 0 def test_sliding_surface_stability(self): “””Test sliding surface leads to stable dynamics.””” controller = ClassicalSMC(lambda1=2.0, lambda2=1.5) # Test exponential stability on sliding surface dt = 0.01 times = np.arange(0, 5, dt) for initial_error in [0.1, 0.5, 1.0]: e1_history = [initial_error] e2_history = [initial_error] for t in times[1:]: # Sliding dynamics: ė₁ + λ₁e₁ = 0, ė₂ + λ₂e₂ = 0 e1_new = e1_history[-1] * np.exp(-controller.lambda1 * dt) e2_new = e2_history[-1] * np.exp(-controller.lambda2 * dt) e1_history.append(e1_new) e2_history.append(e2_new) # Verify exponential decay assert e1_history[-1] &lt; 0.01 * initial_error assert e2_history[-1] &lt; 0.01 * initial_error</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#id4">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_algorithm_validation.html#runnable-false-def-test-end-to-end-mathematical-properties-test-mathematical-properties-in-complete-system-initialize-system-system-doubleinvertedpendulum-controller-classicalsmc-initial-condition-away-from-equilibrium-x0-np-array-0-2-0-1-0-0-0-0-0-0-0-0-target-np-zeros-6-simulate-system-trajectory-simulate-system-system-controller-x0-target-t-final-10-0-mathematical-property-verification-1-verify-lyapunov-function-decreases-v-values-controller-compute-lyapunov-function-state-for-state-in-trajectory-states-assert-np-all-np-diff-v-values-0-lyapunov-function-must-be-non-increasing-2-verify-convergence-to-target-final-error-np-linalg-norm-trajectory-states-1-target-assert-final-error-0-01-f-final-error-final-error-too-large-3-verify-control-signal-bounds-max-control-np-max-np-abs-trajectory-controls-assert-max-control-controller-u-max-control-signal-exceeds-limits">runnable: false def test_end_to_end_mathematical_properties(): “””Test mathematical properties in complete system.””” # Initialize system system = DoubleInvertedPendulum() controller = ClassicalSMC() # Initial condition away from equilibrium x0 = np.array([0.2, 0.1, 0.0, 0.0, 0.0, 0.0]) target = np.zeros(6) # Simulate system trajectory = simulate_system(system, controller, x0, target, t_final=10.0) # Mathematical property verification # 1. Verify Lyapunov function decreases V_values = [controller.compute_lyapunov_function(state) for state in trajectory.states] assert np.all(np.diff(V_values) &lt;= 0), “Lyapunov function must be non-increasing” # 2. Verify convergence to target final_error = np.linalg.norm(trajectory.states[-1] - target) assert final_error &lt; 0.01, f”Final error {final_error} too large” # 3. Verify control signal bounds max_control = np.max(np.abs(trajectory.controls)) assert max_control &lt;= controller.u_max, “Control signal exceeds limits”</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mathematical_foundations/index.html">Mathematical Foundations</a><input aria-label="Toggle navigation of Mathematical Foundations" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/README.html">SMC Mathematical Foundations Documentation This directory contains mathematical documentation for all SMC algorithm fixes and validation methodology implemented for GitHub Issue #5. ## 📋 Documentation Overview This mathematical foundation documentation provides: - <strong>Complete mathematical theory</strong> behind all SMC algorithm implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/smc_complete_theory.html">Complete Sliding Mode Control Mathematical Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/smc_theory.html">SMC Mathematical Theory Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/sliding_surface_analysis.html">Sliding Surface Mathematical Properties and Stability Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/boundary_layer_derivations.html">Boundary Layer Mathematical Derivations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/controller_comparison_theory.html">SMC Controller Comparison Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html">Advanced Algorithms Guide <strong>Technical Reference for Optimization, Numerical Stability, and Algorithm Comparison</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#configure-inertia-weight-schedule-in-config-yaml">Configure inertia weight schedule in config.yaml:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#pso">pso:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#w-schedule-0-9-0-4-start-at-0-9-end-at-0-4">w_schedule: [0.9, 0.4] # Start at 0.9, end at 0.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#iters-100">iters: 100</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#n-particles-30-result-tuner-optimise-uses-w-schedule-from-config-manual-iteration-loop-for-custom-control">n_particles: 30 result = tuner.optimise() # Uses w_schedule from config # Manual iteration loop for custom control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#runnable-false-configure-physics-uncertainty-in-config-yaml">runnable: false # Configure physics uncertainty in config.yaml:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#physics-uncertainty">physics_uncertainty:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#n-evals-5-5-perturbed-models-per-evaluation">n_evals: 5 # 5 perturbed models per evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#cart-mass-0-10-10">cart_mass: 0.10 # ±10%</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#pendulum1-mass-0-15-15">pendulum1_mass: 0.15 # ±15%</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#pendulum2-mass-0-15-15">pendulum2_mass: 0.15 # ±15%</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#pendulum1-length-0-05-5">pendulum1_length: 0.05 # ±5%</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#pendulum2-length-0-05-5-tuner-psotuner-controller-factory-controller-factory-config-config-seed-42">pendulum2_length: 0.05 # ±5% tuner = PSOTuner( controller_factory=controller_factory, config=config, seed=42</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/advanced_algorithms_guide.html#cost-aggregation-0-7-mean-0-3-max">Cost aggregation: 0.7 * mean + 0.3 * max</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html">SMC Algorithm Fixes and Mathematical Validation Summary This document provides a summary of all mathematical algorithm fixes, validation improvements, and corrected implementations in the SMC controller system for GitHub Issue #5. ## 1. Executive Summary The SMC mathematical foundation has been completely restructured and validated with the following major improvements: - <strong>Boundary Layer Mathematics</strong>: Corrected chattering reduction theory and implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-compute-switching-function-self-surface-value-float-float-compute-continuous-switching-function-with-adaptive-boundary-layer-adaptive-boundary-layer-thickness-surface-derivative-self-get-surface-derivative-effective-thickness-self-base-thickness-self-slope-abs-surface-derivative-continuous-switching-approximation-if-self-switch-method-tanh-return-np-tanh-surface-value-effective-thickness-elif-self-switch-method-linear-return-np-clip-surface-value-effective-thickness-1-0-1-0-else-sign-return-np-sign-surface-value-3-validation-rules-python-if-thickness-0-raise-valueerror-boundary-layer-thickness-must-be-positive-if-slope-0-raise-valueerror-boundary-layer-slope-must-be-non-negative-mathematical-impact">runnable: false def compute_switching_function(self, surface_value: float) -&gt; float: “””Compute continuous switching function with adaptive boundary layer.””” # Adaptive boundary layer thickness surface_derivative = self._get_surface_derivative() effective_thickness = self.base_thickness + self.slope * abs(surface_derivative) # Continuous switching approximation if self.switch_method == “tanh”: return np.tanh(surface_value / effective_thickness) elif self.switch_method == “linear”: return np.clip(surface_value / effective_thickness, -1.0, 1.0) else: # “sign” return np.sign(surface_value) <code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">**Validation</span> <span class="pre">Rules:**</span></code>python if thickness &lt;= 0: raise ValueError(“Boundary layer thickness must be positive”) if slope &lt; 0: raise ValueError(“Boundary layer slope must be non-negative”) ``` <strong>Mathematical Impact:</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-compute-self-state-np-ndarray-float-compute-linear-sliding-surface-with-numerical-safeguards-input-validation-if-len-state-6-raise-valueerror-state-must-have-at-least-6-elements-handle-non-finite-values-if-not-np-all-np-isfinite-state-state-np-where-np-isfinite-state-state-0-0-extract-components-theta1-theta1-dot-state-2-state-3-theta2-theta2-dot-state-4-state-5-linear-sliding-surface-s-11-k11-22-k22-s-self-lam1-theta1-dot-self-k1-theta1-self-lam2-theta2-dot-self-k2-theta2-numerical-safety-return-0-0-if-not-np-isfinite-s-else-float-s-2-stability-analysis-integration-python">runnable: false def compute(self, state: np.ndarray) -&gt; float: “””Compute linear sliding surface with numerical safeguards.””” # Input validation if len(state) &lt; 6: raise ValueError(“State must have at least 6 elements”) # Handle non-finite values if not np.all(np.isfinite(state)): state = np.where(np.isfinite(state), state, 0.0) # Extract components theta1, theta1_dot = state[2], state[3] theta2, theta2_dot = state[4], state[5] # Linear sliding surface: s = λ₁θ̇₁ + k₁θ₁ + λ₂θ̇₂ + k₂θ₂ s = (self.lam1 * theta1_dot + self.k1 * theta1 + self.lam2 * theta2_dot + self.k2 * theta2) # Numerical safety return 0.0 if not np.isfinite(s) else float(s) <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Stability</span> <span class="pre">Analysis</span> <span class="pre">Integration:**</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id2">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-validate-gains-self-none-validate-gains-according-to-hurwitz-stability-requirements-check-finite-values-if-not-np-all-np-isfinite-self-gains-invalid-indices-np-where-np-isfinite-self-gains-0-raise-valueerror-f-gains-contain-nan-infinite-values-at-indices-invalid-indices-positivity-requirement-for-stability-if-len-self-gains-4-if-any-g-0-for-g-in-self-gains-4-raise-valueerror-surface-gains-k1-k2-1-2-must-be-positive-for-stability-minimum-threshold-for-numerical-stability-if-any-g-1e-12-for-g-in-self-gains-4-raise-valueerror-gains-too-small-min-1e-12-numerical-instability-risk-3-mathematical-property-verification-linearity-s-x1-x2-s-x1-s-x2-homogeneity-s-x-s-x-continuity-lim-xx0-s-x-s-x0-differentiability-ds-dt-exists-and-is-computable-mathematical-impact">runnable: false def _validate_gains(self) -&gt; None: “””Validate gains according to Hurwitz stability requirements.””” # Check finite values if not np.all(np.isfinite(self.gains)): invalid_indices = np.where(~np.isfinite(self.gains))[0] raise ValueError(f”Gains contain NaN/infinite values at indices: {invalid_indices}”) # Positivity requirement for stability if len(self.gains) &gt;= 4: if any(g &lt;= 0 for g in self.gains[:4]): raise ValueError(“Surface gains [k1, k2, λ1, λ2] must be positive for stability”) # Minimum threshold for numerical stability if any(g &lt; 1e-12 for g in self.gains[:4]): raise ValueError(“Gains too small (min: 1e-12) - numerical instability risk”) ``` 3. <strong>Mathematical Property Verification:</strong> - <strong>Linearity</strong>: <code class="docutils literal notranslate"><span class="pre">s(αx₁</span> <span class="pre">+</span> <span class="pre">βx₂)</span> <span class="pre">=</span> <span class="pre">αs(x₁)</span> <span class="pre">+</span> <span class="pre">βs(x₂)</span></code> - <strong>Homogeneity</strong>: <code class="docutils literal notranslate"><span class="pre">s(αx)</span> <span class="pre">=</span> <span class="pre">αs(x)</span></code> - <strong>Continuity</strong>: <code class="docutils literal notranslate"><span class="pre">lim_{x→x₀}</span> <span class="pre">s(x)</span> <span class="pre">=</span> <span class="pre">s(x₀)</span></code> - <strong>Differentiability</strong>: <code class="docutils literal notranslate"><span class="pre">ds/dt</span></code> exists and is computable <strong>Mathematical Impact:</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id3">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-dataclass-frozen-true-class-classicalsmcconfig-type-safe-configuration-with-mathematical-validation-def-post-init-self-validate-configuration-after-creation-self-validate-gains-self-validate-parameters-self-validate-mathematical-constraints-def-validate-gains-self-none-validate-gain-vector-according-to-smc-theory-if-len-self-gains-6-raise-valueerror-classical-smc-requires-exactly-6-gains-k1-k2-lam1-lam2-k-kd-self-gains-surface-gains-positive-for-hurwitz-stability-if-any-g-0-for-g-in-k1-k2-lam1-lam2-raise-valueerror-surface-gains-must-be-positive-for-stability-switching-gain-positive-for-reaching-condition-if-k-0-raise-valueerror-switching-gain-k-must-be-positive-derivative-gain-non-negative-for-damping-if-kd-0-raise-valueerror-derivative-gain-kd-must-be-non-negative-def-validate-mathematical-constraints-self-none-validate-constraints-from-mathematical-theory-damping-ratio-bounds-for-each-subsystem-zeta1-self-lam1-2-np-sqrt-self-k1-zeta2-self-lam2-2-np-sqrt-self-k2-if-zeta1-0-1-or-zeta2-0-1-raise-valueerror-damping-ratios-too-low-may-cause-oscillations-if-zeta1-10-0-or-zeta2-10-0-raise-valueerror-damping-ratios-too-high-may-cause-sluggish-response-2-edge-case-handling-python-def-get-effective-controllability-threshold-self-float-auto-compute-threshold-based-on-system-parameters-if-self-controllability-threshold-is-not-none-return-self-controllability-threshold-scale-with-surface-gains-for-adaptive-behavior-base-threshold-0-05-self-k1-self-k2-bound-within-reasonable-limits-return-np-clip-base-threshold-0-01-1-0-mathematical-impact">runnable: false @dataclass(frozen=True) class ClassicalSMCConfig: “””Type-safe configuration with mathematical validation.””” def <strong>post_init</strong>(self): “””Validate configuration after creation.””” self._validate_gains() self._validate_parameters() self._validate_mathematical_constraints() def _validate_gains(self) -&gt; None: “””Validate gain vector according to SMC theory.””” if len(self.gains) != 6: raise ValueError(“Classical SMC requires exactly 6 gains”) k1, k2, lam1, lam2, K, kd = self.gains # Surface gains: positive for Hurwitz stability if any(g &lt;= 0 for g in [k1, k2, lam1, lam2]): raise ValueError(“Surface gains must be positive for stability”) # Switching gain: positive for reaching condition if K &lt;= 0: raise ValueError(“Switching gain K must be positive”) # Derivative gain: non-negative for damping if kd &lt; 0: raise ValueError(“Derivative gain kd must be non-negative”) def _validate_mathematical_constraints(self) -&gt; None: “””Validate constraints from mathematical theory.””” # Damping ratio bounds for each subsystem zeta1 = self.lam1 / (2 * np.sqrt(self.k1)) zeta2 = self.lam2 / (2 * np.sqrt(self.k2)) if zeta1 &lt; 0.1 or zeta2 &lt; 0.1: raise ValueError(“Damping ratios too low - may cause oscillations”) if zeta1 &gt; 10.0 or zeta2 &gt; 10.0: raise ValueError(“Damping ratios too high - may cause sluggish response”) <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Edge</span> <span class="pre">Case</span> <span class="pre">Handling:**</span></code>python def get_effective_controllability_threshold(self) -&gt; float: “””Auto-compute threshold based on system parameters.””” if self.controllability_threshold is not None: return self.controllability_threshold # Scale with surface gains for adaptive behavior base_threshold = 0.05 * (self.k1 + self.k2) # Bound within reasonable limits return np.clip(base_threshold, 0.01, 1.0) ``` <strong>Mathematical Impact:</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id4">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-given-gains-st-lists-st-floats-min-value-0-1-max-value-50-0-min-size-4-max-size-4-state-st-lists-st-floats-min-value-10-0-max-value-10-0-min-size-6-max-size-6-def-test-sliding-surface-linearity-property-self-gains-state-test-linearity-property-for-all-valid-parameter-combinations-surface-linearslidingsurface-gains-state1-np-array-state-state2-np-random-uniform-10-10-6-s1-surface-compute-state1-s2-surface-compute-state2-s-combined-surface-compute-state1-state2-mathematical-property-s-x1-x2-s-x1-s-x2-assert-abs-s-combined-s1-s2-1e-10-2-boundary-layer-monotonicity-python">runnable: false @given( gains=st.lists(st.floats(min_value=0.1, max_value=50.0), min_size=4, max_size=4), state=st.lists(st.floats(min_value=-10.0, max_value=10.0), min_size=6, max_size=6) ) def test_sliding_surface_linearity_property(self, gains, state): “””Test linearity property for all valid parameter combinations.””” surface = LinearSlidingSurface(gains) state1 = np.array(state) state2 = np.random.uniform(-10, 10, 6) s1 = surface.compute(state1) s2 = surface.compute(state2) s_combined = surface.compute(state1 + state2) # Mathematical property: s(x1 + x2) = s(x1) + s(x2) assert abs(s_combined - (s1 + s2)) &lt; 1e-10 <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Boundary</span> <span class="pre">Layer</span> <span class="pre">Monotonicity:**</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id5">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-test-boundary-layer-monotonicity-all-methods-self-test-monotonicity-for-all-switching-methods-methods-tanh-linear-sign-for-method-in-methods-boundary-layer-boundarylayer-thickness-0-1-switch-method-method-s-values-np-linspace-2-2-1000-switch-values-boundary-layer-compute-switching-function-s-for-s-in-s-values-must-be-monotonically-increasing-for-i-in-range-len-switch-values-1-assert-switch-values-i-1-switch-values-i-3-configuration-validation-coverage-python">runnable: false def test_boundary_layer_monotonicity_all_methods(self): “””Test monotonicity for all switching methods.””” methods = [“tanh”, “linear”, “sign”] for method in methods: boundary_layer = BoundaryLayer(thickness=0.1, switch_method=method) s_values = np.linspace(-2, 2, 1000) switch_values = [boundary_layer.compute_switching_function(s) for s in s_values] # Must be monotonically increasing for i in range(len(switch_values) - 1): assert switch_values[i+1] &gt;= switch_values[i] <code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">**Configuration</span> <span class="pre">Validation</span> <span class="pre">Coverage:**</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id6">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-class-testconfigurationvalidationcoverage-coverage-of-all-validation-rules-pytest-mark-parametrize-invalid-gain-index-0-1-2-3-def-test-zero-surface-gains-rejection-self-invalid-gain-index-test-rejection-of-zero-surface-gains-gains-5-0-3-0-4-0-2-0-10-0-1-0-gains-invalid-gain-index-0-0-with-pytest-raises-valueerror-match-must-be-positive-classicalsmcconfig-gains-gains-max-force-100-dt-0-01-boundary-layer-0-01-pytest-mark-parametrize-invalid-gain-index-0-1-2-3-def-test-negative-surface-gains-rejection-self-invalid-gain-index-test-rejection-of-negative-surface-gains-gains-5-0-3-0-4-0-2-0-10-0-1-0-gains-invalid-gain-index-1-0-with-pytest-raises-valueerror-match-must-be-positive-classicalsmcconfig-gains-gains-max-force-100-dt-0-01-boundary-layer-0-01-3-2-numerical-stability-testing-enhanced-numerical-robustness-tests-1-extreme-value-testing-python">runnable: false class TestConfigurationValidationCoverage: “””coverage of all validation rules.””” @pytest.mark.parametrize(“invalid_gain_index”, [0, 1, 2, 3]) def test_zero_surface_gains_rejection(self, invalid_gain_index): “””Test rejection of zero surface gains.””” gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0] gains[invalid_gain_index] = 0.0 with pytest.raises(ValueError, match=”must be positive”): ClassicalSMCConfig(gains=gains, max_force=100, dt=0.01, boundary_layer=0.01) @pytest.mark.parametrize(“invalid_gain_index”, [0, 1, 2, 3]) def test_negative_surface_gains_rejection(self, invalid_gain_index): “””Test rejection of negative surface gains.””” gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0] gains[invalid_gain_index] = -1.0 with pytest.raises(ValueError, match=”must be positive”): ClassicalSMCConfig(gains=gains, max_force=100, dt=0.01, boundary_layer=0.01) <code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">3.2</span> <span class="pre">Numerical</span> <span class="pre">Stability</span> <span class="pre">Testing</span> <span class="pre">**Enhanced</span> <span class="pre">Numerical</span> <span class="pre">Robustness</span> <span class="pre">Tests:**</span> <span class="pre">1.</span> <span class="pre">**Extreme</span> <span class="pre">Value</span> <span class="pre">Testing:**</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id7">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-test-numerical-stability-extreme-values-self-test-behavior-with-extreme-but-valid-parameter-values-very-small-gains-but-above-minimum-threshold-small-gains-1e-10-1e-10-1e-10-1e-10-1e-8-0-0-config-small-classicalsmcconfig-gains-small-gains-max-force-1e-6-dt-1e-6-boundary-layer-1e-8-very-large-gains-large-gains-1e6-1e6-1e6-1e6-1e8-1e4-config-large-classicalsmcconfig-gains-large-gains-max-force-1e8-dt-1e-3-boundary-layer-1-0-both-should-create-valid-controllers-controller-small-modularclassicalsmc-config-config-small-controller-large-modularclassicalsmc-config-config-large-test-with-moderate-state-values-state-np-array-0-1-0-05-0-08-0-02-0-03-0-01-result-small-controller-small-compute-control-state-result-large-controller-large-compute-control-state-both-should-produce-finite-bounded-results-assert-np-all-np-isfinite-result-small-get-control-output-0-assert-np-all-np-isfinite-result-large-get-control-output-0-2-precision-consistency-testing-python">runnable: false def test_numerical_stability_extreme_values(self): “””Test behavior with extreme but valid parameter values.””” # Very small gains (but above minimum threshold) small_gains = [1e-10, 1e-10, 1e-10, 1e-10, 1e-8, 0.0] config_small = ClassicalSMCConfig(gains=small_gains, max_force=1e-6, dt=1e-6, boundary_layer=1e-8) # Very large gains large_gains = [1e6, 1e6, 1e6, 1e6, 1e8, 1e4] config_large = ClassicalSMCConfig(gains=large_gains, max_force=1e8, dt=1e-3, boundary_layer=1.0) # Both should create valid controllers controller_small = ModularClassicalSMC(config=config_small) controller_large = ModularClassicalSMC(config=config_large) # Test with moderate state values state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]) result_small = controller_small.compute_control(state, {}, {}) result_large = controller_large.compute_control(state, {}, {}) # Both should produce finite, bounded results assert np.all(np.isfinite(result_small.get(‘control_output’, [0]))) assert np.all(np.isfinite(result_large.get(‘control_output’, [0]))) <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Precision</span> <span class="pre">Consistency</span> <span class="pre">Testing:**</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id8">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-def-test-computation-precision-consistency-self-test-that-repeated-computations-maintain-precision-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-state-np-array-0-123456789-0-987654321-0-456789123-0-321654987-0-789123456-0-654987321-compute-control-1000-times-results-for-in-range-1000-result-controller-compute-control-state-control-result-get-control-output-result-get-control-0-results-append-control-results-np-array-results-standard-deviation-should-be-zero-deterministic-computation-std-dev-np-std-results-axis-0-if-results-ndim-1-else-np-std-results-assert-np-all-std-dev-1e-15-machine-precision-level-4-implementation-architecture-improvements-4-1-modular-component-design-before-monolithic-single-458-line-controller-with-mixed-concerns">runnable: false def test_computation_precision_consistency(self): “””Test that repeated computations maintain precision.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) state = np.array([0.123456789, 0.987654321, 0.456789123, 0.321654987, 0.789123456, 0.654987321]) # Compute control 1000 times results = [] for _ in range(1000): result = controller.compute_control(state, {}, {}) control = result.get(‘control_output’, result.get(‘control’, 0)) results.append(control) results = np.array(results) # Standard deviation should be zero (deterministic computation) std_dev = np.std(results, axis=0) if results.ndim &gt; 1 else np.std(results) assert np.all(std_dev &lt; 1e-15) # Machine precision level ``` ## 4. Implementation Architecture Improvements ### 4.1 Modular Component Design <strong>Before (Monolithic):</strong> Single 458-line controller with mixed concerns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#id9">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/algorithm_fixes_summary.html#runnable-false-class-slidingsurface-abc-abstract-interface-for-sliding-surface-calculations-abstractmethod-def-compute-self-state-np-ndarray-float-compute-sliding-surface-value-pass-abstractmethod-def-compute-derivative-self-state-np-ndarray-state-dot-np-ndarray-float-compute-sliding-surface-derivative-pass-abstractmethod-def-validate-gains-self-none-validate-gains-for-mathematical-correctness-pass-class-boundarylayer-interface-for-boundary-layer-implementations-def-compute-switching-function-self-surface-value-float-float-compute-continuous-switching-function-pass-def-compute-switching-control-self-surface-value-float-gain-float-surface-derivative-float-0-0-float-compute-switching-control-with-boundary-layer-pass">runnable: false class SlidingSurface(ABC): “””Abstract interface for sliding surface calculations.””” @abstractmethod def compute(self, state: np.ndarray) -&gt; float: “””Compute sliding surface value.””” pass @abstractmethod def compute_derivative(self, state: np.ndarray, state_dot: np.ndarray) -&gt; float: “””Compute sliding surface derivative.””” pass @abstractmethod def _validate_gains(self) -&gt; None: “””Validate gains for mathematical correctness.””” pass class BoundaryLayer: “””Interface for boundary layer implementations.””” def compute_switching_function(self, surface_value: float) -&gt; float: “””Compute continuous switching function.””” pass def compute_switching_control(self, surface_value: float, gain: float, surface_derivative: float = 0.0) -&gt; float: “””Compute switching control with boundary layer.””” pass</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/pso_algorithm_theory.html">Particle Swarm Optimization: Mathematical Theory <strong>Module:</strong> Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/pso_algorithm_theory.html#balanced-recommended-for-smc">Balanced (recommended for SMC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/optimization_landscape_analysis.html">Optimization Landscape Analysis for Controller Gain Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/dynamics_derivations.html">Double Inverted Pendulum Dynamics: Complete Derivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/numerical_integration_theory.html">Numerical Integration Methods: Theory and Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/simulation_architecture_guide.html">Simulation Architecture Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/config_validation_specification.html">ClassicalSMCConfig Parameters and Validation Rules This document provides specification of the <code class="docutils literal notranslate"><span class="pre">ClassicalSMCConfig</span></code> parameters, their mathematical foundations, validation rules, and edge case handling. ## 1. Configuration Schema Overview The <code class="docutils literal notranslate"><span class="pre">ClassicalSMCConfig</span></code> dataclass provides type-safe, validated configuration for Classical Sliding Mode Control with the following parameter categories: - <strong>Control Parameters</strong>: Core SMC gains and timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html">Mathematical Test Validation Methodology This document describes the methodology for validating mathematical properties and algorithm correctness in the SMC controller implementations. ## 1. Overview The test validation methodology ensures that all mathematical algorithms and fixes in the SMC system are rigorously validated through: - <strong>Property-based testing</strong>: Verification of mathematical properties</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-def-test-sliding-surface-linearity-test-that-sliding-surface-is-linear-in-state-surface-linearslidingsurface-gains-5-3-4-2-state1-np-array-0-1-0-1-0-1-0-05-0-05-0-05-state2-np-array-0-2-0-2-0-2-0-1-0-1-0-1-s1-surface-compute-state1-s2-surface-compute-state2-s-combined-surface-compute-state1-state2-linearity-s-x1-x2-s-x1-s-x2-assert-abs-s-combined-s1-s2-1e-10-2-homogeneity-property-python-def-test-sliding-surface-homogeneity-test-that-sliding-surface-is-homogeneous-of-degree-1-surface-linearslidingsurface-gains-5-3-4-2-state-np-array-0-1-0-1-0-1-0-05-0-05-0-05-alpha-2-5-s-original-surface-compute-state-s-scaled-surface-compute-alpha-state-homogeneity-s-x-s-x-assert-abs-s-scaled-alpha-s-original-1e-10-3-gain-sensitivity-python">runnable: false def test_sliding_surface_linearity(): “””Test that sliding surface is linear in state.””” surface = LinearSlidingSurface(gains=[5, 3, 4, 2]) state1 = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05]) state2 = np.array([0.2, 0.2, 0.2, 0.1, 0.1, 0.1]) s1 = surface.compute(state1) s2 = surface.compute(state2) s_combined = surface.compute(state1 + state2) # Linearity: s(x1 + x2) = s(x1) + s(x2) assert abs(s_combined - (s1 + s2)) &lt; 1e-10 <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Homogeneity</span> <span class="pre">Property**:</span></code>python def test_sliding_surface_homogeneity(): “””Test that sliding surface is homogeneous of degree 1.””” surface = LinearSlidingSurface(gains=[5, 3, 4, 2]) state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05]) alpha = 2.5 s_original = surface.compute(state) s_scaled = surface.compute(alpha * state) # Homogeneity: s(α·x) = α·s(x) assert abs(s_scaled - alpha * s_original) &lt; 1e-10 <code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">**Gain</span> <span class="pre">Sensitivity**:</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-def-test-sliding-surface-gain-sensitivity-test-that-surface-responds-correctly-to-gain-changes-gains1-5-3-4-2-gains2-10-6-8-4-doubled-gains-surface1-linearslidingsurface-gains1-surface2-linearslidingsurface-gains2-state-np-array-0-1-0-1-0-1-0-05-0-05-0-05-s1-surface1-compute-state-s2-surface2-compute-state-surface-value-should-double-with-doubled-gains-assert-abs-s2-2-s1-1e-10-2-1-2-boundary-layer-properties-test-suite-tests-test-controllers-smc-algorithms-classical-test-boundary-layer-py-mathematical-properties-validated-1-continuity-python">runnable: false def test_sliding_surface_gain_sensitivity(): “””Test that surface responds correctly to gain changes.””” gains1 = [5, 3, 4, 2] gains2 = [10, 6, 8, 4] # Doubled gains surface1 = LinearSlidingSurface(gains1) surface2 = LinearSlidingSurface(gains2) state = np.array([0.1, 0.1, 0.1, 0.05, 0.05, 0.05]) s1 = surface1.compute(state) s2 = surface2.compute(state) # Surface value should double with doubled gains assert abs(s2 - 2 * s1) &lt; 1e-10 <code class="docutils literal notranslate"><span class="pre">####</span> <span class="pre">2.1.2</span> <span class="pre">Boundary</span> <span class="pre">Layer</span> <span class="pre">Properties</span> <span class="pre">**Test</span> <span class="pre">Suite:**</span> <span class="pre">`tests/test_controllers/smc/algorithms/classical/test_boundary_layer.py`</span> <span class="pre">**Mathematical</span> <span class="pre">Properties</span> <span class="pre">Validated:**</span> <span class="pre">1.</span> <span class="pre">**Continuity**:</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id2">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-def-test-boundary-layer-continuity-test-that-boundary-layer-provides-continuous-switching-boundary-layer-boundarylayer-thickness-0-1-switch-method-tanh-test-continuity-at-surface-s-0-epsilon-1e-8-switch-left-boundary-layer-compute-switching-function-epsilon-switch-right-boundary-layer-compute-switching-function-epsilon-switch-center-boundary-layer-compute-switching-function-0-0-values-should-be-very-close-at-the-boundary-assert-abs-switch-left-switch-center-1e-6-assert-abs-switch-right-switch-center-1e-6-2-monotonicity-python-def-test-boundary-layer-monotonicity-test-that-switching-function-is-monotonic-boundary-layer-boundarylayer-thickness-0-1-switch-method-tanh-s-values-np-linspace-1-1-100-switch-values-boundary-layer-compute-switching-function-s-for-s-in-s-values-switching-function-should-be-strictly-increasing-for-i-in-range-len-switch-values-1-assert-switch-values-i-1-switch-values-i-3-asymptotic-behavior-python-def-test-boundary-layer-asymptotic-behavior-test-asymptotic-limits-of-switching-function-boundary-layer-boundarylayer-thickness-0-1-switch-method-tanh-large-positive-surface-value-switch-pos-boundary-layer-compute-switching-function-10-0-assert-abs-switch-pos-1-0-1e-3-large-negative-surface-value-switch-neg-boundary-layer-compute-switching-function-10-0-assert-abs-switch-neg-1-0-1e-3-2-2-configuration-validation-tests-test-suite-tests-test-controllers-smc-algorithms-classical-test-config-validation-py-2-2-1-parameter-validationpython">runnable: false def test_boundary_layer_continuity(): “””Test that boundary layer provides continuous switching.””” boundary_layer = BoundaryLayer(thickness=0.1, switch_method=”tanh”) # Test continuity at surface (s=0) epsilon = 1e-8 switch_left = boundary_layer.compute_switching_function(-epsilon) switch_right = boundary_layer.compute_switching_function(epsilon) switch_center = boundary_layer.compute_switching_function(0.0) # Values should be very close at the boundary assert abs(switch_left - switch_center) &lt; 1e-6 assert abs(switch_right - switch_center) &lt; 1e-6 <code class="docutils literal notranslate"><span class="pre">2.</span> <span class="pre">**Monotonicity**:</span></code>python def test_boundary_layer_monotonicity(): “””Test that switching function is monotonic.””” boundary_layer = BoundaryLayer(thickness=0.1, switch_method=”tanh”) s_values = np.linspace(-1, 1, 100) switch_values = [boundary_layer.compute_switching_function(s) for s in s_values] # Switching function should be strictly increasing for i in range(len(switch_values) - 1): assert switch_values[i+1] &gt;= switch_values[i] <code class="docutils literal notranslate"><span class="pre">3.</span> <span class="pre">**Asymptotic</span> <span class="pre">Behavior**:</span></code>python def test_boundary_layer_asymptotic_behavior(): “””Test asymptotic limits of switching function.””” boundary_layer = BoundaryLayer(thickness=0.1, switch_method=”tanh”) # Large positive surface value switch_pos = boundary_layer.compute_switching_function(10.0) assert abs(switch_pos - 1.0) &lt; 1e-3 # Large negative surface value switch_neg = boundary_layer.compute_switching_function(-10.0) assert abs(switch_neg - (-1.0)) &lt; 1e-3 <code class="docutils literal notranslate"><span class="pre">###</span> <span class="pre">2.2</span> <span class="pre">Configuration</span> <span class="pre">Validation</span> <span class="pre">Tests</span> <span class="pre">**Test</span> <span class="pre">Suite:**</span> <span class="pre">`tests/test_controllers/smc/algorithms/classical/test_config_validation.py`</span> <span class="pre">####</span> <span class="pre">2.2.1</span> <span class="pre">Parameter</span> <span class="pre">Validation</span></code>python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id3">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-class-testclassicalsmcconfigvalidation-test-configuration-parameter-validation-def-test-positive-gain-requirement-self-test-that-all-surface-gains-must-be-positive-valid-configuration-valid-gains-5-0-3-0-4-0-2-0-10-0-1-0-config-classicalsmcconfig-gains-valid-gains-max-force-100-dt-0-01-boundary-layer-0-01-invalid-zero-gain-with-pytest-raises-valueerror-match-must-be-positive-invalid-gains-0-0-3-0-4-0-2-0-10-0-1-0-classicalsmcconfig-gains-invalid-gains-max-force-100-dt-0-01-boundary-layer-0-01-invalid-negative-gain-with-pytest-raises-valueerror-match-must-be-positive-invalid-gains-5-0-3-0-4-0-2-0-10-0-1-0-classicalsmcconfig-gains-invalid-gains-max-force-100-dt-0-01-boundary-layer-0-01-def-test-switching-gain-validation-self-test-switching-gain-must-be-positive-with-pytest-raises-valueerror-match-switching-gain-k-must-be-positive-invalid-gains-5-0-3-0-4-0-2-0-10-0-1-0-k-0-classicalsmcconfig-gains-invalid-gains-max-force-100-dt-0-01-boundary-layer-0-01-def-test-boundary-layer-validation-self-test-boundary-layer-thickness-validation-valid-boundary-layer-valid-gains-5-0-3-0-4-0-2-0-10-0-1-0-config-classicalsmcconfig-gains-valid-gains-max-force-100-dt-0-01-boundary-layer-0-05-invalid-zero-boundary-layer-with-pytest-raises-valueerror-match-boundary-layer-must-be-positive-classicalsmcconfig-gains-valid-gains-max-force-100-dt-0-01-boundary-layer-0-0-invalid-negative-boundary-layer-with-pytest-raises-valueerror-match-boundary-layer-must-be-positive-classicalsmcconfig-gains-valid-gains-max-force-100-dt-0-01-boundary-layer-0-01">runnable: false class TestClassicalSMCConfigValidation: “””Test configuration parameter validation.””” def test_positive_gain_requirement(self): “””Test that all surface gains must be positive.””” # Valid configuration valid_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0] config = ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.01) # Invalid: zero gain with pytest.raises(ValueError, match=”must be positive”): invalid_gains = [0.0, 3.0, 4.0, 2.0, 10.0, 1.0] ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01) # Invalid: negative gain with pytest.raises(ValueError, match=”must be positive”): invalid_gains = [5.0, -3.0, 4.0, 2.0, 10.0, 1.0] ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01) def test_switching_gain_validation(self): “””Test switching gain must be positive.””” with pytest.raises(ValueError, match=”Switching gain K must be positive”): invalid_gains = [5.0, 3.0, 4.0, 2.0, -10.0, 1.0] # K &lt; 0 ClassicalSMCConfig(gains=invalid_gains, max_force=100, dt=0.01, boundary_layer=0.01) def test_boundary_layer_validation(self): “””Test boundary layer thickness validation.””” # Valid boundary layer valid_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0] config = ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.05) # Invalid: zero boundary layer with pytest.raises(ValueError, match=”boundary_layer must be positive”): ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=0.0) # Invalid: negative boundary layer with pytest.raises(ValueError, match=”boundary_layer must be positive”): ClassicalSMCConfig(gains=valid_gains, max_force=100, dt=0.01, boundary_layer=-0.01)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id4">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-def-test-hurwitz-stability-check-test-that-gain-combinations-satisfy-hurwitz-stability-def-check-stability-k1-k2-lam1-lam2-check-if-gains-produce-stable-sliding-dynamics-for-each-2x2-subsystem-s2-is-ci-0-stability-requires-i-0-and-ci-0-return-k1-0-and-k2-0-and-lam1-0-and-lam2-0-stable-configuration-stable-gains-5-0-3-0-4-0-2-0-10-0-1-0-config-classicalsmcconfig-gains-stable-gains-max-force-100-dt-0-01-boundary-layer-0-01-assert-check-stability-config-k1-config-k2-config-lam1-config-lam2-check-damping-ratios-zeta1-config-lam1-2-np-sqrt-config-k1-zeta2-config-lam2-2-np-sqrt-config-k2-both-subsystems-should-have-positive-damping-assert-zeta1-0-assert-zeta2-0">runnable: false def test_hurwitz_stability_check(): “””Test that gain combinations satisfy Hurwitz stability.””” def check_stability(k1, k2, lam1, lam2): “””Check if gains produce stable sliding dynamics.””” # For each 2x2 subsystem: s² + λᵢs + cᵢ = 0 # Stability requires λᵢ &gt; 0 and cᵢ &gt; 0 return k1 &gt; 0 and k2 &gt; 0 and lam1 &gt; 0 and lam2 &gt; 0 # Stable configuration stable_gains = [5.0, 3.0, 4.0, 2.0, 10.0, 1.0] config = ClassicalSMCConfig(gains=stable_gains, max_force=100, dt=0.01, boundary_layer=0.01) assert check_stability(config.k1, config.k2, config.lam1, config.lam2) # Check damping ratios zeta1 = config.lam1 / (2 * np.sqrt(config.k1)) zeta2 = config.lam2 / (2 * np.sqrt(config.k2)) # Both subsystems should have positive damping assert zeta1 &gt; 0 assert zeta2 &gt; 0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id5">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-class-testnumericalaccuracy-test-numerical-accuracy-and-precision-def-test-floating-point-consistency-self-test-that-computations-are-consistent-across-repeated-calls-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-state-np-array-0-1-0-05-0-08-0-02-0-03-0-01-compute-control-multiple-times-results-for-in-range-100-result-controller-compute-control-state-control-result-get-control-output-result-get-control-result-get-u-if-control-is-not-none-results-append-control-if-results-results-np-array-results-all-results-should-be-identical-deterministic-computation-std-dev-np-std-results-axis-0-assert-np-all-std-dev-1e-15-machine-precision-def-test-numerical-stability-small-values-self-test-numerical-stability-with-very-small-state-values-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-very-small-state-values-near-machine-precision-small-state-np-array-1e-15-1e-15-1e-15-1e-15-1e-15-1e-15-result-controller-compute-control-small-state-control-result-get-control-output-result-get-control-result-get-u-if-control-is-not-none-control-should-be-finite-and-small-assert-np-all-np-isfinite-control-assert-np-all-np-abs-control-1-0-def-test-numerical-stability-large-values-self-test-numerical-stability-with-large-state-values-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-large-state-values-but-within-reasonable-bounds-large-state-np-array-10-0-5-0-3-0-2-0-2-0-1-0-result-controller-compute-control-large-state-control-result-get-control-output-result-get-control-result-get-u-if-control-is-not-none-control-should-be-finite-and-saturated-assert-np-all-np-isfinite-control-assert-np-all-np-abs-control-config-max-force-1-01-within-saturation">runnable: false class TestNumericalAccuracy: “””Test numerical accuracy and precision.””” def test_floating_point_consistency(self): “””Test that computations are consistent across repeated calls.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]) # Compute control multiple times results = [] for _ in range(100): result = controller.compute_control(state, {}, {}) control = result.get(‘control_output’, result.get(‘control’, result.get(‘u’))) if control is not None: results.append(control) if results: results = np.array(results) # All results should be identical (deterministic computation) std_dev = np.std(results, axis=0) assert np.all(std_dev &lt; 1e-15) # Machine precision def test_numerical_stability_small_values(self): “””Test numerical stability with very small state values.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) # Very small state values (near machine precision) small_state = np.array([1e-15, 1e-15, 1e-15, 1e-15, 1e-15, 1e-15]) result = controller.compute_control(small_state, {}, {}) control = result.get(‘control_output’, result.get(‘control’, result.get(‘u’))) if control is not None: # Control should be finite and small assert np.all(np.isfinite(control)) assert np.all(np.abs(control) &lt; 1.0) def test_numerical_stability_large_values(self): “””Test numerical stability with large state values.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) # Large state values (but within reasonable bounds) large_state = np.array([10.0, 5.0, 3.0, 2.0, 2.0, 1.0]) result = controller.compute_control(large_state, {}, {}) control = result.get(‘control_output’, result.get(‘control’, result.get(‘u’))) if control is not None: # Control should be finite and saturated assert np.all(np.isfinite(control)) assert np.all(np.abs(control) &lt;= config.max_force * 1.01) # Within saturation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#id6">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#runnable-false-class-testsystemlevelmathematics-test-mathematical-consistency-across-system-components-def-test-control-law-decomposition-self-test-that-control-law-components-sum-correctly-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-state-np-array-0-1-0-05-0-08-0-02-0-03-0-01-get-overall-control-output-result-controller-compute-control-state-total-control-result-get-control-output-result-get-control-result-get-u-get-individual-components-if-available-in-debug-output-components-result-get-debug-if-u-equivalent-in-components-and-u-switching-in-components-and-u-derivative-in-components-u-eq-components-u-equivalent-u-sw-components-u-switching-u-d-components-u-derivative-before-saturation-should-sum-correctly-u-unsaturated-u-eq-u-sw-u-d-after-saturation-u-saturated-np-clip-u-unsaturated-config-max-force-config-max-force-should-match-total-control-before-any-additional-processing-if-total-control-is-not-none-assert-np-allclose-u-saturated-total-control-rtol-1e-10-def-test-lyapunov-function-properties-self-test-lyapunov-function-properties-for-stability-analysis-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-controller-modularclassicalsmc-config-config-surface-linearslidingsurface-config-get-surface-gains-multiple-test-states-states-np-array-0-1-0-05-0-08-0-02-0-03-0-01-np-array-0-2-0-1-0-15-0-05-0-08-0-03-np-array-0-1-0-05-0-08-0-02-0-03-0-01-for-state-in-states-s-surface-compute-state-lyapunov-function-candidate-v-0-5-s2-v-0-5-s-2-v-should-be-non-negative-assert-v-0-v-0-if-and-only-if-s-0-if-abs-s-1e-10-assert-v-1e-15-else-assert-v-0-def-test-reaching-law-satisfaction-self-test-that-reaching-law-is-satisfied-ss-s-config-classicalsmcconfig-gains-5-0-3-0-4-0-2-0-10-0-1-0-max-force-100-0-dt-0-01-boundary-layer-0-01-surface-linearslidingsurface-config-get-surface-gains-test-state-away-from-surface-state-np-array-0-1-0-05-0-08-0-02-0-03-0-01-s-surface-compute-state-simplified-reaching-law-check-without-full-dynamics-for-switching-control-u-sw-k-sign-s-the-reaching-condition-ss-s-should-be-satisfied-when-k-is-chosen-large-enough-this-is-a-simplified-test-full-test-would-require-dynamics-model-if-abs-s-config-boundary-layer-outside-boundary-layer-should-have-strong-reaching-behavior-expected-reaching-rate-config-k-abs-s-max-abs-s-config-boundary-layer-assert-expected-reaching-rate-0-should-be-moving-toward-surface">runnable: false class TestSystemLevelMathematics: “””Test mathematical consistency across system components.””” def test_control_law_decomposition(self): “””Test that control law components sum correctly.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]) # Get overall control output result = controller.compute_control(state, {}, {}) total_control = result.get(‘control_output’, result.get(‘control’, result.get(‘u’))) # Get individual components (if available in debug output) components = result.get(‘debug’, {}) if ‘u_equivalent’ in components and ‘u_switching’ in components and ‘u_derivative’ in components: u_eq = components[‘u_equivalent’] u_sw = components[‘u_switching’] u_d = components[‘u_derivative’] # Before saturation, should sum correctly u_unsaturated = u_eq + u_sw + u_d # After saturation u_saturated = np.clip(u_unsaturated, -config.max_force, config.max_force) # Should match total control (before any additional processing) if total_control is not None: assert np.allclose(u_saturated, total_control, rtol=1e-10) def test_lyapunov_function_properties(self): “””Test Lyapunov function properties for stability analysis.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) controller = ModularClassicalSMC(config=config) surface = LinearSlidingSurface(config.get_surface_gains()) # Multiple test states states = [ np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]), np.array([0.2, 0.1, 0.15, 0.05, 0.08, 0.03]), np.array([-0.1, -0.05, -0.08, -0.02, -0.03, -0.01]) ] for state in states: s = surface.compute(state) # Lyapunov function candidate: V = 0.5 * s² V = 0.5 * s**2 # V should be non-negative assert V &gt;= 0 # V = 0 if and only if s = 0 if abs(s) &lt; 1e-10: assert V &lt; 1e-15 else: assert V &gt; 0 def test_reaching_law_satisfaction(self): “””Test that reaching law is satisfied: s<em>ṡ ≤ -η|s|.””” config = ClassicalSMCConfig( gains=[5.0, 3.0, 4.0, 2.0, 10.0, 1.0], max_force=100.0, dt=0.01, boundary_layer=0.01 ) surface = LinearSlidingSurface(config.get_surface_gains()) # Test state away from surface state = np.array([0.1, 0.05, 0.08, 0.02, 0.03, 0.01]) s = surface.compute(state) # Simplified reaching law check (without full dynamics) # For switching control: u_sw = -K * sign(s) # The reaching condition s</em>ṡ ≤ -η|s| should be satisfied # when K is chosen large enough # This is a simplified test - full test would require dynamics model if abs(s) &gt; config.boundary_layer: # Outside boundary layer, should have strong reaching behavior expected_reaching_rate = -config.K * abs(s) / max(abs(s), config.boundary_layer) assert expected_reaching_rate &lt; 0 # Should be moving toward surface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#fast-unit-tests-mathematical-properties">Fast unit tests (mathematical properties)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/test_validation_methodology.html#extended-property-based-testing">Extended property-based testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/validation_framework_guide.html">Validation Framework Guide <strong>System Reliability Foundation: Robust Parameter Validation &amp; Scientific Verification</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/validation_framework_guide.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/validation_framework_guide.html#runnable-false-good-validate-once-at-construction">runnable: false # ✅ GOOD: Validate once at construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mathematical_foundations/validation_framework_guide.html#good-single-validation-for-array">✅ GOOD: Single validation for array</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../mathematical_validation_procedures.html">Mathematical Validation Procedures for Control Systems ## Executive Summary This document establishes mathematical validation procedures for the double-inverted pendulum sliding mode control (DIP-SMC) project, ensuring theoretical soundness and implementation correctness through rigorous mathematical property verification. The procedures integrate control theory, optimization theory, and numerical analysis validation with automated testing frameworks. <strong>Core Mathematical Domains:</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_patterns.html">Controller Memory Management Patterns (Issue #15 Resolution) <strong>Date:</strong> 2025-10-01</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_patterns.html#no-explicit-cleanup-needed-automatic-via-del">No explicit cleanup needed (automatic via <strong>del</strong>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_patterns.html#controller-automatically-cleaned-up-when-out-of-scope">Controller automatically cleaned up when out of scope</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_patterns.html#explicit-cleanup-recommended">Explicit cleanup recommended</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_patterns.html#cleanup-every-n-iterations">Cleanup every N iterations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../memory_management_quick_reference.html">Controller Memory Management Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../numerical_stability_guide.html">Numerical Stability Guide <strong>Version</strong>: 1.2.0 | <strong>Last Updated</strong>: 2025-10-01 ## Overview This guide documents the adaptive matrix regularization system implemented in the double-inverted pendulum control framework. The system provides robust numerical stability for matrix operations in plant dynamics, controllers, and optimization algorithms.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../numerical_stability_guide.html#for-well-conditioned-systems-or-debugging">For well-conditioned systems or debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plant_model.html">1.x Plant Model</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../production/index.html">Production Deployment</a><input aria-label="Toggle navigation of Production Deployment" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../production/production_readiness_assessment_v2.html">Production Readiness Assessment v2.0 <strong>Date</strong>: 2025-09-29</a></li>
<li class="toctree-l2"><a class="reference internal" href="../production_readiness_final.html">Production Readiness Assessment - Final Report <strong>Date:</strong> 2025-09-29</a></li>
<li class="toctree-l2"><a class="reference internal" href="../production_readiness_framework.html">Production Readiness Assessment Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../production_documentation_summary.html">Production Documentation Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html">PSO Configuration Schema Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#top-level-pso-configuration-structure">Top-level PSO configuration structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#runnable-false-class-constraintpropagator-intelligent-constraint-propagation-for-interdependent-pso-parameters-def-init-self-controller-type-str-self-controller-type-controller-type-self-constraint-graph-self-build-constraint-graph-def-propagate-constraints-self-initial-bounds-dict-dict-propagate-constraints-through-parameter-dependency-graph-example-if-1-is-constrained-to-0-1-5-0-for-issue-2-then-c1-bounds-must-ensure-1-1-2c1-0-69-0-8-propagated-bounds-initial-bounds-copy-iterative-constraint-propagation-converged-false-max-iterations-10-iteration-0-while-not-converged-and-iteration-max-iterations-old-bounds-propagated-bounds-copy-apply-constraint-rules-for-constraint-in-self-constraint-graph-propagated-bounds-self-apply-constraint-rule-constraint-propagated-bounds-check-convergence-converged-self-bounds-converged-old-bounds-propagated-bounds-iteration-1-return-propagated-bounds-def-apply-constraint-rule-self-constraint-dict-bounds-dict-dict-apply-individual-constraint-rule-with-mathematical-validation-if-constraint-type-damping-ratio-2c-constraint-propagation-lambda-idx-constraint-lambda-idx-c-idx-constraint-c-idx-target-zeta-range-constraint-zeta-range-lambda-min-lambda-max-bounds-min-lambda-idx-bounds-max-lambda-idx-derive-c-bounds-from-lambda-bounds-and-zeta-constraints-for-min-2c-max-c-min-2-max-2-c-max-2-min-2-c-min-from-lambda-lambda-min-2-target-zeta-range-1-2-c-max-from-lambda-lambda-max-2-target-zeta-range-0-2-update-c-bounds-with-constraint-propagation-bounds-min-c-idx-max-bounds-min-c-idx-c-min-from-lambda-bounds-max-c-idx-min-bounds-max-c-idx-c-max-from-lambda-elif-constraint-type-sta-stability-k1-k2-constraint-with-margin-k1-idx-k2-idx-constraint-k1-idx-constraint-k2-idx-margin-constraint-get-margin-0-1-ensure-k1-min-k2-max-margin-bounds-min-k1-idx-max-bounds-min-k1-idx-bounds-max-k2-idx-margin-return-bounds-def-build-constraint-graph-self-list-build-constraint-dependency-graph-for-controller-type-if-self-controller-type-classical-smc-return-type-damping-ratio-lambda-idx-1-c-idx-0-zeta-range-0-6-0-8-type-damping-ratio-lambda-idx-3-c-idx-2-zeta-range-0-6-0-8-type-actuator-saturation-gain-indices-4-5-k-kd-max-total-150-0-elif-self-controller-type-sta-smc-return-type-sta-stability-k1-idx-0-k2-idx-1-margin-0-1-type-damping-ratio-lambda-idx-4-c-idx-2-lambda1-k1-zeta-range-0-69-0-8-issue-2-requirement-type-damping-ratio-lambda-idx-5-c-idx-3-lambda2-k2-zeta-range-0-69-0-8-issue-2-requirement-return">runnable: false class ConstraintPropagator: “”” Intelligent constraint propagation for interdependent PSO parameters. “”” def <strong>init</strong>(self, controller_type: str): self.controller_type = controller_type self.constraint_graph = self._build_constraint_graph() def propagate_constraints(self, initial_bounds: dict) -&gt; dict: “”” Propagate constraints through parameter dependency graph. Example: If λ₁ is constrained to [0.1, 5.0] for Issue #2, then c₁ bounds must ensure ζ₁ = λ₁/(2√c₁) ∈ [0.69, 0.8] “”” propagated_bounds = initial_bounds.copy() # Iterative constraint propagation converged = False max_iterations = 10 iteration = 0 while not converged and iteration &lt; max_iterations: old_bounds = propagated_bounds.copy() # Apply constraint rules for constraint in self.constraint_graph: propagated_bounds = self._apply_constraint_rule( constraint, propagated_bounds ) # Check convergence converged = self._bounds_converged(old_bounds, propagated_bounds) iteration += 1 return propagated_bounds def _apply_constraint_rule(self, constraint: dict, bounds: dict) -&gt; dict: “”” Apply individual constraint rule with mathematical validation. “”” if constraint[‘type’] == ‘damping_ratio’: # ζ = λ/(2√c) constraint propagation lambda_idx = constraint[‘lambda_idx’] c_idx = constraint[‘c_idx’] target_zeta_range = constraint[‘zeta_range’] lambda_min, lambda_max = bounds[‘min’][lambda_idx], bounds[‘max’][lambda_idx] # Derive c bounds from lambda bounds and zeta constraints # For ζ_min ≤ λ/(2√c) ≤ ζ_max: # c_min = (λ/(2ζ_max))², c_max = (λ/(2ζ_min))² c_min_from_lambda = (lambda_min / (2 * target_zeta_range[1]))**2 c_max_from_lambda = (lambda_max / (2 * target_zeta_range[0]))**2 # Update c bounds with constraint propagation bounds[‘min’][c_idx] = max(bounds[‘min’][c_idx], c_min_from_lambda) bounds[‘max’][c_idx] = min(bounds[‘max’][c_idx], c_max_from_lambda) elif constraint[‘type’] == ‘sta_stability’: # K₁ &gt; K₂ constraint with margin k1_idx, k2_idx = constraint[‘k1_idx’], constraint[‘k2_idx’] margin = constraint.get(‘margin’, 0.1) # Ensure K₁_min &gt; K₂_max + margin bounds[‘min’][k1_idx] = max( bounds[‘min’][k1_idx], bounds[‘max’][k2_idx] + margin ) return bounds def _build_constraint_graph(self) -&gt; list: “”” Build constraint dependency graph for controller type. “”” if self.controller_type == ‘classical_smc’: return [ { ‘type’: ‘damping_ratio’, ‘lambda_idx’: 1, ‘c_idx’: 0, ‘zeta_range’: [0.6, 0.8] }, { ‘type’: ‘damping_ratio’, ‘lambda_idx’: 3, ‘c_idx’: 2, ‘zeta_range’: [0.6, 0.8] }, { ‘type’: ‘actuator_saturation’, ‘gain_indices’: [4, 5], # K, kd ‘max_total’: 150.0 } ] elif self.controller_type == ‘sta_smc’: return [ { ‘type’: ‘sta_stability’, ‘k1_idx’: 0, ‘k2_idx’: 1, ‘margin’: 0.1 }, { ‘type’: ‘damping_ratio’, ‘lambda_idx’: 4, ‘c_idx’: 2, # lambda1, k1 ‘zeta_range’: [0.69, 0.8] # Issue #2 requirement }, { ‘type’: ‘damping_ratio’, ‘lambda_idx’: 5, ‘c_idx’: 3, # lambda2, k2 ‘zeta_range’: [0.69, 0.8] # Issue #2 requirement } ] return []</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#configuration-schema-version-metadata">Configuration schema version metadata</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#runnable-false-class-configurationmigrator-automatic-migration-framework-for-pso-configuration-schema-evolution-def-init-self-self-migration-rules-1-0-self-migrate-from-v1-0-1-5-self-migrate-from-v1-5-2-0-self-migrate-from-v2-0-def-migrate-configuration-self-config-dict-source-version-str-tuple-migrate-configuration-from-source-version-to-current-schema-returns-tuple-migrated-config-migration-warnings-compatibility-issues-if-source-version-not-in-self-migration-rules-raise-valueerror-f-unsupported-source-version-source-version-migrated-config-config-copy-warnings-issues-apply-migration-rules-in-sequence-current-version-source-version-while-current-version-current-schema-version-migrator-self-migration-rules-current-version-migrated-config-step-warnings-migrator-migrated-config-warnings-extend-step-warnings-current-version-self-get-next-version-current-version-validate-migrated-configuration-validation-result-pso-configurationvalidator-validate-complete-config-migrated-config-if-not-validation-result-is-valid-issues-extend-validation-result-errors-return-migrated-config-warnings-issues-def-migrate-from-v1-0-self-config-dict-tuple-migrate-from-v1-0-to-v1-5-remove-deprecated-fields-update-bounds-migrated-config-copy-warnings-remove-deprecated-fields-deprecated-fields-n-processes-hyper-trials-hyper-search-study-timeout-for-field-in-deprecated-fields-if-field-in-migrated-get-pso-del-migrated-pso-field-warnings-append-f-removed-deprecated-field-field-update-pso-bounds-structure-if-pso-in-migrated-and-bounds-in-migrated-pso-old-bounds-migrated-pso-bounds-new-bounds-self-restructure-bounds-v1-5-old-bounds-migrated-pso-bounds-new-bounds-warnings-append-restructured-bounds-for-controller-specific-optimization-return-migrated-warnings-def-migrate-from-v2-0-self-config-dict-tuple-migrate-from-v2-0-to-v2-1-issue-2-bounds-updates-and-enhanced-features-migrated-config-copy-warnings-update-sta-smc-bounds-for-issue-2-compliance-if-pso-in-migrated-and-bounds-in-migrated-pso-bounds-migrated-pso-bounds-if-sta-smc-in-bounds-sta-bounds-bounds-sta-smc-check-for-issue-2-problematic-bounds-if-max-in-sta-bounds-and-len-sta-bounds-max-6-lambda1-max-lambda2-max-sta-bounds-max-4-sta-bounds-max-5-if-lambda1-max-10-0-or-lambda2-max-10-0-apply-issue-2-corrections-sta-bounds-max-4-min-lambda1-max-10-0-lambda1-sta-bounds-max-5-min-lambda2-max-10-0-lambda2-warnings-append-applied-issue-2-lambda-bounds-corrections-for-overshoot-mitigation-add-enhanced-features-if-missing-if-enhanced-features-not-in-migrated-get-pso-migrated-pso-enhanced-features-w-schedule-0-9-0-4-velocity-clamp-0-1-0-2-early-stopping-patience-50-tolerance-1e-6-warnings-append-added-enhanced-pso-features-for-improved-convergence-return-migrated-warnings-def-generate-migration-report-self-old-config-dict-new-config-dict-warnings-list-issues-list-str-generate-migration-report-for-documentation-report-f">runnable: false class ConfigurationMigrator: “”” Automatic migration framework for PSO configuration schema evolution. “”” def <strong>init</strong>(self): self.migration_rules = { “1.0”: self._migrate_from_v1_0, “1.5”: self._migrate_from_v1_5, “2.0”: self._migrate_from_v2_0 } def migrate_configuration(self, config: dict, source_version: str) -&gt; tuple: “”” Migrate configuration from source version to current schema. Returns: tuple: (migrated_config, migration_warnings, compatibility_issues) “”” if source_version not in self.migration_rules: raise ValueError(f”Unsupported source version: {source_version}”) migrated_config = config.copy() warnings = [] issues = [] # Apply migration rules in sequence current_version = source_version while current_version != CURRENT_SCHEMA_VERSION: migrator = self.migration_rules[current_version] migrated_config, step_warnings = migrator(migrated_config) warnings.extend(step_warnings) current_version = self._get_next_version(current_version) # Validate migrated configuration validation_result = PSO_ConfigurationValidator().validate_complete_config(migrated_config) if not validation_result.is_valid: issues.extend(validation_result.errors) return migrated_config, warnings, issues def _migrate_from_v1_0(self, config: dict) -&gt; tuple: “”” Migrate from v1.0 to v1.5: Remove deprecated fields, update bounds. “”” migrated = config.copy() warnings = [] # Remove deprecated fields deprecated_fields = [‘n_processes’, ‘hyper_trials’, ‘hyper_search’, ‘study_timeout’] for field in deprecated_fields: if field in migrated.get(‘pso’, {}): del migrated[‘pso’][field] warnings.append(f”Removed deprecated field: {field}”) # Update PSO bounds structure if ‘pso’ in migrated and ‘bounds’ in migrated[‘pso’]: old_bounds = migrated[‘pso’][‘bounds’] new_bounds = self._restructure_bounds_v1_5(old_bounds) migrated[‘pso’][‘bounds’] = new_bounds warnings.append(“Restructured bounds for controller-specific optimization”) return migrated, warnings def _migrate_from_v2_0(self, config: dict) -&gt; tuple: “”” Migrate from v2.0 to v2.1: Issue #2 bounds updates and enhanced features. “”” migrated = config.copy() warnings = [] # Update STA-SMC bounds for Issue #2 compliance if ‘pso’ in migrated and ‘bounds’ in migrated[‘pso’]: bounds = migrated[‘pso’][‘bounds’] if ‘sta_smc’ in bounds: sta_bounds = bounds[‘sta_smc’] # Check for Issue #2 problematic bounds if ‘max’ in sta_bounds and len(sta_bounds[‘max’]) &gt;= 6: lambda1_max, lambda2_max = sta_bounds[‘max’][4], sta_bounds[‘max’][5] if lambda1_max &gt; 10.0 or lambda2_max &gt; 10.0: # Apply Issue #2 corrections sta_bounds[‘max’][4] = min(lambda1_max, 10.0) # lambda1 sta_bounds[‘max’][5] = min(lambda2_max, 10.0) # lambda2 warnings.append(“Applied Issue #2 lambda bounds corrections for overshoot mitigation”) # Add enhanced features if missing if ‘enhanced_features’ not in migrated.get(‘pso’, {}): migrated[‘pso’][‘enhanced_features’] = { ‘w_schedule’: [0.9, 0.4], ‘velocity_clamp’: [0.1, 0.2], ‘early_stopping’: {‘patience’: 50, ‘tolerance’: 1e-6} } warnings.append(“Added enhanced PSO features for improved convergence”) return migrated, warnings def generate_migration_report(self, old_config: dict, new_config: dict, warnings: list, issues: list) -&gt; str: “”” Generate migration report for documentation. “”” report = f”””</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#pso-configuration-migration-report-summary">PSO Configuration Migration Report ## Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#id2">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_configuration_schema_documentation.html#runnable-false-class-configurationerrorhandler-error-handling-and-diagnostic-system-for-pso-configuration-error-categories-syntax-severity-critical-auto-fixable-false-description-yaml-syntax-or-structure-errors-type-severity-critical-auto-fixable-true-description-data-type-mismatches-bounds-severity-high-auto-fixable-true-description-parameter-bounds-violations-mathematical-severity-high-auto-fixable-false-description-mathematical-consistency-violations-performance-severity-medium-auto-fixable-true-description-suboptimal-performance-configuration-compatibility-severity-medium-auto-fixable-true-description-controller-compatibility-issues-def-diagnose-configuration-errors-self-config-dict-controller-type-str-none-dict-configuration-error-diagnosis-with-auto-fix-suggestions-diagnosis-errors-warnings-auto-fixes-manual-actions-overall-status-unknown-run-diagnostic-checks-for-category-info-in-self-error-categories-items-category-errors-self-check-category-category-config-controller-type-for-error-in-category-errors-error-category-category-error-severity-info-severity-error-auto-fixable-info-auto-fixable-if-error-severity-critical-diagnosis-errors-append-error-else-diagnosis-warnings-append-error-generate-fix-suggestions-if-error-auto-fixable-fix-self-generate-auto-fix-error-config-if-fix-diagnosis-auto-fixes-append-fix-else-manual-action-self-generate-manual-action-error-if-manual-action-diagnosis-manual-actions-append-manual-action-determine-overall-status-if-diagnosis-errors-diagnosis-overall-status-critical-elif-len-diagnosis-warnings-5-diagnosis-overall-status-needs-attention-elif-diagnosis-warnings-diagnosis-overall-status-minor-issues-else-diagnosis-overall-status-healthy-return-diagnosis-def-check-category-self-category-str-config-dict-controller-type-str-list-check-specific-error-category-and-return-found-issues-errors-if-category-mathematical-pso-convergence-check-if-algorithm-params-in-config-params-config-algorithm-params-if-c1-in-params-and-c2-in-params-phi-params-c1-params-c2-if-phi-4-0-errors-append-code-pso-convergence-risk-message-f-pso-may-not-converge-c1-c2-phi-3f-4-0-location-algorithm-params-c1-algorithm-params-c2-impact-optimization-may-fail-to-converge-elif-category-bounds-and-controller-type-issue-2-specific-checks-for-sta-smc-if-controller-type-sta-smc-and-bounds-in-config-bounds-config-bounds-if-sta-smc-in-bounds-and-max-in-bounds-sta-smc-max-bounds-bounds-sta-smc-max-if-len-max-bounds-6-lambda1-max-lambda2-max-max-bounds-4-max-bounds-5-if-lambda1-max-10-0-or-lambda2-max-10-0-errors-append-code-issue2-bounds-violation-message-f-sta-smc-lambda-bounds-may-cause-overshoot-1-max-lambda1-max-2-max-lambda2-max-location-bounds-sta-smc-max-4-6-impact-may-cause-5-overshoot-issue-2-regression-elif-category-performance-suboptimal-parameter-detection-if-algorithm-params-in-config-params-config-algorithm-params-if-n-particles-in-params-n-particles-params-n-particles-if-n-particles-10-or-n-particles-50-errors-append-code-suboptimal-swarm-size-message-f-swarm-size-n-particles-outside-optimal-range-10-50-location-algorithm-params-n-particles-impact-suboptimal-convergence-speed-or-quality-return-errors-def-generate-auto-fix-self-error-dict-config-dict-dict-generate-automatic-fix-for-fixable-errors-if-error-code-pso-convergence-risk-return-error-code-error-code-fix-type-parameter-adjustment-action-increase-c1-and-c2-to-ensure-4-changes-algorithm-params-c1-2-1-algorithm-params-c2-2-1-justification-ensures-pso-convergence-with-4-2-4-elif-error-code-issue2-bounds-violation-return-error-code-error-code-fix-type-bounds-correction-action-apply-issue-2-lambda-bounds-corrections-changes-bounds-sta-smc-max-4-10-0-lambda1-bounds-sta-smc-max-5-10-0-lambda2-justification-prevents-overshoot-regression-from-issue-2-elif-error-code-suboptimal-swarm-size-current-size-config-algorithm-params-n-particles-optimal-size-np-clip-current-size-15-25-clamp-to-optimal-range-return-error-code-error-code-fix-type-parameter-optimization-action-f-adjust-swarm-size-to-optimal-range-changes-algorithm-params-n-particles-optimal-size-justification-f-optimizes-convergence-for-optimal-size-particles-return-none-def-apply-auto-fixes-self-config-dict-fixes-list-tuple-apply-automatic-fixes-to-configuration-returns-tuple-fixed-config-applied-fixes-failed-fixes-fixed-config-config-copy-applied-fixes-failed-fixes-for-fix-in-fixes-try-for-path-new-value-in-fix-changes-items-self-set-nested-value-fixed-config-path-new-value-applied-fixes-append-fix-except-exception-as-e-fix-error-str-e-failed-fixes-append-fix-return-fixed-config-applied-fixes-failed-fixes-def-set-nested-value-self-config-dict-path-str-value-any-none-set-nested-configuration-value-using-dot-notation-path-keys-path-split-current-config-for-key-in-keys-1-if-in-key-and-in-key-handle-array-indexing-array-key-index-str-key-split-index-int-index-str-rstrip-if-array-key-not-in-current-current-array-key-current-current-array-key-extend-array-if-necessary-while-len-current-index-current-append-none-current-current-index-else-if-key-not-in-current-current-key-current-current-key-set-the-final-value-final-key-keys-1-if-in-final-key-and-in-final-key-array-key-index-str-final-key-split-index-int-index-str-rstrip-if-array-key-not-in-current-current-array-key-while-len-current-array-key-index-current-array-key-append-none-current-array-key-index-value-else-current-final-key-value">runnable: false class ConfigurationErrorHandler: “”” error handling and diagnostic system for PSO configuration. “”” ERROR_CATEGORIES = { ‘SYNTAX’: { ‘severity’: ‘CRITICAL’, ‘auto_fixable’: False, ‘description’: ‘YAML syntax or structure errors’ }, ‘TYPE’: { ‘severity’: ‘CRITICAL’, ‘auto_fixable’: True, ‘description’: ‘Data type mismatches’ }, ‘BOUNDS’: { ‘severity’: ‘HIGH’, ‘auto_fixable’: True, ‘description’: ‘Parameter bounds violations’ }, ‘MATHEMATICAL’: { ‘severity’: ‘HIGH’, ‘auto_fixable’: False, ‘description’: ‘Mathematical consistency violations’ }, ‘PERFORMANCE’: { ‘severity’: ‘MEDIUM’, ‘auto_fixable’: True, ‘description’: ‘Suboptimal performance configuration’ }, ‘COMPATIBILITY’: { ‘severity’: ‘MEDIUM’, ‘auto_fixable’: True, ‘description’: ‘Controller compatibility issues’ } } def diagnose_configuration_errors(self, config: dict, controller_type: str = None) -&gt; dict: “”” configuration error diagnosis with auto-fix suggestions. “”” diagnosis = { ‘errors’: [], ‘warnings’: [], ‘auto_fixes’: [], ‘manual_actions’: [], ‘overall_status’: ‘UNKNOWN’ } # Run diagnostic checks for category, info in self.ERROR_CATEGORIES.items(): category_errors = self._check_category(category, config, controller_type) for error in category_errors: error[‘category’] = category error[‘severity’] = info[‘severity’] error[‘auto_fixable’] = info[‘auto_fixable’] if error[‘severity’] == ‘CRITICAL’: diagnosis[‘errors’].append(error) else: diagnosis[‘warnings’].append(error) # Generate fix suggestions if error[‘auto_fixable’]: fix = self._generate_auto_fix(error, config) if fix: diagnosis[‘auto_fixes’].append(fix) else: manual_action = self._generate_manual_action(error) if manual_action: diagnosis[‘manual_actions’].append(manual_action) # Determine overall status if diagnosis[‘errors’]: diagnosis[‘overall_status’] = ‘CRITICAL’ elif len(diagnosis[‘warnings’]) &gt; 5: diagnosis[‘overall_status’] = ‘NEEDS_ATTENTION’ elif diagnosis[‘warnings’]: diagnosis[‘overall_status’] = ‘MINOR_ISSUES’ else: diagnosis[‘overall_status’] = ‘HEALTHY’ return diagnosis def _check_category(self, category: str, config: dict, controller_type: str) -&gt; list: “”” Check specific error category and return found issues. “”” errors = [] if category == ‘MATHEMATICAL’: # PSO convergence check if ‘algorithm_params’ in config: params = config[‘algorithm_params’] if ‘c1’ in params and ‘c2’ in params: phi = params[‘c1’] + params[‘c2’] if phi &lt;= 4.0: errors.append({ ‘code’: ‘PSO_CONVERGENCE_RISK’, ‘message’: f’PSO may not converge: φ = c₁ + c₂ = {phi:.3f} ≤ 4.0’, ‘location’: ‘algorithm_params.c1, algorithm_params.c2’, ‘impact’: ‘Optimization may fail to converge’ }) elif category == ‘BOUNDS’ and controller_type: # Issue #2 specific checks for STA-SMC if controller_type == ‘sta_smc’ and ‘bounds’ in config: bounds = config[‘bounds’] if ‘sta_smc’ in bounds and ‘max’ in bounds[‘sta_smc’]: max_bounds = bounds[‘sta_smc’][‘max’] if len(max_bounds) &gt;= 6: lambda1_max, lambda2_max = max_bounds[4], max_bounds[5] if lambda1_max &gt; 10.0 or lambda2_max &gt; 10.0: errors.append({ ‘code’: ‘ISSUE2_BOUNDS_VIOLATION’, ‘message’: f’STA-SMC lambda bounds may cause overshoot: λ₁_max={lambda1_max}, λ₂_max={lambda2_max}’, ‘location’: ‘bounds.sta_smc.max[4:6]’, ‘impact’: ‘May cause &gt;5% overshoot (Issue #2 regression)’ }) elif category == ‘PERFORMANCE’: # Suboptimal parameter detection if ‘algorithm_params’ in config: params = config[‘algorithm_params’] if ‘n_particles’ in params: n_particles = params[‘n_particles’] if n_particles &lt; 10 or n_particles &gt; 50: errors.append({ ‘code’: ‘SUBOPTIMAL_SWARM_SIZE’, ‘message’: f’Swarm size {n_particles} outside optimal range [10, 50]’, ‘location’: ‘algorithm_params.n_particles’, ‘impact’: ‘Suboptimal convergence speed or quality’ }) return errors def _generate_auto_fix(self, error: dict, config: dict) -&gt; dict: “”” Generate automatic fix for fixable errors. “”” if error[‘code’] == ‘PSO_CONVERGENCE_RISK’: return { ‘error_code’: error[‘code’], ‘fix_type’: ‘parameter_adjustment’, ‘action’: ‘Increase c₁ and c₂ to ensure φ &gt; 4’, ‘changes’: { ‘algorithm_params.c1’: 2.1, ‘algorithm_params.c2’: 2.1 }, ‘justification’: ‘Ensures PSO convergence with φ = 4.2 &gt; 4’ } elif error[‘code’] == ‘ISSUE2_BOUNDS_VIOLATION’: return { ‘error_code’: error[‘code’], ‘fix_type’: ‘bounds_correction’, ‘action’: ‘Apply Issue #2 lambda bounds corrections’, ‘changes’: { ‘bounds.sta_smc.max[4]’: 10.0, # lambda1 ‘bounds.sta_smc.max[5]’: 10.0 # lambda2 }, ‘justification’: ‘Prevents overshoot regression from Issue #2’ } elif error[‘code’] == ‘SUBOPTIMAL_SWARM_SIZE’: current_size = config[‘algorithm_params’][‘n_particles’] optimal_size = np.clip(current_size, 15, 25) # Clamp to optimal range return { ‘error_code’: error[‘code’], ‘fix_type’: ‘parameter_optimization’, ‘action’: f’Adjust swarm size to optimal range’, ‘changes’: { ‘algorithm_params.n_particles’: optimal_size }, ‘justification’: f’Optimizes convergence for {optimal_size} particles’ } return None def apply_auto_fixes(self, config: dict, fixes: list) -&gt; tuple: “”” Apply automatic fixes to configuration. Returns: tuple: (fixed_config, applied_fixes, failed_fixes) “”” fixed_config = config.copy() applied_fixes = [] failed_fixes = [] for fix in fixes: try: for path, new_value in fix[‘changes’].items(): self._set_nested_value(fixed_config, path, new_value) applied_fixes.append(fix) except Exception as e: fix[‘error’] = str(e) failed_fixes.append(fix) return fixed_config, applied_fixes, failed_fixes def _set_nested_value(self, config: dict, path: str, value: any) -&gt; None: “”” Set nested configuration value using dot notation path. “”” keys = path.split(‘.’) current = config for key in keys[:-1]: if ‘[’ in key and ‘]’ in key: # Handle array indexing array_key, index_str = key.split(‘[’) index = int(index_str.rstrip(‘]’)) if array_key not in current: current[array_key] = [] current = current[array_key] # Extend array if necessary while len(current) &lt;= index: current.append(None) current = current[index] else: if key not in current: current[key] = {} current = current[key] # Set the final value final_key = keys[-1] if ‘[’ in final_key and ‘]’ in final_key: array_key, index_str = final_key.split(‘[’) index = int(index_str.rstrip(‘]’)) if array_key not in current: current[array_key] = [] while len(current[array_key]) &lt;= index: current[array_key].append(None) current[array_key][index] = value else: current[final_key] = value</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_factory_integration_patterns.html">PSO-Factory Integration Patterns Documentation ## Overview This document provides guidance on integrating the factory system with Particle Swarm Optimization (PSO) workflows. The DIP SMC-PSO project features native PSO integration patterns that streamline controller optimization while maintaining scientific rigor and performance. ## Table of Contents 1. <span class="xref myst">PSO Integration Architecture</span></a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_factory_integration_patterns.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_factory_integration_patterns.html#runnable-false-def-adaptive-pso-optimization-controller-type-smctype-tuple-np-ndarray-float-adaptive-pso-with-dynamic-parameter-adjustment-factory-create-pso-controller-factory-controller-type-class-adaptivepsocontroller-adaptive-pso-controller-with-factory-integration-def-init-self-self-iteration-0-self-best-fitness-history-self-stagnation-counter-0-self-current-bounds-get-gain-bounds-for-pso-controller-type-def-adapt-parameters-self-current-best-fitness-float-dict-str-float-adapt-pso-parameters-based-on-progress-check-for-stagnation-if-len-self-best-fitness-history-0-and-abs-current-best-fitness-self-best-fitness-history-1-1e-6-self-stagnation-counter-1-else-self-stagnation-counter-0-self-best-fitness-history-append-current-best-fitness-adaptive-parameter-adjustment-if-self-stagnation-counter-10-increase-exploration-w-0-9-high-inertia-c1-c2-2-5-1-5-high-cognitive-low-social-expand-search-bounds-slightly-lower-upper-self-current-bounds-expansion-0-1-self-current-bounds-l-1-expansion-for-l-in-lower-u-1-expansion-for-u-in-upper-elif-self-iteration-50-early-exploration-phase-w-0-9-c1-c2-2-0-2-0-else-late-exploitation-phase-w-0-4-c1-c2-1-5-2-5-self-iteration-1-return-w-w-c1-c1-c2-c2-bounds-self-current-bounds-def-fitness-function-self-gains-np-ndarray-float-adaptive-fitness-function-with-dynamic-objectives-try-controller-factory-gains-metrics-evaluate-controller-performance-controller-dynamic-objective-weighting-based-on-iteration-if-self-iteration-30-early-phase-focus-on-basic-performance-return-0-7-metrics-ise-0-3-metrics-control-effort-elif-self-iteration-80-middle-phase-balance-performance-and-robustness-return-0-4-metrics-ise-0-3-metrics-control-effort-0-3-metrics-robustness-penalty-else-late-phase-focus-on-refinement-return-0-3-metrics-ise-0-2-metrics-control-effort-0-3-metrics-robustness-penalty-0-2-metrics-chattering-penalty-except-return-float-inf-run-adaptive-pso-adaptive-controller-adaptivepsocontroller-initial-pso-configuration-pso-params-adaptive-controller-adapt-parameters-float-inf-optimizer-psotuner-controller-factory-adaptive-controller-fitness-function-config-config-adaptive-callback-adaptive-controller-adapt-parameters-return-optimizer-optimize-adaptive">runnable: false def adaptive_pso_optimization(controller_type: SMCType) -&gt; Tuple[np.ndarray, float]: “””Adaptive PSO with dynamic parameter adjustment.””” factory = create_pso_controller_factory(controller_type) class AdaptivePSOController: “””Adaptive PSO controller with factory integration.””” def <strong>init</strong>(self): self.iteration = 0 self.best_fitness_history = [] self.stagnation_counter = 0 self.current_bounds = get_gain_bounds_for_pso(controller_type) def adapt_parameters(self, current_best_fitness: float) -&gt; Dict[str, float]: “””Adapt PSO parameters based on progress.””” # Check for stagnation if (len(self.best_fitness_history) &gt; 0 and abs(current_best_fitness - self.best_fitness_history[-1]) &lt; 1e-6): self.stagnation_counter += 1 else: self.stagnation_counter = 0 self.best_fitness_history.append(current_best_fitness) # Adaptive parameter adjustment if self.stagnation_counter &gt; 10: # Increase exploration w = 0.9 # High inertia c1, c2 = 2.5, 1.5 # High cognitive, low social # Expand search bounds slightly lower, upper = self.current_bounds expansion = 0.1 self.current_bounds = ( [l * (1 - expansion) for l in lower], [u * (1 + expansion) for u in upper] ) elif self.iteration &lt; 50: # Early exploration phase w = 0.9 c1, c2 = 2.0, 2.0 else: # Late exploitation phase w = 0.4 c1, c2 = 1.5, 2.5 self.iteration += 1 return { ‘w’: w, ‘c1’: c1, ‘c2’: c2, ‘bounds’: self.current_bounds } def fitness_function(self, gains: np.ndarray) -&gt; float: “””Adaptive fitness function with dynamic objectives.””” try: controller = factory(gains) metrics = evaluate_controller_performance(controller) # Dynamic objective weighting based on iteration if self.iteration &lt; 30: # Early phase: focus on basic performance return 0.7 * metrics[‘ise’] + 0.3 * metrics[‘control_effort’] elif self.iteration &lt; 80: # Middle phase: balance performance and robustness return (0.4 * metrics[‘ise’] + 0.3 * metrics[‘control_effort’] + 0.3 * metrics[‘robustness_penalty’]) else: # Late phase: focus on refinement return (0.3 * metrics[‘ise’] + 0.2 * metrics[‘control_effort’] + 0.3 * metrics[‘robustness_penalty’] + 0.2 * metrics[‘chattering_penalty’]) except: return float(‘inf’) # Run adaptive PSO adaptive_controller = AdaptivePSOController() # Initial PSO configuration pso_params = adaptive_controller.adapt_parameters(float(‘inf’)) optimizer = PSOTuner( controller_factory=adaptive_controller.fitness_function, config=config, adaptive_callback=adaptive_controller.adapt_parameters ) return optimizer.optimize_adaptive()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_factory_integration_patterns.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_factory_integration_patterns.html#runnable-false-usr-bin-env-python3">runnable: false #!/usr/bin/env python3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html">PSO Integration Technical Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-def-controller-factory-gains-np-ndarray-controller-pso-compatible-controller-factory-interface-mathematical-foundation-the-factory-must-instantiate-controllers-with-gain-vector-g-n-where-n-is-controller-specific-dimensionality-classical-smc-g-6-c1-1-c2-2-k-kd-sta-smc-g-6-k1-k2-k1-k2-1-2-adaptive-smc-g-5-c1-1-c2-2-hybrid-adaptive-sta-smc-g-4-c1-1-c2-2-parameters-gains-np-ndarray-shape-n-controller-gain-vector-with-validated-bounds-returns-controller-configured-smc-instance-with-required-attributes-max-force-float-actuator-saturation-limit-validate-gains-optional-callable-pre-filtering-function-interface-contracts-1-factory-function-must-have-attribute-n-gains-specifying-dimensionality-2-returned-controller-must-implement-control-computation-interface-3-all-gains-must-be-positive-and-within-specified-bounds-4-controller-must-handle-edge-cases-singularities-saturation-return-create-controller-controller-type-config-gains-gains-required-factory-attribute">runnable: false def controller_factory(gains: np.ndarray) -&gt; Controller: “”” PSO-compatible controller factory interface. Mathematical Foundation: The factory must instantiate controllers with gain vector G ∈ ℝⁿ where n is controller-specific dimensionality: - Classical SMC: G ∈ ℝ⁶ (c₁, λ₁, c₂, λ₂, K, kd) - STA-SMC: G ∈ ℝ⁶ (K₁, K₂, k₁, k₂, λ₁, λ₂) - Adaptive SMC: G ∈ ℝ⁵ (c₁, λ₁, c₂, λ₂, γ) - Hybrid Adaptive STA-SMC: G ∈ ℝ⁴ (c₁, λ₁, c₂, λ₂) Parameters ———- gains : np.ndarray, shape (n,) Controller gain vector with validated bounds Returns ——- Controller Configured SMC instance with required attributes: - max_force: float (actuator saturation limit) - validate_gains: Optional[Callable] (pre-filtering function) Interface Contracts —————— 1. Factory function MUST have attribute ‘n_gains’ specifying dimensionality 2. Returned controller MUST implement control computation interface 3. All gains MUST be positive and within specified bounds 4. Controller MUST handle edge cases (singularities, saturation) “”” return create_controller(controller_type, config, gains=gains) # Required factory attribute</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-controller-registry-with-pso-integration-metadata">runnable: false # Controller Registry with PSO Integration Metadata</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id2">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-def-validate-controller-gains-controller-type-str-gains-np-ndarray-np-ndarray-validate-gain-vectors-for-controller-specific-stability-requirements-mathematical-validation-rules-classical-smc-all-gains-0-positive-definiteness-sliding-surface-gains-c1-1-c2-2-ensure-hurwitz-characteristic-polynomial-switching-gains-k-kd-provide-reaching-condition-satisfaction-sta-smc-super-twisting-algorithmic-gains-k1-k2-0-stability-condition-surface-coefficients-1-2-for-target-damping-ratio-0-6-0-8-finite-time-convergence-k12-4k2-12-parameters-controller-type-str-controller-identifier-from-registry-gains-np-ndarray-shape-b-n-batch-of-gain-vectors-to-validate-returns-np-ndarray-shape-b-dtype-bool-validity-mask-for-each-gain-vector-registry-info-controller-registry-controller-type-bounds-registry-info-gain-bounds-basic-bounds-checking-valid-mask-np-ones-gains-shape-0-dtype-bool-for-i-min-val-max-val-in-enumerate-bounds-valid-mask-gains-i-min-val-gains-i-max-val-controller-specific-stability-checks-if-controller-type-sta-smc-k1-k2-condition-for-sta-stability-valid-mask-gains-0-gains-1-surface-coefficient-bounds-for-target-damping-lambda1-lambda2-gains-4-gains-5-damping-ratio-lambda2-2-np-sqrt-lambda1-valid-mask-damping-ratio-0-6-damping-ratio-0-8-return-valid-mask">runnable: false def validate_controller_gains(controller_type: str, gains: np.ndarray) -&gt; np.ndarray: “”” Validate gain vectors for controller-specific stability requirements. Mathematical Validation Rules: Classical SMC: - All gains &gt; 0 (positive definiteness) - Sliding surface gains c₁, λ₁, c₂, λ₂ ensure Hurwitz characteristic polynomial - Switching gains K, kd provide reaching condition satisfaction STA-SMC (Super-Twisting): - Algorithmic gains: K₁ &gt; K₂ &gt; 0 (stability condition) - Surface coefficients: λ₁, λ₂ for target damping ratio ζ ∈ [0.6, 0.8] - Finite-time convergence: K₁² &gt; 4K₂|λ₁λ₂| Parameters ———- controller_type : str Controller identifier from registry gains : np.ndarray, shape (B, n) Batch of gain vectors to validate Returns ——- np.ndarray, shape (B,), dtype=bool Validity mask for each gain vector “”” registry_info = CONTROLLER_REGISTRY[controller_type] bounds = registry_info[‘gain_bounds’] # Basic bounds checking valid_mask = np.ones(gains.shape[0], dtype=bool) for i, (min_val, max_val) in enumerate(bounds): valid_mask &amp;= (gains[:, i] &gt;= min_val) &amp; (gains[:, i] &lt;= max_val) # Controller-specific stability checks if controller_type == ‘sta_smc’: # K₁ &gt; K₂ condition for STA stability valid_mask &amp;= gains[:, 0] &gt; gains[:, 1] # Surface coefficient bounds for target damping lambda1, lambda2 = gains[:, 4], gains[:, 5] damping_ratio = lambda2 / (2 * np.sqrt(lambda1)) valid_mask &amp;= (damping_ratio &gt;= 0.6) &amp; (damping_ratio &lt;= 0.8) return valid_mask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id3">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-def-compute-fitness-cost-t-np-ndarray-x-np-ndarray-u-np-ndarray-sigma-np-ndarray-float-multi-objective-fitness-function-for-pso-optimization-mathematical-formulation-j-w10-e-t-2dt-w20-u2-t-dt-w30-du-dt-2dt-w40-2-t-dt-p-where-e-t-x-t-x-ref-state-error-vector-u-t-control-effort-du-dt-control-rate-chattering-penalty-t-sliding-variable-magnitude-p-instability-penalty-for-early-termination-cost-function-components-1-state-error-ise-0-e-t-2dt-2-control-effort-0-u2-t-dt-3-control-rate-0-du-dt-2dt-4-sliding-variable-energy-0-2-t-dt-5-stability-penalty-graded-penalty-for-premature-failure-dt-np-diff-t-dt-matrix-dt-none-shape-1-n-1-state-error-integration-all-state-components-state-error-sq-np-sum-x-1-2-dt-matrix-none-axis-1-2-control-effort-integration-control-effort-sq-np-sum-u2-dt-matrix-axis-1-control-rate-penalty-anti-chattering-du-np-diff-u-axis-1-prepend-u-0-1-control-rate-sq-np-sum-du2-dt-matrix-axis-1-sliding-variable-energy-sliding-energy-np-sum-sigma2-dt-matrix-axis-1-instability-detection-and-penalty-instability-mask-detect-instability-x-u-sigma-stability-penalty-compute-graded-penalty-instability-mask-t-weighted-cost-aggregation-total-cost-weights-state-error-normalize-state-error-sq-norms-ise-weights-control-effort-normalize-control-effort-sq-norms-control-weights-control-rate-normalize-control-rate-sq-norms-rate-weights-stability-normalize-sliding-energy-norms-sliding-stability-penalty-return-total-cost">runnable: false def compute_fitness_cost(t: np.ndarray, x: np.ndarray, u: np.ndarray, sigma: np.ndarray) -&gt; float: “”” Multi-objective fitness function for PSO optimization. Mathematical Formulation: J = w₁∫₀ᵀ||e(t)||²dt + w₂∫₀ᵀu²(t)dt + w₃∫₀ᵀ(du/dt)²dt + w₄∫₀ᵀσ²(t)dt + P Where: - e(t) = x(t) - x_ref: state error vector - u(t): control effort - du/dt: control rate (chattering penalty) - σ(t): sliding variable magnitude - P: instability penalty for early termination Cost Function Components: 1. State Error (ISE): ∫₀ᵀ||e(t)||²dt 2. Control Effort: ∫₀ᵀu²(t)dt 3. Control Rate: ∫₀ᵀ(du/dt)²dt 4. Sliding Variable Energy: ∫₀ᵀσ²(t)dt 5. Stability Penalty: Graded penalty for premature failure “”” dt = np.diff(t) dt_matrix = dt[None, :] # Shape (1, N-1) # State error integration (all state components) state_error_sq = np.sum(x[:, :-1, :]<strong>2 * dt_matrix[:, :, None], axis=(1, 2)) # Control effort integration control_effort_sq = np.sum(u</strong>2 * dt_matrix, axis=1) # Control rate penalty (anti-chattering) du = np.diff(u, axis=1, prepend=u[:, 0:1]) control_rate_sq = np.sum(du<strong>2 * dt_matrix, axis=1) # Sliding variable energy sliding_energy = np.sum(sigma</strong>2 * dt_matrix, axis=1) # Instability detection and penalty instability_mask = detect_instability(x, u, sigma) stability_penalty = compute_graded_penalty(instability_mask, t) # Weighted cost aggregation total_cost = ( weights.state_error * normalize(state_error_sq, norms.ise) + weights.control_effort * normalize(control_effort_sq, norms.control) + weights.control_rate * normalize(control_rate_sq, norms.rate) + weights.stability * normalize(sliding_energy, norms.sliding) + stability_penalty ) return total_cost</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id4">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-class-pso-convergencemonitor-advanced-convergence-monitoring-with-multiple-termination-criteria-def-init-self-patience-int-50-tolerance-float-1e-6-diversity-threshold-float-1e-8-self-patience-patience-self-tolerance-tolerance-self-diversity-threshold-diversity-threshold-self-best-cost-history-self-diversity-history-self-stagnation-counter-0-def-check-convergence-self-swarm-positions-np-ndarray-swarm-costs-np-ndarray-tuple-bool-str-multi-criteria-convergence-detection-1-cost-improvement-stagnation-2-swarm-diversity-collapse-3-gradient-based-local-optimum-detection-current-best-np-min-swarm-costs-self-best-cost-history-append-current-best-swarm-diversity-standard-deviation-of-positions-diversity-np-mean-np-std-swarm-positions-axis-0-self-diversity-history-append-diversity-check-improvement-stagnation-if-len-self-best-cost-history-2-improvement-abs-self-best-cost-history-2-current-best-relative-improvement-improvement-abs-current-best-1e-12-if-relative-improvement-self-tolerance-self-stagnation-counter-1-else-self-stagnation-counter-0-convergence-conditions-if-self-stagnation-counter-self-patience-return-true-f-cost-stagnation-self-stagnation-counter-iterations-without-improvement-if-diversity-self-diversity-threshold-return-true-f-diversity-collapse-diversity-2e-self-diversity-threshold-2e-return-false-optimization-continuing">runnable: false class PSO_ConvergenceMonitor: “”” Advanced convergence monitoring with multiple termination criteria. “”” def <strong>init</strong>(self, patience: int = 50, tolerance: float = 1e-6, diversity_threshold: float = 1e-8): self.patience = patience self.tolerance = tolerance self.diversity_threshold = diversity_threshold self.best_cost_history = [] self.diversity_history = [] self.stagnation_counter = 0 def check_convergence(self, swarm_positions: np.ndarray, swarm_costs: np.ndarray) -&gt; tuple[bool, str]: “”” Multi-criteria convergence detection: 1. Cost improvement stagnation 2. Swarm diversity collapse 3. Gradient-based local optimum detection “”” current_best = np.min(swarm_costs) self.best_cost_history.append(current_best) # Swarm diversity (standard deviation of positions) diversity = np.mean(np.std(swarm_positions, axis=0)) self.diversity_history.append(diversity) # Check improvement stagnation if len(self.best_cost_history) &gt;= 2: improvement = abs(self.best_cost_history[-2] - current_best) relative_improvement = improvement / (abs(current_best) + 1e-12) if relative_improvement &lt; self.tolerance: self.stagnation_counter += 1 else: self.stagnation_counter = 0 # Convergence conditions if self.stagnation_counter &gt;= self.patience: return True, f”Cost stagnation: {self.stagnation_counter} iterations without improvement” if diversity &lt; self.diversity_threshold: return True, f”Diversity collapse: σ = {diversity:.2e} &lt; {self.diversity_threshold:.2e}” return False, “Optimization continuing”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id5">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-def-robust-optimization-under-uncertainty-pso-tuner-psotuner-uncertainty-config-physicsuncertaintyschema-dict-monte-carlo-robust-optimization-with-uncertainty-quantification-methodology-1-sample-n-physics-realizations-from-uncertainty-distributions-2-evaluate-each-particle-against-all-realizations-3-aggregate-costs-using-risk-sensitive-criteria-mean-std-4-report-confidence-intervals-for-optimal-gains-mathematical-framework-uncertain-parameters-n-0-2-for-each-physics-parameter-robust-cost-j-robust-e-j-g-std-j-g-risk-parameter-0-1-balancing-mean-vs-variance-generate-uncertainty-samples-physics-samples-generate-physics-samples-uncertainty-config-multi-realization-evaluation-costs-per-realization-for-physics-params-in-physics-samples-evaluate-swarm-under-this-realization-realization-costs-pso-tuner-evaluate-swarm-with-physics-physics-params-costs-per-realization-append-realization-costs-risk-sensitive-aggregation-mean-costs-np-mean-costs-per-realization-axis-0-std-costs-np-std-costs-per-realization-axis-0-robust-costs-mean-costs-uncertainty-config-risk-factor-std-costs-return-robust-costs-robust-costs-mean-costs-mean-costs-std-costs-std-costs-confidence-intervals-compute-confidence-intervals-costs-per-realization-physics-samples-physics-samples">runnable: false def robust_optimization_under_uncertainty(pso_tuner: PSOTuner, uncertainty_config: PhysicsUncertaintySchema) -&gt; dict: “”” Monte Carlo robust optimization with uncertainty quantification. Methodology: 1. Sample N physics realizations from uncertainty distributions 2. Evaluate each particle against all realizations 3. Aggregate costs using risk-sensitive criteria (mean + α·std) 4. Report confidence intervals for optimal gains Mathematical Framework: - Uncertain parameters: θ ~ N(θ₀, σ²) for each physics parameter - Robust cost: J_robust = E[J(G,θ)] + α·Std[J(G,θ)] - Risk parameter: α ∈ [0, 1] balancing mean vs variance “”” # Generate uncertainty samples physics_samples = generate_physics_samples(uncertainty_config) # Multi-realization evaluation costs_per_realization = [] for physics_params in physics_samples: # Evaluate swarm under this realization realization_costs = pso_tuner.evaluate_swarm_with_physics(physics_params) costs_per_realization.append(realization_costs) # Risk-sensitive aggregation mean_costs = np.mean(costs_per_realization, axis=0) std_costs = np.std(costs_per_realization, axis=0) robust_costs = mean_costs + uncertainty_config.risk_factor * std_costs return { ‘robust_costs’: robust_costs, ‘mean_costs’: mean_costs, ‘std_costs’: std_costs, ‘confidence_intervals’: compute_confidence_intervals(costs_per_realization), ‘physics_samples’: physics_samples }</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#version-1-0-legacy-deprecated">Version 1.0 (Legacy) - Deprecated</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#id6">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_integration_technical_specification.html#runnable-false-def-migrate-pso-configuration-legacy-config-dict-psoconfig-migrate-legacy-pso-configuration-to-current-schema-with-validation-migration-rules-1-remove-deprecated-fields-with-warnings-2-update-bounds-for-issue-2-resolution-compatibility-3-add-new-enhanced-features-with-sensible-defaults-4-validate-mathematical-consistency-of-migrated-parameters-warnings-remove-deprecated-fields-deprecated-fields-n-processes-hyper-trials-hyper-search-study-timeout-for-field-in-deprecated-fields-if-field-in-legacy-config-warnings-append-f-deprecated-field-field-removed-during-migration-del-legacy-config-field-update-bounds-for-issue-2-compatibility-if-bounds-in-legacy-config-old-bounds-legacy-config-bounds-if-max-in-old-bounds-and-len-old-bounds-max-6-check-for-problematic-lambda-bounds-from-issue-2-if-old-bounds-max-4-10-0-or-old-bounds-max-5-10-0-warnings-append-updated-lambda-bounds-for-issue-2-overshoot-resolution-old-bounds-max-4-min-old-bounds-max-4-10-0-old-bounds-max-5-min-old-bounds-max-5-10-0-add-enhanced-features-if-missing-if-w-schedule-not-in-legacy-config-legacy-config-w-schedule-0-9-0-4-warnings-append-added-inertia-weight-scheduling-for-improved-convergence-if-velocity-clamp-not-in-legacy-config-legacy-config-velocity-clamp-0-1-0-2-warnings-append-added-velocity-clamping-for-stability-validate-migrated-configuration-migrated-config-psoconfig-legacy-config-validation-result-pso-configvalidator-validate-hyperparameters-migrated-config-if-not-validation-result-is-valid-raise-configurationerror-f-migration-failed-validation-validation-result-errors-return-migrated-config-warnings">runnable: false def migrate_pso_configuration(legacy_config: dict) -&gt; PSOConfig: “”” Migrate legacy PSO configuration to current schema with validation. Migration Rules: 1. Remove deprecated fields with warnings 2. Update bounds for Issue #2 resolution compatibility 3. Add new enhanced features with sensible defaults 4. Validate mathematical consistency of migrated parameters “”” warnings = [] # Remove deprecated fields deprecated_fields = [‘n_processes’, ‘hyper_trials’, ‘hyper_search’, ‘study_timeout’] for field in deprecated_fields: if field in legacy_config: warnings.append(f”Deprecated field ‘{field}’ removed during migration”) del legacy_config[field] # Update bounds for Issue #2 compatibility if ‘bounds’ in legacy_config: old_bounds = legacy_config[‘bounds’] if ‘max’ in old_bounds and len(old_bounds[‘max’]) &gt;= 6: # Check for problematic lambda bounds from Issue #2 if old_bounds[‘max’][4] &gt; 10.0 or old_bounds[‘max’][5] &gt; 10.0: warnings.append(“Updated lambda bounds for Issue #2 overshoot resolution”) old_bounds[‘max’][4] = min(old_bounds[‘max’][4], 10.0) old_bounds[‘max’][5] = min(old_bounds[‘max’][5], 10.0) # Add enhanced features if missing if ‘w_schedule’ not in legacy_config: legacy_config[‘w_schedule’] = [0.9, 0.4] warnings.append(“Added inertia weight scheduling for improved convergence”) if ‘velocity_clamp’ not in legacy_config: legacy_config[‘velocity_clamp’] = [0.1, 0.2] warnings.append(“Added velocity clamping for stability”) # Validate migrated configuration migrated_config = PSOConfig(**legacy_config) validation_result = PSO_ConfigValidator.validate_hyperparameters(migrated_config) if not validation_result.is_valid: raise ConfigurationError(f”Migration failed validation: {validation_result.errors}”) return migrated_config, warnings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html">PSO Optimization Workflow Specifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#runnable-false-class-optimizationworkflowmanager-management-of-pso-optimization-workflow-execution-def-init-self-config-dict-controller-type-str-self-config-config-self-controller-type-controller-type-self-monitors-performance-performancemonitor-convergence-convergencemonitor-memory-memorymonitor-safety-safetymonitor-self-workflow-state-workflowstate-def-execute-optimization-workflow-self-controller-factory-callable-optimizationresult-execute-complete-pso-optimization-workflow-with-monitoring-workflow-phases-1-pre-optimization-setup-and-validation-2-pso-tuner-initialization-3-optimization-loop-execution-4-real-time-monitoring-and-adaptation-5-post-optimization-validation-6-result-analysis-and-reporting-workflow-start-time-time-time-result-optimizationresult-try-phase-1-pre-optimization-setup-setup-result-self-execute-setup-phase-controller-factory-result-setup-results-setup-result-if-not-setup-result-success-result-status-setup-failed-return-result-phase-2-pso-tuner-initialization-tuner-result-self-execute-tuner-initialization-result-tuner-results-tuner-result-if-not-tuner-result-success-result-status-tuner-failed-return-result-phase-3-optimization-execution-optimization-result-self-execute-optimization-loop-result-optimization-results-optimization-result-if-not-optimization-result-success-result-status-optimization-failed-return-result-phase-4-post-optimization-validation-validation-result-self-execute-validation-phase-optimization-result-result-validation-results-validation-result-phase-5-result-analysis-analysis-result-self-execute-analysis-phase-optimization-result-result-analysis-results-analysis-result-result-status-success-result-total-time-time-time-workflow-start-time-except-exception-as-e-result-status-error-result-error-message-str-e-result-total-time-time-time-workflow-start-time-return-result-def-execute-setup-phase-self-controller-factory-callable-setupresult-execute-pre-optimization-setup-and-validation-setup-result-setupresult-validate-controller-factory-if-not-hasattr-controller-factory-n-gains-setup-result-errors-append-controller-factory-missing-n-gains-attribute-setup-result-success-false-return-setup-result-validate-factory-functionality-try-test-gains-np-ones-controller-factory-n-gains-test-controller-controller-factory-test-gains-if-not-hasattr-test-controller-max-force-setup-result-warnings-append-controller-missing-max-force-attribute-except-exception-as-e-setup-result-errors-append-f-controller-factory-test-failed-str-e-setup-result-success-false-return-setup-result-setup-monitoring-systems-for-name-monitor-in-self-monitors-items-try-monitor-initialize-self-config-setup-result-monitors-initialized-append-name-except-exception-as-e-setup-result-errors-append-f-monitor-name-initialization-failed-str-e-validate-memory-availability-available-memory-psutil-virtual-memory-available-1024-3-gb-required-memory-self-estimate-memory-requirement-if-available-memory-required-memory-setup-result-warnings-append-f-low-memory-available-memory-1f-gb-available-required-memory-1f-gb-recommended-setup-result-success-len-setup-result-errors-0-return-setup-result-def-execute-optimization-loop-self-optimizationloopresult-execute-pso-optimization-loop-with-real-time-monitoring-result-optimizationloopresult-try-initialize-pso-tuner-tuner-psotuner-controller-factory-self-controller-factory-config-self-config-seed-self-config-get-pso-get-execution-get-seed-42-setup-optimization-monitoring-optimization-monitor-optimizationmonitor-monitors-self-monitors-config-self-config-execute-optimization-with-monitoring-pso-result-tuner-optimise-extract-results-result-best-cost-pso-result-best-cost-result-best-gains-pso-result-best-pos-result-cost-history-pso-result-history-cost-result-position-history-pso-result-history-pos-get-monitoring-data-result-performance-metrics-optimization-monitor-get-performance-summary-result-convergence-analysis-optimization-monitor-get-convergence-analysis-result-success-true-except-exception-as-e-result-success-false-result-error-message-str-e-return-result">runnable: false class OptimizationWorkflowManager: “”” management of PSO optimization workflow execution. “”” def <strong>init</strong>(self, config: dict, controller_type: str): self.config = config self.controller_type = controller_type self.monitors = { ‘performance’: PerformanceMonitor(), ‘convergence’: ConvergenceMonitor(), ‘memory’: MemoryMonitor(), ‘safety’: SafetyMonitor() } self.workflow_state = WorkflowState() def execute_optimization_workflow(self, controller_factory: Callable) -&gt; OptimizationResult: “”” Execute complete PSO optimization workflow with monitoring. Workflow Phases: 1. Pre-optimization setup and validation 2. PSO tuner initialization 3. Optimization loop execution 4. Real-time monitoring and adaptation 5. Post-optimization validation 6. Result analysis and reporting “”” workflow_start_time = time.time() result = OptimizationResult() try: # Phase 1: Pre-optimization Setup setup_result = self._execute_setup_phase(controller_factory) result.setup_results = setup_result if not setup_result.success: result.status = ‘SETUP_FAILED’ return result # Phase 2: PSO Tuner Initialization tuner_result = self._execute_tuner_initialization() result.tuner_results = tuner_result if not tuner_result.success: result.status = ‘TUNER_FAILED’ return result # Phase 3: Optimization Execution optimization_result = self._execute_optimization_loop() result.optimization_results = optimization_result if not optimization_result.success: result.status = ‘OPTIMIZATION_FAILED’ return result # Phase 4: Post-optimization Validation validation_result = self._execute_validation_phase(optimization_result) result.validation_results = validation_result # Phase 5: Result Analysis analysis_result = self._execute_analysis_phase(optimization_result) result.analysis_results = analysis_result result.status = ‘SUCCESS’ result.total_time = time.time() - workflow_start_time except Exception as e: result.status = ‘ERROR’ result.error_message = str(e) result.total_time = time.time() - workflow_start_time return result def _execute_setup_phase(self, controller_factory: Callable) -&gt; SetupResult: “”” Execute pre-optimization setup and validation. “”” setup_result = SetupResult() # Validate controller factory if not hasattr(controller_factory, ‘n_gains’): setup_result.errors.append(‘Controller factory missing n_gains attribute’) setup_result.success = False return setup_result # Validate factory functionality try: test_gains = np.ones(controller_factory.n_gains) test_controller = controller_factory(test_gains) if not hasattr(test_controller, ‘max_force’): setup_result.warnings.append(‘Controller missing max_force attribute’) except Exception as e: setup_result.errors.append(f’Controller factory test failed: {str(e)}’) setup_result.success = False return setup_result # Setup monitoring systems for name, monitor in self.monitors.items(): try: monitor.initialize(self.config) setup_result.monitors_initialized.append(name) except Exception as e: setup_result.errors.append(f’Monitor {name} initialization failed: {str(e)}’) # Validate memory availability available_memory = psutil.virtual_memory().available / (1024**3) # GB required_memory = self._estimate_memory_requirement() if available_memory &lt; required_memory: setup_result.warnings.append(f’Low memory: {available_memory:.1f}GB available, {required_memory:.1f}GB recommended’) setup_result.success = len(setup_result.errors) == 0 return setup_result def _execute_optimization_loop(self) -&gt; OptimizationLoopResult: “”” Execute PSO optimization loop with real-time monitoring. “”” result = OptimizationLoopResult() try: # Initialize PSO tuner tuner = PSOTuner( controller_factory=self.controller_factory, config=self.config, seed=self.config.get(‘pso’, {}).get(‘execution’, {}).get(‘seed’, 42) ) # Setup optimization monitoring optimization_monitor = OptimizationMonitor( monitors=self.monitors, config=self.config ) # Execute optimization with monitoring pso_result = tuner.optimise() # Extract results result.best_cost = pso_result[‘best_cost’] result.best_gains = pso_result[‘best_pos’] result.cost_history = pso_result[‘history’][‘cost’] result.position_history = pso_result[‘history’][‘pos’] # Get monitoring data result.performance_metrics = optimization_monitor.get_performance_summary() result.convergence_analysis = optimization_monitor.get_convergence_analysis() result.success = True except Exception as e: result.success = False result.error_message = str(e) return result</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#id1">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#runnable-false-class-optimizationmonitor-real-time-monitoring-system-for-pso-optimization-with-adaptive-features-def-init-self-monitors-dict-config-dict-self-monitors-monitors-self-config-config-self-monitoring-data-iteration-times-memory-usage-cost-improvements-diversity-metrics-constraint-violations-safety-alerts-def-monitor-iteration-self-iteration-int-swarm-state-dict-monitoringresult-monitor-single-pso-iteration-with-metrics-collection-iteration-start-time-time-result-monitoringresult-performance-monitoring-perf-metrics-self-monitors-performance-collect-metrics-swarm-state-self-monitoring-data-iteration-times-append-perf-metrics-iteration-time-self-monitoring-data-memory-usage-append-perf-metrics-memory-mb-convergence-monitoring-conv-metrics-self-monitors-convergence-analyze-convergence-swarm-state-self-monitoring-data-cost-improvements-append-conv-metrics-cost-improvement-self-monitoring-data-diversity-metrics-append-conv-metrics-diversity-constraint-validation-constraint-result-self-validate-constraints-realtime-swarm-state-self-monitoring-data-constraint-violations-extend-constraint-result-violations-safety-monitoring-safety-result-self-monitors-safety-check-safety-conditions-swarm-state-if-safety-result-alerts-self-monitoring-data-safety-alerts-extend-safety-result-alerts-adaptive-parameter-adjustment-if-self-should-adapt-parameters-iteration-swarm-state-adaptations-self-compute-parameter-adaptations-swarm-state-result-parameter-adaptations-adaptations-issue-2-specific-monitoring-for-sta-smc-if-self-config-get-controller-type-sta-smc-issue2-result-self-monitor-issue2-compliance-swarm-state-result-issue2-compliance-issue2-result-result-monitoring-data-self-monitoring-data-result-iteration-time-time-time-iteration-start-return-result-def-validate-constraints-realtime-self-swarm-state-dict-dict-real-time-validation-of-mathematical-and-physical-constraints-violations-particles-swarm-state-get-positions-np-array-if-particles-size-0-return-violations-violations-controller-type-self-config-get-controller-type-classical-smc-controller-specific-constraint-checking-if-controller-type-sta-smc-and-particles-shape-1-6-k1-k2-constraint-k1-particles-k2-particles-particles-0-particles-1-k1-le-k2-mask-k1-particles-k2-particles-if-np-any-k1-le-k2-mask-violation-count-np-sum-k1-le-k2-mask-violations-append-type-sta-stability-violation-count-violation-count-particles-np-where-k1-le-k2-mask-0-tolist-severity-high-issue-2-damping-ratio-constraint-if-particles-shape-1-6-lambda1-lambda2-particles-4-particles-5-k1-k2-particles-2-particles-3-safe-computation-with-epsilon-to-avoid-division-by-zero-epsilon-1e-12-zeta1-lambda1-2-np-sqrt-k1-epsilon-zeta2-lambda2-2-np-sqrt-k2-epsilon-check-issue-2-requirement-0-69-zeta1-violation-zeta1-0-69-zeta2-violation-zeta2-0-69-if-np-any-zeta1-violation-or-np-any-zeta2-violation-violation-particles-np-where-zeta1-violation-zeta2-violation-0-violations-append-type-issue2-damping-violation-count-len-violation-particles-particles-violation-particles-tolist-severity-high-details-min-zeta1-np-min-zeta1-min-zeta2-np-min-zeta2-requirement-0-69-for-5-overshoot-return-violations-violations-def-monitor-issue2-compliance-self-swarm-state-dict-dict-specialized-monitoring-for-issue-2-overshoot-compliance-particles-swarm-state-get-positions-np-array-if-particles-size-0-or-particles-shape-1-6-return-status-insufficient-data-extract-surface-coefficients-lambda1-lambda2-particles-4-particles-5-k1-k2-particles-2-particles-3-compute-damping-ratios-epsilon-1e-12-zeta1-lambda1-2-np-sqrt-k1-epsilon-zeta2-lambda2-2-np-sqrt-k2-epsilon-issue-2-compliance-analysis-compliance-stats-compliant-particles-0-total-particles-len-particles-min-damping-ratio-min-np-min-zeta1-np-min-zeta2-avg-damping-ratio-np-mean-zeta1-np-mean-zeta2-2-predicted-overshoot-range-lambda-bounds-status-unknown-count-compliant-particles-0-69-compliant-mask-zeta1-0-69-zeta2-0-69-compliance-stats-compliant-particles-np-sum-compliant-mask-predict-overshoot-for-representative-particles-for-i-in-range-min-5-len-particles-sample-first-5-particles-zeta-avg-zeta1-i-zeta2-i-2-if-zeta-avg-1-0-underdamped-predicted-overshoot-100-np-exp-zeta-avg-np-pi-np-sqrt-1-zeta-avg-2-else-overdamped-predicted-overshoot-0-0-compliance-stats-predicted-overshoot-range-append-predicted-overshoot-check-lambda-bounds-status-max-lambda1-max-lambda2-np-max-lambda1-np-max-lambda2-if-max-lambda1-10-0-and-max-lambda2-10-0-compliance-stats-lambda-bounds-status-compliant-else-compliance-stats-lambda-bounds-status-violation-return-compliance-stats">runnable: false class OptimizationMonitor: “”” Real-time monitoring system for PSO optimization with adaptive features. “”” def <strong>init</strong>(self, monitors: dict, config: dict): self.monitors = monitors self.config = config self.monitoring_data = { ‘iteration_times’: [], ‘memory_usage’: [], ‘cost_improvements’: [], ‘diversity_metrics’: [], ‘constraint_violations’: [], ‘safety_alerts’: [] } def monitor_iteration(self, iteration: int, swarm_state: dict) -&gt; MonitoringResult: “”” Monitor single PSO iteration with metrics collection. “”” iteration_start = time.time() result = MonitoringResult() # Performance monitoring perf_metrics = self.monitors[‘performance’].collect_metrics(swarm_state) self.monitoring_data[‘iteration_times’].append(perf_metrics[‘iteration_time’]) self.monitoring_data[‘memory_usage’].append(perf_metrics[‘memory_mb’]) # Convergence monitoring conv_metrics = self.monitors[‘convergence’].analyze_convergence(swarm_state) self.monitoring_data[‘cost_improvements’].append(conv_metrics[‘cost_improvement’]) self.monitoring_data[‘diversity_metrics’].append(conv_metrics[‘diversity’]) # Constraint validation constraint_result = self._validate_constraints_realtime(swarm_state) self.monitoring_data[‘constraint_violations’].extend(constraint_result[‘violations’]) # Safety monitoring safety_result = self.monitors[‘safety’].check_safety_conditions(swarm_state) if safety_result[‘alerts’]: self.monitoring_data[‘safety_alerts’].extend(safety_result[‘alerts’]) # Adaptive parameter adjustment if self._should_adapt_parameters(iteration, swarm_state): adaptations = self._compute_parameter_adaptations(swarm_state) result.parameter_adaptations = adaptations # Issue #2 specific monitoring for STA-SMC if self.config.get(‘controller_type’) == ‘sta_smc’: issue2_result = self._monitor_issue2_compliance(swarm_state) result.issue2_compliance = issue2_result result.monitoring_data = self.monitoring_data result.iteration_time = time.time() - iteration_start return result def _validate_constraints_realtime(self, swarm_state: dict) -&gt; dict: “”” Real-time validation of mathematical and physical constraints. “”” violations = [] particles = swarm_state.get(‘positions’, np.array([])) if particles.size == 0: return {‘violations’: violations} controller_type = self.config.get(‘controller_type’, ‘classical_smc’) # Controller-specific constraint checking if controller_type == ‘sta_smc’ and particles.shape[1] &gt;= 6: # K₁ &gt; K₂ constraint k1_particles, k2_particles = particles[:, 0], particles[:, 1] k1_le_k2_mask = k1_particles &lt;= k2_particles if np.any(k1_le_k2_mask): violation_count = np.sum(k1_le_k2_mask) violations.append({ ‘type’: ‘STA_STABILITY_VIOLATION’, ‘count’: violation_count, ‘particles’: np.where(k1_le_k2_mask)[0].tolist(), ‘severity’: ‘HIGH’ }) # Issue #2 damping ratio constraint if particles.shape[1] &gt;= 6: lambda1, lambda2 = particles[:, 4], particles[:, 5] k1, k2 = particles[:, 2], particles[:, 3] # Safe computation with epsilon to avoid division by zero epsilon = 1e-12 zeta1 = lambda1 / (2 * np.sqrt(k1 + epsilon)) zeta2 = lambda2 / (2 * np.sqrt(k2 + epsilon)) # Check Issue #2 requirement: ζ ≥ 0.69 zeta1_violation = zeta1 &lt; 0.69 zeta2_violation = zeta2 &lt; 0.69 if np.any(zeta1_violation) or np.any(zeta2_violation): violation_particles = np.where(zeta1_violation | zeta2_violation)[0] violations.append({ ‘type’: ‘ISSUE2_DAMPING_VIOLATION’, ‘count’: len(violation_particles), ‘particles’: violation_particles.tolist(), ‘severity’: ‘HIGH’, ‘details’: { ‘min_zeta1’: np.min(zeta1), ‘min_zeta2’: np.min(zeta2), ‘requirement’: ‘ζ ≥ 0.69 for &lt;5% overshoot’ } }) return {‘violations’: violations} def _monitor_issue2_compliance(self, swarm_state: dict) -&gt; dict: “”” Specialized monitoring for Issue #2 overshoot compliance. “”” particles = swarm_state.get(‘positions’, np.array([])) if particles.size == 0 or particles.shape[1] &lt; 6: return {‘status’: ‘insufficient_data’} # Extract surface coefficients lambda1, lambda2 = particles[:, 4], particles[:, 5] k1, k2 = particles[:, 2], particles[:, 3] # Compute damping ratios epsilon = 1e-12 zeta1 = lambda1 / (2 * np.sqrt(k1 + epsilon)) zeta2 = lambda2 / (2 * np.sqrt(k2 + epsilon)) # Issue #2 compliance analysis compliance_stats = { ‘compliant_particles’: 0, ‘total_particles’: len(particles), ‘min_damping_ratio’: min(np.min(zeta1), np.min(zeta2)), ‘avg_damping_ratio’: (np.mean(zeta1) + np.mean(zeta2)) / 2, ‘predicted_overshoot_range’: [], ‘lambda_bounds_status’: ‘unknown’ } # Count compliant particles (ζ ≥ 0.69) compliant_mask = (zeta1 &gt;= 0.69) &amp; (zeta2 &gt;= 0.69) compliance_stats[‘compliant_particles’] = np.sum(compliant_mask) # Predict overshoot for representative particles for i in range(min(5, len(particles))): # Sample first 5 particles zeta_avg = (zeta1[i] + zeta2[i]) / 2 if zeta_avg &lt; 1.0: # Underdamped predicted_overshoot = 100 * np.exp(-zeta_avg * np.pi / np.sqrt(1 - zeta_avg**2)) else: # Overdamped predicted_overshoot = 0.0 compliance_stats[‘predicted_overshoot_range’].append(predicted_overshoot) # Check lambda bounds status max_lambda1, max_lambda2 = np.max(lambda1), np.max(lambda2) if max_lambda1 &lt;= 10.0 and max_lambda2 &lt;= 10.0: compliance_stats[‘lambda_bounds_status’] = ‘compliant’ else: compliance_stats[‘lambda_bounds_status’] = ‘violation’ return compliance_stats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#id2">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#runnable-false-class-qualitygatesystem-automated-quality-gate-system-for-pso-optimization-workflow-def-init-self-config-dict-self-config-config-self-quality-gates-configurationqualitygate-optimizationqualitygate-performancequalitygate-safetyqualitygate-issue2compliancequalitygate-regressionqualitygate-def-evaluate-quality-gates-self-workflow-result-dict-qualitygatereport-evaluate-all-quality-gates-and-generate-report-report-qualitygatereport-for-gate-in-self-quality-gates-gate-result-gate-evaluate-workflow-result-self-config-report-add-gate-result-gate-name-gate-result-generate-overall-assessment-report-generate-overall-assessment-return-report-class-issue2compliancequalitygate-qualitygate-quality-gate-specifically-for-issue-2-overshoot-compliance-def-init-self-self-name-issue2-overshoot-compliance-self-acceptance-criteria-max-predicted-overshoot-5-0-maximum-theoretical-overshoot-min-damping-ratio-0-69-minimum-damping-for-compliance-max-lambda-bounds-10-0-maximum-lambda-values-simulation-overshoot-limit-5-0-maximum-measured-overshoot-def-evaluate-self-workflow-result-dict-config-dict-qualitygateresult-evaluate-issue-2-overshoot-compliance-result-qualitygateresult-gate-name-self-name-skip-if-not-sta-smc-if-config-get-controller-type-sta-smc-result-status-skipped-result-message-issue-2-compliance-only-applies-to-sta-smc-return-result-optimized-gains-workflow-result-get-best-gains-if-optimized-gains-is-none-or-len-optimized-gains-6-result-status-failed-result-message-missing-or-insufficient-optimized-gains-return-result-extract-surface-coefficients-lambda1-lambda2-optimized-gains-4-optimized-gains-5-k1-k2-optimized-gains-2-optimized-gains-3-check-1-lambda-bounds-compliance-lambda-bounds-ok-lambda1-self-acceptance-criteria-max-lambda-bounds-and-lambda2-self-acceptance-criteria-max-lambda-bounds-check-2-damping-ratio-compliance-zeta1-lambda1-2-np-sqrt-k1-zeta2-lambda2-2-np-sqrt-k2-damping-ok-zeta1-self-acceptance-criteria-min-damping-ratio-and-zeta2-self-acceptance-criteria-min-damping-ratio-check-3-predicted-overshoot-avg-zeta-zeta1-zeta2-2-if-avg-zeta-1-0-predicted-overshoot-100-np-exp-avg-zeta-np-pi-np-sqrt-1-avg-zeta-2-else-predicted-overshoot-0-0-overshoot-prediction-ok-predicted-overshoot-self-acceptance-criteria-max-predicted-overshoot-check-4-simulation-validation-if-available-simulation-ok-true-measured-overshoot-none-if-overshoot-measurement-in-workflow-result-overshoot-data-workflow-result-overshoot-measurement-measured-overshoot-overshoot-data-get-measured-overshoot-percent-0-simulation-ok-measured-overshoot-self-acceptance-criteria-simulation-overshoot-limit-overall-assessment-all-checks-pass-lambda-bounds-ok-and-damping-ok-and-overshoot-prediction-ok-and-simulation-ok-if-all-checks-pass-result-status-passed-result-message-f-issue-2-compliance-verified-predicted-overshoot-predicted-overshoot-2f-else-result-status-failed-failed-checks-if-not-lambda-bounds-ok-failed-checks-append-f-lambda-bounds-1-lambda1-3f-2-lambda2-3f-self-acceptance-criteria-max-lambda-bounds-if-not-damping-ok-failed-checks-append-f-damping-ratios-1-zeta1-3f-2-zeta2-3f-self-acceptance-criteria-min-damping-ratio-if-not-overshoot-prediction-ok-failed-checks-append-f-predicted-overshoot-predicted-overshoot-2f-self-acceptance-criteria-max-predicted-overshoot-if-not-simulation-ok-and-measured-overshoot-is-not-none-failed-checks-append-f-measured-overshoot-measured-overshoot-2f-self-acceptance-criteria-simulation-overshoot-limit-result-message-f-issue-2-compliance-failed-join-failed-checks-add-detailed-metrics-result-metrics-lambda1-lambda1-lambda2-lambda2-damping-ratio-1-zeta1-damping-ratio-2-zeta2-predicted-overshoot-percent-predicted-overshoot-measured-overshoot-percent-measured-overshoot-lambda-bounds-compliant-lambda-bounds-ok-damping-compliant-damping-ok-overshoot-prediction-compliant-overshoot-prediction-ok-simulation-compliant-simulation-ok-return-result">runnable: false class QualityGateSystem: “”” Automated quality gate system for PSO optimization workflow. “”” def <strong>init</strong>(self, config: dict): self.config = config self.quality_gates = [ ConfigurationQualityGate(), OptimizationQualityGate(), PerformanceQualityGate(), SafetyQualityGate(), Issue2ComplianceQualityGate(), RegressionQualityGate() ] def evaluate_quality_gates(self, workflow_result: dict) -&gt; QualityGateReport: “”” Evaluate all quality gates and generate report. “”” report = QualityGateReport() for gate in self.quality_gates: gate_result = gate.evaluate(workflow_result, self.config) report.add_gate_result(gate.name, gate_result) # Generate overall assessment report.generate_overall_assessment() return report class Issue2ComplianceQualityGate(QualityGate): “”” Quality gate specifically for Issue #2 overshoot compliance. “”” def <strong>init</strong>(self): self.name = “Issue2_Overshoot_Compliance” self.acceptance_criteria = { ‘max_predicted_overshoot’: 5.0, # % maximum theoretical overshoot ‘min_damping_ratio’: 0.69, # Minimum damping for compliance ‘max_lambda_bounds’: 10.0, # Maximum lambda values ‘simulation_overshoot_limit’: 5.0 # % maximum measured overshoot } def evaluate(self, workflow_result: dict, config: dict) -&gt; QualityGateResult: “”” Evaluate Issue #2 overshoot compliance. “”” result = QualityGateResult(gate_name=self.name) # Skip if not STA-SMC if config.get(‘controller_type’) != ‘sta_smc’: result.status = ‘SKIPPED’ result.message = ‘Issue #2 compliance only applies to STA-SMC’ return result optimized_gains = workflow_result.get(‘best_gains’) if optimized_gains is None or len(optimized_gains) &lt; 6: result.status = ‘FAILED’ result.message = ‘Missing or insufficient optimized gains’ return result # Extract surface coefficients lambda1, lambda2 = optimized_gains[4], optimized_gains[5] k1, k2 = optimized_gains[2], optimized_gains[3] # Check 1: Lambda bounds compliance lambda_bounds_ok = (lambda1 &lt;= self.acceptance_criteria[‘max_lambda_bounds’] and lambda2 &lt;= self.acceptance_criteria[‘max_lambda_bounds’]) # Check 2: Damping ratio compliance zeta1 = lambda1 / (2 * np.sqrt(k1)) zeta2 = lambda2 / (2 * np.sqrt(k2)) damping_ok = (zeta1 &gt;= self.acceptance_criteria[‘min_damping_ratio’] and zeta2 &gt;= self.acceptance_criteria[‘min_damping_ratio’]) # Check 3: Predicted overshoot avg_zeta = (zeta1 + zeta2) / 2 if avg_zeta &lt; 1.0: predicted_overshoot = 100 * np.exp(-avg_zeta * np.pi / np.sqrt(1 - avg_zeta**2)) else: predicted_overshoot = 0.0 overshoot_prediction_ok = predicted_overshoot &lt;= self.acceptance_criteria[‘max_predicted_overshoot’] # Check 4: Simulation validation (if available) simulation_ok = True measured_overshoot = None if ‘overshoot_measurement’ in workflow_result: overshoot_data = workflow_result[‘overshoot_measurement’] measured_overshoot = overshoot_data.get(‘measured_overshoot_percent’, 0) simulation_ok = measured_overshoot &lt;= self.acceptance_criteria[‘simulation_overshoot_limit’] # Overall assessment all_checks_pass = lambda_bounds_ok and damping_ok and overshoot_prediction_ok and simulation_ok if all_checks_pass: result.status = ‘PASSED’ result.message = f’Issue #2 compliance verified: predicted overshoot {predicted_overshoot:.2f}%’ else: result.status = ‘FAILED’ failed_checks = [] if not lambda_bounds_ok: failed_checks.append(f’Lambda bounds: λ₁={lambda1:.3f}, λ₂={lambda2:.3f} &gt; {self.acceptance_criteria[“max_lambda_bounds”]}’) if not damping_ok: failed_checks.append(f’Damping ratios: ζ₁={zeta1:.3f}, ζ₂={zeta2:.3f} &lt; {self.acceptance_criteria[“min_damping_ratio”]}’) if not overshoot_prediction_ok: failed_checks.append(f’Predicted overshoot: {predicted_overshoot:.2f}% &gt; {self.acceptance_criteria[“max_predicted_overshoot”]}%’) if not simulation_ok and measured_overshoot is not None: failed_checks.append(f’Measured overshoot: {measured_overshoot:.2f}% &gt; {self.acceptance_criteria[“simulation_overshoot_limit”]}%’) result.message = f’Issue #2 compliance failed: {”; “.join(failed_checks)}’ # Add detailed metrics result.metrics = { ‘lambda1’: lambda1, ‘lambda2’: lambda2, ‘damping_ratio_1’: zeta1, ‘damping_ratio_2’: zeta2, ‘predicted_overshoot_percent’: predicted_overshoot, ‘measured_overshoot_percent’: measured_overshoot, ‘lambda_bounds_compliant’: lambda_bounds_ok, ‘damping_compliant’: damping_ok, ‘overshoot_prediction_compliant’: overshoot_prediction_ok, ‘simulation_compliant’: simulation_ok } return result</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#id3">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_specifications.html#runnable-false-class-workflowperformanceoptimizer-adaptive-optimization-of-workflow-performance-based-on-runtime-metrics-def-init-self-self-performance-history-self-optimization-strategies-memory-optimization-self-optimize-memory-usage-convergence-acceleration-self-accelerate-convergence-bounds-tightening-self-tighten-bounds-dynamically-parameter-adaptation-self-adapt-pso-parameters-def-optimize-workflow-performance-self-current-metrics-dict-workflow-config-dict-optimizationresult-analyze-current-performance-and-apply-optimization-strategies-result-optimizationresult-analyze-performance-trends-performance-analysis-self-analyze-performance-trends-current-metrics-apply-relevant-optimization-strategies-for-strategy-name-strategy-func-in-self-optimization-strategies-items-if-self-should-apply-strategy-strategy-name-performance-analysis-strategy-result-strategy-func-current-metrics-workflow-config-result-add-strategy-result-strategy-name-strategy-result-return-result-def-accelerate-convergence-self-metrics-dict-config-dict-dict-apply-convergence-acceleration-strategies-based-on-performance-analysis-acceleration-result-applied-optimizations-expected-improvement-0-0-check-convergence-rate-convergence-rate-metrics-get-convergence-rate-0-0-if-convergence-rate-0-05-slow-convergence-detected-suggest-inertia-weight-adjustment-current-w-config-get-pso-get-algorithm-params-get-w-0-7-if-current-w-0-5-suggested-w-max-0-4-current-w-0-1-acceleration-result-applied-optimizations-append-parameter-inertia-weight-current-value-current-w-suggested-value-suggested-w-justification-reduce-inertia-for-faster-exploitation-acceleration-result-expected-improvement-15-0-15-improvement-check-diversity-metrics-diversity-metrics-get-swarm-diversity-1-0-if-diversity-1e-8-very-low-diversity-acceleration-result-applied-optimizations-append-parameter-restart-mechanism-action-enable-fraction-0-2-justification-restart-20-of-particles-to-escape-local-optimum-acceleration-result-expected-improvement-20-0-20-improvement-return-acceleration-result">runnable: false class WorkflowPerformanceOptimizer: “”” Adaptive optimization of workflow performance based on runtime metrics. “”” def <strong>init</strong>(self): self.performance_history = [] self.optimization_strategies = { ‘memory_optimization’: self._optimize_memory_usage, ‘convergence_acceleration’: self._accelerate_convergence, ‘bounds_tightening’: self._tighten_bounds_dynamically, ‘parameter_adaptation’: self._adapt_pso_parameters } def optimize_workflow_performance(self, current_metrics: dict, workflow_config: dict) -&gt; OptimizationResult: “”” Analyze current performance and apply optimization strategies. “”” result = OptimizationResult() # Analyze performance trends performance_analysis = self._analyze_performance_trends(current_metrics) # Apply relevant optimization strategies for strategy_name, strategy_func in self.optimization_strategies.items(): if self._should_apply_strategy(strategy_name, performance_analysis): strategy_result = strategy_func(current_metrics, workflow_config) result.add_strategy_result(strategy_name, strategy_result) return result def _accelerate_convergence(self, metrics: dict, config: dict) -&gt; dict: “”” Apply convergence acceleration strategies based on performance analysis. “”” acceleration_result = { ‘applied_optimizations’: [], ‘expected_improvement’: 0.0 } # Check convergence rate convergence_rate = metrics.get(‘convergence_rate’, 0.0) if convergence_rate &lt; 0.05: # Slow convergence detected # Suggest inertia weight adjustment current_w = config.get(‘pso’, {}).get(‘algorithm_params’, {}).get(‘w’, 0.7) if current_w &gt; 0.5: suggested_w = max(0.4, current_w - 0.1) acceleration_result[‘applied_optimizations’].append({ ‘parameter’: ‘inertia_weight’, ‘current_value’: current_w, ‘suggested_value’: suggested_w, ‘justification’: ‘Reduce inertia for faster exploitation’ }) acceleration_result[‘expected_improvement’] += 15.0 # 15% improvement # Check diversity metrics diversity = metrics.get(‘swarm_diversity’, 1.0) if diversity &lt; 1e-8: # Very low diversity acceleration_result[‘applied_optimizations’].append({ ‘parameter’: ‘restart_mechanism’, ‘action’: ‘enable’, ‘fraction’: 0.2, ‘justification’: ‘Restart 20% of particles to escape local optimum’ }) acceleration_result[‘expected_improvement’] += 20.0 # 20% improvement return acceleration_result</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_optimization_workflow_user_guide.html">PSO Optimization Workflow User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_troubleshooting_maintenance_manual.html">PSO Troubleshooting and Maintenance Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_troubleshooting_maintenance_manual.html#pso-health-monitor-sh-regular-pso-system-health-monitoring-log-file-var-log-pso-health-log">pso_health_monitor.sh - Regular PSO system health monitoring LOG_FILE=”/var/log/pso_health.log”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_troubleshooting_maintenance_manual.html#emergency-recovery-sh-emergency-pso-system-recovery-echo-pso-emergency-recovery-procedure">emergency_recovery.sh - Emergency PSO system recovery echo “🚨 PSO EMERGENCY RECOVERY PROCEDURE”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_troubleshooting_maintenance_manual.html#recovery-restore-from-backup-backup-index-1">recovery.restore_from_backup(backup_index=1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pso_troubleshooting_maintenance_manual.html#recovery-restore-factory-defaults">recovery.restore_factory_defaults()</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quality_gate_independence_framework.html">Quality Gate Independence Framework ## Executive Summary The Quality Gate Independence Framework establishes resilient, parallel validation paths that operate independently to prevent cascade failures and ensure robust quality assessment for the double-inverted pendulum sliding mode control (DIP-SMC) project. This framework addresses the critical issue identified in GitHub Issue #9 where single component failures could prevent system validation. <strong>Core Principle:</strong> No single point of failure should block system quality assessment. ## 1. Framework Architecture ### 1.1 Independent Validation Paths The framework implements <strong>four parallel, independent validation paths</strong> that can operate and report results independently: ```python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quality_gate_independence_framework.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quality_gate_independence_framework.html#runnable-false-class-independentvalidationpaths-four-independent-validation-paths-preventing-cascade-failures-def-init-self-self-validation-paths-coverage-validation-coveragevalidationpath-mathematical-validation-mathematicalvalidationpath-performance-validation-performancevalidationpath-compliance-validation-compliancevalidationpath-def-execute-independent-validation-self-independentvalidationresults-execute-all-validation-paths-independently-with-failure-isolation-results-for-path-name-validator-in-self-validation-paths-items-try-each-path-executes-in-complete-isolation-results-path-name-validator-validate-independently-except-exception-as-e-failure-isolation-one-path-failure-doesn-t-affect-others-results-path-name-validationresult-status-failed-error-str-e-partial-results-validator-get-partial-results-return-independentvalidationresults-path-results-results-overall-status-self-calculate-composite-status-results-deployment-recommendation-self-make-deployment-decision-results">runnable: false class IndependentValidationPaths: “””Four independent validation paths preventing cascade failures.””” def <strong>init</strong>(self): self.validation_paths = { ‘coverage_validation’: CoverageValidationPath(), ‘mathematical_validation’: MathematicalValidationPath(), ‘performance_validation’: PerformanceValidationPath(), ‘compliance_validation’: ComplianceValidationPath() } def execute_independent_validation(self) -&gt; IndependentValidationResults: “””Execute all validation paths independently with failure isolation.””” results = {} for path_name, validator in self.validation_paths.items(): try: # Each path executes in complete isolation results[path_name] = validator.validate_independently() except Exception as e: # Failure isolation: one path failure doesn’t affect others results[path_name] = ValidationResult( status=’failed’, error=str(e), partial_results=validator.get_partial_results() ) return IndependentValidationResults( path_results=results, overall_status=self._calculate_composite_status(results), deployment_recommendation=self._make_deployment_decision(results) )</a></li>
<li class="toctree-l1"><a class="reference internal" href="../results_readme.html">Results &amp; Plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../safety_system_validation_protocols.html">Safety System Validation Protocols</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sitemap_cards.html">Visual Documentation Navigator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sitemap_interactive.html">Interactive Documentation Map</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sitemap_visual.html">Visual Documentation Map</a></li>
<li class="toctree-l1"><a class="reference internal" href="../streamlit_dashboard_guide.html">Streamlit Dashboard User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../symbols.html">Symbols &amp; Units</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_execution_guide.html">Test Execution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html">Test Execution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html#quick-development-testing-unit-tests-only">Quick development testing (unit tests only)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html#recommended-pre-commit-test-sequence">Recommended pre-commit test sequence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html#test-algorithm-convergence-properties">Test algorithm convergence properties</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html#quality-gate-sh-production-deployment-validation-set-e-echo-starting-quality-gate-validation-1-fast-unit-tests">quality_gate.sh - Production deployment validation set -e echo “🚀 Starting quality gate validation…” # 1. Fast unit tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_execution_guide.html#pre-commit-config-yaml">.pre-commit-config.yaml</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html">Test Infrastructure Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#run-only-unit-tests-fast-execution">Run only unit tests (fast execution)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#full-test-suite-with-coverage">Full test suite with coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#convergence-and-stability-analysis">Convergence and stability analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#all-tests-except-known-failing-concurrent-tests">All tests except known failing concurrent tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#automatic-configuration-in-tests-conftest-py">Automatic configuration in tests/conftest.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_documentation.html#quality-gate-sh-production-deployment-gate-echo-running-quality-gate-validation-1-unit-and-integration-tests">quality_gate.sh - Production deployment gate echo “Running quality gate validation…” # 1. Unit and integration tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_infrastructure_validation_report.html">Test Infrastructure Validation Report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../test_protocols.html">Test Protocols</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/index.html">Theoretical Foundations ```{toctree}</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html">Particle Swarm Optimization Algorithm Mathematical Foundations <strong>Authors:</strong> Documentation Expert Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#result-simulate-pso-particle-trajectory">result = simulate_pso_particle_trajectory(</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#initial-position-np-array-5-0-5-0">initial_position=np.array([5.0, 5.0]),</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#initial-velocity-np-array-0-0-0-0">initial_velocity=np.array([0.0, 0.0]),</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#personal-best-np-array-3-0-3-0">personal_best=np.array([3.0, 3.0]),</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#global-best-np-array-0-0-0-0">global_best=np.array([0.0, 0.0]),</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#w-0-7-c1-2-0-c2-2-0-n-iterations-50">w=0.7, c1=2.0, c2=2.0, n_iterations=50</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#id1">)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#expected-converged-true-convergence-rate-0-final-distance-1e-3">Expected: converged=True, convergence_rate &gt; 0, final_distance &lt; 1e-3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#result1-analyze-pso-stability-w-0-7-c1-2-0-c2-2-0">result1 = analyze_pso_stability(w=0.7, c1=2.0, c2=2.0)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#expected-stable-empirical-false-oscillatory-stable-theoretical-false">Expected: stable_empirical=False (oscillatory), stable_theoretical=False</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#id2"></a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#result2-analyze-pso-stability-w-0-5-c1-1-5-c2-1-5">result2 = analyze_pso_stability(w=0.5, c1=1.5, c2=1.5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#expected-stable-empirical-true-stable-theoretical-true">Expected: stable_empirical=True, stable_theoretical=True</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#convergence-rate-decreases-as-kappa-increases">- Convergence rate decreases as kappa increases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#well-conditioned-kappa-1-rate-0-1-0-2">- Well-conditioned (kappa=1): rate ~ 0.1-0.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/pso_algorithm_foundations.html#ill-conditioned-kappa-10000-rate-0-001-0-01">- Ill-conditioned (kappa=10000): rate ~ 0.001-0.01</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory_overview.html">Theory Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../use_cases.html">4. Use Cases &amp; Operating Modes</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Validation &amp; Verification</a><input aria-label="Toggle navigation of Validation &amp; Verification" checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="validation_workflow.html">Validation Workflow Guide &gt; <strong>Coming Soon:</strong> validation workflow documentation. ## Current Resources For validation guidance, see: - <strong><span class="xref myst">Validation Examples</span></strong> - Practical validation examples and patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="simulation_validation_guide.html">Simulation Validation Guide &gt; <strong>Note:</strong> Simulation validation is covered in multiple guides. ## Quick Links - <strong><span class="xref myst">Validation Examples</span></strong> - Practical validation patterns</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Simulation Result Validation Methodology <strong>Document Status:</strong> Phase 3.3 Completion - Monte Carlo and Statistical Testing Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="#controller-adapts-on-t0-t1">- Controller adapts on [t₀, t₁]</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performance-evaluated-on-t1-gap-t2">- Performance evaluated on [t₁+gap, t₂]</a></li>
<li class="toctree-l2"><a class="reference internal" href="#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#runnable-false-monte-carlo-cross-validation-statistical-tests">runnable: false # Monte Carlo + Cross-Validation + Statistical Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#if-diverge-investigate-why">If diverge → investigate why</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html">Validation Examples: Practical Implementation Guide <strong>Document Status:</strong> Phase 3.3 Completion - Executable Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#runnable-false">runnable: false “””</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#conservative-20-uncertainty">Conservative (±20% uncertainty)</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#pso-hyperparameter-selection-via-cross-validation-1-configuration-number-of-scenarios-100-pso-configurations-to-compare-4-1-small-explorative-pop-20-w-0-9-c1-2-0-c2-1-0-2-standard-pop-30-w-0-7-c1-1-5-c2-1-5-3-large-exploitative-pop-50-w-0-4-c1-1-0-c2-2-0-4-adaptive-pop-30-w-0-5-c1-1-8-c2-1-2-2-cross-validation-setup-method-monte-carlo-repetitions-50-train-test-split-80-20-3-running-cross-validation-this-may-take-several-minutes-4-results-cross-validation-scores-small-explorative-mean-cv-score-2-134-std-cv-score-0-312-median-cv-score-2-098-95-ci-2-223-2-045-standard-mean-cv-score-1-987-std-cv-score-0-267-median-cv-score-1-963-95-ci-2-062-1-912-large-exploitative-mean-cv-score-2-056-std-cv-score-0-298-median-cv-score-2-031-95-ci-2-138-1-974-adaptive-mean-cv-score-1-923-std-cv-score-0-245-median-cv-score-1-904-95-ci-1-992-1-854-5-statistical-comparison-pairwise-tests-after-multiple-comparison-correction-model-0-vs-model-3-model-3-is-significantly-better-p-0-0023-0-211-model-1-vs-model-3-model-3-is-significantly-better-p-0-0412-0-064-overall-ranking-1-adaptive-score-1-923-2-standard-score-1-987-3-large-exploitative-score-2-056-4-small-explorative-score-2-134-6-bias-variance-analysis-small-explorative-bias2-0-123456-variance-0-098234-high-bias-underfitting-consider-larger-population-standard-bias2-0-087654-variance-0-071234-good-balance-large-exploitative-bias2-0-091234-variance-0-089012-good-balance-adaptive-bias2-0-076543-variance-0-060123-good-balance-recommendation-recommended-pso-configuration-adaptive-parameters-population-size-30-inertia-weight-w-0-5-cognitive-coeff-c1-1-8-social-coeff-c2-1-2-mean-cv-score-1-923-this-configuration-showed-best-generalization-across-50-random-splits">======================================================================
PSO Hyperparameter Selection via Cross-Validation
====================================================================== 1. Configuration: Number of scenarios: 100 PSO configurations to compare: 4 1. Small-Explorative: pop=20, w=0.9, c1=2.0, c2=1.0 2. Standard: pop=30, w=0.7, c1=1.5, c2=1.5 3. Large-Exploitative: pop=50, w=0.4, c1=1.0, c2=2.0 4. Adaptive: pop=30, w=0.5, c1=1.8, c2=1.2 2. Cross-Validation Setup: Method: monte_carlo Repetitions: 50 Train-test split: 80%-20% 3. Running cross-validation… (This may take several minutes…) 4. Results:
———————————————————————- Cross-Validation Scores: Small-Explorative: Mean CV score: -2.134 Std CV score: 0.312 Median CV score: -2.098 95% CI: [-2.223, -2.045] Standard: Mean CV score: -1.987 Std CV score: 0.267 Median CV score: -1.963 95% CI: [-2.062, -1.912] Large-Exploitative: Mean CV score: -2.056 Std CV score: 0.298 Median CV score: -2.031 95% CI: [-2.138, -1.974] Adaptive: Mean CV score: -1.923 Std CV score: 0.245 Median CV score: -1.904 95% CI: [-1.992, -1.854] 5. Statistical Comparison: Pairwise Tests (after multiple comparison correction): model_0_vs_model_3: model_3 is significantly better (p=0.0023, Δ=0.211) model_1_vs_model_3: model_3 is significantly better (p=0.0412, Δ=0.064) Overall Ranking: 1. Adaptive (score: -1.923) 2. Standard (score: -1.987) 3. Large-Exploitative (score: -2.056) 4. Small-Explorative (score: -2.134) 6. Bias-Variance Analysis: Small-Explorative: Bias²: 0.123456 Variance: 0.098234 ⚠ High bias - underfitting (consider larger population) Standard: Bias²: 0.087654 Variance: 0.071234 ✓ Good balance Large-Exploitative: Bias²: 0.091234 Variance: 0.089012 ✓ Good balance Adaptive: Bias²: 0.076543 Variance: 0.060123 ✓ Good balance ======================================================================
RECOMMENDATION: ✓ RECOMMENDED PSO Configuration: Adaptive Parameters: - Population size: 30 - Inertia weight (w): 0.5 - Cognitive coeff (c1): 1.8 - Social coeff (c2): 1.2 Mean CV score: -1.923 This configuration showed best generalization across 50 random splits.</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#statistical-comparison-of-controller-performance-1-experimental-setup-controllers-classical-smc-super-twisting-smc-adaptive-smc-trials-per-controller-30-significance-level-0-05-metric-settling-time-seconds-2-collecting-performance-data-3-descriptive-statistics-classical-smc-mean-2-487-s-std-0-398-s-median-2-465-s-min-1-823-s-max-3-312-s-cv-16-0-super-twisting-smc-mean-1-789-s-std-0-246-s-median-1-776-s-min-1-312-s-max-2-345-s-cv-13-8-adaptive-smc-mean-2-098-s-std-0-489-s-median-2-073-s-min-1-234-s-max-3-145-s-cv-23-3-4-assumption-testing-normality-tests-shapiro-wilk-classical-smc-w-0-9821-p-0-8734-normal-super-twisting-smc-w-0-9765-p-0-7231-normal-adaptive-smc-w-0-9798-p-0-8123-normal-homogeneity-of-variance-levene-s-test-f-3-2145-p-0-0456-unequal-variances-will-use-welch-s-test-5-pairwise-comparisons-multiple-comparison-correction-bonferroni-corrected-significance-level-0-0167-classical-smc-vs-super-twisting-smc-welch-s-t-test-t-7-8234-p-0-0001-significant-p-0-0167-mann-whitney-u-test-non-parametric-u-123-0-p-0-0002-effect-size-cohen-s-d-d-2-013-large-mean-difference-0-698-s-95-ci-for-difference-0-512-0-884-s-classical-smc-vs-adaptive-smc-welch-s-t-test-t-3-4567-p-0-0012-significant-p-0-0167-mann-whitney-u-test-non-parametric-u-287-0-p-0-0018-effect-size-cohen-s-d-d-0-891-large-mean-difference-0-389-s-95-ci-for-difference-0-167-0-611-s-super-twisting-smc-vs-adaptive-smc-welch-s-t-test-t-2-8901-p-0-0056-significant-p-0-0167-mann-whitney-u-test-non-parametric-u-234-0-p-0-0071-effect-size-cohen-s-d-d-0-743-medium-mean-difference-0-309-s-95-ci-for-difference-0-521-0-097-s-6-omnibus-test-one-way-anova-f-26-7891-p-0-000001-significant-at-least-one-controller-differs-kruskal-wallis-test-non-parametric-h-25-3456-p-0-000003-7-power-analysis-classical-smc-vs-super-twisting-smc-effect-size-d-2-013-sample-size-n-30-power-0-998-99-8-adequate-power-80-classical-smc-vs-adaptive-smc-effect-size-d-0-891-sample-size-n-30-power-0-865-86-5-adequate-power-80-super-twisting-smc-vs-adaptive-smc-effect-size-d-0-743-sample-size-n-30-power-0-752-75-2-low-power-recommend-n-36-for-80-power-conclusions-1-statistical-significance-significant-differences-found-0-0167-classical-smc-vs-super-twisting-smc-classical-smc-vs-adaptive-smc-super-twisting-smc-vs-adaptive-smc-2-effect-sizes-classical-smc-vs-super-twisting-smc-cohen-s-d-2-013-large-classical-smc-vs-adaptive-smc-cohen-s-d-0-891-large-super-twisting-smc-vs-adaptive-smc-cohen-s-d-0-743-medium-3-practical-recommendations-performance-ranking-by-mean-settling-time-1-super-twisting-smc-1-789-s-2-adaptive-smc-2-098-s-3-classical-smc-2-487-s-recommended-super-twisting-smc-fastest-mean-settling-time-significantly-better-than-classical-smc-p-0-0001-d-2-013-significantly-better-than-adaptive-smc-p-0-0056-d-0-743">======================================================================
Statistical Comparison of Controller Performance
====================================================================== 1. Experimental Setup: Controllers: Classical SMC, Super-Twisting SMC, Adaptive SMC Trials per controller: 30 Significance level: 0.05 Metric: Settling time (seconds) 2. Collecting performance data… 3. Descriptive Statistics:
———————————————————————- Classical SMC: Mean: 2.487 s Std: 0.398 s Median: 2.465 s Min: 1.823 s Max: 3.312 s CV: 16.0% Super-Twisting SMC: Mean: 1.789 s Std: 0.246 s Median: 1.776 s Min: 1.312 s Max: 2.345 s CV: 13.8% Adaptive SMC: Mean: 2.098 s Std: 0.489 s Median: 2.073 s Min: 1.234 s Max: 3.145 s CV: 23.3% 4. Assumption Testing:
———————————————————————- Normality Tests (Shapiro-Wilk): Classical SMC : W=0.9821, p=0.8734 ✓ Normal Super-Twisting SMC : W=0.9765, p=0.7231 ✓ Normal Adaptive SMC : W=0.9798, p=0.8123 ✓ Normal Homogeneity of Variance (Levene’s test): F=3.2145, p=0.0456 ⚠ Unequal variances - will use Welch’s test 5. Pairwise Comparisons:
———————————————————————- Multiple comparison correction: Bonferroni Corrected significance level: α=0.0167 Classical SMC vs Super-Twisting SMC: Welch’s t-test: t=7.8234, p=0.0001 ✓ SIGNIFICANT (p &lt; 0.0167) Mann-Whitney U test (non-parametric): U=123.0, p=0.0002 Effect Size (Cohen’s d): d=2.013 (large) Mean difference: 0.698 s 95% CI for difference: [0.512, 0.884] s Classical SMC vs Adaptive SMC: Welch’s t-test: t=3.4567, p=0.0012 ✓ SIGNIFICANT (p &lt; 0.0167) Mann-Whitney U test (non-parametric): U=287.0, p=0.0018 Effect Size (Cohen’s d): d=0.891 (large) Mean difference: 0.389 s 95% CI for difference: [0.167, 0.611] s Super-Twisting SMC vs Adaptive SMC: Welch’s t-test: t=-2.8901, p=0.0056 ✓ SIGNIFICANT (p &lt; 0.0167) Mann-Whitney U test (non-parametric): U=234.0, p=0.0071 Effect Size (Cohen’s d): d=-0.743 (medium) Mean difference: -0.309 s 95% CI for difference: [-0.521, -0.097] s 6. Omnibus Test (One-Way ANOVA):
———————————————————————- F=26.7891, p=0.000001 ✓ SIGNIFICANT: At least one controller differs Kruskal-Wallis test (non-parametric): H=25.3456, p=0.000003 7. Power Analysis:
———————————————————————- Classical SMC vs Super-Twisting SMC: Effect size (d): 2.013 Sample size (n): 30 Power: 0.998 (99.8%) ✓ Adequate power (≥80%) Classical SMC vs Adaptive SMC: Effect size (d): 0.891 Sample size (n): 30 Power: 0.865 (86.5%) ✓ Adequate power (≥80%) Super-Twisting SMC vs Adaptive SMC: Effect size (d): 0.743 Sample size (n): 30 Power: 0.752 (75.2%) ⚠ Low power - recommend n=36 for 80% power ======================================================================
CONCLUSIONS:
====================================================================== 1. Statistical Significance: Significant differences found (α=0.0167): - Classical SMC vs Super-Twisting SMC - Classical SMC vs Adaptive SMC - Super-Twisting SMC vs Adaptive SMC 2. Effect Sizes: Classical SMC vs Super-Twisting SMC: Cohen’s d = 2.013 (large) Classical SMC vs Adaptive SMC: Cohen’s d = 0.891 (large) Super-Twisting SMC vs Adaptive SMC: Cohen’s d = -0.743 (medium) 3. Practical Recommendations: Performance ranking (by mean settling time): 1. Super-Twisting SMC : 1.789 s 2. Adaptive SMC : 2.098 s 3. Classical SMC : 2.487 s ✓ RECOMMENDED: Super-Twisting SMC - Fastest mean settling time - Significantly better than Classical SMC (p=0.0001, d=2.013) - Significantly better than Adaptive SMC (p=0.0056, d=0.743)</a></li>
<li class="toctree-l2"><a class="reference internal" href="validation_examples.html#uncertainty-quantification-for-settling-time-1-safety-requirement-settling-time-must-be-3-0s-with-99-confidence-2-collecting-experimental-data-number-of-test-runs-200-3-descriptive-statistics-mean-2-123-s-std-0-687-s-median-1-983-s-min-0-987-s-max-4-823-s-range-3-836-s-percentiles-5-1-234-s-25-1-653-s-50-1-983-s-75-2-456-s-95-3-567-s-99-4-234-s-4-bootstrap-confidence-intervals-bootstrap-iterations-10000-confidence-level-95-mean-settling-time-point-estimate-2-123-s-95-ci-2-026-2-223-s-ci-width-0-197-s-median-settling-time-point-estimate-1-983-s-95-ci-1-876-2-087-s-95th-percentile-point-estimate-3-567-s-95-ci-3-289-3-891-s-5-distribution-fitting-normal-k-s-statistic-0-0867-p-value-0-0234-aic-412-34-reject-poor-fit-lognormal-k-s-statistic-0-0421-p-value-0-6523-aic-387-12-cannot-reject-good-fit-gamma-k-s-statistic-0-0534-p-value-0-3421-aic-391-67-cannot-reject-good-fit-exponential-k-s-statistic-0-1234-p-value-0-0001-aic-445-89-reject-poor-fit-best-fit-lowest-aic-lognormal-aic-387-12-6-risk-analysis-value-at-risk-var-var-1-3-892-s-top-1-worst-cases-var-5-3-567-s-top-5-worst-cases-var-10-3-234-s-top-10-worst-cases-conditional-value-at-risk-cvar-expected-shortfall-cvar-1-4-123-s-avg-of-worst-1-cvar-5-3-789-s-avg-of-worst-5-cvar-10-3-456-s-avg-of-worst-10-7-safety-validation-empirical-analysis-samples-exceeding-3-0s-18-200-empirical-p-t-3-0s-0-0900-9-00-95-ci-for-p-t-3-0s-0-0523-0-1342-fitted-lognormal-distribution-p-t-3-0s-0-0823-8-23-p-t-3-0s-0-9177-91-77-fails-safety-requirement-91-8-99-0-to-meet-99-confidence-target-99-percentile-4-521-s-required-4-521s-3-0s-need-to-improve-99-percentile-by-1-521s-8-extreme-value-analysis-block-maxima-method-block-size-20-number-of-blocks-10-gev-parameters-0-234-3-876-0-456-return-levels-10-run-worst-case-4-876-s-50-run-worst-case-5-432-s-100-run-worst-case-5-687-s-uncertainty-quantification-summary-1-point-estimates-mean-2-123-s-95th-percentile-3-567-s-99th-percentile-4-234-s-2-uncertainty-95-ci-mean-2-026-2-223-s-95th-percentile-3-289-3-891-s-3-distributional-model-best-fit-lognormal-goodness-of-fit-p-value-0-6523-4-safety-assessment-threshold-3-0s-required-confidence-99-fails-only-91-8-of-scenarios-meet-requirement-5-recommendations-further-controller-improvement-needed-option-1-tune-controller-for-better-worst-case-performance-option-2-increase-safety-threshold-option-3-accept-lower-confidence-level-if-acceptable">======================================================================
Uncertainty Quantification for Settling Time
====================================================================== 1. Safety Requirement: Settling time must be &lt; 3.0s with 99% confidence 2. Collecting experimental data… Number of test runs: 200 3. Descriptive Statistics:
———————————————————————- Mean: 2.123 s Std: 0.687 s Median: 1.983 s Min: 0.987 s Max: 4.823 s Range: 3.836 s Percentiles: 5%: 1.234 s 25%: 1.653 s 50%: 1.983 s 75%: 2.456 s 95%: 3.567 s 99%: 4.234 s 4. Bootstrap Confidence Intervals:
———————————————————————- Bootstrap iterations: 10000 Confidence level: 95% Mean settling time: Point estimate: 2.123 s 95% CI: [2.026, 2.223] s CI width: 0.197 s Median settling time: Point estimate: 1.983 s 95% CI: [1.876, 2.087] s 95th percentile: Point estimate: 3.567 s 95% CI: [3.289, 3.891] s 5. Distribution Fitting:
———————————————————————- Normal: K-S statistic: 0.0867 p-value: 0.0234 AIC: 412.34 ✗ Reject (poor fit) Lognormal: K-S statistic: 0.0421 p-value: 0.6523 AIC: 387.12 ✓ Cannot reject (good fit) Gamma: K-S statistic: 0.0534 p-value: 0.3421 AIC: 391.67 ✓ Cannot reject (good fit) Exponential: K-S statistic: 0.1234 p-value: 0.0001 AIC: 445.89 ✗ Reject (poor fit) Best fit (lowest AIC): Lognormal AIC = 387.12 6. Risk Analysis:
———————————————————————- Value at Risk (VaR): VaR(1%): 3.892 s (top 1% worst cases) VaR(5%): 3.567 s (top 5% worst cases) VaR(10%): 3.234 s (top 10% worst cases) Conditional Value at Risk (CVaR / Expected Shortfall): CVaR(1%): 4.123 s (avg of worst 1%) CVaR(5%): 3.789 s (avg of worst 5%) CVaR(10%): 3.456 s (avg of worst 10%) 7. Safety Validation:
———————————————————————- Empirical Analysis: Samples exceeding 3.0s: 18/200 Empirical P(T &gt; 3.0s) = 0.0900 (9.00%) 95% CI for P(T &gt; 3.0s): [0.0523, 0.1342] Fitted Lognormal Distribution: P(T &gt; 3.0s) = 0.0823 (8.23%) P(T ≤ 3.0s) = 0.9177 (91.77%) ✗ FAILS safety requirement (91.8% &lt; 99.0%) To meet 99% confidence: Target: 99% percentile = 4.521 s Required: 4.521s &lt; 3.0s ⚠ Need to improve 99% percentile by 1.521s 8. Extreme Value Analysis:
———————————————————————- Block Maxima Method: Block size: 20 Number of blocks: 10 GEV parameters: ξ=-0.234, μ=3.876, σ=0.456 Return Levels: 10-run worst-case: 4.876 s 50-run worst-case: 5.432 s 100-run worst-case: 5.687 s ======================================================================
UNCERTAINTY QUANTIFICATION SUMMARY:
====================================================================== 1. Point Estimates: Mean: 2.123 s 95th percentile: 3.567 s 99th percentile: 4.234 s 2. Uncertainty (95% CI): Mean: [2.026, 2.223] s 95th percentile: [3.289, 3.891] s 3. Distributional Model: Best fit: Lognormal Goodness-of-fit p-value: 0.6523 4. Safety Assessment: Threshold: 3.0s Required confidence: 99% ✗ FAILS: Only 91.8% of scenarios meet requirement 5. Recommendations: ✗ Further controller improvement needed □ Option 1: Tune controller for better worst-case performance □ Option 2: Increase safety threshold □ Option 3: Accept lower confidence level (if acceptable)</a></li>
<li class="toctree-l2"><a class="reference internal" href="api_reference.html">Validation API Reference &gt; <strong>Coming Soon:</strong> validation API documentation. ## Current Resources For validation APIs, see: - <strong><span class="xref myst">Analysis Validation</span></strong> - Validation metrics API</a></li>
<li class="toctree-l2"><a class="reference internal" href="statistical_reference_tables.html">Statistical Reference Tables &gt; <strong>Coming Soon:</strong> statistical reference tables for validation. ## Current Resources For statistical validation, see: - <strong><span class="xref myst">Statistical Tests</span></strong> - Statistical test implementations</a></li>
<li class="toctree-l2"><a class="reference internal" href="phase_3_3_completion_report.html">Phase 3.3 Completion Report: Simulation Result Validation Documentation <strong>Completion Date:</strong> 2025-10-07</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning_guide.html">Documentation Versioning Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../workflows/index.html">Workflows &amp; Integration Guides</a><input aria-label="Toggle navigation of Workflows &amp; Integration Guides" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html">Complete Integration Workflow Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#test-each-controller-individually">Test each controller individually</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#use-pre-optimized-gains-for-immediate-results">Use pre-optimized gains for immediate results</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#launch-interactive-web-interface">Launch interactive web interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#select-controller-adjust-parameters-run-simulations">Select controller, adjust parameters, run simulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#optimize-classical-smc-gains">Optimize classical SMC gains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#optimize-adaptive-smc-with-uncertainty">Optimize adaptive SMC with uncertainty</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#optimize-sta-smc-for-finite-time-performance">Optimize STA SMC for finite-time performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#optimize-hybrid-smc-most-sophisticated">Optimize hybrid SMC (most sophisticated)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#optimize-all-controllers-in-sequence">Optimize all controllers in sequence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#example-metadata">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#runnable-false-scripts-custom-batch-optimization-py">runnable: false # scripts/custom_batch_optimization.py</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#multi-objective-optimization-for-competing-requirements">Multi-objective optimization for competing requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#id1">example-metadata:</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#runnable-false-adaptive-pso-with-time-varying-parameters">runnable: false # Adaptive PSO with time-varying parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#run-hil-simulation">Run HIL simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#real-time-monitoring-setup">Real-time monitoring setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#distributed-control-system">Distributed control system</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#adaptive-controller-selection-based-on-performance">Adaptive controller selection based on performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#diagnose-controller-performance-problems">Diagnose controller performance problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#debug-pso-optimization-problems">Debug PSO optimization problems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/complete_integration_guide.html#continuous-system-health-monitoring">Continuous system health monitoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/pytest_testing_workflow.html">Quick Start Guide for Running Tests <strong>Document Version</strong>: 1.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../workflows/pytest_testing_workflow.html#run-all-tests-basic-command">1. Run all tests (basic command)</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/validation/simulation_result_validation.md.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section class="tex2jax_ignore mathjax_ignore" id="simulation-result-validation-methodology-document-status-phase-3-3-completion-monte-carlo-and-statistical-testing-framework">
<h1>Simulation Result Validation Methodology <strong>Document Status:</strong> Phase 3.3 Completion - Monte Carlo and Statistical Testing Framework<a class="headerlink" href="#simulation-result-validation-methodology-document-status-phase-3-3-completion-monte-carlo-and-statistical-testing-framework" title="Link to this heading">¶</a></h1>
<p><strong>Last Updated:</strong> 2025-10-07
<strong>Part of:</strong> MCP-Orchestrated Documentation Enhancement Workflow ## Executive Summary This document provides validation methodologies for control system simulation results, covering Monte Carlo analysis, cross-validation protocols, statistical testing frameworks, and benchmark comparisons. These methods ensure scientific rigor and reproducibility in controller performance evaluation. <strong>Key Validation features:</strong></p>
<ul class="simple">
<li><p><strong>Monte Carlo Simulation:</strong> LHS, Sobol, Halton sampling with convergence analysis</p></li>
<li><p><strong>Cross-Validation:</strong> K-fold, time series, Monte Carlo CV for generalization assessment</p></li>
<li><p><strong>Statistical Testing:</strong> Normality, stationarity, hypothesis testing with power analysis</p></li>
<li><p><strong>Benchmark Comparison:</strong> Multi-method statistical comparison with effect size analysis <strong>Implementation:</strong> <code class="docutils literal notranslate"><span class="pre">src/analysis/validation/</span></code> (4 modules, 3,777 total lines)</p></li>
</ul>
<hr class="docutils" />
<section id="table-of-contents-1-monte-carlo-simulation-methodology">
<h2>Table of Contents 1. <a class="reference internal" href="#1-monte-carlo-simulation-methodology"><span class="xref myst">Monte Carlo Simulation Methodology</span></a><a class="headerlink" href="#table-of-contents-1-monte-carlo-simulation-methodology" title="Link to this heading">¶</a></h2>
<ol class="arabic simple" start="2">
<li><p><a class="reference internal" href="#2-cross-validation-protocols"><span class="xref myst">Cross-Validation Protocols</span></a></p></li>
<li><p><a class="reference internal" href="#3-statistical-testing-framework"><span class="xref myst">Statistical Testing Framework</span></a></p></li>
<li><p><a class="reference internal" href="#4-benchmark-comparison-methodology"><span class="xref myst">Benchmark Comparison Methodology</span></a></p></li>
<li><p><a class="reference internal" href="#5-uncertainty-quantification"><span class="xref myst">Uncertainty Quantification</span></a></p></li>
<li><p><a class="reference internal" href="#6-integration-with-control-systems"><span class="xref myst">Integration with Control Systems</span></a></p></li>
<li><p><a class="reference internal" href="#7-best-practices-and-pitfalls"><span class="xref myst">Best Practices and Pitfalls</span></a></p></li>
</ol>
</section>
<hr class="docutils" />
<section id="monte-carlo-simulation-methodology-1-1-overview-monte-carlo-simulation-propagates-uncertainty-through-control-system-models-to-quantify-performance-variability-and-validate-stability-claims-under-realistic-conditions-implementation-src-analysis-validation-monte-carlo-py-1-007-lines-1-2-sampling-strategies-1-2-1-random-sampling-baseline-description-standard-pseudorandom-sampling-from-specified-distributions-use-cases">
<h2>1. Monte Carlo Simulation Methodology ### 1.1 Overview Monte Carlo simulation propagates uncertainty through control system models to quantify performance variability and validate stability claims under realistic conditions. <strong>Implementation:</strong> <code class="docutils literal notranslate"><span class="pre">src/analysis/validation/monte_carlo.py</span></code> (1,007 lines) ### 1.2 Sampling Strategies #### 1.2.1 Random Sampling (Baseline) <strong>Description:</strong> Standard pseudorandom sampling from specified distributions. <strong>Use Cases:</strong><a class="headerlink" href="#monte-carlo-simulation-methodology-1-1-overview-monte-carlo-simulation-propagates-uncertainty-through-control-system-models-to-quantify-performance-variability-and-validate-stability-claims-under-realistic-conditions-implementation-src-analysis-validation-monte-carlo-py-1-007-lines-1-2-sampling-strategies-1-2-1-random-sampling-baseline-description-standard-pseudorandom-sampling-from-specified-distributions-use-cases" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Quick uncertainty propagation</p></li>
<li><p>Initial sensitivity screening</p></li>
<li><p>Non-critical applications <strong>Mathematical Foundation:</strong> For parameter θ with distribution F(θ), generate samples: ```
θᵢ ~ F(θ), i = 1, …, N</p></li>
</ul>
<div class="highlight-**Convergence notranslate"><div class="highlight"><pre><span></span>```python

from src.analysis.validation.monte_carlo import MonteCarloConfig, MonteCarloAnalyzer config = MonteCarloConfig( n_samples=1000, sampling_method=&quot;random&quot;, random_seed=42
)
analyzer = MonteCarloAnalyzer(config)
``` **Advantages:**
- Simple to implement
- Unbiased estimator
- Parallelizable **Limitations:**
- Slow convergence
- Poor space coverage
- High variance for same N

---

### 1.2.2 Latin Hypercube Sampling (LHS) **Description:** Stratified sampling ensuring uniform coverage of parameter space. **Use Cases:**
- **Recommended for most control applications**
- Parameter sensitivity analysis
- Design space exploration
- Limited computational budget **Mathematical Foundation:** Partition each parameter dimension into N intervals of equal probability. Sample one point from each interval with random permutation across dimensions: ```
For parameter θⱼ ∈ [a, b]:
Intervals: [a + (i-1)(b-a)/N, a + i(b-a)/N], i = 1,...,N
Sample: θⱼ,ᵢ ~ Uniform(interval_i)
Apply random permutation π across dimensions
``` **Convergence Rate:** O(N^(-1)) - faster than random sampling **Implementation Example:**

```python
config = MonteCarloConfig( n_samples=500, # Can use fewer samples than random sampling_method=&quot;latin_hypercube&quot;, random_seed=42
)
analyzer = MonteCarloAnalyzer(config)
``` **Advantages:**

- Better space coverage than random sampling
- Faster convergence
- Efficient for sensitivity analysis
- Works well with 100-1000 samples **When to Use:**
- Computational budget limited (expensive simulations)
- Need uniform coverage of uncertainty space
- Sensitivity analysis required
- 5-20 uncertain parameters

---

### 1.2.3 Sobol Sequence (Quasi-Monte Carlo) **Description:** Low-discrepancy sequence for deterministic space-filling sampling. **Use Cases:**

- High-dimensional parameter spaces (&gt;10 dimensions)
- Global sensitivity analysis (Sobol indices)
- Expensive simulations requiring maximum efficiency
- Publication-quality uncertainty quantification **Mathematical Foundation:** Sobol sequences are quasi-random sequences with low discrepancy D(N): ```
D(N) = O((log N)^d / N) where d = dimension
``` Much better than random sampling: D(N) = O(N^(-1/2)) **Convergence Rate:** O(N^(-1) log^d N) - best for high dimensions **Implementation Example:**
```python

config = MonteCarloConfig( n_samples=1024, # Typically use powers of 2 sampling_method=&quot;sobol&quot;, sensitivity_analysis=True, sensitivity_method=&quot;sobol&quot;
)
analyzer = MonteCarloAnalyzer(config)
``` **Advantages:**
- Deterministic and reproducible
- space-filling properties
- Best for high-dimensional problems
- Enables Sobol sensitivity indices **Limitations:**
- Implementation complexity
- Requires specific sample sizes (powers of 2)
- May not work well with adaptive sampling **When to Use:**
- &gt;10 uncertain parameters
- Need global sensitivity analysis
- Computational budget allows 1000+ samples
- Deterministic reproducibility required

---

#### 1.2.4 Halton Sequence **Description:** Another quasi-random low-discrepancy sequence based on prime numbers. **Use Cases:**
- Alternative to Sobol for moderate dimensions (5-15)
- Sequential simulation (easy to extend sample size)
- Real-time uncertainty propagation **Mathematical Foundation:** Halton sequence uses van der Corput sequences with different prime bases: ```
For dimension j with prime pⱼ:
xⱼ,ᵢ = vdC(i, pⱼ) where vdC(n, p) = Σₖ aₖp^(-k-1)
and n = Σₖ aₖp^k (base-p expansion)
``` **Convergence Rate:** O(N^(-1) log N) - slightly worse than Sobol **Implementation Example:**

```python
config = MonteCarloConfig( n_samples=1000, sampling_method=&quot;halton&quot;
)
analyzer = MonteCarloAnalyzer(config)
``` **Advantages:**

- Easy to extend sample size incrementally
- Simpler implementation than Sobol
- Good for sequential analysis **Limitations:**
- Correlation issues in higher dimensions
- Slightly worse convergence than Sobol **When to Use:**
- Sequential/adaptive sampling needed
- 5-15 dimensions
- Simpler alternative to Sobol

---

### 1.3 Variance Reduction Techniques #### 1.3.1 Antithetic Variates **Description:** Generate paired samples with negative correlation to reduce variance. **Mathematical Principle:** For estimator θ̂ = (Y₁ + Y₂)/2 where Y₁, Y₂ are antithetic: ```

Var(θ̂) = [Var(Y₁) + Var(Y₂) + 2Cov(Y₁, Y₂)] / 4 If Cov(Y₁, Y₂) &lt; 0, then Var(θ̂) &lt; Var(Ȳ)
``` **Implementation:**
```python

config = MonteCarloConfig( n_samples=1000, antithetic_variates=True
)
``` **Example:** For uniform θ ~ U(0,1), use pairs (θ, 1-θ) **Variance Reduction:** Typically 50-90% for monotonic functions

---

#### 1.3.2 Control Variates **Description:** Use known expectation of correlated variable to reduce variance. **Mathematical Principle:** ```
θ̂_CV = θ̂ + c(Ẑ - E[Z]) where Z is control variate with known E[Z]
``` Optimal coefficient:

</pre></div>
</div>
<p>c* = -Cov(θ̂, Ẑ) / Var(Ẑ)</p>
<div class="highlight-Variance notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>Var(θ̂_CV) = Var(θ̂)(1 - ρ²) where ρ = Corr(θ̂, Ẑ)</p>
<div class="highlight-**Use notranslate"><div class="highlight"><pre><span></span>
- Linear approximation available
- Similar problem solved analytically
- High correlation with known quantity

---

### 1.4 Convergence Criteria #### 1.4.1 Running Mean Stability **Criterion:** Stop when running mean stabilizes within tolerance. **Mathematical Test:** ```

|μ̂ₙ - μ̂ₙ₋ₖ| / |μ̂ₙ| &lt; ε where:
μ̂ₙ = (1/n)Σᵢ₌₁ⁿ Xᵢ
k = convergence_window
ε = convergence_tolerance
``` **Implementation:**
```python

config = MonteCarloConfig( convergence_tolerance=0.01, # 1% relative change convergence_window=50, min_samples=100, max_samples=10000
)
``` **Interpretation:**
- Converged: Mean stable to within 1% over last 50 samples
- Not converged: Increase max_samples

---

#### 1.4.2 Confidence Interval Width **Criterion:** Stop when confidence interval is sufficiently narrow. **Mathematical Test:** ```
CI_width = 2 × t_{α/2,n-1} × (s/√n) &lt; δ where:
t_{α/2,n-1} = t-distribution critical value
s = sample standard deviation
δ = desired precision
``` **Target Precision:**

- Safety-critical: δ &lt; 0.05 × |μ̂| (5% of mean)
- Performance analysis: δ &lt; 0.10 × |μ̂| (10% of mean)
- Initial screening: δ &lt; 0.20 × |μ̂| (20% of mean)

---

### 1.5 Bootstrap Analysis **Description:** Resampling method for estimating sampling distribution and confidence intervals without distributional assumptions. **Mathematical Foundation:** From sample {x₁, ..., xₙ}, generate B bootstrap samples: ```

X*ᵇ = {x*₁, ..., x*ₙ} sampled with replacement Compute statistic: θ̂*ᵇ = g(X*ᵇ) Bootstrap CI (percentile method):
[θ̂*_{α/2}, θ̂*_{1-α/2}]
``` **Implementation:**
```python

config = MonteCarloConfig( bootstrap_samples=1000, bootstrap_confidence_level=0.95
) result = analyzer.validate(data)
bootstrap_ci = result.data[&#39;bootstrap_analysis&#39;][&#39;mean_confidence_interval&#39;]
``` **Use Cases:**
- Non-normal distributions
- Small sample sizes
- Complex statistics (e.g., ratio of means)
- Unknown analytical CI **Bootstrap CI Types:**
1. **Percentile:** [θ̂*_{α/2}, θ̂*_{1-α/2}]
2. **Basic:** [2θ̂ - θ̂*_{1-α/2}, 2θ̂ - θ̂*_{α/2}]
3. **BCa (Bias-Corrected Accelerated):** Adjusts for bias and skewness

---

### 1.6 Sensitivity Analysis #### 1.6.1 One-at-a-Time (OAT) Sensitivity **Description:** Vary each parameter individually while holding others constant. **Sensitivity Measure:** ```
S_i = ∂f/∂θᵢ ≈ [f(θ + Δθᵢ) - f(θ)] / Δθᵢ
``` **Implementation:**

```python
config = MonteCarloConfig( sensitivity_analysis=True, sensitivity_method=&quot;simple&quot; # One-at-a-time
)
``` **Advantages:**

- Intuitive interpretation
- Low computational cost
- Good for screening **Limitations:**
- Ignores parameter interactions
- Local (not global) sensitivity
- Misses nonlinear effects **When to Use:**
- Initial parameter screening
- Linear/weakly nonlinear systems
- Limited computational budget

---

#### 1.6.2 Sobol Sensitivity Indices **Description:** Variance-based global sensitivity analysis decomposing output variance into parameter contributions. **Mathematical Foundation:** Total variance decomposition: ```

Var(Y) = Σᵢ Vᵢ + Σᵢ&lt;ⱼ Vᵢⱼ + ... + V₁₂...ₙ where:
Vᵢ = Var[E(Y|Xᵢ)] = variance due to Xᵢ alone
Vᵢⱼ = Var[E(Y|Xᵢ,Xⱼ)] - Vᵢ - Vⱼ = interaction effect
``` **Sobol Indices:** First-order (main effect):
</pre></div>
</div>
<p>Sᵢ = Vᵢ / Var(Y)</p>
<div class="highlight-Total-order notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>STᵢ = [Var(Y) - Var[E(Y|X₋ᵢ)]] / Var(Y)</p>
<div class="highlight-**Interpretation:** notranslate"><div class="highlight"><pre><span></span>- Sᵢ: Fraction of variance explained by Xᵢ alone
- STᵢ - Sᵢ: Interaction effects involving Xᵢ
- Σᵢ Sᵢ ≠ 1 if interactions present **Use Cases:**
- Nonlinear systems
- Parameter interactions expected
- Need global sensitivity
- &gt;5 parameters to screen **Computational Cost:**
- Basic Sobol: O(N × (d+2)) simulations
- Second-order: O(N × d²) simulations **When to Use:**
- Need rigorous global sensitivity
- Can afford 1000+ simulations
- Parameter ranking for optimization
- Publication-quality analysis

---

### 1.7 Distribution Fitting **Description:** Identify best-fit probability distribution for simulation output. **Supported Distributions:**
1. **Normal:** Gaussian distribution
2. **Lognormal:** Positive skewed data
3. **Exponential:** Failure times, waiting times
4. **Gamma:** Positive continuous data
5. **Beta:** Bounded data [0,1] **Goodness-of-Fit Tests:** **Kolmogorov-Smirnov (K-S):**
</pre></div>
</div>
<p>D = sup_x |F̂(x) - F₀(x)| where F̂ = empirical CDF, F₀ = hypothesized CDF</p>
<div class="highlight-**Anderson-Darling:** notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>A² = -n - (1/n)Σᵢ (2i-1)[ln F₀(Xᵢ) + ln(1-F₀(Xₙ₊₁₋ᵢ))]</p>
<div class="highlight-More notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>AIC = 2k - 2ln(L̂) where k = number of parameters, L̂ = likelihood</p>
<div class="highlight-**Best notranslate"><div class="highlight"><pre><span></span>```python

result = analyzer.validate(data)
dist_analysis = result.data[&#39;distribution_analysis&#39;] best_fit = dist_analysis[&#39;best_fit&#39;] # e.g., &quot;lognormal&quot;
ks_stat = dist_analysis[&#39;distribution_fits&#39;][best_fit][&#39;ks_statistic&#39;]
p_value = dist_analysis[&#39;distribution_fits&#39;][best_fit][&#39;p_value&#39;]
``` **Interpretation:**
- p_value &gt; 0.05: Cannot reject hypothesized distribution
- AIC comparison: Lower is better (difference &gt;10 is strong evidence)

---

## 2. Cross-Validation Protocols ### 2.1 Overview Cross-validation assesses generalization performance and prevents overfitting in controller tuning and model selection. **Implementation:** `src/analysis/validation/cross_validation.py` (920 lines) **Key Question:** Will this controller perform well on unseen scenarios?

---

### 2.2 K-Fold Cross-Validation **Description:** Split data into K equal folds; train on K-1, test on 1, repeat K times. **Mathematical Framework:** ```
For k = 1, ..., K: Train on D \ Dₖ Test on Dₖ Compute score Sₖ CV score = (1/K) Σₖ Sₖ
CV std = √[(1/K) Σₖ (Sₖ - S̄)²]
``` **Implementation:**

```python
from src.analysis.validation.cross_validation import CrossValidationConfig, CrossValidator config = CrossValidationConfig( cv_method=&quot;k_fold&quot;, n_splits=5, shuffle=True, random_state=42
)
validator = CrossValidator(config)
``` **Choosing K:**

- **K=5:** Standard choice, good bias-variance tradeoff
- **K=10:** More stable, higher variance
- **K=N (LOO):** Unbiased but high variance, expensive **Bias-Variance Tradeoff:**
- **Small K:** Low computational cost, high bias (small training sets)
- **Large K:** Low bias, high variance (similar training sets) **When to Use:**
- General-purpose validation
- i.i.d. data (not time series)
- Sufficient data (N &gt; 50)
- Hyperparameter tuning **Advantages:**
- Simple and interpretable
- Efficient (all data used for training and testing)
- Low variance estimates **Limitations:**
- Assumes i.i.d. data
- Not suitable for time series
- May leak temporal information

---

### 2.3 Time Series Cross-Validation **Description:** Respects temporal order; train on past, test on future. **Mathematical Framework:** ```

Split 1: Train [1, n₁] Test [n₁+1, n₁+t]
Split 2: Train [1, n₂] Test [n₂+1, n₂+t]
...
Split K: Train [1, nₖ] Test [nₖ+1, nₖ+t] where n₁ &lt; n₂ &lt; ... &lt; nₖ
``` **Implementation:**
```python

config = CrossValidationConfig( cv_method=&quot;time_series&quot;, n_splits=5, max_train_size=None, # Use all past data test_size=None, # Auto-determined gap=0 # No gap between train/test
)
validator = CrossValidator(config)
``` **Parameters:**
- **gap:** Forecast horizon (e.g., gap=10 for 10-step-ahead prediction)
- **max_train_size:** Limit training window (e.g., sliding window)
- **test_size:** Fixed test set size **Use Cases for Control Systems:**
1. **Controller Performance Prediction:** - Train on historical trajectories - Test on future scenarios - Gap = control horizon 2. **Adaptive Controller Validation:** - Sliding window training - Evaluate online adaptation 3. **Disturbance Rejection:** - Train on nominal conditions - Test on perturbed scenarios **When to Use:**
- Time series data (trajectories, adaptive control)
- Temporal dependencies important
- Evaluate forecasting ability
- Controller adaptation analysis **Advantages:**
- Respects temporal order
- Realistic evaluation
- Prevents temporal leakage **Limitations:**
- Fewer training samples than K-fold
- High variance if limited data
- Correlated test sets

---

### 2.4 Stratified K-Fold **Description:** Maintain class/value distribution in each fold. **Use Cases:**
- Imbalanced scenarios (e.g., rare fault conditions)
- Discrete operating regimes
- Classification tasks **Implementation:**
```python

config = CrossValidationConfig( cv_method=&quot;stratified&quot;, n_splits=5
)
``` **When to Use:**
- Imbalanced operating conditions
- Rare events (faults, constraints)
- Ensure representative test sets

---

### 2.5 Monte Carlo Cross-Validation **Description:** Random train-test splits repeated many times. **Mathematical Framework:** ```
For iteration i = 1, ..., N: Random split: 80% train, 20% test Train model and compute score Sᵢ CV score = mean(S)
CV std = std(S)
``` **Implementation:**

```python
config = CrossValidationConfig( cv_method=&quot;monte_carlo&quot;, n_repetitions=100, test_ratio=0.2, random_state=42
)
``` **Advantages:**

- Flexible train/test ratio
- More iterations than K-fold
- Lower variance estimates **When to Use:**
- Large datasets
- Need precise CV estimates
- Computational budget allows

---

### 2.6 Nested Cross-Validation **Description:** Outer CV for performance estimation, inner CV for hyperparameter tuning. **Purpose:** Obtain unbiased performance estimate when hyperparameters are tuned. **Mathematical Framework:** ```

Outer CV (performance estimation): For k = 1, ..., K_outer: Train_outer = D \ Dₖ Inner CV (hyperparameter selection): For j = 1, ..., K_inner: Train_inner ⊂ Train_outer Tune hyperparameters Select best hyperparameters Evaluate on Dₖ
``` **Implementation:**
```python

config = CrossValidationConfig( cv_method=&quot;k_fold&quot;, n_splits=5, # Outer CV enable_nested_cv=True, inner_cv_splits=3 # Inner CV
)
``` **Computational Cost:**
- K_outer × K_inner × n_hyperparameter_configs evaluations
- Example: 5 × 3 × 10 = 150 model trains **When to Use:**
- Hyperparameter tuning required
- Need unbiased performance estimate
- Avoid optimistic bias **Warning:** High computational cost - use for final validation only.

---

### 2.7 Bias-Variance Decomposition **Description:** Decompose prediction error into bias², variance, and irreducible noise. **Mathematical Foundation:** Expected prediction error: ```
E[(y - f̂(x))²] = Bias²(f̂) + Var(f̂) + σ² where:
Bias(f̂) = E[f̂(x)] - f(x)
Var(f̂) = E[(f̂(x) - E[f̂(x)])²]
σ² = irreducible noise
``` **Implementation:**

```python
result = validator.validate( data, models=[model], prediction_function=predict_fn
)
bv_analysis = result.data[&#39;bias_variance_analysis&#39;] bias_squared = bv_analysis[model_name][&#39;bias_squared&#39;]
variance = bv_analysis[model_name][&#39;variance&#39;]
``` **Interpretation:** **High Bias (Underfitting):**

- Model too simple
- Missing important features
- **Solution:** Increase model complexity **High Variance (Overfitting):**
- Model too complex
- Overfitting training data
- **Solution:** Regularization, more data, simpler model **Bias-Variance Tradeoff:**
</pre></div>
</div>
<p>Total Error = Bias² + Variance + Noise Optimal complexity minimizes total error</p>
<div class="highlight-**Control notranslate"><div class="highlight"><pre><span></span>
- **Bias:** Systematic controller error (e.g., tracking offset)
- **Variance:** Performance variability across scenarios
- **Target:** Low bias AND low variance

---

### 2.8 Learning Curves **Description:** Plot performance vs. training set size to diagnose learning behavior. **Mathematical Framework:** ```

For n = [n₁, n₂, ..., nₖ]: Train on first n samples Evaluate on validation set Record train and test scores
``` **Interpretation:** **Convergence Patterns:** 1. **High Bias (Underfitting):** ``` Train error: High, plateaus quickly Test error: High, parallel to train error Gap: Small ``` **Diagnosis:** Model capacity insufficient **Solution:** More complex model, more features 2. **High Variance (Overfitting):** ``` Train error: Low, continues decreasing Test error: High, large gap from train Gap: Large ``` **Diagnosis:** Model memorizing training data **Solution:** More data, regularization, simpler model 3. **Good Fit:** ``` Train error: Low, stable Test error: Low, converging to train error Gap: Small and decreasing ``` **Diagnosis:** Optimal model complexity **Action:** Production ready **Implementation:**
```python

result = validator.validate(data, models=[model])
lc = result.data[&#39;learning_curve_analysis&#39;][model_name] train_sizes = lc[&#39;train_sizes&#39;]
train_scores = lc[&#39;train_scores&#39;]
test_scores = lc[&#39;test_scores&#39;]
``` **When to Use:**
- Diagnose underfitting vs. overfitting
- Determine if more data would help
- Select appropriate model complexity
- Convince stakeholders of data needs

---

## 3. Statistical Testing Framework ### 3.1 Overview Statistical tests validate assumptions and quantify confidence in analysis results. **Implementation:** `src/analysis/validation/statistical_tests.py` (905 lines) **Core Questions:**
1. Are my data normally distributed?
2. Is my time series stationary?
3. Is the difference statistically significant?
4. How large is the effect?

---

### 3.2 Normality Tests **Purpose:** Many statistical tests assume normality. Verify this assumption. **Implementation:** `src/analysis/validation/statistical_tests.py` (lines 217-291)

---

#### 3.2.1 Shapiro-Wilk Test **Description:** Most normality test for small-to-moderate samples. **Null Hypothesis:** Data come from normal distribution **Test Statistic:** ```
W = (Σᵢ aᵢx₍ᵢ₎)² / Σᵢ(xᵢ - x̄)² where x₍ᵢ₎ are order statistics, aᵢ are weights
``` **Implementation:**

```python
from src.analysis.validation.statistical_tests import StatisticalTestSuite suite = StatisticalTestSuite()
result = suite.validate(data, test_types=[&#39;normality_tests&#39;]) shapiro = result.data[&#39;normality_tests&#39;][&#39;shapiro_wilk&#39;]
print(f&quot;W = {shapiro[&#39;statistic&#39;]:.4f}, p = {shapiro[&#39;p_value&#39;]:.4f}&quot;)
``` **Decision Rule:**

- p &gt; 0.05: Cannot reject normality (data may be normal)
- p &lt; 0.05: Reject normality (data not normal) **Sample Size:**
- **Recommended:** 10 ≤ n ≤ 5000
- **Limitation:** Not applicable for n &gt; 5000 **Power:** Highest among normality tests for small samples

---

#### 3.2.2 Anderson-Darling Test **Description:** Emphasizes tails more than K-S test. **Test Statistic:** ```

A² = -n - (1/n)Σᵢ (2i-1)[ln Φ(zᵢ) + ln(1-Φ(zₙ₊₁₋ᵢ))] where zᵢ = (xᵢ - μ̂)/σ̂, Φ = standard normal CDF
``` **Critical Values (α = 0.05):**
- A² &lt; 0.787: Cannot reject normality
- A² &gt; 0.787: Reject normality **Advantages:**
- More sensitive to tail deviations
- Works for larger samples
- Distribution-specific critical values

---

#### 3.2.3 Kolmogorov-Smirnov Test **Description:** Tests if empirical CDF matches hypothesized distribution. **Test Statistic:** ```
D = sup_x |F̂ₙ(x) - F₀(x)| where F̂ₙ = empirical CDF, F₀ = normal CDF
``` **Decision Rule:** ```

Reject H₀ if D &gt; critical value(α, n) Critical value ≈ 1.36/√n for α=0.05
``` **Limitations:**
- Less than Shapiro-Wilk
- Conservative (may not reject false H₀)
- Sensitive to ties in data

---

#### 3.2.4 D&#39;Agostino-Pearson Test **Description:** Tests skewness and kurtosis jointly. **Test Statistic:** ```
K² = Z₁² + Z₂² ~ χ²(2) where Z₁ = skewness test, Z₂ = kurtosis test
``` **Advantages:**

- Works for larger samples (n &gt; 20)
- Identifies specific departures (skewness vs. kurtosis)

---

**Normality Test Decision Tree:** ```
Sample Size?
│
├─ n &lt; 50: Use Shapiro-Wilk (most powerful)
├─ 50 ≤ n ≤ 300: Use Shapiro-Wilk or Anderson-Darling
├─ n &gt; 300: Use D&#39;Agostino-Pearson
└─ Very large: Use QQ-plot (visual) + A-D test
``` **If Non-Normal:**
1. Check for outliers
2. Consider transformation (log, Box-Cox)
3. Use non-parametric tests
4. Use bootstrap for confidence intervals

---

### 3.3 Stationarity Tests **Purpose:** Time series analysis assumes stationarity. Non-stationary data can lead to spurious conclusions. **Definition:** A time series is stationary if:
1. Constant mean: E[Xₜ] = μ for all t
2. Constant variance: Var(Xₜ) = σ² for all t
3. Autocovariance depends only on lag: Cov(Xₜ, Xₜ₊ₖ) = γₖ

---

#### 3.3.1 Augmented Dickey-Fuller (ADF) Test **Description:** Tests for unit root (non-stationarity). **Null Hypothesis:** Series has unit root (non-stationary) **Test Regression:** ```
Δyₜ = α + βt + γyₜ₋₁ + ΣⱼδⱼΔyₜ₋ⱼ + εₜ H₀: γ = 0 (unit root)
H₁: γ &lt; 0 (stationary)
``` **Implementation:**

```python
result = suite.validate(data, test_types=[&#39;stationarity_tests&#39;])
adf = result.data[&#39;stationarity_tests&#39;][&#39;augmented_dickey_fuller&#39;] print(f&quot;ADF statistic: {adf[&#39;test_statistic&#39;]:.4f}&quot;)
print(f&quot;Conclusion: {adf[&#39;conclusion&#39;]}&quot;)
``` **Decision Rule:**

- ADF statistic &lt; critical value: Reject H₀ (stationary)
- ADF statistic &gt; critical value: Cannot reject H₀ (non-stationary) **Critical Values (α = 0.05):**
- No trend: -2.86
- With trend: -3.41 **If Non-Stationary:**
1. Difference the series: ∇Xₜ = Xₜ - Xₜ₋₁
2. Remove trend: detrend(X)
3. Use non-stationary methods (e.g., cointegration)

---

#### 3.3.2 KPSS Test **Description:** Tests for stationarity (opposite of ADF). **Null Hypothesis:** Series is stationary **Note:** KPSS and ADF are complementary:

- ADF: H₀ = non-stationary
- KPSS: H₀ = stationary **Best Practice:** Use both tests: | ADF | KPSS | Conclusion |
|-------------|-------------|-----------------------------|
| Reject H₀ | Don&#39;t reject| **Stationary** |
| Don&#39;t reject| Reject H₀ | **Non-stationary** |
| Reject H₀ | Reject H₀ | Trending stationary |
| Don&#39;t reject| Don&#39;t reject| Inconclusive (more data) |

---

### 3.4 Hypothesis Testing **Purpose:** Quantify evidence for/against research claims. **Framework:** 1. State hypotheses: - H₀ (null): No effect / No difference - H₁ (alternative): Effect exists 2. Choose test statistic and significance level α (typically 0.05) 3. Compute p-value: P(observe data or more extreme | H₀ true) 4. Decision: - p &lt; α: Reject H₀ (statistically significant) - p ≥ α: Cannot reject H₀ (not significant)

#### 3.4.1 One-Sample Tests **Purpose:** Test if population mean equals hypothesized value. **t-Test:** ```

H₀: μ = μ₀
H₁: μ ≠ μ₀ (two-sided) Test statistic: t = (x̄ - μ₀) / (s/√n) ~ t(n-1)
``` **Implementation:**
```python

result = suite.validate(data, test_types=[&#39;hypothesis_tests&#39;])
ttest = result.data[&#39;hypothesis_tests&#39;][&#39;one_sample&#39;][&#39;t_test_zero_mean&#39;] if ttest[&#39;p_value&#39;] &lt; 0.05: print(f&quot;Mean significantly different from 0 (p={ttest[&#39;p_value&#39;]:.4f})&quot;)
``` **Example (Control System):**
- H₀: Tracking error mean = 0
- H₁: Systematic bias exists
- Reject H₀ → Controller has systematic bias

---

#### 3.4.2 Two-Sample Tests **Purpose:** Compare two controllers/methods. **Independent t-Test (Welch&#39;s):** ```
H₀: μ₁ = μ₂
H₁: μ₁ ≠ μ₂ Test statistic: t = (x̄₁ - x̄₂) / √(s₁²/n₁ + s₂²/n₂)
``` **Paired t-Test:** Use when same scenarios tested with both methods: ```

H₀: μ_diff = 0
H₁: μ_diff ≠ μ₀ Test statistic: t = d̄ / (s_d/√n)
where d̄ = mean difference, s_d = std of differences
``` **Implementation:**
```python

config = StatisticalTestConfig( use_paired_tests=True, # Use paired if same scenarios significance_level=0.05
)
suite = StatisticalTestSuite(config)
``` **Mann-Whitney U Test (Non-parametric):** Use when normality assumption violated: ```
H₀: Distributions are equal
H₁: Distributions differ Test based on rank sums
``` **When to Use:**

- **t-test:** Normal data, continuous outcomes
- **Mann-Whitney:** Non-normal data, ordinal data, outliers
- **Paired:** Same scenarios, within-subject comparisons

---

#### 3.4.3 Multiple Comparison Corrections **Problem:** Testing multiple hypotheses increases false positive rate. **Example:** 20 comparisons at α=0.05 → expect 1 false positive **Family-Wise Error Rate (FWER):** Probability of at least one false positive: ```

FWER = 1 - (1-α)ᵐ ≈ mα for small α where m = number of tests
``` **Bonferroni Correction:** ```
α_corrected = α / m Most conservative - reject if p &lt; α/m
``` **Holm-Bonferroni (Sequential):** 1. Order p-values: p₍₁₎ ≤ p₍₂₎ ≤ ... ≤ p₍ₘ₎

2. Reject H₍ᵢ₎ if p₍ᵢ₎ &lt; α/(m-i+1)
3. Stop at first non-rejection **Benjamini-Hochberg (FDR Control):** Controls False Discovery Rate instead of FWER (less conservative): 1. Order p-values
2. Find largest i where p₍ᵢ₎ ≤ (i/m)α
3. Reject all H₍₁₎, ..., H₍ᵢ₎ **Implementation:**
```python
config = StatisticalTestConfig( multiple_comparisons_correction=&quot;bonferroni&quot; # or &quot;holm&quot;, &quot;fdr_bh&quot;
)
``` **Choosing Correction:**

- **Bonferroni:** Very conservative, exploratory phase
- **Holm:** Less conservative, more power
- **FDR (B-H):** Large-scale testing (e.g., 100+ tests), discovery-focused
- **None:** Pre-planned single comparison

---

### 3.5 Power Analysis **Purpose:** Determine sample size needed to detect an effect of given size with desired probability. **Key Concepts:** 1. **Power (1-β):** Probability of correctly rejecting false H₀ - Standard: 0.80 (80% power) - Rigorous: 0.90 or 0.95 2. **Effect Size:** Magnitude of difference - Small: Hard to detect - Large: Easy to detect 3. **Significance Level (α):** Type I error rate - Standard: 0.05 - Stringent: 0.01 4. **Sample Size (n):** Number of observations **Relationship:**

</pre></div>
</div>
<p>↑ Effect size → ↑ Power (easier to detect)
↑ Sample size → ↑ Power (more data)
↑ α (less stringent) → ↑ Power (more false positives)
<code class="docutils literal notranslate"><span class="pre">**Sample</span> <span class="pre">Size</span> <span class="pre">Formula</span> <span class="pre">(two-sample</span> <span class="pre">t-test):**</span></code></p>
<p>n = 2(z₁₋α/₂ + z₁₋β)² / δ² where δ = effect size (Cohen’s d)</p>
<div class="highlight-**Implementation:** notranslate"><div class="highlight"><pre><span></span>```python

result = suite.validate(data, test_types=[&#39;power_analysis&#39;])
power_analysis = result.data[&#39;power_analysis&#39;] print(f&quot;Current power: {power_analysis[&#39;estimated_power&#39;]:.2f}&quot;)
print(f&quot;Recommended N: {power_analysis[&#39;recommended_sample_size&#39;]}&quot;) if not power_analysis[&#39;power_adequate&#39;]: print(&quot;⚠ Insufficient power - need more data&quot;)
``` **Interpretation:** | Current N | Power | Action |
|-----------|-------|----------------------------------|
| 30 | 0.45 | Need 2x more data (underpowered)|
| 50 | 0.75 | Marginal - collect more if possible|
| 100 | 0.85 | Adequate power ✓ |
| 200 | 0.95 | power ✓✓ | **Control System Context:** - **Before Experiments:** Determine required test scenarios
- **During Analysis:** Check if differences are detectable
- **Publication:** Report achieved power to avoid false negatives

---

### 3.6 Effect Size Analysis **Purpose:** Quantify practical significance (not just statistical significance). **Key Insight:** With large n, tiny differences become statistically significant but may not be practically important.

---

#### 3.6.1 Cohen&#39;s d **Definition:** Standardized mean difference ```
d = (μ₁ - μ₂) / σ_pooled where σ_pooled = √[(s₁² + s₂²) / 2]
``` **Interpretation (Cohen&#39;s conventions):** | |d| | Magnitude | Interpretation |

|-----|------------|------------------------------|
| 0.0-0.2 | Negligible | Not worth pursuing |
| 0.2-0.5 | Small | Detectable, minor practical value|
| 0.5-0.8 | Medium | Noticeable, moderate importance|
| &gt;0.8 | Large | Obvious, high practical value| **Implementation:**
```python
result = suite.validate( data, compare_groups=[group2], test_types=[&#39;effect_size_analysis&#39;]
) effect_size = result.data[&#39;effect_size_analysis&#39;]
cohens_d = effect_size[&#39;cohens_d_group_0&#39;][&#39;value&#39;]
interpretation = effect_size[&#39;cohens_d_group_0&#39;][&#39;interpretation&#39;]
``` **Control System Example:** Comparing two controllers:

- Controller A: mean settling time = 2.5s, std = 0.5s
- Controller B: mean settling time = 2.0s, std = 0.4s ```
d = (2.5 - 2.0) / √[(0.5² + 0.4²)/2] = 1.11 → Large effect
``` **Conclusion:** 0.5s improvement is **large** effect - substantial practical benefit.

---

#### 3.6.2 Glass&#39;s Δ **Definition:** Standardize by control group std only ```
Δ = (μ_treatment - μ_control) / σ_control
``` **Use When:** Control group is the established baseline, treatment may have different variance.

---

#### 3.6.3 Hedges&#39; g **Definition:** Bias-corrected Cohen&#39;s d for small samples ```

g = d × [1 - 3/(4n - 9)] Correction factor ≈ 1 for n &gt; 50
``` **Use When:** Small samples (n &lt; 20)

---

**Effect Size Decision Tree:** ```
What are you comparing?
│
├─ Two groups (between-subjects)
│ ├─ Equal variances expected: Cohen&#39;s d
│ ├─ Control is reference: Glass&#39;s Δ
│ └─ Small sample: Hedges&#39; g
│
├─ Paired observations (within-subjects)
│ └─ Use Cohen&#39;s d on differences
│
└─ Multiple groups └─ Use η² (eta-squared) or ω² (omega-squared)
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="benchmark-comparison-methodology-4-1-overview-rigorous-statistical-comparison-of-multiple-controllers-methods-implementation-src-analysis-validation-benchmarking-py-841-lines-workflow">
<h2>4. Benchmark Comparison Methodology ### 4.1 Overview Rigorous statistical comparison of multiple controllers/methods. <strong>Implementation:</strong> <code class="docutils literal notranslate"><span class="pre">src/analysis/validation/benchmarking.py</span></code> (841 lines) <strong>Workflow:</strong><a class="headerlink" href="#benchmark-comparison-methodology-4-1-overview-rigorous-statistical-comparison-of-multiple-controllers-methods-implementation-src-analysis-validation-benchmarking-py-841-lines-workflow" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Define test scenarios</p></li>
<li><p>Run all methods on same scenarios</p></li>
<li><p>Statistical comparison</p></li>
<li><p>Ranking and recommendations</p></li>
</ol>
<hr class="docutils" />
<section id="performance-metrics-selection-key-principle-select-metrics-aligned-with-application-requirements-standard-control-metrics-metric-definition-use-case">
<h3>4.2 Performance Metrics Selection <strong>Key Principle:</strong> Select metrics aligned with application requirements. <strong>Standard Control Metrics:</strong> | Metric | Definition | Use Case |<a class="headerlink" href="#performance-metrics-selection-key-principle-select-metrics-aligned-with-application-requirements-standard-control-metrics-metric-definition-use-case" title="Link to this heading">¶</a></h3>
<p>|——————-|—————————–|——————————|
| Rise Time | 10% → 90% of steady-state | Responsiveness |
| Settling Time | Within ±2% of steady-state | Stability |
| Overshoot | Peak - steady-state | Safety, constraints |
| Steady-State Error| |target - final| | Accuracy |
| RMS Tracking Error| √(mean(e²)) | Overall performance |
| Control Effort | Σ|u| | Actuator wear, energy |
| Disturbance Rejection| RMSE with disturbance | Robustness | <strong>Implementation:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">src.analysis.validation.benchmarking</span><span class="w"> </span><span class="kn">import</span> <span class="n">BenchmarkConfig</span><span class="p">,</span> <span class="n">BenchmarkSuite</span> <span class="n">config</span> <span class="o">=</span> <span class="n">BenchmarkConfig</span><span class="p">(</span> <span class="n">metrics_to_compare</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;settling_time&quot;</span><span class="p">,</span> <span class="s2">&quot;overshoot&quot;</span><span class="p">,</span> <span class="s2">&quot;control_effort&quot;</span><span class="p">],</span> <span class="n">primary_metric</span><span class="o">=</span><span class="s2">&quot;settling_time&quot;</span>
<span class="p">)</span>
<span class="err">```</span> <span class="o">**</span><span class="n">Multi</span><span class="o">-</span><span class="n">Objective</span> <span class="n">Ranking</span><span class="p">:</span><span class="o">**</span> <span class="n">When</span> <span class="n">multiple</span> <span class="n">metrics</span> <span class="n">matter</span><span class="p">,</span> <span class="n">use</span> <span class="n">weighted</span> <span class="n">score</span><span class="p">:</span> <span class="err">```</span>

<span class="n">Score</span> <span class="o">=</span> <span class="n">Σᵢ</span> <span class="n">wᵢ</span> <span class="err">×</span> <span class="p">(</span><span class="n">normalized_metricᵢ</span><span class="p">)</span> <span class="n">Normalization</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="n">where</span> <span class="mi">1</span> <span class="ow">is</span> <span class="n">best</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="statistical-significance-testing-workflow-1-run-trials-each-method-each-scenario-multiple-trials">
<h3>4.3 Statistical Significance Testing <strong>Workflow:</strong> 1. <strong>Run Trials:</strong> Each method × each scenario × multiple trials<a class="headerlink" href="#statistical-significance-testing-workflow-1-run-trials-each-method-each-scenario-multiple-trials" title="Link to this heading">¶</a></h3>
<ol class="arabic simple" start="2">
<li><p><strong>Collect Scores:</strong> Distribution of performance for each method</p></li>
<li><p><strong>Pairwise Tests:</strong> Compare each pair statistically</p></li>
<li><p><strong>Multiple Comparison Correction:</strong> Adjust for many tests</p></li>
<li><p><strong>Ranking:</strong> Order methods by performance <strong>Implementation:</strong></p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">BenchmarkSuite</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="n">result</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="n">controller_A</span><span class="p">,</span> <span class="n">controller_B</span><span class="p">,</span> <span class="n">controller_C</span><span class="p">],</span> <span class="n">simulation_function</span><span class="o">=</span><span class="n">run_simulation</span><span class="p">,</span> <span class="n">test_cases</span><span class="o">=</span><span class="p">[</span><span class="n">scenario1</span><span class="p">,</span> <span class="n">scenario2</span><span class="p">,</span> <span class="n">scenario3</span><span class="p">]</span>
<span class="p">)</span> <span class="n">sig_tests</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;statistical_significance_testing&#39;</span><span class="p">]</span>
<span class="n">ranking</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;ranking_analysis&#39;</span><span class="p">][</span><span class="s1">&#39;final_ranking&#39;</span><span class="p">]</span>
<span class="err">```</span> <span class="o">**</span><span class="n">Interpreting</span> <span class="n">Results</span><span class="p">:</span><span class="o">**</span> <span class="err">```</span><span class="n">python</span>
<span class="k">for</span> <span class="n">comparison</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">sig_tests</span><span class="p">[</span><span class="s1">&#39;corrected_tests&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> <span class="k">if</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;corrected_significant&#39;</span><span class="p">]:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">comparison</span><span class="si">}</span><span class="s2">: Significant difference (p=</span><span class="si">{</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;corrected_p_value&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span> <span class="k">else</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">comparison</span><span class="si">}</span><span class="s2">: No significant difference&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="robustness-comparison-robustness-measures-1-coefficient-of-variation-cv-cv-lower-cv-more-robust-consistent-performance-2-interquartile-range-iqr-iqr-q3-q1-smaller-iqr-less-variability-3-worst-case-performance-worst-case-95th-percentile-of-error-critical-for-safety-critical-systems-implementation">
<h3>4.4 Robustness Comparison <strong>Robustness Measures:</strong> 1. <strong>Coefficient of Variation (CV):</strong> <code class="docutils literal notranslate"><span class="pre">CV</span> <span class="pre">=</span> <span class="pre">σ</span> <span class="pre">/</span> <span class="pre">|μ|</span> <span class="pre">Lower</span> <span class="pre">CV</span> <span class="pre">=</span> <span class="pre">more</span> <span class="pre">robust</span> <span class="pre">(consistent</span> <span class="pre">performance)</span></code> 2. <strong>Interquartile Range (IQR):</strong> <code class="docutils literal notranslate"><span class="pre">IQR</span> <span class="pre">=</span> <span class="pre">Q₃</span> <span class="pre">-</span> <span class="pre">Q₁</span> <span class="pre">Smaller</span> <span class="pre">IQR</span> <span class="pre">=</span> <span class="pre">less</span> <span class="pre">variability</span></code> 3. <strong>Worst-Case Performance:</strong> <code class="docutils literal notranslate"><span class="pre">Worst-case</span> <span class="pre">=</span> <span class="pre">95th</span> <span class="pre">percentile</span> <span class="pre">of</span> <span class="pre">error</span> <span class="pre">Critical</span> <span class="pre">for</span> <span class="pre">safety-critical</span> <span class="pre">systems</span></code> <strong>Implementation:</strong><a class="headerlink" href="#robustness-comparison-robustness-measures-1-coefficient-of-variation-cv-cv-lower-cv-more-robust-consistent-performance-2-interquartile-range-iqr-iqr-q3-q1-smaller-iqr-less-variability-3-worst-case-performance-worst-case-95th-percentile-of-error-critical-for-safety-critical-systems-implementation" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">robustness</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;robustness_comparison&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">method_name</span><span class="p">,</span> <span class="n">metrics</span> <span class="ow">in</span> <span class="n">robustness</span><span class="p">[</span><span class="s1">&#39;robustness_metrics&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;settling_time&#39;</span><span class="p">][</span><span class="s1">&#39;coefficient_of_variation&#39;</span><span class="p">]</span> <span class="n">score</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;settling_time&#39;</span><span class="p">][</span><span class="s1">&#39;robustness_score&#39;</span><span class="p">]</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">method_name</span><span class="si">}</span><span class="s2">: CV=</span><span class="si">{</span><span class="n">cv</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Robustness Score=</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="err">```</span> <span class="o">**</span><span class="n">Robustness</span> <span class="n">Ranking</span><span class="p">:</span><span class="o">**</span>

<span class="err">```</span><span class="n">python</span>
<span class="n">ranking</span> <span class="o">=</span> <span class="n">robustness</span><span class="p">[</span><span class="s1">&#39;robustness_ranking&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Most robust: </span><span class="si">{</span><span class="n">ranking</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> (score=</span><span class="si">{</span><span class="n">ranking</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="efficiency-comparison-computational-efficiency-metrics-1-mean-computation-time-average-time-per-simulation">
<h3>4.5 Efficiency Comparison <strong>Computational Efficiency Metrics:</strong> 1. <strong>Mean Computation Time:</strong> Average time per simulation<a class="headerlink" href="#efficiency-comparison-computational-efficiency-metrics-1-mean-computation-time-average-time-per-simulation" title="Link to this heading">¶</a></h3>
<ol class="arabic simple" start="2">
<li><p><strong>Peak Memory Usage:</strong> Maximum memory required</p></li>
<li><p><strong>Scalability:</strong> Time vs. problem size <strong>Implementation:</strong></p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">BenchmarkConfig</span><span class="p">(</span> <span class="n">measure_computation_time</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">measure_memory_usage</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="err">```</span> <span class="o">**</span><span class="n">Trade</span><span class="o">-</span><span class="n">off</span> <span class="n">Analysis</span><span class="p">:</span><span class="o">**</span> <span class="err">```</span>

<span class="n">Performance</span> <span class="n">vs</span><span class="o">.</span> <span class="n">Efficiency</span><span class="p">:</span> <span class="n">High</span> <span class="n">Performance</span><span class="p">,</span> <span class="n">High</span> <span class="n">Cost</span><span class="p">:</span> <span class="n">Advanced</span> <span class="n">control</span> <span class="p">(</span><span class="n">MPC</span><span class="p">,</span> <span class="n">adaptive</span><span class="p">)</span>
<span class="n">High</span> <span class="n">Performance</span><span class="p">,</span> <span class="n">Low</span> <span class="n">Cost</span><span class="p">:</span> <span class="n">Well</span><span class="o">-</span><span class="n">tuned</span> <span class="n">classical</span> <span class="n">control</span> <span class="p">(</span><span class="n">ideal</span><span class="err">!</span><span class="p">)</span>
<span class="n">Low</span> <span class="n">Performance</span><span class="p">,</span> <span class="n">Low</span> <span class="n">Cost</span><span class="p">:</span> <span class="n">Simple</span> <span class="n">control</span> <span class="p">(</span><span class="n">acceptable</span> <span class="k">for</span> <span class="n">some</span><span class="p">)</span>
<span class="n">Low</span> <span class="n">Performance</span><span class="p">,</span> <span class="n">High</span> <span class="n">Cost</span><span class="p">:</span> <span class="n">Poorly</span> <span class="n">designed</span> <span class="p">(</span><span class="n">avoid</span><span class="err">!</span><span class="p">)</span>
<span class="err">```</span> <span class="o">**</span><span class="n">Pareto</span> <span class="n">Front</span><span class="p">:</span><span class="o">**</span> <span class="n">Identify</span> <span class="n">non</span><span class="o">-</span><span class="n">dominated</span> <span class="n">solutions</span><span class="p">:</span>
<span class="o">-</span> <span class="n">Method</span> <span class="n">A</span><span class="p">:</span> <span class="mf">2.0</span><span class="n">s</span> <span class="n">settling</span> <span class="n">time</span><span class="p">,</span> <span class="mi">10</span><span class="n">ms</span> <span class="n">compute</span> <span class="n">time</span>
<span class="o">-</span> <span class="n">Method</span> <span class="n">B</span><span class="p">:</span> <span class="mf">1.8</span><span class="n">s</span> <span class="n">settling</span> <span class="n">time</span><span class="p">,</span> <span class="mi">50</span><span class="n">ms</span> <span class="n">compute</span> <span class="n">time</span> <span class="err">←</span> <span class="n">Pareto</span> <span class="n">optimal</span>
<span class="o">-</span> <span class="n">Method</span> <span class="n">C</span><span class="p">:</span> <span class="mf">2.5</span><span class="n">s</span> <span class="n">settling</span> <span class="n">time</span><span class="p">,</span> <span class="mi">60</span><span class="n">ms</span> <span class="n">compute</span> <span class="n">time</span> <span class="err">←</span> <span class="n">Dominated</span> <span class="n">by</span> <span class="n">A</span>

<span class="o">---</span>

<span class="c1">### 4.6 Ranking Methodologies #### 4.6.1 Single-Metric Ranking **Simplest:** Rank by primary metric mean. ```python</span>
<span class="c1"># example-metadata:</span>
<span class="c1"># runnable: false ranking = result.data[&#39;performance_comparison&#39;][&#39;method_ranking&#39;]</span>
<span class="c1"># [(method1, score1), (method2, score2), ...]</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="borda-count-multi-metric-description-aggregate-rankings-across-multiple-metrics-algorithm-1-rank-methods-for-each-metric">
<h2>4.6.2 Borda Count (Multi-Metric) <strong>Description:</strong> Aggregate rankings across multiple metrics. <strong>Algorithm:</strong> 1. Rank methods for each metric<a class="headerlink" href="#borda-count-multi-metric-description-aggregate-rankings-across-multiple-metrics-algorithm-1-rank-methods-for-each-metric" title="Link to this heading">¶</a></h2>
<ol class="arabic simple" start="2">
<li><p>Assign points: 1st place = n-1 points, 2nd = n-2, …, last = 0</p></li>
<li><p>Sum points across all metrics</p></li>
<li><p>Final ranking by total points <strong>Example:</strong> | Method | Metric A Rank | Metric B Rank | Metric C Rank | Total |
|——–|—————|—————|—————|——-|
| A | 1 (2pts) | 2 (1pt) | 1 (2pts) | 5 |
| B | 2 (1pt) | 1 (2pts) | 3 (0pts) | 3 |
| C | 3 (0pts) | 3 (0pts) | 2 (1pt) | 1 | <strong>Winner:</strong> Method A (highest Borda count) <strong>Implementation:</strong></p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ranking</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;ranking_analysis&#39;</span><span class="p">]</span>
<span class="n">borda_scores</span> <span class="o">=</span> <span class="n">ranking</span><span class="p">[</span><span class="s1">&#39;borda_scores&#39;</span><span class="p">]</span>
<span class="n">final_ranking</span> <span class="o">=</span> <span class="n">ranking</span><span class="p">[</span><span class="s1">&#39;final_ranking&#39;</span><span class="p">]</span>
</pre></div>
</div>
<hr class="docutils" />
<section id="weighted-score-description-weight-metrics-by-importance">
<h3>4.6.3 Weighted Score <strong>Description:</strong> Weight metrics by importance. ```<a class="headerlink" href="#weighted-score-description-weight-metrics-by-importance" title="Link to this heading">¶</a></h3>
<p>Score = Σᵢ wᵢ × normalized_metricᵢ where Σᵢ wᵢ = 1</p>
<div class="highlight-**Example:** notranslate"><div class="highlight"><pre><span></span>- w_settling = 0.3
- w_overshoot = 0.5 (most important - avoid constraint violation)
- w_control_effort = 0.2 **Implementation:**
```python

weights = {&#39;settling_time&#39;: 0.3, &#39;overshoot&#39;: 0.5, &#39;control_effort&#39;: 0.2} # Compute weighted scores
for method_name, method_data in performance_data.items(): score = sum(weights[m] * normalize(method_data[m]) for m in weights)
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="uncertainty-quantification-5-1-overview-quantify-uncertainty-in-performance-predictions-and-stability-guarantees-sources-of-uncertainty">
<h2>5. Uncertainty Quantification ### 5.1 Overview Quantify uncertainty in performance predictions and stability guarantees. <strong>Sources of Uncertainty:</strong><a class="headerlink" href="#uncertainty-quantification-5-1-overview-quantify-uncertainty-in-performance-predictions-and-stability-guarantees-sources-of-uncertainty" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p><strong>Aleatory (Stochastic):</strong> Inherent randomness (disturbances, noise)</p></li>
<li><p><strong>Epistemic (Knowledge):</strong> Model uncertainty, parameter uncertainty</p></li>
</ol>
<hr class="docutils" />
<section id="confidence-intervals-parametric-ci-normal-assumption">
<h3>5.2 Confidence Intervals <strong>Parametric CI (Normal Assumption):</strong> ```<a class="headerlink" href="#confidence-intervals-parametric-ci-normal-assumption" title="Link to this heading">¶</a></h3>
<p>CI = x̄ ± t_{α/2,n-1} × (s/√n) where t_{α/2,n-1} = Student’s t critical value</p>
<div class="highlight-**Bootstrap notranslate"><div class="highlight"><pre><span></span>
2. Compute statistic for each bootstrap sample
3. CI = [θ̂*_{α/2}, θ̂*_{1-α/2}] (percentile method) **Interpretation:** &quot;95% CI [2.1, 2.5]&quot;: We are 95% confident true mean settling time is between 2.1s and 2.5s. **Control System Context:** - **Narrow CI:** Predictable performance, safe for deployment
- **Wide CI:** High uncertainty, need more data or better control **Safety Margin:** For safety-critical applications:
</pre></div>
</div>
<p>Worst-case bound = Upper CI + k×σ where k = 3 for 99.7% coverage (3-sigma)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
---

### 5.3 Distribution Fitting and Goodness-of-Fit **Why Fit Distributions?** 1. Predict probabilities: P(settling time &gt; 3s) = ?

2. Generate synthetic scenarios
3. Formal probabilistic guarantees **Fitted Distribution Usage:** ```python
# After fitting (e.g., lognormal)

from scipy import stats dist_params = result.data[&#39;distribution_analysis&#39;][&#39;distribution_fits&#39;][&#39;lognormal&#39;][&#39;parameters&#39;]
dist = stats.lognorm(*dist_params) # Probability of exceeding threshold
prob_exceed = 1 - dist.cdf(threshold)
print(f&quot;P(settling time &gt; 3s) = {prob_exceed:.4f}&quot;) # 95th percentile
percentile_95 = dist.ppf(0.95)
print(f&quot;95% of scenarios have settling time &lt; {percentile_95:.2f}s&quot;)
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="risk-analysis-for-safety-critical-systems-value-at-risk-var">
<h2>5.4 Risk Analysis for Safety-Critical Systems <strong>Value at Risk (VaR):</strong> ```<a class="headerlink" href="#risk-analysis-for-safety-critical-systems-value-at-risk-var" title="Link to this heading">¶</a></h2>
<p>VaR_α = inf{x : P(X ≤ x) ≥ α} Example: VaR₀.₀₅ = worst-case performance for bottom 5% of scenarios
<code class="docutils literal notranslate"><span class="pre">**Conditional</span> <span class="pre">Value</span> <span class="pre">at</span> <span class="pre">Risk</span> <span class="pre">(CVaR</span> <span class="pre">/</span> <span class="pre">Expected</span> <span class="pre">Shortfall):**</span></code></p>
<p>CVaR_α = E[X | X ≤ VaR_α] Average performance in worst α% of cases</p>
<div class="highlight-**Implementation:** notranslate"><div class="highlight"><pre><span></span>```python

risk_analysis = result.data[&#39;risk_analysis&#39;] var_5 = risk_analysis[&#39;value_at_risk&#39;][&#39;var_5&#39;] # 5th percentile
cvar_5 = risk_analysis[&#39;conditional_value_at_risk&#39;][&#39;cvar_5&#39;] print(f&quot;Worst 5% scenarios: VaR={var_5:.2f}, CVaR={cvar_5:.2f}&quot;)
``` **Safety Validation:** For a controller to be &quot;safe&quot;, require:
</pre></div>
</div>
<p>P(performance &lt; acceptable_threshold) &lt; ε where ε = acceptable failure rate (e.g., 10⁻⁶ for aviation)</p>
<div class="highlight-**Extreme notranslate"><div class="highlight"><pre><span></span>```python

extreme = risk_analysis[&#39;extreme_value_analysis&#39;] # 100-year return level
return_100 = extreme[&#39;return_levels&#39;][&#39;100_year&#39;]
print(f&quot;Once-in-100-scenarios worst-case: {return_100:.2f}&quot;)
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="integration-with-control-systems-6-1-validation-workflow-for-new-controllers-standard-validation-protocol">
<h2>6. Integration with Control Systems ### 6.1 Validation Workflow for New Controllers <strong>Standard Validation Protocol:</strong> ```<a class="headerlink" href="#integration-with-control-systems-6-1-validation-workflow-for-new-controllers-standard-validation-protocol" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p><strong>Unit Testing:</strong> ├─ Verify implementation correctness └─ Test edge cases (saturation, singular configurations) 2. <strong>Monte Carlo Validation:</strong> ├─ Parameter uncertainty propagation ├─ LHS sampling (500-1000 samples) ├─ Check convergence └─ Distribution fitting 3. <strong>Cross-Validation:</strong> ├─ Time series CV (respect temporal order) ├─ Test on held-out scenarios └─ Bias-variance analysis 4. <strong>Statistical Testing:</strong> ├─ Normality of residuals ├─ Stationarity of performance └─ Hypothesis tests vs. baseline 5. <strong>Benchmark Comparison:</strong> ├─ Compare with ├─ Statistical significance + effect size └─ Robustness comparison 6. <strong>Uncertainty Quantification:</strong> ├─ Confidence intervals ├─ Risk analysis (VaR, CVaR) └─ Extreme value analysis 7. <strong>Production Validation:</strong> ├─ Hardware-in-the-loop testing ├─ Field trials └─ Long-term monitoring</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
---

## 6.2 PSO Hyperparameter Validation **Challenge:** Ensure PSO-tuned parameters generalize beyond training scenarios. **Validation Approach:** 1. **Training Scenarios:** Nominal operating conditions

2. **Validation Scenarios:** Hold-out scenarios (10-20% of total)
3. **Test Scenarios:** Completely new conditions **Cross-Validation for PSO:** ```python
from src.analysis.validation.cross_validation import CrossValidator validator = CrossValidator(CrossValidationConfig( cv_method=&quot;monte_carlo&quot;, n_repetitions=50, test_ratio=0.2
)) # For each CV split:
# - Optimize on training scenarios

# - Evaluate on test scenarios

# - Record generalization gap cv_result = validator.validate( scenarios, models=[pso_optimized_controller], prediction_function=simulate_controller

) generalization_gap = ( cv_result.data[&#39;monte_carlo_validation&#39;][&#39;training_score&#39;] - cv_result.data[&#39;monte_carlo_validation&#39;][&#39;test_score&#39;]
) if generalization_gap &gt; threshold: print(&quot;⚠ Overfitting detected - need more diverse training scenarios&quot;)
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="adaptive-controller-validation-challenge-performance-depends-on-online-adaptation-cannot-use-standard-cv-time-series-validation-approach-python">
<h2>6.3 Adaptive Controller Validation <strong>Challenge:</strong> Performance depends on online adaptation - cannot use standard CV. <strong>Time Series Validation Approach:</strong> ```python<a class="headerlink" href="#adaptive-controller-validation-challenge-performance-depends-on-online-adaptation-cannot-use-standard-cv-time-series-validation-approach-python" title="Link to this heading">¶</a></h2>
<p>config = CrossValidationConfig( cv_method=”time_series”, n_splits=5, max_train_size=100, # Limit adaptation window gap=10 # Predict 10 steps ahead
) # Each fold:</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="controller-adapts-on-t0-t1">
<h1>- Controller adapts on [t₀, t₁]<a class="headerlink" href="#controller-adapts-on-t0-t1" title="Link to this heading">¶</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="performance-evaluated-on-t1-gap-t2">
<h1>- Performance evaluated on [t₁+gap, t₂]<a class="headerlink" href="#performance-evaluated-on-t1-gap-t2" title="Link to this heading">¶</a></h1>
<div class="highlight-**Metrics:** notranslate"><div class="highlight"><pre><span></span>
- **Adaptation Speed:** Time to converge after disturbance
- **Tracking Performance:** RMSE during adaptation vs. after
- **Stability Margin:** Lyapunov function or gain margin

---

## 6.4 Real-Time Control Validation **Timing Validation:** ```python

# example-metadata:

# runnable: false config = BenchmarkConfig( measure_computation_time=True, n_trials=100

) benchmark = BenchmarkSuite(config)
result = benchmark.validate(...) comp_time = result.data[&#39;simulation_benchmarks&#39;][scenario][method][&#39;computational_analysis&#39;] mean_time = comp_time[&#39;mean_computation_time&#39;]
std_time = comp_time[&#39;std_computation_time&#39;]
worst_case_time = comp_time[&#39;mean_computation_time&#39;] + 3*comp_time[&#39;std_computation_time&#39;] if worst_case_time &lt; control_period: print(&quot;✓ Real-time feasible&quot;)
else: print(&quot;✗ Timing constraint violated&quot;)
``` **Jitter Analysis:** ```
Jitter = std(computation_time) Low jitter (&lt;10% of mean) → Predictable timing
High jitter (&gt;30% of mean) → May cause control instability
</pre></div>
</div>
<hr class="docutils" />
<section id="best-practices-and-pitfalls-7-1-common-pitfalls-pitfall-1-insufficient-sample-size-problem-low-statistical-power-cannot-detect-real-differences-solution">
<h2>7. Best Practices and Pitfalls ### 7.1 Common Pitfalls #### Pitfall 1: Insufficient Sample Size <strong>Problem:</strong> Low statistical power → cannot detect real differences. <strong>Solution:</strong><a class="headerlink" href="#best-practices-and-pitfalls-7-1-common-pitfalls-pitfall-1-insufficient-sample-size-problem-low-statistical-power-cannot-detect-real-differences-solution" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Always check power</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">suite</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_types</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;power_analysis&#39;</span><span class="p">])</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;power_analysis&#39;</span><span class="p">][</span><span class="s1">&#39;power_adequate&#39;</span><span class="p">]:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;⚠ Need </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;power_analysis&#39;</span><span class="p">][</span><span class="s1">&#39;recommended_sample_size&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> samples&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="pitfall-2-multiple-testing-without-correction-problem-20-tests-at-0-05-expect-1-false-positive-solution">
<h2>Pitfall 2: Multiple Testing Without Correction <strong>Problem:</strong> 20 tests at α=0.05 → expect 1 false positive. <strong>Solution:</strong><a class="headerlink" href="#pitfall-2-multiple-testing-without-correction-problem-20-tests-at-0-05-expect-1-false-positive-solution" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">StatisticalTestConfig</span><span class="p">(</span> <span class="n">multiple_comparisons_correction</span><span class="o">=</span><span class="s2">&quot;holm&quot;</span> <span class="c1"># Use Holm or FDR</span>
<span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<section id="pitfall-3-confusing-statistical-and-practical-significance-problem-p-0-05-doesn-t-mean-the-effect-is-important-solution">
<h3>Pitfall 3: Confusing Statistical and Practical Significance <strong>Problem:</strong> p &lt; 0.05 doesn’t mean the effect is important. <strong>Solution:</strong><a class="headerlink" href="#pitfall-3-confusing-statistical-and-practical-significance-problem-p-0-05-doesn-t-mean-the-effect-is-important-solution" title="Link to this heading">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Always report effect size</span>
<span class="k">if</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;p_value&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span> <span class="n">effect_size</span> <span class="o">=</span> <span class="n">compute_cohens_d</span><span class="p">(</span><span class="n">group1</span><span class="p">,</span> <span class="n">group2</span><span class="p">)</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">effect_size</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;⚠ Statistically significant but negligible effect&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="pitfall-4-inappropriate-cross-validation-for-time-series-problem-using-standard-k-fold-on-time-series-leaks-future-information-solution">
<h2>Pitfall 4: Inappropriate Cross-Validation for Time Series <strong>Problem:</strong> Using standard K-fold on time series leaks future information. <strong>Solution:</strong><a class="headerlink" href="#pitfall-4-inappropriate-cross-validation-for-time-series-problem-using-standard-k-fold-on-time-series-leaks-future-information-solution" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># For time series, ALWAYS use time series CV</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CrossValidationConfig</span><span class="p">(</span> <span class="n">cv_method</span><span class="o">=</span><span class="s2">&quot;time_series&quot;</span> <span class="c1"># Not &quot;k_fold&quot;!</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="pitfall-5-ignoring-non-normality-problem-using-t-tests-on-non-normal-data-invalid-conclusions-solution">
<h2>Pitfall 5: Ignoring Non-Normality <strong>Problem:</strong> Using t-tests on non-normal data → invalid conclusions. <strong>Solution:</strong><a class="headerlink" href="#pitfall-5-ignoring-non-normality-problem-using-t-tests-on-non-normal-data-invalid-conclusions-solution" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check normality first</span>
<span class="n">normality</span> <span class="o">=</span> <span class="n">suite</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_types</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;normality_tests&#39;</span><span class="p">])</span> <span class="k">if</span> <span class="n">normality_rejected</span><span class="p">:</span> <span class="c1"># Use non-parametric test use_mann_whitney_u() # Instead of t-test # OR transform data log_data = np.log(data) # OR use bootstrap CI</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="pitfall-6-overfitting-in-parameter-tuning-problem-pso-optimizes-perfectly-for-training-scenarios-fails-on-new-ones-solution">
<h2>Pitfall 6: Overfitting in Parameter Tuning <strong>Problem:</strong> PSO optimizes perfectly for training scenarios, fails on new ones. <strong>Solution:</strong><a class="headerlink" href="#pitfall-6-overfitting-in-parameter-tuning-problem-pso-optimizes-perfectly-for-training-scenarios-fails-on-new-ones-solution" title="Link to this heading">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use nested CV for unbiased evaluation</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">CrossValidationConfig</span><span class="p">(</span> <span class="n">enable_nested_cv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">inner_cv_splits</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="best-practices-practice-1-pre-register-analysis-plan-before-collecting-data">
<h2>7.2 Best Practices #### Practice 1: Pre-Register Analysis Plan <strong>Before collecting data:</strong><a class="headerlink" href="#best-practices-practice-1-pre-register-analysis-plan-before-collecting-data" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>State hypotheses</p></li>
<li><p>Choose metrics</p></li>
<li><p>Select statistical tests</p></li>
<li><p>Determine sample size (power analysis) <strong>Prevents:</strong> p-hacking, HARKing (Hypothesizing After Results Known)</p></li>
</ol>
<hr class="docutils" />
<section id="practice-2-report-effect-sizes-always-report">
<h3>Practice 2: Report Effect Sizes <strong>Always report:</strong><a class="headerlink" href="#practice-2-report-effect-sizes-always-report" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Test statistic</p></li>
<li><p>p-value</p></li>
<li><p><strong>Effect size</strong> (Cohen’s d, η², etc.)</p></li>
<li><p>Confidence intervals <strong>Example:</strong></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;Controller A achieved 20</span><span class="si">% f</span><span class="s2">aster settling time than B (2.0s vs. 2.5s),</span>
<span class="n">t</span><span class="p">(</span><span class="mi">58</span><span class="p">)</span><span class="o">=</span><span class="mf">3.2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mf">0.85</span> <span class="p">(</span><span class="n">large</span> <span class="n">effect</span><span class="p">),</span> <span class="mi">95</span><span class="o">%</span> <span class="n">CI</span> <span class="p">[</span><span class="mf">0.2</span><span class="n">s</span><span class="p">,</span> <span class="mf">0.8</span><span class="n">s</span><span class="p">]</span><span class="s2">&quot;</span>
</pre></div>
</div>
<hr class="docutils" />
<section id="practice-3-visualize-uncertainty-don-t-just-report-means">
<h4>Practice 3: Visualize Uncertainty <strong>Don’t just report means:</strong><a class="headerlink" href="#practice-3-visualize-uncertainty-don-t-just-report-means" title="Link to this heading">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span> <span class="c1"># Show distribution, not just mean</span>
<span class="n">plt</span><span class="o">.</span><span class="n">violinplot</span><span class="p">([</span><span class="n">data_A</span><span class="p">,</span> <span class="n">data_B</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">([</span><span class="n">data_A</span><span class="p">,</span> <span class="n">data_B</span><span class="p">])</span> <span class="c1"># Show confidence intervals</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">yerr</span><span class="o">=</span><span class="n">confidence_intervals</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="practice-4-use-multiple-validation-methods-triangulation-converging-evidence-from-multiple-methods-increases-confidence-python">
<h4>Practice 4: Use Multiple Validation Methods <strong>Triangulation:</strong> Converging evidence from multiple methods increases confidence. ```python<a class="headerlink" href="#practice-4-use-multiple-validation-methods-triangulation-converging-evidence-from-multiple-methods-increases-confidence-python" title="Link to this heading">¶</a></h4>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="example-metadata">
<h1>example-metadata:<a class="headerlink" href="#example-metadata" title="Link to this heading">¶</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="runnable-false-monte-carlo-cross-validation-statistical-tests">
<h1>runnable: false # Monte Carlo + Cross-Validation + Statistical Tests<a class="headerlink" href="#runnable-false-monte-carlo-cross-validation-statistical-tests" title="Link to this heading">¶</a></h1>
<p>mc_result = mc_analyzer.validate(…)
cv_result = cv_validator.validate(…)
stat_result = stat_suite.validate(…) # If all agree → high confidence</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="if-diverge-investigate-why">
<h1>If diverge → investigate why<a class="headerlink" href="#if-diverge-investigate-why" title="Link to this heading">¶</a></h1>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="o">---</span>

<span class="c1">## Practice 5: Document Assumptions **Always state:**</span>
<span class="o">-</span> <span class="n">Distributional</span> <span class="n">assumptions</span> <span class="p">(</span><span class="n">normality</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span><span class="p">)</span>
<span class="o">-</span> <span class="n">Independence</span> <span class="n">assumptions</span>
<span class="o">-</span> <span class="n">Stationarity</span> <span class="n">assumptions</span>
<span class="o">-</span> <span class="n">Validation</span> <span class="n">of</span> <span class="n">assumptions</span> <span class="o">**</span><span class="n">Example</span><span class="p">:</span><span class="o">**</span>
</pre></div>
</div>
<p>“Assumption: Tracking errors are normally distributed.
Validation: Shapiro-Wilk test W=0.98, p=0.23 → cannot reject normality.”</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
---

### 7.3 Checklist for Publication-Ready Validation **Monte Carlo:**
- [ ] Appropriate sampling method for dimensionality
- [ ] Convergence analysis performed
- [ ] Sample size justified (power analysis)
- [ ] Sensitivity analysis included
- [ ] Random seed reported for reproducibility **Cross-Validation:**
- [ ] Method appropriate for data structure (time series vs. i.i.d.)
- [ ] Sufficient folds/repetitions
- [ ] Metrics aligned with application
- [ ] Bias-variance analysis performed
- [ ] Overfitting assessed **Statistical Testing:**
- [ ] Assumptions validated (normality, etc.)
- [ ] Appropriate test selected
- [ ] Multiple comparison correction applied
- [ ] Effect sizes reported
- [ ] Confidence intervals provided **Benchmark Comparison:**
- [ ] Fair comparison (same scenarios, resources)
- [ ] Statistical significance tested
- [ ] Robustness compared
- [ ] Computational cost reported
- [ ] Limitations discussed **Uncertainty Quantification:**
- [ ] Confidence intervals for all estimates
- [ ] Distribution fitting with goodness-of-fit tests
- [ ] Risk analysis for safety-critical applications
- [ ] Sensitivity to assumptions analyzed **Reproducibility:**
- [ ] Random seeds documented
- [ ] Software versions listed
- [ ] Hyperparameters reported
- [ ] Data availability statement
- [ ] Code archived (e.g., GitHub, Zenodo)

---

## References **Monte Carlo Methods:**
1. Kroese, D.P., et al. &quot;Why the Monte Carlo method is so important today.&quot; WIREs Computational Statistics, 2014.
2. McKay, M.D., et al. &quot;A Comparison of Three Methods for Selecting Values of Input Variables in the Analysis of Output from a Computer Code.&quot; Technometrics, 1979. [Latin Hypercube Sampling] **Cross-Validation:**
3. Hastie, T., Tibshirani, R., Friedman, J. &quot;The Elements of Statistical Learning.&quot; Springer, 2009. [Chapter 7: Model Assessment and Selection]
4. Bergmeir, C., Benítez, J.M. &quot;On the use of cross-validation for time series predictor evaluation.&quot; Information Sciences, 2012. **Statistical Testing:**
5. Razali, N.M., Wah, Y.B. &quot;Power comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests.&quot; Journal of Statistical Modeling and Analytics, 2011.
6. Benjamini, Y., Hochberg, Y. &quot;Controlling the False Discovery Rate: A Practical and Approach to Multiple Testing.&quot; JRSS-B, 1995. **Effect Size:**
7. Cohen, J. &quot;Statistical Power Analysis for the Behavioral Sciences.&quot; 2nd ed., 1988.
8. Sullivan, G.M., Feinn, R. &quot;Using Effect Size—or Why the P Value Is Not Enough.&quot; Journal of Graduate Medical Education, 2012. **Uncertainty Quantification:**
9. Smith, R.C. &quot;Uncertainty Quantification: Theory, Implementation, and Applications.&quot; SIAM, 2013.
10. Saltelli, A., et al. &quot;Global Sensitivity Analysis: The Primer.&quot; Wiley, 2008. **Control Systems:**
11. Åström, K.J., Murray, R.M. &quot;Feedback Systems: An Introduction for Scientists and Engineers.&quot; Princeton, 2008.
12. Ljung, L. &quot;System Identification: Theory for the User.&quot; Prentice Hall, 1999. [Cross-validation for model selection]

---

## Related Documentation **Phase 2 (Theory Foundations):**
- [SMC Theory Complete](../theory/smc_theory_complete.md) - Control-theoretic foundations
- [PSO Optimization Complete](../theory/pso_optimization_complete.md) - Optimization theory
- [Lyapunov Stability Analysis](../theory/lyapunov_stability_analysis.md) - Stability guarantees **Phase 3.1-3.2 (Performance Analysis):**
- [Controller Performance Benchmarks](../benchmarks/controller_performance_benchmarks.md) - Benchmark results
- [Performance Benchmarking Guide](../testing/guides/performance_benchmarking.md) - Testing protocols **API References:**
- [Monte Carlo Analyzer](../reference/analysis/validation_monte_carlo.md)
- [Cross Validator](../reference/analysis/validation_cross_validation.md)
- [Statistical Test Suite](../reference/analysis/validation_statistical_tests.md)
- [Benchmark Suite](../reference/analysis/validation_benchmarking.md)

---

**Document Metadata:**
- **Implementation:** `src/analysis/validation/` (4 modules, 3,777 lines)
- **Examples:** See `docs/validation/validation_examples.md`
- **Workflow:** See `docs/validation/validation_workflow.md`
- **API Reference:** See `docs/validation/api_reference.md`
- **Version:** Phase 3.3 Completion
- **Last Updated:** 2025-10-07
</pre></div>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="validation_examples.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Validation Examples: Practical Implementation Guide <strong>Document Status:</strong> Phase 3.3 Completion - Executable Examples</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="simulation_validation_guide.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Simulation Validation Guide &gt; <strong>Note:</strong> Simulation validation is covered in multiple guides. ## Quick Links - <strong><span class="xref myst">Validation Examples</span></strong> - Practical validation patterns</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Research Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Simulation Result Validation Methodology <strong>Document Status:</strong> Phase 3.3 Completion - Monte Carlo and Statistical Testing Framework</a><ul>
<li><a class="reference internal" href="#table-of-contents-1-monte-carlo-simulation-methodology">Table of Contents 1. <span class="xref myst">Monte Carlo Simulation Methodology</span></a></li>
<li><a class="reference internal" href="#monte-carlo-simulation-methodology-1-1-overview-monte-carlo-simulation-propagates-uncertainty-through-control-system-models-to-quantify-performance-variability-and-validate-stability-claims-under-realistic-conditions-implementation-src-analysis-validation-monte-carlo-py-1-007-lines-1-2-sampling-strategies-1-2-1-random-sampling-baseline-description-standard-pseudorandom-sampling-from-specified-distributions-use-cases">1. Monte Carlo Simulation Methodology ### 1.1 Overview Monte Carlo simulation propagates uncertainty through control system models to quantify performance variability and validate stability claims under realistic conditions. <strong>Implementation:</strong> <code class="docutils literal notranslate"><span class="pre">src/analysis/validation/monte_carlo.py</span></code> (1,007 lines) ### 1.2 Sampling Strategies #### 1.2.1 Random Sampling (Baseline) <strong>Description:</strong> Standard pseudorandom sampling from specified distributions. <strong>Use Cases:</strong></a></li>
<li><a class="reference internal" href="#benchmark-comparison-methodology-4-1-overview-rigorous-statistical-comparison-of-multiple-controllers-methods-implementation-src-analysis-validation-benchmarking-py-841-lines-workflow">4. Benchmark Comparison Methodology ### 4.1 Overview Rigorous statistical comparison of multiple controllers/methods. <strong>Implementation:</strong> <code class="docutils literal notranslate"><span class="pre">src/analysis/validation/benchmarking.py</span></code> (841 lines) <strong>Workflow:</strong></a><ul>
<li><a class="reference internal" href="#performance-metrics-selection-key-principle-select-metrics-aligned-with-application-requirements-standard-control-metrics-metric-definition-use-case">4.2 Performance Metrics Selection <strong>Key Principle:</strong> Select metrics aligned with application requirements. <strong>Standard Control Metrics:</strong> | Metric | Definition | Use Case |</a></li>
<li><a class="reference internal" href="#statistical-significance-testing-workflow-1-run-trials-each-method-each-scenario-multiple-trials">4.3 Statistical Significance Testing <strong>Workflow:</strong> 1. <strong>Run Trials:</strong> Each method × each scenario × multiple trials</a></li>
<li><a class="reference internal" href="#robustness-comparison-robustness-measures-1-coefficient-of-variation-cv-cv-lower-cv-more-robust-consistent-performance-2-interquartile-range-iqr-iqr-q3-q1-smaller-iqr-less-variability-3-worst-case-performance-worst-case-95th-percentile-of-error-critical-for-safety-critical-systems-implementation">4.4 Robustness Comparison <strong>Robustness Measures:</strong> 1. <strong>Coefficient of Variation (CV):</strong> <code class="docutils literal notranslate"><span class="pre">CV</span> <span class="pre">=</span> <span class="pre">σ</span> <span class="pre">/</span> <span class="pre">|μ|</span> <span class="pre">Lower</span> <span class="pre">CV</span> <span class="pre">=</span> <span class="pre">more</span> <span class="pre">robust</span> <span class="pre">(consistent</span> <span class="pre">performance)</span></code> 2. <strong>Interquartile Range (IQR):</strong> <code class="docutils literal notranslate"><span class="pre">IQR</span> <span class="pre">=</span> <span class="pre">Q₃</span> <span class="pre">-</span> <span class="pre">Q₁</span> <span class="pre">Smaller</span> <span class="pre">IQR</span> <span class="pre">=</span> <span class="pre">less</span> <span class="pre">variability</span></code> 3. <strong>Worst-Case Performance:</strong> <code class="docutils literal notranslate"><span class="pre">Worst-case</span> <span class="pre">=</span> <span class="pre">95th</span> <span class="pre">percentile</span> <span class="pre">of</span> <span class="pre">error</span> <span class="pre">Critical</span> <span class="pre">for</span> <span class="pre">safety-critical</span> <span class="pre">systems</span></code> <strong>Implementation:</strong></a></li>
<li><a class="reference internal" href="#efficiency-comparison-computational-efficiency-metrics-1-mean-computation-time-average-time-per-simulation">4.5 Efficiency Comparison <strong>Computational Efficiency Metrics:</strong> 1. <strong>Mean Computation Time:</strong> Average time per simulation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#borda-count-multi-metric-description-aggregate-rankings-across-multiple-metrics-algorithm-1-rank-methods-for-each-metric">4.6.2 Borda Count (Multi-Metric) <strong>Description:</strong> Aggregate rankings across multiple metrics. <strong>Algorithm:</strong> 1. Rank methods for each metric</a><ul>
<li><a class="reference internal" href="#weighted-score-description-weight-metrics-by-importance">4.6.3 Weighted Score <strong>Description:</strong> Weight metrics by importance. ```</a></li>
</ul>
</li>
<li><a class="reference internal" href="#uncertainty-quantification-5-1-overview-quantify-uncertainty-in-performance-predictions-and-stability-guarantees-sources-of-uncertainty">5. Uncertainty Quantification ### 5.1 Overview Quantify uncertainty in performance predictions and stability guarantees. <strong>Sources of Uncertainty:</strong></a><ul>
<li><a class="reference internal" href="#confidence-intervals-parametric-ci-normal-assumption">5.2 Confidence Intervals <strong>Parametric CI (Normal Assumption):</strong> ```</a></li>
</ul>
</li>
<li><a class="reference internal" href="#risk-analysis-for-safety-critical-systems-value-at-risk-var">5.4 Risk Analysis for Safety-Critical Systems <strong>Value at Risk (VaR):</strong> ```</a></li>
<li><a class="reference internal" href="#integration-with-control-systems-6-1-validation-workflow-for-new-controllers-standard-validation-protocol">6. Integration with Control Systems ### 6.1 Validation Workflow for New Controllers <strong>Standard Validation Protocol:</strong> ```</a></li>
<li><a class="reference internal" href="#adaptive-controller-validation-challenge-performance-depends-on-online-adaptation-cannot-use-standard-cv-time-series-validation-approach-python">6.3 Adaptive Controller Validation <strong>Challenge:</strong> Performance depends on online adaptation - cannot use standard CV. <strong>Time Series Validation Approach:</strong> ```python</a></li>
</ul>
</li>
<li><a class="reference internal" href="#controller-adapts-on-t0-t1">- Controller adapts on [t₀, t₁]</a></li>
<li><a class="reference internal" href="#performance-evaluated-on-t1-gap-t2">- Performance evaluated on [t₁+gap, t₂]</a><ul>
<li><a class="reference internal" href="#best-practices-and-pitfalls-7-1-common-pitfalls-pitfall-1-insufficient-sample-size-problem-low-statistical-power-cannot-detect-real-differences-solution">7. Best Practices and Pitfalls ### 7.1 Common Pitfalls #### Pitfall 1: Insufficient Sample Size <strong>Problem:</strong> Low statistical power → cannot detect real differences. <strong>Solution:</strong></a></li>
<li><a class="reference internal" href="#pitfall-2-multiple-testing-without-correction-problem-20-tests-at-0-05-expect-1-false-positive-solution">Pitfall 2: Multiple Testing Without Correction <strong>Problem:</strong> 20 tests at α=0.05 → expect 1 false positive. <strong>Solution:</strong></a><ul>
<li><a class="reference internal" href="#pitfall-3-confusing-statistical-and-practical-significance-problem-p-0-05-doesn-t-mean-the-effect-is-important-solution">Pitfall 3: Confusing Statistical and Practical Significance <strong>Problem:</strong> p &lt; 0.05 doesn’t mean the effect is important. <strong>Solution:</strong></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pitfall-4-inappropriate-cross-validation-for-time-series-problem-using-standard-k-fold-on-time-series-leaks-future-information-solution">Pitfall 4: Inappropriate Cross-Validation for Time Series <strong>Problem:</strong> Using standard K-fold on time series leaks future information. <strong>Solution:</strong></a></li>
<li><a class="reference internal" href="#pitfall-5-ignoring-non-normality-problem-using-t-tests-on-non-normal-data-invalid-conclusions-solution">Pitfall 5: Ignoring Non-Normality <strong>Problem:</strong> Using t-tests on non-normal data → invalid conclusions. <strong>Solution:</strong></a></li>
<li><a class="reference internal" href="#pitfall-6-overfitting-in-parameter-tuning-problem-pso-optimizes-perfectly-for-training-scenarios-fails-on-new-ones-solution">Pitfall 6: Overfitting in Parameter Tuning <strong>Problem:</strong> PSO optimizes perfectly for training scenarios, fails on new ones. <strong>Solution:</strong></a></li>
<li><a class="reference internal" href="#best-practices-practice-1-pre-register-analysis-plan-before-collecting-data">7.2 Best Practices #### Practice 1: Pre-Register Analysis Plan <strong>Before collecting data:</strong></a><ul>
<li><a class="reference internal" href="#practice-2-report-effect-sizes-always-report">Practice 2: Report Effect Sizes <strong>Always report:</strong></a><ul>
<li><a class="reference internal" href="#practice-3-visualize-uncertainty-don-t-just-report-means">Practice 3: Visualize Uncertainty <strong>Don’t just report means:</strong></a></li>
<li><a class="reference internal" href="#practice-4-use-multiple-validation-methods-triangulation-converging-evidence-from-multiple-methods-increases-confidence-python">Practice 4: Use Multiple Validation Methods <strong>Triangulation:</strong> Converging evidence from multiple methods increases confidence. ```python</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#example-metadata">example-metadata:</a></li>
<li><a class="reference internal" href="#runnable-false-monte-carlo-cross-validation-statistical-tests">runnable: false # Monte Carlo + Cross-Validation + Statistical Tests</a></li>
<li><a class="reference internal" href="#if-diverge-investigate-why">If diverge → investigate why</a></li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>