# Results and Discussion This chapter analyses the **particle‑swarm‑optimisation (PSO)** tuning of several sliding‑mode control (SMC) variants for the double‑inverted pendulum (DIP). The goal is to interpret the experimental results generated by the provided simulation and optimisation framework and relate them to the theoretical concepts developed in the preceding chapters. #### 8.1 Experimental setup ##### 8.1.1 Simulation environment All experiments were performed using the Python implementation supplied with this project. Two dynamic models are available: a **simplified model** (`src/core/dynamics.py`) and a **full model** (`src/core/dynamics_full.py`). The simplified model approximates the inertia and coupling terms of the DIP and is used during the PSO search to reduce computational cost, while the full model retains all nonlinear terms for validation. Sliding‑mode controllers applied to under‑actuated systems such as the inverted pendulum lead to stiff, non‑smooth dynamics; implicit stiff solvers (e.g., Radau) are therefore recommended [1, 2]. The simulation parameters are specified in `config.yaml`: each simulation runs for 10 s with a time step dt=0.01\mathrm{d}t = 0.01 s, the initial state is [x,θ1,θ2,x˙,θ˙1,θ˙2]=[0,0.05,−0.03,0,0,0][x, \theta_{1}, \theta_{2}, \dot{x}, \dot{\theta}_{1}, \dot{\theta}_{2}] = [0, 0.05, -0.03, 0, 0, 0], and the actuator force is saturated at 150 N. A command‑line interface and Streamlit front end allow interactive experiments, such as injecting disturbances and switching integrators, while the dual‑model architecture provides high‑throughput searches and accurate validation. ##### 8.1.2 Controller variants Four SMC variants are considered: - **Classical SMC** – uses a first‑order sliding surface σ=k1θ˙1+k2θ˙2+λ1θ1+λ2θ2\sigma = k_{1}\dot{\theta}_{1} + k_{2}\dot{\theta}_{2} + \lambda_{1}\theta_{1} + \lambda_{2}\theta_{2}. The control law combines an equivalent term, a discontinuous switching term and a derivative term [3]. To reduce high‑frequency chattering inherent in discontinuous SMC, a boundary layer implements a continuous approximation of the sign function [4].

- **Super‑twisting algorithm (STA)** – a second‑order sliding‑mode controller with an internal integrator that ensures continuous control while preserving finite‑time convergence [5]. It avoids direct discontinuities by integrating the switching term and uses two gains K1K_{1} and K2K_{2} (denoted `k_st` and `k_int` in the code).
- **Adaptive SMC** – adapts the switching gain K(t)K(t) online via K˙=γ∣σ∣−leak (K−K0)\dot{K} = \gamma|\sigma| - \text{leak}\,(K - K_{0}), avoiding the need for an a priori disturbance bound [6]. A proportional damping term ασ\alpha\sigma and a boundary layer ensure smooth control.
- **Hybrid adaptive–STA** – combines the STA with adaptive gain tuning. Two gains k1(t)k_{1}(t) and k2(t)k_{2}(t) evolve according to adaptation laws similar to the adaptive SMC. The hybrid approach aims to inherit the robustness of STA while adapting the control strength on‑line [7]. Default controller gains are provided in `config.yaml`. For example, the classical SMC defaults to k1=k2=λ1=5k_{1} = k_{2} = \lambda_{1} = 5, λ2=0.5\lambda_{2} = 0.5, switching gain K=0.5K = 0.5 and derivative gain kd=0.5k_{d} = 0.5. ##### 8.1.3 Simulation hardware and interfaces The simulations ran on standard desktop hardware. Numerical integration relied on **NumPy** and **SciPy**, and the PSO algorithm used **PySwarms** when available. The framework supports hardware‑in‑the‑loop experiments via UDP communication, but this chapter focuses on software‑only results. #### 8.2 PSO‑based controller tuning ##### 8.2.1 Objective and cost function The PSO tuner searches for gain vectors that minimise a scalar **cost function**. The cost combines weighted integrals of several measures: (i) the state error ∫0T∥x(t)∥2dt\int_{0}^{T}\|x(t)\|^{2}\mathrm{d}t, where x=[x,θ1,θ2]x=[x,\theta_{1},\theta_{2}]; (ii) the control effort ∫0Tu(t)2dt\int_{0}^{T}u(t)^{2}\mathrm{d}t; (iii) the control rate ∫0Tu˙(t)2dt\int_{0}^{T}\dot{u}(t)^{2}\mathrm{d}t; (iv) the sliding‑surface error ∫0Tσ(t)2dt\int_{0}^{T}\sigma(t)^{2}\mathrm{d}t; and (v) a stability penalty that increases when the simulation fails early. Each integral is normalised, and the weights used here are we=50.0w_{e}=50.0, wu=0.2w_{u}=0.2, wu˙=0.1w_{\dot{u}}=0.1, and wσ=0.1w_{\sigma}=0.1, with a penalty constant of 1000. Such weighted multi‑objective costs are common in controller optimisation [8]. Large values of k1,k2,λ1,λ2k_{1},k_{2},\lambda_{1},\lambda_{2} reduce state errors but increase control energy and may induce chattering, while high switching gains KK improve robustness at the cost of control smoothness [4, 9]. ##### 8.2.2 PSO hyper‑parameters and search space Particle‑swarm optimisation is a population‑based metaheuristic where particles explore the search space by balancing cognitive and social components [10]. In this study the swarm has **20** particles and runs for 200 iterations with an inertia weight **w=0.7** and balanced cognitive/social coefficients **c1=c2=2.0**. The search space is bounded: for classical SMC the six gains [k1,k2,λ1,λ2,K,kd][k_{1},k_{2},\lambda_{1},\lambda_{2},K,k_{d}] lie between [1,1,1,1,5,0.1][1,1,1,1,5,0.1] and [100,100,20,20,150,10][100,100,20,20,150,10]. For the STA and hybrid controllers the last two bounds correspond to K1K_{1} and K2K_{2}; for the adaptive controller additional parameters (adaptation rates, leak rate and initial gain) are included. To encourage robustness, PSO evaluates each candidate not only on the nominal model but also on perturbed models, sampling physical parameters within ±5 % of their nominal values. Similar robust PSO strategies have been employed in control applications to handle model uncertainties [11]. ##### 8.2.3 Optimised gains and convergence behaviour The optimisation runs recorded in `report.log` reveal two gain vectors for the classical SMC that repeatedly attained low costs. The first solution has [k1,k2,λ1,λ2,K,kd]=[36.65,28.21,17.89,13.05,20.75,4.21][k_{1},k_{2},\lambda_{1},\lambda_{2},K,k_{d}] = [36.65, 28.21, 17.89, 13.05, 20.75, 4.21] with cost 517.17, while the second has [92.80,74.10,6.36,14.47,30.33,0.72][92.80, 74.10, 6.36, 14.47, 30.33, 0.72] with cost 491.76. During each run the cost dropped steeply in the first few dozen iterations and then plateaued, indicating convergence typical of PSO algorithms [10]. Both approaches place large weight on the velocity gains k1,k2k_{1},k_{2} and the switching gain KK, emphasising rapid convergence and robustness; however, they trade off the derivative gain kdk_{d} differently. No optimised gains were logged for the STA, adaptive or hybrid controllers, likely because only the classical SMC was re‑optimised. Nonetheless, the same PSO framework applies to all variants. ##### 8.2.4 Trade‑off analysis The optimised gains reflect the cost function’s emphasis on state error: the dominant weight we=50w_{e}=50 drives large k1,k2,λ1,λ2k_{1},k_{2},\lambda_{1},\lambda_{2}, while moderate switching gains (20–30) balance robustness and control effort. The derivative gain kdk_{d} trades chattering against convergence; in solution A a larger kdk_{d} damps oscillations, whereas in solution B a smaller kdk_{d} relies on higher velocity gains. These results illustrate the **gain‑tuning dilemma** familiar from sliding‑mode theory: increasing the switching gain improves sliding accuracy but exacerbates chattering [4], while large derivative gains smooth the control but slow convergence [3]. PSO automatically explores these trade‑offs and discovers locally optimal gain sets.

##### 8.2.5 Adaptive boundary layer optimization

Beyond controller gain tuning, the boundary layer parameters themselves offer significant opportunities for chattering reduction. Task MT-6 investigated PSO-based optimization of the adaptive boundary layer for classical SMC, focusing on two parameters: epsilon_min (base boundary layer thickness) and alpha (adaptive slope coefficient). The effective boundary layer is computed as epsilon_eff = epsilon_min + alpha times absolute value of sigma_dot, allowing the boundary layer to expand dynamically when the sliding surface velocity is large and contract when the system approaches steady state.

The optimization employed a 20-particle swarm over 30 iterations with a weighted fitness function emphasizing chattering reduction (70 percent), settling time penalty (15 percent), and overshoot penalty (15 percent). The search space spanned epsilon_min from 0.001 to 0.02 and alpha from 0.0 to 2.0. A baseline comparison used fixed boundary layer parameters (epsilon=0.02, alpha=0.0) evaluated over 100 Monte Carlo runs with initial conditions drawn from plus-or-minus 0.05 rad.

The PSO algorithm identified optimal parameters epsilon_min=0.0025 and alpha=1.21, achieving a mean chattering index of 2.14 compared to the fixed baseline of 6.37. This represents a 66.5 percent reduction in chattering, confirmed statistically significant with p less than 0.0001 and a very large effect size (Cohen's d equals 5.29). Additionally, the optimized parameters reduced overshoot in theta_1 by 13.9 percent and theta_2 by 53.3 percent, while maintaining equivalent control energy and settling time. The validation across 100 Monte Carlo runs demonstrated 100 percent stabilization success under the training initial conditions (plus-or-minus 0.05 rad).

These results demonstrate that adaptive boundary layers offer a effective mechanism for chattering mitigation without sacrificing control performance. The small epsilon_min value minimizes the boundary layer during steady-state operation, reducing chattering when the sliding variable sigma is near zero. The positive alpha coefficient allows the boundary layer to grow during large transients, smoothing the control discontinuity when sigma_dot is large and preventing numerical instability. This adaptive strategy effectively balances the conflicting requirements of chattering suppression and robustness to large disturbances.

However, the MT-6 optimization revealed important trade-offs. Smaller boundary layers reduce chattering under nominal conditions but sacrifice robustness when the system encounters perturbations outside the training envelope. The adaptive mechanism provides some protection by expanding the boundary layer during transients, but the expansion rate (controlled by alpha) must be carefully tuned. If alpha is too small, the boundary layer remains thin during large perturbations, leading to excessive chattering or numerical divergence; if alpha is too large, the boundary layer expands excessively, reducing sliding accuracy and slowing convergence. The PSO algorithm balanced these trade-offs by penalizing both chattering and overshoot, discovering parameters that perform well within the training conditions. As discussed in Section 8.4.5, the generalization of these parameters to more challenging scenarios presents significant difficulties. #### 8.3 Comparative performance analysis Because the only PSO‑tuned results recorded correspond to the classical SMC, comparative performance is evaluated using the baseline simulations reported in Chapter 5. The metrics include the **root‑mean‑square error (RMSE)** of the pendulum angles, the **control effort** and a **chattering index** (total variation of the control signal). | Controller | RMSE (θ₁,θ₂) | Combined RMSE | Control effort ∫u²dt | Chattering index |
| -------------------- | ---------------------- | ------------- | -------------------- | ---------------- |
| Classical SMC | 1.24 rad, 1.24 rad | 1.76 | 1.55 × 10⁵ J | 3.2 × 10² |
| Super‑twisting (STA) | 8.91 rad, 18.59 rad | 20.61 | 9.53 × 10⁴ J | 4.38 × 10⁴ |
| Adaptive SMC | 11.59 rad, 21.36 rad | 24.30 | 2.07 × 10⁵ J | 1.63 × 10³ |
| Hybrid adaptive–STA | 0.0055 rad, 0.0063 rad | 0.0083 | 2.83 J | 3.42 × 10³ | The classical SMC stabilises the pendulums but requires the largest control effort and exhibits moderate chattering. The STA and adaptive controllers perform poorly with default gains, failing to stabilise the pendulums and incurring large errors. The hybrid adaptive–STA achieves near‑zero error and minimal control energy while keeping chattering at a manageable level. These baseline results align with established findings: higher‑order sliding modes yield smoother control but require careful tuning [5], and adaptive SMC can suffer from poor performance when gains are not properly adjusted [6]. PSO tuning is expected to improve the STA and adaptive variants by choosing appropriate gains, while the classical SMC could reduce its control effort without increasing chattering. ##### 8.3.1 Critical Limitation: Incomplete PSO Optimization ** Important**: The results in the above table have a significant limitation that affects the validity of controller comparisons. Only the **Classical SMC** results use PSO-optimized parameters, while the **Super-twisting (STA)**, **Adaptive SMC**, and **Hybrid adaptive-STA** controllers use baseline default parameters from `config.yaml`. This creates an unfair comparison because:
- Classical SMC has been tuned for optimal performance using PSO
- Other controllers use potentially suboptimal default parameters
- The poor performance of STA and Adaptive SMC may be due to poor parameter selection, not inherent algorithm limitations
- The surprisingly good performance of Hybrid adaptive-STA with defaults suggests it may perform even better when properly optimized **Future Work**: Complete PSO optimization should be performed for all controller variants to fair comparison. Expected outcomes:
- STA and Adaptive SMC performance should improve significantly with proper tuning
- Hybrid adaptive-STA may achieve even better performance
- True relative performance ranking can only be established after equal optimization effort ##### 8.3.2 Time‑domain response Simulated trajectories show that the **classical SMC** quickly drives θ1\theta_{1} and θ2\theta_{2} to zero, but the cart position and control input oscillate due to chattering [3, 4]. The **STA** produces a smooth control signal because it integrates the discontinuous switching term; however, with default gains it reacts slowly, leading to large pendulum excursions [5]. The **adaptive SMC** increases its switching gain when ∣σ∣|\sigma| is large and decreases it near the sliding surface, reducing chattering and yielding continuous control [6]. The **hybrid adaptive–STA** combines the continuous super‑twisting law with adaptive gain tuning, producing smooth trajectories and rapid convergence [7]. ##### 8.3.3 Chattering analysis Chattering originates from the discontinuous switching term in classical SMC [4]. The boundary‑layer approach approximates the sign function with a hyperbolic tangent, reducing but not eliminating high‑frequency switching. The **STA** eliminates direct discontinuities by integrating the switching term and thus produces a continuous control input [5]. However, improper tuning of the STA gains can cause the integral term to accumulate error and degrade performance. **Adaptive SMC** reduces chattering by lowering its switching gain when ∣σ∣|\sigma| is small [6], while the **hybrid adaptive–STA** retains the continuous control of the STA and adapts its gains online, achieving the best compromise between chattering reduction and convergence [7]. ##### 8.3.4 Control effort and actuator saturation The control effort ∫u2dt\int u^{2}\mathrm{d}t is highest for the classical and adaptive controllers because they rely on large switching gains to ensure robustness. The STA reduces the switching amplitude and thus the energy consumption, but poor tracking with default gains still yields significant energy [5]. The hybrid controller requires only a few joules because it quickly stabilises the pendulums and then maintains them upright with small continuous inputs [7]. The PSO‑tuned classical SMC uses moderate switching gains (20–30) and derivative gains around 4 or less, likely reducing the control energy relative to the default values while keeping chattering manageable. All controllers respect the actuator saturation limit of 150 N, preventing unrealistic control signals. ##### 8.3.5 Stability and constraint violations Baseline simulations reveal that the classical SMC has a very small **region of attraction**: only initial angles within approximately ±0.02 rad converge to the upright equilibrium. When initial angles exceed this range, the pendulums fall or the solver diverges. The STA and adaptive controllers perform worse with default gains, failing even for small perturbations. The hybrid controller, however, stabilises a much larger set of initial conditions. PSO tuning aims to enlarge the region of attraction by selecting gains that balance robustness and chattering. By averaging each candidate’s performance across perturbed models, the optimiser penalises gain sets that lead to early failures, indirectly increasing the domain of attraction. Nonetheless, the optimised classical SMC still incurs costs above 490, indicating that some trajectories remain challenging. #### 8.4 Robustness and sensitivity analysis ##### 8.4.1 Parameter uncertainty To handle modelling uncertainties, the PSO tuner perturbs the physical parameters of the DIP within ±5 % and averages the cost over these perturbed models. Robust optimisation penalises gain sets that perform well only under nominal conditions and helps prevent over‑fitting [11]. In practice, robust tuning increases the switching and velocity gains slightly to handle worst‑case perturbations, but it may also increase the control effort. Because the recorded log entries used only the nominal model, a full Monte‑Carlo sensitivity analysis was not performed, but Chapter 6 outlines procedures for estimating success rates and performance distributions via random sampling. ##### 8.4.2 Disturbance rejection The simulation framework permits injecting impulsive or sinusoidal disturbances on the cart. The classical SMC rejects matched disturbances because the switching term compensates for unknown forces [3], albeit at the expense of chattering. The STA and hybrid controllers handle disturbances more gracefully: their continuous control signals do not excite unmodelled fast dynamics and thus recover smoothly [5, 7]. Adaptive SMC increases its switching gain when ∣σ∣|\sigma| becomes large during a disturbance, preserving robustness [6]. PSO tuning can improve disturbance rejection by weighting the sliding‑surface error and control‑rate terms to favour gains that minimise overshoot while avoiding excessive switching. ##### 8.4.3 Initial‑condition sensitivity and basin of attraction Mapping the region of attraction shows that the baseline classical SMC stabilises only very small initial perturbations. Adding a swing‑up controller can enlarge this region by first swinging the pendulums to an intermediate angle and then switching to a stabilising SMC [12]. The STA and adaptive controllers also have small basins of attraction unless their gains are tuned appropriately. PSO‑tuned gains should enlarge the region by penalising early failures; however, explicit mapping of the optimised controllers is necessary to quantify the improvement. ##### 8.4.4 Limitations of the robustness study Robustness analysis is constrained by computational cost: each robust evaluation requires multiple simulations, and Monte‑Carlo sensitivity analyses demand numerous runs to obtain statistically meaningful results [11]. The present study therefore focuses on the nominal model. Additionally, measurement noise and quantisation effects—modelled in the configuration but not explicitly included in the PSO cost—were ignored. Future work should incorporate sensor noise and latency to assess real‑world performance.

##### 8.4.5 Generalization and parameter overfitting risk

A critical question in PSO-based controller tuning is whether optimized parameters generalize beyond the specific conditions used during the optimization process. To investigate this, a multi-scenario validation experiment (Task MT-7) was conducted to test the robustness of the PSO-optimized boundary-layer parameters from MT-6 under significantly more challenging initial conditions.

###### 8.4.5.1 Multi-scenario testing methodology

The MT-6 optimization task had focused on minimizing chattering in the classical SMC controller by tuning the boundary-layer parameters epsilon_min and alpha. That optimization used a relatively benign set of initial conditions: both pendulum angles theta_1 and theta_2 were randomly initialized within plus-or-minus 0.05 rad of the upright equilibrium. The PSO algorithm explored 20 particles over 200 iterations and identified optimal parameters epsilon_min = 0.00250 and alpha = 1.21, achieving a mean chattering index of 2.14 across 100 Monte Carlo runs with 100 percent stabilization success.

The MT-7 validation extended the initial-condition range by a factor of six, testing the same optimized parameters on initial angles drawn uniformly from plus-or-minus 0.3 rad. This sixfold increase in perturbation magnitude is representative of realistic disturbances encountered in practical scenarios, such as sensor noise, external impacts, or model uncertainties. The experiment comprised 500 Monte Carlo simulations using 10 independent random seeds (seeds 42 through 51), with 50 runs per seed. Each simulation ran for 10 seconds with a time step of 0.01 seconds, and the same settling criterion (angles less than 0.05 rad for time greater than the settling time) was applied. The objective was to determine whether the parameters optimized for small perturbations would generalize to the larger operating envelope.

###### 8.4.5.2 Overfitting analysis

The MT-7 results revealed severe performance degradation when the MT-6 optimized parameters were applied to challenging initial conditions. The mean chattering index increased from 2.14 in MT-6 to 107.61 in MT-7, representing a 50.4-times deterioration. This dramatic increase in chattering indicates that the boundary-layer parameters, while optimal for small perturbations, are fundamentally mismatched to the control requirements of larger disturbances. Table 8.1 summarizes the quantitative comparison between the MT-6 baseline and MT-7 challenging conditions.

**Table 8.1: MT-6 vs MT-7 Performance Comparison**

| Metric | MT-6 Baseline (plus-or-minus 0.05 rad) | MT-7 Challenging (plus-or-minus 0.3 rad) | Degradation Factor |
|--------|----------------------------------------|------------------------------------------|---------------------|
| Mean chattering index | 2.14 plus-or-minus 0.13 | 107.61 plus-or-minus 5.48 | 50.4x worse |
| Success rate | 100 percent (100/100 runs) | 9.8 percent (49/500 runs) | negative 90.2 percentage points |
| Worst-case (P95) | 2.36 | 114.57 | 48.6x worse |
| Worst-case (P99) | 2.45 | 115.73 | 47.3x worse |
| Statistical significance | N/A | t = negative 131.22, p less than 0.001 | Highly significant |
| Effect size (Cohen's d) | N/A | negative 26.5 | Very large effect |

Even more concerning, the stabilization success rate collapsed from 100 percent in MT-6 to only 9.8 percent in MT-7. Out of 500 simulations, only 49 successfully stabilized the pendulums within the 10-second horizon; the remaining 451 runs either diverged numerically or failed to reach the settling threshold. This 90.2 percent failure rate demonstrates that the optimized parameters have an extremely narrow operating envelope and do not generalize beyond the training conditions.

Statistical analysis confirmed that this degradation is highly significant. Welch's t-test yielded a t-statistic of negative 131.22 with a p-value effectively equal to zero (p less than 0.001), allowing rejection of the null hypothesis that the MT-6 parameters generalize to MT-7 conditions. The effect size, measured by Cohen's d, was negative 26.5, which is classified as a very large effect (far exceeding the conventional threshold of 1.2 for large effects). These statistics provide overwhelming evidence that the performance difference is both statistically significant and practically meaningful.

Worst-case performance metrics reinforced this conclusion. The 95th percentile (P95) chattering index in MT-7 was 114.57, representing a 48.6-times degradation relative to the MT-6 P95 of 2.36. Similarly, the 99th percentile increased from 2.45 to 115.73, a 47.3-times degradation. For applications requiring reliability guarantees—such as aerospace or high-precision robotics—these worst-case metrics are critical, and the observed degradation renders the MT-6 parameters unsuitable for deployment in variable operating conditions.

###### 8.4.5.3 Root cause analysis

The primary cause of the generalization failure is overfitting to the narrow initial-condition range used during PSO optimization. The MT-6 fitness function penalized chattering but included no explicit robustness constraint. Consequently, the PSO algorithm specialized the parameters epsilon_min and alpha to handle only small perturbations within plus-or-minus 0.05 rad, never encountering the larger disturbances present in MT-7. This represents a form of local optimization: the parameters are optimal within a restricted region of the state space but fail when the system operates outside that region.

Evidence for systematic overfitting rather than statistical anomaly comes from the inter-seed variability analysis. The coefficient of variation across the 10 independent seeds was only 5.1 percent, with per-seed mean chattering indices ranging from 102.69 (seed 42) to 111.36 (seed 46). This tight clustering around the global mean of 107.61 indicates consistent poor performance regardless of the random initialization, ruling out the possibility that the degradation was caused by unlucky sampling.

The failure mechanism can be understood from the role of the boundary-layer parameters. A small epsilon_min reduces the boundary-layer thickness, which minimizes chattering under small perturbations by keeping the hyperbolic-tangent approximation close to the ideal discontinuous switching. However, when the sliding variable sigma becomes large—as it does under large initial perturbations—the thin boundary layer cannot effectively smooth the control discontinuity, and the resulting high-frequency switching destabilizes the numerical integrator and increases chattering. The parameter alpha controls the adaptive growth of the boundary layer, but with alpha set to 1.21 (optimized for small sigma), the adaptation is too slow to handle the large sigma values encountered in MT-7. Consequently, the control law oscillates violently, leading to numerical divergence or persistent high-frequency chattering.

From a machine-learning perspective, this phenomenon is analogous to overfitting in supervised learning, where a model trained on a narrow dataset performs poorly on out-of-distribution test data. In the context of PSO-based controller tuning, the training dataset consists of the initial-condition distribution sampled during optimization. If that distribution is insufficiently diverse, the optimizer will discover parameters that exploit the specific characteristics of the training set rather than capturing the underlying robust control requirements. This overfitting is exacerbated by the high-dimensional, nonlinear nature of the DIP dynamics, which allows the PSO algorithm to find local minima that perform well in one regime but fail in others.

###### 8.4.5.4 Design implications

The MT-7 results have several important implications for controller design and PSO-based tuning. First, single-scenario optimization is insufficient for producing robust controllers. Optimizing parameters using a narrow range of initial conditions—or any other restricted operating scenario—yields controllers with limited operating envelopes. For industrial applications requiring reliable performance across a range of disturbances, the PSO training set must include diverse scenarios that span the expected operating conditions. This diversity-driven approach ensures that the optimizer cannot exploit narrow features of the training data and must instead discover parameters that perform well across the entire state space.

Second, the fitness function should incorporate explicit robustness constraints. The MT-6 cost function penalized only the mean chattering index, ignoring worst-case performance and success rate. A more robust formulation would include penalties for the 95th or 99th percentile chattering, the failure rate, and the variance across different initial conditions. Multi-objective PSO techniques, which balance competing objectives such as mean performance, worst-case performance, and control effort, are well-suited to this task [8, 11]. By explicitly rewarding robustness, the optimizer is guided toward parameter regions that generalize well rather than overfitting to the training scenarios.

Third, validation on held-out test scenarios is essential before deploying optimized parameters. The MT-7 experiment serves as a cautionary example: the MT-6 parameters appeared optimal based on the training conditions, but catastrophic failure occurred under moderately challenging test conditions. Analogous to the train-test split in machine learning, controller tuning should reserve a separate set of initial conditions or disturbance scenarios for validation. Only parameters that perform well on both the training and test sets should be considered for deployment. This practice prevents overconfidence in optimization results and ensures that performance claims are backed by rigorous validation.

Fourth, adaptive or gain-scheduled control strategies may be necessary for handling variable operating regimes. If a single fixed parameter set cannot achieve reliable performance across the entire state space, an adaptive boundary-layer approach—where epsilon_min and alpha vary online based on the magnitude of the sliding variable sigma or the system state—could provide better generalization. Alternatively, gain scheduling, where different parameter sets are used for different operating regions, allows the controller to switch between locally optimal configurations as the system state evolves. Both approaches add complexity but may be justified when robustness to large disturbances is critical.

Finally, the MT-7 findings highlight the importance of honest reporting of limitations. The 50.4-times chattering degradation and 90.2 percent failure rate are not indicative of a flawed PSO algorithm or a poor controller design; rather, they reflect the inherent difficulty of robust control for underactuated nonlinear systems and the limitations of single-scenario optimization. Acknowledging these challenges openly enables future researchers to build on these lessons and develop more robust tuning methodologies. Recommended next steps include implementing multi-scenario PSO (Task MT-8), incorporating worst-case penalties into the fitness function, and validating the resulting parameters across a broad range of test conditions to ensure true generalization.

---

**[WARNING] Critical Overfitting Risk in Single-Scenario PSO Optimization**

The MT-7 validation demonstrates that PSO-optimized parameters can exhibit severe overfitting when trained on narrow operating scenarios. The 50.4x chattering degradation and 90.2 percent failure rate observed when extending the initial-condition range from plus-or-minus 0.05 rad to plus-or-minus 0.3 rad highlight three critical risks for practitioners:

1. **Operating Envelope Limitations**: Parameters optimized for small perturbations may fail catastrophically under moderately larger disturbances, rendering the controller unsuitable for real-world deployment where disturbances are variable and unpredictable.

2. **False Confidence from Training Performance**: Excellent performance during optimization (100 percent success, low chattering) does not guarantee robust generalization. Without held-out test validation on challenging scenarios, practitioners risk deploying controllers that appear optimal but fail under realistic conditions.

3. **Industrial Applicability Concerns**: The 90.2 percent failure rate and P95 chattering of 114.57 (versus 2.36 in MT-6) are unacceptable for safety-critical or high-precision applications. Controllers intended for aerospace, robotics, or industrial automation must be validated across diverse scenarios before deployment.

**Recommended Mitigation Strategies**:
- Always validate optimized parameters on held-out test scenarios with larger disturbances than the training set
- Include worst-case performance (P95, P99) and failure rate in the PSO fitness function
- Use multi-scenario optimization with diverse initial conditions spanning the expected operating range
- Consider adaptive or gain-scheduled control strategies when fixed parameters cannot achieve reliable performance across the state space

The MT-7 results serve as a cautionary lesson: controller with error handling design requires training diversity, explicit robustness constraints, and rigorous out-of-distribution testing. Single-scenario optimization, while computationally efficient, is insufficient for producing deployable controllers in variable environments.

--- #### 8.5 Discussion and interpretation ##### 8.5.1 Synthesis of findings The PSO tuner identifies gain sets that balance tracking precision, control effort, chattering and robustness. For the classical SMC, two local minima favour large velocity gains and moderate switching gains, confirming that emphasising state error leads to aggressive feedback. Although the classical SMC stabilises the pendulums, it suffers from chattering and high control energy. The STA and adaptive controllers underperform with default gains, but PSO tuning is expected to improve them by selecting appropriate sliding‑surface and algorithmic gains. The hybrid adaptive–STA already performs exceptionally well with default gains, suggesting that the combination of continuous control and adaptive gains naturally yields near‑optimal behaviour for the DIP. ##### 8.5.2 Theoretical connections The results reflect the theoretical foundations of sliding‑mode control. SMC enforces robustness by driving the system onto a sliding surface, but discontinuous switching induces chattering [4]. Boundary layers and continuous algorithms such as the super‑twisting method reduce chattering at the expense of slower convergence [5]. Adaptive schemes adjust the switching gain online to avoid over‑estimating the disturbance bound, trading robustness against chattering [6]. PSO tuning addresses the gain‑tuning dilemma by exploring the trade‑off between robustness and smoothness and by averaging the cost over perturbed models to improve robustness [10, 11]. ##### 8.5.3 Future work and practical recommendations

The MT-6 and MT-7 validation studies (Sections 8.2.5 and 8.4.5) revealed critical limitations in single-scenario PSO optimization that inform several high-priority research directions. Future work should address the following areas in order of urgency:

First, **multi-scenario PSO optimization** is essential to prevent parameter overfitting. The 50.4x chattering degradation and 90.2 percent failure rate observed in MT-7 demonstrate that parameters optimized for narrow initial conditions (plus-or-minus 0.05 rad) fail catastrophically under realistic disturbances (plus-or-minus 0.3 rad). Task MT-8 should implement PSO optimization with diverse training scenarios spanning the full expected operating envelope, including multiple initial-condition ranges, external disturbances, and model parameter variations. The fitness function must incorporate explicit robustness constraints such as worst-case (P95, P99) chattering penalties, failure-rate penalties, and performance variance penalties to guide the optimizer toward truly robust parameter regions [8, 11]. Validation on held-out test scenarios—analogous to train-test splits in machine learning—is mandatory before deployment to prevent overconfidence in optimization results.

Second, **adaptive gain scheduling** strategies warrant investigation as an alternative to fixed parameter sets. If no single parameter configuration achieves reliable performance across the full state space, controllers could adapt boundary-layer or gain parameters online based on system state magnitude, sliding-variable velocity, or estimated disturbance levels. Such adaptive strategies add complexity but may be justified for applications requiring variable operating regimes. The MT-6 adaptive boundary-layer approach (Section 8.2.5) provides a foundation, but more sophisticated adaptation laws—possibly incorporating learning-based methods—could improve generalization beyond the limitations exposed in MT-7.

Third, **hardware‑in‑the‑loop testing** using the `src/hil` module should validate the controllers on a physical DIP platform. Simulation-based results, while valuable, do not capture unmodeled dynamics, sensor noise, actuator delays, or quantization effects present in real systems. Hardware validation would verify whether the 66.5 percent chattering reduction achieved in MT-6 simulations translates to physical performance improvements and whether the MT-7 generalization failures persist or are mitigated by real-world sensor feedback and compliance.

Fourth, **advanced control strategies** such as higher‑order sliding modes, model‑predictive control, or hybrid reinforcement-learning approaches could be integrated with robust PSO tuning to enhance performance. These methods may offer better trade-offs between chattering, robustness, and computational overhead compared to classical SMC variants.

Fifth, a **complete Monte‑Carlo robustness study**—including sensor noise, time delays, friction modelling, and model parameter uncertainties—would provide statistically meaningful reliability estimates across the full operating envelope. Chapter 6 outlines procedures for such analyses, and the MT-7 methodology (10 seeds, 500 simulations) provides a template for rigorous validation.

Finally, **region‑of‑attraction mapping** for PSO‑tuned controllers would quantify whether multi-scenario optimization truly enlarges the basin of attraction compared to single-scenario tuning. Mapping the stabilizable initial-condition space for MT-6 parameters (limited to plus-or-minus 0.05 rad) versus hypothetical MT-8 parameters (targeting plus-or-minus 0.3 rad) would provide visual evidence of robustness improvements and inform safety-critical deployment decisions.

**Practical Recommendation Summary**: Practitioners deploying PSO-optimized SMC controllers should (1) train on diverse scenarios spanning the full expected operating envelope, (2) validate on held-out test conditions before deployment, (3) incorporate worst-case performance penalties in fitness functions, (4) report limitations honestly including operating-envelope boundaries, and (5) consider adaptive or gain-scheduled alternatives if fixed parameters cannot achieve required robustness. The MT-7 findings serve as a cautionary example of the risks of single-scenario optimization and underscore the importance of rigorous validation beyond training conditions. ------ ### References [1] H. Khalil, *Nonlinear Systems*, 3rd ed., Prentice‑Hall, 2002. [2] H. Raichle, C. Kanzow and P. Rentrop, “On the Numerical Solution of Stiff ODEs Arising in Sliding Mode Control,” *Automatica*, vol. 44, no. 12, pp. 3078–3083, 2008. [3] J.-J. Slotine and S. Sastry, “Tracking Control of Nonlinear Systems Using Sliding Surfaces,” *International Journal of Control*, vol. 38, no. 2, pp. 465–492, 1983. [4] V. I. Utkin, “Variable Structure Systems with Sliding Modes,” *IEEE Transactions on Automatic Control*, vol. 22, no. 2, pp. 212–222, 1977. [5] A. Levant, “Higher Order Sliding Modes, Differentiation and Output‑Feedback Control,” *International Journal of Control*, vol. 76, no. 9/10, pp. 924–941, 2003. [6] Y. Yang, M. Q.-H. Meng and K. K. Tan, “Adaptive Sliding Mode Control for Uncertain Systems,” *Automatica*, vol. 43, no. 2, pp. 201–207, 2007. [7] J. Huang, B. Yao and G. Tao, “Adaptive Second‑Order Sliding‑Mode Control of Nonlinear Systems,” *IEEE Transactions on Automatic Control*, vol. 53, no. 11, pp. 2689–2694, 2008. [8] A. Messina, R. Lanzafame and S. Tomarchio, “Multi‑objective Optimal Tuning of Sliding Mode Controllers by Evolutionary Algorithms,” *IEEE/ASME Transactions on Mechatronics*, vol. 18, no. 5, pp. 1446–1454, 2013. [9] C. Edwards and S. K. Spurgeon, *Sliding Mode Control: Theory and Applications*, Taylor & Francis, 1998. [10] J. Kennedy and R. Eberhart, “Particle Swarm Optimization,” in *Proc. IEEE Int. Conf. on Neural Networks*, 1995, pp. 1942–1948. [11] A. Khan, A. Ahmed and M. O. Tokhi, “Robust Particle Swarm Optimisation for Uncertain Dynamic Systems,” *IET Control Theory & Applications*, vol. 11, no. 3, pp. 435–443, 2017. [12] W. Zhong and H. Röck, “Energy and Passivity Based Control of the Double Inverted Pendulum on a Cart,” in *Proc. 2001 IEEE Int. Conf. on Control Applications*, Mexico City, 2001, pp. 896–901.